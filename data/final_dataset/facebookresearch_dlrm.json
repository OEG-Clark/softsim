{"home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.DataLoader.__init__": [[24, 52], ["os.path.join", "sum", "numpy.load", "int", "numpy.ceil", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "data_filename", ",", "\n", "data_directory", ",", "\n", "days", ",", "\n", "batch_size", ",", "\n", "max_ind_range", "=", "-", "1", ",", "\n", "split", "=", "\"train\"", ",", "\n", "drop_last_batch", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "data_filename", "=", "data_filename", "\n", "self", ".", "data_directory", "=", "data_directory", "\n", "self", ".", "days", "=", "days", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_ind_range", "=", "max_ind_range", "\n", "\n", "total_file", "=", "os", ".", "path", ".", "join", "(", "\n", "data_directory", ",", "\n", "data_filename", "+", "\"_day_count.npz\"", "\n", ")", "\n", "with", "np", ".", "load", "(", "total_file", ")", "as", "data", ":", "\n", "            ", "total_per_file", "=", "data", "[", "\"total_per_file\"", "]", "[", "np", ".", "array", "(", "days", ")", "]", "\n", "\n", "", "self", ".", "length", "=", "sum", "(", "total_per_file", ")", "\n", "if", "split", "==", "\"test\"", "or", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "length", "=", "int", "(", "np", ".", "ceil", "(", "self", ".", "length", "/", "2.", ")", ")", "\n", "", "self", ".", "split", "=", "split", "\n", "self", ".", "drop_last_batch", "=", "drop_last_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.DataLoader.__iter__": [[53, 58], ["iter", "data_loader_terabyte._batch_generator"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._batch_generator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "\n", "_batch_generator", "(", "\n", "self", ".", "data_filename", ",", "self", ".", "data_directory", ",", "self", ".", "days", ",", "\n", "self", ".", "batch_size", ",", "self", ".", "split", ",", "self", ".", "drop_last_batch", ",", "self", ".", "max_ind_range", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.DataLoader.__len__": [[61, 66], ["math.ceil"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "drop_last_batch", ":", "\n", "            ", "return", "self", ".", "length", "//", "self", ".", "batch_size", "\n", "", "else", ":", "\n", "            ", "return", "math", ".", "ceil", "(", "self", ".", "length", "/", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.CriteoBinDataset.__init__": [[200, 223], ["math.ceil", "print", "open", "numpy.load", "os.path.getsize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_file", ",", "counts_file", ",", "\n", "batch_size", "=", "1", ",", "max_ind_range", "=", "-", "1", ",", "bytes_per_feature", "=", "4", ")", ":", "\n", "# dataset", "\n", "        ", "self", ".", "tar_fea", "=", "1", "# single target", "\n", "self", ".", "den_fea", "=", "13", "# 13 dense  features", "\n", "self", ".", "spa_fea", "=", "26", "# 26 sparse features", "\n", "self", ".", "tad_fea", "=", "self", ".", "tar_fea", "+", "self", ".", "den_fea", "\n", "self", ".", "tot_fea", "=", "self", ".", "tad_fea", "+", "self", ".", "spa_fea", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_ind_range", "=", "max_ind_range", "\n", "self", ".", "bytes_per_entry", "=", "(", "bytes_per_feature", "*", "self", ".", "tot_fea", "*", "batch_size", ")", "\n", "\n", "self", ".", "num_entries", "=", "math", ".", "ceil", "(", "os", ".", "path", ".", "getsize", "(", "data_file", ")", "/", "self", ".", "bytes_per_entry", ")", "\n", "\n", "print", "(", "'data file:'", ",", "data_file", ",", "'number of batches:'", ",", "self", ".", "num_entries", ")", "\n", "self", ".", "file", "=", "open", "(", "data_file", ",", "'rb'", ")", "\n", "\n", "with", "np", ".", "load", "(", "counts_file", ")", "as", "data", ":", "\n", "            ", "self", ".", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "\n", "# hardcoded for now", "\n", "", "self", ".", "m_den", "=", "13", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.CriteoBinDataset.__len__": [[224, 226], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_entries", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.CriteoBinDataset.__getitem__": [[227, 238], ["data_loader_terabyte.CriteoBinDataset.file.seek", "data_loader_terabyte.CriteoBinDataset.file.read", "numpy.frombuffer", "torch.from_numpy().view", "data_loader_terabyte._transform_features", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._transform_features"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "self", ".", "file", ".", "seek", "(", "idx", "*", "self", ".", "bytes_per_entry", ",", "0", ")", "\n", "raw_data", "=", "self", ".", "file", ".", "read", "(", "self", ".", "bytes_per_entry", ")", "\n", "array", "=", "np", ".", "frombuffer", "(", "raw_data", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "tensor", "=", "torch", ".", "from_numpy", "(", "array", ")", ".", "view", "(", "(", "-", "1", ",", "self", ".", "tot_fea", ")", ")", "\n", "\n", "return", "_transform_features", "(", "x_int_batch", "=", "tensor", "[", ":", ",", "1", ":", "14", "]", ",", "\n", "x_cat_batch", "=", "tensor", "[", ":", ",", "14", ":", "]", ",", "\n", "y_batch", "=", "tensor", "[", ":", ",", "0", "]", ",", "\n", "max_ind_range", "=", "self", ".", "max_ind_range", ",", "\n", "flag_input_torch_tensor", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.CriteoBinDataset.__del__": [[239, 241], ["data_loader_terabyte.CriteoBinDataset.file.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._transform_features": [[68, 88], ["torch.arange().reshape().repeat", "torch.log", "torch.tensor.clone().detach().type", "torch.tensor().view.clone().detach().type().view", "torch.log", "torch.tensor", "torch.tensor().view", "torch.tensor.t", "torch.tensor().view.view", "torch.arange().reshape", "torch.log.clone().detach().type", "torch.tensor.clone().detach", "torch.tensor().view.clone().detach().type", "torch.tensor", "torch.tensor", "torch.arange", "torch.log.clone().detach", "torch.tensor.clone", "torch.tensor().view.clone().detach", "torch.log.clone", "torch.tensor().view.clone"], "function", ["None"], ["", "", "", "def", "_transform_features", "(", "\n", "x_int_batch", ",", "x_cat_batch", ",", "y_batch", ",", "max_ind_range", ",", "flag_input_torch_tensor", "=", "False", "\n", ")", ":", "\n", "    ", "if", "max_ind_range", ">", "0", ":", "\n", "        ", "x_cat_batch", "=", "x_cat_batch", "%", "max_ind_range", "\n", "\n", "", "if", "flag_input_torch_tensor", ":", "\n", "        ", "x_int_batch", "=", "torch", ".", "log", "(", "x_int_batch", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "type", "(", "torch", ".", "float", ")", "+", "1", ")", "\n", "x_cat_batch", "=", "x_cat_batch", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "type", "(", "torch", ".", "long", ")", "\n", "y_batch", "=", "y_batch", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "type", "(", "torch", ".", "float32", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "x_int_batch", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "x_int_batch", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "x_cat_batch", "=", "torch", ".", "tensor", "(", "x_cat_batch", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "y_batch", "=", "torch", ".", "tensor", "(", "y_batch", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "batch_size", "=", "x_cat_batch", ".", "shape", "[", "0", "]", "\n", "feature_count", "=", "x_cat_batch", ".", "shape", "[", "1", "]", "\n", "lS_o", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "feature_count", ",", "1", ")", "\n", "\n", "return", "x_int_batch", ",", "lS_o", ",", "x_cat_batch", ".", "t", "(", ")", ",", "y_batch", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._batch_generator": [[90, 172], ["os.path.join", "numpy.load", "int", "slice", "slice", "data_loader_terabyte._transform_features", "numpy.ceil", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "ValueError", "data_loader_terabyte._transform_features", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._transform_features", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._transform_features"], ["", "def", "_batch_generator", "(", "\n", "data_filename", ",", "data_directory", ",", "days", ",", "batch_size", ",", "split", ",", "drop_last", ",", "max_ind_range", "\n", ")", ":", "\n", "    ", "previous_file", "=", "None", "\n", "for", "day", "in", "days", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "\n", "data_directory", ",", "\n", "data_filename", "+", "\"_{}_reordered.npz\"", ".", "format", "(", "day", ")", "\n", ")", "\n", "\n", "# print('Loading file: ', filepath)", "\n", "with", "np", ".", "load", "(", "filepath", ")", "as", "data", ":", "\n", "            ", "x_int", "=", "data", "[", "\"X_int\"", "]", "\n", "x_cat", "=", "data", "[", "\"X_cat\"", "]", "\n", "y", "=", "data", "[", "\"y\"", "]", "\n", "\n", "", "samples_in_file", "=", "y", ".", "shape", "[", "0", "]", "\n", "batch_start_idx", "=", "0", "\n", "if", "split", "==", "\"test\"", "or", "split", "==", "\"val\"", ":", "\n", "            ", "length", "=", "int", "(", "np", ".", "ceil", "(", "samples_in_file", "/", "2.", ")", ")", "\n", "if", "split", "==", "\"test\"", ":", "\n", "                ", "samples_in_file", "=", "length", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "                ", "batch_start_idx", "=", "samples_in_file", "-", "length", "\n", "\n", "", "", "while", "batch_start_idx", "<", "samples_in_file", "-", "batch_size", ":", "\n", "\n", "            ", "missing_samples", "=", "batch_size", "\n", "if", "previous_file", "is", "not", "None", ":", "\n", "                ", "missing_samples", "-=", "previous_file", "[", "'y'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "current_slice", "=", "slice", "(", "batch_start_idx", ",", "batch_start_idx", "+", "missing_samples", ")", "\n", "\n", "x_int_batch", "=", "x_int", "[", "current_slice", "]", "\n", "x_cat_batch", "=", "x_cat", "[", "current_slice", "]", "\n", "y_batch", "=", "y", "[", "current_slice", "]", "\n", "\n", "if", "previous_file", "is", "not", "None", ":", "\n", "                ", "x_int_batch", "=", "np", ".", "concatenate", "(", "\n", "[", "previous_file", "[", "'x_int'", "]", ",", "x_int_batch", "]", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "x_cat_batch", "=", "np", ".", "concatenate", "(", "\n", "[", "previous_file", "[", "'x_cat'", "]", ",", "x_cat_batch", "]", ",", "\n", "axis", "=", "0", "\n", ")", "\n", "y_batch", "=", "np", ".", "concatenate", "(", "[", "previous_file", "[", "'y'", "]", ",", "y_batch", "]", ",", "axis", "=", "0", ")", "\n", "previous_file", "=", "None", "\n", "\n", "", "if", "x_int_batch", ".", "shape", "[", "0", "]", "!=", "batch_size", ":", "\n", "                ", "raise", "ValueError", "(", "'should not happen'", ")", "\n", "\n", "", "yield", "_transform_features", "(", "x_int_batch", ",", "x_cat_batch", ",", "y_batch", ",", "max_ind_range", ")", "\n", "\n", "batch_start_idx", "+=", "missing_samples", "\n", "", "if", "batch_start_idx", "!=", "samples_in_file", ":", "\n", "            ", "current_slice", "=", "slice", "(", "batch_start_idx", ",", "samples_in_file", ")", "\n", "if", "previous_file", "is", "not", "None", ":", "\n", "                ", "previous_file", "=", "{", "\n", "'x_int'", ":", "np", ".", "concatenate", "(", "\n", "[", "previous_file", "[", "'x_int'", "]", ",", "x_int", "[", "current_slice", "]", "]", ",", "\n", "axis", "=", "0", "\n", ")", ",", "\n", "'x_cat'", ":", "np", ".", "concatenate", "(", "\n", "[", "previous_file", "[", "'x_cat'", "]", ",", "x_cat", "[", "current_slice", "]", "]", ",", "\n", "axis", "=", "0", "\n", ")", ",", "\n", "'y'", ":", "np", ".", "concatenate", "(", "[", "previous_file", "[", "'y'", "]", ",", "y", "[", "current_slice", "]", "]", ",", "axis", "=", "0", ")", "\n", "}", "\n", "", "else", ":", "\n", "                ", "previous_file", "=", "{", "\n", "'x_int'", ":", "x_int", "[", "current_slice", "]", ",", "\n", "'x_cat'", ":", "x_cat", "[", "current_slice", "]", ",", "\n", "'y'", ":", "y", "[", "current_slice", "]", "\n", "}", "\n", "\n", "", "", "", "if", "not", "drop_last", ":", "\n", "        ", "yield", "_transform_features", "(", "\n", "previous_file", "[", "'x_int'", "]", ",", "\n", "previous_file", "[", "'x_cat'", "]", ",", "\n", "previous_file", "[", "'y'", "]", ",", "\n", "max_ind_range", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._test": [[175, 193], ["data_loader_terabyte._batch_generator", "time.time", "time.time", "print", "range"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._batch_generator"], ["", "", "def", "_test", "(", ")", ":", "\n", "    ", "generator", "=", "_batch_generator", "(", "\n", "data_filename", "=", "'day'", ",", "\n", "data_directory", "=", "'./input'", ",", "\n", "days", "=", "range", "(", "23", ")", ",", "\n", "split", "=", "\"train\"", ",", "\n", "batch_size", "=", "2048", ",", "\n", "drop_last", "=", "True", ",", "\n", "max_ind_range", "=", "-", "1", "\n", ")", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "for", "x_int", ",", "lS_o", ",", "x_cat", ",", "y", "in", "generator", ":", "\n", "        ", "t2", "=", "time", ".", "time", "(", ")", "\n", "time_diff", "=", "t2", "-", "t1", "\n", "t1", "=", "t2", "\n", "print", "(", "\n", "\"time {} x_int.shape: {} lS_o.shape: {} x_cat.shape: {} y.shape: {}\"", ".", "format", "(", "\n", "time_diff", ",", "x_int", ".", "shape", ",", "lS_o", ".", "shape", ",", "x_cat", ".", "shape", ",", "y", ".", "shape", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.numpy_to_binary": [[243, 281], ["open", "numpy.load", "numpy.concatenate", "np_data.astype.astype", "int", "output_file.write", "print", "numpy.load", "numpy.concatenate", "np_data.astype.astype", "output_file.write", "len", "numpy.ceil", "np_data[].tobytes", "np_data.astype.tobytes", "np_data[].reshape", "ValueError", "np_data[].reshape"], "function", ["None"], ["", "", "def", "numpy_to_binary", "(", "input_files", ",", "output_file_path", ",", "split", "=", "'train'", ")", ":", "\n", "    ", "\"\"\"Convert the data to a binary format to be read with CriteoBinDataset.\"\"\"", "\n", "\n", "# WARNING - both categorical and numerical data must fit into int32 for", "\n", "# the following code to work correctly", "\n", "\n", "with", "open", "(", "output_file_path", ",", "'wb'", ")", "as", "output_file", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "for", "input_file", "in", "input_files", ":", "\n", "                ", "print", "(", "'Processing file: '", ",", "input_file", ")", "\n", "\n", "np_data", "=", "np", ".", "load", "(", "input_file", ")", "\n", "np_data", "=", "np", ".", "concatenate", "(", "[", "np_data", "[", "'y'", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "\n", "np_data", "[", "'X_int'", "]", ",", "\n", "np_data", "[", "'X_cat'", "]", "]", ",", "axis", "=", "1", ")", "\n", "np_data", "=", "np_data", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "output_file", ".", "write", "(", "np_data", ".", "tobytes", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "len", "(", "input_files", ")", "==", "1", "\n", "np_data", "=", "np", ".", "load", "(", "input_files", "[", "0", "]", ")", "\n", "np_data", "=", "np", ".", "concatenate", "(", "[", "np_data", "[", "'y'", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "\n", "np_data", "[", "'X_int'", "]", ",", "\n", "np_data", "[", "'X_cat'", "]", "]", ",", "axis", "=", "1", ")", "\n", "np_data", "=", "np_data", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "samples_in_file", "=", "np_data", ".", "shape", "[", "0", "]", "\n", "midpoint", "=", "int", "(", "np", ".", "ceil", "(", "samples_in_file", "/", "2.", ")", ")", "\n", "if", "split", "==", "\"test\"", ":", "\n", "                ", "begin", "=", "0", "\n", "end", "=", "midpoint", "\n", "", "elif", "split", "==", "\"val\"", ":", "\n", "                ", "begin", "=", "midpoint", "\n", "end", "=", "samples_in_file", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown split value: '", ",", "split", ")", "\n", "\n", "", "output_file", ".", "write", "(", "np_data", "[", "begin", ":", "end", "]", ".", "tobytes", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._preprocess": [[283, 300], ["os.makedirs", "print", "os.path.join", "data_loader_terabyte.numpy_to_binary", "range"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.numpy_to_binary"], ["", "", "", "def", "_preprocess", "(", "args", ")", ":", "\n", "    ", "train_files", "=", "[", "'{}_{}_reordered.npz'", ".", "format", "(", "args", ".", "input_data_prefix", ",", "day", ")", "for", "\n", "day", "in", "range", "(", "0", ",", "23", ")", "]", "\n", "\n", "test_valid_file", "=", "args", ".", "input_data_prefix", "+", "'_23_reordered.npz'", "\n", "\n", "os", ".", "makedirs", "(", "args", ".", "output_directory", ",", "exist_ok", "=", "True", ")", "\n", "for", "split", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "        ", "print", "(", "'Running preprocessing for split ='", ",", "split", ")", "\n", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_directory", ",", "\n", "'{}_data.bin'", ".", "format", "(", "split", ")", ")", "\n", "\n", "input_files", "=", "train_files", "if", "split", "==", "'train'", "else", "[", "test_valid_file", "]", "\n", "numpy_to_binary", "(", "input_files", "=", "input_files", ",", "\n", "output_file_path", "=", "output_file", ",", "\n", "split", "=", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._test_bin": [[302, 364], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "data_loader_terabyte._preprocess", "os.path.join", "os.path.join", "data_loader_terabyte.CriteoBinDataset", "torch.utils.data.DataLoader", "CriteoDataset", "torch.utils.data.DataLoader", "tqdm.tqdm", "print", "len", "len", "enumerate", "range", "zip", "len", "len", "len", "numpy.array_equal", "ValueError"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.parse_args", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte._preprocess"], ["", "", "def", "_test_bin", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--output_directory'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--input_data_prefix'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "choices", "=", "[", "'train'", ",", "'test'", ",", "'val'", "]", ",", "\n", "required", "=", "True", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "_preprocess", "(", "args", ")", "\n", "\n", "binary_data_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_directory", ",", "\n", "'{}_data.bin'", ".", "format", "(", "args", ".", "split", ")", ")", "\n", "\n", "counts_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_directory", ",", "'day_fea_count.npz'", ")", "\n", "dataset_binary", "=", "CriteoBinDataset", "(", "data_file", "=", "binary_data_file", ",", "\n", "counts_file", "=", "counts_file", ",", "\n", "batch_size", "=", "2048", ",", ")", "\n", "from", "dlrm_data_pytorch", "import", "CriteoDataset", "\n", "from", "dlrm_data_pytorch", "import", "collate_wrapper_criteo_offset", "as", "collate_wrapper_criteo", "\n", "\n", "binary_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset_binary", ",", "\n", "batch_size", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "None", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "\n", "original_dataset", "=", "CriteoDataset", "(", "\n", "dataset", "=", "'terabyte'", ",", "\n", "max_ind_range", "=", "10", "*", "1000", "*", "1000", ",", "\n", "sub_sample_rate", "=", "1", ",", "\n", "randomize", "=", "True", ",", "\n", "split", "=", "args", ".", "split", ",", "\n", "raw_path", "=", "args", ".", "input_data_prefix", ",", "\n", "pro_data", "=", "'dummy_string'", ",", "\n", "memory_map", "=", "True", "\n", ")", "\n", "\n", "original_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "original_dataset", ",", "\n", "batch_size", "=", "2048", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "collate_wrapper_criteo", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "\n", "assert", "len", "(", "dataset_binary", ")", "==", "len", "(", "original_loader", ")", "\n", "for", "i", ",", "(", "old_batch", ",", "new_batch", ")", "in", "tqdm", "(", "enumerate", "(", "zip", "(", "original_loader", ",", "\n", "binary_loader", ")", ")", ",", "\n", "total", "=", "len", "(", "dataset_binary", ")", ")", ":", "\n", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "new_batch", ")", ")", ":", "\n", "            ", "if", "not", "np", ".", "array_equal", "(", "old_batch", "[", "j", "]", ",", "new_batch", "[", "j", "]", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'FAILED: Datasets not equal'", ")", "\n", "", "", "if", "i", ">", "len", "(", "dataset_binary", ")", ":", "\n", "            ", "break", "\n", "", "", "print", "(", "'PASSED'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.CriteoDatasetWMemoryMap.__init__": [[49, 123], ["raw_path.split", "numpy.array", "range", "len", "print", "numpy.load", "numpy.load", "ValueError", "lstr[].split", "list", "int", "sys.exit", "numpy.load", "numpy.ceil"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "split", "=", "\"train\"", ",", "\n", "raw_path", "=", "\"\"", ",", "\n", "pro_data", "=", "\"\"", ",", "\n", ")", ":", "\n", "# dataset", "\n", "# tar_fea = 1   # single target", "\n", "        ", "den_fea", "=", "13", "# 13 dense  features", "\n", "# spa_fea = 26  # 26 sparse features", "\n", "# tad_fea = tar_fea + den_fea", "\n", "# tot_fea = tad_fea + spa_fea", "\n", "if", "dataset", "==", "\"kaggle\"", ":", "\n", "            ", "days", "=", "7", "\n", "", "elif", "dataset", "==", "\"terabyte\"", ":", "\n", "            ", "days", "=", "24", "\n", "", "else", ":", "\n", "            ", "raise", "(", "ValueError", "(", "\"Data set option is not supported\"", ")", ")", "\n", "", "self", ".", "max_ind_range", "=", "max_ind_range", "\n", "\n", "# split the datafile into path and filename", "\n", "lstr", "=", "raw_path", ".", "split", "(", "\"/\"", ")", "\n", "self", ".", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "\n", "self", ".", "d_file", "=", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "if", "dataset", "==", "\"kaggle\"", "else", "lstr", "[", "-", "1", "]", "\n", "self", ".", "npzfile", "=", "self", ".", "d_path", "+", "(", "\n", "(", "self", ".", "d_file", "+", "\"_day\"", ")", "if", "dataset", "==", "\"kaggle\"", "else", "self", ".", "d_file", "\n", ")", "\n", "self", ".", "trafile", "=", "self", ".", "d_path", "+", "(", "\n", "(", "self", ".", "d_file", "+", "\"_fea\"", ")", "if", "dataset", "==", "\"kaggle\"", "else", "\"fea\"", "\n", ")", "\n", "\n", "# get a number of samples per day", "\n", "total_file", "=", "self", ".", "d_path", "+", "self", ".", "d_file", "+", "\"_day_count.npz\"", "\n", "with", "np", ".", "load", "(", "total_file", ")", "as", "data", ":", "\n", "            ", "total_per_file", "=", "data", "[", "\"total_per_file\"", "]", "\n", "# compute offsets per file", "\n", "", "self", ".", "offset_per_file", "=", "np", ".", "array", "(", "[", "0", "]", "+", "list", "(", "total_per_file", ")", ")", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "self", ".", "offset_per_file", "[", "i", "+", "1", "]", "+=", "self", ".", "offset_per_file", "[", "i", "]", "\n", "# print(self.offset_per_file)", "\n", "\n", "# setup data", "\n", "", "self", ".", "split", "=", "split", "\n", "if", "split", "==", "\"none\"", "or", "split", "==", "\"train\"", ":", "\n", "            ", "self", ".", "day", "=", "0", "\n", "self", ".", "max_day_range", "=", "days", "if", "split", "==", "\"none\"", "else", "days", "-", "1", "\n", "", "elif", "split", "==", "\"test\"", "or", "split", "==", "\"val\"", ":", "\n", "            ", "self", ".", "day", "=", "days", "-", "1", "\n", "num_samples", "=", "self", ".", "offset_per_file", "[", "days", "]", "-", "self", ".", "offset_per_file", "[", "days", "-", "1", "]", "\n", "self", ".", "test_size", "=", "int", "(", "np", ".", "ceil", "(", "num_samples", "/", "2.0", ")", ")", "\n", "self", ".", "val_size", "=", "num_samples", "-", "self", ".", "test_size", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train or test.\"", ")", "\n", "\n", "# load unique counts", "\n", "", "with", "np", ".", "load", "(", "self", ".", "d_path", "+", "self", ".", "d_file", "+", "\"_fea_count.npz\"", ")", "as", "data", ":", "\n", "            ", "self", ".", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "", "self", ".", "m_den", "=", "den_fea", "# X_int.shape[1]", "\n", "self", ".", "n_emb", "=", "len", "(", "self", ".", "counts", ")", "\n", "print", "(", "\"Sparse features= %d, Dense features= %d\"", "%", "(", "self", ".", "n_emb", ",", "self", ".", "m_den", ")", ")", "\n", "\n", "# Load the test data", "\n", "# Only a single day is used for testing", "\n", "if", "self", ".", "split", "==", "\"test\"", "or", "self", ".", "split", "==", "\"val\"", ":", "\n", "# only a single day is used for testing", "\n", "            ", "fi", "=", "self", ".", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "self", ".", "day", ")", "\n", "with", "np", ".", "load", "(", "fi", ")", "as", "data", ":", "\n", "                ", "self", ".", "X_int", "=", "data", "[", "\"X_int\"", "]", "# continuous  feature", "\n", "self", ".", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "# categorical feature", "\n", "self", ".", "y", "=", "data", "[", "\"y\"", "]", "# target", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.CriteoDatasetWMemoryMap.__getitem__": [[124, 157], ["isinstance", "sys.exit", "range", "numpy.load", "len"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "index", ",", "slice", ")", ":", "\n", "            ", "return", "[", "\n", "self", "[", "idx", "]", "\n", "for", "idx", "in", "range", "(", "\n", "index", ".", "start", "or", "0", ",", "index", ".", "stop", "or", "len", "(", "self", ")", ",", "index", ".", "step", "or", "1", "\n", ")", "\n", "]", "\n", "", "if", "self", ".", "split", "==", "\"none\"", "or", "self", ".", "split", "==", "\"train\"", ":", "\n", "# check if need to swicth to next day and load data", "\n", "            ", "if", "index", "==", "self", ".", "offset_per_file", "[", "self", ".", "day", "]", ":", "\n", "# print(\"day_boundary switch\", index)", "\n", "                ", "self", ".", "day_boundary", "=", "self", ".", "offset_per_file", "[", "self", ".", "day", "]", "\n", "fi", "=", "self", ".", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "self", ".", "day", ")", "\n", "# print('Loading file: ', fi)", "\n", "with", "np", ".", "load", "(", "fi", ")", "as", "data", ":", "\n", "                    ", "self", ".", "X_int", "=", "data", "[", "\"X_int\"", "]", "# continuous  feature", "\n", "self", ".", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "# categorical feature", "\n", "self", ".", "y", "=", "data", "[", "\"y\"", "]", "# target", "\n", "", "self", ".", "day", "=", "(", "self", ".", "day", "+", "1", ")", "%", "self", ".", "max_day_range", "\n", "\n", "", "i", "=", "index", "-", "self", ".", "day_boundary", "\n", "", "elif", "self", ".", "split", "==", "\"test\"", "or", "self", ".", "split", "==", "\"val\"", ":", "\n", "# only a single day is used for testing", "\n", "            ", "i", "=", "index", "+", "(", "0", "if", "self", ".", "split", "==", "\"test\"", "else", "self", ".", "test_size", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train or test.\"", ")", "\n", "\n", "", "if", "self", ".", "max_ind_range", ">", "0", ":", "\n", "            ", "return", "self", ".", "X_int", "[", "i", "]", ",", "self", ".", "X_cat", "[", "i", "]", "%", "self", ".", "max_ind_range", ",", "self", ".", "y", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "X_int", "[", "i", "]", ",", "self", ".", "X_cat", "[", "i", "]", ",", "self", ".", "y", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.CriteoDatasetWMemoryMap._default_preprocess": [[158, 167], ["torch.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.astype", "torch.tensor"], "methods", ["None"], ["", "", "def", "_default_preprocess", "(", "self", ",", "X_int", ",", "X_cat", ",", "y", ")", ":", "\n", "        ", "X_int", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "X_int", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "if", "self", ".", "max_ind_range", ">", "0", ":", "\n", "            ", "X_cat", "=", "torch", ".", "tensor", "(", "X_cat", "%", "self", ".", "max_ind_range", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "            ", "X_cat", "=", "torch", ".", "tensor", "(", "X_cat", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "y", "=", "torch", ".", "tensor", "(", "y", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "return", "X_int", ",", "X_cat", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.CriteoDatasetWMemoryMap.__len__": [[168, 179], ["sys.exit"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "split", "==", "\"none\"", ":", "\n", "            ", "return", "self", ".", "offset_per_file", "[", "-", "1", "]", "\n", "", "elif", "self", ".", "split", "==", "\"train\"", ":", "\n", "            ", "return", "self", ".", "offset_per_file", "[", "-", "2", "]", "\n", "", "elif", "self", ".", "split", "==", "\"test\"", ":", "\n", "            ", "return", "self", ".", "test_size", "\n", "", "elif", "self", ".", "split", "==", "\"val\"", ":", "\n", "            ", "return", "self", ".", "val_size", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train nor test.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.collate_wrapper_criteo": [[181, 195], ["list", "torch.log", "torch.tensor", "torch.tensor().view", "zip", "torch.tensor", "torch.stack", "torch.stack", "torch.tensor", "torch.tensor", "range", "range", "range"], "function", ["None"], ["", "", "", "def", "collate_wrapper_criteo", "(", "list_of_tuples", ")", ":", "\n", "# where each tuple is (X_int, X_cat, y)", "\n", "    ", "transposed_data", "=", "list", "(", "zip", "(", "*", "list_of_tuples", ")", ")", "\n", "X_int", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "transposed_data", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "X_cat", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "T", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "2", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "batchSize", "=", "X_cat", ".", "shape", "[", "0", "]", "\n", "featureCnt", "=", "X_cat", ".", "shape", "[", "1", "]", "\n", "\n", "lS_i", "=", "[", "X_cat", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "featureCnt", ")", "]", "\n", "lS_o", "=", "[", "torch", ".", "tensor", "(", "range", "(", "batchSize", ")", ")", "for", "_", "in", "range", "(", "featureCnt", ")", "]", "\n", "\n", "return", "X_int", ",", "torch", ".", "stack", "(", "lS_o", ")", ",", "torch", ".", "stack", "(", "lS_i", ")", ",", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.offset_to_length_convertor": [[198, 206], ["torch.stack", "dlrm_data_caffe2.offset_to_length_convertor.diff"], "function", ["None"], ["", "def", "offset_to_length_convertor", "(", "lS_o", ",", "lS_i", ")", ":", "\n", "    ", "def", "diff", "(", "tensor", ")", ":", "\n", "        ", "return", "tensor", "[", "1", ":", "]", "-", "tensor", "[", ":", "-", "1", "]", "\n", "\n", "", "return", "torch", ".", "stack", "(", "\n", "[", "\n", "diff", "(", "torch", ".", "cat", "(", "(", "S_o", ",", "torch", ".", "tensor", "(", "lS_i", "[", "ind", "]", ".", "shape", ")", ")", ")", ".", "int", "(", ")", ")", "\n", "for", "ind", ",", "S_o", "in", "enumerate", "(", "lS_o", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.unpack_batch": [[210, 212], ["torch.ones", "b[].size"], "function", ["None"], ["", "def", "unpack_batch", "(", "b", ",", "data_gen", ",", "data_set", ")", ":", "\n", "    ", "return", "b", "[", "0", "]", ",", "b", "[", "1", "]", ",", "b", "[", "2", "]", ",", "b", "[", "3", "]", ",", "torch", ".", "ones", "(", "b", "[", "3", "]", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.read_dataset": [[214, 409], ["raw_data.split", "print", "data_utils.loadDataset", "dlrm_data_caffe2.CriteoDatasetWMemoryMap", "dlrm_data_caffe2.CriteoDatasetWMemoryMap", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_utils.transformCriteoAdData", "len", "print", "dlrm_data_caffe2.read_dataset.assemble_samples"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.loadDataset", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.transformCriteoAdData"], ["", "def", "read_dataset", "(", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "mini_batch_size", ",", "\n", "num_batches", ",", "\n", "randomize", ",", "\n", "split", "=", "\"train\"", ",", "\n", "raw_data", "=", "\"\"", ",", "\n", "processed_data", "=", "\"\"", ",", "\n", "memory_map", "=", "False", ",", "\n", "inference_only", "=", "False", ",", "\n", "test_mini_batch_size", "=", "1", ",", "\n", ")", ":", "\n", "# split the datafile into path and filename", "\n", "    ", "lstr", "=", "raw_data", ".", "split", "(", "\"/\"", ")", "\n", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "\n", "d_file", "=", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "if", "dataset", "==", "\"kaggle\"", "else", "lstr", "[", "-", "1", "]", "\n", "# npzfile = d_path + ((d_file + \"_day\") if dataset == \"kaggle\" else d_file)", "\n", "# trafile = d_path + ((d_file + \"_fea\") if dataset == \"kaggle\" else \"fea\")", "\n", "\n", "# load", "\n", "print", "(", "\"Loading %s dataset...\"", "%", "dataset", ")", "\n", "nbatches", "=", "0", "\n", "file", ",", "days", "=", "data_utils", ".", "loadDataset", "(", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "split", ",", "\n", "raw_data", ",", "\n", "processed_data", ",", "\n", "memory_map", ",", "\n", ")", "\n", "\n", "if", "memory_map", ":", "\n", "# WARNING: at this point the data has been reordered and shuffled across files", "\n", "# e.g. day_<number>_reordered.npz, what remains is simply to read and feed", "\n", "# the data from each file, going in the order of days file-by-file, to the", "\n", "# model during training.", "\n", "        ", "train_data", "=", "CriteoDatasetWMemoryMap", "(", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "\"train\"", ",", "\n", "raw_data", ",", "\n", "processed_data", ",", "\n", ")", "\n", "\n", "test_data", "=", "CriteoDatasetWMemoryMap", "(", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "\"test\"", ",", "\n", "raw_data", ",", "\n", "processed_data", ",", "\n", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_data", ",", "\n", "batch_size", "=", "mini_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "collate_wrapper_criteo", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "test_mini_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "collate_wrapper_criteo", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "\n", "return", "train_data", ",", "train_loader", ",", "test_data", ",", "test_loader", "\n", "\n", "", "else", ":", "\n", "# load and preprocess data", "\n", "        ", "with", "np", ".", "load", "(", "file", ")", "as", "data", ":", "\n", "            ", "X_int", "=", "data", "[", "\"X_int\"", "]", "\n", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "\n", "y", "=", "data", "[", "\"y\"", "]", "\n", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "\n", "# get a number of samples per day", "\n", "", "total_file", "=", "d_path", "+", "d_file", "+", "\"_day_count.npz\"", "\n", "with", "np", ".", "load", "(", "total_file", ")", "as", "data", ":", "\n", "            ", "total_per_file", "=", "data", "[", "\"total_per_file\"", "]", "\n", "\n", "# transform", "\n", "", "(", "\n", "X_cat_train", ",", "\n", "X_int_train", ",", "\n", "y_train", ",", "\n", "X_cat_val", ",", "\n", "X_int_val", ",", "\n", "y_val", ",", "\n", "X_cat_test", ",", "\n", "X_int_test", ",", "\n", "y_test", ",", "\n", ")", "=", "data_utils", ".", "transformCriteoAdData", "(", "\n", "X_cat", ",", "X_int", ",", "y", ",", "days", ",", "split", ",", "randomize", ",", "total_per_file", "\n", ")", "\n", "ln_emb", "=", "counts", "\n", "m_den", "=", "X_int_train", ".", "shape", "[", "1", "]", "\n", "n_emb", "=", "len", "(", "counts", ")", "\n", "print", "(", "\"Sparse features = %d, Dense features = %d\"", "%", "(", "n_emb", ",", "m_den", ")", ")", "\n", "\n", "# adjust parameters", "\n", "def", "assemble_samples", "(", "X_cat", ",", "X_int", ",", "y", ",", "max_ind_range", ",", "print_message", ")", ":", "\n", "            ", "if", "max_ind_range", ">", "0", ":", "\n", "                ", "X_cat", "=", "X_cat", "%", "max_ind_range", "\n", "\n", "", "nsamples", "=", "len", "(", "y", ")", "\n", "data_size", "=", "nsamples", "\n", "# using floor is equivalent to dropping last mini-batch (drop_last = True)", "\n", "nbatches", "=", "int", "(", "np", ".", "floor", "(", "(", "data_size", "*", "1.0", ")", "/", "mini_batch_size", ")", ")", "\n", "print", "(", "print_message", ")", "\n", "if", "num_batches", "!=", "0", "and", "num_batches", "<", "nbatches", ":", "\n", "                ", "print", "(", "\n", "\"Limiting to %d batches of the total % d batches\"", "\n", "%", "(", "num_batches", ",", "nbatches", ")", "\n", ")", "\n", "nbatches", "=", "num_batches", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Total number of batches %d\"", "%", "nbatches", ")", "\n", "\n", "# data main loop", "\n", "", "lX", "=", "[", "]", "\n", "lS_lengths", "=", "[", "]", "\n", "lS_indices", "=", "[", "]", "\n", "lT", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "0", ",", "nbatches", ")", ":", "\n", "# number of data points in a batch", "\n", "                ", "print", "(", "\"Reading in batch: %d / %d\"", "%", "(", "j", "+", "1", ",", "nbatches", ")", ",", "end", "=", "\"\\r\"", ")", "\n", "n", "=", "min", "(", "mini_batch_size", ",", "data_size", "-", "(", "j", "*", "mini_batch_size", ")", ")", "\n", "# dense feature", "\n", "idx_start", "=", "j", "*", "mini_batch_size", "\n", "lX", ".", "append", "(", "(", "X_int", "[", "idx_start", ":", "(", "idx_start", "+", "n", ")", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "# Targets - outputs", "\n", "lT", ".", "append", "(", "\n", "(", "y", "[", "idx_start", ":", "idx_start", "+", "n", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", ")", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "size", "in", "range", "(", "n_emb", ")", ":", "\n", "                    ", "lS_batch_indices", "=", "[", "]", "\n", "for", "_b", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding, e.g. for", "\n", "# store lengths and indices", "\n", "                        ", "lS_batch_indices", "+=", "(", "\n", "(", "X_cat", "[", "idx_start", "+", "_b", "]", "[", "size", "]", ".", "reshape", "(", "-", "1", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", ")", ".", "tolist", "(", ")", "\n", "", "lS_emb_indices", ".", "append", "(", "lS_batch_indices", ")", "\n", "", "lS_indices", ".", "append", "(", "lS_emb_indices", ")", "\n", "# Criteo Kaggle data it is 1 because data is categorical", "\n", "lS_lengths", ".", "append", "(", "\n", "[", "(", "list", "(", "np", ".", "ones", "(", "n", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", ")", "for", "_", "in", "range", "(", "n_emb", ")", "]", "\n", ")", "\n", "", "print", "(", "\"\\n\"", ")", "\n", "\n", "return", "nbatches", ",", "lX", ",", "lS_lengths", ",", "lS_indices", ",", "lT", "\n", "\n", "# adjust training data", "\n", "", "(", "nbatches", ",", "lX", ",", "lS_lengths", ",", "lS_indices", ",", "lT", ")", "=", "assemble_samples", "(", "\n", "X_cat_train", ",", "X_int_train", ",", "y_train", ",", "max_ind_range", ",", "\"Training data\"", "\n", ")", "\n", "\n", "# adjust testing data", "\n", "(", "nbatches_t", ",", "lX_t", ",", "lS_lengths_t", ",", "lS_indices_t", ",", "lT_t", ")", "=", "assemble_samples", "(", "\n", "X_cat_test", ",", "X_int_test", ",", "y_test", ",", "max_ind_range", ",", "\"Testing data\"", "\n", ")", "\n", "# end if memory_map", "\n", "\n", "", "return", "(", "\n", "nbatches", ",", "\n", "lX", ",", "\n", "lS_lengths", ",", "\n", "lS_indices", ",", "\n", "lT", ",", "\n", "nbatches_t", ",", "\n", "lX_t", ",", "\n", "lS_lengths_t", ",", "\n", "lS_indices_t", ",", "\n", "lT_t", ",", "\n", "ln_emb", ",", "\n", "m_den", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.generate_random_data": [[412, 471], ["int", "range", "numpy.ceil", "min", "lX.append", "lS_lengths.append", "lS_indices.append", "dlrm_data_caffe2.generate_random_output_batch", "lT.append", "dlrm_data_caffe2.generate_uniform_input_batch", "dlrm_data_caffe2.generate_synthetic_input_batch", "sys.exit"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_random_output_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_uniform_input_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_synthetic_input_batch"], ["", "def", "generate_random_data", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "data_size", ",", "\n", "num_batches", ",", "\n", "mini_batch_size", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "num_targets", "=", "1", ",", "\n", "round_targets", "=", "False", ",", "\n", "data_generation", "=", "\"random\"", ",", "\n", "trace_file", "=", "\"\"", ",", "\n", "enable_padding", "=", "False", ",", "\n", ")", ":", "\n", "    ", "nbatches", "=", "int", "(", "np", ".", "ceil", "(", "(", "data_size", "*", "1.0", ")", "/", "mini_batch_size", ")", ")", "\n", "if", "num_batches", "!=", "0", ":", "\n", "        ", "nbatches", "=", "num_batches", "\n", "data_size", "=", "nbatches", "*", "mini_batch_size", "\n", "# print(\"Total number of batches %d\" % nbatches)", "\n", "\n", "# inputs and targets", "\n", "", "lT", "=", "[", "]", "\n", "lX", "=", "[", "]", "\n", "lS_lengths", "=", "[", "]", "\n", "lS_indices", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "0", ",", "nbatches", ")", ":", "\n", "# number of data points in a batch", "\n", "        ", "n", "=", "min", "(", "mini_batch_size", ",", "data_size", "-", "(", "j", "*", "mini_batch_size", ")", ")", "\n", "\n", "# generate a batch of dense and sparse features", "\n", "if", "data_generation", "==", "\"random\"", ":", "\n", "            ", "(", "Xt", ",", "lS_emb_lengths", ",", "lS_emb_indices", ")", "=", "generate_uniform_input_batch", "(", "\n", "m_den", ",", "ln_emb", ",", "n", ",", "num_indices_per_lookup", ",", "num_indices_per_lookup_fixed", "\n", ")", "\n", "", "elif", "data_generation", "==", "\"synthetic\"", ":", "\n", "            ", "(", "Xt", ",", "lS_emb_lengths", ",", "lS_emb_indices", ")", "=", "generate_synthetic_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "trace_file", ",", "\n", "enable_padding", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: --data-generation=\"", "+", "data_generation", "+", "\" is not supported\"", "\n", ")", "\n", "# dense feature", "\n", "", "lX", ".", "append", "(", "Xt", ")", "\n", "# sparse feature (sparse indices)", "\n", "lS_lengths", ".", "append", "(", "lS_emb_lengths", ")", "\n", "lS_indices", ".", "append", "(", "lS_emb_indices", ")", "\n", "\n", "# generate a batch of target (probability of a click)", "\n", "P", "=", "generate_random_output_batch", "(", "n", ",", "num_targets", ",", "round_targets", ")", "\n", "lT", ".", "append", "(", "P", ")", "\n", "\n", "", "return", "(", "nbatches", ",", "lX", ",", "lS_lengths", ",", "lS_indices", ",", "lT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.generate_random_output_batch": [[473, 481], ["numpy.round().astype", "numpy.random.rand().astype", "numpy.round", "numpy.random.rand", "numpy.random.rand().astype", "numpy.random.rand"], "function", ["None"], ["", "def", "generate_random_output_batch", "(", "n", ",", "num_targets", "=", "1", ",", "round_targets", "=", "False", ")", ":", "\n", "# target (probability of a click)", "\n", "    ", "if", "round_targets", ":", "\n", "        ", "P", "=", "np", ".", "round", "(", "ra", ".", "rand", "(", "n", ",", "num_targets", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "else", ":", "\n", "        ", "P", "=", "ra", ".", "rand", "(", "n", ",", "num_targets", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "return", "P", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.generate_uniform_input_batch": [[484, 524], ["numpy.random.rand().astype", "range", "lS_emb_lengths.append", "lS_emb_indices.append", "numpy.random.rand", "numpy.random.random", "numpy.unique", "numpy.int32", "np.unique.tolist", "numpy.int32", "numpy.random.random", "numpy.int32", "numpy.round().astype", "max", "numpy.round", "numpy.round", "min"], "function", ["None"], ["", "def", "generate_uniform_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", ")", ":", "\n", "# dense feature", "\n", "    ", "Xt", "=", "ra", ".", "rand", "(", "n", ",", "m_den", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_lengths", "=", "[", "]", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "size", "in", "ln_emb", ":", "\n", "        ", "lS_batch_lengths", "=", "[", "]", "\n", "lS_batch_indices", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding (between", "\n", "            ", "if", "num_indices_per_lookup_fixed", ":", "\n", "                ", "sparse_group_size", "=", "np", ".", "int32", "(", "num_indices_per_lookup", ")", "\n", "", "else", ":", "\n", "# random between [1,num_indices_per_lookup])", "\n", "                ", "r", "=", "ra", ".", "random", "(", "1", ")", "\n", "sparse_group_size", "=", "np", ".", "int32", "(", "\n", "max", "(", "1", ",", "np", ".", "round", "(", "r", "*", "min", "(", "size", ",", "num_indices_per_lookup", ")", ")", "[", "0", "]", ")", "\n", ")", "\n", "# sparse indices to be used per embedding", "\n", "", "r", "=", "ra", ".", "random", "(", "sparse_group_size", ")", "\n", "sparse_group", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "r", "*", "(", "size", "-", "1", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "# reset sparse_group_size in case some index duplicates were removed", "\n", "sparse_group_size", "=", "np", ".", "int32", "(", "sparse_group", ".", "size", ")", "\n", "# store lengths and indices", "\n", "lS_batch_lengths", "+=", "[", "sparse_group_size", "]", "\n", "lS_batch_indices", "+=", "sparse_group", ".", "tolist", "(", ")", "\n", "", "lS_emb_lengths", ".", "append", "(", "lS_batch_lengths", ")", "\n", "lS_emb_indices", ".", "append", "(", "lS_batch_indices", ")", "\n", "\n", "", "return", "(", "Xt", ",", "lS_emb_lengths", ",", "lS_emb_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.generate_synthetic_input_batch": [[527, 596], ["numpy.random.rand().astype", "enumerate", "range", "lS_emb_lengths.append", "lS_emb_indices.append", "numpy.random.rand", "dlrm_data_caffe2.read_dist_from_file", "dlrm_data_caffe2.trace_generate_lru", "numpy.unique().astype", "numpy.min", "numpy.max", "numpy.int32", "np.mod().astype.tolist", "numpy.int32", "numpy.random.random", "numpy.int32", "file_path.replace", "print", "numpy.mod().astype", "max", "str", "numpy.unique", "numpy.mod", "numpy.round", "min"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.read_dist_from_file", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.trace_generate_lru"], ["", "def", "generate_synthetic_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "trace_file", ",", "\n", "enable_padding", "=", "False", ",", "\n", ")", ":", "\n", "# dense feature", "\n", "    ", "Xt", "=", "ra", ".", "rand", "(", "n", ",", "m_den", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_lengths", "=", "[", "]", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "ln_emb", ")", ":", "\n", "        ", "lS_batch_lengths", "=", "[", "]", "\n", "lS_batch_indices", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding (between", "\n", "            ", "if", "num_indices_per_lookup_fixed", ":", "\n", "                ", "sparse_group_size", "=", "np", ".", "int32", "(", "num_indices_per_lookup", ")", "\n", "", "else", ":", "\n", "# random between [1,num_indices_per_lookup])", "\n", "                ", "r", "=", "ra", ".", "random", "(", "1", ")", "\n", "sparse_group_size", "=", "np", ".", "int32", "(", "\n", "max", "(", "1", ",", "np", ".", "round", "(", "r", "*", "min", "(", "size", ",", "num_indices_per_lookup", ")", ")", "[", "0", "]", ")", "\n", ")", "\n", "# sparse indices to be used per embedding", "\n", "", "file_path", "=", "trace_file", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", "=", "read_dist_from_file", "(", "\n", "file_path", ".", "replace", "(", "\"j\"", ",", "str", "(", "i", ")", ")", "\n", ")", "\n", "# debug print", "\n", "# print('input')", "\n", "# print(line_accesses); print(list_sd); print(cumm_sd);", "\n", "# print(sparse_group_size)", "\n", "# approach 1: rand", "\n", "# r = trace_generate_rand(", "\n", "#     line_accesses, list_sd, cumm_sd, sparse_group_size, enable_padding", "\n", "# )", "\n", "# approach 2: lru", "\n", "r", "=", "trace_generate_lru", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "sparse_group_size", ",", "enable_padding", "\n", ")", "\n", "# WARNING: if the distribution in the file is not consistent with", "\n", "# embedding table dimensions, below mod guards against out of", "\n", "# range access", "\n", "sparse_group", "=", "np", ".", "unique", "(", "r", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "minsg", "=", "np", ".", "min", "(", "sparse_group", ")", "\n", "maxsg", "=", "np", ".", "max", "(", "sparse_group", ")", "\n", "if", "(", "minsg", "<", "0", ")", "or", "(", "size", "<=", "maxsg", ")", ":", "\n", "                ", "print", "(", "\n", "\"WARNING: distribution is inconsistent with embedding \"", "\n", "+", "\"table size (using mod to recover and continue)\"", "\n", ")", "\n", "sparse_group", "=", "np", ".", "mod", "(", "sparse_group", ",", "size", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "# sparse_group = np.unique(np.array(np.mod(r, size-1)).astype(np.int32))", "\n", "# reset sparse_group_size in case some index duplicates were removed", "\n", "", "sparse_group_size", "=", "np", ".", "int32", "(", "sparse_group", ".", "size", ")", "\n", "# store lengths and indices", "\n", "lS_batch_lengths", "+=", "[", "sparse_group_size", "]", "\n", "lS_batch_indices", "+=", "sparse_group", ".", "tolist", "(", ")", "\n", "", "lS_emb_lengths", ".", "append", "(", "lS_batch_lengths", ")", "\n", "lS_emb_indices", ".", "append", "(", "lS_batch_indices", ")", "\n", "\n", "", "return", "(", "Xt", ",", "lS_emb_lengths", ",", "lS_emb_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.generate_stack_distance": [[598, 613], ["numpy.random.rand", "enumerate", "bisect.bisect"], "function", ["None"], ["", "def", "generate_stack_distance", "(", "cumm_val", ",", "cumm_dist", ",", "max_i", ",", "i", ",", "enable_padding", "=", "False", ")", ":", "\n", "    ", "u", "=", "ra", ".", "rand", "(", "1", ")", "\n", "if", "i", "<", "max_i", ":", "\n", "# only generate stack distances up to the number of new references seen so far", "\n", "        ", "j", "=", "bisect", ".", "bisect", "(", "cumm_val", ",", "i", ")", "-", "1", "\n", "fi", "=", "cumm_dist", "[", "j", "]", "\n", "u", "*=", "fi", "# shrink distribution support to exclude last values", "\n", "", "elif", "enable_padding", ":", "\n", "# WARNING: disable generation of new references (once all have been seen)", "\n", "        ", "fi", "=", "cumm_dist", "[", "0", "]", "\n", "u", "=", "(", "1.0", "-", "fi", ")", "*", "u", "+", "fi", "# remap distribution support to exclude first value", "\n", "\n", "", "for", "(", "j", ",", "f", ")", "in", "enumerate", "(", "cumm_dist", ")", ":", "\n", "        ", "if", "u", "<=", "f", ":", "\n", "            ", "return", "cumm_val", "[", "j", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.trace_generate_lru": [[619, 644], ["len", "range", "dlrm_data_caffe2.generate_stack_distance", "ztrace.append", "line_accesses.pop", "line_accesses.append", "numpy.uint64", "numpy.uint64", "line_accesses.pop", "line_accesses.append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_stack_distance"], ["def", "trace_generate_lru", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "out_trace_len", ",", "enable_padding", "=", "False", "\n", ")", ":", "\n", "    ", "max_sd", "=", "list_sd", "[", "-", "1", "]", "\n", "l", "=", "len", "(", "line_accesses", ")", "\n", "i", "=", "0", "\n", "ztrace", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "out_trace_len", ")", ":", "\n", "        ", "sd", "=", "generate_stack_distance", "(", "list_sd", ",", "cumm_sd", ",", "max_sd", ",", "i", ",", "enable_padding", ")", "\n", "mem_ref_within_line", "=", "0", "# floor(ra.rand(1)*cache_line_size) #0", "\n", "# generate memory reference", "\n", "if", "sd", "==", "0", ":", "# new reference #", "\n", "            ", "line_ref", "=", "line_accesses", ".", "pop", "(", "0", ")", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "# existing reference #", "\n", "            ", "line_ref", "=", "line_accesses", "[", "l", "-", "sd", "]", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "line_accesses", ".", "pop", "(", "l", "-", "sd", ")", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "# save generated memory reference", "\n", "", "ztrace", ".", "append", "(", "mem_ref", ")", "\n", "\n", "", "return", "ztrace", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.trace_generate_rand": [[646, 668], ["len", "range", "dlrm_data_caffe2.generate_stack_distance", "ztrace.append", "line_accesses.pop", "line_accesses.append", "numpy.uint64", "numpy.uint64"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_stack_distance"], ["", "def", "trace_generate_rand", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "out_trace_len", ",", "enable_padding", "=", "False", "\n", ")", ":", "\n", "    ", "max_sd", "=", "list_sd", "[", "-", "1", "]", "\n", "l", "=", "len", "(", "line_accesses", ")", "# !!!Unique,", "\n", "i", "=", "0", "\n", "ztrace", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "out_trace_len", ")", ":", "\n", "        ", "sd", "=", "generate_stack_distance", "(", "list_sd", ",", "cumm_sd", ",", "max_sd", ",", "i", ",", "enable_padding", ")", "\n", "mem_ref_within_line", "=", "0", "# floor(ra.rand(1)*cache_line_size) #0", "\n", "# generate memory reference", "\n", "if", "sd", "==", "0", ":", "# new reference #", "\n", "            ", "line_ref", "=", "line_accesses", ".", "pop", "(", "0", ")", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "# existing reference #", "\n", "            ", "line_ref", "=", "line_accesses", "[", "l", "-", "sd", "]", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "", "ztrace", ".", "append", "(", "mem_ref", ")", "\n", "\n", "", "return", "ztrace", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.trace_profile": [[670, 716], ["numpy.uint64", "len", "len", "max", "int", "rstack.index", "stack_distances.insert", "rstack.pop", "rstack.insert", "numpy.ceil", "stack_distances.insert", "line_accesses.insert", "rstack.insert"], "function", ["None"], ["", "def", "trace_profile", "(", "trace", ",", "enable_padding", "=", "False", ")", ":", "\n", "# number of elements in the array (assuming 1D)", "\n", "# n = trace.size", "\n", "\n", "    ", "rstack", "=", "[", "]", "# S", "\n", "stack_distances", "=", "[", "]", "# SDS", "\n", "line_accesses", "=", "[", "]", "# L", "\n", "for", "x", "in", "trace", ":", "\n", "        ", "r", "=", "np", ".", "uint64", "(", "x", "/", "cache_line_size", ")", "\n", "l", "=", "len", "(", "rstack", ")", "\n", "try", ":", "# found #", "\n", "            ", "i", "=", "rstack", ".", "index", "(", "r", ")", "\n", "# WARNING: I believe below is the correct depth in terms of meaning of the", "\n", "#          algorithm, but that is not what seems to be in the paper alg.", "\n", "#          -1 can be subtracted if we defined the distance between", "\n", "#          consecutive accesses (e.g. r, r) as 0 rather than 1.", "\n", "sd", "=", "l", "-", "i", "# - 1", "\n", "# push r to the end of stack_distances", "\n", "stack_distances", ".", "insert", "(", "0", ",", "sd", ")", "\n", "# remove r from its position and insert to the top of stack", "\n", "rstack", ".", "pop", "(", "i", ")", "# rstack.remove(r)", "\n", "rstack", ".", "insert", "(", "l", "-", "1", ",", "r", ")", "\n", "", "except", "ValueError", ":", "# not found #", "\n", "            ", "sd", "=", "0", "# -1", "\n", "# push r to the end of stack_distances/line_accesses", "\n", "stack_distances", ".", "insert", "(", "0", ",", "sd", ")", "\n", "line_accesses", ".", "insert", "(", "0", ",", "r", ")", "\n", "# push r to the top of stack", "\n", "rstack", ".", "insert", "(", "l", ",", "r", ")", "\n", "\n", "", "", "if", "enable_padding", ":", "\n", "# WARNING: notice that as the ratio between the number of samples (l)", "\n", "# and cardinality (c) of a sample increases the probability of", "\n", "# generating a sample gets smaller and smaller because there are", "\n", "# few new samples compared to repeated samples. This means that for a", "\n", "# long trace with relatively small cardinality it will take longer to", "\n", "# generate all new samples and therefore obtain full distribution support", "\n", "# and hence it takes longer for distribution to resemble the original.", "\n", "# Therefore, we may pad the number of new samples to be on par with", "\n", "# average number of samples l/c artificially.", "\n", "        ", "l", "=", "len", "(", "stack_distances", ")", "\n", "c", "=", "max", "(", "stack_distances", ")", "\n", "padding", "=", "int", "(", "np", ".", "ceil", "(", "l", "/", "c", ")", ")", "\n", "stack_distances", "=", "stack_distances", "+", "[", "0", "]", "*", "padding", "\n", "\n", "", "return", "(", "rstack", ",", "stack_distances", ",", "line_accesses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.read_trace_from_file": [[719, 731], ["open", "print", "numpy.fromfile", "np.fromfile.astype().tolist", "f.readline", "list", "map", "np.fromfile.astype", "f.readline.split", "numpy.uint64"], "function", ["None"], ["", "def", "read_trace_from_file", "(", "file_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "if", "args", ".", "trace_file_binary_type", ":", "\n", "                ", "array", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "trace", "=", "array", ".", "astype", "(", "np", ".", "uint64", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "line", "=", "f", ".", "readline", "(", ")", "\n", "trace", "=", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "uint64", "(", "x", ")", ",", "line", ".", "split", "(", "\", \"", ")", ")", ")", "\n", "", "return", "trace", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"ERROR: no input trace file has been provided\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.write_trace_to_file": [[733, 744], ["print", "open", "numpy.array().astype().tofile", "open", "str", "f.write", "numpy.array().astype", "numpy.array", "len"], "function", ["None"], ["", "", "def", "write_trace_to_file", "(", "file_path", ",", "trace", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "if", "args", ".", "trace_file_binary_type", ":", "\n", "            ", "with", "open", "(", "file_path", ",", "\"wb+\"", ")", "as", "f", ":", "\n", "                ", "np", ".", "array", "(", "trace", ")", ".", "astype", "(", "np", ".", "uint64", ")", ".", "tofile", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "file_path", ",", "\"w+\"", ")", "as", "f", ":", "\n", "                ", "s", "=", "str", "(", "trace", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", ")", "\n", "", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"ERROR: no output trace file has been provided\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.read_dist_from_file": [[746, 759], ["int", "int", "float", "open", "f.read().splitlines", "print", "lines[].split", "lines[].split", "lines[].split", "f.read"], "function", ["None"], ["", "", "def", "read_dist_from_file", "(", "file_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"Wrong file or file path\"", ")", "\n", "# read unique accesses", "\n", "", "unique_accesses", "=", "[", "int", "(", "el", ")", "for", "el", "in", "lines", "[", "0", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "# read cumulative distribution (elements are passed as two separate lists)", "\n", "list_sd", "=", "[", "int", "(", "el", ")", "for", "el", "in", "lines", "[", "1", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "cumm_sd", "=", "[", "float", "(", "el", ")", "for", "el", "in", "lines", "[", "2", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "\n", "return", "unique_accesses", ",", "list_sd", ",", "cumm_sd", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_caffe2.write_dist_to_file": [[761, 775], ["open", "str", "f.write", "str", "f.write", "str", "f.write", "print", "len", "len", "len"], "function", ["None"], ["", "def", "write_dist_to_file", "(", "file_path", ",", "unique_accesses", ",", "list_sd", ",", "cumm_sd", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "# unique_acesses", "\n", "            ", "s", "=", "str", "(", "unique_accesses", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "# list_sd", "\n", "s", "=", "str", "(", "list_sd", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "# cumm_sd", "\n", "s", "=", "str", "(", "cumm_sd", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"Wrong file or file path\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.convertUStringToDistinctIntsDict": [[51, 84], ["numpy.zeros", "range", "print", "print", "range", "len", "len", "range", "range"], "function", ["None"], ["def", "convertUStringToDistinctIntsDict", "(", "mat", ",", "convertDicts", ",", "counts", ")", ":", "\n", "# Converts matrix of unicode strings into distinct integers.", "\n", "#", "\n", "# Inputs:", "\n", "#     mat (np.array): array of unicode strings to convert", "\n", "#     convertDicts (list): dictionary for each column", "\n", "#     counts (list): number of different categories in each column", "\n", "#", "\n", "# Outputs:", "\n", "#     out (np.array): array of output integers", "\n", "#     convertDicts (list): dictionary for each column", "\n", "#     counts (list): number of different categories in each column", "\n", "\n", "# check if convertDicts and counts match correct length of mat", "\n", "    ", "if", "len", "(", "convertDicts", ")", "!=", "mat", ".", "shape", "[", "1", "]", "or", "len", "(", "counts", ")", "!=", "mat", ".", "shape", "[", "1", "]", ":", "\n", "        ", "print", "(", "\"Length of convertDicts or counts does not match input shape\"", ")", "\n", "print", "(", "\"Generating convertDicts and counts...\"", ")", "\n", "\n", "convertDicts", "=", "[", "{", "}", "for", "_", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", "]", "\n", "counts", "=", "[", "0", "for", "_", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "# initialize output", "\n", "", "out", "=", "np", ".", "zeros", "(", "mat", ".", "shape", ")", "\n", "\n", "for", "j", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "mat", ".", "shape", "[", "0", "]", ")", ":", "\n", "# add to convertDict and increment count", "\n", "            ", "if", "mat", "[", "i", ",", "j", "]", "not", "in", "convertDicts", "[", "j", "]", ":", "\n", "                ", "convertDicts", "[", "j", "]", "[", "mat", "[", "i", ",", "j", "]", "]", "=", "counts", "[", "j", "]", "\n", "counts", "[", "j", "]", "+=", "1", "\n", "", "out", "[", "i", ",", "j", "]", "=", "convertDicts", "[", "j", "]", "[", "mat", "[", "i", ",", "j", "]", "]", "\n", "\n", "", "", "return", "out", ",", "convertDicts", ",", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.convertUStringToDistinctIntsUnique": [[86, 110], ["numpy.zeros", "range", "print", "print", "numpy.array", "numpy.concatenate", "numpy.unique", "len", "len", "numpy.array", "range", "range", "range"], "function", ["None"], ["", "def", "convertUStringToDistinctIntsUnique", "(", "mat", ",", "mat_uni", ",", "counts", ")", ":", "\n", "# mat is an array of 0,...,# samples, with each being 26 categorical features", "\n", "\n", "# check if mat_unique and counts match correct length of mat", "\n", "    ", "if", "len", "(", "mat_uni", ")", "!=", "mat", ".", "shape", "[", "1", "]", "or", "len", "(", "counts", ")", "!=", "mat", ".", "shape", "[", "1", "]", ":", "\n", "        ", "print", "(", "\"Length of mat_unique or counts does not match input shape\"", ")", "\n", "print", "(", "\"Generating mat_unique and counts...\"", ")", "\n", "\n", "mat_uni", "=", "[", "np", ".", "array", "(", "[", "]", ")", "for", "_", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", "]", "\n", "counts", "=", "[", "0", "for", "_", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "# initialize output", "\n", "", "out", "=", "np", ".", "zeros", "(", "mat", ".", "shape", ")", "\n", "ind_map", "=", "[", "np", ".", "array", "(", "[", "]", ")", "for", "_", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "# find out and assign unique ids to features", "\n", "for", "j", "in", "range", "(", "mat", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "m", "=", "mat_uni", "[", "j", "]", ".", "size", "\n", "mat_concat", "=", "np", ".", "concatenate", "(", "(", "mat_uni", "[", "j", "]", ",", "mat", "[", ":", ",", "j", "]", ")", ")", "\n", "mat_uni", "[", "j", "]", ",", "ind_map", "[", "j", "]", "=", "np", ".", "unique", "(", "mat_concat", ",", "return_inverse", "=", "True", ")", "\n", "out", "[", ":", ",", "j", "]", "=", "ind_map", "[", "j", "]", "[", "m", ":", "]", "\n", "counts", "[", "j", "]", "=", "mat_uni", "[", "j", "]", ".", "size", "\n", "\n", "", "return", "out", ",", "mat_uni", ",", "counts", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.processCriteoAdData": [[112, 170], ["os.path.exists", "print", "print", "numpy.savez_compressed", "print", "numpy.load", "numpy.zeros", "range", "enumerate", "numpy.transpose"], "function", ["None"], ["", "def", "processCriteoAdData", "(", "d_path", ",", "d_file", ",", "npzfile", ",", "i", ",", "convertDicts", ",", "pre_comp_counts", ")", ":", "\n", "# Process Kaggle Display Advertising Challenge or Terabyte Dataset", "\n", "# by converting unicode strings in X_cat to integers and", "\n", "# converting negative integer values in X_int.", "\n", "#", "\n", "# Loads data in the form \"{kaggle|terabyte}_day_i.npz\" where i is the day.", "\n", "#", "\n", "# Inputs:", "\n", "#   d_path (str): path for {kaggle|terabyte}_day_i.npz files", "\n", "#   i (int): splits in the dataset (typically 0 to 7 or 0 to 24)", "\n", "\n", "# process data if not all files exist", "\n", "    ", "filename_i", "=", "npzfile", "+", "\"_{0}_processed.npz\"", ".", "format", "(", "i", ")", "\n", "\n", "if", "path", ".", "exists", "(", "filename_i", ")", ":", "\n", "        ", "print", "(", "\"Using existing \"", "+", "filename_i", ",", "end", "=", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Not existing \"", "+", "filename_i", ")", "\n", "with", "np", ".", "load", "(", "npzfile", "+", "\"_{0}.npz\"", ".", "format", "(", "i", ")", ")", "as", "data", ":", "\n", "# categorical features", "\n", "            ", "'''\n            # Approach 1a: using empty dictionaries\n            X_cat, convertDicts, counts = convertUStringToDistinctIntsDict(\n                data[\"X_cat\"], convertDicts, counts\n            )\n            '''", "\n", "'''\n            # Approach 1b: using empty np.unique\n            X_cat, convertDicts, counts = convertUStringToDistinctIntsUnique(\n                data[\"X_cat\"], convertDicts, counts\n            )\n            '''", "\n", "# Approach 2a: using pre-computed dictionaries", "\n", "X_cat_t", "=", "np", ".", "zeros", "(", "data", "[", "\"X_cat_t\"", "]", ".", "shape", ")", "\n", "for", "j", "in", "range", "(", "26", ")", ":", "\n", "                ", "for", "k", ",", "x", "in", "enumerate", "(", "data", "[", "\"X_cat_t\"", "]", "[", "j", ",", ":", "]", ")", ":", "\n", "                    ", "X_cat_t", "[", "j", ",", "k", "]", "=", "convertDicts", "[", "j", "]", "[", "x", "]", "\n", "# continuous features", "\n", "", "", "X_int", "=", "data", "[", "\"X_int\"", "]", "\n", "X_int", "[", "X_int", "<", "0", "]", "=", "0", "\n", "# targets", "\n", "y", "=", "data", "[", "\"y\"", "]", "\n", "\n", "", "np", ".", "savez_compressed", "(", "\n", "filename_i", ",", "\n", "# X_cat = X_cat,", "\n", "X_cat", "=", "np", ".", "transpose", "(", "X_cat_t", ")", ",", "# transpose of the data", "\n", "X_int", "=", "X_int", ",", "\n", "y", "=", "y", ",", "\n", ")", "\n", "print", "(", "\"Processed \"", "+", "filename_i", ",", "end", "=", "\"\\n\"", ")", "\n", "# sanity check (applicable only if counts have been pre-computed & are re-computed)", "\n", "# for j in range(26):", "\n", "#    if pre_comp_counts[j] != counts[j]:", "\n", "#        sys.exit(\"ERROR: Sanity check on counts has failed\")", "\n", "# print(\"\\nSanity check on counts passed\")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.concatCriteoAdData": [[172, 754], ["numpy.array", "range", "range", "range", "print", "range", "print", "numpy.savez_compressed", "range", "range", "os.path.exists", "range", "print", "numpy.load", "os.path.exists", "os.path.exists", "os.path.exists", "print", "numpy.save", "numpy.save", "numpy.save", "len", "print", "range", "range", "print", "numpy.load", "numpy.load", "numpy.load", "range", "print", "numpy.savez_compressed", "str", "numpy.load", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.load", "sys.exit", "buckets.append", "numpy.random.randint", "range", "range", "numpy.sum", "sys.exit", "numpy.load", "numpy.load", "numpy.load", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "buckets[].append", "buckets[].append", "numpy.random.permutation", "range", "numpy.random.randint"], "function", ["None"], ["", "def", "concatCriteoAdData", "(", "\n", "d_path", ",", "\n", "d_file", ",", "\n", "npzfile", ",", "\n", "trafile", ",", "\n", "days", ",", "\n", "data_split", ",", "\n", "randomize", ",", "\n", "total_per_file", ",", "\n", "total_count", ",", "\n", "memory_map", ",", "\n", "o_filename", "\n", ")", ":", "\n", "# Concatenates different days and saves the result.", "\n", "#", "\n", "# Inputs:", "\n", "#   days (int): total number of days in the dataset (typically 7 or 24)", "\n", "#   d_path (str): path for {kaggle|terabyte}_day_i.npz files", "\n", "#   o_filename (str): output file name", "\n", "#", "\n", "# Output:", "\n", "#   o_file (str): output file path", "\n", "\n", "    ", "if", "memory_map", ":", "\n", "# dataset break up per fea", "\n", "# tar_fea = 1   # single target", "\n", "        ", "den_fea", "=", "13", "# 13 dense  features", "\n", "spa_fea", "=", "26", "# 26 sparse features", "\n", "# tad_fea = tar_fea + den_fea", "\n", "# tot_fea = tad_fea + spa_fea", "\n", "# create offset per file", "\n", "offset_per_file", "=", "np", ".", "array", "(", "[", "0", "]", "+", "[", "x", "for", "x", "in", "total_per_file", "]", ")", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "offset_per_file", "[", "i", "+", "1", "]", "+=", "offset_per_file", "[", "i", "]", "\n", "\n", "", "'''\n        # Approach 1, 2 and 3 use indices, while Approach 4 does not use them\n        # create indices\n        indices = np.arange(total_count)\n        if data_split == \"none\":\n            if randomize == \"total\":\n                indices = np.random.permutation(indices)\n        else:\n            indices = np.array_split(indices, offset_per_file[1:-1])\n\n            # randomize train data (per day)\n            if randomize == \"day\":  # or randomize == \"total\":\n                for i in range(len(indices) - 1):\n                    indices[i] = np.random.permutation(indices[i])\n                print(\"Randomized indices per day ...\")\n\n            train_indices = np.concatenate(indices[:-1])\n            test_indices = indices[-1]\n\n            # randomize train data (across days)\n            if randomize == \"total\":\n                train_indices = np.random.permutation(train_indices)\n                print(\"Randomized indices across days ...\")\n\n            indices = np.concatenate((train_indices, test_indices))\n        # no reordering\n        # indices = np.arange(total_count)\n        '''", "\n", "'''\n        # Approach 1: simple and slow (no grouping is used)\n        # check if data already exists\n        recreate_flag = False\n        for j in range(tot_fea):\n            filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n            if path.exists(filename_j):\n                print(\"Using existing \" + filename_j)\n            else:\n                recreate_flag = True\n        # load, reorder and concatenate data (memmap all reordered files per feature)\n        if recreate_flag:\n            # init reordered files (.npy appended automatically)\n            z = np.zeros((total_count))\n            for j in range(tot_fea):\n                filename_j = trafile + \"_{0}_reordered\".format(j)\n                np.save(filename_j, z)\n                print(\"Creating \" + filename_j)\n\n            for i in range(days):\n                filename_i = d_path + npzfile + \"_{0}_processed.npz\".format(i)\n                with np.load(filename_i) as data:\n                    X_cat_t = np.transpose(data[\"X_cat\"])\n                    X_int_t = np.transpose(data[\"X_int\"])\n                    y = data[\"y\"]\n                size = len(y)\n                # sanity check\n                if total_per_file[i] != size:\n                    sys.exit(\"ERROR: sanity check on number of samples failed\")\n                # setup start and end ranges\n                start = offset_per_file[i]\n                end = offset_per_file[i + 1]\n                # print(filename_i)\n                # print(\"start=\" + str(start) + \" end=\" + str(end)\n                #     + \" diff=\" + str(end - start) + \"=\" + str(total_per_file[i]))\n\n                for j in range(tot_fea):\n                    filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n                    fj = np.load(filename_j, mmap_mode='r+')\n                    if j < tar_fea:\n                        fj[indices[start:end]] = y\n                    elif tar_fea <= j and j < tad_fea:\n                        fj[indices[start:end]] = X_int_t[j - tar_fea, :]\n                    else:\n                        fj[indices[start:end]] = X_cat_t[j - tad_fea, :]\n                    del fj\n        else:\n            print(\"Reordered fea files already exist, skipping ...\")\n\n        # check if data already exists\n        recreate_flag = False\n        for i in range(days):\n            filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n            if path.exists(filename_i):\n                print(\"Using existing \" + filename_i)\n            else:\n                recreate_flag = True\n        # split reordered data by files (memmap all reordered files per feature)\n        # on the day boundary del the file object and memmap again\n        if recreate_flag:\n            for i in range(days):\n                filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n                size = total_per_file[i]\n                X_int_t = np.zeros((den_fea, size))\n                X_cat_t = np.zeros((spa_fea, size))\n                # setup start and end ranges\n                start = offset_per_file[i]\n                end = offset_per_file[i + 1]\n                print(\"Creating \" + filename_i)\n                # print(\"start=\" + str(start) + \" end=\" + str(end)\n                #     + \" diff=\" + str(end - start) + \"=\" + str(total_per_file[i]))\n\n                for j in range(tot_fea):\n                    filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n                    fj = np.load(filename_j, mmap_mode='r')\n                    if j < tar_fea:\n                        y = fj[start:end]\n                    elif tar_fea <= j and j < tad_fea:\n                        X_int_t[j - tar_fea, :] = fj[start:end]\n                    else:\n                        X_cat_t[j - tad_fea, :] = fj[start:end]\n                    del fj\n\n                np.savez_compressed(\n                    filename_i,\n                    X_cat=np.transpose(X_cat_t),  # transpose of the data\n                    X_int=np.transpose(X_int_t),  # transpose of the data\n                    y=y,\n                )\n        else:\n            print(\"Reordered day files already exist, skipping ...\")\n        '''", "\n", "'''\n        # Approach 2: group days\n        # check if data already exists\n        recreate_flag = False\n        for j in range(tot_fea):\n            filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n            if path.exists(filename_j):\n                print(\"Using existing \" + filename_j)\n            else:\n                recreate_flag = True\n        # load, reorder and concatenate data (memmap all reordered files per feature)\n        if recreate_flag:\n            # init reordered files (.npy appended automatically)\n            z = np.zeros((total_count))\n            for j in range(tot_fea):\n                filename_j = trafile + \"_{0}_reordered\".format(j)\n                np.save(filename_j, z)\n                print(\"Creating \" + filename_j)\n\n            group_day = 3  # e.g. 8, 4 or 3\n            group_num = days // group_day\n            file_group = [i*group_day for i in range(group_num)] + [days]\n            for ii in range(group_num):\n                # for last may be group_size != group_num, therefore reset it below\n                group_size = file_group[ii + 1] - file_group[ii]\n                X_cat_t = [0]*group_size\n                X_int_t = [0]*group_size\n                y = [0]*group_size\n                start = [0]*group_size\n                end  = [0]*group_size\n                for ig in range(group_size):\n                    i = file_group[ii] + ig\n                    filename_i = d_path + npzfile + \"_{0}_processed.npz\".format(i)\n                    # setup start and end ranges\n                    start[ig] = offset_per_file[i]\n                    end[ig] = offset_per_file[i + 1]\n                    # print(filename_i)\n                    # load a group of files\n                    with np.load(filename_i) as data:\n                        X_cat_t[ig] = np.transpose(data[\"X_cat\"])\n                        X_int_t[ig] = np.transpose(data[\"X_int\"])\n                        y[ig] = data[\"y\"]\n                    # sanity check\n                    if total_per_file[i] != len(y[ig]):\n                        sys.exit(\"ERROR: sanity check on number of samples failed\")\n                # print(\"start=\" + str(start) + \" end=\" + str(end)\n                #  + \" diff=\" + str(end[ig]-start[ig]) + \"=\" + str(total_per_file[i]))\n\n                for j in range(tot_fea):\n                    filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n                    fj = np.load(filename_j, mmap_mode='r+')\n                    for ig in range(group_size):\n                        if j < tar_fea:\n                            fj[indices[start[ig]:end[ig]]] = y[ig]\n                        elif tar_fea <= j and j < tad_fea:\n                            fj[indices[start[ig]:end[ig]]] = X_int_t[ig][j - tar_fea, :]\n                        else:\n                            fj[indices[start[ig]:end[ig]]] = X_cat_t[ig][j - tad_fea, :]\n                    del fj\n        else:\n            print(\"Reordered fea files already exist, skipping ...\")\n\n        # check if data already exists\n        recreate_flag = False\n        for i in range(days):\n            filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n            if path.exists(filename_i):\n                print(\"Using existing \" + filename_i)\n            else:\n                recreate_flag = True\n        # split reordered data by files (memmap all reordered files per feature)\n        # on the day boundary del the file object and memmap again\n        if recreate_flag:\n            for ii in range(group_num):\n                # for last may be group_size != group_num, therefore reset it below\n                group_size = file_group[ii + 1] - file_group[ii]\n                X_cat_t= []; X_int_t = []\n                for ig in range(group_size):\n                    i = file_group[ii] + ig\n                    X_int_t.append(np.zeros((den_fea, total_per_file[i])))\n                    X_cat_t.append(np.zeros((spa_fea, total_per_file[i])))\n                y = [0]*group_size\n                start = [0]*group_size\n                end  = [0]*group_size\n\n                for j in range(tot_fea):\n                    filename_j = trafile + \"_{0}_reordered.npy\".format(j)\n                    fj = np.load(filename_j, mmap_mode='r')\n                    # load a group of files\n                    for ig in range(group_size):\n                        i = file_group[ii] + ig\n                        # setup start and end ranges\n                        start[ig] = offset_per_file[i]\n                        end[ig] = offset_per_file[i + 1]\n                        # load data for the group of files\n                        if j < tar_fea:\n                            y[ig] = fj[start[ig]:end[ig]]\n                        elif tar_fea <= j and j < tad_fea:\n                            X_int_t[ig][j - tar_fea, :] = fj[start[ig]:end[ig]]\n                        else:\n                            X_cat_t[ig][j - tad_fea, :] = fj[start[ig]:end[ig]]\n                    del fj\n\n                for ig in range(group_size):\n                    i = file_group[ii] + ig\n                    filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n                    print(\"Creating \" + filename_i)\n                    np.savez_compressed(\n                        filename_i,\n                        X_cat=np.transpose(X_cat_t[ig]),  # transpose of the data\n                        X_int=np.transpose(X_int_t[ig]),  # transpose of the data\n                        y=y[ig],\n                    )\n        else:\n            print(\"Reordered day files already exist, skipping ...\")\n        '''", "\n", "'''\n        # Approach 3: group features\n        # check if data already exists\n        group_fea = 5  # e.g. 8, 5 or 4\n        group_num = tot_fea // group_fea\n        if tot_fea % group_fea != 0:  # sanity check\n            sys.exit(\"ERROR: the group_fea must divided tot_fea evenly.\")\n        recreate_flag = False\n        for jn in range(group_num):\n            filename_j = trafile + \"_{0}_reordered{1}.npy\".format(\n                jn, group_fea\n            )\n            if path.exists(filename_j):\n                print(\"Using existing \" + filename_j)\n            else:\n                recreate_flag = True\n        # load, reorder and concatenate data (memmap all reordered files per feature)\n        if recreate_flag:\n            # init reordered files (.npy appended automatically)\n            z = np.zeros((group_fea, total_count))\n            for jn in range(group_num):\n                filename_j = trafile + \"_{0}_reordered{1}\".format(\n                    jn, group_fea\n                )\n                np.save(filename_j, z)\n                print(\"Creating \" + filename_j)\n\n            for i in range(days):\n                filename_i = d_path + npzfile + \"_{0}_processed.npz\".format(i)\n                with np.load(filename_i) as data:\n                    X_cat_t = np.transpose(data[\"X_cat\"])\n                    X_int_t = np.transpose(data[\"X_int\"])\n                    y = data[\"y\"]\n                size = len(y)\n                # sanity check\n                if total_per_file[i] != size:\n                    sys.exit(\"ERROR: sanity check on number of samples failed\")\n                # setup start and end ranges\n                start = offset_per_file[i]\n                end = offset_per_file[i + 1]\n                # print(filename_i)\n                # print(\"start=\" + str(start) + \" end=\" + str(end)\n                #      + \" diff=\" + str(end - start) + \"=\" + str(total_per_file[i]))\n\n                for jn in range(group_num):\n                    filename_j = trafile + \"_{0}_reordered{1}.npy\".format(\n                        jn, group_fea\n                    )\n                    fj = np.load(filename_j, mmap_mode='r+')\n                    for jg in range(group_fea):\n                        j = jn * group_fea + jg\n                        # print(\"j=\" + str(j) + \" jn=\" + str(jn) + \" jg=\" + str(jg))\n                        if j < tar_fea:\n                            fj[jg, indices[start:end]] = y\n                        elif tar_fea <= j and j < tad_fea:\n                            fj[jg, indices[start:end]] = X_int_t[j - tar_fea, :]\n                        else:\n                            fj[jg, indices[start:end]] = X_cat_t[j - tad_fea, :]\n                    del fj\n        else:\n            print(\"Reordered fea files already exist, skipping ...\")\n\n        # check if data already exists\n        recreate_flag = False\n        for i in range(days):\n            filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n            if path.exists(filename_i):\n                print(\"Using existing\" + filename_i)\n            else:\n                recreate_flag = True\n        # split reordered data by files (memmap all reordered files per feature)\n        # on the day boundary del the file object and memmap again\n        if recreate_flag:\n            for i in range(days):\n                filename_i = d_path + npzfile + \"_{0}_reordered.npz\".format(i)\n                size = total_per_file[i]\n                X_int_t = np.zeros((den_fea, size))\n                X_cat_t = np.zeros((spa_fea, size))\n                # setup start and end ranges\n                start = offset_per_file[i]\n                end = offset_per_file[i + 1]\n                print(\"Creating \" + filename_i)\n                # print(\"start=\" + str(start) + \" end=\" + str(end)\n                #      + \" diff=\" + str(end - start) + \"=\" + str(total_per_file[i]))\n\n                for jn in range(group_num):\n                    filename_j = trafile + \"_{0}_reordered{1}.npy\".format(\n                        jn, group_fea\n                    )\n                    fj = np.load(filename_j, mmap_mode='r')\n                    for jg in range(group_fea):\n                        j = jn * group_fea + jg\n                        # print(\"j=\" + str(j) + \" jn=\" + str(jn) + \" jg=\" + str(jg))\n                        if j < tar_fea:\n                            y = fj[jg, start:end]\n                        elif tar_fea <= j and j < tad_fea:\n                            X_int_t[j - tar_fea, :] = fj[jg, start:end]\n                        else:\n                            X_cat_t[j - tad_fea, :] = fj[jg, start:end]\n                    del fj\n\n                np.savez_compressed(\n                    filename_i,\n                    X_cat=np.transpose(X_cat_t),  # transpose of the data\n                    X_int=np.transpose(X_int_t),  # transpose of the data\n                    y=y,\n                )\n\n        else:\n            print(\"Reordered day files already exist, skipping ...\")\n        '''", "\n", "\n", "# Approach 4: Fisher-Yates-Rao (FYR) shuffle algorithm", "\n", "# 1st pass of FYR shuffle", "\n", "# check if data already exists", "\n", "recreate_flag", "=", "False", "\n", "for", "j", "in", "range", "(", "days", ")", ":", "\n", "            ", "filename_j_y", "=", "npzfile", "+", "\"_{0}_intermediate_y.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_d", "=", "npzfile", "+", "\"_{0}_intermediate_d.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_s", "=", "npzfile", "+", "\"_{0}_intermediate_s.npy\"", ".", "format", "(", "j", ")", "\n", "if", "(", "\n", "path", ".", "exists", "(", "filename_j_y", ")", "\n", "and", "path", ".", "exists", "(", "filename_j_d", ")", "\n", "and", "path", ".", "exists", "(", "filename_j_s", ")", "\n", ")", ":", "\n", "                ", "print", "(", "\n", "\"Using existing\\n\"", "\n", "+", "filename_j_y", "+", "\"\\n\"", "\n", "+", "filename_j_d", "+", "\"\\n\"", "\n", "+", "filename_j_s", "\n", ")", "\n", "", "else", ":", "\n", "                ", "recreate_flag", "=", "True", "\n", "# reorder across buckets using sampling", "\n", "", "", "if", "recreate_flag", ":", "\n", "# init intermediate files (.npy appended automatically)", "\n", "            ", "for", "j", "in", "range", "(", "days", ")", ":", "\n", "                ", "filename_j_y", "=", "npzfile", "+", "\"_{0}_intermediate_y\"", ".", "format", "(", "j", ")", "\n", "filename_j_d", "=", "npzfile", "+", "\"_{0}_intermediate_d\"", ".", "format", "(", "j", ")", "\n", "filename_j_s", "=", "npzfile", "+", "\"_{0}_intermediate_s\"", ".", "format", "(", "j", ")", "\n", "np", ".", "save", "(", "filename_j_y", ",", "np", ".", "zeros", "(", "(", "total_per_file", "[", "j", "]", ")", ")", ")", "\n", "np", ".", "save", "(", "filename_j_d", ",", "np", ".", "zeros", "(", "(", "total_per_file", "[", "j", "]", ",", "den_fea", ")", ")", ")", "\n", "np", ".", "save", "(", "filename_j_s", ",", "np", ".", "zeros", "(", "(", "total_per_file", "[", "j", "]", ",", "spa_fea", ")", ")", ")", "\n", "# start processing files", "\n", "", "total_counter", "=", "[", "0", "]", "*", "days", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "                ", "filename_i", "=", "npzfile", "+", "\"_{0}_processed.npz\"", ".", "format", "(", "i", ")", "\n", "with", "np", ".", "load", "(", "filename_i", ")", "as", "data", ":", "\n", "                    ", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "\n", "X_int", "=", "data", "[", "\"X_int\"", "]", "\n", "y", "=", "data", "[", "\"y\"", "]", "\n", "", "size", "=", "len", "(", "y", ")", "\n", "# sanity check", "\n", "if", "total_per_file", "[", "i", "]", "!=", "size", ":", "\n", "                    ", "sys", ".", "exit", "(", "\"ERROR: sanity check on number of samples failed\"", ")", "\n", "# debug prints", "\n", "", "print", "(", "\"Reordering (1st pass) \"", "+", "filename_i", ")", "\n", "\n", "# create buckets using sampling of random ints", "\n", "# from (discrete) uniform distribution", "\n", "buckets", "=", "[", "]", "\n", "for", "_j", "in", "range", "(", "days", ")", ":", "\n", "                    ", "buckets", ".", "append", "(", "[", "]", ")", "\n", "", "counter", "=", "[", "0", "]", "*", "days", "\n", "days_to_sample", "=", "days", "if", "data_split", "==", "\"none\"", "else", "days", "-", "1", "\n", "if", "randomize", "==", "\"total\"", ":", "\n", "                    ", "rand_u", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "days_to_sample", ",", "size", "=", "size", ")", "\n", "for", "k", "in", "range", "(", "size", ")", ":", "\n", "# sample and make sure elements per buckets do not overflow", "\n", "                        ", "if", "data_split", "==", "\"none\"", "or", "i", "<", "days", "-", "1", ":", "\n", "# choose bucket", "\n", "                            ", "p", "=", "rand_u", "[", "k", "]", "\n", "# retry of the bucket is full", "\n", "while", "total_counter", "[", "p", "]", "+", "counter", "[", "p", "]", ">=", "total_per_file", "[", "p", "]", ":", "\n", "                                ", "p", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "days_to_sample", ")", "\n", "", "", "else", ":", "# preserve the last day/bucket if needed", "\n", "                            ", "p", "=", "i", "\n", "", "buckets", "[", "p", "]", ".", "append", "(", "k", ")", "\n", "counter", "[", "p", "]", "+=", "1", "\n", "", "", "else", ":", "# randomize is day or none", "\n", "                    ", "for", "k", "in", "range", "(", "size", ")", ":", "\n", "# do not sample, preserve the data in this bucket", "\n", "                        ", "p", "=", "i", "\n", "buckets", "[", "p", "]", ".", "append", "(", "k", ")", "\n", "counter", "[", "p", "]", "+=", "1", "\n", "\n", "# sanity check", "\n", "", "", "if", "np", ".", "sum", "(", "counter", ")", "!=", "size", ":", "\n", "                    ", "sys", ".", "exit", "(", "\"ERROR: sanity check on number of samples failed\"", ")", "\n", "# debug prints", "\n", "# print(counter)", "\n", "# print(str(np.sum(counter)) + \" = \" + str(size))", "\n", "# print([len(x) for x in buckets])", "\n", "# print(total_counter)", "\n", "\n", "# partially feel the buckets", "\n", "", "for", "j", "in", "range", "(", "days", ")", ":", "\n", "                    ", "filename_j_y", "=", "npzfile", "+", "\"_{0}_intermediate_y.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_d", "=", "npzfile", "+", "\"_{0}_intermediate_d.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_s", "=", "npzfile", "+", "\"_{0}_intermediate_s.npy\"", ".", "format", "(", "j", ")", "\n", "start", "=", "total_counter", "[", "j", "]", "\n", "end", "=", "total_counter", "[", "j", "]", "+", "counter", "[", "j", "]", "\n", "# target buckets", "\n", "fj_y", "=", "np", ".", "load", "(", "filename_j_y", ",", "mmap_mode", "=", "'r+'", ")", "\n", "# print(\"start=\" + str(start) + \" end=\" + str(end)", "\n", "#       + \" end - start=\" + str(end - start) + \" \"", "\n", "#       + str(fj_y[start:end].shape) + \" \"", "\n", "#       + str(len(buckets[j])))", "\n", "fj_y", "[", "start", ":", "end", "]", "=", "y", "[", "buckets", "[", "j", "]", "]", "\n", "del", "fj_y", "\n", "# dense buckets", "\n", "fj_d", "=", "np", ".", "load", "(", "filename_j_d", ",", "mmap_mode", "=", "'r+'", ")", "\n", "# print(\"start=\" + str(start) + \" end=\" + str(end)", "\n", "#       + \" end - start=\" + str(end - start) + \" \"", "\n", "#       + str(fj_d[start:end, :].shape) + \" \"", "\n", "#       + str(len(buckets[j])))", "\n", "fj_d", "[", "start", ":", "end", ",", ":", "]", "=", "X_int", "[", "buckets", "[", "j", "]", ",", ":", "]", "\n", "del", "fj_d", "\n", "# sparse buckets", "\n", "fj_s", "=", "np", ".", "load", "(", "filename_j_s", ",", "mmap_mode", "=", "'r+'", ")", "\n", "# print(\"start=\" + str(start) + \" end=\" + str(end)", "\n", "#       + \" end - start=\" + str(end - start) + \" \"", "\n", "#       + str(fj_s[start:end, :].shape) + \" \"", "\n", "#       + str(len(buckets[j])))", "\n", "fj_s", "[", "start", ":", "end", ",", ":", "]", "=", "X_cat", "[", "buckets", "[", "j", "]", ",", ":", "]", "\n", "del", "fj_s", "\n", "# update counters for next step", "\n", "total_counter", "[", "j", "]", "+=", "counter", "[", "j", "]", "\n", "\n", "# 2nd pass of FYR shuffle", "\n", "# check if data already exists", "\n", "", "", "", "for", "j", "in", "range", "(", "days", ")", ":", "\n", "            ", "filename_j", "=", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "j", ")", "\n", "if", "path", ".", "exists", "(", "filename_j", ")", ":", "\n", "                ", "print", "(", "\"Using existing \"", "+", "filename_j", ")", "\n", "", "else", ":", "\n", "                ", "recreate_flag", "=", "True", "\n", "# reorder within buckets", "\n", "", "", "if", "recreate_flag", ":", "\n", "            ", "for", "j", "in", "range", "(", "days", ")", ":", "\n", "                ", "filename_j_y", "=", "npzfile", "+", "\"_{0}_intermediate_y.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_d", "=", "npzfile", "+", "\"_{0}_intermediate_d.npy\"", ".", "format", "(", "j", ")", "\n", "filename_j_s", "=", "npzfile", "+", "\"_{0}_intermediate_s.npy\"", ".", "format", "(", "j", ")", "\n", "fj_y", "=", "np", ".", "load", "(", "filename_j_y", ")", "\n", "fj_d", "=", "np", ".", "load", "(", "filename_j_d", ")", "\n", "fj_s", "=", "np", ".", "load", "(", "filename_j_s", ")", "\n", "\n", "indices", "=", "range", "(", "total_per_file", "[", "j", "]", ")", "\n", "if", "randomize", "==", "\"day\"", "or", "randomize", "==", "\"total\"", ":", "\n", "                    ", "if", "data_split", "==", "\"none\"", "or", "j", "<", "days", "-", "1", ":", "\n", "                        ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "range", "(", "total_per_file", "[", "j", "]", ")", ")", "\n", "\n", "", "", "filename_r", "=", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "j", ")", "\n", "print", "(", "\"Reordering (2nd pass) \"", "+", "filename_r", ")", "\n", "np", ".", "savez_compressed", "(", "\n", "filename_r", ",", "\n", "X_cat", "=", "fj_s", "[", "indices", ",", ":", "]", ",", "\n", "X_int", "=", "fj_d", "[", "indices", ",", ":", "]", ",", "\n", "y", "=", "fj_y", "[", "indices", "]", ",", "\n", ")", "\n", "\n", "", "", "'''\n        # sanity check (under no reordering norms should be zero)\n        for i in range(days):\n            filename_i_o = npzfile + \"_{0}_processed.npz\".format(i)\n            print(filename_i_o)\n            with np.load(filename_i_o) as data_original:\n                X_cat_o = data_original[\"X_cat\"]\n                X_int_o = data_original[\"X_int\"]\n                y_o = data_original[\"y\"]\n            filename_i_r = npzfile + \"_{0}_reordered.npz\".format(i)\n            print(filename_i_r)\n            with np.load(filename_i_r) as data_reordered:\n                X_cat_r = data_reordered[\"X_cat\"]\n                X_int_r = data_reordered[\"X_int\"]\n                y_r = data_reordered[\"y\"]\n            print(np.linalg.norm(y_o - y_r))\n            print(np.linalg.norm(X_int_o - X_int_r))\n            print(np.linalg.norm(X_cat_o - X_cat_r))\n        '''", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Concatenating multiple days into %s.npz file\"", "%", "str", "(", "d_path", "+", "o_filename", ")", ")", "\n", "\n", "# load and concatenate data", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "filename_i", "=", "npzfile", "+", "\"_{0}_processed.npz\"", ".", "format", "(", "i", ")", "\n", "with", "np", ".", "load", "(", "filename_i", ")", "as", "data", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "\n", "X_int", "=", "data", "[", "\"X_int\"", "]", "\n", "y", "=", "data", "[", "\"y\"", "]", "\n", "", "else", ":", "\n", "                    ", "X_cat", "=", "np", ".", "concatenate", "(", "(", "X_cat", ",", "data", "[", "\"X_cat\"", "]", ")", ")", "\n", "X_int", "=", "np", ".", "concatenate", "(", "(", "X_int", ",", "data", "[", "\"X_int\"", "]", ")", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "(", "y", ",", "data", "[", "\"y\"", "]", ")", ")", "\n", "", "", "print", "(", "\"Loaded day:\"", ",", "i", ",", "\"y = 1:\"", ",", "len", "(", "y", "[", "y", "==", "1", "]", ")", ",", "\"y = 0:\"", ",", "len", "(", "y", "[", "y", "==", "0", "]", ")", ")", "\n", "\n", "", "with", "np", ".", "load", "(", "d_path", "+", "d_file", "+", "\"_fea_count.npz\"", ")", "as", "data", ":", "\n", "            ", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "", "print", "(", "\"Loaded counts!\"", ")", "\n", "\n", "np", ".", "savez_compressed", "(", "\n", "d_path", "+", "o_filename", "+", "\".npz\"", ",", "\n", "X_cat", "=", "X_cat", ",", "\n", "X_int", "=", "X_int", ",", "\n", "y", "=", "y", ",", "\n", "counts", "=", "counts", ",", "\n", ")", "\n", "\n", "", "return", "d_path", "+", "o_filename", "+", "\".npz\"", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.transformCriteoAdData": [[756, 874], ["numpy.arange", "numpy.array", "range", "len", "numpy.array_split", "numpy.concatenate", "numpy.array_split", "print", "print", "X_cat_train.astype.astype", "numpy.log", "y_train.astype.astype", "X_cat_val.astype.astype", "numpy.log", "y_val.astype.astype", "X_cat_test.astype.astype", "numpy.log", "y_test.astype.astype", "print", "X_cat[].astype", "numpy.log", "y[].astype", "print", "range", "print", "numpy.random.permutation", "print", "numpy.random.permutation", "print", "numpy.random.permutation", "np.log.astype", "np.log.astype", "np.log.astype", "X_int[].astype", "len"], "function", ["None"], ["", "def", "transformCriteoAdData", "(", "X_cat", ",", "X_int", ",", "y", ",", "days", ",", "data_split", ",", "randomize", ",", "total_per_file", ")", ":", "\n", "# Transforms Criteo Kaggle or terabyte data by applying log transformation", "\n", "# on dense features and converting everything to appropriate tensors.", "\n", "#", "\n", "# Inputs:", "\n", "#     X_cat (ndarray): array of integers corresponding to preprocessed", "\n", "#                      categorical features", "\n", "#     X_int (ndarray): array of integers corresponding to dense features", "\n", "#     y (ndarray):     array of bool corresponding to labels", "\n", "#     data_split(str): flag for splitting dataset into training/validation/test", "\n", "#                      sets", "\n", "#     randomize (str): determines randomization scheme", "\n", "#         \"none\": no randomization", "\n", "#         \"day\": randomizes each day\"s data (only works if split = True)", "\n", "#         \"total\": randomizes total dataset", "\n", "#", "\n", "# Outputs:", "\n", "#     if split:", "\n", "#         X_cat_train (tensor): sparse features for training set", "\n", "#         X_int_train (tensor): dense features for training set", "\n", "#         y_train (tensor): labels for training set", "\n", "#         X_cat_val (tensor): sparse features for validation set", "\n", "#         X_int_val (tensor): dense features for validation set", "\n", "#         y_val (tensor): labels for validation set", "\n", "#         X_cat_test (tensor): sparse features for test set", "\n", "#         X_int_test (tensor): dense features for test set", "\n", "#         y_test (tensor): labels for test set", "\n", "#     else:", "\n", "#         X_cat (tensor): sparse features", "\n", "#         X_int (tensor): dense features", "\n", "#         y (tensor): label", "\n", "\n", "# define initial set of indices", "\n", "    ", "indices", "=", "np", ".", "arange", "(", "len", "(", "y", ")", ")", "\n", "\n", "# create offset per file", "\n", "offset_per_file", "=", "np", ".", "array", "(", "[", "0", "]", "+", "[", "x", "for", "x", "in", "total_per_file", "]", ")", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "        ", "offset_per_file", "[", "i", "+", "1", "]", "+=", "offset_per_file", "[", "i", "]", "\n", "\n", "# split dataset", "\n", "", "if", "data_split", "==", "'train'", ":", "\n", "        ", "indices", "=", "np", ".", "array_split", "(", "indices", ",", "offset_per_file", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# randomize train data (per day)", "\n", "if", "randomize", "==", "\"day\"", ":", "# or randomize == \"total\":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "indices", ")", "-", "1", ")", ":", "\n", "                ", "indices", "[", "i", "]", "=", "np", ".", "random", ".", "permutation", "(", "indices", "[", "i", "]", ")", "\n", "", "print", "(", "\"Randomized indices per day ...\"", ")", "\n", "\n", "", "train_indices", "=", "np", ".", "concatenate", "(", "indices", "[", ":", "-", "1", "]", ")", "\n", "test_indices", "=", "indices", "[", "-", "1", "]", "\n", "test_indices", ",", "val_indices", "=", "np", ".", "array_split", "(", "test_indices", ",", "2", ")", "\n", "\n", "print", "(", "\"Defined training and testing indices...\"", ")", "\n", "\n", "# randomize train data (across days)", "\n", "if", "randomize", "==", "\"total\"", ":", "\n", "            ", "train_indices", "=", "np", ".", "random", ".", "permutation", "(", "train_indices", ")", "\n", "print", "(", "\"Randomized indices across days ...\"", ")", "\n", "\n", "# indices = np.concatenate((train_indices, test_indices))", "\n", "\n", "# create training, validation, and test sets", "\n", "", "X_cat_train", "=", "X_cat", "[", "train_indices", "]", "\n", "X_int_train", "=", "X_int", "[", "train_indices", "]", "\n", "y_train", "=", "y", "[", "train_indices", "]", "\n", "\n", "X_cat_val", "=", "X_cat", "[", "val_indices", "]", "\n", "X_int_val", "=", "X_int", "[", "val_indices", "]", "\n", "y_val", "=", "y", "[", "val_indices", "]", "\n", "\n", "X_cat_test", "=", "X_cat", "[", "test_indices", "]", "\n", "X_int_test", "=", "X_int", "[", "test_indices", "]", "\n", "y_test", "=", "y", "[", "test_indices", "]", "\n", "\n", "print", "(", "\"Split data according to indices...\"", ")", "\n", "\n", "X_cat_train", "=", "X_cat_train", ".", "astype", "(", "np", ".", "long", ")", "\n", "X_int_train", "=", "np", ".", "log", "(", "X_int_train", ".", "astype", "(", "np", ".", "float32", ")", "+", "1", ")", "\n", "y_train", "=", "y_train", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "X_cat_val", "=", "X_cat_val", ".", "astype", "(", "np", ".", "long", ")", "\n", "X_int_val", "=", "np", ".", "log", "(", "X_int_val", ".", "astype", "(", "np", ".", "float32", ")", "+", "1", ")", "\n", "y_val", "=", "y_val", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "X_cat_test", "=", "X_cat_test", ".", "astype", "(", "np", ".", "long", ")", "\n", "X_int_test", "=", "np", ".", "log", "(", "X_int_test", ".", "astype", "(", "np", ".", "float32", ")", "+", "1", ")", "\n", "y_test", "=", "y_test", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "print", "(", "\"Converted to tensors...done!\"", ")", "\n", "\n", "return", "(", "\n", "X_cat_train", ",", "\n", "X_int_train", ",", "\n", "y_train", ",", "\n", "X_cat_val", ",", "\n", "X_int_val", ",", "\n", "y_val", ",", "\n", "X_cat_test", ",", "\n", "X_int_test", ",", "\n", "y_test", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# randomize data", "\n", "        ", "if", "randomize", "==", "\"total\"", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "indices", ")", "\n", "print", "(", "\"Randomized indices...\"", ")", "\n", "\n", "", "X_cat", "=", "X_cat", "[", "indices", "]", ".", "astype", "(", "np", ".", "long", ")", "\n", "X_int", "=", "np", ".", "log", "(", "X_int", "[", "indices", "]", ".", "astype", "(", "np", ".", "float32", ")", "+", "1", ")", "\n", "y", "=", "y", "[", "indices", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "print", "(", "\"Converted to tensors...done!\"", ")", "\n", "\n", "return", "(", "X_cat", ",", "X_int", ",", "y", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.getCriteoAdData": [[876, 1203], ["datafile.split", "os.path.exists", "range", "numpy.sum", "print", "print", "numpy.zeros", "data_utils.concatCriteoAdData", "numpy.sum", "print", "os.path.exists", "os.path.exists", "numpy.savez_compressed", "range", "range", "range", "lstr[].split", "numpy.load", "list", "os.path.exists", "range", "open", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "os.path.exists", "range", "print", "os.path.exists", "multiprocessing.Manager().dict", "multiprocessing.Manager().dict", "range", "range", "enumerate", "len", "os.path.exists", "numpy.savez_compressed", "enumerate", "numpy.load", "multiprocessing.Process", "process.start", "process.join", "data_utils.processCriteoAdData", "print", "list.append", "divmod", "range", "open", "open.close", "sys.exit", "os.path.exists", "str", "numpy.random.uniform", "line.split.split", "range", "numpy.int32", "numpy.array", "print", "numpy.savez_compressed", "print", "print", "multiprocessing.Process", "process.start", "process.join", "print", "range", "data_utils.getCriteoAdData.process_one_file"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.concatCriteoAdData", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.processCriteoAdData"], ["", "", "def", "getCriteoAdData", "(", "\n", "datafile", ",", "\n", "o_filename", ",", "\n", "max_ind_range", "=", "-", "1", ",", "\n", "sub_sample_rate", "=", "0.0", ",", "\n", "days", "=", "7", ",", "\n", "data_split", "=", "'train'", ",", "\n", "randomize", "=", "'total'", ",", "\n", "criteo_kaggle", "=", "True", ",", "\n", "memory_map", "=", "False", ",", "\n", "dataset_multiprocessing", "=", "False", ",", "\n", ")", ":", "\n", "# Passes through entire dataset and defines dictionaries for categorical", "\n", "# features and determines the number of total categories.", "\n", "#", "\n", "# Inputs:", "\n", "#    datafile : path to downloaded raw data file", "\n", "#    o_filename (str): saves results under o_filename if filename is not \"\"", "\n", "#", "\n", "# Output:", "\n", "#   o_file (str): output file path", "\n", "\n", "#split the datafile into path and filename", "\n", "    ", "lstr", "=", "datafile", ".", "split", "(", "\"/\"", ")", "\n", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "\n", "d_file", "=", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "if", "criteo_kaggle", "else", "lstr", "[", "-", "1", "]", "\n", "npzfile", "=", "d_path", "+", "(", "(", "d_file", "+", "\"_day\"", ")", "if", "criteo_kaggle", "else", "d_file", ")", "\n", "trafile", "=", "d_path", "+", "(", "(", "d_file", "+", "\"_fea\"", ")", "if", "criteo_kaggle", "else", "\"fea\"", ")", "\n", "\n", "# count number of datapoints in training set", "\n", "total_file", "=", "d_path", "+", "d_file", "+", "\"_day_count.npz\"", "\n", "if", "path", ".", "exists", "(", "total_file", ")", ":", "\n", "        ", "with", "np", ".", "load", "(", "total_file", ")", "as", "data", ":", "\n", "            ", "total_per_file", "=", "list", "(", "data", "[", "\"total_per_file\"", "]", ")", "\n", "", "total_count", "=", "np", ".", "sum", "(", "total_per_file", ")", "\n", "print", "(", "\"Skipping counts per file (already exist)\"", ")", "\n", "", "else", ":", "\n", "        ", "total_count", "=", "0", "\n", "total_per_file", "=", "[", "]", "\n", "if", "criteo_kaggle", ":", "\n", "# WARNING: The raw data consists of a single train.txt file", "\n", "# Each line in the file is a sample, consisting of 13 continuous and", "\n", "# 26 categorical features (an extra space indicates that feature is", "\n", "# missing and will be interpreted as 0).", "\n", "            ", "if", "path", ".", "exists", "(", "datafile", ")", ":", "\n", "                ", "print", "(", "\"Reading data from path=%s\"", "%", "(", "datafile", ")", ")", "\n", "with", "open", "(", "str", "(", "datafile", ")", ")", "as", "f", ":", "\n", "                    ", "for", "_", "in", "f", ":", "\n", "                        ", "total_count", "+=", "1", "\n", "", "", "total_per_file", ".", "append", "(", "total_count", ")", "\n", "# reset total per file due to split", "\n", "num_data_per_split", ",", "extras", "=", "divmod", "(", "total_count", ",", "days", ")", "\n", "total_per_file", "=", "[", "num_data_per_split", "]", "*", "days", "\n", "for", "j", "in", "range", "(", "extras", ")", ":", "\n", "                    ", "total_per_file", "[", "j", "]", "+=", "1", "\n", "# split into days (simplifies code later on)", "\n", "", "file_id", "=", "0", "\n", "boundary", "=", "total_per_file", "[", "file_id", "]", "\n", "nf", "=", "open", "(", "npzfile", "+", "\"_\"", "+", "str", "(", "file_id", ")", ",", "\"w\"", ")", "\n", "with", "open", "(", "str", "(", "datafile", ")", ")", "as", "f", ":", "\n", "                    ", "for", "j", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                        ", "if", "j", "==", "boundary", ":", "\n", "                            ", "nf", ".", "close", "(", ")", "\n", "file_id", "+=", "1", "\n", "nf", "=", "open", "(", "npzfile", "+", "\"_\"", "+", "str", "(", "file_id", ")", ",", "\"w\"", ")", "\n", "boundary", "+=", "total_per_file", "[", "file_id", "]", "\n", "", "nf", ".", "write", "(", "line", ")", "\n", "", "", "nf", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "                ", "sys", ".", "exit", "(", "\"ERROR: Criteo Kaggle Display Ad Challenge Dataset path is invalid; please download from https://labs.criteo.com/2014/02/kaggle-display-advertising-challenge-dataset\"", ")", "\n", "", "", "else", ":", "\n", "# WARNING: The raw data consist of day_0.gz,... ,day_23.gz text files", "\n", "# Each line in the file is a sample, consisting of 13 continuous and", "\n", "# 26 categorical features (an extra space indicates that feature is", "\n", "# missing and will be interpreted as 0).", "\n", "            ", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "                ", "datafile_i", "=", "datafile", "+", "\"_\"", "+", "str", "(", "i", ")", "# + \".gz\"", "\n", "if", "path", ".", "exists", "(", "str", "(", "datafile_i", ")", ")", ":", "\n", "                    ", "print", "(", "\"Reading data from path=%s\"", "%", "(", "str", "(", "datafile_i", ")", ")", ")", "\n", "# file day_<number>", "\n", "total_per_file_count", "=", "0", "\n", "with", "open", "(", "str", "(", "datafile_i", ")", ")", "as", "f", ":", "\n", "                        ", "for", "_", "in", "f", ":", "\n", "                            ", "total_per_file_count", "+=", "1", "\n", "", "", "total_per_file", ".", "append", "(", "total_per_file_count", ")", "\n", "total_count", "+=", "total_per_file_count", "\n", "", "else", ":", "\n", "                    ", "sys", ".", "exit", "(", "\"ERROR: Criteo Terabyte Dataset path is invalid; please download from https://labs.criteo.com/2013/12/download-terabyte-click-logs\"", ")", "\n", "\n", "# process a file worth of data and reinitialize data", "\n", "# note that a file main contain a single or multiple splits", "\n", "", "", "", "", "def", "process_one_file", "(", "\n", "datfile", ",", "\n", "npzfile", ",", "\n", "split", ",", "\n", "num_data_in_split", ",", "\n", "dataset_multiprocessing", ",", "\n", "convertDictsDay", "=", "None", ",", "\n", "resultDay", "=", "None", "\n", ")", ":", "\n", "        ", "if", "dataset_multiprocessing", ":", "\n", "            ", "convertDicts_day", "=", "[", "{", "}", "for", "_", "in", "range", "(", "26", ")", "]", "\n", "\n", "", "with", "open", "(", "str", "(", "datfile", ")", ")", "as", "f", ":", "\n", "            ", "y", "=", "np", ".", "zeros", "(", "num_data_in_split", ",", "dtype", "=", "\"i4\"", ")", "# 4 byte int", "\n", "X_int", "=", "np", ".", "zeros", "(", "(", "num_data_in_split", ",", "13", ")", ",", "dtype", "=", "\"i4\"", ")", "# 4 byte int", "\n", "X_cat", "=", "np", ".", "zeros", "(", "(", "num_data_in_split", ",", "26", ")", ",", "dtype", "=", "\"i4\"", ")", "# 4 byte int", "\n", "if", "sub_sample_rate", "==", "0.0", ":", "\n", "                ", "rand_u", "=", "1.0", "\n", "", "else", ":", "\n", "                ", "rand_u", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ",", "size", "=", "num_data_in_split", ")", "\n", "\n", "", "i", "=", "0", "\n", "percent", "=", "0", "\n", "for", "k", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "# process a line (data point)", "\n", "                ", "line", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "# set missing values to zero", "\n", "for", "j", "in", "range", "(", "len", "(", "line", ")", ")", ":", "\n", "                    ", "if", "(", "line", "[", "j", "]", "==", "''", ")", "or", "(", "line", "[", "j", "]", "==", "'\\n'", ")", ":", "\n", "                        ", "line", "[", "j", "]", "=", "'0'", "\n", "# sub-sample data by dropping zero targets, if needed", "\n", "", "", "target", "=", "np", ".", "int32", "(", "line", "[", "0", "]", ")", "\n", "if", "target", "==", "0", "and", "(", "rand_u", "if", "sub_sample_rate", "==", "0.0", "else", "rand_u", "[", "k", "]", ")", "<", "sub_sample_rate", ":", "\n", "                    ", "continue", "\n", "\n", "", "y", "[", "i", "]", "=", "target", "\n", "X_int", "[", "i", "]", "=", "np", ".", "array", "(", "line", "[", "1", ":", "14", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "max_ind_range", ">", "0", ":", "\n", "                    ", "X_cat", "[", "i", "]", "=", "np", ".", "array", "(", "\n", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ",", "16", ")", "%", "max_ind_range", ",", "line", "[", "14", ":", "]", ")", ")", ",", "\n", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "X_cat", "[", "i", "]", "=", "np", ".", "array", "(", "\n", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ",", "16", ")", ",", "line", "[", "14", ":", "]", ")", ")", ",", "\n", "dtype", "=", "np", ".", "int32", "\n", ")", "\n", "\n", "# count uniques", "\n", "", "if", "dataset_multiprocessing", ":", "\n", "                    ", "for", "j", "in", "range", "(", "26", ")", ":", "\n", "                        ", "convertDicts_day", "[", "j", "]", "[", "X_cat", "[", "i", "]", "[", "j", "]", "]", "=", "1", "\n", "# debug prints", "\n", "", "if", "float", "(", "i", ")", "/", "num_data_in_split", "*", "100", ">", "percent", "+", "1", ":", "\n", "                        ", "percent", "=", "int", "(", "float", "(", "i", ")", "/", "num_data_in_split", "*", "100", ")", "\n", "print", "(", "\n", "\"Load %d/%d (%d%%) Split: %d  Label True: %d  Stored: %d\"", "\n", "%", "(", "\n", "i", ",", "\n", "num_data_in_split", ",", "\n", "percent", ",", "\n", "split", ",", "\n", "target", ",", "\n", "y", "[", "i", "]", ",", "\n", ")", ",", "\n", "end", "=", "\"\\n\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "for", "j", "in", "range", "(", "26", ")", ":", "\n", "                        ", "convertDicts", "[", "j", "]", "[", "X_cat", "[", "i", "]", "[", "j", "]", "]", "=", "1", "\n", "# debug prints", "\n", "", "print", "(", "\n", "\"Load %d/%d  Split: %d  Label True: %d  Stored: %d\"", "\n", "%", "(", "\n", "i", ",", "\n", "num_data_in_split", ",", "\n", "split", ",", "\n", "target", ",", "\n", "y", "[", "i", "]", ",", "\n", ")", ",", "\n", "end", "=", "\"\\r\"", ",", "\n", ")", "\n", "", "i", "+=", "1", "\n", "\n", "# store num_data_in_split samples or extras at the end of file", "\n", "# count uniques", "\n", "# X_cat_t  = np.transpose(X_cat)", "\n", "# for j in range(26):", "\n", "#     for x in X_cat_t[j,:]:", "\n", "#         convertDicts[j][x] = 1", "\n", "# store parsed", "\n", "", "filename_s", "=", "npzfile", "+", "\"_{0}.npz\"", ".", "format", "(", "split", ")", "\n", "if", "path", ".", "exists", "(", "filename_s", ")", ":", "\n", "                ", "print", "(", "\"\\nSkip existing \"", "+", "filename_s", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "savez_compressed", "(", "\n", "filename_s", ",", "\n", "X_int", "=", "X_int", "[", "0", ":", "i", ",", ":", "]", ",", "\n", "# X_cat=X_cat[0:i, :],", "\n", "X_cat_t", "=", "np", ".", "transpose", "(", "X_cat", "[", "0", ":", "i", ",", ":", "]", ")", ",", "# transpose of the data", "\n", "y", "=", "y", "[", "0", ":", "i", "]", ",", "\n", ")", "\n", "print", "(", "\"\\nSaved \"", "+", "npzfile", "+", "\"_{0}.npz!\"", ".", "format", "(", "split", ")", ")", "\n", "\n", "", "", "if", "dataset_multiprocessing", ":", "\n", "            ", "resultDay", "[", "split", "]", "=", "i", "\n", "convertDictsDay", "[", "split", "]", "=", "convertDicts_day", "\n", "return", "\n", "", "else", ":", "\n", "            ", "return", "i", "\n", "\n", "# create all splits (reuse existing files if possible)", "\n", "", "", "recreate_flag", "=", "False", "\n", "convertDicts", "=", "[", "{", "}", "for", "_", "in", "range", "(", "26", ")", "]", "\n", "# WARNING: to get reproducable sub-sampling results you must reset the seed below", "\n", "# np.random.seed(123)", "\n", "# in this case there is a single split in each day", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "        ", "npzfile_i", "=", "npzfile", "+", "\"_{0}.npz\"", ".", "format", "(", "i", ")", "\n", "npzfile_p", "=", "npzfile", "+", "\"_{0}_processed.npz\"", ".", "format", "(", "i", ")", "\n", "if", "path", ".", "exists", "(", "npzfile_i", ")", ":", "\n", "            ", "print", "(", "\"Skip existing \"", "+", "npzfile_i", ")", "\n", "", "elif", "path", ".", "exists", "(", "npzfile_p", ")", ":", "\n", "            ", "print", "(", "\"Skip existing \"", "+", "npzfile_p", ")", "\n", "", "else", ":", "\n", "            ", "recreate_flag", "=", "True", "\n", "\n", "", "", "if", "recreate_flag", ":", "\n", "        ", "if", "dataset_multiprocessing", ":", "\n", "            ", "resultDay", "=", "Manager", "(", ")", ".", "dict", "(", ")", "\n", "convertDictsDay", "=", "Manager", "(", ")", ".", "dict", "(", ")", "\n", "processes", "=", "[", "Process", "(", "target", "=", "process_one_file", ",", "\n", "name", "=", "\"process_one_file:%i\"", "%", "i", ",", "\n", "args", "=", "(", "npzfile", "+", "\"_{0}\"", ".", "format", "(", "i", ")", ",", "\n", "npzfile", ",", "\n", "i", ",", "\n", "total_per_file", "[", "i", "]", ",", "\n", "dataset_multiprocessing", ",", "\n", "convertDictsDay", ",", "\n", "resultDay", ",", "\n", ")", "\n", ")", "for", "i", "in", "range", "(", "0", ",", "days", ")", "]", "\n", "for", "process", "in", "processes", ":", "\n", "                ", "process", ".", "start", "(", ")", "\n", "", "for", "process", "in", "processes", ":", "\n", "                ", "process", ".", "join", "(", ")", "\n", "", "for", "day", "in", "range", "(", "days", ")", ":", "\n", "                ", "total_per_file", "[", "day", "]", "=", "resultDay", "[", "day", "]", "\n", "print", "(", "\"Constructing convertDicts Split: {}\"", ".", "format", "(", "day", ")", ")", "\n", "convertDicts_tmp", "=", "convertDictsDay", "[", "day", "]", "\n", "for", "i", "in", "range", "(", "26", ")", ":", "\n", "                    ", "for", "j", "in", "convertDicts_tmp", "[", "i", "]", ":", "\n", "                        ", "convertDicts", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "", "", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "                ", "total_per_file", "[", "i", "]", "=", "process_one_file", "(", "\n", "npzfile", "+", "\"_{0}\"", ".", "format", "(", "i", ")", ",", "\n", "npzfile", ",", "\n", "i", ",", "\n", "total_per_file", "[", "i", "]", ",", "\n", "dataset_multiprocessing", ",", "\n", ")", "\n", "\n", "# report and save total into a file", "\n", "", "", "", "total_count", "=", "np", ".", "sum", "(", "total_per_file", ")", "\n", "if", "not", "path", ".", "exists", "(", "total_file", ")", ":", "\n", "        ", "np", ".", "savez_compressed", "(", "total_file", ",", "total_per_file", "=", "total_per_file", ")", "\n", "", "print", "(", "\"Total number of samples:\"", ",", "total_count", ")", "\n", "print", "(", "\"Divided into days/splits:\\n\"", ",", "total_per_file", ")", "\n", "\n", "# dictionary files", "\n", "counts", "=", "np", ".", "zeros", "(", "26", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "if", "recreate_flag", ":", "\n", "# create dictionaries", "\n", "        ", "for", "j", "in", "range", "(", "26", ")", ":", "\n", "            ", "for", "i", ",", "x", "in", "enumerate", "(", "convertDicts", "[", "j", "]", ")", ":", "\n", "                ", "convertDicts", "[", "j", "]", "[", "x", "]", "=", "i", "\n", "", "dict_file_j", "=", "d_path", "+", "d_file", "+", "\"_fea_dict_{0}.npz\"", ".", "format", "(", "j", ")", "\n", "if", "not", "path", ".", "exists", "(", "dict_file_j", ")", ":", "\n", "                ", "np", ".", "savez_compressed", "(", "\n", "dict_file_j", ",", "\n", "unique", "=", "np", ".", "array", "(", "list", "(", "convertDicts", "[", "j", "]", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", ")", "\n", "", "counts", "[", "j", "]", "=", "len", "(", "convertDicts", "[", "j", "]", ")", "\n", "# store (uniques and) counts", "\n", "", "count_file", "=", "d_path", "+", "d_file", "+", "\"_fea_count.npz\"", "\n", "if", "not", "path", ".", "exists", "(", "count_file", ")", ":", "\n", "            ", "np", ".", "savez_compressed", "(", "count_file", ",", "counts", "=", "counts", ")", "\n", "", "", "else", ":", "\n", "# create dictionaries (from existing files)", "\n", "        ", "for", "j", "in", "range", "(", "26", ")", ":", "\n", "            ", "with", "np", ".", "load", "(", "d_path", "+", "d_file", "+", "\"_fea_dict_{0}.npz\"", ".", "format", "(", "j", ")", ")", "as", "data", ":", "\n", "                ", "unique", "=", "data", "[", "\"unique\"", "]", "\n", "", "for", "i", ",", "x", "in", "enumerate", "(", "unique", ")", ":", "\n", "                ", "convertDicts", "[", "j", "]", "[", "x", "]", "=", "i", "\n", "# load (uniques and) counts", "\n", "", "", "with", "np", ".", "load", "(", "d_path", "+", "d_file", "+", "\"_fea_count.npz\"", ")", "as", "data", ":", "\n", "            ", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "\n", "# process all splits", "\n", "", "", "if", "dataset_multiprocessing", ":", "\n", "        ", "processes", "=", "[", "Process", "(", "target", "=", "processCriteoAdData", ",", "\n", "name", "=", "\"processCriteoAdData:%i\"", "%", "i", ",", "\n", "args", "=", "(", "d_path", ",", "\n", "d_file", ",", "\n", "npzfile", ",", "\n", "i", ",", "\n", "convertDicts", ",", "\n", "counts", ",", "\n", ")", "\n", ")", "for", "i", "in", "range", "(", "0", ",", "days", ")", "]", "\n", "for", "process", "in", "processes", ":", "\n", "            ", "process", ".", "start", "(", ")", "\n", "", "for", "process", "in", "processes", ":", "\n", "            ", "process", ".", "join", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "processCriteoAdData", "(", "d_path", ",", "d_file", ",", "npzfile", ",", "i", ",", "convertDicts", ",", "counts", ")", "\n", "\n", "", "", "o_file", "=", "concatCriteoAdData", "(", "\n", "d_path", ",", "\n", "d_file", ",", "\n", "npzfile", ",", "\n", "trafile", ",", "\n", "days", ",", "\n", "data_split", ",", "\n", "randomize", ",", "\n", "total_per_file", ",", "\n", "total_count", ",", "\n", "memory_map", ",", "\n", "o_filename", "\n", ")", "\n", "\n", "return", "o_file", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.loadDataset": [[1205, 1263], ["raw_path.split", "range", "print", "str", "print", "data_utils.getCriteoAdData", "ValueError", "lstr[].split", "os.path.exists", "os.path.exists", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.getCriteoAdData"], ["", "def", "loadDataset", "(", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "data_split", ",", "\n", "raw_path", "=", "\"\"", ",", "\n", "pro_data", "=", "\"\"", ",", "\n", "memory_map", "=", "False", "\n", ")", ":", "\n", "# dataset", "\n", "    ", "if", "dataset", "==", "\"kaggle\"", ":", "\n", "        ", "days", "=", "7", "\n", "o_filename", "=", "\"kaggleAdDisplayChallenge_processed\"", "\n", "", "elif", "dataset", "==", "\"terabyte\"", ":", "\n", "        ", "days", "=", "24", "\n", "o_filename", "=", "\"terabyte_processed\"", "\n", "", "else", ":", "\n", "        ", "raise", "(", "ValueError", "(", "\"Data set option is not supported\"", ")", ")", "\n", "\n", "# split the datafile into path and filename", "\n", "", "lstr", "=", "raw_path", ".", "split", "(", "\"/\"", ")", "\n", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "\n", "d_file", "=", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "if", "dataset", "==", "\"kaggle\"", "else", "lstr", "[", "-", "1", "]", "\n", "npzfile", "=", "(", "d_file", "+", "\"_day\"", ")", "if", "dataset", "==", "\"kaggle\"", "else", "d_file", "\n", "# trafile = d_path + ((d_file + \"_fea\") if dataset == \"kaggle\" else \"fea\")", "\n", "\n", "# check if pre-processed data is available", "\n", "data_ready", "=", "True", "\n", "if", "memory_map", ":", "\n", "        ", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "reo_data", "=", "d_path", "+", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "i", ")", "\n", "if", "not", "path", ".", "exists", "(", "str", "(", "reo_data", ")", ")", ":", "\n", "                ", "data_ready", "=", "False", "\n", "", "", "", "else", ":", "\n", "        ", "if", "not", "path", ".", "exists", "(", "str", "(", "pro_data", ")", ")", ":", "\n", "            ", "data_ready", "=", "False", "\n", "\n", "# pre-process data if needed", "\n", "# WARNNING: when memory mapping is used we get a collection of files", "\n", "", "", "if", "data_ready", ":", "\n", "        ", "print", "(", "\"Reading pre-processed data=%s\"", "%", "(", "str", "(", "pro_data", ")", ")", ")", "\n", "file", "=", "str", "(", "pro_data", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Reading raw data=%s\"", "%", "(", "str", "(", "raw_path", ")", ")", ")", "\n", "file", "=", "getCriteoAdData", "(", "\n", "raw_path", ",", "\n", "o_filename", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "days", ",", "\n", "data_split", ",", "\n", "randomize", ",", "\n", "dataset", "==", "\"kaggle\"", ",", "\n", "memory_map", "\n", ")", "\n", "\n", "", "return", "file", ",", "days", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.__init__": [[195, 199], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "req", "=", "None", "\n", "self", ".", "tensor", "=", "None", "\n", "self", ".", "WaitFunction", "=", "All2All_Scatter_Wait", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait": [[200, 205], ["extend_distributed.Request.WaitFunction.apply"], "methods", ["None"], ["", "def", "wait", "(", "self", ")", ":", "\n", "        ", "ret", "=", "self", ".", "WaitFunction", ".", "apply", "(", "*", "self", ".", "tensor", ")", "\n", "self", ".", "req", "=", "None", "\n", "self", ".", "tensor", "=", "None", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_ScatterList_Req.forward": [[208, 240], ["range", "tuple", "range", "inputs[].new_empty", "torch.scatter", "torch.scatter", "gather_list.append", "req_list.append", "list", "inputs[].split"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "a2a_info", ",", "*", "inputs", ")", ":", "\n", "        ", "global", "myreq", "\n", "batch_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_batch_partition_slices", "\n", "if", "a2a_info", ".", "global_batch_partition_slices", "\n", "else", "a2a_info", ".", "local_batch_num", "\n", ")", "\n", "table_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "if", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "else", "[", "a2a_info", ".", "local_table_num", "]", "*", "my_size", "\n", ")", "\n", "gather_list", "=", "[", "]", "\n", "req_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "my_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "table_split_lengths", "[", "i", "]", ")", ":", "\n", "                ", "out_tensor", "=", "inputs", "[", "0", "]", ".", "new_empty", "(", "\n", "[", "a2a_info", ".", "local_batch_num", ",", "a2a_info", ".", "emb_dim", "]", "\n", ")", "\n", "scatter_list", "=", "(", "\n", "list", "(", "inputs", "[", "j", "]", ".", "split", "(", "batch_split_lengths", ",", "dim", "=", "0", ")", ")", "\n", "if", "i", "==", "my_rank", "\n", "else", "[", "]", "\n", ")", "\n", "req", "=", "dist", ".", "scatter", "(", "out_tensor", ",", "scatter_list", ",", "src", "=", "i", ",", "async_op", "=", "True", ")", "\n", "gather_list", ".", "append", "(", "out_tensor", ")", "\n", "req_list", ".", "append", "(", "req", ")", "\n", "", "", "myreq", ".", "req", "=", "req_list", "\n", "myreq", ".", "tensor", "=", "tuple", "(", "gather_list", ")", "\n", "myreq", ".", "a2a_info", "=", "a2a_info", "\n", "return", "myreq", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_ScatterList_Req.backward": [[241, 250], ["r.wait"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_output", ")", ":", "\n", "        ", "global", "myreq", "\n", "for", "r", "in", "myreq", ".", "req", ":", "\n", "            ", "r", ".", "wait", "(", ")", "\n", "", "myreq", ".", "req", "=", "None", "\n", "grad_inputs", "=", "myreq", ".", "tensor", "\n", "myreq", ".", "tensor", "=", "None", "\n", "return", "(", "None", ",", "*", "grad_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_ScatterList_Wait.forward": [[253, 262], ["r.wait"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "*", "output", ")", ":", "\n", "        ", "global", "myreq", "\n", "ctx", ".", "a2a_info", "=", "myreq", ".", "a2a_info", "\n", "for", "r", "in", "myreq", ".", "req", ":", "\n", "            ", "r", ".", "wait", "(", ")", "\n", "", "myreq", ".", "req", "=", "None", "\n", "myreq", ".", "tensor", "=", "None", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_ScatterList_Wait.backward": [[263, 297], ["range", "tuple", "t.contiguous", "grad_output[].new_empty", "range", "range", "torch.gather", "torch.gather", "req_list.append", "list", "grad_inputs[].split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_output", ")", ":", "\n", "        ", "global", "myreq", "\n", "a2a_info", "=", "ctx", ".", "a2a_info", "\n", "grad_output", "=", "[", "t", ".", "contiguous", "(", ")", "for", "t", "in", "grad_output", "]", "\n", "batch_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_batch_partition_slices", "\n", "if", "a2a_info", ".", "global_batch_partition_slices", "\n", "else", "[", "a2a_info", ".", "local_batch_num", "]", "*", "my_size", "\n", ")", "\n", "per_rank_table_splits", "=", "(", "\n", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "if", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "else", "[", "a2a_info", ".", "local_table_num", "]", "*", "my_size", "\n", ")", "\n", "grad_inputs", "=", "[", "\n", "grad_output", "[", "0", "]", ".", "new_empty", "(", "[", "ctx", ".", "a2a_info", ".", "batch_size", ",", "ctx", ".", "a2a_info", ".", "emb_dim", "]", ")", "\n", "for", "_", "in", "range", "(", "a2a_info", ".", "local_table_num", ")", "\n", "]", "\n", "req_list", "=", "[", "]", "\n", "ind", "=", "0", "\n", "for", "i", "in", "range", "(", "my_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "per_rank_table_splits", "[", "i", "]", ")", ":", "\n", "                ", "gather_list", "=", "(", "\n", "list", "(", "grad_inputs", "[", "j", "]", ".", "split", "(", "batch_split_lengths", ",", "dim", "=", "0", ")", ")", "\n", "if", "i", "==", "my_rank", "\n", "else", "None", "\n", ")", "\n", "req", "=", "dist", ".", "gather", "(", "grad_output", "[", "ind", "]", ",", "gather_list", ",", "dst", "=", "i", ",", "async_op", "=", "True", ")", "\n", "req_list", ".", "append", "(", "req", ")", "\n", "ind", "+=", "1", "\n", "", "", "myreq", ".", "req", "=", "req_list", "\n", "myreq", ".", "tensor", "=", "grad_inputs", "\n", "return", "tuple", "(", "grad_output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Scatter_Req.forward": [[300, 331], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "range", "tuple", "torch.cat.split", "torch.cat.split", "torch.cat.new_empty", "torch.cat.new_empty", "torch.scatter", "torch.scatter", "gather_list.append", "req_list.append"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "a2a_info", ",", "*", "inputs", ")", ":", "\n", "        ", "global", "myreq", "\n", "batch_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_batch_partition_slices", "\n", "if", "a2a_info", ".", "global_batch_partition_slices", "\n", "else", "a2a_info", ".", "local_batch_num", "\n", ")", "\n", "table_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "if", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "else", "[", "a2a_info", ".", "local_table_num", "]", "*", "my_size", "\n", ")", "\n", "input", "=", "torch", ".", "cat", "(", "inputs", ",", "dim", "=", "1", ")", "\n", "scatter_list", "=", "list", "(", "input", ".", "split", "(", "batch_split_lengths", ",", "dim", "=", "0", ")", ")", "\n", "gather_list", "=", "[", "]", "\n", "req_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "my_size", ")", ":", "\n", "            ", "out_tensor", "=", "input", ".", "new_empty", "(", "\n", "[", "a2a_info", ".", "local_batch_num", ",", "table_split_lengths", "[", "i", "]", "*", "a2a_info", ".", "emb_dim", "]", "\n", ")", "\n", "req", "=", "dist", ".", "scatter", "(", "\n", "out_tensor", ",", "scatter_list", "if", "i", "==", "my_rank", "else", "[", "]", ",", "src", "=", "i", ",", "async_op", "=", "True", "\n", ")", "\n", "gather_list", ".", "append", "(", "out_tensor", ")", "\n", "req_list", ".", "append", "(", "req", ")", "\n", "", "myreq", ".", "req", "=", "req_list", "\n", "myreq", ".", "tensor", "=", "tuple", "(", "gather_list", ")", "\n", "myreq", ".", "a2a_info", "=", "a2a_info", "\n", "ctx", ".", "a2a_info", "=", "a2a_info", "\n", "return", "myreq", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Scatter_Req.backward": [[332, 342], ["grad_input.split", "r.wait"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_output", ")", ":", "\n", "        ", "global", "myreq", "\n", "for", "r", "in", "myreq", ".", "req", ":", "\n", "            ", "r", ".", "wait", "(", ")", "\n", "", "myreq", ".", "req", "=", "None", "\n", "grad_input", "=", "myreq", ".", "tensor", "\n", "grad_inputs", "=", "grad_input", ".", "split", "(", "ctx", ".", "a2a_info", ".", "emb_dim", ",", "dim", "=", "1", ")", "\n", "myreq", ".", "tensor", "=", "None", "\n", "return", "(", "None", ",", "*", "grad_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Scatter_Wait.forward": [[345, 354], ["r.wait"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "*", "output", ")", ":", "\n", "        ", "global", "myreq", "\n", "ctx", ".", "a2a_info", "=", "myreq", ".", "a2a_info", "\n", "for", "r", "in", "myreq", ".", "req", ":", "\n", "            ", "r", ".", "wait", "(", ")", "\n", "", "myreq", ".", "req", "=", "None", "\n", "myreq", ".", "tensor", "=", "None", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Scatter_Wait.backward": [[355, 387], ["grad_output[].new_empty", "list", "range", "len", "t.contiguous", "grad_output[].new_empty.split", "torch.gather", "torch.gather", "req_list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_output", ")", ":", "\n", "        ", "global", "myreq", "\n", "assert", "len", "(", "grad_output", ")", "==", "my_size", "\n", "scatter_list", "=", "[", "t", ".", "contiguous", "(", ")", "for", "t", "in", "grad_output", "]", "\n", "a2a_info", "=", "ctx", ".", "a2a_info", "\n", "batch_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_batch_partition_slices", "\n", "if", "a2a_info", ".", "global_batch_partition_slices", "\n", "else", "a2a_info", ".", "local_batch_num", "\n", ")", "\n", "table_split_lengths", "=", "(", "\n", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "if", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "else", "[", "a2a_info", ".", "local_table_num", "]", "*", "my_size", "\n", ")", "\n", "grad_input", "=", "grad_output", "[", "0", "]", ".", "new_empty", "(", "\n", "[", "a2a_info", ".", "batch_size", ",", "a2a_info", ".", "emb_dim", "*", "a2a_info", ".", "local_table_num", "]", "\n", ")", "\n", "gather_list", "=", "list", "(", "grad_input", ".", "split", "(", "batch_split_lengths", ",", "dim", "=", "0", ")", ")", "\n", "req_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "my_size", ")", ":", "\n", "            ", "req", "=", "dist", ".", "gather", "(", "\n", "scatter_list", "[", "i", "]", ",", "\n", "gather_list", "if", "i", "==", "my_rank", "else", "[", "]", ",", "\n", "dst", "=", "i", ",", "\n", "async_op", "=", "True", ",", "\n", ")", "\n", "req_list", ".", "append", "(", "req", ")", "\n", "", "myreq", ".", "req", "=", "req_list", "\n", "myreq", ".", "tensor", "=", "grad_input", "\n", "return", "grad_output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Req.forward": [[390, 427], ["torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view.new_empty", "torch.cat().view.new_empty", "torch.all_to_all_single", "torch.all_to_all_single", "myreq.tensor.append", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "a2a_info", ",", "*", "inputs", ")", ":", "\n", "        ", "global", "myreq", "\n", "with", "record_function", "(", "\"DLRM alltoall_req_fwd_single\"", ")", ":", "\n", "            ", "batch_split_lengths", "=", "a2a_info", ".", "global_batch_partition_slices", "\n", "if", "batch_split_lengths", ":", "\n", "                ", "batch_split_lengths", "=", "[", "\n", "m", "*", "a2a_info", ".", "emb_dim", "*", "a2a_info", ".", "local_table_num", "\n", "for", "m", "in", "batch_split_lengths", "\n", "]", "\n", "", "table_split_lengths", "=", "a2a_info", ".", "global_table_wise_parition_slices", "\n", "if", "table_split_lengths", ":", "\n", "                ", "table_split_lengths", "=", "[", "\n", "a2a_info", ".", "local_batch_num", "*", "e", "*", "a2a_info", ".", "emb_dim", "\n", "for", "e", "in", "table_split_lengths", "\n", "]", "\n", "", "input", "=", "torch", ".", "cat", "(", "inputs", ",", "dim", "=", "1", ")", ".", "view", "(", "[", "-", "1", "]", ")", "\n", "output", "=", "input", ".", "new_empty", "(", "\n", "[", "\n", "a2a_info", ".", "global_table_num", "\n", "*", "a2a_info", ".", "local_batch_num", "\n", "*", "a2a_info", ".", "emb_dim", "\n", "]", "\n", ")", "\n", "req", "=", "dist", ".", "all_to_all_single", "(", "\n", "output", ",", "input", ",", "table_split_lengths", ",", "batch_split_lengths", ",", "async_op", "=", "True", "\n", ")", "\n", "\n", "myreq", ".", "req", "=", "req", "\n", "myreq", ".", "tensor", "=", "[", "]", "\n", "myreq", ".", "tensor", ".", "append", "(", "output", ")", "\n", "myreq", ".", "tensor", "=", "tuple", "(", "myreq", ".", "tensor", ")", "\n", "a2a_info", ".", "batch_split_lengths", "=", "batch_split_lengths", "\n", "a2a_info", ".", "table_split_lengths", "=", "table_split_lengths", "\n", "myreq", ".", "a2a_info", "=", "a2a_info", "\n", "ctx", ".", "a2a_info", "=", "a2a_info", "\n", "return", "myreq", ".", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Req.backward": [[428, 442], ["torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "myreq.req.wait", "grad_input.view().split", "gin.contiguous", "grad_input.view"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_output", ")", ":", "\n", "        ", "global", "myreq", "\n", "with", "record_function", "(", "\"DLRM alltoall_req_bwd_single\"", ")", ":", "\n", "            ", "a2a_info", "=", "ctx", ".", "a2a_info", "\n", "myreq", ".", "req", ".", "wait", "(", ")", "\n", "myreq", ".", "req", "=", "None", "\n", "grad_input", "=", "myreq", ".", "tensor", "\n", "grad_inputs", "=", "grad_input", ".", "view", "(", "[", "a2a_info", ".", "batch_size", ",", "-", "1", "]", ")", ".", "split", "(", "\n", "a2a_info", ".", "emb_dim", ",", "dim", "=", "1", "\n", ")", "\n", "grad_inputs", "=", "[", "gin", ".", "contiguous", "(", ")", "for", "gin", "in", "grad_inputs", "]", "\n", "myreq", ".", "tensor", "=", "None", "\n", "return", "(", "None", ",", "*", "grad_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Wait.forward": [[445, 466], ["torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "myreq.req.wait", "output[].split", "tuple", "out.view"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "*", "output", ")", ":", "\n", "        ", "global", "myreq", "\n", "with", "record_function", "(", "\"DLRM alltoall_wait_fwd_single\"", ")", ":", "\n", "            ", "a2a_info", "=", "myreq", ".", "a2a_info", "\n", "ctx", ".", "a2a_info", "=", "a2a_info", "\n", "myreq", ".", "req", ".", "wait", "(", ")", "\n", "myreq", ".", "req", "=", "None", "\n", "myreq", ".", "tensor", "=", "None", "\n", "table_split_lengths", "=", "(", "\n", "a2a_info", ".", "table_split_lengths", "\n", "if", "a2a_info", ".", "table_split_lengths", "\n", "else", "a2a_info", ".", "local_table_num", "\n", "*", "a2a_info", ".", "local_batch_num", "\n", "*", "a2a_info", ".", "emb_dim", "\n", ")", "\n", "outputs", "=", "output", "[", "0", "]", ".", "split", "(", "table_split_lengths", ")", "\n", "outputs", "=", "tuple", "(", "\n", "[", "out", ".", "view", "(", "[", "a2a_info", ".", "local_batch_num", ",", "-", "1", "]", ")", "for", "out", "in", "outputs", "]", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.All2All_Wait.backward": [[467, 487], ["torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_empty", "torch.cat.new_empty", "torch.all_to_all_single", "torch.all_to_all_single", "gout.contiguous().view", "gout.contiguous"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "grad_outputs", ")", ":", "\n", "        ", "global", "myreq", "\n", "with", "record_function", "(", "\"DLRM alltoall_wait_bwd_single\"", ")", ":", "\n", "            ", "a2a_info", "=", "ctx", ".", "a2a_info", "\n", "grad_outputs", "=", "[", "gout", ".", "contiguous", "(", ")", ".", "view", "(", "[", "-", "1", "]", ")", "for", "gout", "in", "grad_outputs", "]", "\n", "grad_output", "=", "torch", ".", "cat", "(", "grad_outputs", ")", "\n", "grad_input", "=", "grad_output", ".", "new_empty", "(", "\n", "[", "a2a_info", ".", "batch_size", "*", "a2a_info", ".", "local_table_num", "*", "a2a_info", ".", "emb_dim", "]", "\n", ")", "\n", "req", "=", "dist", ".", "all_to_all_single", "(", "\n", "grad_input", ",", "\n", "grad_output", ",", "\n", "a2a_info", ".", "batch_split_lengths", ",", "\n", "a2a_info", ".", "table_split_lengths", ",", "\n", "async_op", "=", "True", ",", "\n", ")", "\n", "myreq", ".", "req", "=", "req", "\n", "myreq", ".", "tensor", "=", "grad_input", "\n", "return", "(", "grad_output", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.AllGather.forward": [[490, 524], ["sum", "list", "input.contiguous.contiguous.contiguous", "torch.all_gather", "torch.all_gather", "isinstance", "len", "input.contiguous.contiguous.size", "input.contiguous.contiguous.size", "sum", "input.contiguous.contiguous.new_empty", "list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.split", "torch.cat.split", "torch.empty_like", "torch.empty_like", "torch.empty_like", "torch.empty_like", "list.append", "range", "input.contiguous.contiguous.new_empty"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.all_gather", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.all_gather"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "global_lengths", ",", "dim", "=", "0", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "global_lengths", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "global_lengths", "=", "[", "global_lengths", "]", "*", "my_size", "\n", "\n", "", "assert", "len", "(", "global_lengths", ")", "==", "my_size", "\n", "assert", "global_lengths", "[", "my_rank", "]", "==", "input", ".", "size", "(", "dim", ")", "\n", "local_start", "=", "sum", "(", "global_lengths", "[", ":", "my_rank", "]", ")", "\n", "\n", "output_size", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "\n", "ctx", ".", "dim", "=", "dim", "\n", "ctx", ".", "local_start", "=", "local_start", "\n", "ctx", ".", "local_length", "=", "global_lengths", "[", "my_rank", "]", "\n", "\n", "input", "=", "input", ".", "contiguous", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "            ", "out_len", "=", "sum", "(", "global_lengths", ")", "\n", "output_size", "[", "dim", "]", "=", "out_len", "\n", "output", "=", "input", ".", "new_empty", "(", "output_size", ")", "\n", "gather_list", "=", "list", "(", "output", ".", "split", "(", "global_lengths", ",", "dim", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "gather_list", "=", "[", "torch", ".", "empty_like", "(", "input", ")", "for", "_", "in", "range", "(", "my_size", ")", "]", "\n", "gather_list", "=", "[", "]", "\n", "for", "length", "in", "global_lengths", ":", "\n", "                ", "output_size", "[", "dim", "]", "=", "length", "\n", "gather_list", ".", "append", "(", "input", ".", "new_empty", "(", "output_size", ")", ")", "\n", "\n", "", "", "dist", ".", "all_gather", "(", "gather_list", ",", "input", ")", "\n", "\n", "if", "dim", "!=", "0", ":", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "gather_list", ",", "dim", "=", "dim", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.AllGather.backward": [[525, 535], ["grad_output.narrow"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "# print(\"Inside All2AllBackward\")", "\n", "        ", "dim", "=", "ctx", ".", "dim", "\n", "start", "=", "ctx", ".", "local_start", "\n", "length", "=", "ctx", ".", "local_length", "\n", "\n", "grad_input", "=", "grad_output", ".", "narrow", "(", "dim", ",", "start", ",", "length", ")", "\n", "\n", "return", "(", "grad_input", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int": [[39, 45], ["int", "os.environ.get"], "function", ["None"], ["def", "env2int", "(", "env_list", ",", "default", "=", "-", "1", ")", ":", "\n", "    ", "for", "e", "in", "env_list", ":", "\n", "        ", "val", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "e", ",", "-", "1", ")", ")", "\n", "if", "val", ">=", "0", ":", "\n", "            ", "return", "val", "\n", "", "", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_my_slice": [[47, 51], ["divmod", "slice", "min", "min"], "function", ["None"], ["", "def", "get_my_slice", "(", "n", ")", ":", "\n", "    ", "k", ",", "m", "=", "divmod", "(", "n", ",", "my_size", ")", "\n", "return", "slice", "(", "\n", "my_rank", "*", "k", "+", "min", "(", "my_rank", ",", "m", ")", ",", "(", "my_rank", "+", "1", ")", "*", "k", "+", "min", "(", "my_rank", "+", "1", ",", "m", ")", ",", "1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_split_lengths": [[54, 63], ["divmod", "range"], "function", ["None"], ["", "def", "get_split_lengths", "(", "n", ")", ":", "\n", "    ", "k", ",", "m", "=", "divmod", "(", "n", ",", "my_size", ")", "\n", "if", "m", "==", "0", ":", "\n", "        ", "splits", "=", "None", "\n", "my_len", "=", "k", "\n", "", "else", ":", "\n", "        ", "splits", "=", "[", "(", "k", "+", "1", ")", "if", "i", "<", "m", "else", "k", "for", "i", "in", "range", "(", "my_size", ")", "]", "\n", "my_len", "=", "splits", "[", "my_rank", "]", "\n", "", "return", "(", "my_len", ",", "splits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.init_distributed": [[65, 192], ["extend_distributed.env2int", "extend_distributed.print_all", "extend_distributed.Request", "extend_distributed.env2int", "torch.init_process_group", "torch.get_rank", "torch.get_world_size", "hasattr", "extend_distributed.env2int", "extend_distributed.env2int", "str", "str", "os.environ.get", "os.environ.get", "extend_distributed.env2int", "extend_distributed.env2int", "torch.cuda.set_device", "torch.cuda.set_device", "print", "print", "print", "extend_distributed.env2int", "torch.is_nccl_available", "torch.is_mpi_available", "os.environ.get", "os.environ.get", "print", "print", "torch.cuda.device_count", "torch.cuda.device_count", "print", "sys.exit", "torch.zeros", "torch.zeros", "torch.all_to_all_single", "print", "t.cuda.cuda", "print", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.print_all", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.env2int"], ["", "def", "init_distributed", "(", "rank", "=", "-", "1", ",", "local_rank", "=", "-", "1", ",", "size", "=", "-", "1", ",", "use_gpu", "=", "False", ",", "backend", "=", "\"\"", ")", ":", "\n", "    ", "global", "myreq", "\n", "global", "my_rank", "\n", "global", "my_size", "\n", "global", "my_local_rank", "\n", "global", "my_local_size", "\n", "global", "a2a_impl", "\n", "global", "alltoall_supported", "\n", "\n", "# guess MPI ranks from env (works for IMPI, OMPI and MVAPICH2)", "\n", "num_mpi_ranks", "=", "env2int", "(", "\n", "[", "\"PMI_SIZE\"", ",", "\"OMPI_COMM_WORLD_SIZE\"", ",", "\"MV2_COMM_WORLD_SIZE\"", ",", "\"WORLD_SIZE\"", "]", "\n", ")", "\n", "if", "backend", "==", "\"\"", "and", "num_mpi_ranks", ">", "1", ":", "\n", "        ", "if", "torch_ccl", "and", "env2int", "(", "[", "\"CCL_WORKER_COUNT\"", "]", ")", ">", "0", ":", "\n", "            ", "backend", "=", "\"ccl\"", "\n", "", "elif", "use_gpu", "and", "dist", ".", "is_nccl_available", "(", ")", ":", "\n", "            ", "backend", "=", "\"nccl\"", "\n", "", "elif", "dist", ".", "is_mpi_available", "(", ")", ":", "\n", "            ", "backend", "=", "\"mpi\"", "\n", "", "else", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: MPI multi-process launch detected but PyTorch MPI backend not available.\"", "\n", ")", "\n", "backend", "=", "\"gloo\"", "\n", "\n", "", "", "if", "backend", "!=", "\"\"", ":", "\n", "# guess Rank and size", "\n", "        ", "if", "rank", "==", "-", "1", ":", "\n", "            ", "rank", "=", "env2int", "(", "\n", "[", "\"PMI_RANK\"", ",", "\"OMPI_COMM_WORLD_RANK\"", ",", "\"MV2_COMM_WORLD_RANK\"", ",", "\"RANK\"", "]", ",", "0", "\n", ")", "\n", "", "if", "size", "==", "-", "1", ":", "\n", "            ", "size", "=", "env2int", "(", "\n", "[", "\n", "\"PMI_SIZE\"", ",", "\n", "\"OMPI_COMM_WORLD_SIZE\"", ",", "\n", "\"MV2_COMM_WORLD_SIZE\"", ",", "\n", "\"WORLD_SIZE\"", ",", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "", "if", "not", "os", ".", "environ", ".", "get", "(", "\"RANK\"", ",", "None", ")", "and", "rank", "!=", "-", "1", ":", "\n", "            ", "os", ".", "environ", "[", "\"RANK\"", "]", "=", "str", "(", "rank", ")", "\n", "", "if", "not", "os", ".", "environ", ".", "get", "(", "\"WORLD_SIZE\"", ",", "None", ")", "and", "size", "!=", "-", "1", ":", "\n", "            ", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", "=", "str", "(", "size", ")", "\n", "", "if", "not", "os", ".", "environ", ".", "get", "(", "\"MASTER_PORT\"", ",", "None", ")", ":", "\n", "            ", "os", ".", "environ", "[", "\"MASTER_PORT\"", "]", "=", "\"29500\"", "\n", "", "if", "not", "os", ".", "environ", ".", "get", "(", "\"MASTER_ADDR\"", ",", "None", ")", ":", "\n", "            ", "local_size", "=", "env2int", "(", "\n", "[", "\n", "\"MPI_LOCALNRANKS\"", ",", "\n", "\"OMPI_COMM_WORLD_LOCAL_SIZE\"", ",", "\n", "\"MV2_COMM_WORLD_LOCAL_SIZE\"", ",", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "if", "local_size", "!=", "size", "and", "backend", "!=", "\"mpi\"", ":", "\n", "                ", "print", "(", "\n", "\"Warning: Looks like distributed multinode run but MASTER_ADDR env not set, using '127.0.0.1' as default\"", "\n", ")", "\n", "print", "(", "\n", "\"If this run hangs, try exporting rank 0's hostname as MASTER_ADDR\"", "\n", ")", "\n", "", "os", ".", "environ", "[", "\"MASTER_ADDR\"", "]", "=", "\"127.0.0.1\"", "\n", "\n", "", "", "if", "size", ">", "1", ":", "\n", "        ", "if", "local_rank", "==", "-", "1", ":", "\n", "            ", "my_local_rank", "=", "env2int", "(", "\n", "[", "\n", "\"MPI_LOCALRANKID\"", ",", "\n", "\"OMPI_COMM_WORLD_LOCAL_RANK\"", ",", "\n", "\"MV2_COMM_WORLD_LOCAL_RANK\"", ",", "\n", "\"LOCAL_RANK\"", ",", "\n", "]", ",", "\n", "0", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "my_local_rank", "=", "local_rank", "\n", "", "my_local_size", "=", "env2int", "(", "\n", "[", "\n", "\"MPI_LOCALNRANKS\"", ",", "\n", "\"OMPI_COMM_WORLD_LOCAL_SIZE\"", ",", "\n", "\"MV2_COMM_WORLD_LOCAL_SIZE\"", ",", "\n", "]", ",", "\n", "1", ",", "\n", ")", "\n", "if", "use_gpu", ":", "\n", "            ", "if", "my_local_size", ">", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "                ", "print", "(", "\n", "\"Not sufficient GPUs available... local_size = %d, ngpus = %d\"", "\n", "%", "(", "my_local_size", ",", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "my_local_rank", ")", "\n", "", "dist", ".", "init_process_group", "(", "backend", ",", "rank", "=", "rank", ",", "world_size", "=", "size", ")", "\n", "my_rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "my_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "my_rank", "==", "0", ":", "\n", "            ", "print", "(", "\"Running on %d ranks using %s backend\"", "%", "(", "my_size", ",", "backend", ")", ")", "\n", "", "if", "hasattr", "(", "dist", ",", "\"all_to_all_single\"", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "t", "=", "torch", ".", "zeros", "(", "[", "4", "]", ")", "\n", "if", "use_gpu", ":", "\n", "                    ", "t", "=", "t", ".", "cuda", "(", ")", "\n", "", "dist", ".", "all_to_all_single", "(", "t", ",", "t", ")", "\n", "alltoall_supported", "=", "True", "\n", "", "except", "RuntimeError", "as", "err", ":", "\n", "                ", "print", "(", "\"fail to enable all_to_all_single primitive: %s\"", "%", "err", ")", "\n", "", "", "if", "a2a_impl", "==", "\"alltoall\"", "and", "alltoall_supported", "==", "False", ":", "\n", "            ", "print", "(", "\n", "\"Requested DLRM_ALLTOALL_IMPL=%s but backend %s does not support it, use scatter/gather based alltoall\"", "\n", "%", "(", "a2a_impl", ",", "backend", ")", "\n", ")", "\n", "a2a_impl", "=", "\"scatter\"", "\n", "", "if", "a2a_impl", "!=", "\"\"", ":", "\n", "            ", "print", "(", "\"Using DLRM_ALLTOALL_IMPL=%s\"", "%", "a2a_impl", ")", "\n", "", "", "else", ":", "\n", "        ", "my_rank", "=", "0", "\n", "my_size", "=", "1", "\n", "my_local_rank", "=", "0", "\n", "my_local_size", "=", "1", "\n", "", "print_all", "(", "\n", "\"world size: %d, current rank: %d, local rank: %d\"", "\n", "%", "(", "my_size", ",", "my_rank", ",", "my_local_rank", ")", "\n", ")", "\n", "myreq", "=", "Request", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.alltoall": [[541, 577], ["inputs[].size", "extend_distributed.All2AllInfo", "len", "extend_distributed.get_split_lengths", "sum", "All2All_Req.apply", "All2All_Scatter_Req.apply", "All2All_ScatterList_Req.apply", "print"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_split_lengths"], ["", "def", "alltoall", "(", "inputs", ",", "per_rank_table_splits", ")", ":", "\n", "    ", "global", "myreq", "\n", "batch_size", ",", "emb_dim", "=", "inputs", "[", "0", "]", ".", "size", "(", ")", "\n", "a2a_info", "=", "All2AllInfo", "(", ")", "\n", "a2a_info", ".", "local_table_num", "=", "len", "(", "inputs", ")", "\n", "a2a_info", ".", "global_table_wise_parition_slices", "=", "per_rank_table_splits", "\n", "(", "\n", "a2a_info", ".", "local_batch_num", ",", "\n", "a2a_info", ".", "global_batch_partition_slices", ",", "\n", ")", "=", "get_split_lengths", "(", "batch_size", ")", "\n", "a2a_info", ".", "emb_dim", "=", "emb_dim", "\n", "a2a_info", ".", "batch_size", "=", "batch_size", "\n", "a2a_info", ".", "global_table_num", "=", "(", "\n", "sum", "(", "per_rank_table_splits", ")", "\n", "if", "per_rank_table_splits", "\n", "else", "a2a_info", ".", "local_table_num", "*", "my_size", "\n", ")", "\n", "\n", "if", "a2a_impl", "==", "\"\"", "and", "alltoall_supported", "or", "a2a_impl", "==", "\"alltoall\"", ":", "\n", "# print(\"Using All2All_Req\")", "\n", "        ", "output", "=", "All2All_Req", ".", "apply", "(", "a2a_info", ",", "*", "inputs", ")", "\n", "myreq", ".", "WaitFunction", "=", "All2All_Wait", "\n", "", "elif", "a2a_impl", "==", "\"\"", "or", "a2a_impl", "==", "\"scatter\"", ":", "\n", "# print(\"Using All2All_Scatter_Req\")", "\n", "        ", "output", "=", "All2All_Scatter_Req", ".", "apply", "(", "a2a_info", ",", "*", "inputs", ")", "\n", "myreq", ".", "WaitFunction", "=", "All2All_Scatter_Wait", "\n", "", "elif", "a2a_impl", "==", "\"scatter_list\"", ":", "\n", "# print(\"Using All2All_ScatterList_Req\")", "\n", "        ", "output", "=", "All2All_ScatterList_Req", ".", "apply", "(", "a2a_info", ",", "*", "inputs", ")", "\n", "myreq", ".", "WaitFunction", "=", "All2All_ScatterList_Wait", "\n", "", "else", ":", "\n", "        ", "print", "(", "\n", "\"Unknown value set for DLRM_ALLTOALL_IMPL (%s), \"", "\n", "\"please use one of [alltoall, scatter, scatter_list]\"", "%", "a2a_impl", "\n", ")", "\n", "", "return", "myreq", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.all_gather": [[579, 583], ["AllGather.apply", "input.size"], "function", ["None"], ["", "def", "all_gather", "(", "input", ",", "lengths", ",", "dim", "=", "0", ")", ":", "\n", "    ", "if", "not", "lengths", ":", "\n", "        ", "lengths", "=", "[", "input", ".", "size", "(", "0", ")", "]", "*", "my_size", "\n", "", "return", "AllGather", ".", "apply", "(", "input", ",", "lengths", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.barrier": [[585, 588], ["torch.barrier"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier"], ["", "def", "barrier", "(", ")", ":", "\n", "    ", "if", "my_size", ">", "1", ":", "\n", "        ", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.rank0_print": [[594, 597], ["kwargs.get", "orig_print"], "function", ["None"], ["def", "rank0_print", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "my_rank", "<=", "0", "or", "kwargs", ".", "get", "(", "\"print_all\"", ",", "False", ")", ":", "\n", "        ", "orig_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.print_all": [[602, 604], ["orig_print"], "function", ["None"], ["def", "print_all", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "orig_print", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.LRPolicyScheduler.__init__": [[158, 168], ["torch.optim.lr_scheduler._LRScheduler.__init__", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__"], ["    ", "def", "__init__", "(", "self", ",", "optimizer", ",", "num_warmup_steps", ",", "decay_start_step", ",", "num_decay_steps", ")", ":", "\n", "        ", "self", ".", "num_warmup_steps", "=", "num_warmup_steps", "\n", "self", ".", "decay_start_step", "=", "decay_start_step", "\n", "self", ".", "decay_end_step", "=", "decay_start_step", "+", "num_decay_steps", "\n", "self", ".", "num_decay_steps", "=", "num_decay_steps", "\n", "\n", "if", "self", ".", "decay_start_step", "<", "self", ".", "num_warmup_steps", ":", "\n", "            ", "sys", ".", "exit", "(", "\"Learning rate warmup must finish before the decay starts\"", ")", "\n", "\n", "", "super", "(", "LRPolicyScheduler", ",", "self", ")", ".", "__init__", "(", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.LRPolicyScheduler.get_lr": [[169, 192], ["max"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "step_count", "=", "self", ".", "_step_count", "\n", "if", "step_count", "<", "self", ".", "num_warmup_steps", ":", "\n", "# warmup", "\n", "            ", "scale", "=", "1.0", "-", "(", "self", ".", "num_warmup_steps", "-", "step_count", ")", "/", "self", ".", "num_warmup_steps", "\n", "lr", "=", "[", "base_lr", "*", "scale", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "self", ".", "last_lr", "=", "lr", "\n", "", "elif", "self", ".", "decay_start_step", "<=", "step_count", "and", "step_count", "<", "self", ".", "decay_end_step", ":", "\n", "# decay", "\n", "            ", "decayed_steps", "=", "step_count", "-", "self", ".", "decay_start_step", "\n", "scale", "=", "(", "(", "self", ".", "num_decay_steps", "-", "decayed_steps", ")", "/", "self", ".", "num_decay_steps", ")", "**", "2", "\n", "min_lr", "=", "0.0000001", "\n", "lr", "=", "[", "max", "(", "min_lr", ",", "base_lr", "*", "scale", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "\n", "self", ".", "last_lr", "=", "lr", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "num_decay_steps", ">", "0", ":", "\n", "# freeze at last, either because we're after decay", "\n", "# or because we're between warmup and decay", "\n", "                ", "lr", "=", "self", ".", "last_lr", "\n", "", "else", ":", "\n", "# do not adjust", "\n", "                ", "lr", "=", "self", ".", "base_lrs", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.create_mlp": [[196, 235], ["torch.ModuleList", "torch.ModuleList", "range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.Linear", "torch.Linear", "numpy.sqrt", "numpy.random.normal().astype", "numpy.sqrt", "numpy.random.normal().astype", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ModuleList.append", "int", "int", "torch.ModuleList.append", "torch.ModuleList.append", "numpy.random.normal", "numpy.random.normal", "torch.Sigmoid", "torch.Sigmoid", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["    ", "def", "create_mlp", "(", "self", ",", "ln", ",", "sigmoid_layer", ")", ":", "\n", "# build MLP layer by layer", "\n", "        ", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "ln", ".", "size", "-", "1", ")", ":", "\n", "            ", "n", "=", "ln", "[", "i", "]", "\n", "m", "=", "ln", "[", "i", "+", "1", "]", "\n", "\n", "# construct fully connected operator", "\n", "LL", "=", "nn", ".", "Linear", "(", "int", "(", "n", ")", ",", "int", "(", "m", ")", ",", "bias", "=", "True", ")", "\n", "\n", "# initialize the weights", "\n", "# with torch.no_grad():", "\n", "# custom Xavier input, output or two-sided fill", "\n", "mean", "=", "0.0", "# std_dev = np.sqrt(variance)", "\n", "std_dev", "=", "np", ".", "sqrt", "(", "2", "/", "(", "m", "+", "n", ")", ")", "# np.sqrt(1 / m) # np.sqrt(1 / n)", "\n", "W", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "std_dev", ",", "size", "=", "(", "m", ",", "n", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "std_dev", "=", "np", ".", "sqrt", "(", "1", "/", "m", ")", "# np.sqrt(2 / (m + 1))", "\n", "bt", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "std_dev", ",", "size", "=", "m", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# approach 1", "\n", "LL", ".", "weight", ".", "data", "=", "torch", ".", "tensor", "(", "W", ",", "requires_grad", "=", "True", ")", "\n", "LL", ".", "bias", ".", "data", "=", "torch", ".", "tensor", "(", "bt", ",", "requires_grad", "=", "True", ")", "\n", "# approach 2", "\n", "# LL.weight.data.copy_(torch.tensor(W))", "\n", "# LL.bias.data.copy_(torch.tensor(bt))", "\n", "# approach 3", "\n", "# LL.weight = Parameter(torch.tensor(W),requires_grad=True)", "\n", "# LL.bias = Parameter(torch.tensor(bt),requires_grad=True)", "\n", "layers", ".", "append", "(", "LL", ")", "\n", "\n", "# construct sigmoid or relu operator", "\n", "if", "i", "==", "sigmoid_layer", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n", "# approach 1: use ModuleList", "\n", "# return layers", "\n", "# approach 2: use Sequential container to wrap all layers", "\n", "", "", "return", "torch", ".", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.create_emb": [[236, 283], ["torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList.append", "tricks.qr_embedding_bag.QREmbeddingBag", "v_W_l.append", "v_W_l.append", "max", "tricks.md_embedding_bag.PrEmbeddingBag", "numpy.random.uniform().astype", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.EmbeddingBag", "torch.EmbeddingBag", "numpy.random.uniform().astype", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.random.uniform", "numpy.random.uniform", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "create_emb", "(", "self", ",", "m", ",", "ln", ",", "weighted_pooling", "=", "None", ")", ":", "\n", "        ", "emb_l", "=", "nn", ".", "ModuleList", "(", ")", "\n", "v_W_l", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "ln", ".", "size", ")", ":", "\n", "            ", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "                ", "if", "i", "not", "in", "self", ".", "local_emb_indices", ":", "\n", "                    ", "continue", "\n", "", "", "n", "=", "ln", "[", "i", "]", "\n", "\n", "# construct embedding operator", "\n", "if", "self", ".", "qr_flag", "and", "n", ">", "self", ".", "qr_threshold", ":", "\n", "                ", "EE", "=", "QREmbeddingBag", "(", "\n", "n", ",", "\n", "m", ",", "\n", "self", ".", "qr_collisions", ",", "\n", "operation", "=", "self", ".", "qr_operation", ",", "\n", "mode", "=", "\"sum\"", ",", "\n", "sparse", "=", "True", ",", "\n", ")", "\n", "", "elif", "self", ".", "md_flag", "and", "n", ">", "self", ".", "md_threshold", ":", "\n", "                ", "base", "=", "max", "(", "m", ")", "\n", "_m", "=", "m", "[", "i", "]", "if", "n", ">", "self", ".", "md_threshold", "else", "base", "\n", "EE", "=", "PrEmbeddingBag", "(", "n", ",", "_m", ",", "base", ")", "\n", "# use np initialization as below for consistency...", "\n", "W", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "-", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "high", "=", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "size", "=", "(", "n", ",", "_m", ")", "\n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "EE", ".", "embs", ".", "weight", ".", "data", "=", "torch", ".", "tensor", "(", "W", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "EE", "=", "nn", ".", "EmbeddingBag", "(", "n", ",", "m", ",", "mode", "=", "\"sum\"", ",", "sparse", "=", "True", ")", "\n", "# initialize embeddings", "\n", "# nn.init.uniform_(EE.weight, a=-np.sqrt(1 / n), b=np.sqrt(1 / n))", "\n", "W", "=", "np", ".", "random", ".", "uniform", "(", "\n", "low", "=", "-", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "high", "=", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "size", "=", "(", "n", ",", "m", ")", "\n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# approach 1", "\n", "EE", ".", "weight", ".", "data", "=", "torch", ".", "tensor", "(", "W", ",", "requires_grad", "=", "True", ")", "\n", "# approach 2", "\n", "# EE.weight.data.copy_(torch.tensor(W))", "\n", "# approach 3", "\n", "# EE.weight = Parameter(torch.tensor(W),requires_grad=True)", "\n", "", "if", "weighted_pooling", "is", "None", ":", "\n", "                ", "v_W_l", ".", "append", "(", "None", ")", "\n", "", "else", ":", "\n", "                ", "v_W_l", ".", "append", "(", "torch", ".", "ones", "(", "n", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "\n", "", "emb_l", ".", "append", "(", "EE", ")", "\n", "", "return", "emb_l", ",", "v_W_l", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.__init__": [[284, 386], ["torch.Module.__init__", "dlrm_s_pytorch.DLRM_Net.create_mlp", "dlrm_s_pytorch.DLRM_Net.create_mlp", "len", "extend_distributed.get_split_lengths", "extend_distributed.get_my_slice", "dlrm_s_pytorch.DLRM_Net.create_emb", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "sys.exit", "list", "torch.ParameterList", "torch.ParameterList", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "range", "dlrm_s_pytorch.DLRM_Net.v_W_l.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "sys.exit", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_split_lengths", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_my_slice", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_emb"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "m_spa", "=", "None", ",", "\n", "ln_emb", "=", "None", ",", "\n", "ln_bot", "=", "None", ",", "\n", "ln_top", "=", "None", ",", "\n", "arch_interaction_op", "=", "None", ",", "\n", "arch_interaction_itself", "=", "False", ",", "\n", "sigmoid_bot", "=", "-", "1", ",", "\n", "sigmoid_top", "=", "-", "1", ",", "\n", "sync_dense_params", "=", "True", ",", "\n", "loss_threshold", "=", "0.0", ",", "\n", "ndevices", "=", "-", "1", ",", "\n", "qr_flag", "=", "False", ",", "\n", "qr_operation", "=", "\"mult\"", ",", "\n", "qr_collisions", "=", "0", ",", "\n", "qr_threshold", "=", "200", ",", "\n", "md_flag", "=", "False", ",", "\n", "md_threshold", "=", "200", ",", "\n", "weighted_pooling", "=", "None", ",", "\n", "loss_function", "=", "\"bce\"", "\n", ")", ":", "\n", "        ", "super", "(", "DLRM_Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "(", "\n", "(", "m_spa", "is", "not", "None", ")", "\n", "and", "(", "ln_emb", "is", "not", "None", ")", "\n", "and", "(", "ln_bot", "is", "not", "None", ")", "\n", "and", "(", "ln_top", "is", "not", "None", ")", "\n", "and", "(", "arch_interaction_op", "is", "not", "None", ")", "\n", ")", ":", "\n", "\n", "# save arguments", "\n", "            ", "self", ".", "ndevices", "=", "ndevices", "\n", "self", ".", "output_d", "=", "0", "\n", "self", ".", "parallel_model_batch_size", "=", "-", "1", "\n", "self", ".", "parallel_model_is_not_prepared", "=", "True", "\n", "self", ".", "arch_interaction_op", "=", "arch_interaction_op", "\n", "self", ".", "arch_interaction_itself", "=", "arch_interaction_itself", "\n", "self", ".", "sync_dense_params", "=", "sync_dense_params", "\n", "self", ".", "loss_threshold", "=", "loss_threshold", "\n", "self", ".", "loss_function", "=", "loss_function", "\n", "if", "weighted_pooling", "is", "not", "None", "and", "weighted_pooling", "!=", "\"fixed\"", ":", "\n", "                ", "self", ".", "weighted_pooling", "=", "\"learned\"", "\n", "", "else", ":", "\n", "                ", "self", ".", "weighted_pooling", "=", "weighted_pooling", "\n", "# create variables for QR embedding if applicable", "\n", "", "self", ".", "qr_flag", "=", "qr_flag", "\n", "if", "self", ".", "qr_flag", ":", "\n", "                ", "self", ".", "qr_collisions", "=", "qr_collisions", "\n", "self", ".", "qr_operation", "=", "qr_operation", "\n", "self", ".", "qr_threshold", "=", "qr_threshold", "\n", "# create variables for MD embedding if applicable", "\n", "", "self", ".", "md_flag", "=", "md_flag", "\n", "if", "self", ".", "md_flag", ":", "\n", "                ", "self", ".", "md_threshold", "=", "md_threshold", "\n", "\n", "# If running distributed, get local slice of embedding tables", "\n", "", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "                ", "n_emb", "=", "len", "(", "ln_emb", ")", "\n", "if", "n_emb", "<", "ext_dist", ".", "my_size", ":", "\n", "                    ", "sys", ".", "exit", "(", "\n", "\"only (%d) sparse features for (%d) devices, table partitions will fail\"", "\n", "%", "(", "n_emb", ",", "ext_dist", ".", "my_size", ")", "\n", ")", "\n", "", "self", ".", "n_global_emb", "=", "n_emb", "\n", "self", ".", "n_local_emb", ",", "self", ".", "n_emb_per_rank", "=", "ext_dist", ".", "get_split_lengths", "(", "\n", "n_emb", "\n", ")", "\n", "self", ".", "local_emb_slice", "=", "ext_dist", ".", "get_my_slice", "(", "n_emb", ")", "\n", "self", ".", "local_emb_indices", "=", "list", "(", "range", "(", "n_emb", ")", ")", "[", "self", ".", "local_emb_slice", "]", "\n", "\n", "# create operators", "\n", "", "if", "ndevices", "<=", "1", ":", "\n", "                ", "self", ".", "emb_l", ",", "w_list", "=", "self", ".", "create_emb", "(", "m_spa", ",", "ln_emb", ",", "weighted_pooling", ")", "\n", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "                    ", "self", ".", "v_W_l", "=", "nn", ".", "ParameterList", "(", ")", "\n", "for", "w", "in", "w_list", ":", "\n", "                        ", "self", ".", "v_W_l", ".", "append", "(", "Parameter", "(", "w", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "v_W_l", "=", "w_list", "\n", "", "", "self", ".", "bot_l", "=", "self", ".", "create_mlp", "(", "ln_bot", ",", "sigmoid_bot", ")", "\n", "self", ".", "top_l", "=", "self", ".", "create_mlp", "(", "ln_top", ",", "sigmoid_top", ")", "\n", "\n", "# quantization", "\n", "self", ".", "quantize_emb", "=", "False", "\n", "self", ".", "emb_l_q", "=", "[", "]", "\n", "self", ".", "quantize_bits", "=", "32", "\n", "\n", "# specify the loss function", "\n", "if", "self", ".", "loss_function", "==", "\"mse\"", ":", "\n", "                ", "self", ".", "loss_fn", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "", "elif", "self", ".", "loss_function", "==", "\"bce\"", ":", "\n", "                ", "self", ".", "loss_fn", "=", "torch", ".", "nn", ".", "BCELoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "", "elif", "self", ".", "loss_function", "==", "\"wbce\"", ":", "\n", "                ", "self", ".", "loss_ws", "=", "torch", ".", "tensor", "(", "\n", "np", ".", "fromstring", "(", "args", ".", "loss_weights", ",", "dtype", "=", "float", ",", "sep", "=", "\"-\"", ")", "\n", ")", "\n", "self", ".", "loss_fn", "=", "torch", ".", "nn", ".", "BCELoss", "(", "reduction", "=", "\"none\"", ")", "\n", "", "else", ":", "\n", "                ", "sys", ".", "exit", "(", "\n", "\"ERROR: --loss-function=\"", "+", "self", ".", "loss_function", "+", "\" is not supported\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp": [[388, 395], ["layers"], "methods", ["None"], ["", "", "", "def", "apply_mlp", "(", "self", ",", "x", ",", "layers", ")", ":", "\n", "# approach 1: use ModuleList", "\n", "# for layer in layers:", "\n", "#     x = layer(x)", "\n", "# return x", "\n", "# approach 2: use Sequential container to wrap all layers", "\n", "        ", "return", "layers", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_emb": [[396, 452], ["enumerate", "v_W_l[].gather", "print", "ly.append", "E", "ly.append", "dlrm_s_pytorch.DLRM_Net.emb_l_q[].element_size", "dlrm_s_pytorch.DLRM_Net.emb_l_q[].nelement", "dlrm_s_pytorch.DLRM_Net.emb_l_q[].element_size", "dlrm_s_pytorch.DLRM_Net.emb_l_q[].nelement", "torch._ops.ops.quantized.embedding_bag_4bit_rowwise_offsets", "torch._ops.ops.quantized.embedding_bag_4bit_rowwise_offsets", "torch._ops.ops.quantized.embedding_bag_byte_rowwise_offsets", "torch._ops.ops.quantized.embedding_bag_byte_rowwise_offsets"], "methods", ["None"], ["", "def", "apply_emb", "(", "self", ",", "lS_o", ",", "lS_i", ",", "emb_l", ",", "v_W_l", ")", ":", "\n", "# WARNING: notice that we are processing the batch at once. We implicitly", "\n", "# assume that the data is laid out such that:", "\n", "# 1. each embedding is indexed with a group of sparse indices,", "\n", "#   corresponding to a single lookup", "\n", "# 2. for each embedding the lookups are further organized into a batch", "\n", "# 3. for a list of embedding tables there is a list of batched lookups", "\n", "\n", "        ", "ly", "=", "[", "]", "\n", "for", "k", ",", "sparse_index_group_batch", "in", "enumerate", "(", "lS_i", ")", ":", "\n", "            ", "sparse_offset_group_batch", "=", "lS_o", "[", "k", "]", "\n", "\n", "# embedding lookup", "\n", "# We are using EmbeddingBag, which implicitly uses sum operator.", "\n", "# The embeddings are represented as tall matrices, with sum", "\n", "# happening vertically across 0 axis, resulting in a row vector", "\n", "# E = emb_l[k]", "\n", "\n", "if", "v_W_l", "[", "k", "]", "is", "not", "None", ":", "\n", "                ", "per_sample_weights", "=", "v_W_l", "[", "k", "]", ".", "gather", "(", "0", ",", "sparse_index_group_batch", ")", "\n", "", "else", ":", "\n", "                ", "per_sample_weights", "=", "None", "\n", "\n", "", "if", "self", ".", "quantize_emb", ":", "\n", "                ", "s1", "=", "self", ".", "emb_l_q", "[", "k", "]", ".", "element_size", "(", ")", "*", "self", ".", "emb_l_q", "[", "k", "]", ".", "nelement", "(", ")", "\n", "s2", "=", "self", ".", "emb_l_q", "[", "k", "]", ".", "element_size", "(", ")", "*", "self", ".", "emb_l_q", "[", "k", "]", ".", "nelement", "(", ")", "\n", "print", "(", "\"quantized emb sizes:\"", ",", "s1", ",", "s2", ")", "\n", "\n", "if", "self", ".", "quantize_bits", "==", "4", ":", "\n", "                    ", "QV", "=", "ops", ".", "quantized", ".", "embedding_bag_4bit_rowwise_offsets", "(", "\n", "self", ".", "emb_l_q", "[", "k", "]", ",", "\n", "sparse_index_group_batch", ",", "\n", "sparse_offset_group_batch", ",", "\n", "per_sample_weights", "=", "per_sample_weights", ",", "\n", ")", "\n", "", "elif", "self", ".", "quantize_bits", "==", "8", ":", "\n", "                    ", "QV", "=", "ops", ".", "quantized", ".", "embedding_bag_byte_rowwise_offsets", "(", "\n", "self", ".", "emb_l_q", "[", "k", "]", ",", "\n", "sparse_index_group_batch", ",", "\n", "sparse_offset_group_batch", ",", "\n", "per_sample_weights", "=", "per_sample_weights", ",", "\n", ")", "\n", "\n", "", "ly", ".", "append", "(", "QV", ")", "\n", "", "else", ":", "\n", "                ", "E", "=", "emb_l", "[", "k", "]", "\n", "V", "=", "E", "(", "\n", "sparse_index_group_batch", ",", "\n", "sparse_offset_group_batch", ",", "\n", "per_sample_weights", "=", "per_sample_weights", ",", "\n", ")", "\n", "\n", "ly", ".", "append", "(", "V", ")", "\n", "\n", "# print(ly)", "\n", "", "", "return", "ly", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.quantize_embedding": [[454, 472], ["len", "range", "torch._ops.ops.quantized.embedding_bag_4bit_prepack", "torch._ops.ops.quantized.embedding_bag_4bit_prepack", "torch._ops.ops.quantized.embedding_bag_byte_prepack", "torch._ops.ops.quantized.embedding_bag_byte_prepack"], "methods", ["None"], ["", "def", "quantize_embedding", "(", "self", ",", "bits", ")", ":", "\n", "\n", "        ", "n", "=", "len", "(", "self", ".", "emb_l", ")", "\n", "self", ".", "emb_l_q", "=", "[", "None", "]", "*", "n", "\n", "for", "k", "in", "range", "(", "n", ")", ":", "\n", "            ", "if", "bits", "==", "4", ":", "\n", "                ", "self", ".", "emb_l_q", "[", "k", "]", "=", "ops", ".", "quantized", ".", "embedding_bag_4bit_prepack", "(", "\n", "self", ".", "emb_l", "[", "k", "]", ".", "weight", "\n", ")", "\n", "", "elif", "bits", "==", "8", ":", "\n", "                ", "self", ".", "emb_l_q", "[", "k", "]", "=", "ops", ".", "quantized", ".", "embedding_bag_byte_prepack", "(", "\n", "self", ".", "emb_l", "[", "k", "]", ".", "weight", "\n", ")", "\n", "", "else", ":", "\n", "                ", "return", "\n", "", "", "self", ".", "emb_l", "=", "None", "\n", "self", ".", "quantize_emb", "=", "True", "\n", "self", ".", "quantize_bits", "=", "bits", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.interact_features": [[473, 507], ["torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sys.exit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "interact_features", "(", "self", ",", "x", ",", "ly", ")", ":", "\n", "\n", "        ", "if", "self", ".", "arch_interaction_op", "==", "\"dot\"", ":", "\n", "# concatenate dense and sparse features", "\n", "            ", "(", "batch_size", ",", "d", ")", "=", "x", ".", "shape", "\n", "T", "=", "torch", ".", "cat", "(", "[", "x", "]", "+", "ly", ",", "dim", "=", "1", ")", ".", "view", "(", "(", "batch_size", ",", "-", "1", ",", "d", ")", ")", "\n", "# perform a dot product", "\n", "Z", "=", "torch", ".", "bmm", "(", "T", ",", "torch", ".", "transpose", "(", "T", ",", "1", ",", "2", ")", ")", "\n", "# append dense feature with the interactions (into a row vector)", "\n", "# approach 1: all", "\n", "# Zflat = Z.view((batch_size, -1))", "\n", "# approach 2: unique", "\n", "_", ",", "ni", ",", "nj", "=", "Z", ".", "shape", "\n", "# approach 1: tril_indices", "\n", "# offset = 0 if self.arch_interaction_itself else -1", "\n", "# li, lj = torch.tril_indices(ni, nj, offset=offset)", "\n", "# approach 2: custom", "\n", "offset", "=", "1", "if", "self", ".", "arch_interaction_itself", "else", "0", "\n", "li", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", "in", "range", "(", "ni", ")", "for", "j", "in", "range", "(", "i", "+", "offset", ")", "]", ")", "\n", "lj", "=", "torch", ".", "tensor", "(", "[", "j", "for", "i", "in", "range", "(", "nj", ")", "for", "j", "in", "range", "(", "i", "+", "offset", ")", "]", ")", "\n", "Zflat", "=", "Z", "[", ":", ",", "li", ",", "lj", "]", "\n", "# concatenate dense features and interactions", "\n", "R", "=", "torch", ".", "cat", "(", "[", "x", "]", "+", "[", "Zflat", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "arch_interaction_op", "==", "\"cat\"", ":", "\n", "# concatenation features (into a row vector)", "\n", "            ", "R", "=", "torch", ".", "cat", "(", "[", "x", "]", "+", "ly", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: --arch-interaction-op=\"", "\n", "+", "self", ".", "arch_interaction_op", "\n", "+", "\" is not supported\"", "\n", ")", "\n", "\n", "", "return", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.forward": [[508, 518], ["dlrm_s_pytorch.DLRM_Net.distributed_forward", "dlrm_s_pytorch.DLRM_Net.sequential_forward", "dlrm_s_pytorch.DLRM_Net.parallel_forward"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.distributed_forward", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.sequential_forward", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.parallel_forward"], ["", "def", "forward", "(", "self", ",", "dense_x", ",", "lS_o", ",", "lS_i", ")", ":", "\n", "        ", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "# multi-node multi-device run", "\n", "            ", "return", "self", ".", "distributed_forward", "(", "dense_x", ",", "lS_o", ",", "lS_i", ")", "\n", "", "elif", "self", ".", "ndevices", "<=", "1", ":", "\n", "# single device run", "\n", "            ", "return", "self", ".", "sequential_forward", "(", "dense_x", ",", "lS_o", ",", "lS_i", ")", "\n", "", "else", ":", "\n", "# single-node multi-device run", "\n", "            ", "return", "self", ".", "parallel_forward", "(", "dense_x", ",", "lS_o", ",", "lS_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.distributed_forward": [[519, 577], ["extend_distributed.alltoall", "extend_distributed.alltoall.wait", "list", "dense_x.size", "sys.exit", "sys.exit", "sys.exit", "torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "dlrm_s_pytorch.DLRM_Net.apply_emb", "len", "len", "sys.exit", "torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "dlrm_s_pytorch.DLRM_Net.apply_mlp", "torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "dlrm_s_pytorch.DLRM_Net.interact_features", "torch.autograd.profiler.record_function", "torch.autograd.profiler.record_function", "dlrm_s_pytorch.DLRM_Net.apply_mlp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "extend_distributed.get_my_slice", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.alltoall", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.Request.wait", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.interact_features", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_my_slice"], ["", "", "def", "distributed_forward", "(", "self", ",", "dense_x", ",", "lS_o", ",", "lS_i", ")", ":", "\n", "        ", "batch_size", "=", "dense_x", ".", "size", "(", ")", "[", "0", "]", "\n", "# WARNING: # of ranks must be <= batch size in distributed_forward call", "\n", "if", "batch_size", "<", "ext_dist", ".", "my_size", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: batch_size (%d) must be larger than number of ranks (%d)\"", "\n", "%", "(", "batch_size", ",", "ext_dist", ".", "my_size", ")", "\n", ")", "\n", "", "if", "batch_size", "%", "ext_dist", ".", "my_size", "!=", "0", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: batch_size %d can not split across %d ranks evenly\"", "\n", "%", "(", "batch_size", ",", "ext_dist", ".", "my_size", ")", "\n", ")", "\n", "\n", "", "dense_x", "=", "dense_x", "[", "ext_dist", ".", "get_my_slice", "(", "batch_size", ")", "]", "\n", "lS_o", "=", "lS_o", "[", "self", ".", "local_emb_slice", "]", "\n", "lS_i", "=", "lS_i", "[", "self", ".", "local_emb_slice", "]", "\n", "\n", "if", "(", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "lS_o", ")", ")", "or", "(", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "lS_i", ")", ")", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: corrupted model input detected in distributed_forward call\"", "\n", ")", "\n", "\n", "# embeddings", "\n", "", "with", "record_function", "(", "\"DLRM embedding forward\"", ")", ":", "\n", "            ", "ly", "=", "self", ".", "apply_emb", "(", "lS_o", ",", "lS_i", ",", "self", ".", "emb_l", ",", "self", ".", "v_W_l", ")", "\n", "\n", "# WARNING: Note that at this point we have the result of the embedding lookup", "\n", "# for the entire batch on each rank. We would like to obtain partial results", "\n", "# corresponding to all embedding lookups, but part of the batch on each rank.", "\n", "# Therefore, matching the distribution of output of bottom mlp, so that both", "\n", "# could be used for subsequent interactions on each device.", "\n", "", "if", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "ly", ")", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: corrupted intermediate result in distributed_forward call\"", ")", "\n", "\n", "", "a2a_req", "=", "ext_dist", ".", "alltoall", "(", "ly", ",", "self", ".", "n_emb_per_rank", ")", "\n", "\n", "with", "record_function", "(", "\"DLRM bottom nlp forward\"", ")", ":", "\n", "            ", "x", "=", "self", ".", "apply_mlp", "(", "dense_x", ",", "self", ".", "bot_l", ")", "\n", "\n", "", "ly", "=", "a2a_req", ".", "wait", "(", ")", "\n", "ly", "=", "list", "(", "ly", ")", "\n", "\n", "# interactions", "\n", "with", "record_function", "(", "\"DLRM interaction forward\"", ")", ":", "\n", "            ", "z", "=", "self", ".", "interact_features", "(", "x", ",", "ly", ")", "\n", "\n", "# top mlp", "\n", "", "with", "record_function", "(", "\"DLRM top nlp forward\"", ")", ":", "\n", "            ", "p", "=", "self", ".", "apply_mlp", "(", "z", ",", "self", ".", "top_l", ")", "\n", "\n", "# clamp output if needed", "\n", "", "if", "0.0", "<", "self", ".", "loss_threshold", "and", "self", ".", "loss_threshold", "<", "1.0", ":", "\n", "            ", "z", "=", "torch", ".", "clamp", "(", "p", ",", "min", "=", "self", ".", "loss_threshold", ",", "max", "=", "(", "1.0", "-", "self", ".", "loss_threshold", ")", ")", "\n", "", "else", ":", "\n", "            ", "z", "=", "p", "\n", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.sequential_forward": [[578, 604], ["dlrm_s_pytorch.DLRM_Net.apply_mlp", "dlrm_s_pytorch.DLRM_Net.apply_emb", "dlrm_s_pytorch.DLRM_Net.interact_features", "dlrm_s_pytorch.DLRM_Net.apply_mlp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.interact_features", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp"], ["", "def", "sequential_forward", "(", "self", ",", "dense_x", ",", "lS_o", ",", "lS_i", ")", ":", "\n", "# process dense features (using bottom mlp), resulting in a row vector", "\n", "        ", "x", "=", "self", ".", "apply_mlp", "(", "dense_x", ",", "self", ".", "bot_l", ")", "\n", "# debug prints", "\n", "# print(\"intermediate\")", "\n", "# print(x.detach().cpu().numpy())", "\n", "\n", "# process sparse features(using embeddings), resulting in a list of row vectors", "\n", "ly", "=", "self", ".", "apply_emb", "(", "lS_o", ",", "lS_i", ",", "self", ".", "emb_l", ",", "self", ".", "v_W_l", ")", "\n", "# for y in ly:", "\n", "#     print(y.detach().cpu().numpy())", "\n", "\n", "# interact features (dense and sparse)", "\n", "z", "=", "self", ".", "interact_features", "(", "x", ",", "ly", ")", "\n", "# print(z.detach().cpu().numpy())", "\n", "\n", "# obtain probability of a click (using top mlp)", "\n", "p", "=", "self", ".", "apply_mlp", "(", "z", ",", "self", ".", "top_l", ")", "\n", "\n", "# clamp output if needed", "\n", "if", "0.0", "<", "self", ".", "loss_threshold", "and", "self", ".", "loss_threshold", "<", "1.0", ":", "\n", "            ", "z", "=", "torch", ".", "clamp", "(", "p", ",", "min", "=", "self", ".", "loss_threshold", ",", "max", "=", "(", "1.0", "-", "self", ".", "loss_threshold", ")", ")", "\n", "", "else", ":", "\n", "            ", "z", "=", "p", "\n", "\n", "", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.parallel_forward": [[605, 722], ["min", "range", "torch.nn.parallel.scatter_gather.scatter", "torch.nn.parallel.scatter_gather.scatter", "enumerate", "torch.nn.parallel.parallel_apply.parallel_apply", "torch.nn.parallel.parallel_apply.parallel_apply", "dlrm_s_pytorch.DLRM_Net.apply_emb", "enumerate", "list", "range", "torch.nn.parallel.parallel_apply.parallel_apply", "torch.nn.parallel.parallel_apply.parallel_apply", "torch.nn.parallel.scatter_gather.gather", "torch.nn.parallel.scatter_gather.gather", "torch.nn.parallel.scatter_gather.scatter.size", "torch.nn.parallel.scatter_gather.scatter.size", "len", "torch.nn.parallel.replicate.replicate", "torch.nn.parallel.replicate.replicate", "torch.nn.parallel.replicate.replicate", "torch.nn.parallel.replicate.replicate", "enumerate", "torch.ModuleList", "torch.ModuleList", "sys.exit", "torch.device", "torch.device", "torch.device", "torch.device", "t_list.append", "i_list.append", "len", "len", "sys.exit", "torch.device", "torch.device", "torch.device", "torch.device", "torch.nn.parallel.scatter_gather.scatter", "torch.nn.parallel.scatter_gather.scatter", "t_list.append", "map", "dlrm_s_pytorch.DLRM_Net.interact_features", "z.append", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.device", "torch.device", "torch.device", "torch.device", "t_list.append", "torch.ParameterList", "torch.ParameterList", "len", "len", "len", "len", "lS_o[].to", "lS_i[].to", "zip", "emb.to", "w_list.append", "str", "str", "list", "str", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "w_list.append", "w_list.append", "dlrm_s_pytorch.DLRM_Net.v_W_l[].to", "dlrm_s_pytorch.DLRM_Net.v_W_l[].to"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.interact_features"], ["", "def", "parallel_forward", "(", "self", ",", "dense_x", ",", "lS_o", ",", "lS_i", ")", ":", "\n", "### prepare model (overwrite) ###", "\n", "# WARNING: # of devices must be >= batch size in parallel_forward call", "\n", "        ", "batch_size", "=", "dense_x", ".", "size", "(", ")", "[", "0", "]", "\n", "ndevices", "=", "min", "(", "self", ".", "ndevices", ",", "batch_size", ",", "len", "(", "self", ".", "emb_l", ")", ")", "\n", "device_ids", "=", "range", "(", "ndevices", ")", "\n", "# WARNING: must redistribute the model if mini-batch size changes(this is common", "\n", "# for last mini-batch, when # of elements in the dataset/batch size is not even", "\n", "if", "self", ".", "parallel_model_batch_size", "!=", "batch_size", ":", "\n", "            ", "self", ".", "parallel_model_is_not_prepared", "=", "True", "\n", "\n", "", "if", "self", ".", "parallel_model_is_not_prepared", "or", "self", ".", "sync_dense_params", ":", "\n", "# replicate mlp (data parallelism)", "\n", "            ", "self", ".", "bot_l_replicas", "=", "replicate", "(", "self", ".", "bot_l", ",", "device_ids", ")", "\n", "self", ".", "top_l_replicas", "=", "replicate", "(", "self", ".", "top_l", ",", "device_ids", ")", "\n", "self", ".", "parallel_model_batch_size", "=", "batch_size", "\n", "\n", "", "if", "self", ".", "parallel_model_is_not_prepared", ":", "\n", "# distribute embeddings (model parallelism)", "\n", "            ", "t_list", "=", "[", "]", "\n", "w_list", "=", "[", "]", "\n", "for", "k", ",", "emb", "in", "enumerate", "(", "self", ".", "emb_l", ")", ":", "\n", "                ", "d", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "k", "%", "ndevices", ")", ")", "\n", "t_list", ".", "append", "(", "emb", ".", "to", "(", "d", ")", ")", "\n", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "                    ", "w_list", ".", "append", "(", "Parameter", "(", "self", ".", "v_W_l", "[", "k", "]", ".", "to", "(", "d", ")", ")", ")", "\n", "", "elif", "self", ".", "weighted_pooling", "==", "\"fixed\"", ":", "\n", "                    ", "w_list", ".", "append", "(", "self", ".", "v_W_l", "[", "k", "]", ".", "to", "(", "d", ")", ")", "\n", "", "else", ":", "\n", "                    ", "w_list", ".", "append", "(", "None", ")", "\n", "", "", "self", ".", "emb_l", "=", "nn", ".", "ModuleList", "(", "t_list", ")", "\n", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "                ", "self", ".", "v_W_l", "=", "nn", ".", "ParameterList", "(", "w_list", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "v_W_l", "=", "w_list", "\n", "", "self", ".", "parallel_model_is_not_prepared", "=", "False", "\n", "\n", "### prepare input (overwrite) ###", "\n", "# scatter dense features (data parallelism)", "\n", "# print(dense_x.device)", "\n", "", "dense_x", "=", "scatter", "(", "dense_x", ",", "device_ids", ",", "dim", "=", "0", ")", "\n", "# distribute sparse features (model parallelism)", "\n", "if", "(", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "lS_o", ")", ")", "or", "(", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "lS_i", ")", ")", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: corrupted model input detected in parallel_forward call\"", ")", "\n", "\n", "", "t_list", "=", "[", "]", "\n", "i_list", "=", "[", "]", "\n", "for", "k", ",", "_", "in", "enumerate", "(", "self", ".", "emb_l", ")", ":", "\n", "            ", "d", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "k", "%", "ndevices", ")", ")", "\n", "t_list", ".", "append", "(", "lS_o", "[", "k", "]", ".", "to", "(", "d", ")", ")", "\n", "i_list", ".", "append", "(", "lS_i", "[", "k", "]", ".", "to", "(", "d", ")", ")", "\n", "", "lS_o", "=", "t_list", "\n", "lS_i", "=", "i_list", "\n", "\n", "### compute results in parallel ###", "\n", "# bottom mlp", "\n", "# WARNING: Note that the self.bot_l is a list of bottom mlp modules", "\n", "# that have been replicated across devices, while dense_x is a tuple of dense", "\n", "# inputs that has been scattered across devices on the first (batch) dimension.", "\n", "# The output is a list of tensors scattered across devices according to the", "\n", "# distribution of dense_x.", "\n", "x", "=", "parallel_apply", "(", "self", ".", "bot_l_replicas", ",", "dense_x", ",", "None", ",", "device_ids", ")", "\n", "# debug prints", "\n", "# print(x)", "\n", "\n", "# embeddings", "\n", "ly", "=", "self", ".", "apply_emb", "(", "lS_o", ",", "lS_i", ",", "self", ".", "emb_l", ",", "self", ".", "v_W_l", ")", "\n", "# debug prints", "\n", "# print(ly)", "\n", "\n", "# butterfly shuffle (implemented inefficiently for now)", "\n", "# WARNING: Note that at this point we have the result of the embedding lookup", "\n", "# for the entire batch on each device. We would like to obtain partial results", "\n", "# corresponding to all embedding lookups, but part of the batch on each device.", "\n", "# Therefore, matching the distribution of output of bottom mlp, so that both", "\n", "# could be used for subsequent interactions on each device.", "\n", "if", "len", "(", "self", ".", "emb_l", ")", "!=", "len", "(", "ly", ")", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: corrupted intermediate result in parallel_forward call\"", ")", "\n", "\n", "", "t_list", "=", "[", "]", "\n", "for", "k", ",", "_", "in", "enumerate", "(", "self", ".", "emb_l", ")", ":", "\n", "            ", "d", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "k", "%", "ndevices", ")", ")", "\n", "y", "=", "scatter", "(", "ly", "[", "k", "]", ",", "device_ids", ",", "dim", "=", "0", ")", "\n", "t_list", ".", "append", "(", "y", ")", "\n", "# adjust the list to be ordered per device", "\n", "", "ly", "=", "list", "(", "map", "(", "lambda", "y", ":", "list", "(", "y", ")", ",", "zip", "(", "*", "t_list", ")", ")", ")", "\n", "# debug prints", "\n", "# print(ly)", "\n", "\n", "# interactions", "\n", "z", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "ndevices", ")", ":", "\n", "            ", "zk", "=", "self", ".", "interact_features", "(", "x", "[", "k", "]", ",", "ly", "[", "k", "]", ")", "\n", "z", ".", "append", "(", "zk", ")", "\n", "# debug prints", "\n", "# print(z)", "\n", "\n", "# top mlp", "\n", "# WARNING: Note that the self.top_l is a list of top mlp modules that", "\n", "# have been replicated across devices, while z is a list of interaction results", "\n", "# that by construction are scattered across devices on the first (batch) dim.", "\n", "# The output is a list of tensors scattered across devices according to the", "\n", "# distribution of z.", "\n", "", "p", "=", "parallel_apply", "(", "self", ".", "top_l_replicas", ",", "z", ",", "None", ",", "device_ids", ")", "\n", "\n", "### gather the distributed results ###", "\n", "p0", "=", "gather", "(", "p", ",", "self", ".", "output_d", ",", "dim", "=", "0", ")", "\n", "\n", "# clamp output if needed", "\n", "if", "0.0", "<", "self", ".", "loss_threshold", "and", "self", ".", "loss_threshold", "<", "1.0", ":", "\n", "            ", "z0", "=", "torch", ".", "clamp", "(", "\n", "p0", ",", "min", "=", "self", ".", "loss_threshold", ",", "max", "=", "(", "1.0", "-", "self", ".", "loss_threshold", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "z0", "=", "p0", "\n", "\n", "", "return", "z0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.time_wrap": [[114, 118], ["time.time", "torch.cuda.synchronize", "torch.cuda.synchronize"], "function", ["None"], ["def", "time_wrap", "(", "use_gpu", ")", ":", "\n", "    ", "if", "use_gpu", ":", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "return", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.dlrm_wrap": [[120, 137], ["torch.autograd.profiler.record_function", "dlrm", "X.to", "isinstance", "lS_i.to", "isinstance", "lS_o.to", "S_i.to", "S_o.to"], "function", ["None"], ["", "def", "dlrm_wrap", "(", "X", ",", "lS_o", ",", "lS_i", ",", "use_gpu", ",", "device", ",", "ndevices", "=", "1", ")", ":", "\n", "    ", "with", "record_function", "(", "\"DLRM forward\"", ")", ":", "\n", "        ", "if", "use_gpu", ":", "# .cuda()", "\n", "# lS_i can be either a list of tensors or a stacked tensor.", "\n", "# Handle each case below:", "\n", "            ", "if", "ndevices", "==", "1", ":", "\n", "                ", "lS_i", "=", "(", "\n", "[", "S_i", ".", "to", "(", "device", ")", "for", "S_i", "in", "lS_i", "]", "\n", "if", "isinstance", "(", "lS_i", ",", "list", ")", "\n", "else", "lS_i", ".", "to", "(", "device", ")", "\n", ")", "\n", "lS_o", "=", "(", "\n", "[", "S_o", ".", "to", "(", "device", ")", "for", "S_o", "in", "lS_o", "]", "\n", "if", "isinstance", "(", "lS_o", ",", "list", ")", "\n", "else", "lS_o", ".", "to", "(", "device", ")", "\n", ")", "\n", "", "", "return", "dlrm", "(", "X", ".", "to", "(", "device", ")", ",", "lS_o", ",", "lS_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.loss_fn_wrap": [[139, 148], ["torch.autograd.profiler.record_function", "dlrm.loss_fn", "T.to", "dlrm.loss_ws[].view_as().to", "dlrm.loss_fn", "loss_sc_.mean", "T.to", "dlrm.loss_ws[].view_as", "T.data.view().long", "T.data.view"], "function", ["None"], ["", "", "def", "loss_fn_wrap", "(", "Z", ",", "T", ",", "use_gpu", ",", "device", ")", ":", "\n", "    ", "with", "record_function", "(", "\"DLRM loss compute\"", ")", ":", "\n", "        ", "if", "args", ".", "loss_function", "==", "\"mse\"", "or", "args", ".", "loss_function", "==", "\"bce\"", ":", "\n", "            ", "return", "dlrm", ".", "loss_fn", "(", "Z", ",", "T", ".", "to", "(", "device", ")", ")", "\n", "", "elif", "args", ".", "loss_function", "==", "\"wbce\"", ":", "\n", "            ", "loss_ws_", "=", "dlrm", ".", "loss_ws", "[", "T", ".", "data", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "]", ".", "view_as", "(", "T", ")", ".", "to", "(", "device", ")", "\n", "loss_fn_", "=", "dlrm", ".", "loss_fn", "(", "Z", ",", "T", ".", "to", "(", "device", ")", ")", "\n", "loss_sc_", "=", "loss_ws_", "*", "loss_fn_", "\n", "return", "loss_sc_", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.unpack_batch": [[152, 155], ["torch.ones", "torch.ones", "b[].size"], "function", ["None"], ["", "", "", "def", "unpack_batch", "(", "b", ")", ":", "\n", "# Experiment with unweighted samples", "\n", "    ", "return", "b", "[", "0", "]", ",", "b", "[", "1", "]", ",", "b", "[", "2", "]", ",", "b", "[", "3", "]", ",", "torch", ".", "ones", "(", "b", "[", "3", "]", ".", "size", "(", ")", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.dash_separated_ints": [[724, 735], ["value.split", "int", "argparse.ArgumentTypeError"], "function", ["None"], ["", "", "def", "dash_separated_ints", "(", "value", ")", ":", "\n", "    ", "vals", "=", "value", ".", "split", "(", "\"-\"", ")", "\n", "for", "val", "in", "vals", ":", "\n", "        ", "try", ":", "\n", "            ", "int", "(", "val", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "raise", "argparse", ".", "ArgumentTypeError", "(", "\n", "\"%s is not a valid dash separated list of ints\"", "%", "value", "\n", ")", "\n", "\n", "", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.dash_separated_floats": [[737, 748], ["value.split", "float", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "dash_separated_floats", "(", "value", ")", ":", "\n", "    ", "vals", "=", "value", ".", "split", "(", "\"-\"", ")", "\n", "for", "val", "in", "vals", ":", "\n", "        ", "try", ":", "\n", "            ", "float", "(", "val", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "raise", "argparse", ".", "ArgumentTypeError", "(", "\n", "\"%s is not a valid dash separated list of floats\"", "%", "value", "\n", ")", "\n", "\n", "", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.inference": [[750, 891], ["enumerate", "dlrm_s_pytorch.unpack_batch", "dlrm_s_pytorch.dlrm_wrap", "extend_distributed.get_split_lengths", "metrics.items", "writer.add_scalar", "dlrm.state_dict", "print", "print", "print", "torch.cuda.synchronize", "torch.cuda.synchronize", "X_test.size", "extend_distributed.all_gather", "ext_dist.all_gather.detach().cpu().numpy", "T_test.detach().cpu().numpy.detach().cpu().numpy", "np.concatenate.append", "np.concatenate.append", "torch.autograd.profiler.record_function", "numpy.concatenate", "numpy.concatenate", "metric_function", "writer.add_scalar", "torch.autograd.profiler.record_function", "ext_dist.all_gather.detach().cpu().numpy", "T_test.detach().cpu().numpy.detach().cpu().numpy", "numpy.sum", "X_test.size", "ext_dist.all_gather.detach().cpu", "T_test.detach().cpu().numpy.detach().cpu", "sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "X_test.size", "ext_dist.all_gather.detach().cpu", "T_test.detach().cpu().numpy.detach().cpu", "ext_dist.all_gather.detach", "T_test.detach().cpu().numpy.detach", "numpy.round", "numpy.round", "numpy.round", "numpy.round", "ext_dist.all_gather.detach", "T_test.detach().cpu().numpy.detach", "numpy.round"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.unpack_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.dlrm_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_split_lengths", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.all_gather"], ["", "def", "inference", "(", "\n", "args", ",", "\n", "dlrm", ",", "\n", "best_acc_test", ",", "\n", "best_auc_test", ",", "\n", "test_ld", ",", "\n", "device", ",", "\n", "use_gpu", ",", "\n", "log_iter", "=", "-", "1", ",", "\n", ")", ":", "\n", "    ", "test_accu", "=", "0", "\n", "test_samp", "=", "0", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "scores", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "", "for", "i", ",", "testBatch", "in", "enumerate", "(", "test_ld", ")", ":", "\n", "# early exit if nbatches was set by the user and was exceeded", "\n", "        ", "if", "nbatches", ">", "0", "and", "i", ">=", "nbatches", ":", "\n", "            ", "break", "\n", "\n", "", "X_test", ",", "lS_o_test", ",", "lS_i_test", ",", "T_test", ",", "W_test", ",", "CBPP_test", "=", "unpack_batch", "(", "\n", "testBatch", "\n", ")", "\n", "\n", "# Skip the batch if batch size not multiple of total ranks", "\n", "if", "ext_dist", ".", "my_size", ">", "1", "and", "X_test", ".", "size", "(", "0", ")", "%", "ext_dist", ".", "my_size", "!=", "0", ":", "\n", "            ", "print", "(", "\"Warning: Skiping the batch %d with size %d\"", "%", "(", "i", ",", "X_test", ".", "size", "(", "0", ")", ")", ")", "\n", "continue", "\n", "\n", "# forward pass", "\n", "", "Z_test", "=", "dlrm_wrap", "(", "\n", "X_test", ",", "\n", "lS_o_test", ",", "\n", "lS_i_test", ",", "\n", "use_gpu", ",", "\n", "device", ",", "\n", "ndevices", "=", "ndevices", ",", "\n", ")", "\n", "### gather the distributed results on each rank ###", "\n", "# For some reason it requires explicit sync before all_gather call if", "\n", "# tensor is on GPU memory", "\n", "if", "Z_test", ".", "is_cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "(", "_", ",", "batch_split_lengths", ")", "=", "ext_dist", ".", "get_split_lengths", "(", "X_test", ".", "size", "(", "0", ")", ")", "\n", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "            ", "Z_test", "=", "ext_dist", ".", "all_gather", "(", "Z_test", ",", "batch_split_lengths", ")", "\n", "\n", "", "if", "args", ".", "mlperf_logging", ":", "\n", "            ", "S_test", "=", "Z_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# numpy array", "\n", "T_test", "=", "T_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# numpy array", "\n", "scores", ".", "append", "(", "S_test", ")", "\n", "targets", ".", "append", "(", "T_test", ")", "\n", "", "else", ":", "\n", "            ", "with", "record_function", "(", "\"DLRM accuracy compute\"", ")", ":", "\n", "# compute loss and accuracy", "\n", "                ", "S_test", "=", "Z_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# numpy array", "\n", "T_test", "=", "T_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# numpy array", "\n", "\n", "mbs_test", "=", "T_test", ".", "shape", "[", "0", "]", "# = mini_batch_size except last", "\n", "A_test", "=", "np", ".", "sum", "(", "(", "np", ".", "round", "(", "S_test", ",", "0", ")", "==", "T_test", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "test_accu", "+=", "A_test", "\n", "test_samp", "+=", "mbs_test", "\n", "\n", "", "", "", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "with", "record_function", "(", "\"DLRM mlperf sklearn metrics compute\"", ")", ":", "\n", "            ", "scores", "=", "np", ".", "concatenate", "(", "scores", ",", "axis", "=", "0", ")", "\n", "targets", "=", "np", ".", "concatenate", "(", "targets", ",", "axis", "=", "0", ")", "\n", "\n", "metrics", "=", "{", "\n", "\"recall\"", ":", "lambda", "y_true", ",", "y_score", ":", "sklearn", ".", "metrics", ".", "recall_score", "(", "\n", "y_true", "=", "y_true", ",", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "\"precision\"", ":", "lambda", "y_true", ",", "y_score", ":", "sklearn", ".", "metrics", ".", "precision_score", "(", "\n", "y_true", "=", "y_true", ",", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "\"f1\"", ":", "lambda", "y_true", ",", "y_score", ":", "sklearn", ".", "metrics", ".", "f1_score", "(", "\n", "y_true", "=", "y_true", ",", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "\"ap\"", ":", "sklearn", ".", "metrics", ".", "average_precision_score", ",", "\n", "\"roc_auc\"", ":", "sklearn", ".", "metrics", ".", "roc_auc_score", ",", "\n", "\"accuracy\"", ":", "lambda", "y_true", ",", "y_score", ":", "sklearn", ".", "metrics", ".", "accuracy_score", "(", "\n", "y_true", "=", "y_true", ",", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "}", "\n", "\n", "", "validation_results", "=", "{", "}", "\n", "for", "metric_name", ",", "metric_function", "in", "metrics", ".", "items", "(", ")", ":", "\n", "            ", "validation_results", "[", "metric_name", "]", "=", "metric_function", "(", "targets", ",", "scores", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "\"mlperf-metrics-test/\"", "+", "metric_name", ",", "\n", "validation_results", "[", "metric_name", "]", ",", "\n", "log_iter", ",", "\n", ")", "\n", "", "acc_test", "=", "validation_results", "[", "\"accuracy\"", "]", "\n", "", "else", ":", "\n", "        ", "acc_test", "=", "test_accu", "/", "test_samp", "\n", "writer", ".", "add_scalar", "(", "\"Test/Acc\"", ",", "acc_test", ",", "log_iter", ")", "\n", "\n", "", "model_metrics_dict", "=", "{", "\n", "\"nepochs\"", ":", "args", ".", "nepochs", ",", "\n", "\"nbatches\"", ":", "nbatches", ",", "\n", "\"nbatches_test\"", ":", "nbatches_test", ",", "\n", "\"state_dict\"", ":", "dlrm", ".", "state_dict", "(", ")", ",", "\n", "\"test_acc\"", ":", "acc_test", ",", "\n", "}", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "is_best", "=", "validation_results", "[", "\"roc_auc\"", "]", ">", "best_auc_test", "\n", "if", "is_best", ":", "\n", "            ", "best_auc_test", "=", "validation_results", "[", "\"roc_auc\"", "]", "\n", "model_metrics_dict", "[", "\"test_auc\"", "]", "=", "best_auc_test", "\n", "", "print", "(", "\n", "\"recall {:.4f}, precision {:.4f},\"", ".", "format", "(", "\n", "validation_results", "[", "\"recall\"", "]", ",", "\n", "validation_results", "[", "\"precision\"", "]", ",", "\n", ")", "\n", "+", "\" f1 {:.4f}, ap {:.4f},\"", ".", "format", "(", "\n", "validation_results", "[", "\"f1\"", "]", ",", "validation_results", "[", "\"ap\"", "]", "\n", ")", "\n", "+", "\" auc {:.4f}, best auc {:.4f},\"", ".", "format", "(", "\n", "validation_results", "[", "\"roc_auc\"", "]", ",", "best_auc_test", "\n", ")", "\n", "+", "\" accuracy {:3.3f} %, best accuracy {:3.3f} %\"", ".", "format", "(", "\n", "validation_results", "[", "\"accuracy\"", "]", "*", "100", ",", "best_acc_test", "*", "100", "\n", ")", ",", "\n", "flush", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "is_best", "=", "acc_test", ">", "best_acc_test", "\n", "if", "is_best", ":", "\n", "            ", "best_acc_test", "=", "acc_test", "\n", "", "print", "(", "\n", "\" accuracy {:3.3f} %, best {:3.3f} %\"", ".", "format", "(", "\n", "acc_test", "*", "100", ",", "best_acc_test", "*", "100", "\n", ")", ",", "\n", "flush", "=", "True", ",", "\n", ")", "\n", "", "return", "model_metrics_dict", ",", "is_best", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.run": [[893, 1874], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "numpy.random.seed", "numpy.set_printoptions", "torch.set_printoptions", "torch.set_printoptions", "torch.manual_seed", "torch.manual_seed", "numpy.fromstring", "np.array.tolist", "numpy.asarray", "numpy.fromstring", "dlrm_s_pytorch.DLRM_Net", "print", "torch.utils.tensorboard.SummaryWriter", "extend_distributed.barrier", "dlrm_s_pytorch.time_wrap", "mlperf_logger.log_event", "mlperf_logger.log_start", "torch.cuda.is_available", "torch.cuda.is_available", "extend_distributed.init_distributed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "print", "torch.device", "torch.device", "print", "mlperf_logger.barrier", "mlperf_logger.log_end", "mlperf_logger.barrier", "mlperf_logger.log_start", "mlperf_logger.barrier", "dlrm_data_pytorch.make_criteo_data_and_loaders", "len", "numpy.fromstring", "dlrm_data_pytorch.make_random_data_and_loader", "len", "print", "sys.exit", "sys.exit", "tricks.md_embedding_bag.md_solver().tolist", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "enumerate", "min", "print", "torch.quantization.quantize_dynamic.parameters", "torch.quantization.quantize_dynamic.to", "dlrm_s_pytorch.LRPolicyScheduler", "mlperf_logger.mlperf_submission_log", "mlperf_logger.log_event", "mlperf_logger.log_event", "print", "torch.quantization.quantize_dynamic.load_state_dict", "print", "print", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "torch.autograd.profiler.profile", "torch.autograd.profiler.profile", "str().replace", "prof.export_chrome_trace", "sys.exit", "print", "torch.quantization.quantize_dynamic.parameters", "print", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "print", "print", "torch.onnx.export", "torch.onnx.export", "onnx.load", "onnx.checker.check_model", "float", "sys.exit", "sys.exit", "sys.exit", "sys.exit", "sys.exit", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.device", "torch.device", "len", "numpy.array", "numpy.array", "len", "json.dumps", "sys.exit", "str", "sys.exit", "sys.exit", "sys.exit", "dlrm_s_pytorch.unpack_batch", "torch.set_printoptions", "torch.set_printoptions", "print", "print", "print", "print", "print", "print", "torch.quantization.quantize_dynamic.create_emb", "extend_distributed.DDP", "extend_distributed.DDP", "extend_distributed.DDP", "extend_distributed.DDP", "sys.exit", "torch.quantization.quantize_dynamic.parameters", "torch.load", "torch.load", "optimizer.load_state_dict", "print", "print", "torch.quantization.quantize_dynamic", "torch.quantization.quantize_dynamic", "torch.quantization.quantize_dynamic.quantize_embedding", "print", "dlrm_s_pytorch.inference", "open", "prof_f.write", "open", "prof_f.write", "print", "print", "print", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "dynamic_axes.update", "dynamic_axes.update", "range", "list", "vars", "str", "str", "tricks.md_embedding_bag.md_solver", "X.detach().cpu", "torch.IntTensor", "torch.IntTensor", "T.detach().cpu", "param.detach().cpu().numpy", "enumerate", "torch.load", "torch.load", "torch.load", "torch.load", "enumerate", "mlperf_logger.barrier", "mlperf_logger.log_end", "str", "prof.key_averages().table", "prof.key_averages().table", "param.detach().cpu().numpy", "print", "print", "len", "map", "str", "str", "torch.tensor", "torch.tensor", "str", "str", "str", "S_i.detach().cpu", "w.cuda", "torch.quantization.quantize_dynamic.bot_l.parameters", "torch.quantization.quantize_dynamic.top_l.parameters", "torch.device", "torch.device", "mlperf_logger.barrier", "mlperf_logger.log_start", "mlperf_logger.barrier", "mlperf_logger.log_start", "dlrm_s_pytorch.unpack_batch", "dlrm_s_pytorch.dlrm_wrap", "dlrm_s_pytorch.loss_fn_wrap", "loss_fn_wrap.detach().cpu().numpy", "mlperf_logger.barrier", "mlperf_logger.log_end", "mlperf_logger.barrier", "mlperf_logger.log_end", "datetime.datetime.now", "str", "range", "str", "range", "range", "range", "str", "str", "str", "X.detach", "numpy.diff().tolist", "T.detach", "param.detach().cpu", "torch.device", "torch.device", "dlrm_s_pytorch.unpack_batch", "dlrm_s_pytorch.time_wrap", "dlrm_s_pytorch.time_wrap", "print", "torch.autograd.profiler.record_function", "loss_fn_wrap.backward", "dlrm_s_pytorch.time_wrap", "print", "torch.utils.tensorboard.SummaryWriter.add_scalar", "print", "dlrm_s_pytorch.inference", "prof.key_averages", "prof.key_averages", "param.detach().cpu", "len", "len", "str", "len", "str", "len", "str", "str", "str", "enumerate", "S_i.detach", "emb.parameters", "loss_fn_wrap.detach().cpu", "optimizer.zero_grad", "optimizer.step", "LRPolicyScheduler.step", "mlperf_logger.barrier", "mlperf_logger.log_start", "optimizer.state_dict", "print", "torch.save", "torch.save", "mlperf_logger.barrier", "mlperf_logger.log_end", "print", "print", "str", "numpy.diff", "param.detach", "X.size", "extend_distributed.get_my_slice", "extend_distributed.get_my_slice", "time.strftime", "mlperf_logger.barrier", "mlperf_logger.log_end", "param.detach", "X.size", "loss_fn_wrap.detach", "len", "S_o.detach().cpu().tolist", "list", "str", "str", "S_o.detach().cpu", "S_o.detach"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.parse_args", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.time_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.init_distributed", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.make_criteo_data_and_loaders", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.make_random_data_and_loader", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.mlperf_submission_log", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.unpack_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.quantize_embedding", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.inference", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.md_solver", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.unpack_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.dlrm_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.loss_fn_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.unpack_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.time_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.time_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.AllGather.backward", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.time_wrap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.inference", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters", "home.repos.pwc.inspect_result.facebookresearch_dlrm.optim.rwsadagrad.RWSAdagrad.step", "home.repos.pwc.inspect_result.facebookresearch_dlrm.optim.rwsadagrad.RWSAdagrad.step", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_my_slice", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.extend_distributed.get_my_slice", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end"], ["", "def", "run", "(", ")", ":", "\n", "### parse arguments ###", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Train Deep Learning Recommendation Model (DLRM)\"", "\n", ")", "\n", "# model related parameters", "\n", "parser", ".", "add_argument", "(", "\"--arch-sparse-feature-size\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--arch-embedding-size\"", ",", "type", "=", "dash_separated_ints", ",", "default", "=", "\"4-3-2\"", "\n", ")", "\n", "# j will be replaced with the table number", "\n", "parser", ".", "add_argument", "(", "\"--arch-mlp-bot\"", ",", "type", "=", "dash_separated_ints", ",", "default", "=", "\"4-3-2\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--arch-mlp-top\"", ",", "type", "=", "dash_separated_ints", ",", "default", "=", "\"4-2-1\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--arch-interaction-op\"", ",", "type", "=", "str", ",", "choices", "=", "[", "\"dot\"", ",", "\"cat\"", "]", ",", "default", "=", "\"dot\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--arch-interaction-itself\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--weighted-pooling\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "# embedding table options", "\n", "parser", ".", "add_argument", "(", "\"--md-flag\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--md-threshold\"", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "\"--md-temperature\"", ",", "type", "=", "float", ",", "default", "=", "0.3", ")", "\n", "parser", ".", "add_argument", "(", "\"--md-round-dims\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--qr-flag\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--qr-threshold\"", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "\"--qr-operation\"", ",", "type", "=", "str", ",", "default", "=", "\"mult\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--qr-collisions\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "# activations and loss", "\n", "parser", ".", "add_argument", "(", "\"--activation-function\"", ",", "type", "=", "str", ",", "default", "=", "\"relu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--loss-function\"", ",", "type", "=", "str", ",", "default", "=", "\"mse\"", ")", "# or bce or wbce", "\n", "parser", ".", "add_argument", "(", "\n", "\"--loss-weights\"", ",", "type", "=", "dash_separated_floats", ",", "default", "=", "\"1.0-1.0\"", "\n", ")", "# for wbce", "\n", "parser", ".", "add_argument", "(", "\"--loss-threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "# 1.0e-7", "\n", "parser", ".", "add_argument", "(", "\"--round-targets\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "# data", "\n", "parser", ".", "add_argument", "(", "\"--data-size\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-batches\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data-generation\"", ",", "type", "=", "str", ",", "default", "=", "\"random\"", "\n", ")", "# synthetic or dataset", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rand-data-dist\"", ",", "type", "=", "str", ",", "default", "=", "\"uniform\"", "\n", ")", "# uniform or gaussian", "\n", "parser", ".", "add_argument", "(", "\"--rand-data-min\"", ",", "type", "=", "float", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--rand-data-max\"", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--rand-data-mu\"", ",", "type", "=", "float", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--rand-data-sigma\"", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-trace-file\"", ",", "type", "=", "str", ",", "default", "=", "\"./input/dist_emb_j.log\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-set\"", ",", "type", "=", "str", ",", "default", "=", "\"kaggle\"", ")", "# or terabyte", "\n", "parser", ".", "add_argument", "(", "\"--raw-data-file\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--processed-data-file\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-randomize\"", ",", "type", "=", "str", ",", "default", "=", "\"total\"", ")", "# or day or none", "\n", "parser", ".", "add_argument", "(", "\"--data-trace-enable-padding\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-ind-range\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-sub-sample-rate\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "# in [0, 1]", "\n", "parser", ".", "add_argument", "(", "\"--num-indices-per-lookup\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-indices-per-lookup-fixed\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-workers\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--memory-map\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# training", "\n", "parser", ".", "add_argument", "(", "\"--mini-batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--nepochs\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning-rate\"", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-precision\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "\"--numpy-rand-seed\"", ",", "type", "=", "int", ",", "default", "=", "123", ")", "\n", "parser", ".", "add_argument", "(", "\"--sync-dense-params\"", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--optimizer\"", ",", "type", "=", "str", ",", "default", "=", "\"sgd\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset-multiprocessing\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"The Kaggle dataset can be multiprocessed in an environment \\\n                        with more than 7 CPU cores and more than 20 GB of memory. \\n \\\n                        The Terabyte dataset can be multiprocessed in an environment \\\n                        with more than 24 CPU cores and at least 1 TB of memory.\"", ",", "\n", ")", "\n", "# inference", "\n", "parser", ".", "add_argument", "(", "\"--inference-only\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# quantize", "\n", "parser", ".", "add_argument", "(", "\"--quantize-mlp-with-bit\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "parser", ".", "add_argument", "(", "\"--quantize-emb-with-bit\"", ",", "type", "=", "int", ",", "default", "=", "32", ")", "\n", "# onnx", "\n", "parser", ".", "add_argument", "(", "\"--save-onnx\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# gpu", "\n", "parser", ".", "add_argument", "(", "\"--use-gpu\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# distributed", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--dist-backend\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "# debugging and profiling", "\n", "parser", ".", "add_argument", "(", "\"--print-freq\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--test-freq\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--test-mini-batch-size\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--test-num-workers\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-time\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-wall-time\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug-mode\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--enable-profiling\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--plot-compute-graph\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--tensor-board-filename\"", ",", "type", "=", "str", ",", "default", "=", "\"run_kaggle_pt\"", ")", "\n", "# store/load model", "\n", "parser", ".", "add_argument", "(", "\"--save-model\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load-model\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "# mlperf logging (disables other output and stops early)", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-logging\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# stop at target accuracy Kaggle 0.789, Terabyte (sub-sampled=0.875) 0.8107", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-acc-threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "# stop at target AUC Terabyte (no subsampling) 0.8025", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-auc-threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-bin-loader\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-bin-shuffle\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# mlperf gradient accumulation iterations", "\n", "parser", ".", "add_argument", "(", "\"--mlperf-grad-accum-iter\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "# LR policy", "\n", "parser", ".", "add_argument", "(", "\"--lr-num-warmup-steps\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-decay-start-step\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-num-decay-steps\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "global", "args", "\n", "global", "nbatches", "\n", "global", "nbatches_test", "\n", "global", "writer", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "dataset_multiprocessing", ":", "\n", "        ", "assert", "float", "(", "sys", ".", "version", "[", ":", "3", "]", ")", ">", "3.7", ",", "\"The dataset_multiprocessing \"", "+", "\"flag is susceptible to a bug in Python 3.7 and under. \"", "+", "\"https://github.com/facebookresearch/dlrm/issues/172\"", "\n", "\n", "", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "mlperf_logger", ".", "log_event", "(", "key", "=", "mlperf_logger", ".", "constants", ".", "CACHE_CLEAR", ",", "value", "=", "True", ")", "\n", "mlperf_logger", ".", "log_start", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "INIT_START", ",", "log_all_ranks", "=", "True", "\n", ")", "\n", "\n", "", "if", "args", ".", "weighted_pooling", "is", "not", "None", ":", "\n", "        ", "if", "args", ".", "qr_flag", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: quotient remainder with weighted pooling is not supported\"", ")", "\n", "", "if", "args", ".", "md_flag", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: mixed dimensions with weighted pooling is not supported\"", ")", "\n", "", "", "if", "args", ".", "quantize_emb_with_bit", "in", "[", "4", ",", "8", "]", ":", "\n", "        ", "if", "args", ".", "qr_flag", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: 4 and 8-bit quantization with quotient remainder is not supported\"", "\n", ")", "\n", "", "if", "args", ".", "md_flag", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: 4 and 8-bit quantization with mixed dimensions is not supported\"", "\n", ")", "\n", "", "if", "args", ".", "use_gpu", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: 4 and 8-bit quantization on GPU is not supported\"", "\n", ")", "\n", "\n", "### some basic setup ###", "\n", "", "", "np", ".", "random", ".", "seed", "(", "args", ".", "numpy_rand_seed", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "args", ".", "print_precision", ")", "\n", "torch", ".", "set_printoptions", "(", "precision", "=", "args", ".", "print_precision", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "numpy_rand_seed", ")", "\n", "\n", "if", "args", ".", "test_mini_batch_size", "<", "0", ":", "\n", "# if the parameter is not set, use the training batch size", "\n", "        ", "args", ".", "test_mini_batch_size", "=", "args", ".", "mini_batch_size", "\n", "", "if", "args", ".", "test_num_workers", "<", "0", ":", "\n", "# if the parameter is not set, use the same parameter for training", "\n", "        ", "args", ".", "test_num_workers", "=", "args", ".", "num_workers", "\n", "\n", "", "use_gpu", "=", "args", ".", "use_gpu", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "if", "not", "args", ".", "debug_mode", ":", "\n", "        ", "ext_dist", ".", "init_distributed", "(", "local_rank", "=", "args", ".", "local_rank", ",", "use_gpu", "=", "use_gpu", ",", "backend", "=", "args", ".", "dist_backend", ")", "\n", "\n", "", "if", "use_gpu", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "numpy_rand_seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "            ", "ngpus", "=", "1", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "ext_dist", ".", "my_local_rank", ")", "\n", "", "else", ":", "\n", "            ", "ngpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "0", ")", "\n", "", "print", "(", "\"Using {} GPU(s)...\"", ".", "format", "(", "ngpus", ")", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "print", "(", "\"Using CPU...\"", ")", "\n", "\n", "### prepare training data ###", "\n", "", "ln_bot", "=", "np", ".", "fromstring", "(", "args", ".", "arch_mlp_bot", ",", "dtype", "=", "int", ",", "sep", "=", "\"-\"", ")", "\n", "# input data", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "key", "=", "mlperf_logger", ".", "constants", ".", "INIT_STOP", ")", "\n", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_start", "(", "key", "=", "mlperf_logger", ".", "constants", ".", "RUN_START", ")", "\n", "mlperf_logger", ".", "barrier", "(", ")", "\n", "\n", "", "if", "args", ".", "data_generation", "==", "\"dataset\"", ":", "\n", "        ", "train_data", ",", "train_ld", ",", "test_data", ",", "test_ld", "=", "dp", ".", "make_criteo_data_and_loaders", "(", "args", ")", "\n", "table_feature_map", "=", "{", "idx", ":", "idx", "for", "idx", "in", "range", "(", "len", "(", "train_data", ".", "counts", ")", ")", "}", "\n", "nbatches", "=", "args", ".", "num_batches", "if", "args", ".", "num_batches", ">", "0", "else", "len", "(", "train_ld", ")", "\n", "nbatches_test", "=", "len", "(", "test_ld", ")", "\n", "\n", "ln_emb", "=", "train_data", ".", "counts", "\n", "# enforce maximum limit on number of vectors per embedding", "\n", "if", "args", ".", "max_ind_range", ">", "0", ":", "\n", "            ", "ln_emb", "=", "np", ".", "array", "(", "\n", "list", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "x", "if", "x", "<", "args", ".", "max_ind_range", "else", "args", ".", "max_ind_range", ",", "\n", "ln_emb", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "ln_emb", "=", "np", ".", "array", "(", "ln_emb", ")", "\n", "", "m_den", "=", "train_data", ".", "m_den", "\n", "ln_bot", "[", "0", "]", "=", "m_den", "\n", "", "else", ":", "\n", "# input and target at random", "\n", "        ", "ln_emb", "=", "np", ".", "fromstring", "(", "args", ".", "arch_embedding_size", ",", "dtype", "=", "int", ",", "sep", "=", "\"-\"", ")", "\n", "m_den", "=", "ln_bot", "[", "0", "]", "\n", "train_data", ",", "train_ld", ",", "test_data", ",", "test_ld", "=", "dp", ".", "make_random_data_and_loader", "(", "args", ",", "ln_emb", ",", "m_den", ")", "\n", "nbatches", "=", "args", ".", "num_batches", "if", "args", ".", "num_batches", ">", "0", "else", "len", "(", "train_ld", ")", "\n", "nbatches_test", "=", "len", "(", "test_ld", ")", "\n", "\n", "", "args", ".", "ln_emb", "=", "ln_emb", ".", "tolist", "(", ")", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "print", "(", "\"command line args: \"", ",", "json", ".", "dumps", "(", "vars", "(", "args", ")", ")", ")", "\n", "\n", "### parse command line arguments ###", "\n", "", "m_spa", "=", "args", ".", "arch_sparse_feature_size", "\n", "ln_emb", "=", "np", ".", "asarray", "(", "ln_emb", ")", "\n", "num_fea", "=", "ln_emb", ".", "size", "+", "1", "# num sparse + num dense features", "\n", "\n", "m_den_out", "=", "ln_bot", "[", "ln_bot", ".", "size", "-", "1", "]", "\n", "if", "args", ".", "arch_interaction_op", "==", "\"dot\"", ":", "\n", "# approach 1: all", "\n", "# num_int = num_fea * num_fea + m_den_out", "\n", "# approach 2: unique", "\n", "        ", "if", "args", ".", "arch_interaction_itself", ":", "\n", "            ", "num_int", "=", "(", "num_fea", "*", "(", "num_fea", "+", "1", ")", ")", "//", "2", "+", "m_den_out", "\n", "", "else", ":", "\n", "            ", "num_int", "=", "(", "num_fea", "*", "(", "num_fea", "-", "1", ")", ")", "//", "2", "+", "m_den_out", "\n", "", "", "elif", "args", ".", "arch_interaction_op", "==", "\"cat\"", ":", "\n", "        ", "num_int", "=", "num_fea", "*", "m_den_out", "\n", "", "else", ":", "\n", "        ", "sys", ".", "exit", "(", "\n", "\"ERROR: --arch-interaction-op=\"", "\n", "+", "args", ".", "arch_interaction_op", "\n", "+", "\" is not supported\"", "\n", ")", "\n", "", "arch_mlp_top_adjusted", "=", "str", "(", "num_int", ")", "+", "\"-\"", "+", "args", ".", "arch_mlp_top", "\n", "ln_top", "=", "np", ".", "fromstring", "(", "arch_mlp_top_adjusted", ",", "dtype", "=", "int", ",", "sep", "=", "\"-\"", ")", "\n", "\n", "# sanity check: feature sizes and mlp dimensions must match", "\n", "if", "m_den", "!=", "ln_bot", "[", "0", "]", ":", "\n", "        ", "sys", ".", "exit", "(", "\n", "\"ERROR: arch-dense-feature-size \"", "\n", "+", "str", "(", "m_den", ")", "\n", "+", "\" does not match first dim of bottom mlp \"", "\n", "+", "str", "(", "ln_bot", "[", "0", "]", ")", "\n", ")", "\n", "", "if", "args", ".", "qr_flag", ":", "\n", "        ", "if", "args", ".", "qr_operation", "==", "\"concat\"", "and", "2", "*", "m_spa", "!=", "m_den_out", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: 2 arch-sparse-feature-size \"", "\n", "+", "str", "(", "2", "*", "m_spa", ")", "\n", "+", "\" does not match last dim of bottom mlp \"", "\n", "+", "str", "(", "m_den_out", ")", "\n", "+", "\" (note that the last dim of bottom mlp must be 2x the embedding dim)\"", "\n", ")", "\n", "", "if", "args", ".", "qr_operation", "!=", "\"concat\"", "and", "m_spa", "!=", "m_den_out", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: arch-sparse-feature-size \"", "\n", "+", "str", "(", "m_spa", ")", "\n", "+", "\" does not match last dim of bottom mlp \"", "\n", "+", "str", "(", "m_den_out", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "m_spa", "!=", "m_den_out", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: arch-sparse-feature-size \"", "\n", "+", "str", "(", "m_spa", ")", "\n", "+", "\" does not match last dim of bottom mlp \"", "\n", "+", "str", "(", "m_den_out", ")", "\n", ")", "\n", "", "", "if", "num_int", "!=", "ln_top", "[", "0", "]", ":", "\n", "        ", "sys", ".", "exit", "(", "\n", "\"ERROR: # of feature interactions \"", "\n", "+", "str", "(", "num_int", ")", "\n", "+", "\" does not match first dimension of top mlp \"", "\n", "+", "str", "(", "ln_top", "[", "0", "]", ")", "\n", ")", "\n", "\n", "# assign mixed dimensions if applicable", "\n", "", "if", "args", ".", "md_flag", ":", "\n", "        ", "m_spa", "=", "md_solver", "(", "\n", "torch", ".", "tensor", "(", "ln_emb", ")", ",", "\n", "args", ".", "md_temperature", ",", "# alpha", "\n", "d0", "=", "m_spa", ",", "\n", "round_dim", "=", "args", ".", "md_round_dims", ",", "\n", ")", ".", "tolist", "(", ")", "\n", "\n", "# test prints (model arch)", "\n", "", "if", "args", ".", "debug_mode", ":", "\n", "        ", "print", "(", "\"model arch:\"", ")", "\n", "print", "(", "\n", "\"mlp top arch \"", "\n", "+", "str", "(", "ln_top", ".", "size", "-", "1", ")", "\n", "+", "\" layers, with input to output dimensions:\"", "\n", ")", "\n", "print", "(", "ln_top", ")", "\n", "print", "(", "\"# of interactions\"", ")", "\n", "print", "(", "num_int", ")", "\n", "print", "(", "\n", "\"mlp bot arch \"", "\n", "+", "str", "(", "ln_bot", ".", "size", "-", "1", ")", "\n", "+", "\" layers, with input to output dimensions:\"", "\n", ")", "\n", "print", "(", "ln_bot", ")", "\n", "print", "(", "\"# of features (sparse and dense)\"", ")", "\n", "print", "(", "num_fea", ")", "\n", "print", "(", "\"dense feature size\"", ")", "\n", "print", "(", "m_den", ")", "\n", "print", "(", "\"sparse feature size\"", ")", "\n", "print", "(", "m_spa", ")", "\n", "print", "(", "\n", "\"# of embeddings (= # of sparse features) \"", "\n", "+", "str", "(", "ln_emb", ".", "size", ")", "\n", "+", "\", with dimensions \"", "\n", "+", "str", "(", "m_spa", ")", "\n", "+", "\"x:\"", "\n", ")", "\n", "print", "(", "ln_emb", ")", "\n", "\n", "print", "(", "\"data (inputs and targets):\"", ")", "\n", "for", "j", ",", "inputBatch", "in", "enumerate", "(", "train_ld", ")", ":", "\n", "            ", "X", ",", "lS_o", ",", "lS_i", ",", "T", ",", "W", ",", "CBPP", "=", "unpack_batch", "(", "inputBatch", ")", "\n", "\n", "torch", ".", "set_printoptions", "(", "precision", "=", "4", ")", "\n", "# early exit if nbatches was set by the user and has been exceeded", "\n", "if", "nbatches", ">", "0", "and", "j", ">=", "nbatches", ":", "\n", "                ", "break", "\n", "", "print", "(", "\"mini-batch: %d\"", "%", "j", ")", "\n", "print", "(", "X", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "# transform offsets to lengths when printing", "\n", "print", "(", "\n", "torch", ".", "IntTensor", "(", "\n", "[", "\n", "np", ".", "diff", "(", "\n", "S_o", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "+", "list", "(", "lS_i", "[", "i", "]", ".", "shape", ")", "\n", ")", ".", "tolist", "(", ")", "\n", "for", "i", ",", "S_o", "in", "enumerate", "(", "lS_o", ")", "\n", "]", "\n", ")", "\n", ")", "\n", "print", "(", "[", "S_i", ".", "detach", "(", ")", ".", "cpu", "(", ")", "for", "S_i", "in", "lS_i", "]", ")", "\n", "print", "(", "T", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", "\n", "\n", "", "", "global", "ndevices", "\n", "ndevices", "=", "min", "(", "ngpus", ",", "args", ".", "mini_batch_size", ",", "num_fea", "-", "1", ")", "if", "use_gpu", "else", "-", "1", "\n", "\n", "### construct the neural network specified above ###", "\n", "# WARNING: to obtain exactly the same initialization for", "\n", "# the weights we need to start from the same random seed.", "\n", "# np.random.seed(args.numpy_rand_seed)", "\n", "global", "dlrm", "\n", "dlrm", "=", "DLRM_Net", "(", "\n", "m_spa", ",", "\n", "ln_emb", ",", "\n", "ln_bot", ",", "\n", "ln_top", ",", "\n", "arch_interaction_op", "=", "args", ".", "arch_interaction_op", ",", "\n", "arch_interaction_itself", "=", "args", ".", "arch_interaction_itself", ",", "\n", "sigmoid_bot", "=", "-", "1", ",", "\n", "sigmoid_top", "=", "ln_top", ".", "size", "-", "2", ",", "\n", "sync_dense_params", "=", "args", ".", "sync_dense_params", ",", "\n", "loss_threshold", "=", "args", ".", "loss_threshold", ",", "\n", "ndevices", "=", "ndevices", ",", "\n", "qr_flag", "=", "args", ".", "qr_flag", ",", "\n", "qr_operation", "=", "args", ".", "qr_operation", ",", "\n", "qr_collisions", "=", "args", ".", "qr_collisions", ",", "\n", "qr_threshold", "=", "args", ".", "qr_threshold", ",", "\n", "md_flag", "=", "args", ".", "md_flag", ",", "\n", "md_threshold", "=", "args", ".", "md_threshold", ",", "\n", "weighted_pooling", "=", "args", ".", "weighted_pooling", ",", "\n", "loss_function", "=", "args", ".", "loss_function", "\n", ")", "\n", "\n", "# test prints", "\n", "if", "args", ".", "debug_mode", ":", "\n", "        ", "print", "(", "\"initial parameters (weights and bias):\"", ")", "\n", "for", "param", "in", "dlrm", ".", "parameters", "(", ")", ":", "\n", "            ", "print", "(", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# print(dlrm)", "\n", "\n", "", "", "if", "use_gpu", ":", "\n", "# Custom Model-Data Parallel", "\n", "# the mlps are replicated and use data parallelism, while", "\n", "# the embeddings are distributed and use model parallelism", "\n", "        ", "dlrm", "=", "dlrm", ".", "to", "(", "device", ")", "# .cuda()", "\n", "if", "dlrm", ".", "ndevices", ">", "1", ":", "\n", "            ", "dlrm", ".", "emb_l", ",", "dlrm", ".", "v_W_l", "=", "dlrm", ".", "create_emb", "(", "\n", "m_spa", ",", "ln_emb", ",", "args", ".", "weighted_pooling", "\n", ")", "\n", "", "else", ":", "\n", "            ", "if", "dlrm", ".", "weighted_pooling", "==", "\"fixed\"", ":", "\n", "                ", "for", "k", ",", "w", "in", "enumerate", "(", "dlrm", ".", "v_W_l", ")", ":", "\n", "                    ", "dlrm", ".", "v_W_l", "[", "k", "]", "=", "w", ".", "cuda", "(", ")", "\n", "\n", "# distribute data parallel mlps", "\n", "", "", "", "", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "        ", "if", "use_gpu", ":", "\n", "            ", "device_ids", "=", "[", "ext_dist", ".", "my_local_rank", "]", "\n", "dlrm", ".", "bot_l", "=", "ext_dist", ".", "DDP", "(", "dlrm", ".", "bot_l", ",", "device_ids", "=", "device_ids", ")", "\n", "dlrm", ".", "top_l", "=", "ext_dist", ".", "DDP", "(", "dlrm", ".", "top_l", ",", "device_ids", "=", "device_ids", ")", "\n", "", "else", ":", "\n", "            ", "dlrm", ".", "bot_l", "=", "ext_dist", ".", "DDP", "(", "dlrm", ".", "bot_l", ")", "\n", "dlrm", ".", "top_l", "=", "ext_dist", ".", "DDP", "(", "dlrm", ".", "top_l", ")", "\n", "\n", "", "", "if", "not", "args", ".", "inference_only", ":", "\n", "        ", "if", "use_gpu", "and", "args", ".", "optimizer", "in", "[", "\"rwsadagrad\"", ",", "\"adagrad\"", "]", ":", "\n", "            ", "sys", ".", "exit", "(", "\"GPU version of Adagrad is not supported by PyTorch.\"", ")", "\n", "# specify the optimizer algorithm", "\n", "", "opts", "=", "{", "\n", "\"sgd\"", ":", "torch", ".", "optim", ".", "SGD", ",", "\n", "\"rwsadagrad\"", ":", "RowWiseSparseAdagrad", ".", "RWSAdagrad", ",", "\n", "\"adagrad\"", ":", "torch", ".", "optim", ".", "Adagrad", ",", "\n", "}", "\n", "\n", "parameters", "=", "(", "\n", "dlrm", ".", "parameters", "(", ")", "\n", "if", "ext_dist", ".", "my_size", "==", "1", "\n", "else", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "emb", "in", "dlrm", ".", "emb_l", "for", "p", "in", "emb", ".", "parameters", "(", ")", "]", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "}", ",", "\n", "# TODO check this lr setup", "\n", "# bottom mlp has no data parallelism", "\n", "# need to check how do we deal with top mlp", "\n", "{", "\n", "\"params\"", ":", "dlrm", ".", "bot_l", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "dlrm", ".", "top_l", ".", "parameters", "(", ")", ",", "\n", "\"lr\"", ":", "args", ".", "learning_rate", ",", "\n", "}", ",", "\n", "]", "\n", ")", "\n", "optimizer", "=", "opts", "[", "args", ".", "optimizer", "]", "(", "parameters", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "lr_scheduler", "=", "LRPolicyScheduler", "(", "\n", "optimizer", ",", "\n", "args", ".", "lr_num_warmup_steps", ",", "\n", "args", ".", "lr_decay_start_step", ",", "\n", "args", ".", "lr_num_decay_steps", ",", "\n", ")", "\n", "\n", "### main loop ###", "\n", "\n", "# training or inference", "\n", "", "best_acc_test", "=", "0", "\n", "best_auc_test", "=", "0", "\n", "skip_upto_epoch", "=", "0", "\n", "skip_upto_batch", "=", "0", "\n", "total_time", "=", "0", "\n", "total_loss", "=", "0", "\n", "total_iter", "=", "0", "\n", "total_samp", "=", "0", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "        ", "mlperf_logger", ".", "mlperf_submission_log", "(", "\"dlrm\"", ")", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "SEED", ",", "value", "=", "args", ".", "numpy_rand_seed", "\n", ")", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "GLOBAL_BATCH_SIZE", ",", "value", "=", "args", ".", "mini_batch_size", "\n", ")", "\n", "\n", "# Load model is specified", "\n", "", "if", "not", "(", "args", ".", "load_model", "==", "\"\"", ")", ":", "\n", "        ", "print", "(", "\"Loading saved model {}\"", ".", "format", "(", "args", ".", "load_model", ")", ")", "\n", "if", "use_gpu", ":", "\n", "            ", "if", "dlrm", ".", "ndevices", ">", "1", ":", "\n", "# NOTE: when targeting inference on multiple GPUs,", "\n", "# load the model as is on CPU or GPU, with the move", "\n", "# to multiple GPUs to be done in parallel_forward", "\n", "                ", "ld_model", "=", "torch", ".", "load", "(", "args", ".", "load_model", ")", "\n", "", "else", ":", "\n", "# NOTE: when targeting inference on single GPU,", "\n", "# note that the call to .to(device) has already happened", "\n", "                ", "ld_model", "=", "torch", ".", "load", "(", "\n", "args", ".", "load_model", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "# map_location=lambda storage, loc: storage.cuda(0)", "\n", ")", "\n", "", "", "else", ":", "\n", "# when targeting inference on CPU", "\n", "            ", "ld_model", "=", "torch", ".", "load", "(", "args", ".", "load_model", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "", "dlrm", ".", "load_state_dict", "(", "ld_model", "[", "\"state_dict\"", "]", ")", "\n", "ld_j", "=", "ld_model", "[", "\"iter\"", "]", "\n", "ld_k", "=", "ld_model", "[", "\"epoch\"", "]", "\n", "ld_nepochs", "=", "ld_model", "[", "\"nepochs\"", "]", "\n", "ld_nbatches", "=", "ld_model", "[", "\"nbatches\"", "]", "\n", "ld_nbatches_test", "=", "ld_model", "[", "\"nbatches_test\"", "]", "\n", "ld_train_loss", "=", "ld_model", "[", "\"train_loss\"", "]", "\n", "ld_total_loss", "=", "ld_model", "[", "\"total_loss\"", "]", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "            ", "ld_gAUC_test", "=", "ld_model", "[", "\"test_auc\"", "]", "\n", "", "ld_acc_test", "=", "ld_model", "[", "\"test_acc\"", "]", "\n", "if", "not", "args", ".", "inference_only", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "ld_model", "[", "\"opt_state_dict\"", "]", ")", "\n", "best_acc_test", "=", "ld_acc_test", "\n", "total_loss", "=", "ld_total_loss", "\n", "skip_upto_epoch", "=", "ld_k", "# epochs", "\n", "skip_upto_batch", "=", "ld_j", "# batches", "\n", "", "else", ":", "\n", "            ", "args", ".", "print_freq", "=", "ld_nbatches", "\n", "args", ".", "test_freq", "=", "0", "\n", "\n", "", "print", "(", "\n", "\"Saved at: epoch = {:d}/{:d}, batch = {:d}/{:d}, ntbatch = {:d}\"", ".", "format", "(", "\n", "ld_k", ",", "ld_nepochs", ",", "ld_j", ",", "ld_nbatches", ",", "ld_nbatches_test", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "\"Training state: loss = {:.6f}\"", ".", "format", "(", "\n", "ld_train_loss", ",", "\n", ")", "\n", ")", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "            ", "print", "(", "\n", "\"Testing state: accuracy = {:3.3f} %, auc = {:.3f}\"", ".", "format", "(", "\n", "ld_acc_test", "*", "100", ",", "ld_gAUC_test", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Testing state: accuracy = {:3.3f} %\"", ".", "format", "(", "ld_acc_test", "*", "100", ")", ")", "\n", "\n", "", "", "if", "args", ".", "inference_only", ":", "\n", "# Currently only dynamic quantization with INT8 and FP16 weights are", "\n", "# supported for MLPs and INT4 and INT8 weights for EmbeddingBag", "\n", "# post-training quantization during the inference.", "\n", "# By default we don't do the quantization: quantize_{mlp,emb}_with_bit == 32 (FP32)", "\n", "        ", "assert", "args", ".", "quantize_mlp_with_bit", "in", "[", "\n", "8", ",", "\n", "16", ",", "\n", "32", ",", "\n", "]", ",", "\"only support 8/16/32-bit but got {}\"", ".", "format", "(", "args", ".", "quantize_mlp_with_bit", ")", "\n", "assert", "args", ".", "quantize_emb_with_bit", "in", "[", "\n", "4", ",", "\n", "8", ",", "\n", "32", ",", "\n", "]", ",", "\"only support 4/8/32-bit but got {}\"", ".", "format", "(", "args", ".", "quantize_emb_with_bit", ")", "\n", "if", "args", ".", "quantize_mlp_with_bit", "!=", "32", ":", "\n", "            ", "if", "args", ".", "quantize_mlp_with_bit", "in", "[", "8", "]", ":", "\n", "                ", "quantize_dtype", "=", "torch", ".", "qint8", "\n", "", "else", ":", "\n", "                ", "quantize_dtype", "=", "torch", ".", "float16", "\n", "", "dlrm", "=", "torch", ".", "quantization", ".", "quantize_dynamic", "(", "\n", "dlrm", ",", "{", "torch", ".", "nn", ".", "Linear", "}", ",", "quantize_dtype", "\n", ")", "\n", "", "if", "args", ".", "quantize_emb_with_bit", "!=", "32", ":", "\n", "            ", "dlrm", ".", "quantize_embedding", "(", "args", ".", "quantize_emb_with_bit", ")", "\n", "# print(dlrm)", "\n", "\n", "", "", "print", "(", "\"time/loss/accuracy (if enabled):\"", ")", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "# LR is logged twice for now because of a compliance checker bug", "\n", "        ", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "OPT_BASE_LR", ",", "value", "=", "args", ".", "learning_rate", "\n", ")", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "OPT_LR_WARMUP_STEPS", ",", "\n", "value", "=", "args", ".", "lr_num_warmup_steps", ",", "\n", ")", "\n", "\n", "# use logging keys from the official HP table and not from the logging library", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "\"sgd_opt_base_learning_rate\"", ",", "value", "=", "args", ".", "learning_rate", "\n", ")", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "\"lr_decay_start_steps\"", ",", "value", "=", "args", ".", "lr_decay_start_step", "\n", ")", "\n", "mlperf_logger", ".", "log_event", "(", "\n", "key", "=", "\"sgd_opt_learning_rate_decay_steps\"", ",", "value", "=", "args", ".", "lr_num_decay_steps", "\n", ")", "\n", "mlperf_logger", ".", "log_event", "(", "key", "=", "\"sgd_opt_learning_rate_decay_poly_power\"", ",", "value", "=", "2", ")", "\n", "\n", "", "tb_file", "=", "\"./\"", "+", "args", ".", "tensor_board_filename", "\n", "writer", "=", "SummaryWriter", "(", "tb_file", ")", "\n", "\n", "ext_dist", ".", "barrier", "(", ")", "\n", "with", "torch", ".", "autograd", ".", "profiler", ".", "profile", "(", "\n", "args", ".", "enable_profiling", ",", "use_cuda", "=", "use_gpu", ",", "record_shapes", "=", "True", "\n", ")", "as", "prof", ":", "\n", "        ", "if", "not", "args", ".", "inference_only", ":", "\n", "            ", "k", "=", "0", "\n", "total_time_begin", "=", "0", "\n", "while", "k", "<", "args", ".", "nepochs", ":", "\n", "                ", "if", "args", ".", "mlperf_logging", ":", "\n", "                    ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_start", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "BLOCK_START", ",", "\n", "metadata", "=", "{", "\n", "mlperf_logger", ".", "constants", ".", "FIRST_EPOCH_NUM", ":", "(", "k", "+", "1", ")", ",", "\n", "mlperf_logger", ".", "constants", ".", "EPOCH_COUNT", ":", "1", ",", "\n", "}", ",", "\n", ")", "\n", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_start", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "EPOCH_START", ",", "\n", "metadata", "=", "{", "mlperf_logger", ".", "constants", ".", "EPOCH_NUM", ":", "(", "k", "+", "1", ")", "}", ",", "\n", ")", "\n", "\n", "", "if", "k", "<", "skip_upto_epoch", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "args", ".", "mlperf_logging", ":", "\n", "                    ", "previous_iteration_time", "=", "None", "\n", "\n", "", "for", "j", ",", "inputBatch", "in", "enumerate", "(", "train_ld", ")", ":", "\n", "                    ", "if", "j", "==", "0", "and", "args", ".", "save_onnx", ":", "\n", "                        ", "X_onnx", ",", "lS_o_onnx", ",", "lS_i_onnx", ",", "_", ",", "_", ",", "_", "=", "unpack_batch", "(", "inputBatch", ")", "\n", "\n", "", "if", "j", "<", "skip_upto_batch", ":", "\n", "                        ", "continue", "\n", "\n", "", "X", ",", "lS_o", ",", "lS_i", ",", "T", ",", "W", ",", "CBPP", "=", "unpack_batch", "(", "inputBatch", ")", "\n", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "                        ", "current_time", "=", "time_wrap", "(", "use_gpu", ")", "\n", "if", "previous_iteration_time", ":", "\n", "                            ", "iteration_time", "=", "current_time", "-", "previous_iteration_time", "\n", "", "else", ":", "\n", "                            ", "iteration_time", "=", "0", "\n", "", "previous_iteration_time", "=", "current_time", "\n", "", "else", ":", "\n", "                        ", "t1", "=", "time_wrap", "(", "use_gpu", ")", "\n", "\n", "# early exit if nbatches was set by the user and has been exceeded", "\n", "", "if", "nbatches", ">", "0", "and", "j", ">=", "nbatches", ":", "\n", "                        ", "break", "\n", "\n", "# Skip the batch if batch size not multiple of total ranks", "\n", "", "if", "ext_dist", ".", "my_size", ">", "1", "and", "X", ".", "size", "(", "0", ")", "%", "ext_dist", ".", "my_size", "!=", "0", ":", "\n", "                        ", "print", "(", "\n", "\"Warning: Skiping the batch %d with size %d\"", "\n", "%", "(", "j", ",", "X", ".", "size", "(", "0", ")", ")", "\n", ")", "\n", "continue", "\n", "\n", "", "mbs", "=", "T", ".", "shape", "[", "0", "]", "# = args.mini_batch_size except maybe for last", "\n", "\n", "# forward pass", "\n", "Z", "=", "dlrm_wrap", "(", "\n", "X", ",", "\n", "lS_o", ",", "\n", "lS_i", ",", "\n", "use_gpu", ",", "\n", "device", ",", "\n", "ndevices", "=", "ndevices", ",", "\n", ")", "\n", "\n", "if", "ext_dist", ".", "my_size", ">", "1", ":", "\n", "                        ", "T", "=", "T", "[", "ext_dist", ".", "get_my_slice", "(", "mbs", ")", "]", "\n", "W", "=", "W", "[", "ext_dist", ".", "get_my_slice", "(", "mbs", ")", "]", "\n", "\n", "# loss", "\n", "", "E", "=", "loss_fn_wrap", "(", "Z", ",", "T", ",", "use_gpu", ",", "device", ")", "\n", "\n", "# compute loss and accuracy", "\n", "L", "=", "E", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# numpy array", "\n", "# training accuracy is not disabled", "\n", "# S = Z.detach().cpu().numpy()  # numpy array", "\n", "# T = T.detach().cpu().numpy()  # numpy array", "\n", "\n", "# # print(\"res: \", S)", "\n", "\n", "# # print(\"j, train: BCE \", j, L)", "\n", "\n", "# mbs = T.shape[0]  # = args.mini_batch_size except maybe for last", "\n", "# A = np.sum((np.round(S, 0) == T).astype(np.uint8))", "\n", "\n", "with", "record_function", "(", "\"DLRM backward\"", ")", ":", "\n", "# scaled error gradient propagation", "\n", "# (where we do not accumulate gradients across mini-batches)", "\n", "                        ", "if", "(", "args", ".", "mlperf_logging", "and", "(", "j", "+", "1", ")", "%", "args", ".", "mlperf_grad_accum_iter", "==", "0", ")", "or", "not", "args", ".", "mlperf_logging", ":", "\n", "                            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "# backward pass", "\n", "", "E", ".", "backward", "(", ")", "\n", "\n", "# optimizer", "\n", "if", "(", "args", ".", "mlperf_logging", "and", "(", "j", "+", "1", ")", "%", "args", ".", "mlperf_grad_accum_iter", "==", "0", ")", "or", "not", "args", ".", "mlperf_logging", ":", "\n", "                            ", "optimizer", ".", "step", "(", ")", "\n", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "if", "args", ".", "mlperf_logging", ":", "\n", "                        ", "total_time", "+=", "iteration_time", "\n", "", "else", ":", "\n", "                        ", "t2", "=", "time_wrap", "(", "use_gpu", ")", "\n", "total_time", "+=", "t2", "-", "t1", "\n", "\n", "", "total_loss", "+=", "L", "*", "mbs", "\n", "total_iter", "+=", "1", "\n", "total_samp", "+=", "mbs", "\n", "\n", "should_print", "=", "(", "(", "j", "+", "1", ")", "%", "args", ".", "print_freq", "==", "0", ")", "or", "(", "\n", "j", "+", "1", "==", "nbatches", "\n", ")", "\n", "should_test", "=", "(", "\n", "(", "args", ".", "test_freq", ">", "0", ")", "\n", "and", "(", "args", ".", "data_generation", "in", "[", "\"dataset\"", ",", "\"random\"", "]", ")", "\n", "and", "(", "(", "(", "j", "+", "1", ")", "%", "args", ".", "test_freq", "==", "0", ")", "or", "(", "j", "+", "1", "==", "nbatches", ")", ")", "\n", ")", "\n", "\n", "# print time, loss and accuracy", "\n", "if", "should_print", "or", "should_test", ":", "\n", "                        ", "gT", "=", "1000.0", "*", "total_time", "/", "total_iter", "if", "args", ".", "print_time", "else", "-", "1", "\n", "total_time", "=", "0", "\n", "\n", "train_loss", "=", "total_loss", "/", "total_samp", "\n", "total_loss", "=", "0", "\n", "\n", "str_run_type", "=", "(", "\n", "\"inference\"", "if", "args", ".", "inference_only", "else", "\"training\"", "\n", ")", "\n", "\n", "wall_time", "=", "\"\"", "\n", "if", "args", ".", "print_wall_time", ":", "\n", "                            ", "wall_time", "=", "\" ({})\"", ".", "format", "(", "time", ".", "strftime", "(", "\"%H:%M\"", ")", ")", "\n", "\n", "", "print", "(", "\n", "\"Finished {} it {}/{} of epoch {}, {:.2f} ms/it,\"", ".", "format", "(", "\n", "str_run_type", ",", "j", "+", "1", ",", "nbatches", ",", "k", ",", "gT", "\n", ")", "\n", "+", "\" loss {:.6f}\"", ".", "format", "(", "train_loss", ")", "\n", "+", "wall_time", ",", "\n", "flush", "=", "True", ",", "\n", ")", "\n", "\n", "log_iter", "=", "nbatches", "*", "k", "+", "j", "+", "1", "\n", "writer", ".", "add_scalar", "(", "\"Train/Loss\"", ",", "train_loss", ",", "log_iter", ")", "\n", "\n", "total_iter", "=", "0", "\n", "total_samp", "=", "0", "\n", "\n", "# testing", "\n", "", "if", "should_test", ":", "\n", "                        ", "epoch_num_float", "=", "(", "j", "+", "1", ")", "/", "len", "(", "train_ld", ")", "+", "k", "+", "1", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "                            ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_start", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "EVAL_START", ",", "\n", "metadata", "=", "{", "\n", "mlperf_logger", ".", "constants", ".", "EPOCH_NUM", ":", "epoch_num_float", "\n", "}", ",", "\n", ")", "\n", "\n", "# don't measure training iter time in a test iteration", "\n", "", "if", "args", ".", "mlperf_logging", ":", "\n", "                            ", "previous_iteration_time", "=", "None", "\n", "", "print", "(", "\n", "\"Testing at - {}/{} of epoch {},\"", ".", "format", "(", "j", "+", "1", ",", "nbatches", ",", "k", ")", "\n", ")", "\n", "model_metrics_dict", ",", "is_best", "=", "inference", "(", "\n", "args", ",", "\n", "dlrm", ",", "\n", "best_acc_test", ",", "\n", "best_auc_test", ",", "\n", "test_ld", ",", "\n", "device", ",", "\n", "use_gpu", ",", "\n", "log_iter", ",", "\n", ")", "\n", "\n", "if", "(", "\n", "is_best", "\n", "and", "not", "(", "args", ".", "save_model", "==", "\"\"", ")", "\n", "and", "not", "args", ".", "inference_only", "\n", ")", ":", "\n", "                            ", "model_metrics_dict", "[", "\"epoch\"", "]", "=", "k", "\n", "model_metrics_dict", "[", "\"iter\"", "]", "=", "j", "+", "1", "\n", "model_metrics_dict", "[", "\"train_loss\"", "]", "=", "train_loss", "\n", "model_metrics_dict", "[", "\"total_loss\"", "]", "=", "total_loss", "\n", "model_metrics_dict", "[", "\n", "\"opt_state_dict\"", "\n", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "print", "(", "\"Saving model to {}\"", ".", "format", "(", "args", ".", "save_model", ")", ")", "\n", "torch", ".", "save", "(", "model_metrics_dict", ",", "args", ".", "save_model", ")", "\n", "\n", "", "if", "args", ".", "mlperf_logging", ":", "\n", "                            ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "EVAL_STOP", ",", "\n", "metadata", "=", "{", "\n", "mlperf_logger", ".", "constants", ".", "EPOCH_NUM", ":", "epoch_num_float", "\n", "}", ",", "\n", ")", "\n", "\n", "# Uncomment the line below to print out the total time with overhead", "\n", "# print(\"Total test time for this group: {}\" \\", "\n", "# .format(time_wrap(use_gpu) - accum_test_time_begin))", "\n", "\n", "", "if", "(", "\n", "args", ".", "mlperf_logging", "\n", "and", "(", "args", ".", "mlperf_acc_threshold", ">", "0", ")", "\n", "and", "(", "best_acc_test", ">", "args", ".", "mlperf_acc_threshold", ")", "\n", ")", ":", "\n", "                            ", "print", "(", "\n", "\"MLPerf testing accuracy threshold \"", "\n", "+", "str", "(", "args", ".", "mlperf_acc_threshold", ")", "\n", "+", "\" reached, stop training\"", "\n", ")", "\n", "break", "\n", "\n", "", "if", "(", "\n", "args", ".", "mlperf_logging", "\n", "and", "(", "args", ".", "mlperf_auc_threshold", ">", "0", ")", "\n", "and", "(", "best_auc_test", ">", "args", ".", "mlperf_auc_threshold", ")", "\n", ")", ":", "\n", "                            ", "print", "(", "\n", "\"MLPerf testing auc threshold \"", "\n", "+", "str", "(", "args", ".", "mlperf_auc_threshold", ")", "\n", "+", "\" reached, stop training\"", "\n", ")", "\n", "if", "args", ".", "mlperf_logging", ":", "\n", "                                ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "RUN_STOP", ",", "\n", "metadata", "=", "{", "\n", "mlperf_logger", ".", "constants", ".", "STATUS", ":", "mlperf_logger", ".", "constants", ".", "SUCCESS", "\n", "}", ",", "\n", ")", "\n", "", "break", "\n", "\n", "", "", "", "if", "args", ".", "mlperf_logging", ":", "\n", "                    ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "EPOCH_STOP", ",", "\n", "metadata", "=", "{", "mlperf_logger", ".", "constants", ".", "EPOCH_NUM", ":", "(", "k", "+", "1", ")", "}", ",", "\n", ")", "\n", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "BLOCK_STOP", ",", "\n", "metadata", "=", "{", "mlperf_logger", ".", "constants", ".", "FIRST_EPOCH_NUM", ":", "(", "k", "+", "1", ")", "}", ",", "\n", ")", "\n", "", "k", "+=", "1", "# nepochs", "\n", "", "if", "args", ".", "mlperf_logging", "and", "best_auc_test", "<=", "args", ".", "mlperf_auc_threshold", ":", "\n", "                ", "mlperf_logger", ".", "barrier", "(", ")", "\n", "mlperf_logger", ".", "log_end", "(", "\n", "key", "=", "mlperf_logger", ".", "constants", ".", "RUN_STOP", ",", "\n", "metadata", "=", "{", "\n", "mlperf_logger", ".", "constants", ".", "STATUS", ":", "mlperf_logger", ".", "constants", ".", "ABORTED", "\n", "}", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"Testing for inference only\"", ")", "\n", "inference", "(", "\n", "args", ",", "\n", "dlrm", ",", "\n", "best_acc_test", ",", "\n", "best_auc_test", ",", "\n", "test_ld", ",", "\n", "device", ",", "\n", "use_gpu", ",", "\n", ")", "\n", "\n", "# profiling", "\n", "", "", "if", "args", ".", "enable_profiling", ":", "\n", "        ", "time_stamp", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "with", "open", "(", "\"dlrm_s_pytorch\"", "+", "time_stamp", "+", "\"_shape.prof\"", ",", "\"w\"", ")", "as", "prof_f", ":", "\n", "            ", "prof_f", ".", "write", "(", "\n", "prof", ".", "key_averages", "(", "group_by_input_shape", "=", "True", ")", ".", "table", "(", "\n", "sort_by", "=", "\"self_cpu_time_total\"", "\n", ")", "\n", ")", "\n", "", "with", "open", "(", "\"dlrm_s_pytorch\"", "+", "time_stamp", "+", "\"_total.prof\"", ",", "\"w\"", ")", "as", "prof_f", ":", "\n", "            ", "prof_f", ".", "write", "(", "prof", ".", "key_averages", "(", ")", ".", "table", "(", "sort_by", "=", "\"self_cpu_time_total\"", ")", ")", "\n", "", "prof", ".", "export_chrome_trace", "(", "\"dlrm_s_pytorch\"", "+", "time_stamp", "+", "\".json\"", ")", "\n", "# print(prof.key_averages().table(sort_by=\"cpu_time_total\"))", "\n", "\n", "# plot compute graph", "\n", "", "if", "args", ".", "plot_compute_graph", ":", "\n", "        ", "sys", ".", "exit", "(", "\n", "\"ERROR: Please install pytorchviz package in order to use the\"", "\n", "+", "\" visualization. Then, uncomment its import above as well as\"", "\n", "+", "\" three lines below and run the code again.\"", "\n", ")", "\n", "# V = Z.mean() if args.inference_only else E", "\n", "# dot = make_dot(V, params=dict(dlrm.named_parameters()))", "\n", "# dot.render('dlrm_s_pytorch_graph') # write .pdf file", "\n", "\n", "# test prints", "\n", "", "if", "not", "args", ".", "inference_only", "and", "args", ".", "debug_mode", ":", "\n", "        ", "print", "(", "\"updated parameters (weights and bias):\"", ")", "\n", "for", "param", "in", "dlrm", ".", "parameters", "(", ")", ":", "\n", "            ", "print", "(", "param", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# export the model in onnx", "\n", "", "", "if", "args", ".", "save_onnx", ":", "\n", "        ", "\"\"\"\n        # workaround 1: tensor -> list\n        if torch.is_tensor(lS_i_onnx):\n            lS_i_onnx = [lS_i_onnx[j] for j in range(len(lS_i_onnx))]\n        # workaound 2: list -> tensor\n        lS_i_onnx = torch.stack(lS_i_onnx)\n        \"\"\"", "\n", "# debug prints", "\n", "# print(\"inputs\", X_onnx, lS_o_onnx, lS_i_onnx)", "\n", "# print(\"output\", dlrm_wrap(X_onnx, lS_o_onnx, lS_i_onnx, use_gpu, device))", "\n", "dlrm_pytorch_onnx_file", "=", "\"dlrm_s_pytorch.onnx\"", "\n", "batch_size", "=", "X_onnx", ".", "shape", "[", "0", "]", "\n", "print", "(", "\"X_onnx.shape\"", ",", "X_onnx", ".", "shape", ")", "\n", "if", "torch", ".", "is_tensor", "(", "lS_o_onnx", ")", ":", "\n", "            ", "print", "(", "\"lS_o_onnx.shape\"", ",", "lS_o_onnx", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "for", "oo", "in", "lS_o_onnx", ":", "\n", "                ", "print", "(", "\"oo.shape\"", ",", "oo", ".", "shape", ")", "\n", "", "", "if", "torch", ".", "is_tensor", "(", "lS_i_onnx", ")", ":", "\n", "            ", "print", "(", "\"lS_i_onnx.shape\"", ",", "lS_i_onnx", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "for", "ii", "in", "lS_i_onnx", ":", "\n", "                ", "print", "(", "\"ii.shape\"", ",", "ii", ".", "shape", ")", "\n", "\n", "# name inputs and outputs", "\n", "", "", "o_inputs", "=", "(", "\n", "[", "\"offsets\"", "]", "\n", "if", "torch", ".", "is_tensor", "(", "lS_o_onnx", ")", "\n", "else", "[", "\"offsets_\"", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "lS_o_onnx", ")", ")", "]", "\n", ")", "\n", "i_inputs", "=", "(", "\n", "[", "\"indices\"", "]", "\n", "if", "torch", ".", "is_tensor", "(", "lS_i_onnx", ")", "\n", "else", "[", "\"indices_\"", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "lS_i_onnx", ")", ")", "]", "\n", ")", "\n", "all_inputs", "=", "[", "\"dense_x\"", "]", "+", "o_inputs", "+", "i_inputs", "\n", "# debug prints", "\n", "print", "(", "\"inputs\"", ",", "all_inputs", ")", "\n", "\n", "# create dynamic_axis dictionaries", "\n", "do_inputs", "=", "(", "\n", "[", "{", "\"offsets\"", ":", "{", "1", ":", "\"batch_size\"", "}", "}", "]", "\n", "if", "torch", ".", "is_tensor", "(", "lS_o_onnx", ")", "\n", "else", "[", "\n", "{", "\"offsets_\"", "+", "str", "(", "i", ")", ":", "{", "0", ":", "\"batch_size\"", "}", "}", "for", "i", "in", "range", "(", "len", "(", "lS_o_onnx", ")", ")", "\n", "]", "\n", ")", "\n", "di_inputs", "=", "(", "\n", "[", "{", "\"indices\"", ":", "{", "1", ":", "\"batch_size\"", "}", "}", "]", "\n", "if", "torch", ".", "is_tensor", "(", "lS_i_onnx", ")", "\n", "else", "[", "\n", "{", "\"indices_\"", "+", "str", "(", "i", ")", ":", "{", "0", ":", "\"batch_size\"", "}", "}", "for", "i", "in", "range", "(", "len", "(", "lS_i_onnx", ")", ")", "\n", "]", "\n", ")", "\n", "dynamic_axes", "=", "{", "\"dense_x\"", ":", "{", "0", ":", "\"batch_size\"", "}", ",", "\"pred\"", ":", "{", "0", ":", "\"batch_size\"", "}", "}", "\n", "for", "do", "in", "do_inputs", ":", "\n", "            ", "dynamic_axes", ".", "update", "(", "do", ")", "\n", "", "for", "di", "in", "di_inputs", ":", "\n", "            ", "dynamic_axes", ".", "update", "(", "di", ")", "\n", "# debug prints", "\n", "", "print", "(", "dynamic_axes", ")", "\n", "# export model", "\n", "torch", ".", "onnx", ".", "export", "(", "\n", "dlrm", ",", "\n", "(", "X_onnx", ",", "lS_o_onnx", ",", "lS_i_onnx", ")", ",", "\n", "dlrm_pytorch_onnx_file", ",", "\n", "verbose", "=", "True", ",", "\n", "opset_version", "=", "11", ",", "\n", "input_names", "=", "all_inputs", ",", "\n", "output_names", "=", "[", "\"pred\"", "]", ",", "\n", "dynamic_axes", "=", "dynamic_axes", ",", "\n", ")", "\n", "# recover the model back", "\n", "dlrm_pytorch_onnx", "=", "onnx", ".", "load", "(", "\"dlrm_s_pytorch.onnx\"", ")", "\n", "# check the onnx model", "\n", "onnx", ".", "checker", ".", "check_model", "(", "dlrm_pytorch_onnx", ")", "\n", "", "total_time_end", "=", "time_wrap", "(", "use_gpu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.CriteoDataset.__init__": [[52, 262], ["raw_path.split", "numpy.array", "range", "range", "print", "str", "print", "data_utils.getCriteoAdData", "numpy.load", "len", "print", "len", "print", "numpy.arange", "print", "ValueError", "lstr[].split", "os.path.exists", "numpy.load", "numpy.load", "len", "numpy.array_split", "numpy.concatenate", "numpy.array_split", "print", "os.path.exists", "str", "str", "str", "int", "sys.exit", "numpy.load", "numpy.random.permutation", "print", "range", "print", "numpy.random.permutation", "print", "str", "numpy.ceil", "numpy.random.permutation", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_utils.getCriteoAdData"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dataset", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "randomize", ",", "\n", "split", "=", "\"train\"", ",", "\n", "raw_path", "=", "\"\"", ",", "\n", "pro_data", "=", "\"\"", ",", "\n", "memory_map", "=", "False", ",", "\n", "dataset_multiprocessing", "=", "False", ",", "\n", ")", ":", "\n", "# dataset", "\n", "# tar_fea = 1   # single target", "\n", "        ", "den_fea", "=", "13", "# 13 dense  features", "\n", "# spa_fea = 26  # 26 sparse features", "\n", "# tad_fea = tar_fea + den_fea", "\n", "# tot_fea = tad_fea + spa_fea", "\n", "if", "dataset", "==", "\"kaggle\"", ":", "\n", "            ", "days", "=", "7", "\n", "out_file", "=", "\"kaggleAdDisplayChallenge_processed\"", "\n", "", "elif", "dataset", "==", "\"terabyte\"", ":", "\n", "            ", "days", "=", "24", "\n", "out_file", "=", "\"terabyte_processed\"", "\n", "", "else", ":", "\n", "            ", "raise", "(", "ValueError", "(", "\"Data set option is not supported\"", ")", ")", "\n", "", "self", ".", "max_ind_range", "=", "max_ind_range", "\n", "self", ".", "memory_map", "=", "memory_map", "\n", "\n", "# split the datafile into path and filename", "\n", "lstr", "=", "raw_path", ".", "split", "(", "\"/\"", ")", "\n", "self", ".", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "\n", "self", ".", "d_file", "=", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "if", "dataset", "==", "\"kaggle\"", "else", "lstr", "[", "-", "1", "]", "\n", "self", ".", "npzfile", "=", "self", ".", "d_path", "+", "(", "\n", "(", "self", ".", "d_file", "+", "\"_day\"", ")", "if", "dataset", "==", "\"kaggle\"", "else", "self", ".", "d_file", "\n", ")", "\n", "self", ".", "trafile", "=", "self", ".", "d_path", "+", "(", "\n", "(", "self", ".", "d_file", "+", "\"_fea\"", ")", "if", "dataset", "==", "\"kaggle\"", "else", "\"fea\"", "\n", ")", "\n", "\n", "# check if pre-processed data is available", "\n", "data_ready", "=", "True", "\n", "if", "memory_map", ":", "\n", "            ", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "                ", "reo_data", "=", "self", ".", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "i", ")", "\n", "if", "not", "path", ".", "exists", "(", "str", "(", "reo_data", ")", ")", ":", "\n", "                    ", "data_ready", "=", "False", "\n", "", "", "", "else", ":", "\n", "            ", "if", "not", "path", ".", "exists", "(", "str", "(", "pro_data", ")", ")", ":", "\n", "                ", "data_ready", "=", "False", "\n", "\n", "# pre-process data if needed", "\n", "# WARNNING: when memory mapping is used we get a collection of files", "\n", "", "", "if", "data_ready", ":", "\n", "            ", "print", "(", "\"Reading pre-processed data=%s\"", "%", "(", "str", "(", "pro_data", ")", ")", ")", "\n", "file", "=", "str", "(", "pro_data", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Reading raw data=%s\"", "%", "(", "str", "(", "raw_path", ")", ")", ")", "\n", "file", "=", "data_utils", ".", "getCriteoAdData", "(", "\n", "raw_path", ",", "\n", "out_file", ",", "\n", "max_ind_range", ",", "\n", "sub_sample_rate", ",", "\n", "days", ",", "\n", "split", ",", "\n", "randomize", ",", "\n", "dataset", "==", "\"kaggle\"", ",", "\n", "memory_map", ",", "\n", "dataset_multiprocessing", ",", "\n", ")", "\n", "\n", "# get a number of samples per day", "\n", "", "total_file", "=", "self", ".", "d_path", "+", "self", ".", "d_file", "+", "\"_day_count.npz\"", "\n", "with", "np", ".", "load", "(", "total_file", ")", "as", "data", ":", "\n", "            ", "total_per_file", "=", "data", "[", "\"total_per_file\"", "]", "\n", "# compute offsets per file", "\n", "", "self", ".", "offset_per_file", "=", "np", ".", "array", "(", "[", "0", "]", "+", "[", "x", "for", "x", "in", "total_per_file", "]", ")", "\n", "for", "i", "in", "range", "(", "days", ")", ":", "\n", "            ", "self", ".", "offset_per_file", "[", "i", "+", "1", "]", "+=", "self", ".", "offset_per_file", "[", "i", "]", "\n", "# print(self.offset_per_file)", "\n", "\n", "# setup data", "\n", "", "if", "memory_map", ":", "\n", "# setup the training/testing split", "\n", "            ", "self", ".", "split", "=", "split", "\n", "if", "split", "==", "'none'", "or", "split", "==", "'train'", ":", "\n", "                ", "self", ".", "day", "=", "0", "\n", "self", ".", "max_day_range", "=", "days", "if", "split", "==", "'none'", "else", "days", "-", "1", "\n", "", "elif", "split", "==", "'test'", "or", "split", "==", "'val'", ":", "\n", "                ", "self", ".", "day", "=", "days", "-", "1", "\n", "num_samples", "=", "self", ".", "offset_per_file", "[", "days", "]", "-", "self", ".", "offset_per_file", "[", "days", "-", "1", "]", "\n", "self", ".", "test_size", "=", "int", "(", "np", ".", "ceil", "(", "num_samples", "/", "2.", ")", ")", "\n", "self", ".", "val_size", "=", "num_samples", "-", "self", ".", "test_size", "\n", "", "else", ":", "\n", "                ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train or test.\"", ")", "\n", "\n", "", "'''\n            # text\n            print(\"text\")\n            for i in range(days):\n                fi = self.npzfile + \"_{0}\".format(i)\n                with open(fi) as data:\n                    ttt = 0; nnn = 0\n                    for _j, line in enumerate(data):\n                        ttt +=1\n                        if np.int32(line[0]) > 0:\n                            nnn +=1\n                    print(\"day=\" + str(i) + \" total=\" + str(ttt) + \" non-zeros=\"\n                          + str(nnn) + \" ratio=\" +str((nnn * 100.) / ttt) + \"%\")\n            # processed\n            print(\"processed\")\n            for i in range(days):\n                fi = self.npzfile + \"_{0}_processed.npz\".format(i)\n                with np.load(fi) as data:\n                    yyy = data[\"y\"]\n                ttt = len(yyy)\n                nnn = np.count_nonzero(yyy)\n                print(\"day=\" + str(i) + \" total=\" + str(ttt) + \" non-zeros=\"\n                      + str(nnn) + \" ratio=\" +str((nnn * 100.) / ttt) + \"%\")\n            # reordered\n            print(\"reordered\")\n            for i in range(days):\n                fi = self.npzfile + \"_{0}_reordered.npz\".format(i)\n                with np.load(fi) as data:\n                    yyy = data[\"y\"]\n                ttt = len(yyy)\n                nnn = np.count_nonzero(yyy)\n                print(\"day=\" + str(i) + \" total=\" + str(ttt) + \" non-zeros=\"\n                      + str(nnn) + \" ratio=\" +str((nnn * 100.) / ttt) + \"%\")\n            '''", "\n", "\n", "# load unique counts", "\n", "with", "np", ".", "load", "(", "self", ".", "d_path", "+", "self", ".", "d_file", "+", "\"_fea_count.npz\"", ")", "as", "data", ":", "\n", "                ", "self", ".", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "", "self", ".", "m_den", "=", "den_fea", "# X_int.shape[1]", "\n", "self", ".", "n_emb", "=", "len", "(", "self", ".", "counts", ")", "\n", "print", "(", "\"Sparse features= %d, Dense features= %d\"", "%", "(", "self", ".", "n_emb", ",", "self", ".", "m_den", ")", ")", "\n", "\n", "# Load the test data", "\n", "# Only a single day is used for testing", "\n", "if", "self", ".", "split", "==", "'test'", "or", "self", ".", "split", "==", "'val'", ":", "\n", "# only a single day is used for testing", "\n", "                ", "fi", "=", "self", ".", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "\n", "self", ".", "day", "\n", ")", "\n", "with", "np", ".", "load", "(", "fi", ")", "as", "data", ":", "\n", "                    ", "self", ".", "X_int", "=", "data", "[", "\"X_int\"", "]", "# continuous  feature", "\n", "self", ".", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "# categorical feature", "\n", "self", ".", "y", "=", "data", "[", "\"y\"", "]", "# target", "\n", "\n", "", "", "", "else", ":", "\n", "# load and preprocess data", "\n", "            ", "with", "np", ".", "load", "(", "file", ")", "as", "data", ":", "\n", "                ", "X_int", "=", "data", "[", "\"X_int\"", "]", "# continuous  feature", "\n", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "# categorical feature", "\n", "y", "=", "data", "[", "\"y\"", "]", "# target", "\n", "self", ".", "counts", "=", "data", "[", "\"counts\"", "]", "\n", "", "self", ".", "m_den", "=", "X_int", ".", "shape", "[", "1", "]", "# den_fea", "\n", "self", ".", "n_emb", "=", "len", "(", "self", ".", "counts", ")", "\n", "print", "(", "\"Sparse fea = %d, Dense fea = %d\"", "%", "(", "self", ".", "n_emb", ",", "self", ".", "m_den", ")", ")", "\n", "\n", "# create reordering", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "y", ")", ")", "\n", "\n", "if", "split", "==", "\"none\"", ":", "\n", "# randomize all data", "\n", "                ", "if", "randomize", "==", "\"total\"", ":", "\n", "                    ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "indices", ")", "\n", "print", "(", "\"Randomized indices...\"", ")", "\n", "\n", "", "X_int", "[", "indices", "]", "=", "X_int", "\n", "X_cat", "[", "indices", "]", "=", "X_cat", "\n", "y", "[", "indices", "]", "=", "y", "\n", "\n", "", "else", ":", "\n", "                ", "indices", "=", "np", ".", "array_split", "(", "indices", ",", "self", ".", "offset_per_file", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# randomize train data (per day)", "\n", "if", "randomize", "==", "\"day\"", ":", "# or randomize == \"total\":", "\n", "                    ", "for", "i", "in", "range", "(", "len", "(", "indices", ")", "-", "1", ")", ":", "\n", "                        ", "indices", "[", "i", "]", "=", "np", ".", "random", ".", "permutation", "(", "indices", "[", "i", "]", ")", "\n", "", "print", "(", "\"Randomized indices per day ...\"", ")", "\n", "\n", "", "train_indices", "=", "np", ".", "concatenate", "(", "indices", "[", ":", "-", "1", "]", ")", "\n", "test_indices", "=", "indices", "[", "-", "1", "]", "\n", "test_indices", ",", "val_indices", "=", "np", ".", "array_split", "(", "test_indices", ",", "2", ")", "\n", "\n", "print", "(", "\"Defined %s indices...\"", "%", "(", "split", ")", ")", "\n", "\n", "# randomize train data (across days)", "\n", "if", "randomize", "==", "\"total\"", ":", "\n", "                    ", "train_indices", "=", "np", ".", "random", ".", "permutation", "(", "train_indices", ")", "\n", "print", "(", "\"Randomized indices across days ...\"", ")", "\n", "\n", "# create training, validation, and test sets", "\n", "", "if", "split", "==", "'train'", ":", "\n", "                    ", "self", ".", "X_int", "=", "[", "X_int", "[", "i", "]", "for", "i", "in", "train_indices", "]", "\n", "self", ".", "X_cat", "=", "[", "X_cat", "[", "i", "]", "for", "i", "in", "train_indices", "]", "\n", "self", ".", "y", "=", "[", "y", "[", "i", "]", "for", "i", "in", "train_indices", "]", "\n", "", "elif", "split", "==", "'val'", ":", "\n", "                    ", "self", ".", "X_int", "=", "[", "X_int", "[", "i", "]", "for", "i", "in", "val_indices", "]", "\n", "self", ".", "X_cat", "=", "[", "X_cat", "[", "i", "]", "for", "i", "in", "val_indices", "]", "\n", "self", ".", "y", "=", "[", "y", "[", "i", "]", "for", "i", "in", "val_indices", "]", "\n", "", "elif", "split", "==", "'test'", ":", "\n", "                    ", "self", ".", "X_int", "=", "[", "X_int", "[", "i", "]", "for", "i", "in", "test_indices", "]", "\n", "self", ".", "X_cat", "=", "[", "X_cat", "[", "i", "]", "for", "i", "in", "test_indices", "]", "\n", "self", ".", "y", "=", "[", "y", "[", "i", "]", "for", "i", "in", "test_indices", "]", "\n", "\n", "", "", "print", "(", "\"Split data according to indices...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.CriteoDataset.__getitem__": [[263, 301], ["isinstance", "range", "sys.exit", "numpy.load", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "index", ",", "slice", ")", ":", "\n", "            ", "return", "[", "\n", "self", "[", "idx", "]", "for", "idx", "in", "range", "(", "\n", "index", ".", "start", "or", "0", ",", "index", ".", "stop", "or", "len", "(", "self", ")", ",", "index", ".", "step", "or", "1", "\n", ")", "\n", "]", "\n", "\n", "", "if", "self", ".", "memory_map", ":", "\n", "            ", "if", "self", ".", "split", "==", "'none'", "or", "self", ".", "split", "==", "'train'", ":", "\n", "# check if need to swicth to next day and load data", "\n", "                ", "if", "index", "==", "self", ".", "offset_per_file", "[", "self", ".", "day", "]", ":", "\n", "# print(\"day_boundary switch\", index)", "\n", "                    ", "self", ".", "day_boundary", "=", "self", ".", "offset_per_file", "[", "self", ".", "day", "]", "\n", "fi", "=", "self", ".", "npzfile", "+", "\"_{0}_reordered.npz\"", ".", "format", "(", "\n", "self", ".", "day", "\n", ")", "\n", "# print('Loading file: ', fi)", "\n", "with", "np", ".", "load", "(", "fi", ")", "as", "data", ":", "\n", "                        ", "self", ".", "X_int", "=", "data", "[", "\"X_int\"", "]", "# continuous  feature", "\n", "self", ".", "X_cat", "=", "data", "[", "\"X_cat\"", "]", "# categorical feature", "\n", "self", ".", "y", "=", "data", "[", "\"y\"", "]", "# target", "\n", "", "self", ".", "day", "=", "(", "self", ".", "day", "+", "1", ")", "%", "self", ".", "max_day_range", "\n", "\n", "", "i", "=", "index", "-", "self", ".", "day_boundary", "\n", "", "elif", "self", ".", "split", "==", "'test'", "or", "self", ".", "split", "==", "'val'", ":", "\n", "# only a single day is used for testing", "\n", "                ", "i", "=", "index", "+", "(", "0", "if", "self", ".", "split", "==", "'test'", "else", "self", ".", "test_size", ")", "\n", "", "else", ":", "\n", "                ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train or test.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "i", "=", "index", "\n", "\n", "", "if", "self", ".", "max_ind_range", ">", "0", ":", "\n", "            ", "return", "self", ".", "X_int", "[", "i", "]", ",", "self", ".", "X_cat", "[", "i", "]", "%", "self", ".", "max_ind_range", ",", "self", ".", "y", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "X_int", "[", "i", "]", ",", "self", ".", "X_cat", "[", "i", "]", ",", "self", ".", "y", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.CriteoDataset._default_preprocess": [[302, 311], ["torch.log", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.astype", "torch.tensor"], "methods", ["None"], ["", "", "def", "_default_preprocess", "(", "self", ",", "X_int", ",", "X_cat", ",", "y", ")", ":", "\n", "        ", "X_int", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "X_int", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "if", "self", ".", "max_ind_range", ">", "0", ":", "\n", "            ", "X_cat", "=", "torch", ".", "tensor", "(", "X_cat", "%", "self", ".", "max_ind_range", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "            ", "X_cat", "=", "torch", ".", "tensor", "(", "X_cat", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "y", "=", "torch", ".", "tensor", "(", "y", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "return", "X_int", ",", "X_cat", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.CriteoDataset.__len__": [[312, 326], ["len", "sys.exit"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "memory_map", ":", "\n", "            ", "if", "self", ".", "split", "==", "'none'", ":", "\n", "                ", "return", "self", ".", "offset_per_file", "[", "-", "1", "]", "\n", "", "elif", "self", ".", "split", "==", "'train'", ":", "\n", "                ", "return", "self", ".", "offset_per_file", "[", "-", "2", "]", "\n", "", "elif", "self", ".", "split", "==", "'test'", ":", "\n", "                ", "return", "self", ".", "test_size", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "                ", "return", "self", ".", "val_size", "\n", "", "else", ":", "\n", "                ", "sys", ".", "exit", "(", "\"ERROR: dataset split is neither none, nor train nor test.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "len", "(", "self", ".", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.RandomDataset.__init__": [[578, 627], ["int", "numpy.ceil"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "data_size", ",", "\n", "num_batches", ",", "\n", "mini_batch_size", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "num_targets", "=", "1", ",", "\n", "round_targets", "=", "False", ",", "\n", "data_generation", "=", "\"random\"", ",", "\n", "trace_file", "=", "\"\"", ",", "\n", "enable_padding", "=", "False", ",", "\n", "reset_seed_on_access", "=", "False", ",", "\n", "rand_data_dist", "=", "\"uniform\"", ",", "\n", "rand_data_min", "=", "1", ",", "\n", "rand_data_max", "=", "1", ",", "\n", "rand_data_mu", "=", "-", "1", ",", "\n", "rand_data_sigma", "=", "1", ",", "\n", "rand_seed", "=", "0", "\n", ")", ":", "\n", "# compute batch size", "\n", "        ", "nbatches", "=", "int", "(", "np", ".", "ceil", "(", "(", "data_size", "*", "1.0", ")", "/", "mini_batch_size", ")", ")", "\n", "if", "num_batches", "!=", "0", ":", "\n", "            ", "nbatches", "=", "num_batches", "\n", "data_size", "=", "nbatches", "*", "mini_batch_size", "\n", "# print(\"Total number of batches %d\" % nbatches)", "\n", "\n", "# save args (recompute data_size if needed)", "\n", "", "self", ".", "m_den", "=", "m_den", "\n", "self", ".", "ln_emb", "=", "ln_emb", "\n", "self", ".", "data_size", "=", "data_size", "\n", "self", ".", "num_batches", "=", "nbatches", "\n", "self", ".", "mini_batch_size", "=", "mini_batch_size", "\n", "self", ".", "num_indices_per_lookup", "=", "num_indices_per_lookup", "\n", "self", ".", "num_indices_per_lookup_fixed", "=", "num_indices_per_lookup_fixed", "\n", "self", ".", "num_targets", "=", "num_targets", "\n", "self", ".", "round_targets", "=", "round_targets", "\n", "self", ".", "data_generation", "=", "data_generation", "\n", "self", ".", "trace_file", "=", "trace_file", "\n", "self", ".", "enable_padding", "=", "enable_padding", "\n", "self", ".", "reset_seed_on_access", "=", "reset_seed_on_access", "\n", "self", ".", "rand_seed", "=", "rand_seed", "\n", "self", ".", "rand_data_dist", "=", "rand_data_dist", "\n", "self", ".", "rand_data_min", "=", "rand_data_min", "\n", "self", ".", "rand_data_max", "=", "rand_data_max", "\n", "self", ".", "rand_data_mu", "=", "rand_data_mu", "\n", "self", ".", "rand_data_sigma", "=", "rand_data_sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.RandomDataset.reset_numpy_seed": [[628, 630], ["numpy.random.seed"], "methods", ["None"], ["", "def", "reset_numpy_seed", "(", "self", ",", "numpy_rand_seed", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "numpy_rand_seed", ")", "\n", "# torch.manual_seed(numpy_rand_seed)", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.RandomDataset.__getitem__": [[632, 682], ["isinstance", "min", "dlrm_data_pytorch.generate_random_output_batch", "dlrm_data_pytorch.RandomDataset.reset_numpy_seed", "dlrm_data_pytorch.generate_dist_input_batch", "dlrm_data_pytorch.generate_synthetic_input_batch", "sys.exit", "range", "len"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_random_output_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.RandomDataset.reset_numpy_seed", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_dist_input_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_synthetic_input_batch"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "index", ",", "slice", ")", ":", "\n", "            ", "return", "[", "\n", "self", "[", "idx", "]", "for", "idx", "in", "range", "(", "\n", "index", ".", "start", "or", "0", ",", "index", ".", "stop", "or", "len", "(", "self", ")", ",", "index", ".", "step", "or", "1", "\n", ")", "\n", "]", "\n", "\n", "# WARNING: reset seed on access to first element", "\n", "# (e.g. if same random samples needed across epochs)", "\n", "", "if", "self", ".", "reset_seed_on_access", "and", "index", "==", "0", ":", "\n", "            ", "self", ".", "reset_numpy_seed", "(", "self", ".", "rand_seed", ")", "\n", "\n", "# number of data points in a batch", "\n", "", "n", "=", "min", "(", "self", ".", "mini_batch_size", ",", "self", ".", "data_size", "-", "(", "index", "*", "self", ".", "mini_batch_size", ")", ")", "\n", "\n", "# generate a batch of dense and sparse features", "\n", "if", "self", ".", "data_generation", "==", "\"random\"", ":", "\n", "            ", "(", "X", ",", "lS_o", ",", "lS_i", ")", "=", "generate_dist_input_batch", "(", "\n", "self", ".", "m_den", ",", "\n", "self", ".", "ln_emb", ",", "\n", "n", ",", "\n", "self", ".", "num_indices_per_lookup", ",", "\n", "self", ".", "num_indices_per_lookup_fixed", ",", "\n", "rand_data_dist", "=", "self", ".", "rand_data_dist", ",", "\n", "rand_data_min", "=", "self", ".", "rand_data_min", ",", "\n", "rand_data_max", "=", "self", ".", "rand_data_max", ",", "\n", "rand_data_mu", "=", "self", ".", "rand_data_mu", ",", "\n", "rand_data_sigma", "=", "self", ".", "rand_data_sigma", ",", "\n", ")", "\n", "", "elif", "self", ".", "data_generation", "==", "\"synthetic\"", ":", "\n", "            ", "(", "X", ",", "lS_o", ",", "lS_i", ")", "=", "generate_synthetic_input_batch", "(", "\n", "self", ".", "m_den", ",", "\n", "self", ".", "ln_emb", ",", "\n", "n", ",", "\n", "self", ".", "num_indices_per_lookup", ",", "\n", "self", ".", "num_indices_per_lookup_fixed", ",", "\n", "self", ".", "trace_file", ",", "\n", "self", ".", "enable_padding", "\n", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: --data-generation=\"", "+", "self", ".", "data_generation", "+", "\" is not supported\"", "\n", ")", "\n", "\n", "# generate a batch of target (probability of a click)", "\n", "", "T", "=", "generate_random_output_batch", "(", "n", ",", "self", ".", "num_targets", ",", "self", ".", "round_targets", ")", "\n", "\n", "return", "(", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.RandomDataset.__len__": [[683, 687], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# WARNING: note that we produce bacthes of outputs in __getitem__", "\n", "# therefore we should use num_batches rather than data_size below", "\n", "        ", "return", "self", ".", "num_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.collate_wrapper_criteo_offset": [[328, 342], ["list", "torch.log", "torch.tensor", "torch.tensor().view", "zip", "torch.tensor", "torch.stack", "torch.stack", "torch.tensor", "torch.tensor", "range", "range", "range"], "function", ["None"], ["", "", "", "def", "collate_wrapper_criteo_offset", "(", "list_of_tuples", ")", ":", "\n", "# where each tuple is (X_int, X_cat, y)", "\n", "    ", "transposed_data", "=", "list", "(", "zip", "(", "*", "list_of_tuples", ")", ")", "\n", "X_int", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "transposed_data", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "X_cat", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "T", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "2", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "batchSize", "=", "X_cat", ".", "shape", "[", "0", "]", "\n", "featureCnt", "=", "X_cat", ".", "shape", "[", "1", "]", "\n", "\n", "lS_i", "=", "[", "X_cat", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "featureCnt", ")", "]", "\n", "lS_o", "=", "[", "torch", ".", "tensor", "(", "range", "(", "batchSize", ")", ")", "for", "_", "in", "range", "(", "featureCnt", ")", "]", "\n", "\n", "return", "X_int", ",", "torch", ".", "stack", "(", "lS_o", ")", ",", "torch", ".", "stack", "(", "lS_i", ")", ",", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.ensure_dataset_preprocessed": [[344, 384], ["dlrm_data_pytorch.CriteoDataset", "dlrm_data_pytorch.CriteoDataset", "print", "data_loader_terabyte.numpy_to_binary", "range"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.data_loader_terabyte.numpy_to_binary"], ["", "def", "ensure_dataset_preprocessed", "(", "args", ",", "d_path", ")", ":", "\n", "    ", "_", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"train\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", "\n", ")", "\n", "\n", "_", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"test\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", "\n", ")", "\n", "\n", "for", "split", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "        ", "print", "(", "'Running preprocessing for split ='", ",", "split", ")", "\n", "\n", "train_files", "=", "[", "'{}_{}_reordered.npz'", ".", "format", "(", "args", ".", "raw_data_file", ",", "day", ")", "\n", "for", "\n", "day", "in", "range", "(", "0", ",", "23", ")", "]", "\n", "\n", "test_valid_file", "=", "args", ".", "raw_data_file", "+", "'_23_reordered.npz'", "\n", "\n", "output_file", "=", "d_path", "+", "'_{}.bin'", ".", "format", "(", "split", ")", "\n", "\n", "input_files", "=", "train_files", "if", "split", "==", "'train'", "else", "[", "test_valid_file", "]", "\n", "data_loader_terabyte", ".", "numpy_to_binary", "(", "input_files", "=", "input_files", ",", "\n", "output_file_path", "=", "output_file", ",", "\n", "split", "=", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.offset_to_length_converter": [[387, 395], ["torch.stack", "dlrm_data_pytorch.offset_to_length_converter.diff"], "function", ["None"], ["", "", "def", "offset_to_length_converter", "(", "lS_o", ",", "lS_i", ")", ":", "\n", "    ", "def", "diff", "(", "tensor", ")", ":", "\n", "        ", "return", "tensor", "[", "1", ":", "]", "-", "tensor", "[", ":", "-", "1", "]", "\n", "\n", "", "return", "torch", ".", "stack", "(", "\n", "[", "\n", "diff", "(", "torch", ".", "cat", "(", "(", "S_o", ",", "torch", ".", "tensor", "(", "lS_i", "[", "ind", "]", ".", "shape", ")", ")", ")", ".", "int", "(", ")", ")", "\n", "for", "ind", ",", "S_o", "in", "enumerate", "(", "lS_o", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.collate_wrapper_criteo_length": [[399, 417], ["list", "torch.log", "torch.tensor", "torch.tensor().view", "torch.stack", "torch.stack", "dlrm_data_pytorch.offset_to_length_converter", "zip", "torch.tensor", "torch.tensor", "torch.tensor", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.offset_to_length_converter"], ["", "def", "collate_wrapper_criteo_length", "(", "list_of_tuples", ")", ":", "\n", "# where each tuple is (X_int, X_cat, y)", "\n", "    ", "transposed_data", "=", "list", "(", "zip", "(", "*", "list_of_tuples", ")", ")", "\n", "X_int", "=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "transposed_data", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float", ")", "+", "1", ")", "\n", "X_cat", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "1", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "T", "=", "torch", ".", "tensor", "(", "transposed_data", "[", "2", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "batchSize", "=", "X_cat", ".", "shape", "[", "0", "]", "\n", "featureCnt", "=", "X_cat", ".", "shape", "[", "1", "]", "\n", "\n", "lS_i", "=", "torch", ".", "stack", "(", "[", "X_cat", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "featureCnt", ")", "]", ")", "\n", "lS_o", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "tensor", "(", "range", "(", "batchSize", ")", ")", "for", "_", "in", "range", "(", "featureCnt", ")", "]", "\n", ")", "\n", "\n", "lS_l", "=", "offset_to_length_converter", "(", "lS_o", ",", "lS_i", ")", "\n", "\n", "return", "X_int", ",", "lS_l", ",", "lS_i", ",", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.make_criteo_data_and_loaders": [[419, 573], ["os.path.dirname", "dlrm_data_pytorch.CriteoDataset", "dlrm_data_pytorch.CriteoDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "args.processed_data_file.split", "any", "data_loader_terabyte.CriteoBinDataset", "mlperf_logger.log_event", "torch.utils.data.DataLoader", "data_loader_terabyte.CriteoBinDataset", "mlperf_logger.log_event", "torch.utils.data.DataLoader", "dlrm_data_pytorch.CriteoDataset", "dlrm_data_pytorch.CriteoDataset", "data_loader_terabyte.DataLoader", "data_loader_terabyte.DataLoader", "dlrm_data_pytorch.ensure_dataset_preprocessed", "args.raw_data_file.split", "lstr[].split", "list", "os.path.exists", "torch.utils.data.RandomSampler", "range"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.ensure_dataset_preprocessed"], ["", "def", "make_criteo_data_and_loaders", "(", "args", ",", "offset_to_length_converter", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "mlperf_logging", "and", "args", ".", "memory_map", "and", "args", ".", "data_set", "==", "\"terabyte\"", ":", "\n", "# more efficient for larger batches", "\n", "        ", "data_directory", "=", "path", ".", "dirname", "(", "args", ".", "raw_data_file", ")", "\n", "\n", "if", "args", ".", "mlperf_bin_loader", ":", "\n", "            ", "lstr", "=", "args", ".", "processed_data_file", ".", "split", "(", "\"/\"", ")", "\n", "d_path", "=", "\"/\"", ".", "join", "(", "lstr", "[", "0", ":", "-", "1", "]", ")", "+", "\"/\"", "+", "lstr", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "train_file", "=", "d_path", "+", "\"_train.bin\"", "\n", "test_file", "=", "d_path", "+", "\"_test.bin\"", "\n", "# val_file = d_path + \"_val.bin\"", "\n", "counts_file", "=", "args", ".", "raw_data_file", "+", "'_fea_count.npz'", "\n", "\n", "if", "any", "(", "not", "path", ".", "exists", "(", "p", ")", "for", "p", "in", "[", "train_file", ",", "\n", "test_file", ",", "\n", "counts_file", "]", ")", ":", "\n", "                ", "ensure_dataset_preprocessed", "(", "args", ",", "d_path", ")", "\n", "\n", "", "train_data", "=", "data_loader_terabyte", ".", "CriteoBinDataset", "(", "\n", "data_file", "=", "train_file", ",", "\n", "counts_file", "=", "counts_file", ",", "\n", "batch_size", "=", "args", ".", "mini_batch_size", ",", "\n", "max_ind_range", "=", "args", ".", "max_ind_range", "\n", ")", "\n", "\n", "mlperf_logger", ".", "log_event", "(", "key", "=", "mlperf_logger", ".", "constants", ".", "TRAIN_SAMPLES", ",", "\n", "value", "=", "train_data", ".", "num_samples", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_data", ",", "\n", "batch_size", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "None", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", "sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "mlperf_bin_shuffle", "else", "None", "\n", ")", "\n", "\n", "test_data", "=", "data_loader_terabyte", ".", "CriteoBinDataset", "(", "\n", "data_file", "=", "test_file", ",", "\n", "counts_file", "=", "counts_file", ",", "\n", "batch_size", "=", "args", ".", "test_mini_batch_size", ",", "\n", "max_ind_range", "=", "args", ".", "max_ind_range", "\n", ")", "\n", "\n", "mlperf_logger", ".", "log_event", "(", "key", "=", "mlperf_logger", ".", "constants", ".", "EVAL_SAMPLES", ",", "\n", "value", "=", "test_data", ".", "num_samples", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "None", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "data_filename", "=", "args", ".", "raw_data_file", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "\n", "train_data", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"train\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", "\n", ")", "\n", "\n", "test_data", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"test\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", "\n", ")", "\n", "\n", "train_loader", "=", "data_loader_terabyte", ".", "DataLoader", "(", "\n", "data_directory", "=", "data_directory", ",", "\n", "data_filename", "=", "data_filename", ",", "\n", "days", "=", "list", "(", "range", "(", "23", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "mini_batch_size", ",", "\n", "max_ind_range", "=", "args", ".", "max_ind_range", ",", "\n", "split", "=", "\"train\"", "\n", ")", "\n", "\n", "test_loader", "=", "data_loader_terabyte", ".", "DataLoader", "(", "\n", "data_directory", "=", "data_directory", ",", "\n", "data_filename", "=", "data_filename", ",", "\n", "days", "=", "[", "23", "]", ",", "\n", "batch_size", "=", "args", ".", "test_mini_batch_size", ",", "\n", "max_ind_range", "=", "args", ".", "max_ind_range", ",", "\n", "split", "=", "\"test\"", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "train_data", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"train\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", ",", "\n", ")", "\n", "\n", "test_data", "=", "CriteoDataset", "(", "\n", "args", ".", "data_set", ",", "\n", "args", ".", "max_ind_range", ",", "\n", "args", ".", "data_sub_sample_rate", ",", "\n", "args", ".", "data_randomize", ",", "\n", "\"test\"", ",", "\n", "args", ".", "raw_data_file", ",", "\n", "args", ".", "processed_data_file", ",", "\n", "args", ".", "memory_map", ",", "\n", "args", ".", "dataset_multiprocessing", ",", "\n", ")", "\n", "\n", "collate_wrapper_criteo", "=", "collate_wrapper_criteo_offset", "\n", "if", "offset_to_length_converter", ":", "\n", "            ", "collate_wrapper_criteo", "=", "collate_wrapper_criteo_length", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_data", ",", "\n", "batch_size", "=", "args", ".", "mini_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "collate_fn", "=", "collate_wrapper_criteo", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "args", ".", "test_mini_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "test_num_workers", ",", "\n", "collate_fn", "=", "collate_wrapper_criteo", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "\n", "", "return", "train_data", ",", "train_loader", ",", "test_data", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.collate_wrapper_random_offset": [[689, 696], ["torch.stack"], "function", ["None"], ["", "", "def", "collate_wrapper_random_offset", "(", "list_of_tuples", ")", ":", "\n", "# where each tuple is (X, lS_o, lS_i, T)", "\n", "    ", "(", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", "=", "list_of_tuples", "[", "0", "]", "\n", "return", "(", "X", ",", "\n", "torch", ".", "stack", "(", "lS_o", ")", ",", "\n", "lS_i", ",", "\n", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.collate_wrapper_random_length": [[698, 705], ["dlrm_data_pytorch.offset_to_length_converter", "torch.stack"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.offset_to_length_converter"], ["", "def", "collate_wrapper_random_length", "(", "list_of_tuples", ")", ":", "\n", "# where each tuple is (X, lS_o, lS_i, T)", "\n", "    ", "(", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", "=", "list_of_tuples", "[", "0", "]", "\n", "return", "(", "X", ",", "\n", "offset_to_length_converter", "(", "torch", ".", "stack", "(", "lS_o", ")", ",", "lS_i", ")", ",", "\n", "lS_i", ",", "\n", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.make_random_data_and_loader": [[707, 779], ["dlrm_data_pytorch.RandomDataset", "dlrm_data_pytorch.RandomDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "make_random_data_and_loader", "(", "args", ",", "ln_emb", ",", "m_den", ",", "\n", "offset_to_length_converter", "=", "False", ",", "\n", ")", ":", "\n", "\n", "    ", "train_data", "=", "RandomDataset", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "args", ".", "data_size", ",", "\n", "args", ".", "num_batches", ",", "\n", "args", ".", "mini_batch_size", ",", "\n", "args", ".", "num_indices_per_lookup", ",", "\n", "args", ".", "num_indices_per_lookup_fixed", ",", "\n", "1", ",", "# num_targets", "\n", "args", ".", "round_targets", ",", "\n", "args", ".", "data_generation", ",", "\n", "args", ".", "data_trace_file", ",", "\n", "args", ".", "data_trace_enable_padding", ",", "\n", "reset_seed_on_access", "=", "True", ",", "\n", "rand_data_dist", "=", "args", ".", "rand_data_dist", ",", "\n", "rand_data_min", "=", "args", ".", "rand_data_min", ",", "\n", "rand_data_max", "=", "args", ".", "rand_data_max", ",", "\n", "rand_data_mu", "=", "args", ".", "rand_data_mu", ",", "\n", "rand_data_sigma", "=", "args", ".", "rand_data_sigma", ",", "\n", "rand_seed", "=", "args", ".", "numpy_rand_seed", "\n", ")", "# WARNING: generates a batch of lookups at once", "\n", "\n", "test_data", "=", "RandomDataset", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "args", ".", "data_size", ",", "\n", "args", ".", "num_batches", ",", "\n", "args", ".", "mini_batch_size", ",", "\n", "args", ".", "num_indices_per_lookup", ",", "\n", "args", ".", "num_indices_per_lookup_fixed", ",", "\n", "1", ",", "# num_targets", "\n", "args", ".", "round_targets", ",", "\n", "args", ".", "data_generation", ",", "\n", "args", ".", "data_trace_file", ",", "\n", "args", ".", "data_trace_enable_padding", ",", "\n", "reset_seed_on_access", "=", "True", ",", "\n", "rand_data_dist", "=", "args", ".", "rand_data_dist", ",", "\n", "rand_data_min", "=", "args", ".", "rand_data_min", ",", "\n", "rand_data_max", "=", "args", ".", "rand_data_max", ",", "\n", "rand_data_mu", "=", "args", ".", "rand_data_mu", ",", "\n", "rand_data_sigma", "=", "args", ".", "rand_data_sigma", ",", "\n", "rand_seed", "=", "args", ".", "numpy_rand_seed", "\n", ")", "\n", "\n", "collate_wrapper_random", "=", "collate_wrapper_random_offset", "\n", "if", "offset_to_length_converter", ":", "\n", "        ", "collate_wrapper_random", "=", "collate_wrapper_random_length", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_data", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "collate_fn", "=", "collate_wrapper_random", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "collate_fn", "=", "collate_wrapper_random", ",", "\n", "pin_memory", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "# True", "\n", ")", "\n", "return", "train_data", ",", "train_loader", ",", "test_data", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_random_data": [[781, 846], ["int", "range", "numpy.ceil", "min", "lX.append", "lS_offsets.append", "lS_indices.append", "dlrm_data_pytorch.generate_random_output_batch", "lT.append", "dlrm_data_pytorch.generate_uniform_input_batch", "dlrm_data_pytorch.generate_synthetic_input_batch", "sys.exit"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_random_output_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_uniform_input_batch", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_synthetic_input_batch"], ["", "def", "generate_random_data", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "data_size", ",", "\n", "num_batches", ",", "\n", "mini_batch_size", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "num_targets", "=", "1", ",", "\n", "round_targets", "=", "False", ",", "\n", "data_generation", "=", "\"random\"", ",", "\n", "trace_file", "=", "\"\"", ",", "\n", "enable_padding", "=", "False", ",", "\n", "length", "=", "False", ",", "# length for caffe2 version (except dlrm_s_caffe2)", "\n", ")", ":", "\n", "    ", "nbatches", "=", "int", "(", "np", ".", "ceil", "(", "(", "data_size", "*", "1.0", ")", "/", "mini_batch_size", ")", ")", "\n", "if", "num_batches", "!=", "0", ":", "\n", "        ", "nbatches", "=", "num_batches", "\n", "data_size", "=", "nbatches", "*", "mini_batch_size", "\n", "# print(\"Total number of batches %d\" % nbatches)", "\n", "\n", "# inputs", "\n", "", "lT", "=", "[", "]", "\n", "lX", "=", "[", "]", "\n", "lS_offsets", "=", "[", "]", "\n", "lS_indices", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "0", ",", "nbatches", ")", ":", "\n", "# number of data points in a batch", "\n", "        ", "n", "=", "min", "(", "mini_batch_size", ",", "data_size", "-", "(", "j", "*", "mini_batch_size", ")", ")", "\n", "\n", "# generate a batch of dense and sparse features", "\n", "if", "data_generation", "==", "\"random\"", ":", "\n", "            ", "(", "Xt", ",", "lS_emb_offsets", ",", "lS_emb_indices", ")", "=", "generate_uniform_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "length", ",", "\n", ")", "\n", "", "elif", "data_generation", "==", "\"synthetic\"", ":", "\n", "            ", "(", "Xt", ",", "lS_emb_offsets", ",", "lS_emb_indices", ")", "=", "generate_synthetic_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "trace_file", ",", "\n", "enable_padding", "\n", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\n", "\"ERROR: --data-generation=\"", "+", "data_generation", "+", "\" is not supported\"", "\n", ")", "\n", "# dense feature", "\n", "", "lX", ".", "append", "(", "Xt", ")", "\n", "# sparse feature (sparse indices)", "\n", "lS_offsets", ".", "append", "(", "lS_emb_offsets", ")", "\n", "lS_indices", ".", "append", "(", "lS_emb_indices", ")", "\n", "\n", "# generate a batch of target (probability of a click)", "\n", "P", "=", "generate_random_output_batch", "(", "n", ",", "num_targets", ",", "round_targets", ")", "\n", "lT", ".", "append", "(", "P", ")", "\n", "\n", "", "return", "(", "nbatches", ",", "lX", ",", "lS_offsets", ",", "lS_indices", ",", "lT", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_random_output_batch": [[848, 856], ["torch.tensor", "numpy.round().astype", "numpy.random.rand().astype", "numpy.round", "numpy.random.rand", "numpy.random.rand().astype", "numpy.random.rand"], "function", ["None"], ["", "def", "generate_random_output_batch", "(", "n", ",", "num_targets", ",", "round_targets", "=", "False", ")", ":", "\n", "# target (probability of a click)", "\n", "    ", "if", "round_targets", ":", "\n", "        ", "P", "=", "np", ".", "round", "(", "ra", ".", "rand", "(", "n", ",", "num_targets", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "P", "=", "ra", ".", "rand", "(", "n", ",", "num_targets", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "P", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_uniform_input_batch": [[859, 906], ["torch.tensor", "numpy.random.rand().astype", "range", "lS_emb_offsets.append", "lS_emb_indices.append", "numpy.random.random", "numpy.unique", "numpy.int32", "np.unique.tolist", "torch.tensor", "torch.tensor", "numpy.random.rand", "numpy.int64", "numpy.random.random", "numpy.int64", "numpy.round().astype", "numpy.round", "max", "numpy.round", "min"], "function", ["None"], ["", "def", "generate_uniform_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "length", ",", "\n", ")", ":", "\n", "# dense feature", "\n", "    ", "Xt", "=", "torch", ".", "tensor", "(", "ra", ".", "rand", "(", "n", ",", "m_den", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_offsets", "=", "[", "]", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "size", "in", "ln_emb", ":", "\n", "        ", "lS_batch_offsets", "=", "[", "]", "\n", "lS_batch_indices", "=", "[", "]", "\n", "offset", "=", "0", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding (between", "\n", "            ", "if", "num_indices_per_lookup_fixed", ":", "\n", "                ", "sparse_group_size", "=", "np", ".", "int64", "(", "num_indices_per_lookup", ")", "\n", "", "else", ":", "\n", "# random between [1,num_indices_per_lookup])", "\n", "                ", "r", "=", "ra", ".", "random", "(", "1", ")", "\n", "sparse_group_size", "=", "np", ".", "int64", "(", "\n", "np", ".", "round", "(", "max", "(", "[", "1.0", "]", ",", "r", "*", "min", "(", "size", ",", "num_indices_per_lookup", ")", ")", ")", "\n", ")", "\n", "# sparse indices to be used per embedding", "\n", "", "r", "=", "ra", ".", "random", "(", "sparse_group_size", ")", "\n", "sparse_group", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "r", "*", "(", "size", "-", "1", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", ")", "\n", "# reset sparse_group_size in case some index duplicates were removed", "\n", "sparse_group_size", "=", "np", ".", "int32", "(", "sparse_group", ".", "size", ")", "\n", "# store lengths and indices", "\n", "if", "length", ":", "# for caffe2 version", "\n", "                ", "lS_batch_offsets", "+=", "[", "sparse_group_size", "]", "\n", "", "else", ":", "\n", "                ", "lS_batch_offsets", "+=", "[", "offset", "]", "\n", "", "lS_batch_indices", "+=", "sparse_group", ".", "tolist", "(", ")", "\n", "# update offset for next iteration", "\n", "offset", "+=", "sparse_group_size", "\n", "", "lS_emb_offsets", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_offsets", ")", ")", "\n", "lS_emb_indices", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_indices", ")", ")", "\n", "\n", "", "return", "(", "Xt", ",", "lS_emb_offsets", ",", "lS_emb_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_dist_input_batch": [[909, 968], ["torch.tensor", "numpy.random.rand().astype", "range", "lS_emb_offsets.append", "lS_emb_indices.append", "numpy.int64", "np.unique.tolist", "torch.tensor", "torch.tensor", "numpy.random.rand", "numpy.int64", "numpy.random.random", "numpy.int64", "numpy.random.normal", "numpy.clip", "numpy.unique().astype", "numpy.round", "numpy.random.random", "numpy.unique", "max", "numpy.unique", "numpy.round().astype", "min", "numpy.round"], "function", ["None"], ["", "def", "generate_dist_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "rand_data_dist", ",", "\n", "rand_data_min", ",", "\n", "rand_data_max", ",", "\n", "rand_data_mu", ",", "\n", "rand_data_sigma", ",", "\n", ")", ":", "\n", "# dense feature", "\n", "    ", "Xt", "=", "torch", ".", "tensor", "(", "ra", ".", "rand", "(", "n", ",", "m_den", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_offsets", "=", "[", "]", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "size", "in", "ln_emb", ":", "\n", "        ", "lS_batch_offsets", "=", "[", "]", "\n", "lS_batch_indices", "=", "[", "]", "\n", "offset", "=", "0", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding (between", "\n", "            ", "if", "num_indices_per_lookup_fixed", ":", "\n", "                ", "sparse_group_size", "=", "np", ".", "int64", "(", "num_indices_per_lookup", ")", "\n", "", "else", ":", "\n", "# random between [1,num_indices_per_lookup])", "\n", "                ", "r", "=", "ra", ".", "random", "(", "1", ")", "\n", "sparse_group_size", "=", "np", ".", "int64", "(", "\n", "np", ".", "round", "(", "max", "(", "[", "1.0", "]", ",", "r", "*", "min", "(", "size", ",", "num_indices_per_lookup", ")", ")", ")", "\n", ")", "\n", "# sparse indices to be used per embedding", "\n", "", "if", "rand_data_dist", "==", "\"gaussian\"", ":", "\n", "                ", "if", "rand_data_mu", "==", "-", "1", ":", "\n", "                    ", "rand_data_mu", "=", "(", "rand_data_max", "+", "rand_data_min", ")", "/", "2.0", "\n", "", "r", "=", "ra", ".", "normal", "(", "rand_data_mu", ",", "rand_data_sigma", ",", "sparse_group_size", ")", "\n", "sparse_group", "=", "np", ".", "clip", "(", "r", ",", "rand_data_min", ",", "rand_data_max", ")", "\n", "sparse_group", "=", "np", ".", "unique", "(", "sparse_group", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "elif", "rand_data_dist", "==", "\"uniform\"", ":", "\n", "                ", "r", "=", "ra", ".", "random", "(", "sparse_group_size", ")", "\n", "sparse_group", "=", "np", ".", "unique", "(", "np", ".", "round", "(", "r", "*", "(", "size", "-", "1", ")", ")", ".", "astype", "(", "np", ".", "int64", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "(", "rand_data_dist", ",", "\"distribution is not supported. \\\n                     please select uniform or gaussian\"", ")", "\n", "\n", "# reset sparse_group_size in case some index duplicates were removed", "\n", "", "sparse_group_size", "=", "np", ".", "int64", "(", "sparse_group", ".", "size", ")", "\n", "# store lengths and indices", "\n", "lS_batch_offsets", "+=", "[", "offset", "]", "\n", "lS_batch_indices", "+=", "sparse_group", ".", "tolist", "(", ")", "\n", "# update offset for next iteration", "\n", "offset", "+=", "sparse_group_size", "\n", "", "lS_emb_offsets", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_offsets", ")", ")", "\n", "lS_emb_indices", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_indices", ")", ")", "\n", "\n", "", "return", "(", "Xt", ",", "lS_emb_offsets", ",", "lS_emb_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_synthetic_input_batch": [[971, 1043], ["torch.tensor", "enumerate", "numpy.random.rand().astype", "range", "lS_emb_offsets.append", "lS_emb_indices.append", "dlrm_data_pytorch.read_dist_from_file", "dlrm_data_pytorch.trace_generate_lru", "numpy.unique().astype", "numpy.min", "numpy.max", "numpy.int64", "np.mod().astype.tolist", "torch.tensor", "torch.tensor", "numpy.random.rand", "numpy.int64", "numpy.random.random", "numpy.int64", "file_path.replace", "print", "numpy.mod().astype", "max", "str", "numpy.unique", "numpy.mod", "numpy.round", "min"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.read_dist_from_file", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.trace_generate_lru"], ["", "def", "generate_synthetic_input_batch", "(", "\n", "m_den", ",", "\n", "ln_emb", ",", "\n", "n", ",", "\n", "num_indices_per_lookup", ",", "\n", "num_indices_per_lookup_fixed", ",", "\n", "trace_file", ",", "\n", "enable_padding", "=", "False", ",", "\n", ")", ":", "\n", "# dense feature", "\n", "    ", "Xt", "=", "torch", ".", "tensor", "(", "ra", ".", "rand", "(", "n", ",", "m_den", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "# sparse feature (sparse indices)", "\n", "lS_emb_offsets", "=", "[", "]", "\n", "lS_emb_indices", "=", "[", "]", "\n", "# for each embedding generate a list of n lookups,", "\n", "# where each lookup is composed of multiple sparse indices", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "ln_emb", ")", ":", "\n", "        ", "lS_batch_offsets", "=", "[", "]", "\n", "lS_batch_indices", "=", "[", "]", "\n", "offset", "=", "0", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "# num of sparse indices to be used per embedding (between", "\n", "            ", "if", "num_indices_per_lookup_fixed", ":", "\n", "                ", "sparse_group_size", "=", "np", ".", "int64", "(", "num_indices_per_lookup", ")", "\n", "", "else", ":", "\n", "# random between [1,num_indices_per_lookup])", "\n", "                ", "r", "=", "ra", ".", "random", "(", "1", ")", "\n", "sparse_group_size", "=", "np", ".", "int64", "(", "\n", "max", "(", "1", ",", "np", ".", "round", "(", "r", "*", "min", "(", "size", ",", "num_indices_per_lookup", ")", ")", "[", "0", "]", ")", "\n", ")", "\n", "# sparse indices to be used per embedding", "\n", "", "file_path", "=", "trace_file", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", "=", "read_dist_from_file", "(", "\n", "file_path", ".", "replace", "(", "\"j\"", ",", "str", "(", "i", ")", ")", "\n", ")", "\n", "# debug prints", "\n", "# print(\"input\")", "\n", "# print(line_accesses); print(list_sd); print(cumm_sd);", "\n", "# print(sparse_group_size)", "\n", "# approach 1: rand", "\n", "# r = trace_generate_rand(", "\n", "#     line_accesses, list_sd, cumm_sd, sparse_group_size, enable_padding", "\n", "# )", "\n", "# approach 2: lru", "\n", "r", "=", "trace_generate_lru", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "sparse_group_size", ",", "enable_padding", "\n", ")", "\n", "# WARNING: if the distribution in the file is not consistent", "\n", "# with embedding table dimensions, below mod guards against out", "\n", "# of range access", "\n", "sparse_group", "=", "np", ".", "unique", "(", "r", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "minsg", "=", "np", ".", "min", "(", "sparse_group", ")", "\n", "maxsg", "=", "np", ".", "max", "(", "sparse_group", ")", "\n", "if", "(", "minsg", "<", "0", ")", "or", "(", "size", "<=", "maxsg", ")", ":", "\n", "                ", "print", "(", "\n", "\"WARNING: distribution is inconsistent with embedding \"", "\n", "+", "\"table size (using mod to recover and continue)\"", "\n", ")", "\n", "sparse_group", "=", "np", ".", "mod", "(", "sparse_group", ",", "size", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "# sparse_group = np.unique(np.array(np.mod(r, size-1)).astype(np.int64))", "\n", "# reset sparse_group_size in case some index duplicates were removed", "\n", "", "sparse_group_size", "=", "np", ".", "int64", "(", "sparse_group", ".", "size", ")", "\n", "# store lengths and indices", "\n", "lS_batch_offsets", "+=", "[", "offset", "]", "\n", "lS_batch_indices", "+=", "sparse_group", ".", "tolist", "(", ")", "\n", "# update offset for next iteration", "\n", "offset", "+=", "sparse_group_size", "\n", "", "lS_emb_offsets", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_offsets", ")", ")", "\n", "lS_emb_indices", ".", "append", "(", "torch", ".", "tensor", "(", "lS_batch_indices", ")", ")", "\n", "\n", "", "return", "(", "Xt", ",", "lS_emb_offsets", ",", "lS_emb_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_stack_distance": [[1045, 1060], ["numpy.random.rand", "enumerate", "bisect.bisect"], "function", ["None"], ["", "def", "generate_stack_distance", "(", "cumm_val", ",", "cumm_dist", ",", "max_i", ",", "i", ",", "enable_padding", "=", "False", ")", ":", "\n", "    ", "u", "=", "ra", ".", "rand", "(", "1", ")", "\n", "if", "i", "<", "max_i", ":", "\n", "# only generate stack distances up to the number of new references seen so far", "\n", "        ", "j", "=", "bisect", ".", "bisect", "(", "cumm_val", ",", "i", ")", "-", "1", "\n", "fi", "=", "cumm_dist", "[", "j", "]", "\n", "u", "*=", "fi", "# shrink distribution support to exclude last values", "\n", "", "elif", "enable_padding", ":", "\n", "# WARNING: disable generation of new references (once all have been seen)", "\n", "        ", "fi", "=", "cumm_dist", "[", "0", "]", "\n", "u", "=", "(", "1.0", "-", "fi", ")", "*", "u", "+", "fi", "# remap distribution support to exclude first value", "\n", "\n", "", "for", "(", "j", ",", "f", ")", "in", "enumerate", "(", "cumm_dist", ")", ":", "\n", "        ", "if", "u", "<=", "f", ":", "\n", "            ", "return", "cumm_val", "[", "j", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.trace_generate_lru": [[1066, 1093], ["len", "collections.deque", "range", "dlrm_data_pytorch.generate_stack_distance", "collections.deque.append", "line_accesses.append", "numpy.uint64", "numpy.uint64", "line_accesses.append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_stack_distance"], ["def", "trace_generate_lru", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "out_trace_len", ",", "enable_padding", "=", "False", "\n", ")", ":", "\n", "    ", "max_sd", "=", "list_sd", "[", "-", "1", "]", "\n", "l", "=", "len", "(", "line_accesses", ")", "\n", "i", "=", "0", "\n", "ztrace", "=", "deque", "(", ")", "\n", "for", "_", "in", "range", "(", "out_trace_len", ")", ":", "\n", "        ", "sd", "=", "generate_stack_distance", "(", "list_sd", ",", "cumm_sd", ",", "max_sd", ",", "i", ",", "enable_padding", ")", "\n", "mem_ref_within_line", "=", "0", "# floor(ra.rand(1)*cache_line_size) #0", "\n", "\n", "# generate memory reference", "\n", "if", "sd", "==", "0", ":", "# new reference #", "\n", "            ", "line_ref", "=", "line_accesses", "[", "0", "]", "\n", "del", "line_accesses", "[", "0", "]", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "# existing reference #", "\n", "            ", "line_ref", "=", "line_accesses", "[", "l", "-", "sd", "]", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "del", "line_accesses", "[", "l", "-", "sd", "]", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "# save generated memory reference", "\n", "", "ztrace", ".", "append", "(", "mem_ref", ")", "\n", "\n", "", "return", "ztrace", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.trace_generate_rand": [[1095, 1117], ["len", "range", "dlrm_data_pytorch.generate_stack_distance", "ztrace.append", "line_accesses.pop", "line_accesses.append", "numpy.uint64", "numpy.uint64"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.generate_stack_distance"], ["", "def", "trace_generate_rand", "(", "\n", "line_accesses", ",", "list_sd", ",", "cumm_sd", ",", "out_trace_len", ",", "enable_padding", "=", "False", "\n", ")", ":", "\n", "    ", "max_sd", "=", "list_sd", "[", "-", "1", "]", "\n", "l", "=", "len", "(", "line_accesses", ")", "# !!!Unique,", "\n", "i", "=", "0", "\n", "ztrace", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "out_trace_len", ")", ":", "\n", "        ", "sd", "=", "generate_stack_distance", "(", "list_sd", ",", "cumm_sd", ",", "max_sd", ",", "i", ",", "enable_padding", ")", "\n", "mem_ref_within_line", "=", "0", "# floor(ra.rand(1)*cache_line_size) #0", "\n", "# generate memory reference", "\n", "if", "sd", "==", "0", ":", "# new reference #", "\n", "            ", "line_ref", "=", "line_accesses", ".", "pop", "(", "0", ")", "\n", "line_accesses", ".", "append", "(", "line_ref", ")", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "i", "+=", "1", "\n", "", "else", ":", "# existing reference #", "\n", "            ", "line_ref", "=", "line_accesses", "[", "l", "-", "sd", "]", "\n", "mem_ref", "=", "np", ".", "uint64", "(", "line_ref", "*", "cache_line_size", "+", "mem_ref_within_line", ")", "\n", "", "ztrace", ".", "append", "(", "mem_ref", ")", "\n", "\n", "", "return", "ztrace", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.trace_profile": [[1119, 1165], ["collections.deque", "collections.deque", "collections.deque", "numpy.uint64", "len", "len", "max", "int", "collections.deque.index", "collections.deque.appendleft", "collections.deque.append", "numpy.ceil", "collections.deque.appendleft", "collections.deque.appendleft", "collections.deque.append"], "function", ["None"], ["", "def", "trace_profile", "(", "trace", ",", "enable_padding", "=", "False", ")", ":", "\n", "# number of elements in the array (assuming 1D)", "\n", "# n = trace.size", "\n", "\n", "    ", "rstack", "=", "deque", "(", ")", "# S", "\n", "stack_distances", "=", "deque", "(", ")", "# SDS", "\n", "line_accesses", "=", "deque", "(", ")", "# L", "\n", "for", "x", "in", "trace", ":", "\n", "        ", "r", "=", "np", ".", "uint64", "(", "x", "/", "cache_line_size", ")", "\n", "l", "=", "len", "(", "rstack", ")", "\n", "try", ":", "# found #", "\n", "            ", "i", "=", "rstack", ".", "index", "(", "r", ")", "\n", "# WARNING: I believe below is the correct depth in terms of meaning of the", "\n", "#          algorithm, but that is not what seems to be in the paper alg.", "\n", "#          -1 can be subtracted if we defined the distance between", "\n", "#          consecutive accesses (e.g. r, r) as 0 rather than 1.", "\n", "sd", "=", "l", "-", "i", "# - 1", "\n", "# push r to the end of stack_distances", "\n", "stack_distances", ".", "appendleft", "(", "sd", ")", "\n", "# remove r from its position and insert to the top of stack", "\n", "del", "rstack", "[", "i", "]", "# rstack.remove(r)", "\n", "rstack", ".", "append", "(", "r", ")", "\n", "", "except", "ValueError", ":", "# not found #", "\n", "            ", "sd", "=", "0", "# -1", "\n", "# push r to the end of stack_distances/line_accesses", "\n", "stack_distances", ".", "appendleft", "(", "sd", ")", "\n", "line_accesses", ".", "appendleft", "(", "r", ")", "\n", "# push r to the top of stack", "\n", "rstack", ".", "append", "(", "r", ")", "\n", "\n", "", "", "if", "enable_padding", ":", "\n", "# WARNING: notice that as the ratio between the number of samples (l)", "\n", "# and cardinality (c) of a sample increases the probability of", "\n", "# generating a sample gets smaller and smaller because there are", "\n", "# few new samples compared to repeated samples. This means that for a", "\n", "# long trace with relatively small cardinality it will take longer to", "\n", "# generate all new samples and therefore obtain full distribution support", "\n", "# and hence it takes longer for distribution to resemble the original.", "\n", "# Therefore, we may pad the number of new samples to be on par with", "\n", "# average number of samples l/c artificially.", "\n", "        ", "l", "=", "len", "(", "stack_distances", ")", "\n", "c", "=", "max", "(", "stack_distances", ")", "\n", "padding", "=", "int", "(", "np", ".", "ceil", "(", "l", "/", "c", ")", ")", "\n", "stack_distances", "=", "stack_distances", "+", "[", "0", "]", "*", "padding", "\n", "\n", "", "return", "(", "rstack", ",", "stack_distances", ",", "line_accesses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.read_trace_from_file": [[1168, 1180], ["open", "print", "numpy.fromfile", "np.fromfile.astype().tolist", "f.readline", "list", "map", "np.fromfile.astype", "f.readline.split", "numpy.uint64"], "function", ["None"], ["", "def", "read_trace_from_file", "(", "file_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "if", "args", ".", "trace_file_binary_type", ":", "\n", "                ", "array", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "uint64", ")", "\n", "trace", "=", "array", ".", "astype", "(", "np", ".", "uint64", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "                ", "line", "=", "f", ".", "readline", "(", ")", "\n", "trace", "=", "list", "(", "map", "(", "lambda", "x", ":", "np", ".", "uint64", "(", "x", ")", ",", "line", ".", "split", "(", "\", \"", ")", ")", ")", "\n", "", "return", "trace", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "f\"ERROR: trace file '{file_path}' is not available.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.write_trace_to_file": [[1182, 1193], ["print", "open", "numpy.array().astype().tofile", "open", "str", "f.write", "list", "numpy.array().astype", "numpy.array", "len"], "function", ["None"], ["", "", "def", "write_trace_to_file", "(", "file_path", ",", "trace", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "if", "args", ".", "trace_file_binary_type", ":", "\n", "            ", "with", "open", "(", "file_path", ",", "\"wb+\"", ")", "as", "f", ":", "\n", "                ", "np", ".", "array", "(", "trace", ")", ".", "astype", "(", "np", ".", "uint64", ")", ".", "tofile", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "file_path", ",", "\"w+\"", ")", "as", "f", ":", "\n", "                ", "s", "=", "str", "(", "list", "(", "trace", ")", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", ")", "\n", "", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"ERROR: no output trace file has been provided\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.read_dist_from_file": [[1195, 1208], ["int", "int", "float", "open", "f.read().splitlines", "print", "lines[].split", "lines[].split", "lines[].split", "f.read"], "function", ["None"], ["", "", "def", "read_dist_from_file", "(", "file_path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"{file_path} Wrong file or file path\"", ")", "\n", "# read unique accesses", "\n", "", "unique_accesses", "=", "[", "int", "(", "el", ")", "for", "el", "in", "lines", "[", "0", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "# read cumulative distribution (elements are passed as two separate lists)", "\n", "list_sd", "=", "[", "int", "(", "el", ")", "for", "el", "in", "lines", "[", "1", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "cumm_sd", "=", "[", "float", "(", "el", ")", "for", "el", "in", "lines", "[", "2", "]", ".", "split", "(", "\", \"", ")", "]", "\n", "\n", "return", "unique_accesses", ",", "list_sd", ",", "cumm_sd", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_data_pytorch.write_dist_to_file": [[1210, 1224], ["open", "str", "f.write", "str", "f.write", "str", "f.write", "print", "list", "list", "len", "len", "len"], "function", ["None"], ["", "def", "write_dist_to_file", "(", "file_path", ",", "unique_accesses", ",", "list_sd", ",", "cumm_sd", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "# unique_acesses", "\n", "            ", "s", "=", "str", "(", "list", "(", "unique_accesses", ")", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "# list_sd", "\n", "s", "=", "str", "(", "list_sd", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "# cumm_sd", "\n", "s", "=", "str", "(", "list", "(", "cumm_sd", ")", ")", "\n", "f", ".", "write", "(", "s", "[", "1", ":", "len", "(", "s", ")", "-", "1", "]", "+", "\"\\n\"", ")", "\n", "", "", "except", "Exception", ":", "\n", "        ", "print", "(", "\"Wrong file or file path\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper": [[102, 146], ["numpy.split", "range", "range", "caffe2.python.core.DeviceOption", "caffe2.python.workspace.FeedBlob", "caffe2.python.workspace.FeedBlob", "sys.exit", "caffe2.python.core.DeviceOption", "caffe2.python.workspace.FeedBlob", "caffe2.python.core.DeviceOption", "caffe2.python.workspace.FeedBlob", "str", "str", "str", "str"], "methods", ["None"], ["    ", "def", "FeedBlobWrapper", "(", "self", ",", "tag", ",", "val", ",", "add_prefix", "=", "True", ",", "split", "=", "False", ",", "device_id", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "ndevices", ">", "1", "and", "add_prefix", ":", "\n", "            ", "if", "split", ":", "\n", "# split across devices", "\n", "                ", "mini_batch_size", "=", "val", ".", "shape", "[", "0", "]", "\n", "# approach 1: np and caffe2 operators assume the mini-batch size is", "\n", "# divisible exactly by the number of available devices", "\n", "if", "mini_batch_size", "%", "self", ".", "ndevices", "!=", "0", ":", "\n", "                    ", "sys", ".", "exit", "(", "\"ERROR: caffe2 net assumes that the mini_batch_size \"", "\n", "+", "str", "(", "mini_batch_size", ")", "\n", "+", "\" is evenly divisible by the number of available devices\"", "\n", "+", "str", "(", "self", ".", "ndevices", ")", ")", "\n", "", "vals", "=", "np", ".", "split", "(", "val", ",", "self", ".", "ndevices", ",", "axis", "=", "0", ")", "\n", "\"\"\"\n                # approach 2: np and caffe2 operators do not assume exact divisibility\n                if args.mini_batch_size != mini_batch_size:\n                    sys.exit(\"ERROR: caffe2 net was prepared for mini-batch size \"\n                             + str(args.mini_batch_size)\n                             + \" which is different from current mini-batch size \"\n                             + str(mini_batch_size) + \" being passed to it. \"\n                             + \"This is common for the last mini-batch, when \"\n                             + \"mini-batch size does not evenly divided the number of \"\n                             + \"elements in the data set.\")\n                ls = where_to_split(mini_batch_size, self.ndevices)\n                vals = np.split(val, ls, axis=0)\n                \"\"\"", "\n", "# feed to multiple devices", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", ":", "\n", "                    ", "tag_on_device", "=", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "+", "tag", "\n", "_d", "=", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", "workspace", ".", "FeedBlob", "(", "tag_on_device", ",", "vals", "[", "d", "]", ",", "device_option", "=", "_d", ")", "\n", "", "", "else", ":", "\n", "# feed to multiple devices", "\n", "                ", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", ":", "\n", "                    ", "tag_on_device", "=", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "+", "tag", "\n", "_d", "=", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", "workspace", ".", "FeedBlob", "(", "tag_on_device", ",", "val", ",", "device_option", "=", "_d", ")", "\n", "", "", "", "else", ":", "\n", "# feed to a single device (named or not)", "\n", "            ", "if", "device_id", ">=", "0", ":", "\n", "                ", "_d", "=", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "device_id", ")", "\n", "workspace", ".", "FeedBlob", "(", "tag", ",", "val", ",", "device_option", "=", "_d", ")", "\n", "", "else", ":", "\n", "                ", "workspace", ".", "FeedBlob", "(", "tag", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper": [[147, 172], ["range", "caffe2.python.workspace.FetchBlob", "vals.append", "functools.reduce", "caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchBlob", "numpy.concatenate", "str", "str"], "methods", ["None"], ["", "", "", "def", "FetchBlobWrapper", "(", "self", ",", "tag", ",", "add_prefix", "=", "True", ",", "reduce_across", "=", "None", ",", "device_id", "=", "-", "1", ")", ":", "\n", "        ", "if", "self", ".", "ndevices", ">", "1", "and", "add_prefix", ":", "\n", "# fetch from multiple devices", "\n", "            ", "vals", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", ":", "\n", "                ", "if", "tag", ".", "__class__", "==", "list", ":", "\n", "                    ", "tag_on_device", "=", "tag", "[", "d", "]", "\n", "", "else", ":", "\n", "                    ", "tag_on_device", "=", "\"gpu_\"", "+", "str", "(", "0", ")", "+", "\"/\"", "+", "tag", "\n", "", "val", "=", "workspace", ".", "FetchBlob", "(", "tag_on_device", ")", "\n", "vals", ".", "append", "(", "val", ")", "\n", "# reduce across devices", "\n", "", "if", "reduce_across", "==", "\"add\"", ":", "\n", "                ", "return", "functools", ".", "reduce", "(", "operator", ".", "add", ",", "vals", ")", "\n", "", "elif", "reduce_across", "==", "\"concat\"", ":", "\n", "                ", "return", "np", ".", "concatenate", "(", "vals", ")", "\n", "", "else", ":", "\n", "                ", "return", "vals", "\n", "", "", "else", ":", "\n", "# fetch from a single device (named or not)", "\n", "            ", "if", "device_id", ">=", "0", ":", "\n", "                ", "tag_on_device", "=", "\"gpu_\"", "+", "str", "(", "device_id", ")", "+", "\"/\"", "+", "tag", "\n", "return", "workspace", ".", "FetchBlob", "(", "tag_on_device", ")", "\n", "", "else", ":", "\n", "                ", "return", "workspace", ".", "FetchBlob", "(", "tag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper": [[173, 219], ["range", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper.adjust_tag"], "methods", ["None"], ["", "", "", "def", "AddLayerWrapper", "(", "self", ",", "layer", ",", "inp_blobs", ",", "out_blobs", ",", "\n", "add_prefix", "=", "True", ",", "reset_grad", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# auxiliary routine to adjust tags", "\n", "        ", "def", "adjust_tag", "(", "blobs", ",", "on_device", ")", ":", "\n", "            ", "if", "blobs", ".", "__class__", "==", "str", ":", "\n", "                ", "_blobs", "=", "on_device", "+", "blobs", "\n", "", "elif", "blobs", ".", "__class__", "==", "list", ":", "\n", "                ", "_blobs", "=", "list", "(", "map", "(", "lambda", "tag", ":", "on_device", "+", "tag", ",", "blobs", ")", ")", "\n", "", "else", ":", "# blobs.__class__ == model_helper.ModelHelper or something else", "\n", "                ", "_blobs", "=", "blobs", "\n", "", "return", "_blobs", "\n", "\n", "", "if", "self", ".", "ndevices", ">", "1", "and", "add_prefix", ":", "\n", "# add layer on multiple devices", "\n", "            ", "ll", "=", "[", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", ":", "\n", "# add prefix on_device", "\n", "                ", "on_device", "=", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "_inp_blobs", "=", "adjust_tag", "(", "inp_blobs", ",", "on_device", ")", "\n", "_out_blobs", "=", "adjust_tag", "(", "out_blobs", ",", "on_device", ")", "\n", "# WARNING: reset_grad option was exlusively designed for WeightedSum", "\n", "#         with inp_blobs=[w, tag_one, \"\", lr], where \"\" will be replaced", "\n", "if", "reset_grad", ":", "\n", "                    ", "w_grad", "=", "self", ".", "gradientMap", "[", "_inp_blobs", "[", "0", "]", "]", "\n", "_inp_blobs", "[", "2", "]", "=", "w_grad", "\n", "# add layer to the model", "\n", "", "with", "core", ".", "DeviceScope", "(", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", ")", ":", "\n", "                    ", "if", "kwargs", ":", "\n", "                        ", "new_layer", "=", "layer", "(", "_inp_blobs", ",", "_out_blobs", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                        ", "new_layer", "=", "layer", "(", "_inp_blobs", ",", "_out_blobs", ")", "\n", "", "", "ll", ".", "append", "(", "new_layer", ")", "\n", "", "return", "ll", "\n", "", "else", ":", "\n", "# add layer on a single device", "\n", "# WARNING: reset_grad option was exlusively designed for WeightedSum", "\n", "#          with inp_blobs=[w, tag_one, \"\", lr], where \"\" will be replaced", "\n", "            ", "if", "reset_grad", ":", "\n", "                ", "w_grad", "=", "self", ".", "gradientMap", "[", "inp_blobs", "[", "0", "]", "]", "\n", "inp_blobs", "[", "2", "]", "=", "w_grad", "\n", "# add layer to the model", "\n", "", "if", "kwargs", ":", "\n", "                ", "new_layer", "=", "layer", "(", "inp_blobs", ",", "out_blobs", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "                ", "new_layer", "=", "layer", "(", "inp_blobs", ",", "out_blobs", ")", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp": [[220, 309], ["range", "weights.append", "weights.append", "numpy.sqrt", "numpy.random.normal().astype", "numpy.sqrt", "numpy.random.normal().astype", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "layers.append", "layers.append", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "str", "str", "str", "str", "numpy.random.normal", "numpy.random.normal", "numpy.full", "numpy.full"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], ["", "", "def", "create_mlp", "(", "self", ",", "ln", ",", "sigmoid_layer", ",", "model", ",", "tag", ")", ":", "\n", "        ", "(", "tag_layer", ",", "tag_in", ",", "tag_out", ")", "=", "tag", "\n", "\n", "# build MLP layer by layer", "\n", "layers", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "ln", ".", "size", ")", ":", "\n", "            ", "n", "=", "ln", "[", "i", "-", "1", "]", "\n", "m", "=", "ln", "[", "i", "]", "\n", "\n", "# create tags", "\n", "tag_fc_w", "=", "tag_layer", "+", "\":::\"", "+", "\"fc\"", "+", "str", "(", "i", ")", "+", "\"_w\"", "\n", "tag_fc_b", "=", "tag_layer", "+", "\":::\"", "+", "\"fc\"", "+", "str", "(", "i", ")", "+", "\"_b\"", "\n", "tag_fc_y", "=", "tag_layer", "+", "\":::\"", "+", "\"fc\"", "+", "str", "(", "i", ")", "+", "\"_y\"", "\n", "tag_fc_z", "=", "tag_layer", "+", "\":::\"", "+", "\"fc\"", "+", "str", "(", "i", ")", "+", "\"_z\"", "\n", "if", "i", "==", "ln", ".", "size", "-", "1", ":", "\n", "                ", "tag_fc_z", "=", "tag_out", "\n", "", "weights", ".", "append", "(", "tag_fc_w", ")", "\n", "weights", ".", "append", "(", "tag_fc_b", ")", "\n", "\n", "# initialize the weights", "\n", "# approach 1: custom Xavier input, output or two-sided fill", "\n", "mean", "=", "0.0", "# std_dev = np.sqrt(variance)", "\n", "std_dev", "=", "np", ".", "sqrt", "(", "2", "/", "(", "m", "+", "n", ")", ")", "# np.sqrt(1 / m) # np.sqrt(1 / n)", "\n", "W", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "std_dev", ",", "size", "=", "(", "m", ",", "n", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "std_dev", "=", "np", ".", "sqrt", "(", "1", "/", "m", ")", "# np.sqrt(2 / (m + 1))", "\n", "b", "=", "np", ".", "random", ".", "normal", "(", "mean", ",", "std_dev", ",", "size", "=", "m", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "tag_fc_w", ",", "W", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "tag_fc_b", ",", "b", ")", "\n", "# approach 2: caffe2 xavier", "\n", "# W = self.AddLayerWrapper(", "\n", "#     model.param_init_net.XavierFill,", "\n", "#     [],", "\n", "#     tag_fc_w,", "\n", "#     shape=[m, n]", "\n", "# )", "\n", "# b = self.AddLayerWrapper(", "\n", "#     model.param_init_net.ConstantFill,", "\n", "#     [],", "\n", "#     tag_fc_b,", "\n", "#     shape=[m]", "\n", "# )", "\n", "\n", "# initialize the MLP's momentum for the Adagrad optimizer", "\n", "if", "self", ".", "emb_optimizer", "in", "[", "\"adagrad\"", ",", "\"rwsadagrad\"", "]", ":", "\n", "# momentum of the weights", "\n", "                ", "self", ".", "FeedBlobWrapper", "(", "\n", "\"momentum_mlp_{}_{}\"", ".", "format", "(", "tag_layer", ",", "2", "*", "i", "-", "1", ")", ",", "\n", "np", ".", "full", "(", "(", "m", ",", "n", ")", ",", "0", ",", "dtype", "=", "np", ".", "float32", ")", "\n", ")", "\n", "# momentum of the biases", "\n", "self", ".", "FeedBlobWrapper", "(", "\n", "\"momentum_mlp_{}_{}\"", ".", "format", "(", "tag_layer", ",", "2", "*", "i", ")", ",", "\n", "np", ".", "full", "(", "(", "m", ")", ",", "0", ",", "dtype", "=", "np", ".", "float32", ")", "\n", ")", "\n", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "", "if", "self", ".", "save_onnx", ":", "\n", "                ", "self", ".", "onnx_tsd", "[", "tag_fc_w", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "W", ".", "shape", ")", "\n", "self", ".", "onnx_tsd", "[", "tag_fc_b", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "b", ".", "shape", ")", "\n", "\n", "# approach 1: construct fully connected operator using model.net", "\n", "", "fc", "=", "self", ".", "AddLayerWrapper", "(", "\n", "model", ".", "net", ".", "FC", ",", "[", "tag_in", ",", "tag_fc_w", ",", "tag_fc_b", "]", ",", "tag_fc_y", "\n", ")", "\n", "# approach 2: construct fully connected operator using brew", "\n", "# https://github.com/caffe2/tutorials/blob/master/MNIST.ipynb", "\n", "# fc = brew.fc(model, layer, tag_fc_w, dim_in=m, dim_out=n)", "\n", "layers", ".", "append", "(", "fc", ")", "\n", "\n", "if", "i", "==", "sigmoid_layer", ":", "\n", "# approach 1: construct sigmoid operator using model.net", "\n", "                ", "layer", "=", "self", ".", "AddLayerWrapper", "(", "model", ".", "net", ".", "Sigmoid", ",", "tag_fc_y", ",", "tag_fc_z", ")", "\n", "# approach 2: using brew (which currently does not support sigmoid)", "\n", "# tag_sigm = tag_layer + \":::\" + \"sigmoid\" + str(i)", "\n", "# layer = brew.sigmoid(model,fc,tag_sigmoid)", "\n", "", "else", ":", "\n", "# approach 1: construct relu operator using model.net", "\n", "                ", "layer", "=", "self", ".", "AddLayerWrapper", "(", "model", ".", "net", ".", "Relu", ",", "tag_fc_y", ",", "tag_fc_z", ")", "\n", "# approach 2: using brew", "\n", "# tag_relu = tag_layer + \":::\" + \"relu\" + str(i)", "\n", "# layer = brew.relu(model,fc,tag_relu)", "\n", "", "tag_in", "=", "tag_fc_z", "\n", "layers", ".", "append", "(", "layer", ")", "\n", "\n", "# WARNING: the dependency between layers is implicit in the tags,", "\n", "# so only the last layer is added to the layers list. It will", "\n", "# later be used for interactions.", "\n", "", "return", "layers", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_emb": [[310, 399], ["range", "weights_l.append", "numpy.random.uniform().astype", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "emb_l.append", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "numpy.ones().astype", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "str", "str", "str", "str", "numpy.random.uniform", "numpy.full", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "vw_l.append", "model.net.Gather", "model.net.SparseLengthsWeightedSum", "model.net.SparseLengthsSum", "str", "numpy.full", "str", "str", "numpy.ones", "caffe2.python.core.DeviceScope", "model.net.Gather", "model.net.SparseLengthsWeightedSum", "caffe2.python.core.DeviceScope", "model.net.SparseLengthsSum", "numpy.sqrt", "caffe2.python.core.DeviceOption", "caffe2.python.core.DeviceOption", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper"], ["", "def", "create_emb", "(", "self", ",", "m", ",", "ln", ",", "model", ",", "tag", ")", ":", "\n", "        ", "(", "tag_layer", ",", "tag_in", ",", "tag_out", ")", "=", "tag", "\n", "emb_l", "=", "[", "]", "\n", "weights_l", "=", "[", "]", "\n", "vw_l", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "ln", ".", "size", ")", ":", "\n", "            ", "n", "=", "ln", "[", "i", "]", "\n", "\n", "# select device", "\n", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "", "else", ":", "\n", "                ", "d", "=", "-", "1", "\n", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "len_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_l\"", "\n", "ind_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_i\"", "\n", "tbl_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_w\"", "\n", "sum_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_z\"", "\n", "weights_l", ".", "append", "(", "tbl_s", ")", "\n", "\n", "# initialize the weights", "\n", "# approach 1a: custom", "\n", "W", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "\n", "high", "=", "np", ".", "sqrt", "(", "1", "/", "n", ")", ",", "\n", "size", "=", "(", "n", ",", "m", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# approach 1b: numpy rand", "\n", "# W = ra.rand(n, m).astype(np.float32)", "\n", "self", ".", "FeedBlobWrapper", "(", "tbl_s", ",", "W", ",", "False", ",", "device_id", "=", "d", ")", "\n", "# approach 2: caffe2 xavier", "\n", "# with core.DeviceScope(core.DeviceOption(workspace.GpuDeviceType, d)):", "\n", "#     W = model.param_init_net.XavierFill([], tbl_s, shape=[n, m])", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "\n", "# initialize the embedding's momentum for the Adagrad optimizer", "\n", "if", "self", ".", "emb_optimizer", "==", "\"adagrad\"", ":", "\n", "                ", "self", ".", "FeedBlobWrapper", "(", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", ",", "\n", "np", ".", "full", "(", "(", "n", ",", "m", ")", ",", "0", ")", ",", "add_prefix", "=", "False", ",", "device_id", "=", "d", ")", "\n", "", "elif", "self", ".", "emb_optimizer", "==", "\"rwsadagrad\"", ":", "\n", "                ", "self", ".", "FeedBlobWrapper", "(", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", ",", "\n", "np", ".", "full", "(", "(", "n", ")", ",", "0", ")", ",", "add_prefix", "=", "False", ",", "device_id", "=", "d", ")", "\n", "\n", "", "if", "self", ".", "save_onnx", ":", "\n", "                ", "self", ".", "onnx_tsd", "[", "tbl_s", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "W", ".", "shape", ")", "\n", "\n", "# create operator", "\n", "", "if", "self", ".", "weighted_pooling", "is", "not", "None", ":", "\n", "                ", "vw_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_v\"", "\n", "psw_s", "=", "on_device", "+", "tag_layer", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_s\"", "\n", "VW", "=", "np", ".", "ones", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "vw_s", ",", "VW", ",", "False", ",", "device_id", "=", "d", ")", "\n", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "                    ", "vw_l", ".", "append", "(", "vw_s", ")", "\n", "grad_on_weights", "=", "True", "\n", "", "else", ":", "\n", "                    ", "grad_on_weights", "=", "False", "\n", "", "if", "self", ".", "save_onnx", ":", "\n", "                    ", "self", ".", "onnx_tsd", "[", "vw_s", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "VW", ".", "shape", ")", "\n", "", "if", "self", ".", "ndevices", "<=", "1", ":", "\n", "                    ", "PSW", "=", "model", ".", "net", ".", "Gather", "(", "[", "vw_s", ",", "ind_s", "]", ",", "[", "psw_s", "]", ")", "\n", "EE", "=", "model", ".", "net", ".", "SparseLengthsWeightedSum", "(", "\n", "[", "tbl_s", ",", "PSW", ",", "ind_s", ",", "len_s", "]", ",", "[", "sum_s", "]", ",", "\n", "grad_on_weights", "=", "grad_on_weights", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "with", "core", ".", "DeviceScope", "(", "\n", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", ")", ":", "\n", "                        ", "PSW", "=", "model", ".", "net", ".", "Gather", "(", "[", "vw_s", ",", "ind_s", "]", ",", "[", "psw_s", "]", ")", "\n", "EE", "=", "model", ".", "net", ".", "SparseLengthsWeightedSum", "(", "\n", "[", "tbl_s", ",", "PSW", ",", "ind_s", ",", "len_s", "]", ",", "[", "sum_s", "]", ",", "\n", "grad_on_weights", "=", "grad_on_weights", "\n", ")", "\n", "", "", "", "else", ":", "\n", "                ", "if", "self", ".", "ndevices", "<=", "1", ":", "\n", "                    ", "EE", "=", "model", ".", "net", ".", "SparseLengthsSum", "(", "\n", "[", "tbl_s", ",", "ind_s", ",", "len_s", "]", ",", "[", "sum_s", "]", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "with", "core", ".", "DeviceScope", "(", "\n", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", ")", ":", "\n", "                        ", "EE", "=", "model", ".", "net", ".", "SparseLengthsSum", "(", "\n", "[", "tbl_s", ",", "ind_s", ",", "len_s", "]", ",", "[", "sum_s", "]", "\n", ")", "\n", "", "", "", "emb_l", ".", "append", "(", "EE", ")", "\n", "\n", "", "return", "emb_l", ",", "weights_l", ",", "vw_l", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_interactions": [[400, 437], ["model.net.Concat", "model.net.BatchMatMul", "model.net.Flatten", "model.net.BatchGather", "model.net.Concat", "model.net.Concat", "sys.exit"], "methods", ["None"], ["", "def", "create_interactions", "(", "self", ",", "x", ",", "ly", ",", "model", ",", "tag", ")", ":", "\n", "        ", "(", "tag_dense_in", ",", "tag_sparse_in", ",", "tag_int_out", ")", "=", "tag", "\n", "\n", "if", "self", ".", "arch_interaction_op", "==", "\"dot\"", ":", "\n", "# concatenate dense and sparse features", "\n", "            ", "tag_int_out_info", "=", "tag_int_out", "+", "\"_info\"", "\n", "T", ",", "T_info", "=", "model", ".", "net", ".", "Concat", "(", "\n", "x", "+", "ly", ",", "\n", "[", "tag_int_out", "+", "\"_cat_axis0\"", ",", "tag_int_out_info", "+", "\"_cat_axis0\"", "]", ",", "\n", "axis", "=", "1", ",", "\n", "add_axis", "=", "1", ",", "\n", ")", "\n", "# perform a dot product", "\n", "Z", "=", "model", ".", "net", ".", "BatchMatMul", "(", "[", "T", ",", "T", "]", ",", "tag_int_out", "+", "\"_matmul\"", ",", "trans_b", "=", "1", ")", "\n", "# append dense feature with the interactions (into a row vector)", "\n", "# approach 1: all", "\n", "# Zflat = model.net.Flatten(Z, tag_int_out + \"_flatten\", axis=1)", "\n", "# approach 2: unique", "\n", "Zflat_all", "=", "model", ".", "net", ".", "Flatten", "(", "Z", ",", "tag_int_out", "+", "\"_flatten_all\"", ",", "axis", "=", "1", ")", "\n", "Zflat", "=", "model", ".", "net", ".", "BatchGather", "(", "\n", "[", "Zflat_all", ",", "tag_int_out", "+", "\"_tril_indices\"", "]", ",", "\n", "tag_int_out", "+", "\"_flatten\"", "\n", ")", "\n", "R", ",", "R_info", "=", "model", ".", "net", ".", "Concat", "(", "\n", "x", "+", "[", "Zflat", "]", ",", "[", "tag_int_out", ",", "tag_int_out_info", "]", ",", "axis", "=", "1", "\n", ")", "\n", "", "elif", "self", ".", "arch_interaction_op", "==", "\"cat\"", ":", "\n", "# concatenation features (into a row vector)", "\n", "            ", "tag_int_out_info", "=", "tag_int_out", "+", "\"_info\"", "\n", "R", ",", "R_info", "=", "model", ".", "net", ".", "Concat", "(", "\n", "x", "+", "ly", ",", "[", "tag_int_out", ",", "tag_int_out_info", "]", ",", "axis", "=", "1", "\n", ")", "\n", "", "else", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: --arch-interaction-op=\"", "\n", "+", "self", ".", "arch_interaction_op", "+", "\" is not supported\"", ")", "\n", "\n", "", "return", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_sequential_forward_ops": [[438, 463], ["dlrm_s_caffe2.DLRM_Net.create_emb", "dlrm_s_caffe2.DLRM_Net.create_mlp", "dlrm_s_caffe2.DLRM_Net.create_interactions", "dlrm_s_caffe2.DLRM_Net.create_mlp"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_interactions", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp"], ["", "def", "create_sequential_forward_ops", "(", "self", ")", ":", "\n", "# embeddings", "\n", "        ", "tag", "=", "(", "self", ".", "temb", ",", "self", ".", "tsin", ",", "self", ".", "tsout", ")", "\n", "self", ".", "emb_l", ",", "self", ".", "emb_w", ",", "self", ".", "emb_vw", "=", "self", ".", "create_emb", "(", "\n", "self", ".", "m_spa", ",", "self", ".", "ln_emb", ",", "self", ".", "model", ",", "tag", "\n", ")", "\n", "# bottom mlp", "\n", "tag", "=", "(", "self", ".", "tbot", ",", "self", ".", "tdin", ",", "self", ".", "tdout", ")", "\n", "self", ".", "bot_l", ",", "self", ".", "bot_w", "=", "self", ".", "create_mlp", "(", "self", ".", "ln_bot", ",", "self", ".", "sigmoid_bot", ",", "\n", "self", ".", "model", ",", "tag", ")", "\n", "# interactions", "\n", "tag", "=", "(", "self", ".", "tdout", ",", "self", ".", "tsout", ",", "self", ".", "tint", ")", "\n", "Z", "=", "self", ".", "create_interactions", "(", "[", "self", ".", "bot_l", "[", "-", "1", "]", "]", ",", "self", ".", "emb_l", ",", "self", ".", "model", ",", "tag", ")", "\n", "\n", "# top mlp", "\n", "tag", "=", "(", "self", ".", "ttop", ",", "Z", ",", "self", ".", "tout", ")", "\n", "self", ".", "top_l", ",", "self", ".", "top_w", "=", "self", ".", "create_mlp", "(", "self", ".", "ln_top", ",", "self", ".", "sigmoid_top", ",", "\n", "self", ".", "model", ",", "tag", ")", "\n", "# debug prints", "\n", "# print(self.emb_l)", "\n", "# print(self.bot_l)", "\n", "# print(self.top_l)", "\n", "\n", "# setup the last output variable", "\n", "self", ".", "last_output", "=", "self", ".", "top_l", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_parallel_forward_ops": [[464, 531], ["dlrm_s_caffe2.DLRM_Net.create_emb", "dlrm_s_caffe2.DLRM_Net.create_mlp", "enumerate", "list", "list", "range", "dlrm_s_caffe2.DLRM_Net.create_mlp", "range", "t_list.append", "map", "map", "caffe2.python.core.DeviceScope", "dlrm_s_caffe2.DLRM_Net.model.net.Split", "len", "str().replace", "y.append", "zip", "zip", "caffe2.python.core.DeviceScope", "dlrm_s_caffe2.DLRM_Net.create_interactions", "str", "range", "caffe2.python.core.DeviceOption", "list", "list", "str", "caffe2.python.core.DeviceOption", "str", "str", "str", "caffe2.python.core.DeviceScope", "dlrm_s_caffe2.DLRM_Net.model.Copy", "caffe2.python.core.DeviceOption"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_interactions"], ["", "def", "create_parallel_forward_ops", "(", "self", ")", ":", "\n", "# distribute embeddings (model parallelism)", "\n", "        ", "tag", "=", "(", "self", ".", "temb", ",", "self", ".", "tsin", ",", "self", ".", "tsout", ")", "\n", "self", ".", "emb_l", ",", "self", ".", "emb_w", ",", "self", ".", "emb_vw", "=", "self", ".", "create_emb", "(", "\n", "self", ".", "m_spa", ",", "self", ".", "ln_emb", ",", "self", ".", "model", ",", "tag", "\n", ")", "\n", "# replicate mlp (data parallelism)", "\n", "tag", "=", "(", "self", ".", "tbot", ",", "self", ".", "tdin", ",", "self", ".", "tdout", ")", "\n", "self", ".", "bot_l", ",", "self", ".", "bot_w", "=", "self", ".", "create_mlp", "(", "self", ".", "ln_bot", ",", "self", ".", "sigmoid_bot", ",", "\n", "self", ".", "model", ",", "tag", ")", "\n", "\n", "# add communication (butterfly shuffle)", "\n", "t_list", "=", "[", "]", "\n", "for", "i", ",", "emb_output", "in", "enumerate", "(", "self", ".", "emb_l", ")", ":", "\n", "# split input", "\n", "            ", "src_d", "=", "i", "%", "self", ".", "ndevices", "\n", "lo", "=", "[", "emb_output", "+", "\"_split_\"", "+", "str", "(", "d", ")", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", "]", "\n", "# approach 1: np and caffe2 operators assume the mini-batch size is", "\n", "# divisible exactly by the number of available devices", "\n", "with", "core", ".", "DeviceScope", "(", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "src_d", ")", ")", ":", "\n", "                ", "self", ".", "model", ".", "net", ".", "Split", "(", "emb_output", ",", "lo", ",", "axis", "=", "0", ")", "\n", "", "\"\"\"\n            # approach 2: np and caffe2 operators do not assume exact divisibility\n            ls = where_to_split(args.mini_batch_size, self.ndevices, _add_leftover=True)\n            with core.DeviceScope(core.DeviceOption(workspace.GpuDeviceType, src_d)):\n                emb_output_split = self.model.net.Split(\n                    emb_output, lo, split=lp, axis=0\n                )\n            \"\"\"", "\n", "# scatter", "\n", "y", "=", "[", "]", "\n", "for", "dst_d", "in", "range", "(", "len", "(", "lo", ")", ")", ":", "\n", "                ", "src_blob", "=", "lo", "[", "dst_d", "]", "\n", "dst_blob", "=", "str", "(", "src_blob", ")", ".", "replace", "(", "\n", "\"gpu_\"", "+", "str", "(", "src_d", ")", ",", "\"gpu_\"", "+", "str", "(", "dst_d", ")", ",", "1", "\n", ")", "\n", "if", "src_blob", "!=", "dst_blob", ":", "\n", "                    ", "with", "core", ".", "DeviceScope", "(", "\n", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "dst_d", ")", "\n", ")", ":", "\n", "                        ", "blob", "=", "self", ".", "model", ".", "Copy", "(", "src_blob", ",", "dst_blob", ")", "\n", "", "", "else", ":", "\n", "                    ", "blob", "=", "dst_blob", "\n", "", "y", ".", "append", "(", "blob", ")", "\n", "", "t_list", ".", "append", "(", "y", ")", "\n", "# adjust lists to be ordered per device", "\n", "", "x", "=", "list", "(", "map", "(", "lambda", "x", ":", "list", "(", "x", ")", ",", "zip", "(", "*", "self", ".", "bot_l", ")", ")", ")", "\n", "ly", "=", "list", "(", "map", "(", "lambda", "y", ":", "list", "(", "y", ")", ",", "zip", "(", "*", "t_list", ")", ")", ")", "\n", "\n", "# interactions", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", ":", "\n", "            ", "on_device", "=", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "tag", "=", "(", "on_device", "+", "self", ".", "tdout", ",", "on_device", "+", "self", ".", "tsout", ",", "on_device", "+", "self", ".", "tint", ")", "\n", "with", "core", ".", "DeviceScope", "(", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", ")", ":", "\n", "                ", "self", ".", "create_interactions", "(", "[", "x", "[", "d", "]", "[", "-", "1", "]", "]", ",", "ly", "[", "d", "]", ",", "self", ".", "model", ",", "tag", ")", "\n", "\n", "# replicate mlp (data parallelism)", "\n", "", "", "tag", "=", "(", "self", ".", "ttop", ",", "self", ".", "tint", ",", "self", ".", "tout", ")", "\n", "self", ".", "top_l", ",", "self", ".", "top_w", "=", "self", ".", "create_mlp", "(", "self", ".", "ln_top", ",", "self", ".", "sigmoid_top", ",", "\n", "self", ".", "model", ",", "tag", ")", "\n", "\n", "# debug prints", "\n", "# print(self.model.net.Proto(),end='\\n')", "\n", "# sys.exit(\"ERROR: debugging\")", "\n", "\n", "# setup the last output variable", "\n", "self", ".", "last_output", "=", "self", ".", "top_l", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.__init__": [[532, 599], ["object.__init__", "caffe2.python.workspace.GlobalInit", "dlrm_s_caffe2.DLRM_Net.set_tags", "caffe2.python.model_helper.ModelHelper", "dlrm_s_caffe2.DLRM_Net.set_tags", "dlrm_s_caffe2.DLRM_Net.create_sequential_forward_ops", "dlrm_s_caffe2.DLRM_Net.create_parallel_forward_ops"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.set_tags", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.set_tags", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_sequential_forward_ops", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_parallel_forward_ops"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "m_spa", ",", "\n", "ln_emb", ",", "\n", "ln_bot", ",", "\n", "ln_top", ",", "\n", "arch_interaction_op", ",", "\n", "arch_interaction_itself", "=", "False", ",", "\n", "sigmoid_bot", "=", "-", "1", ",", "\n", "sigmoid_top", "=", "-", "1", ",", "\n", "save_onnx", "=", "False", ",", "\n", "model", "=", "None", ",", "\n", "test_net", "=", "None", ",", "\n", "tag", "=", "None", ",", "\n", "ndevices", "=", "-", "1", ",", "\n", "forward_ops", "=", "True", ",", "\n", "enable_prof", "=", "False", ",", "\n", "weighted_pooling", "=", "None", ",", "\n", "emb_optimizer", "=", "\"sgd\"", "\n", ")", ":", "\n", "        ", "super", "(", "DLRM_Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# init model", "\n", "if", "model", "is", "None", ":", "\n", "            ", "global_init_opt", "=", "[", "\"caffe2\"", ",", "\"--caffe2_log_level=0\"", "]", "\n", "if", "enable_prof", ":", "\n", "                ", "global_init_opt", "+=", "[", "\n", "\"--logtostderr=0\"", ",", "\n", "\"--log_dir=$HOME\"", ",", "\n", "\"--caffe2_logging_print_net_summary=1\"", ",", "\n", "]", "\n", "", "workspace", ".", "GlobalInit", "(", "global_init_opt", ")", "\n", "self", ".", "set_tags", "(", ")", "\n", "self", ".", "model", "=", "model_helper", ".", "ModelHelper", "(", "name", "=", "\"DLRM\"", ",", "init_params", "=", "True", ")", "\n", "self", ".", "test_net", "=", "None", "\n", "", "else", ":", "\n", "# WARNING: assume that workspace and tags have been initialized elsewhere", "\n", "            ", "self", ".", "set_tags", "(", "tag", "[", "0", "]", ",", "tag", "[", "1", "]", ",", "tag", "[", "2", "]", ",", "tag", "[", "3", "]", ",", "tag", "[", "4", "]", ",", "tag", "[", "5", "]", ",", "tag", "[", "6", "]", ",", "\n", "tag", "[", "7", "]", ",", "tag", "[", "8", "]", ",", "tag", "[", "9", "]", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "test_net", "=", "test_net", "\n", "\n", "# save arguments", "\n", "", "self", ".", "m_spa", "=", "m_spa", "\n", "self", ".", "ln_emb", "=", "ln_emb", "\n", "self", ".", "ln_bot", "=", "ln_bot", "\n", "self", ".", "ln_top", "=", "ln_top", "\n", "self", ".", "arch_interaction_op", "=", "arch_interaction_op", "\n", "self", ".", "arch_interaction_itself", "=", "arch_interaction_itself", "\n", "self", ".", "sigmoid_bot", "=", "sigmoid_bot", "\n", "self", ".", "sigmoid_top", "=", "sigmoid_top", "\n", "self", ".", "save_onnx", "=", "save_onnx", "\n", "self", ".", "ndevices", "=", "ndevices", "\n", "self", ".", "emb_optimizer", "=", "emb_optimizer", "\n", "if", "weighted_pooling", "is", "not", "None", "and", "weighted_pooling", "!=", "\"fixed\"", ":", "\n", "            ", "self", ".", "weighted_pooling", "=", "\"learned\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "weighted_pooling", "=", "weighted_pooling", "\n", "# onnx types and shapes dictionary", "\n", "", "if", "self", ".", "save_onnx", ":", "\n", "            ", "self", ".", "onnx_tsd", "=", "{", "}", "\n", "# create forward operators", "\n", "", "if", "forward_ops", ":", "\n", "            ", "if", "self", ".", "ndevices", "<=", "1", ":", "\n", "                ", "return", "self", ".", "create_sequential_forward_ops", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "create_parallel_forward_ops", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.set_tags": [[600, 627], ["None"], "methods", ["None"], ["", "", "", "def", "set_tags", "(", "\n", "self", ",", "\n", "_tag_layer_top_mlp", "=", "\"top\"", ",", "\n", "_tag_layer_bot_mlp", "=", "\"bot\"", ",", "\n", "_tag_layer_embedding", "=", "\"emb\"", ",", "\n", "_tag_feature_dense_in", "=", "\"dense_in\"", ",", "\n", "_tag_feature_dense_out", "=", "\"dense_out\"", ",", "\n", "_tag_feature_sparse_in", "=", "\"sparse_in\"", ",", "\n", "_tag_feature_sparse_out", "=", "\"sparse_out\"", ",", "\n", "_tag_interaction", "=", "\"interaction\"", ",", "\n", "_tag_dense_output", "=", "\"prob_click\"", ",", "\n", "_tag_dense_target", "=", "\"target\"", ",", "\n", ")", ":", "\n", "# layer tags", "\n", "        ", "self", ".", "ttop", "=", "_tag_layer_top_mlp", "\n", "self", ".", "tbot", "=", "_tag_layer_bot_mlp", "\n", "self", ".", "temb", "=", "_tag_layer_embedding", "\n", "# dense feature tags", "\n", "self", ".", "tdin", "=", "_tag_feature_dense_in", "\n", "self", ".", "tdout", "=", "_tag_feature_dense_out", "\n", "# sparse feature tags", "\n", "self", ".", "tsin", "=", "_tag_feature_sparse_in", "\n", "self", ".", "tsout", "=", "_tag_feature_sparse_out", "\n", "# output and target tags", "\n", "self", ".", "tint", "=", "_tag_interaction", "\n", "self", ".", "ttar", "=", "_tag_dense_target", "\n", "self", ".", "tout", "=", "_tag_dense_output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.parameters": [[628, 630], ["None"], "methods", ["None"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.get_loss": [[631, 633], ["dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], ["", "def", "get_loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "FetchBlobWrapper", "(", "self", ".", "loss", ",", "reduce_across", "=", "\"add\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.get_output": [[634, 636], ["dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], ["", "def", "get_output", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "FetchBlobWrapper", "(", "self", ".", "last_output", ",", "reduce_across", "=", "\"concat\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create": [[637, 640], ["dlrm_s_caffe2.DLRM_Net.create_input", "dlrm_s_caffe2.DLRM_Net.create_model"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_input", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_model"], ["", "def", "create", "(", "self", ",", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ")", ":", "\n", "        ", "self", ".", "create_input", "(", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ")", "\n", "self", ".", "create_model", "(", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_input": [[641, 674], ["dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "range", "len", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "numpy.zeros().astype", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "numpy.array", "numpy.array", "str", "str", "len", "len", "numpy.zeros", "str"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper"], ["", "def", "create_input", "(", "self", ",", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ")", ":", "\n", "# feed input data to blobs", "\n", "        ", "self", ".", "FeedBlobWrapper", "(", "self", ".", "tdin", ",", "X", ",", "split", "=", "True", ")", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "if", "self", ".", "save_onnx", ":", "\n", "            ", "self", ".", "onnx_tsd", "[", "self", ".", "tdin", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "X", ".", "shape", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "emb_l", ")", ")", ":", "\n", "# select device", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "", "else", ":", "\n", "                ", "d", "=", "-", "1", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "len_s", "=", "on_device", "+", "self", ".", "temb", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_l\"", "\n", "ind_s", "=", "on_device", "+", "self", ".", "temb", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_i\"", "\n", "self", ".", "FeedBlobWrapper", "(", "len_s", ",", "np", ".", "array", "(", "S_lengths", "[", "i", "]", ")", ",", "False", ",", "device_id", "=", "d", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "ind_s", ",", "np", ".", "array", "(", "S_indices", "[", "i", "]", ")", ",", "False", ",", "device_id", "=", "d", ")", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "if", "self", ".", "save_onnx", ":", "\n", "                ", "lshape", "=", "(", "len", "(", "S_lengths", "[", "i", "]", ")", ",", ")", "# =args.mini_batch_size", "\n", "ishape", "=", "(", "len", "(", "S_indices", "[", "i", "]", ")", ",", ")", "\n", "self", ".", "onnx_tsd", "[", "len_s", "]", "=", "(", "onnx", ".", "TensorProto", ".", "INT32", ",", "lshape", ")", "\n", "self", ".", "onnx_tsd", "[", "ind_s", "]", "=", "(", "onnx", ".", "TensorProto", ".", "INT32", ",", "ishape", ")", "\n", "\n", "# feed target data to blobs", "\n", "", "", "if", "T", "is", "not", "None", ":", "\n", "            ", "zeros_fp32", "=", "np", ".", "zeros", "(", "T", ".", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "self", ".", "ttar", ",", "zeros_fp32", ",", "split", "=", "True", ")", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "if", "self", ".", "save_onnx", ":", "\n", "                ", "self", ".", "onnx_tsd", "[", "self", ".", "ttar", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "T", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.create_model": [[675, 691], ["numpy.array", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "len", "caffe2.python.workspace.RunNetOnce", "caffe2.python.workspace.CreateNet", "caffe2.python.workspace.CreateNet", "range", "range"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper"], ["", "", "", "def", "create_model", "(", "self", ",", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ")", ":", "\n", "#setup tril indices for the interactions", "\n", "        ", "offset", "=", "1", "if", "self", ".", "arch_interaction_itself", "else", "0", "\n", "num_fea", "=", "len", "(", "self", ".", "emb_l", ")", "+", "1", "\n", "tril_indices", "=", "np", ".", "array", "(", "[", "j", "+", "i", "*", "num_fea", "\n", "for", "i", "in", "range", "(", "num_fea", ")", "for", "j", "in", "range", "(", "i", "+", "offset", ")", "]", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "self", ".", "tint", "+", "\"_tril_indices\"", ",", "tril_indices", ")", "\n", "\n", "# create compute graph", "\n", "if", "T", "is", "not", "None", ":", "\n", "# WARNING: RunNetOnce call is needed only if we use brew and ConstantFill.", "\n", "# We could use direct calls to self.model functions above to avoid it", "\n", "            ", "workspace", ".", "RunNetOnce", "(", "self", ".", "model", ".", "param_init_net", ")", "\n", "workspace", ".", "CreateNet", "(", "self", ".", "model", ".", "net", ")", "\n", "if", "self", ".", "test_net", "is", "not", "None", ":", "\n", "                ", "workspace", ".", "CreateNet", "(", "self", ".", "test_net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.run": [[692, 721], ["dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "range", "len", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "numpy.array", "numpy.array", "caffe2.python.workspace.RunNet", "str", "str", "caffe2.python.workspace.C.benchmark_net", "caffe2.python.workspace.RunNet", "str", "dlrm_s_caffe2.DLRM_Net.model.net.Name"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FeedBlobWrapper"], ["", "", "", "def", "run", "(", "self", ",", "X", ",", "S_lengths", ",", "S_indices", ",", "T", ",", "test_net", "=", "False", ",", "enable_prof", "=", "False", ")", ":", "\n", "# feed input data to blobs", "\n", "# dense features", "\n", "        ", "self", ".", "FeedBlobWrapper", "(", "self", ".", "tdin", ",", "X", ",", "split", "=", "True", ")", "\n", "# sparse features", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "emb_l", ")", ")", ":", "\n", "# select device", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "", "else", ":", "\n", "                ", "d", "=", "-", "1", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "len_s", "=", "on_device", "+", "self", ".", "temb", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_l\"", "\n", "ind_s", "=", "on_device", "+", "self", ".", "temb", "+", "\":::\"", "+", "\"sls\"", "+", "str", "(", "i", ")", "+", "\"_i\"", "\n", "self", ".", "FeedBlobWrapper", "(", "len_s", ",", "np", ".", "array", "(", "S_lengths", "[", "i", "]", ")", ",", "False", ",", "device_id", "=", "d", ")", "\n", "self", ".", "FeedBlobWrapper", "(", "ind_s", ",", "np", ".", "array", "(", "S_indices", "[", "i", "]", ")", ",", "False", ",", "device_id", "=", "d", ")", "\n", "\n", "# feed target data to blobs if needed", "\n", "", "if", "T", "is", "not", "None", ":", "\n", "            ", "self", ".", "FeedBlobWrapper", "(", "self", ".", "ttar", ",", "T", ",", "split", "=", "True", ")", "\n", "# execute compute graph", "\n", "if", "test_net", ":", "\n", "                ", "workspace", ".", "RunNet", "(", "self", ".", "test_net", ")", "\n", "", "else", ":", "\n", "                ", "if", "enable_prof", ":", "\n", "                    ", "workspace", ".", "C", ".", "benchmark_net", "(", "self", ".", "model", ".", "net", ".", "Name", "(", ")", ",", "0", ",", "1", ",", "True", ")", "\n", "", "else", ":", "\n", "                    ", "workspace", ".", "RunNet", "(", "self", ".", "model", ".", "net", ")", "\n", "# debug prints", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.MSEloss": [[728, 734], ["dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], ["", "", "", "", "def", "MSEloss", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "# add MSEloss to the model", "\n", "        ", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "SquaredL2Distance", ",", "[", "self", ".", "tout", ",", "self", ".", "ttar", "]", ",", "\"sd\"", ")", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "Scale", ",", "\"sd\"", ",", "\"sd2\"", ",", "scale", "=", "2.0", "*", "scale", ")", "\n", "# WARNING: \"loss\" is a special tag and should not be changed", "\n", "self", ".", "loss", "=", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "AveragedLoss", ",", "\"sd2\"", ",", "\"loss\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.BCEloss": [[735, 750], ["dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], ["", "def", "BCEloss", "(", "self", ",", "scale", "=", "1.0", ",", "threshold", "=", "0.0", ")", ":", "\n", "# add BCEloss to the mode", "\n", "        ", "if", "0.0", "<", "threshold", "and", "threshold", "<", "1.0", ":", "\n", "            ", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "Clip", ",", "self", ".", "tout", ",", "\"tout_c\"", ",", "\n", "min", "=", "threshold", ",", "max", "=", "(", "1.0", "-", "threshold", ")", ")", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "MakeTwoClass", ",", "\"tout_c\"", ",", "\"tout_2c\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "MakeTwoClass", ",", "self", ".", "tout", ",", "\"tout_2c\"", ")", "\n", "", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "LabelCrossEntropy", ",", "[", "\"tout_2c\"", ",", "self", ".", "ttar", "]", ",", "\"sd\"", ")", "\n", "# WARNING: \"loss\" is a special tag and should not be changed", "\n", "if", "scale", "==", "1.0", ":", "\n", "            ", "self", ".", "loss", "=", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "AveragedLoss", ",", "\"sd\"", ",", "\"loss\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "Scale", ",", "\"sd\"", ",", "\"sd2\"", ",", "scale", "=", "scale", ")", "\n", "self", ".", "loss", "=", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "AveragedLoss", ",", "\"sd2\"", ",", "\"loss\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.sgd_optimizer": [[751, 857], ["enumerate", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "enumerate", "dlrm_s_caffe2.DLRM_Net.model.AddGradientOperators", "dlrm_s_caffe2.DLRM_Net.model.AddGradientOperators", "dlrm_s_caffe2.DLRM_Net.model.NCCLAllreduce", "dlrm_s_caffe2.DLRM_Net.model.NCCLAllreduce", "dlrm_s_caffe2.DLRM_Net.model.ScatterWeightedSum", "caffe2.python.core.DeviceScope", "dlrm_s_caffe2.DLRM_Net.model.ScatterWeightedSum", "dlrm_s_caffe2.DLRM_Net.model.ScatterWeightedSum", "range", "range", "str", "caffe2.python.core.DeviceOption", "caffe2.python.core.DeviceScope", "dlrm_s_caffe2.DLRM_Net.model.ScatterWeightedSum", "str", "caffe2.python.core.DeviceOption"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], ["", "", "def", "sgd_optimizer", "(", "self", ",", "learning_rate", ",", "\n", "T", "=", "None", ",", "_gradientMap", "=", "None", ",", "sync_dense_params", "=", "True", ")", ":", "\n", "# create one, it and lr tags (or use them if already present)", "\n", "        ", "if", "T", "is", "not", "None", ":", "\n", "            ", "(", "tag_one", ",", "tag_it", ",", "tag_lr", ")", "=", "T", "\n", "", "else", ":", "\n", "            ", "(", "tag_one", ",", "tag_it", ",", "tag_lr", ")", "=", "(", "\"const_one\"", ",", "\"optim_it\"", ",", "\"optim_lr\"", ")", "\n", "\n", "# approach 1: feed values directly", "\n", "# self.FeedBlobWrapper(tag_one, np.ones(1).astype(np.float32))", "\n", "# self.FeedBlobWrapper(tag_it, np.zeros(1).astype(np.int64))", "\n", "# it = self.AddLayerWrapper(self.model.Iter, tag_it, tag_it)", "\n", "# lr = self.AddLayerWrapper(self.model.LearningRate, tag_it, tag_lr,", "\n", "#                           base_lr=-1 * learning_rate, policy=\"fixed\")", "\n", "# approach 2: use brew", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "param_init_net", ".", "ConstantFill", ",", "\n", "[", "]", ",", "tag_one", ",", "shape", "=", "[", "1", "]", ",", "value", "=", "1.0", ")", "\n", "self", ".", "AddLayerWrapper", "(", "brew", ".", "iter", ",", "self", ".", "model", ",", "tag_it", ")", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "LearningRate", ",", "tag_it", ",", "tag_lr", ",", "\n", "base_lr", "=", "-", "1", "*", "learning_rate", ",", "policy", "=", "\"fixed\"", ")", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "if", "self", ".", "save_onnx", ":", "\n", "                ", "self", ".", "onnx_tsd", "[", "tag_one", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "(", "1", ",", ")", ")", "\n", "self", ".", "onnx_tsd", "[", "tag_it", "]", "=", "(", "onnx", ".", "TensorProto", ".", "INT64", ",", "(", "1", ",", ")", ")", "\n", "\n", "# create gradient maps (or use them if already present)", "\n", "", "", "if", "_gradientMap", "is", "not", "None", ":", "\n", "            ", "self", ".", "gradientMap", "=", "_gradientMap", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "loss", ".", "__class__", "==", "list", ":", "\n", "                ", "self", ".", "gradientMap", "=", "self", ".", "model", ".", "AddGradientOperators", "(", "self", ".", "loss", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "gradientMap", "=", "self", ".", "model", ".", "AddGradientOperators", "(", "[", "self", ".", "loss", "]", ")", "\n", "\n", "# update weights", "\n", "# approach 1: builtin function", "\n", "# optimizer.build_sgd(self.model, base_learning_rate=learning_rate)", "\n", "# approach 2: custom code", "\n", "# top MLP weight and bias", "\n", "", "", "for", "w", "in", "self", ".", "top_w", ":", "\n", "# allreduce across devices if needed", "\n", "            ", "if", "sync_dense_params", "and", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "grad_blobs", "=", "[", "\n", "self", ".", "gradientMap", "[", "\"gpu_{}/\"", ".", "format", "(", "d", ")", "+", "w", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", "\n", "]", "\n", "self", ".", "model", ".", "NCCLAllreduce", "(", "grad_blobs", ",", "grad_blobs", ")", "\n", "# update weights", "\n", "", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "WeightedSum", ",", "\n", "[", "w", ",", "tag_one", ",", "\"\"", ",", "tag_lr", "]", ",", "w", ",", "reset_grad", "=", "True", ")", "\n", "# bottom MLP weight and bias", "\n", "", "for", "w", "in", "self", ".", "bot_w", ":", "\n", "# allreduce across devices if needed", "\n", "            ", "if", "sync_dense_params", "and", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "grad_blobs", "=", "[", "\n", "self", ".", "gradientMap", "[", "\"gpu_{}/\"", ".", "format", "(", "d", ")", "+", "w", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", "\n", "]", "\n", "self", ".", "model", ".", "NCCLAllreduce", "(", "grad_blobs", ",", "grad_blobs", ")", "\n", "# update weights", "\n", "", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "WeightedSum", ",", "\n", "[", "w", ",", "tag_one", ",", "\"\"", ",", "tag_lr", "]", ",", "w", ",", "reset_grad", "=", "True", ")", "\n", "# update embeddings", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "emb_w", ")", ":", "\n", "# select device", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "_tag_one", "=", "on_device", "+", "tag_one", "\n", "_tag_lr", "=", "on_device", "+", "tag_lr", "\n", "# pickup gradient", "\n", "w_grad", "=", "self", ".", "gradientMap", "[", "w", "]", "\n", "# update weights", "\n", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "with", "core", ".", "DeviceScope", "(", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", ")", ":", "\n", "                    ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "\n", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "\n", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", ")", "\n", "\n", "# update per sample weights", "\n", "", "", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "            ", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "emb_vw", ")", ":", "\n", "# select device", "\n", "                ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                    ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "_tag_one", "=", "on_device", "+", "tag_one", "\n", "_tag_lr", "=", "on_device", "+", "tag_lr", "\n", "# pickup gradient", "\n", "w_grad", "=", "self", ".", "gradientMap", "[", "w", "]", "\n", "# update weights", "\n", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                    ", "with", "core", ".", "DeviceScope", "(", "\n", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", ")", ":", "\n", "                        ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "\n", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "\n", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "\n", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.adagrad_optimizer": [[859, 1026], ["enumerate", "enumerate", "enumerate", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "dlrm_s_caffe2.DLRM_Net.model.Adagrad", "dlrm_s_caffe2.DLRM_Net.model.Adagrad", "enumerate", "dlrm_s_caffe2.DLRM_Net.model.AddGradientOperators", "dlrm_s_caffe2.DLRM_Net.model.AddGradientOperators", "dlrm_s_caffe2.DLRM_Net.model.NCCLAllreduce", "dlrm_s_caffe2.DLRM_Net.model.NCCLAllreduce", "dlrm_s_caffe2.DLRM_Net.model.Unique", "dlrm_s_caffe2.DLRM_Net.model.UnsortedSegmentSum", "dlrm_s_caffe2.DLRM_Net.adagrad_optimizer.add_optimizer"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.AddLayerWrapper"], ["", "", "", "", "def", "adagrad_optimizer", "(", "self", ",", "learning_rate", ",", "\n", "T", "=", "None", ",", "_gradientMap", "=", "None", ",", "sync_dense_params", "=", "True", ",", "\n", "epsilon", "=", "1e-10", ",", "decay_", "=", "0.0", ",", "weight_decay_", "=", "0.0", ")", ":", "\n", "# create one, it and lr tags (or use them if already present)", "\n", "        ", "if", "T", "is", "not", "None", ":", "\n", "            ", "(", "tag_one", ",", "tag_it", ",", "tag_lr", ")", "=", "T", "\n", "", "else", ":", "\n", "            ", "(", "tag_one", ",", "tag_it", ",", "tag_lr", ")", "=", "(", "\"const_one\"", ",", "\"optim_it\"", ",", "\"optim_lr\"", ")", "\n", "\n", "# approach 1: feed values directly", "\n", "# self.FeedBlobWrapper(tag_one, np.ones(1).astype(np.float32))", "\n", "# self.FeedBlobWrapper(tag_it, np.zeros(1).astype(np.int64))", "\n", "# it = self.AddLayerWrapper(self.model.Iter, tag_it, tag_it)", "\n", "# lr = self.AddLayerWrapper(self.model.LearningRate, tag_it, tag_lr,", "\n", "#                           base_lr=-1 * learning_rate, policy=\"fixed\")", "\n", "# approach 2: use brew", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "param_init_net", ".", "ConstantFill", ",", "\n", "[", "]", ",", "tag_one", ",", "shape", "=", "[", "1", "]", ",", "value", "=", "1.0", ")", "\n", "self", ".", "AddLayerWrapper", "(", "brew", ".", "iter", ",", "self", ".", "model", ",", "tag_it", ")", "\n", "self", ".", "AddLayerWrapper", "(", "self", ".", "model", ".", "LearningRate", ",", "tag_it", ",", "tag_lr", ",", "\n", "base_lr", "=", "-", "1", "*", "learning_rate", ",", "policy", "=", "\"fixed\"", ")", "\n", "# save the blob shapes for latter (only needed if onnx is requested)", "\n", "if", "self", ".", "save_onnx", ":", "\n", "                ", "self", ".", "onnx_tsd", "[", "tag_one", "]", "=", "(", "onnx", ".", "TensorProto", ".", "FLOAT", ",", "(", "1", ",", ")", ")", "\n", "self", ".", "onnx_tsd", "[", "tag_it", "]", "=", "(", "onnx", ".", "TensorProto", ".", "INT64", ",", "(", "1", ",", ")", ")", "\n", "\n", "# create gradient maps (or use them if already present)", "\n", "", "", "if", "_gradientMap", "is", "not", "None", ":", "\n", "            ", "self", ".", "gradientMap", "=", "_gradientMap", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "loss", ".", "__class__", "==", "list", ":", "\n", "                ", "self", ".", "gradientMap", "=", "self", ".", "model", ".", "AddGradientOperators", "(", "self", ".", "loss", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "gradientMap", "=", "self", ".", "model", ".", "AddGradientOperators", "(", "[", "self", ".", "loss", "]", ")", "\n", "\n", "# update weights", "\n", "# approach 1: builtin function", "\n", "# optimizer.build_sgd(self.model, base_learning_rate=learning_rate)", "\n", "# approach 2: custom code", "\n", "# top MLP weight and bias", "\n", "", "", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "top_w", ")", ":", "\n", "# allreduce across devices if needed", "\n", "            ", "if", "sync_dense_params", "and", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "grad_blobs", "=", "[", "\n", "self", ".", "gradientMap", "[", "\"gpu_{}/\"", ".", "format", "(", "d", ")", "+", "w", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", "\n", "]", "\n", "self", ".", "model", ".", "NCCLAllreduce", "(", "grad_blobs", ",", "grad_blobs", ")", "\n", "# update weights", "\n", "", "self", ".", "model", ".", "Adagrad", "(", "\n", "[", "\n", "w", ",", "\n", "\"momentum_mlp_top_{}\"", ".", "format", "(", "i", "+", "1", ")", ",", "\n", "self", ".", "gradientMap", "[", "w", "]", ",", "\n", "tag_lr", "\n", "]", ",", "\n", "[", "w", ",", "\"momentum_mlp_top_{}\"", ".", "format", "(", "i", "+", "1", ")", "]", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "decay_", "=", "decay_", ",", "\n", "weight_decay_", "=", "weight_decay_", "\n", ")", "\n", "\n", "# bottom MLP weight and bias", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "bot_w", ")", ":", "\n", "# allreduce across devices if needed", "\n", "            ", "if", "sync_dense_params", "and", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "grad_blobs", "=", "[", "\n", "self", ".", "gradientMap", "[", "\"gpu_{}/\"", ".", "format", "(", "d", ")", "+", "w", "]", "\n", "for", "d", "in", "range", "(", "self", ".", "ndevices", ")", "\n", "]", "\n", "self", ".", "model", ".", "NCCLAllreduce", "(", "grad_blobs", ",", "grad_blobs", ")", "\n", "# update weights", "\n", "", "self", ".", "model", ".", "Adagrad", "(", "\n", "[", "\n", "w", ",", "\n", "\"momentum_mlp_bot_{}\"", ".", "format", "(", "i", "+", "1", ")", ",", "\n", "self", ".", "gradientMap", "[", "w", "]", ",", "\n", "tag_lr", "\n", "]", ",", "\n", "[", "w", ",", "\"momentum_mlp_bot_{}\"", ".", "format", "(", "i", "+", "1", ")", "]", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "decay_", "=", "decay_", ",", "\n", "weight_decay_", "=", "weight_decay_", "\n", ")", "\n", "\n", "# update embeddings", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "emb_w", ")", ":", "\n", "# select device", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "_tag_one", "=", "on_device", "+", "tag_one", "\n", "_tag_lr", "=", "on_device", "+", "tag_lr", "\n", "# pickup gradient", "\n", "w_grad", "=", "self", ".", "gradientMap", "[", "w", "]", "\n", "# update weights", "\n", "def", "add_optimizer", "(", ")", ":", "\n", "                ", "self", ".", "model", ".", "Unique", "(", "\n", "w_grad", ".", "indices", ",", "\n", "[", "\"unique_w_grad_indices\"", ",", "\"remapping_w_grad_indices\"", "]", "\n", ")", "\n", "self", ".", "model", ".", "UnsortedSegmentSum", "(", "\n", "[", "w_grad", ".", "values", ",", "\"remapping_w_grad_indices\"", "]", ",", "\n", "\"unique_w_grad_values\"", "\n", ")", "\n", "\n", "if", "self", ".", "emb_optimizer", "==", "\"adagrad\"", ":", "\n", "                    ", "self", ".", "model", ".", "SparseAdagrad", "(", "\n", "[", "\n", "w", ",", "\n", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", ",", "\n", "\"unique_w_grad_indices\"", ",", "\n", "\"unique_w_grad_values\"", ",", "\n", "_tag_lr", "\n", "]", ",", "\n", "[", "w", ",", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", "]", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "decay_", "=", "decay_", ",", "\n", "weight_decay_", "=", "weight_decay_", "\n", ")", "\n", "\n", "", "elif", "self", ".", "emb_optimizer", "==", "\"rwsadagrad\"", ":", "\n", "                    ", "self", ".", "model", ".", "RowWiseSparseAdagrad", "(", "\n", "[", "\n", "w", ",", "\n", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", ",", "\n", "\"unique_w_grad_indices\"", ",", "\n", "\"unique_w_grad_values\"", ",", "\n", "_tag_lr", "\n", "]", ",", "\n", "[", "w", ",", "\"momentum_emb_{}\"", ".", "format", "(", "i", ")", "]", ",", "\n", "epsilon", "=", "epsilon", ",", "\n", "decay_", "=", "decay_", ",", "\n", "weight_decay_", "=", "weight_decay_", "\n", ")", "\n", "\n", "", "", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "with", "core", ".", "DeviceScope", "(", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", ")", ":", "\n", "                    ", "add_optimizer", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "add_optimizer", "(", ")", "\n", "\n", "# update per sample weights", "\n", "", "", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "            ", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "emb_vw", ")", ":", "\n", "# select device", "\n", "                ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                    ", "d", "=", "i", "%", "self", ".", "ndevices", "\n", "# create tags", "\n", "", "on_device", "=", "\"\"", "if", "self", ".", "ndevices", "<=", "1", "else", "\"gpu_\"", "+", "str", "(", "d", ")", "+", "\"/\"", "\n", "_tag_one", "=", "on_device", "+", "tag_one", "\n", "_tag_lr", "=", "on_device", "+", "tag_lr", "\n", "# pickup gradient", "\n", "w_grad", "=", "self", ".", "gradientMap", "[", "w", "]", "\n", "# update weights", "\n", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                    ", "with", "core", ".", "DeviceScope", "(", "\n", "core", ".", "DeviceOption", "(", "workspace", ".", "GpuDeviceType", ",", "d", ")", "\n", ")", ":", "\n", "                        ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "\n", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "\n", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "model", ".", "ScatterWeightedSum", "(", "\n", "[", "w", ",", "_tag_one", ",", "w_grad", ".", "indices", ",", "w_grad", ".", "values", ",", "_tag_lr", "]", ",", "w", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.print_all": [[1028, 1034], ["print", "enumerate", "caffe2.python.workspace.Blobs", "caffe2.python.workspace.Blobs", "print", "print", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], ["", "", "", "", "def", "print_all", "(", "self", ")", ":", "\n", "# approach 1: all", "\n", "        ", "print", "(", "workspace", ".", "Blobs", "(", ")", ",", "end", "=", "'\\n'", ")", "\n", "for", "_", ",", "l", "in", "enumerate", "(", "workspace", ".", "Blobs", "(", ")", ")", ":", "\n", "            ", "print", "(", "l", ")", "\n", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ")", ")", "\n", "# approach 2: only summary", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.print_weights": [[1039, 1059], ["enumerate", "enumerate", "enumerate", "print", "enumerate", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "print", "print", "print", "print", "print", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], ["", "", "def", "print_weights", "(", "self", ")", ":", "\n", "        ", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "emb_w", ")", ":", "\n", "# print(l)", "\n", "            ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ",", "False", ")", ")", "\n", "", "if", "self", ".", "weighted_pooling", "==", "\"learned\"", ":", "\n", "            ", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "emb_vw", ")", ":", "\n", "# print(l)", "\n", "                ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ",", "False", ")", ")", "\n", "", "", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "bot_w", ")", ":", "\n", "# print(l)", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ",", "False", ",", "device_id", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ")", ")", "\n", "", "", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "top_w", ")", ":", "\n", "# print(l)", "\n", "            ", "if", "self", ".", "ndevices", ">", "1", ":", "\n", "                ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ",", "False", ",", "device_id", "=", "0", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.print_activations": [[1060, 1072], ["enumerate", "enumerate", "print", "print", "enumerate", "print", "print", "print", "print", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "print", "print", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.DLRM_Net.FetchBlobWrapper"], ["", "", "", "def", "print_activations", "(", "self", ")", ":", "\n", "        ", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "emb_l", ")", ":", "\n", "            ", "print", "(", "l", ")", "\n", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ",", "False", ")", ")", "\n", "", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "bot_l", ")", ":", "\n", "            ", "print", "(", "l", ")", "\n", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ")", ")", "\n", "", "print", "(", "self", ".", "tint", ")", "\n", "print", "(", "self", ".", "FetchBlobWrapper", "(", "self", ".", "tint", ")", ")", "\n", "for", "_", ",", "l", "in", "enumerate", "(", "self", ".", "top_l", ")", ":", "\n", "            ", "print", "(", "l", ")", "\n", "print", "(", "self", ".", "FetchBlobWrapper", "(", "l", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.define_metrics": [[1074, 1107], ["sklearn.metrics.log_loss", "sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "numpy.round", "numpy.round", "numpy.round", "numpy.round"], "function", ["None"], ["", "", "", "def", "define_metrics", "(", ")", ":", "\n", "    ", "metrics", "=", "{", "\n", "'loss'", ":", "lambda", "y_true", ",", "y_score", ":", "\n", "sklearn", ".", "metrics", ".", "log_loss", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "y_score", ",", "\n", "labels", "=", "[", "0", ",", "1", "]", ")", ",", "\n", "'recall'", ":", "lambda", "y_true", ",", "y_score", ":", "\n", "sklearn", ".", "metrics", ".", "recall_score", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "'precision'", ":", "lambda", "y_true", ",", "y_score", ":", "\n", "sklearn", ".", "metrics", ".", "precision_score", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "'f1'", ":", "lambda", "y_true", ",", "y_score", ":", "\n", "sklearn", ".", "metrics", ".", "f1_score", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "'ap'", ":", "sklearn", ".", "metrics", ".", "average_precision_score", ",", "\n", "'roc_auc'", ":", "sklearn", ".", "metrics", ".", "roc_auc_score", ",", "\n", "'accuracy'", ":", "lambda", "y_true", ",", "y_score", ":", "\n", "sklearn", ".", "metrics", ".", "accuracy_score", "(", "\n", "y_true", "=", "y_true", ",", "\n", "y_pred", "=", "np", ".", "round", "(", "y_score", ")", "\n", ")", ",", "\n", "# 'pre_curve' : sklearn.metrics.precision_recall_curve,", "\n", "# 'roc_curve' :  sklearn.metrics.roc_curve,", "\n", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.calculate_metrics": [[1109, 1138], ["numpy.concatenate", "numpy.concatenate", "dlrm_s_caffe2.define_metrics", "define_metrics.items", "metric_function", "print"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_caffe2.define_metrics"], ["", "def", "calculate_metrics", "(", "targets", ",", "scores", ")", ":", "\n", "    ", "scores", "=", "np", ".", "concatenate", "(", "scores", ",", "axis", "=", "0", ")", "\n", "targets", "=", "np", ".", "concatenate", "(", "targets", ",", "axis", "=", "0", ")", "\n", "\n", "metrics", "=", "define_metrics", "(", ")", "\n", "\n", "# print(\"Compute time for validation metric : \", end=\"\")", "\n", "# first_it = True", "\n", "validation_results", "=", "{", "}", "\n", "for", "metric_name", ",", "metric_function", "in", "metrics", ".", "items", "(", ")", ":", "\n", "# if first_it:", "\n", "#     first_it = False", "\n", "# else:", "\n", "#     print(\", \", end=\"\")", "\n", "# metric_compute_start = time_wrap(False)", "\n", "        ", "try", ":", "\n", "            ", "validation_results", "[", "metric_name", "]", "=", "metric_function", "(", "\n", "targets", ",", "\n", "scores", "\n", ")", "\n", "", "except", "Exception", "as", "error", ":", "\n", "            ", "validation_results", "[", "metric_name", "]", "=", "-", "1", "\n", "print", "(", "\"{} in calculating {}\"", ".", "format", "(", "error", ",", "metric_name", ")", ")", "\n", "# metric_compute_end = time_wrap(False)", "\n", "# met_time = metric_compute_end - metric_compute_start", "\n", "# print(\"{} {:.4f}\".format(metric_name, 1000 * (met_time)),", "\n", "#      end=\"\")", "\n", "# print(\" ms\")", "\n", "", "", "return", "validation_results", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_start": [[21, 24], ["mlperf_logger._log_print"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger._log_print"], ["", "def", "log_start", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"log with start tag\"", "\n", "_log_print", "(", "_MLLOGGER", ".", "start", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_end": [[26, 29], ["mlperf_logger._log_print"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger._log_print"], ["", "def", "log_end", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"log with end tag\"", "\n", "_log_print", "(", "_MLLOGGER", ".", "end", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event": [[31, 34], ["mlperf_logger._log_print"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger._log_print"], ["", "def", "log_event", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"log with event tag\"", "\n", "_log_print", "(", "_MLLOGGER", ".", "event", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger._log_print": [[36, 50], ["kwargs.pop", "logger", "mlperf_logger.get_rank"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank"], ["", "def", "_log_print", "(", "logger", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"makes mlperf logger aware of distributed execution\"", "\n", "if", "'stack_offset'", "not", "in", "kwargs", ":", "\n", "        ", "kwargs", "[", "'stack_offset'", "]", "=", "3", "\n", "", "if", "'value'", "not", "in", "kwargs", ":", "\n", "        ", "kwargs", "[", "'value'", "]", "=", "None", "\n", "\n", "", "if", "kwargs", ".", "pop", "(", "'log_all_ranks'", ",", "False", ")", ":", "\n", "        ", "log", "=", "True", "\n", "", "else", ":", "\n", "        ", "log", "=", "(", "get_rank", "(", ")", "==", "0", ")", "\n", "\n", "", "if", "log", ":", "\n", "        ", "logger", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.config_logger": [[52, 56], ["mllog.config", "os.path.join", "os.path.dirname", "os.path.abspath"], "function", ["None"], ["", "", "def", "config_logger", "(", "benchmark", ")", ":", "\n", "    ", "\"initiates mlperf logger\"", "\n", "mllog", ".", "config", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "f'{benchmark}.log'", ")", ")", "\n", "_MLLOGGER", ".", "logger", ".", "propagate", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.barrier": [[58, 67], ["torch.distributed.is_available", "torch.distributed.is_initialized", "torch.distributed.all_reduce", "torch.cuda.synchronize", "torch.cuda.FloatTensor"], "function", ["None"], ["", "def", "barrier", "(", ")", ":", "\n", "    ", "\"\"\"\n    Works as a temporary distributed barrier, currently pytorch\n    doesn't implement barrier for NCCL backend.\n    Calls all_reduce on dummy tensor and synchronizes with GPU.\n    \"\"\"", "\n", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "torch", ".", "distributed", ".", "all_reduce", "(", "torch", ".", "cuda", ".", "FloatTensor", "(", "1", ")", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank": [[69, 78], ["torch.distributed.is_available", "torch.distributed.is_initialized", "torch.distributed.get_rank"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank"], ["", "", "def", "get_rank", "(", ")", ":", "\n", "    ", "\"\"\"\n    Gets distributed rank or returns zero if distributed is not initialized.\n    \"\"\"", "\n", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "rank", "=", "0", "\n", "", "return", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.mlperf_submission_log": [[80, 119], ["mlperf_logger.config_logger", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event", "mlperf_logger.log_event"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.config_logger", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.log_event"], ["", "def", "mlperf_submission_log", "(", "benchmark", ")", ":", "\n", "    ", "\"\"\"\n    Logs information needed for MLPerf submission\n    \"\"\"", "\n", "\n", "config_logger", "(", "benchmark", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_BENCHMARK", ",", "\n", "value", "=", "benchmark", ",", "\n", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_ORG", ",", "\n", "value", "=", "'reference_implementation'", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_DIVISION", ",", "\n", "value", "=", "'closed'", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_STATUS", ",", "\n", "value", "=", "'onprem'", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_PLATFORM", ",", "\n", "value", "=", "'reference_implementation'", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_ENTRY", ",", "\n", "value", "=", "\"reference_implementation\"", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_POC_NAME", ",", "\n", "value", "=", "'reference_implementation'", ")", "\n", "\n", "log_event", "(", "\n", "key", "=", "constants", ".", "SUBMISSION_POC_EMAIL", ",", "\n", "value", "=", "'reference_implementation'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.optim.rwsadagrad.RWSAdagrad.__init__": [[25, 46], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-2", ",", "lr_decay", "=", "0.0", ",", "weight_decay", "=", "0.0", ",", "initial_accumulator_value", "=", "0.0", ",", "eps", "=", "1e-10", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "lr_decay", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid lr_decay value: {}\"", ".", "format", "(", "lr_decay", ")", ")", "\n", "", "if", "not", "0.0", "<=", "weight_decay", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid weight_decay value: {}\"", ".", "format", "(", "weight_decay", ")", ")", "\n", "", "if", "not", "0.0", "<=", "initial_accumulator_value", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid initial_accumulator_value value: {}\"", ".", "format", "(", "initial_accumulator_value", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "\n", "", "self", ".", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "lr_decay", "=", "lr_decay", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "initial_accumulator_value", "=", "initial_accumulator_value", ")", "\n", "super", "(", "RWSAdagrad", ",", "self", ")", ".", "__init__", "(", "params", ",", "self", ".", "defaults", ")", "\n", "\n", "self", ".", "momentum_initialized", "=", "False", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "self", ".", "state", "[", "p", "]", "[", "'step'", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.optim.rwsadagrad.RWSAdagrad.share_memory": [[47, 55], ["state[].share_memory_", "state[].share_memory_"], "methods", ["None"], ["", "", "", "def", "share_memory", "(", "self", ")", ":", "\n", "        ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                    ", "state", "[", "'momentum'", "]", ".", "share_memory_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'sum'", "]", ".", "share_memory_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.optim.rwsadagrad.RWSAdagrad.step": [[56, 123], ["closure", "grad.coalesce.coalesce.add", "grad.coalesce.coalesce.coalesce", "grad.coalesce.coalesce._indices", "grad.coalesce.coalesce._values", "grad.coalesce.coalesce.size", "state[].addcmul_", "state[].sqrt().add_", "p.data.addcdiv_", "torch.full", "torch.full_like", "RuntimeError", "constructor", "grad.coalesce._values.numel", "rwsadagrad.RWSAdagrad.step.make_sparse"], "methods", ["None"], ["", "", "", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "self", ".", "momentum_initialized", ":", "\n", "                    ", "if", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                        ", "self", ".", "state", "[", "p", "]", "[", "'momentum'", "]", "=", "torch", ".", "full", "(", "\n", "[", "p", ".", "data", ".", "shape", "[", "0", "]", "]", ",", "\n", "self", ".", "defaults", "[", "\"initial_accumulator_value\"", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "torch", ".", "full_like", "(", "p", ".", "data", ",", "\n", "self", ".", "defaults", "[", "\"initial_accumulator_value\"", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "\n", ")", "\n", "\n", "", "", "grad", "=", "p", ".", "grad", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "if", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                        ", "raise", "RuntimeError", "(", "\"weight_decay option is not compatible with sparse gradients\"", ")", "\n", "", "grad", "=", "grad", ".", "add", "(", "group", "[", "'weight_decay'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "clr", "=", "group", "[", "'lr'", "]", "/", "(", "1.0", "+", "(", "state", "[", "'step'", "]", "-", "1.0", ")", "*", "group", "[", "'lr_decay'", "]", ")", "\n", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "grad", "=", "grad", ".", "coalesce", "(", ")", "# the update is non-linear so indices must be unique", "\n", "grad_indices", "=", "grad", ".", "_indices", "(", ")", "\n", "grad_values", "=", "grad", ".", "_values", "(", ")", "\n", "size", "=", "grad", ".", "size", "(", ")", "\n", "\n", "def", "make_sparse", "(", "values", ",", "row_wise", ")", ":", "\n", "                        ", "constructor", "=", "grad", ".", "new", "\n", "matrix_size", "=", "[", "size", "[", "0", "]", "]", "if", "row_wise", "else", "size", "\n", "return", "constructor", "(", "grad_indices", ",", "values", ",", "matrix_size", ")", "\n", "\n", "", "if", "grad_values", ".", "numel", "(", ")", ">", "0", ":", "\n", "                        ", "momentum_update", "=", "make_sparse", "(", "grad_values", ".", "pow", "(", "2", ")", ".", "mean", "(", "dim", "=", "1", ")", ",", "True", ")", "\n", "state", "[", "'momentum'", "]", ".", "add_", "(", "momentum_update", ")", "# update momentum", "\n", "std", "=", "state", "[", "'momentum'", "]", ".", "sparse_mask", "(", "momentum_update", ".", "coalesce", "(", ")", ")", "\n", "std_values", "=", "std", ".", "_values", "(", ")", ".", "sqrt_", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p", ".", "data", ".", "add_", "(", "make_sparse", "(", "grad_values", "/", "std_values", ".", "view", "(", "std_values", ".", "size", "(", ")", "[", "0", "]", ",", "1", ")", ",", "False", ")", ",", "alpha", "=", "-", "clr", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "state", "[", "'sum'", "]", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1.0", ")", "\n", "std", "=", "state", "[", "'sum'", "]", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p", ".", "data", ".", "addcdiv_", "(", "grad", ",", "std", ",", "value", "=", "-", "clr", ")", "\n", "\n", "", "", "", "self", ".", "momentum_initialized", "=", "True", "\n", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_embeddings_umap": [[82, 166], ["range", "len", "emb_l[].weight.detach().cpu().numpy", "print", "numpy.histogram", "numpy.logspace", "matplotlib.figure", "matplotlib.title", "matplotlib.hist", "matplotlib.xscale", "matplotlib.savefig", "matplotlib.close", "min", "umap.UMAP", "matplotlib.figure", "matplotlib.title", "matplotlib.savefig", "matplotlib.close", "numpy.linalg.norm", "numpy.log10", "numpy.log10", "len", "print", "umap.UMAP.fit_transform", "range", "print", "umap.UMAP.fit_transform", "len", "matplotlib.scatter", "min", "math.log", "matplotlib.scatter", "matplotlib.colorbar", "emb_l[].weight.detach().cpu", "range", "str", "len", "numpy.array", "len", "max", "len", "str", "E1.append", "math.log", "range", "str", "str", "emb_l[].weight.detach", "str", "len", "numpy.array", "str", "str", "str", "str", "str"], "function", ["None"], ["def", "visualize_embeddings_umap", "(", "emb_l", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "max_size", "=", "500000", ",", "\n", "umap_metric", "=", "\"euclidean\"", ",", "\n", "cat_counts", "=", "None", ",", "\n", "use_max_count", "=", "True", ")", ":", "\n", "\n", "    ", "for", "k", "in", "range", "(", "0", ",", "len", "(", "emb_l", ")", ")", ":", "\n", "\n", "        ", "E", "=", "emb_l", "[", "k", "]", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "print", "(", "\"umap\"", ",", "E", ".", "shape", ")", "\n", "\n", "# create histogram of norms", "\n", "bins", "=", "50", "\n", "norms", "=", "[", "np", ".", "linalg", ".", "norm", "(", "E", "[", "i", "]", ",", "ord", "=", "2", ")", "for", "i", "in", "range", "(", "0", ",", "E", ".", "shape", "[", "0", "]", ")", "]", "\n", "#        plt.hist(norms, bins = bins)", "\n", "#        plt.title(\"Cat norm hist var. \"+str(k))", "\n", "hist", ",", "bins", "=", "np", ".", "histogram", "(", "norms", ",", "bins", "=", "bins", ")", "\n", "logbins", "=", "np", ".", "logspace", "(", "np", ".", "log10", "(", "bins", "[", "0", "]", ")", ",", "np", ".", "log10", "(", "bins", "[", "-", "1", "]", ")", ",", "len", "(", "bins", ")", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "plt", ".", "title", "(", "\"Categorical norms: \"", "+", "str", "(", "k", ")", "+", "\" cardinality \"", "+", "str", "(", "len", "(", "cat_counts", "[", "k", "]", ")", ")", ")", "\n", "plt", ".", "hist", "(", "norms", ",", "bins", "=", "logbins", ")", "\n", "plt", ".", "xscale", "(", "\"log\"", ")", "\n", "#        plt.legend()", "\n", "plt", ".", "savefig", "(", "output_dir", "+", "\"/cat-norm-histogram-\"", "+", "str", "(", "k", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "if", "E", ".", "shape", "[", "0", "]", "<", "20", ":", "\n", "            ", "print", "(", "\"Skipping small embedding\"", ")", "\n", "continue", "\n", "\n", "", "n_vis", "=", "min", "(", "max_size", ",", "E", ".", "shape", "[", "0", "]", ")", "\n", "min_cnt", "=", "0", "\n", "\n", "#        reducer = umap.UMAP(random_state=42, n_neighbors=25, min_dist=0.1)", "\n", "reducer", "=", "umap", ".", "UMAP", "(", "random_state", "=", "42", ",", "metric", "=", "umap_metric", ")", "\n", "\n", "if", "use_max_count", "is", "False", "or", "n_vis", "==", "E", ".", "shape", "[", "0", "]", ":", "\n", "            ", "Y", "=", "reducer", ".", "fit_transform", "(", "E", "[", ":", "n_vis", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "\n", "# select values with couns > 1", "\n", "            ", "done", "=", "False", "\n", "min_cnt", "=", "1", "\n", "while", "done", "==", "False", ":", "\n", "                ", "el_cnt", "=", "(", "cat_counts", "[", "k", "]", ">", "min_cnt", ")", ".", "sum", "(", ")", "\n", "if", "el_cnt", "<=", "max_size", ":", "\n", "                    ", "done", "=", "True", "\n", "", "else", ":", "\n", "                    ", "min_cnt", "=", "min_cnt", "+", "1", "\n", "\n", "", "", "E1", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "E", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "cat_counts", "[", "k", "]", "[", "i", "]", ">", "min_cnt", ":", "\n", "                    ", "E1", ".", "append", "(", "E", "[", "i", ",", ":", "]", ")", "\n", "\n", "", "", "print", "(", "\"max_count_len\"", ",", "len", "(", "E1", ")", ",", "\"mincount\"", ",", "min_cnt", ")", "\n", "Y", "=", "reducer", ".", "fit_transform", "(", "np", ".", "array", "(", "E1", ")", ")", "\n", "\n", "n_vis", "=", "len", "(", "E1", ")", "\n", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "\n", "linewidth", "=", "0", "\n", "size", "=", "1", "\n", "\n", "if", "Y", ".", "shape", "[", "0", "]", "<", "2500", ":", "\n", "            ", "linewidth", "=", "1", "\n", "size", "=", "5", "\n", "\n", "", "if", "cat_counts", "is", "None", ":", "\n", "            ", "plt", ".", "scatter", "(", "-", "Y", "[", ":", ",", "0", "]", ",", "-", "Y", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "linewidth", ")", "\n", "", "else", ":", "\n", "#print(cat_counts[k])", "\n", "            ", "n_disp", "=", "min", "(", "len", "(", "cat_counts", "[", "k", "]", ")", ",", "Y", ".", "shape", "[", "0", "]", ")", "\n", "cur_max", "=", "math", ".", "log", "(", "max", "(", "cat_counts", "[", "k", "]", ")", ")", "\n", "norm_cat_count", "=", "[", "math", ".", "log", "(", "cat_counts", "[", "k", "]", "[", "i", "]", "+", "1", ")", "/", "cur_max", "for", "i", "in", "range", "(", "0", ",", "len", "(", "cat_counts", "[", "k", "]", ")", ")", "]", "\n", "plt", ".", "scatter", "(", "-", "Y", "[", "0", ":", "n_disp", ",", "0", "]", ",", "-", "Y", "[", "0", ":", "n_disp", ",", "1", "]", ",", "s", "=", "size", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "linewidth", ",", "c", "=", "np", ".", "array", "(", "norm_cat_count", ")", "[", "0", ":", "n_disp", "]", ",", "cmap", "=", "\"viridis\"", ")", "\n", "plt", ".", "colorbar", "(", ")", "\n", "\n", "", "plt", ".", "title", "(", "\"UMAP: categorical var. \"", "+", "str", "(", "k", ")", "+", "\"  (\"", "+", "str", "(", "n_vis", ")", "+", "\" of \"", "+", "str", "(", "E", ".", "shape", "[", "0", "]", ")", "+", "\", min count \"", "+", "str", "(", "min_cnt", ")", "+", "\")\"", ")", "\n", "plt", ".", "savefig", "(", "output_dir", "+", "\"/cat-\"", "+", "str", "(", "k", ")", "+", "\"-\"", "+", "str", "(", "n_vis", ")", "+", "\"-of-\"", "+", "str", "(", "E", ".", "shape", "[", "0", "]", ")", "+", "\"-umap.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_embeddings_tsne": [[168, 198], ["range", "len", "emb_l[].weight.detach().cpu", "print", "min", "sklearn.manifold.TSNE", "manifold.TSNE.fit_transform", "matplotlib.figure", "matplotlib.scatter", "matplotlib.title", "matplotlib.savefig", "matplotlib.close", "print", "emb_l[].weight.detach", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "", "def", "visualize_embeddings_tsne", "(", "emb_l", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "max_size", "=", "10000", ")", ":", "\n", "\n", "    ", "for", "k", "in", "range", "(", "0", ",", "len", "(", "emb_l", ")", ")", ":", "\n", "\n", "        ", "E", "=", "emb_l", "[", "k", "]", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "print", "(", "\"tsne\"", ",", "E", ".", "shape", ")", "\n", "\n", "if", "E", ".", "shape", "[", "0", "]", "<", "20", ":", "\n", "            ", "print", "(", "\"Skipping small embedding\"", ")", "\n", "continue", "\n", "\n", "", "n_vis", "=", "min", "(", "max_size", ",", "E", ".", "shape", "[", "0", "]", ")", "\n", "\n", "tsne", "=", "manifold", ".", "TSNE", "(", "init", "=", "\"pca\"", ",", "random_state", "=", "0", ",", "method", "=", "\"exact\"", ")", "\n", "\n", "Y", "=", "tsne", ".", "fit_transform", "(", "E", "[", ":", "n_vis", ",", ":", "]", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "\n", "linewidth", "=", "0", "\n", "if", "Y", ".", "shape", "[", "0", "]", "<", "5000", ":", "\n", "            ", "linewidth", "=", "1", "\n", "\n", "", "plt", ".", "scatter", "(", "-", "Y", "[", ":", ",", "0", "]", ",", "-", "Y", "[", ":", ",", "1", "]", ",", "s", "=", "1", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "linewidth", ")", "\n", "\n", "plt", ".", "title", "(", "\"TSNE: categorical var. \"", "+", "str", "(", "k", ")", "+", "\"  (\"", "+", "str", "(", "n_vis", ")", "+", "\" of \"", "+", "str", "(", "E", ".", "shape", "[", "0", "]", ")", "+", "\")\"", ")", "\n", "plt", ".", "savefig", "(", "output_dir", "+", "\"/cat-\"", "+", "str", "(", "k", ")", "+", "\"-\"", "+", "str", "(", "n_vis", ")", "+", "\"-of-\"", "+", "str", "(", "E", ".", "shape", "[", "0", "]", ")", "+", "\"-tsne.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.analyse_categorical_data": [[200, 258], ["len", "len", "print", "numpy.array", "print", "range", "print", "range", "print", "print", "print", "print", "print", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.legend", "matplotlib.savefig", "matplotlib.close", "int", "set", "set", "list", "l_d.append", "l_s1.append", "l_s2.append", "l_int.append", "l_rem.append", "print", "len", "len", "len", "len", "len", "len", "str", "len", "len", "len", "len", "str().zfill", "str"], "function", ["None"], ["", "", "def", "analyse_categorical_data", "(", "X_cat", ",", "n_days", "=", "10", ",", "output_dir", "=", "\"\"", ")", ":", "\n", "\n", "# analyse categorical variables", "\n", "    ", "n_vec", "=", "len", "(", "X_cat", ")", "\n", "n_cat", "=", "len", "(", "X_cat", "[", "0", "]", ")", "\n", "n_days", "=", "n_days", "\n", "\n", "print", "(", "\"n_vec\"", ",", "n_vec", ",", "\"n_cat\"", ",", "n_cat", ")", "\n", "#    for c in train_data.X_cat:", "\n", "#        print(n_cat, c)", "\n", "\n", "all_cat", "=", "np", ".", "array", "(", "X_cat", ")", "\n", "print", "(", "\"all_cat.shape\"", ",", "all_cat", ".", "shape", ")", "\n", "day_size", "=", "all_cat", ".", "shape", "[", "0", "]", "/", "n_days", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "n_cat", ")", ":", "\n", "        ", "l_d", "=", "[", "]", "\n", "l_s1", "=", "[", "]", "\n", "l_s2", "=", "[", "]", "\n", "l_int", "=", "[", "]", "\n", "l_rem", "=", "[", "]", "\n", "\n", "cat", "=", "all_cat", "[", ":", ",", "i", "]", "\n", "print", "(", "\"cat\"", ",", "i", ",", "cat", ".", "shape", ")", "\n", "for", "d", "in", "range", "(", "1", ",", "n_days", ")", ":", "\n", "            ", "offset", "=", "int", "(", "d", "*", "day_size", ")", "\n", "#print(offset)", "\n", "cat1", "=", "cat", "[", ":", "offset", "]", "\n", "cat2", "=", "cat", "[", "offset", ":", "]", "\n", "\n", "s1", "=", "set", "(", "cat1", ")", "\n", "s2", "=", "set", "(", "cat2", ")", "\n", "\n", "intersect", "=", "list", "(", "s1", "&", "s2", ")", "\n", "#print(intersect)", "\n", "l_d", ".", "append", "(", "d", ")", "\n", "l_s1", ".", "append", "(", "len", "(", "s1", ")", ")", "\n", "l_s2", ".", "append", "(", "len", "(", "s2", ")", ")", "\n", "l_int", ".", "append", "(", "len", "(", "intersect", ")", ")", "\n", "l_rem", ".", "append", "(", "(", "len", "(", "s1", ")", "-", "len", "(", "intersect", ")", ")", ")", "\n", "\n", "print", "(", "d", ",", "\",\"", ",", "len", "(", "s1", ")", ",", "\",\"", ",", "len", "(", "s2", ")", ",", "\",\"", ",", "len", "(", "intersect", ")", ",", "\",\"", ",", "(", "len", "(", "s1", ")", "-", "len", "(", "intersect", ")", ")", ")", "\n", "\n", "", "print", "(", "\"spit\"", ",", "l_d", ")", "\n", "print", "(", "\"before\"", ",", "l_s1", ")", "\n", "print", "(", "\"after\"", ",", "l_s2", ")", "\n", "print", "(", "\"inters.\"", ",", "l_int", ")", "\n", "print", "(", "\"removed\"", ",", "l_rem", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "plt", ".", "plot", "(", "l_d", ",", "l_s1", ",", "\"g\"", ",", "label", "=", "\"before\"", ")", "\n", "plt", ".", "plot", "(", "l_d", ",", "l_s2", ",", "\"r\"", ",", "label", "=", "\"after\"", ")", "\n", "plt", ".", "plot", "(", "l_d", ",", "l_int", ",", "\"b\"", ",", "label", "=", "\"intersect\"", ")", "\n", "plt", ".", "plot", "(", "l_d", ",", "l_rem", ",", "\"y\"", ",", "label", "=", "\"removed\"", ")", "\n", "plt", ".", "title", "(", "\"categorical var. \"", "+", "str", "(", "i", ")", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "savefig", "(", "output_dir", "+", "\"/cat-\"", "+", "str", "(", "i", ")", ".", "zfill", "(", "3", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.analyse_categorical_counts": [[260, 316], ["len", "len", "print", "numpy.array", "print", "range", "range", "all_counts.append", "matplotlib.savefig", "matplotlib.close", "set", "numpy.zeros", "print", "numpy.zeros", "print", "int", "matplotlib.figure", "matplotlib.plot", "matplotlib.title", "emb_l[].weight.detach().cpu().numpy", "matplotlib.subplots", "fig.suptitle", "ax0.plot", "ax0.set_yscale", "ax0.set_title", "ax1.plot", "ax1.set_title", "len", "len", "numpy.linalg.norm", "emb_l[].weight.detach().cpu", "str", "emb_l[].weight.detach().cpu", "range", "str", "str().zfill", "len", "len", "emb_l[].weight.detach", "str", "emb_l[].weight.detach", "str", "str"], "function", ["None"], ["", "", "def", "analyse_categorical_counts", "(", "X_cat", ",", "emb_l", "=", "None", ",", "output_dir", "=", "\"\"", ")", ":", "\n", "\n", "# analyse categorical variables", "\n", "    ", "n_vec", "=", "len", "(", "X_cat", ")", "\n", "n_cat", "=", "len", "(", "X_cat", "[", "0", "]", ")", "\n", "\n", "print", "(", "\"n_vec\"", ",", "n_vec", ",", "\"n_cat\"", ",", "n_cat", ")", "\n", "#    for c in train_data.X_cat:", "\n", "#        print(n_cat, c)", "\n", "\n", "all_cat", "=", "np", ".", "array", "(", "X_cat", ")", "\n", "print", "(", "\"all_cat.shape\"", ",", "all_cat", ".", "shape", ")", "\n", "\n", "all_counts", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "n_cat", ")", ":", "\n", "\n", "        ", "cat", "=", "all_cat", "[", ":", ",", "i", "]", "\n", "if", "emb_l", "is", "None", ":", "\n", "            ", "s", "=", "set", "(", "cat", ")", "\n", "counts", "=", "np", ".", "zeros", "(", "(", "len", "(", "s", ")", ")", ")", "\n", "print", "(", "\"cat\"", ",", "i", ",", "cat", ".", "shape", ",", "len", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "            ", "s", "=", "emb_l", "[", "i", "]", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "shape", "[", "0", "]", "\n", "counts", "=", "np", ".", "zeros", "(", "(", "s", ")", ")", "\n", "print", "(", "\"cat\"", ",", "i", ",", "cat", ".", "shape", ",", "s", ")", "\n", "\n", "", "for", "d", "in", "range", "(", "0", ",", "n_vec", ")", ":", "\n", "            ", "cv", "=", "int", "(", "cat", "[", "d", "]", ")", "\n", "counts", "[", "cv", "]", "=", "counts", "[", "cv", "]", "+", "1", "\n", "\n", "", "all_counts", ".", "append", "(", "counts", ")", "\n", "\n", "if", "emb_l", "is", "None", ":", "\n", "            ", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "plt", ".", "plot", "(", "counts", ")", "\n", "plt", ".", "title", "(", "\"Categorical var \"", "+", "str", "(", "i", ")", "+", "\" cardinality \"", "+", "str", "(", "len", "(", "counts", ")", ")", ")", "\n", "#        plt.legend()", "\n", "", "else", ":", "\n", "            ", "E", "=", "emb_l", "[", "i", "]", ".", "weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "norms", "=", "[", "np", ".", "linalg", ".", "norm", "(", "E", "[", "i", "]", ",", "ord", "=", "2", ")", "for", "i", "in", "range", "(", "0", ",", "E", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "fig", ",", "(", "ax0", ",", "ax1", ")", "=", "plt", ".", "subplots", "(", "2", ",", "1", ")", "\n", "fig", ".", "suptitle", "(", "\"Categorical variable: \"", "+", "str", "(", "i", ")", "+", "\" cardinality \"", "+", "str", "(", "len", "(", "counts", ")", ")", ")", "\n", "\n", "ax0", ".", "plot", "(", "counts", ")", "\n", "ax0", ".", "set_yscale", "(", "\"log\"", ")", "\n", "ax0", ".", "set_title", "(", "\"Counts\"", ",", "fontsize", "=", "10", ")", "\n", "\n", "ax1", ".", "plot", "(", "norms", ")", "\n", "ax1", ".", "set_title", "(", "\"Norms\"", ",", "fontsize", "=", "10", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "output_dir", "+", "\"/cat_counts-\"", "+", "str", "(", "i", ")", ".", "zfill", "(", "3", ")", "+", "\".png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "", "return", "all_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.dlrm_output_wrap": [[318, 401], ["len", "dlrm.apply_mlp", "x[].detach().cpu().numpy", "np.concatenate.append", "dlrm.apply_emb", "numpy.concatenate", "numpy.concatenate", "int", "dlrm.interact_features", "z_out.append", "range", "int", "np.concatenate.append", "np.concatenate.append", "torch.clamp.detach().cpu().numpy().flatten", "z_out.append", "torch.clamp", "int", "x[].detach().cpu", "e[].detach().cpu().numpy", "e[].detach().cpu().numpy", "T.detach().cpu().numpy", "torch.clamp.detach().cpu().numpy().flatten", "torch.clamp.detach().cpu().numpy", "torch.clamp.detach().cpu().numpy", "x[].detach", "e[].detach().cpu", "e[].detach().cpu", "T.detach().cpu", "torch.clamp.detach().cpu().numpy", "torch.clamp.detach().cpu", "torch.clamp.detach().cpu", "e[].detach", "e[].detach", "T.detach", "torch.clamp.detach().cpu", "torch.clamp.detach", "torch.clamp.detach", "torch.clamp.detach"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_mlp", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.apply_emb", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.dlrm_s_pytorch.DLRM_Net.interact_features"], ["", "def", "dlrm_output_wrap", "(", "dlrm", ",", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", ":", "\n", "\n", "    ", "all_feat_vec", "=", "[", "]", "\n", "all_cat_vec", "=", "[", "]", "\n", "x_vec", "=", "None", "\n", "t_out", "=", "None", "\n", "c_out", "=", "None", "\n", "z_out", "=", "[", "]", "\n", "p_out", "=", "None", "\n", "\n", "z_size", "=", "len", "(", "dlrm", ".", "top_l", ")", "\n", "\n", "x", "=", "dlrm", ".", "apply_mlp", "(", "X", ",", "dlrm", ".", "bot_l", ")", "\n", "# debug prints", "\n", "#print(\"intermediate\")", "\n", "#print(x[0].detach().cpu().numpy())", "\n", "x_vec", "=", "x", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "all_feat_vec", ".", "append", "(", "x_vec", ")", "\n", "#    all_X.append(x[0].detach().cpu().numpy())", "\n", "\n", "# process sparse features(using embeddings), resulting in a list of row vectors", "\n", "ly", "=", "dlrm", ".", "apply_emb", "(", "lS_o", ",", "lS_i", ",", "dlrm", ".", "emb_l", ")", "\n", "\n", "for", "e", "in", "ly", ":", "\n", "#print(e.detach().cpu().numpy())", "\n", "        ", "all_feat_vec", ".", "append", "(", "e", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "all_cat_vec", ".", "append", "(", "e", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "all_feat_vec", "=", "np", ".", "concatenate", "(", "all_feat_vec", ",", "axis", "=", "0", ")", "\n", "all_cat_vec", "=", "np", ".", "concatenate", "(", "all_cat_vec", ",", "axis", "=", "0", ")", "\n", "\n", "#    all_features.append(all_feat_vec)", "\n", "#    all_cat.append(all_cat_vec)", "\n", "t_out", "=", "int", "(", "T", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "0", "]", ")", "\n", "#    all_T.append(int(T.detach().cpu().numpy()[0,0]))", "\n", "\n", "z", "=", "dlrm", ".", "interact_features", "(", "x", ",", "ly", ")", "\n", "# print(z.detach().cpu().numpy())", "\n", "#    z_out = z.detach().cpu().numpy().flatten()", "\n", "z_out", ".", "append", "(", "z", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ")", "\n", "#    all_z[0].append(z.detach().cpu().numpy().flatten())", "\n", "\n", "# obtain probability of a click (using top mlp)", "\n", "#        print(dlrm.top_l)", "\n", "#        p = dlrm.apply_mlp(z, dlrm.top_l)", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "z_size", ")", ":", "\n", "        ", "z", "=", "dlrm", ".", "top_l", "[", "i", "]", "(", "z", ")", "\n", "\n", "#        if i < z_size-1:", "\n", "#            curr_z = z.detach().cpu().numpy().flatten()", "\n", "z_out", ".", "append", "(", "z", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", ")", "\n", "#            all_z[i+1].append(curr_z)", "\n", "#            print(\"z append\", i)", "\n", "\n", "#        print(\"z\",i, z.detach().cpu().numpy().flatten().shape)", "\n", "\n", "", "p", "=", "z", "\n", "\n", "# clamp output if needed", "\n", "if", "0.0", "<", "dlrm", ".", "loss_threshold", "and", "dlrm", ".", "loss_threshold", "<", "1.0", ":", "\n", "        ", "z", "=", "torch", ".", "clamp", "(", "p", ",", "min", "=", "dlrm", ".", "loss_threshold", ",", "max", "=", "(", "1.0", "-", "dlrm", ".", "loss_threshold", ")", ")", "\n", "", "else", ":", "\n", "        ", "z", "=", "p", "\n", "\n", "", "class_thresh", "=", "0.0", "#-0.25", "\n", "zp", "=", "z", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "0", "]", "+", "class_thresh", "\n", "\n", "p_out", "=", "int", "(", "zp", "+", "0.5", ")", "\n", "if", "p_out", ">", "1", ":", "\n", "        ", "p_out", "=", "1", "\n", "", "if", "p_out", "<", "0", ":", "\n", "        ", "p_out", "=", "0", "\n", "\n", "#    all_pred.append(int(z.detach().cpu().numpy()[0,0]+0.5))", "\n", "\n", "#print(int(z.detach().cpu().numpy()[0,0]+0.5))", "\n", "", "if", "int", "(", "p_out", ")", "==", "t_out", ":", "\n", "        ", "c_out", "=", "0", "\n", "", "else", ":", "\n", "        ", "c_out", "=", "1", "\n", "\n", "", "return", "all_feat_vec", ",", "x_vec", ",", "all_cat_vec", ",", "t_out", ",", "c_out", ",", "z_out", ",", "p_out", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.create_umap_data": [[403, 447], ["len", "print", "range", "enumerate", "sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "print", "all_z.append", "visualize.dlrm_output_wrap", "all_features.append", "all_X.append", "all_cat.append", "all_T.append", "all_c.append", "all_pred.append", "range", "all_z[].append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.dlrm_output_wrap"], ["", "def", "create_umap_data", "(", "dlrm", ",", "data_ld", ",", "max_size", "=", "50000", ",", "offset", "=", "0", ",", "info", "=", "\"\"", ")", ":", "\n", "\n", "    ", "all_features", "=", "[", "]", "\n", "all_X", "=", "[", "]", "\n", "all_cat", "=", "[", "]", "\n", "all_T", "=", "[", "]", "\n", "all_c", "=", "[", "]", "\n", "all_z", "=", "[", "]", "\n", "all_pred", "=", "[", "]", "\n", "\n", "z_size", "=", "len", "(", "dlrm", ".", "top_l", ")", "\n", "print", "(", "\"z_size\"", ",", "z_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "z_size", ")", ":", "\n", "        ", "all_z", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "for", "j", ",", "(", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", "in", "enumerate", "(", "data_ld", ")", ":", "\n", "\n", "        ", "if", "j", "<", "offset", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "j", ">=", "max_size", "+", "offset", ":", "\n", "            ", "break", "\n", "\n", "", "af", ",", "x", ",", "cat", ",", "t", ",", "c", ",", "z", ",", "p", "=", "dlrm_output_wrap", "(", "dlrm", ",", "X", ",", "lS_o", ",", "lS_i", ",", "T", ")", "\n", "\n", "all_features", ".", "append", "(", "af", ")", "\n", "all_X", ".", "append", "(", "x", ")", "\n", "all_cat", ".", "append", "(", "cat", ")", "\n", "all_T", ".", "append", "(", "t", ")", "\n", "all_c", ".", "append", "(", "c", ")", "\n", "all_pred", ".", "append", "(", "p", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "z_size", ")", ":", "\n", "            ", "all_z", "[", "i", "]", ".", "append", "(", "z", "[", "i", "]", ")", "\n", "\n", "#    # calculate classifier metrics ", "\n", "", "", "ac", "=", "accuracy_score", "(", "all_T", ",", "all_pred", ")", "\n", "f1", "=", "f1_score", "(", "all_T", ",", "all_pred", ")", "\n", "ps", "=", "precision_score", "(", "all_T", ",", "all_pred", ")", "\n", "rc", "=", "recall_score", "(", "all_T", ",", "all_pred", ")", "\n", "\n", "print", "(", "info", ",", "\"accuracy\"", ",", "ac", ",", "\"f1\"", ",", "f1", ",", "\"precision\"", ",", "ps", ",", "\"recall\"", ",", "rc", ")", "\n", "\n", "return", "all_features", ",", "all_X", ",", "all_cat", ",", "all_T", ",", "all_z", ",", "all_c", ",", "all_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_all_data_3": [[449, 480], ["matplotlib.subplots", "fig.suptitle", "ax0.scatter", "ax0.set_title", "matplotlib.savefig", "matplotlib.close", "ax1.scatter", "ax1.set_title", "ax2.scatter", "ax2.set_title", "str", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "str", "len", "str", "str", "len", "len"], "function", ["None"], ["", "def", "plot_all_data_3", "(", "umap_Y", ",", "\n", "umap_T", ",", "\n", "train_Y", "=", "None", ",", "\n", "train_T", "=", "None", ",", "\n", "test_Y", "=", "None", ",", "\n", "test_T", "=", "None", ",", "\n", "total_train_size", "=", "\"\"", ",", "\n", "total_test_size", "=", "\"\"", ",", "\n", "info", "=", "\"\"", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "orig_space_dim", "=", "0", ")", ":", "\n", "\n", "    ", "size", "=", "1", "\n", "colors", "=", "[", "\"red\"", ",", "\"green\"", "]", "\n", "\n", "fig", ",", "(", "ax0", ",", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "1", ",", "3", ")", "\n", "fig", ".", "suptitle", "(", "\"UMAP: \"", "+", "info", "+", "\" space dim \"", "+", "str", "(", "orig_space_dim", ")", ")", "\n", "\n", "ax0", ".", "scatter", "(", "umap_Y", "[", ":", ",", "0", "]", ",", "umap_Y", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "umap_T", ",", "cmap", "=", "matplotlib", ".", "colors", ".", "ListedColormap", "(", "colors", ")", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax0", ".", "set_title", "(", "\"UMAP (\"", "+", "str", "(", "len", "(", "umap_T", ")", ")", "+", "\" of \"", "+", "total_train_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "if", "train_Y", "is", "not", "None", "and", "train_T", "is", "not", "None", ":", "\n", "        ", "ax1", ".", "scatter", "(", "train_Y", "[", ":", ",", "0", "]", ",", "train_Y", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "train_T", ",", "cmap", "=", "matplotlib", ".", "colors", ".", "ListedColormap", "(", "colors", ")", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax1", ".", "set_title", "(", "\"Train (\"", "+", "str", "(", "len", "(", "train_T", ")", ")", "+", "\" of \"", "+", "total_train_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "", "if", "test_Y", "is", "not", "None", "and", "test_T", "is", "not", "None", ":", "\n", "        ", "ax2", ".", "scatter", "(", "test_Y", "[", ":", ",", "0", "]", ",", "test_Y", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "test_T", ",", "cmap", "=", "matplotlib", ".", "colors", ".", "ListedColormap", "(", "colors", ")", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax2", ".", "set_title", "(", "\"Test (\"", "+", "str", "(", "len", "(", "test_T", ")", ")", "+", "\" of \"", "+", "total_test_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "output_dir", "+", "\"/\"", "+", "info", "+", "\"-umap.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3": [[482, 523], ["matplotlib.subplots", "fig.suptitle", "numpy.array", "ax0.scatter", "ax0.set_title", "matplotlib.savefig", "matplotlib.close", "numpy.array", "ax1.scatter", "ax1.set_title", "numpy.array", "ax2.scatter", "ax2.set_title", "str", "enumerate", "enumerate", "enumerate", "str", "len", "str", "str", "len", "len"], "function", ["None"], ["", "def", "plot_one_class_3", "(", "umap_Y", ",", "\n", "umap_T", ",", "\n", "train_Y", ",", "\n", "train_T", ",", "\n", "test_Y", ",", "\n", "test_T", ",", "\n", "target", "=", "0", ",", "\n", "col", "=", "\"red\"", ",", "\n", "total_train_size", "=", "\"\"", ",", "\n", "total_test_size", "=", "\"\"", ",", "\n", "info", "=", "\"\"", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "orig_space_dim", "=", "0", ")", ":", "\n", "\n", "    ", "size", "=", "1", "\n", "\n", "fig", ",", "(", "ax0", ",", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "1", ",", "3", ")", "\n", "fig", ".", "suptitle", "(", "\"UMAP: \"", "+", "info", "+", "\" space dim \"", "+", "str", "(", "orig_space_dim", ")", ")", "\n", "\n", "ind_l_umap", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "umap_T", ")", "if", "x", "==", "target", "]", "\n", "Y_umap_l", "=", "np", ".", "array", "(", "[", "umap_Y", "[", "i", ",", ":", "]", "for", "i", "in", "ind_l_umap", "]", ")", "\n", "\n", "ax0", ".", "scatter", "(", "Y_umap_l", "[", ":", ",", "0", "]", ",", "Y_umap_l", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "col", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax0", ".", "set_title", "(", "\"UMAP, (\"", "+", "str", "(", "len", "(", "umap_T", ")", ")", "+", "\" of \"", "+", "total_train_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "if", "train_Y", "is", "not", "None", "and", "train_T", "is", "not", "None", ":", "\n", "        ", "ind_l_test", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "train_T", ")", "if", "x", "==", "target", "]", "\n", "Y_test_l", "=", "np", ".", "array", "(", "[", "train_Y", "[", "i", ",", ":", "]", "for", "i", "in", "ind_l_test", "]", ")", "\n", "\n", "ax1", ".", "scatter", "(", "Y_test_l", "[", ":", ",", "0", "]", ",", "Y_test_l", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "col", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax1", ".", "set_title", "(", "\"Train, (\"", "+", "str", "(", "len", "(", "train_T", ")", ")", "+", "\" of \"", "+", "total_train_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "", "if", "test_Y", "is", "not", "None", "and", "test_T", "is", "not", "None", ":", "\n", "        ", "ind_l_test", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "test_T", ")", "if", "x", "==", "target", "]", "\n", "Y_test_l", "=", "np", ".", "array", "(", "[", "test_Y", "[", "i", ",", ":", "]", "for", "i", "in", "ind_l_test", "]", ")", "\n", "\n", "ax2", ".", "scatter", "(", "Y_test_l", "[", ":", ",", "0", "]", ",", "Y_test_l", "[", ":", ",", "1", "]", ",", "s", "=", "size", ",", "c", "=", "col", ",", "marker", "=", "\".\"", ",", "linewidth", "=", "0", ")", "\n", "ax2", ".", "set_title", "(", "\"Test, (\"", "+", "str", "(", "len", "(", "test_T", ")", ")", "+", "\" of \"", "+", "total_test_size", "+", "\")\"", ",", "fontsize", "=", "7", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "output_dir", "+", "\"/\"", "+", "info", "+", "\"-umap.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_umap_data": [[525, 659], ["visualize.plot_all_data_3", "visualize.plot_all_data_3", "visualize.plot_one_class_3", "visualize.plot_one_class_3", "visualize.plot_one_class_3", "visualize.plot_one_class_3", "visualize.plot_one_class_3", "visualize.plot_one_class_3", "str", "str"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_all_data_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_all_data_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.plot_one_class_3"], ["", "def", "visualize_umap_data", "(", "umap_Y", ",", "\n", "umap_T", ",", "\n", "umap_C", ",", "\n", "umap_P", ",", "\n", "train_Y", ",", "\n", "train_T", ",", "\n", "train_C", ",", "\n", "train_P", ",", "\n", "test_Y", "=", "None", ",", "\n", "test_T", "=", "None", ",", "\n", "test_C", "=", "None", ",", "\n", "test_P", "=", "None", ",", "\n", "total_train_size", "=", "\"\"", ",", "\n", "total_test_size", "=", "\"\"", ",", "\n", "info", "=", "\"\"", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "orig_space_dim", "=", "0", ")", ":", "\n", "\n", "# all classes", "\n", "    ", "plot_all_data_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_T", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# all predictions", "\n", "plot_all_data_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_P", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_P", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_P", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\", all-predictions\"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "\n", "# class 0", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_T", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "target", "=", "0", ",", "\n", "col", "=", "\"red\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" class \"", "+", "str", "(", "0", ")", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# class 1", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_T", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "target", "=", "1", ",", "\n", "col", "=", "\"green\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" class \"", "+", "str", "(", "1", ")", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# correct classification", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_C", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_C", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_C", ",", "\n", "target", "=", "0", ",", "\n", "col", "=", "\"green\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" correct \"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# errors", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_C", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_C", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_C", ",", "\n", "target", "=", "1", ",", "\n", "col", "=", "\"red\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" errors \"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# prediction 0", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_P", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_P", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_P", ",", "\n", "target", "=", "0", ",", "\n", "col", "=", "\"red\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" predict-0 \"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n", "# prediction 1", "\n", "plot_one_class_3", "(", "umap_Y", "=", "umap_Y", ",", "\n", "umap_T", "=", "umap_P", ",", "\n", "train_Y", "=", "train_Y", ",", "\n", "train_T", "=", "train_P", ",", "\n", "test_Y", "=", "test_Y", ",", "\n", "test_T", "=", "test_P", ",", "\n", "target", "=", "1", ",", "\n", "col", "=", "\"green\"", ",", "\n", "total_train_size", "=", "total_train_size", ",", "\n", "total_test_size", "=", "total_test_size", ",", "\n", "info", "=", "info", "+", "\" predict-1 \"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "orig_space_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.hdbscan_clustering": [[660, 723], ["hdbscan.HDBSCAN", "hdbscan.HDBSCAN.fit_predict", "hdbscan.approximate_predict", "hdbscan.approximate_predict", "matplotlib.subplots", "fig.suptitle", "collections.Counter", "print", "ax00.scatter", "ax00.set_title", "ax10.scatter", "ax10.set_title", "collections.Counter", "ax01.scatter", "ax01.set_title", "ax11.scatter", "ax11.set_title", "collections.Counter", "ax02.scatter", "ax02.set_title", "ax12.scatter", "ax12.set_title", "matplotlib.savefig", "matplotlib.close", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "hdbscan_clustering", "(", "umap_data", ",", "train_data", ",", "test_data", ",", "info", "=", "\"\"", ",", "output_dir", "=", "\"\"", ")", ":", "\n", "\n", "    ", "clusterer", "=", "hdbscan", ".", "HDBSCAN", "(", "min_samples", "=", "10", ",", "min_cluster_size", "=", "500", ",", "prediction_data", "=", "True", ")", "\n", "umap_labels", "=", "clusterer", ".", "fit_predict", "(", "umap_data", ")", "\n", "train_labels", ",", "_", "=", "hdbscan", ".", "approximate_predict", "(", "clusterer", ",", "train_data", ")", "\n", "test_labels", ",", "_", "=", "hdbscan", ".", "approximate_predict", "(", "clusterer", ",", "test_data", ")", "\n", "\n", "fig", ",", "(", "(", "ax00", ",", "ax01", ",", "ax02", ")", ",", "(", "ax10", ",", "ax11", ",", "ax12", ")", ")", "=", "plt", ".", "subplots", "(", "2", ",", "3", ")", "\n", "fig", ".", "suptitle", "(", "\"HDBSCAN clastering: \"", "+", "info", ")", "\n", "\n", "# plot umap data", "\n", "umap_clustered", "=", "(", "umap_labels", ">=", "0", ")", "\n", "umap_coll", "=", "collections", ".", "Counter", "(", "umap_clustered", ")", "\n", "print", "(", "\"umap_clustered\"", ",", "umap_coll", ")", "\n", "#    print(\"umap_data\", umap_data.shape)", "\n", "#    print(\"~umap_clustered\", umap_clustered.count(False), ~umap_clustered)", "\n", "ax00", ".", "scatter", "(", "umap_data", "[", "~", "umap_clustered", ",", "0", "]", ",", "\n", "umap_data", "[", "~", "umap_clustered", ",", "1", "]", ",", "\n", "c", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "s", "=", "0.1", ",", "\n", "alpha", "=", "0.5", ")", "\n", "ax00", ".", "set_title", "(", "\"UMAP Outliers \"", "+", "str", "(", "umap_coll", "[", "False", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "ax10", ".", "scatter", "(", "umap_data", "[", "umap_clustered", ",", "0", "]", ",", "\n", "umap_data", "[", "umap_clustered", ",", "1", "]", ",", "\n", "c", "=", "umap_labels", "[", "umap_clustered", "]", ",", "\n", "s", "=", "0.1", ",", "\n", "cmap", "=", "\"Spectral\"", ")", "\n", "ax10", ".", "set_title", "(", "\"UMAP Inliers \"", "+", "str", "(", "umap_coll", "[", "True", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "\n", "# plot train data", "\n", "train_clustered", "=", "(", "train_labels", ">=", "0", ")", "\n", "train_coll", "=", "collections", ".", "Counter", "(", "train_clustered", ")", "\n", "ax01", ".", "scatter", "(", "train_data", "[", "~", "train_clustered", ",", "0", "]", ",", "\n", "train_data", "[", "~", "train_clustered", ",", "1", "]", ",", "\n", "c", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "s", "=", "0.1", ",", "\n", "alpha", "=", "0.5", ")", "\n", "ax01", ".", "set_title", "(", "\"Train Outliers \"", "+", "str", "(", "train_coll", "[", "False", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "ax11", ".", "scatter", "(", "train_data", "[", "train_clustered", ",", "0", "]", ",", "\n", "train_data", "[", "train_clustered", ",", "1", "]", ",", "\n", "c", "=", "train_labels", "[", "train_clustered", "]", ",", "\n", "s", "=", "0.1", ",", "\n", "cmap", "=", "\"Spectral\"", ")", "\n", "ax11", ".", "set_title", "(", "\"Train Inliers \"", "+", "str", "(", "train_coll", "[", "True", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "\n", "# plot test data", "\n", "test_clustered", "=", "(", "test_labels", ">=", "0", ")", "\n", "test_coll", "=", "collections", ".", "Counter", "(", "test_clustered", ")", "\n", "ax02", ".", "scatter", "(", "test_data", "[", "~", "test_clustered", ",", "0", "]", ",", "\n", "test_data", "[", "~", "test_clustered", ",", "1", "]", ",", "\n", "c", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "\n", "s", "=", "0.1", ",", "\n", "alpha", "=", "0.5", ")", "\n", "ax02", ".", "set_title", "(", "\"Tets Outliers \"", "+", "str", "(", "test_coll", "[", "False", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "ax12", ".", "scatter", "(", "test_data", "[", "test_clustered", ",", "0", "]", ",", "\n", "test_data", "[", "test_clustered", ",", "1", "]", ",", "\n", "c", "=", "test_labels", "[", "test_clustered", "]", ",", "\n", "s", "=", "0.1", ",", "\n", "cmap", "=", "\"Spectral\"", ")", "\n", "ax12", ".", "set_title", "(", "\"Test Inliers \"", "+", "str", "(", "test_coll", "[", "True", "]", ")", ",", "fontsize", "=", "7", ")", "\n", "\n", "plt", ".", "savefig", "(", "output_dir", "+", "\"/\"", "+", "info", "+", "\"-hdbscan.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_all_data_umap": [[725, 854], ["print", "visualize.create_umap_data", "visualize.create_umap_data", "visualize.create_umap_data", "print", "umap.UMAP", "umap.UMAP.fit_transform", "umap.UMAP.transform", "umap.UMAP.transform", "visualize.visualize_umap_data", "visualize.hdbscan_clustering", "print", "umap.UMAP", "umap.UMAP.fit_transform", "umap.UMAP.transform", "umap.UMAP.transform", "visualize.visualize_umap_data", "print", "umap.UMAP", "umap.UMAP.fit_transform", "umap.UMAP.transform", "umap.UMAP.transform", "visualize.visualize_umap_data", "range", "len", "print", "umap.UMAP", "umap.UMAP.fit_transform", "umap.UMAP.transform", "umap.UMAP.transform", "visualize.visualize_umap_data", "numpy.array", "str", "str", "numpy.array", "str", "str", "numpy.array", "str", "str", "len", "len", "len", "len", "len", "len", "numpy.array", "str", "str", "numpy.array", "numpy.array", "numpy.array", "len", "len", "str", "numpy.array"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.create_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.create_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.create_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.hdbscan_clustering", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_umap_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_umap_data"], ["", "def", "visualize_all_data_umap", "(", "dlrm", ",", "\n", "train_ld", ",", "\n", "test_ld", "=", "None", ",", "\n", "max_umap_size", "=", "50000", ",", "\n", "output_dir", "=", "\"\"", ",", "\n", "umap_metric", "=", "\"euclidean\"", ")", ":", "\n", "\n", "    ", "data_ratio", "=", "1", "\n", "\n", "print", "(", "\"creating umap data\"", ")", "\n", "umap_train_feat", ",", "umap_train_X", ",", "umap_train_cat", ",", "umap_train_T", ",", "umap_train_z", ",", "umap_train_c", ",", "umap_train_p", "=", "create_umap_data", "(", "dlrm", "=", "dlrm", ",", "data_ld", "=", "train_ld", ",", "max_size", "=", "max_umap_size", ",", "offset", "=", "0", ",", "info", "=", "\"umap\"", ")", "\n", "\n", "# transform train and test data", "\n", "train_feat", ",", "train_X", ",", "train_cat", ",", "train_T", ",", "train_z", ",", "train_c", ",", "train_p", "=", "create_umap_data", "(", "dlrm", "=", "dlrm", ",", "data_ld", "=", "train_ld", ",", "max_size", "=", "max_umap_size", "*", "data_ratio", ",", "offset", "=", "max_umap_size", ",", "info", "=", "\"train\"", ")", "\n", "test_feat", ",", "test_X", ",", "test_cat", ",", "test_T", ",", "test_z", ",", "test_c", ",", "test_p", "=", "create_umap_data", "(", "dlrm", "=", "dlrm", ",", "data_ld", "=", "test_ld", ",", "max_size", "=", "max_umap_size", "*", "data_ratio", ",", "offset", "=", "0", ",", "info", "=", "\"test\"", ")", "\n", "\n", "print", "(", "\"umap_train_feat\"", ",", "np", ".", "array", "(", "umap_train_feat", ")", ".", "shape", ")", "\n", "reducer_all_feat", "=", "umap", ".", "UMAP", "(", "random_state", "=", "42", ",", "metric", "=", "umap_metric", ")", "\n", "umap_feat_Y", "=", "reducer_all_feat", ".", "fit_transform", "(", "umap_train_feat", ")", "\n", "\n", "train_feat_Y", "=", "reducer_all_feat", ".", "transform", "(", "train_feat", ")", "\n", "test_feat_Y", "=", "reducer_all_feat", ".", "transform", "(", "test_feat", ")", "\n", "\n", "visualize_umap_data", "(", "umap_Y", "=", "umap_feat_Y", ",", "\n", "umap_T", "=", "umap_train_T", ",", "\n", "umap_C", "=", "umap_train_c", ",", "\n", "umap_P", "=", "umap_train_p", ",", "\n", "train_Y", "=", "train_feat_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "train_C", "=", "train_c", ",", "\n", "train_P", "=", "train_p", ",", "\n", "test_Y", "=", "test_feat_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "test_C", "=", "test_c", ",", "\n", "test_P", "=", "test_p", ",", "\n", "total_train_size", "=", "str", "(", "len", "(", "train_ld", ")", ")", ",", "\n", "total_test_size", "=", "str", "(", "len", "(", "test_ld", ")", ")", ",", "\n", "info", "=", "\"all-features\"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "np", ".", "array", "(", "umap_train_feat", ")", ".", "shape", "[", "1", "]", ")", "\n", "\n", "hdbscan_clustering", "(", "umap_data", "=", "umap_feat_Y", ",", "\n", "train_data", "=", "train_feat_Y", ",", "\n", "test_data", "=", "test_feat_Y", ",", "\n", "info", "=", "\"umap-all-features\"", ",", "\n", "output_dir", "=", "output_dir", ")", "\n", "\n", "#    hdbscan_clustering(umap_data  = np.array(umap_train_feat), ", "\n", "#                       train_data = np.array(train_feat), ", "\n", "#                       test_data  = np.array(test_feat), ", "\n", "#                       info       = \"all-features\", ", "\n", "#                       output_dir = output_dir)", "\n", "\n", "print", "(", "\"umap_train_X\"", ",", "np", ".", "array", "(", "umap_train_X", ")", ".", "shape", ")", "\n", "reducer_X", "=", "umap", ".", "UMAP", "(", "random_state", "=", "42", ",", "metric", "=", "umap_metric", ")", "\n", "umap_X_Y", "=", "reducer_X", ".", "fit_transform", "(", "umap_train_X", ")", "\n", "\n", "train_X_Y", "=", "reducer_X", ".", "transform", "(", "train_X", ")", "\n", "test_X_Y", "=", "reducer_X", ".", "transform", "(", "test_X", ")", "\n", "\n", "visualize_umap_data", "(", "umap_Y", "=", "umap_X_Y", ",", "\n", "umap_T", "=", "umap_train_T", ",", "\n", "umap_C", "=", "umap_train_c", ",", "\n", "umap_P", "=", "umap_train_p", ",", "\n", "train_Y", "=", "train_X_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "train_C", "=", "train_c", ",", "\n", "train_P", "=", "train_p", ",", "\n", "test_Y", "=", "test_X_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "test_C", "=", "test_c", ",", "\n", "test_P", "=", "test_p", ",", "\n", "total_train_size", "=", "str", "(", "len", "(", "train_ld", ")", ")", ",", "\n", "total_test_size", "=", "str", "(", "len", "(", "test_ld", ")", ")", ",", "\n", "info", "=", "\"cont-features\"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "np", ".", "array", "(", "umap_train_X", ")", ".", "shape", "[", "1", "]", ")", "\n", "\n", "print", "(", "\"umap_train_cat\"", ",", "np", ".", "array", "(", "umap_train_cat", ")", ".", "shape", ")", "\n", "reducer_cat", "=", "umap", ".", "UMAP", "(", "random_state", "=", "42", ",", "metric", "=", "umap_metric", ")", "\n", "umap_cat_Y", "=", "reducer_cat", ".", "fit_transform", "(", "umap_train_cat", ")", "\n", "\n", "train_cat_Y", "=", "reducer_cat", ".", "transform", "(", "train_cat", ")", "\n", "test_cat_Y", "=", "reducer_cat", ".", "transform", "(", "test_cat", ")", "\n", "\n", "visualize_umap_data", "(", "umap_Y", "=", "umap_cat_Y", ",", "\n", "umap_T", "=", "umap_train_T", ",", "\n", "umap_C", "=", "umap_train_c", ",", "\n", "umap_P", "=", "umap_train_p", ",", "\n", "train_Y", "=", "train_cat_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "train_C", "=", "train_c", ",", "\n", "train_P", "=", "train_p", ",", "\n", "test_Y", "=", "test_cat_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "test_C", "=", "test_c", ",", "\n", "test_P", "=", "test_p", ",", "\n", "total_train_size", "=", "str", "(", "len", "(", "train_ld", ")", ")", ",", "\n", "total_test_size", "=", "str", "(", "len", "(", "test_ld", ")", ")", ",", "\n", "info", "=", "\"cat-features\"", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "np", ".", "array", "(", "umap_train_cat", ")", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# UMAP for z data", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "umap_train_z", ")", ")", ":", "\n", "        ", "print", "(", "\"z\"", ",", "i", ",", "np", ".", "array", "(", "umap_train_z", "[", "i", "]", ")", ".", "shape", ")", "\n", "reducer_z", "=", "umap", ".", "UMAP", "(", "random_state", "=", "42", ",", "metric", "=", "umap_metric", ")", "\n", "umap_z_Y", "=", "reducer_z", ".", "fit_transform", "(", "umap_train_z", "[", "i", "]", ")", "\n", "\n", "train_z_Y", "=", "reducer_z", ".", "transform", "(", "train_z", "[", "i", "]", ")", "\n", "test_z_Y", "=", "reducer_z", ".", "transform", "(", "test_z", "[", "i", "]", ")", "\n", "\n", "visualize_umap_data", "(", "umap_Y", "=", "umap_z_Y", ",", "\n", "umap_T", "=", "umap_train_T", ",", "\n", "umap_C", "=", "umap_train_c", ",", "\n", "umap_P", "=", "umap_train_p", ",", "\n", "train_Y", "=", "train_z_Y", ",", "\n", "train_T", "=", "train_T", ",", "\n", "train_C", "=", "train_c", ",", "\n", "train_P", "=", "train_p", ",", "\n", "test_Y", "=", "test_z_Y", ",", "\n", "test_T", "=", "test_T", ",", "\n", "test_C", "=", "test_c", ",", "\n", "test_P", "=", "test_p", ",", "\n", "total_train_size", "=", "str", "(", "len", "(", "train_ld", ")", ")", ",", "\n", "total_test_size", "=", "str", "(", "len", "(", "test_ld", ")", ")", ",", "\n", "info", "=", "\"z-features-\"", "+", "str", "(", "i", ")", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "orig_space_dim", "=", "np", ".", "array", "(", "umap_train_z", "[", "i", "]", ")", ".", "shape", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.analyze_model_data": [[856, 896], ["os.path.exists", "os.makedirs", "visualize.analyse_categorical_counts", "visualize.visualize_embeddings_umap", "visualize.visualize_all_data_umap", "visualize.analyse_categorical_data", "visualize.visualize_embeddings_tsne"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.analyse_categorical_counts", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_embeddings_umap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_all_data_umap", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.analyse_categorical_data", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tools.visualize.visualize_embeddings_tsne"], ["", "", "def", "analyze_model_data", "(", "output_dir", ",", "\n", "dlrm", ",", "\n", "train_ld", ",", "\n", "test_ld", ",", "\n", "train_data", ",", "\n", "skip_embedding", "=", "False", ",", "\n", "use_tsne", "=", "False", ",", "\n", "max_umap_size", "=", "50000", ",", "\n", "max_tsne_size", "=", "10000", ",", "\n", "skip_categorical_analysis", "=", "False", ",", "\n", "skip_data_plots", "=", "False", ",", "\n", "umap_metric", "=", "\"euclidean\"", ")", ":", "\n", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "if", "skip_embedding", "is", "False", ":", "\n", "\n", "        ", "cat_counts", "=", "None", "\n", "\n", "cat_counts", "=", "analyse_categorical_counts", "(", "X_cat", "=", "train_data", ".", "X_cat", ",", "emb_l", "=", "dlrm", ".", "emb_l", ",", "output_dir", "=", "output_dir", ")", "\n", "\n", "visualize_embeddings_umap", "(", "emb_l", "=", "dlrm", ".", "emb_l", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "max_size", "=", "max_umap_size", ",", "\n", "umap_metric", "=", "umap_metric", ",", "\n", "cat_counts", "=", "cat_counts", ")", "\n", "\n", "if", "use_tsne", "is", "True", ":", "\n", "            ", "visualize_embeddings_tsne", "(", "emb_l", "=", "dlrm", ".", "emb_l", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "max_size", "=", "max_tsne_size", ")", "\n", "\n", "# data visualization and analysis", "\n", "", "", "if", "skip_data_plots", "is", "False", ":", "\n", "        ", "visualize_all_data_umap", "(", "dlrm", "=", "dlrm", ",", "train_ld", "=", "train_ld", ",", "test_ld", "=", "test_ld", ",", "max_umap_size", "=", "max_umap_size", ",", "output_dir", "=", "output_dir", ",", "umap_metric", "=", "umap_metric", ")", "\n", "\n", "# analyse categorical variables", "\n", "", "if", "skip_categorical_analysis", "is", "False", "and", "args", ".", "data_randomize", "==", "\"none\"", ":", "\n", "        ", "analyse_categorical_data", "(", "X_cat", "=", "train_data", ".", "X_cat", ",", "n_days", "=", "10", ",", "output_dir", "=", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.aws_component.run_dlrm_main": [[15, 44], ["os.getcwd", "os.path.join", "os.environ.get", "max", "torchx.components.dist.ddp", "ValueError"], "function", ["None"], ["def", "run_dlrm_main", "(", "num_trainers", ":", "int", "=", "8", ",", "*", "script_args", ":", "str", ")", "->", "specs", ".", "AppDef", ":", "\n", "    ", "\"\"\"\n    Args:\n        num_trainers: The number of trainers to use.\n        script_args: A variable number of parameters to provide dlrm_main.py.\n    \"\"\"", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "entrypoint", "=", "os", ".", "path", ".", "join", "(", "cwd", ",", "\"dlrm_main.py\"", ")", "\n", "\n", "user", "=", "os", ".", "environ", ".", "get", "(", "\"USER\"", ")", "\n", "image", "=", "f\"/data/home/{user}\"", "\n", "\n", "if", "num_trainers", ">", "8", "and", "num_trainers", "%", "8", "!=", "0", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Trainer jobs spanning multiple hosts must be in multiples of 8.\"", "\n", ")", "\n", "", "nproc_per_node", "=", "8", "if", "num_trainers", ">=", "8", "else", "num_trainers", "\n", "num_replicas", "=", "max", "(", "num_trainers", "//", "8", ",", "1", ")", "\n", "\n", "return", "ddp", "(", "\n", "*", "script_args", ",", "\n", "name", "=", "\"train_dlrm\"", ",", "\n", "image", "=", "image", ",", "\n", "# AWS p4d instance (https://aws.amazon.com/ec2/instance-types/p4/).", "\n", "cpu", "=", "96", ",", "\n", "gpu", "=", "8", ",", "\n", "memMB", "=", "-", "1", ",", "\n", "script", "=", "entrypoint", ",", "\n", "j", "=", "f\"{num_replicas}x{nproc_per_node}\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.RestartableMap.__init__": [[12, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "f", ",", "source", ")", ":", "\n", "        ", "self", ".", "source", "=", "source", "\n", "self", ".", "func", "=", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.RestartableMap.__iter__": [[16, 19], ["multi_hot.RestartableMap.func"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "source", ":", "\n", "            ", "yield", "self", ".", "func", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__init__": [[21, 50], ["multi_hot.Multihot.__make_multi_hot_indices_cache", "multi_hot.Multihot.__make_offsets_cache", "ValueError", "multi_hot.Multihot.freqs_pre_hash.append", "multi_hot.Multihot.freqs_post_hash.append", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_multi_hot_indices_cache", "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_offsets_cache"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "multi_hot_size", ":", "int", ",", "\n", "multi_hot_min_table_size", ":", "int", ",", "\n", "ln_emb", ":", "List", "[", "int", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", "collect_freqs_stats", ":", "bool", ",", "\n", "type", ":", "str", "=", "\"uniform\"", ",", "\n", ")", ":", "\n", "        ", "if", "type", "!=", "\"uniform\"", "and", "type", "!=", "\"pareto\"", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Multi-hot distribution type {} is not supported.\"", "\n", "\"Only \\\"uniform\\\" and \\\"pareto\\\" are supported.\"", ".", "format", "(", "type", ")", "\n", ")", "\n", "", "self", ".", "multi_hot_min_table_size", "=", "multi_hot_min_table_size", "\n", "self", ".", "multi_hot_size", "=", "multi_hot_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "ln_emb", "=", "ln_emb", "\n", "self", ".", "lS_i_offsets_cache", "=", "self", ".", "__make_multi_hot_indices_cache", "(", "multi_hot_size", ",", "ln_emb", ")", "\n", "self", ".", "lS_o_cache", "=", "self", ".", "__make_offsets_cache", "(", "multi_hot_size", ",", "multi_hot_min_table_size", ",", "ln_emb", ",", "batch_size", ")", "\n", "\n", "# For plotting frequency access", "\n", "self", ".", "collect_freqs_stats", "=", "collect_freqs_stats", "\n", "self", ".", "model_to_track", "=", "None", "\n", "self", ".", "freqs_pre_hash", "=", "[", "]", "\n", "self", ".", "freqs_post_hash", "=", "[", "]", "\n", "for", "row_count", "in", "ln_emb", ":", "\n", "            ", "self", ".", "freqs_pre_hash", ".", "append", "(", "np", ".", "zeros", "(", "(", "row_count", ")", ")", ")", "\n", "self", ".", "freqs_post_hash", ".", "append", "(", "np", ".", "zeros", "(", "(", "row_count", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.save_freqs_stats": [[51, 60], ["numpy.save", "numpy.save", "torch.distributed.is_available", "torch.distributed.is_initialized", "torch.distributed.get_rank", "str", "str", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank"], ["", "", "def", "save_freqs_stats", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "torch", ".", "distributed", ".", "is_available", "(", ")", "and", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "            ", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "else", ":", "\n", "            ", "rank", "=", "0", "\n", "", "pre_dict", "=", "{", "str", "(", "k", ")", ":", "e", "for", "k", ",", "e", "in", "enumerate", "(", "self", ".", "freqs_pre_hash", ")", "}", "\n", "np", ".", "save", "(", "f\"stats_pre_hash_{rank}_pareto.npy\"", ",", "pre_dict", ")", "\n", "post_dict", "=", "{", "str", "(", "k", ")", ":", "e", "for", "k", ",", "e", "in", "enumerate", "(", "self", ".", "freqs_post_hash", ")", "}", "\n", "np", ".", "save", "(", "f\"stats_post_hash_{rank}_pareto.npy\"", ",", "post_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.pause_stats_collection_during_val_and_test": [[61, 63], ["None"], "methods", ["None"], ["", "def", "pause_stats_collection_during_val_and_test", "(", "self", ",", "model", ":", "torch", ".", "nn", ".", "Module", ")", "->", "None", ":", "\n", "        ", "self", ".", "model_to_track", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_multi_hot_indices_cache": [[64, 79], ["enumerate", "numpy.zeros", "numpy.random.seed", "torch.from_numpy().int", "numpy.random.randint", "torch.from_numpy", "numpy.random.pareto().astype", "numpy.random.pareto"], "methods", ["None"], ["", "def", "__make_multi_hot_indices_cache", "(", "\n", "self", ",", "\n", "multi_hot_size", ":", "int", ",", "\n", "ln_emb", ":", "List", "[", "int", "]", ",", "\n", ")", "->", "List", "[", "np", ".", "array", "]", ":", "\n", "        ", "cache", "=", "[", "np", ".", "zeros", "(", "(", "rows_count", ",", "multi_hot_size", ")", ")", "for", "rows_count", "in", "ln_emb", "]", "\n", "for", "k", ",", "e", "in", "enumerate", "(", "ln_emb", ")", ":", "\n", "            ", "np", ".", "random", ".", "seed", "(", "k", ")", "# The seed is necessary for all ranks to produce the same lookup values.", "\n", "if", "type", "==", "\"uniform\"", ":", "\n", "                ", "cache", "[", "k", "]", "[", ":", ",", "1", ":", "]", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "e", ",", "size", "=", "(", "e", ",", "multi_hot_size", "-", "1", ")", ")", "\n", "", "elif", "type", "==", "\"pareto\"", ":", "\n", "                ", "cache", "[", "k", "]", "[", ":", ",", "1", ":", "]", "=", "np", ".", "random", ".", "pareto", "(", "a", "=", "0.25", ",", "size", "=", "(", "e", ",", "multi_hot_size", "-", "1", ")", ")", ".", "astype", "(", "np", ".", "int32", ")", "%", "e", "\n", "# cache axes are [table, batch, offset]", "\n", "", "", "cache", "=", "[", "torch", ".", "from_numpy", "(", "table_cache", ")", ".", "int", "(", ")", "for", "table_cache", "in", "cache", "]", "\n", "return", "cache", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_offsets_cache": [[80, 93], ["torch.ones", "enumerate", "torch.cumsum", "torch.concat", "len", "torch.tensor"], "methods", ["None"], ["", "def", "__make_offsets_cache", "(", "\n", "self", ",", "\n", "multi_hot_size", ":", "int", ",", "\n", "multi_hot_min_table_size", ":", "int", ",", "\n", "ln_emb", ":", "List", "[", "int", "]", ",", "\n", "batch_size", ":", "int", ",", "\n", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "        ", "lS_o", "=", "torch", ".", "ones", "(", "(", "len", "(", "ln_emb", ")", "*", "self", ".", "batch_size", ")", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "for", "cf", ",", "table_length", "in", "enumerate", "(", "ln_emb", ")", ":", "\n", "            ", "if", "table_length", ">=", "multi_hot_min_table_size", ":", "\n", "                ", "lS_o", "[", "cf", "*", "batch_size", ":", "(", "cf", "+", "1", ")", "*", "batch_size", "]", "=", "multi_hot_size", "\n", "", "", "lS_o", "=", "torch", ".", "cumsum", "(", "torch", ".", "concat", "(", "(", "torch", ".", "tensor", "(", "[", "0", "]", ")", ",", "lS_o", ")", ")", ",", "axis", "=", "0", ")", "\n", "return", "lS_o", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_new_batch": [[94, 121], ["torch.cat.reshape", "enumerate", "torch.cat", "torch.cat", "multi_hot_i_l.append", "torch.nn.functional.embedding", "multi_hot_i.reshape.reshape.reshape", "multi_hot_i_l.append"], "methods", ["None"], ["", "def", "__make_new_batch", "(", "\n", "self", ",", "\n", "lS_o", ":", "torch", ".", "Tensor", ",", "\n", "lS_i", ":", "torch", ".", "Tensor", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "lS_i", "=", "lS_i", ".", "reshape", "(", "-", "1", ",", "self", ".", "batch_size", ")", "\n", "if", "1", "<", "self", ".", "multi_hot_size", ":", "\n", "            ", "multi_hot_i_l", "=", "[", "]", "\n", "for", "cf", ",", "table_length", "in", "enumerate", "(", "self", ".", "ln_emb", ")", ":", "\n", "                ", "if", "table_length", "<", "self", ".", "multi_hot_min_table_size", ":", "\n", "                    ", "multi_hot_i_l", ".", "append", "(", "lS_i", "[", "cf", "]", ")", "\n", "", "else", ":", "\n", "                    ", "keys", "=", "lS_i", "[", "cf", "]", "\n", "multi_hot_i", "=", "torch", ".", "nn", ".", "functional", ".", "embedding", "(", "keys", ",", "self", ".", "lS_i_offsets_cache", "[", "cf", "]", ")", "\n", "multi_hot_i", "[", ":", ",", "0", "]", "=", "keys", "\n", "multi_hot_i", "=", "multi_hot_i", ".", "reshape", "(", "-", "1", ")", "\n", "multi_hot_i_l", ".", "append", "(", "multi_hot_i", ")", "\n", "if", "self", ".", "collect_freqs_stats", "and", "(", "\n", "self", ".", "model_to_track", "is", "None", "or", "self", ".", "model_to_track", ".", "training", "\n", ")", ":", "\n", "                        ", "self", ".", "freqs_pre_hash", "[", "cf", "]", "[", "lS_i", "[", "cf", "]", "]", "+=", "1", "\n", "self", ".", "freqs_post_hash", "[", "cf", "]", "[", "multi_hot_i", "]", "+=", "1", "\n", "", "", "", "lS_i", "=", "torch", ".", "cat", "(", "multi_hot_i_l", ")", "\n", "return", "self", ".", "lS_o_cache", ",", "lS_i", "\n", "", "else", ":", "\n", "            ", "lS_i", "=", "torch", ".", "cat", "(", "lS_i", ")", "\n", "return", "lS_o", ",", "lS_i", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.convert_to_multi_hot": [[122, 135], ["multi_hot.Multihot.__make_new_batch", "torchrec.sparse.jagged_tensor.KeyedJaggedTensor.from_offsets_sync", "torchrec.datasets.utils.Batch"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.multi_hot.Multihot.__make_new_batch"], ["", "", "def", "convert_to_multi_hot", "(", "self", ",", "batch", ":", "Batch", ")", "->", "Batch", ":", "\n", "        ", "lS_i", "=", "batch", ".", "sparse_features", ".", "_values", "\n", "lS_o", "=", "batch", ".", "sparse_features", ".", "_offsets", "\n", "lS_o", ",", "lS_i", "=", "self", ".", "__make_new_batch", "(", "lS_o", ",", "lS_i", ")", "\n", "new_sparse_features", "=", "KeyedJaggedTensor", ".", "from_offsets_sync", "(", "\n", "keys", "=", "batch", ".", "sparse_features", ".", "_keys", ",", "\n", "values", "=", "lS_i", ",", "\n", "offsets", "=", "lS_o", ",", "\n", ")", "\n", "return", "Batch", "(", "\n", "dense_features", "=", "batch", ".", "dense_features", ",", "\n", "sparse_features", "=", "new_sparse_features", ",", "\n", "labels", "=", "batch", ".", "labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.parse_args": [[60, 261], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.parse_args"], ["def", "parse_args", "(", "argv", ":", "List", "[", "str", "]", ")", "->", "argparse", ".", "Namespace", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"torchrec dlrm example trainer\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"number of epochs to train\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch_size\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "\"batch size to use for training\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_batch_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"batch size to use for validation and testing\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--limit_train_batches\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"number of train batches\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--limit_val_batches\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"number of validation batches\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--limit_test_batches\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"number of test batches\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset_name\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"criteo_1t\"", ",", "\n", "help", "=", "\"dataset for experiment, current support criteo_1tb, criteo_kaggle\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_embeddings\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100_000", ",", "\n", "help", "=", "\"max_ind_size. The number of embeddings in each embedding table. Defaults\"", "\n", "\" to 100_000 if num_embeddings_per_feature is not supplied.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_embeddings_per_feature\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Comma separated max_ind_size per sparse feature. The number of embeddings\"", "\n", "\" in each embedding table. 26 values are expected for the Criteo dataset.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dense_arch_layer_sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"512,256,64\"", ",", "\n", "help", "=", "\"Comma separated layer sizes for dense arch.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--over_arch_layer_sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"512,512,256,1\"", ",", "\n", "help", "=", "\"Comma separated layer sizes for over arch.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--embedding_dim\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "64", ",", "\n", "help", "=", "\"Size of each embedding.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--interaction_branch1_layer_sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"2048,2048\"", ",", "\n", "help", "=", "\"Comma separated layer sizes for interaction branch1 (only on dlrmv2).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--interaction_branch2_layer_sizes\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"2048,2048\"", ",", "\n", "help", "=", "\"Comma separated layer sizes for interaction branch2 (only on dlrmv2).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--undersampling_rate\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Desired proportion of zero-labeled samples to retain (i.e. undersampling zero-labeled rows).\"", "\n", "\" Ex. 0.3 indicates only 30pct of the rows with label 0 will be kept.\"", "\n", "\" All rows with label 1 will be kept. Value should be between 0 and 1.\"", "\n", "\" When not supplied, no undersampling occurs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Random seed for reproducibility.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pin_memory\"", ",", "\n", "dest", "=", "\"pin_memory\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use pinned memory when loading data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mmap_mode\"", ",", "\n", "dest", "=", "\"mmap_mode\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"--mmap_mode mmaps the dataset.\"", "\n", "\" That is, the dataset is kept on disk but is accessed as if it were in memory.\"", "\n", "\" --mmap_mode is intended mostly for faster debugging. Use --mmap_mode to bypass\"", "\n", "\" preloading the dataset when preloading takes too long or when there is \"", "\n", "\" insufficient memory available to load the full dataset.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--in_memory_binary_criteo_path\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Path to a folder containing the binary (npy) files for the Criteo dataset.\"", "\n", "\" When supplied, InMemoryBinaryCriteoIterDataPipe is used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "15.0", ",", "\n", "help", "=", "\"Learning rate.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle_batches\"", ",", "\n", "dest", "=", "\"shuffle_batches\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Shuffle each batch during training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--validation_freq_within_epoch\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Frequency at which validation will be run within an epoch.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--change_lr\"", ",", "\n", "dest", "=", "\"change_lr\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Flag to determine whether learning rate should be changed part way through training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_change_point\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.80", ",", "\n", "help", "=", "\"The point through training at which learning rate should change to the value set by\"", "\n", "\" lr_after_change_point. The default value is 0.80 which means that 80% through the total iterations (totaled\"", "\n", "\" across all epochs), the learning rate will change.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_after_change_point\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.20", ",", "\n", "help", "=", "\"Learning rate after change point in first epoch.\"", ",", "\n", ")", "\n", "parser", ".", "set_defaults", "(", "\n", "pin_memory", "=", "None", ",", "\n", "mmap_mode", "=", "None", ",", "\n", "shuffle_batches", "=", "None", ",", "\n", "change_lr", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adagrad\"", ",", "\n", "dest", "=", "\"adagrad\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Flag to determine if adagrad optimizer should be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dlrmv2\"", ",", "\n", "dest", "=", "\"dlrmv2\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Flag to determine if dlrmv2 should be used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--collect_multi_hot_freqs_stats\"", ",", "\n", "dest", "=", "\"collect_multi_hot_freqs_stats\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Flag to determine whether to collect stats on freq of embedding access.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multi_hot_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The number of Multi-hot indices to use. When 1, multi-hot is disabled.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multi_hot_min_table_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "200", ",", "\n", "help", "=", "\"The minimum number of rows an embedding table must have to run multi-hot inputs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multi_hot_distribution_type\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"uniform\"", ",", "\"pareto\"", "]", ",", "\n", "default", "=", "\"uniform\"", ",", "\n", "help", "=", "\"Path to a folder containing the binary (npy) files for the Criteo dataset.\"", "\n", "\" When supplied, InMemoryBinaryCriteoIterDataPipe is used.\"", ",", "\n", ")", "\n", "return", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._evaluate": [[263, 325], ["model.eval", "itertools.chain", "torchmetrics.AUROC().to", "torchmetrics.Accuracy().to", "metrics.AUROC().to.compute().item", "metrics.Accuracy().to.compute().item", "itertools.islice", "torch.no_grad", "tqdm.tqdm", "torch.distributed.get_rank", "print", "print", "itertools.islice", "torchmetrics.AUROC", "torchmetrics.Accuracy", "iter", "metrics.AUROC().to.compute", "metrics.Accuracy().to.compute", "train_pipeline.progress", "torch.sigmoid", "metrics.AUROC().to.", "metrics.Accuracy().to."], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank"], ["", "def", "_evaluate", "(", "\n", "limit_batches", ":", "Optional", "[", "int", "]", ",", "\n", "train_pipeline", ":", "TrainPipelineSparseDist", ",", "\n", "iterator", ":", "Iterator", "[", "Batch", "]", ",", "\n", "next_iterator", ":", "Iterator", "[", "Batch", "]", ",", "\n", "stage", ":", "str", ",", "\n", ")", "->", "Tuple", "[", "float", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Evaluates model. Computes and prints metrics including AUROC and Accuracy. Helper\n    function for train_val_test.\n\n    Args:\n        limit_batches (Optional[int]): number of batches.\n        train_pipeline (TrainPipelineSparseDist): pipelined model.\n        iterator (Iterator[Batch]): Iterator used for val/test batches.\n        next_iterator (Iterator[Batch]): Iterator used for the next phase (either train\n            if there are more epochs to train on or test if all epochs are complete).\n            Used to queue up the next TRAIN_PIPELINE_STAGES - 1 batches before\n            train_val_test switches to the next phase. This is done so that when the\n            next phase starts, the first output train_pipeline generates an output for\n            is the 1st batch for that phase.\n        stage (str): \"val\" or \"test\".\n\n    Returns:\n        Tuple[float, float]: auroc and accuracy result\n    \"\"\"", "\n", "model", "=", "train_pipeline", ".", "_model", "\n", "model", ".", "eval", "(", ")", "\n", "device", "=", "train_pipeline", ".", "_device", "\n", "if", "limit_batches", "is", "not", "None", ":", "\n", "        ", "limit_batches", "-=", "TRAIN_PIPELINE_STAGES", "-", "1", "\n", "\n", "# Because TrainPipelineSparseDist buffer batches internally, we load in", "\n", "# TRAIN_PIPELINE_STAGES - 1 batches from the next_iterator into the buffers so that", "\n", "# when train_val_test switches to the next phase, train_pipeline will start", "\n", "# producing results for the TRAIN_PIPELINE_STAGES - 1 buffered batches (as opposed", "\n", "# to the last TRAIN_PIPELINE_STAGES - 1 batches from iterator).", "\n", "", "combined_iterator", "=", "itertools", ".", "chain", "(", "\n", "iterator", "\n", "if", "limit_batches", "is", "None", "\n", "else", "itertools", ".", "islice", "(", "iterator", ",", "limit_batches", ")", ",", "\n", "itertools", ".", "islice", "(", "next_iterator", ",", "TRAIN_PIPELINE_STAGES", "-", "1", ")", ",", "\n", ")", "\n", "auroc", "=", "metrics", ".", "AUROC", "(", "compute_on_step", "=", "False", ")", ".", "to", "(", "device", ")", "\n", "accuracy", "=", "metrics", ".", "Accuracy", "(", "compute_on_step", "=", "False", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Infinite iterator instead of while-loop to leverage tqdm progress bar.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "_", "in", "tqdm", "(", "iter", "(", "int", ",", "1", ")", ",", "desc", "=", "f\"Evaluating {stage} set\"", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "_loss", ",", "logits", ",", "labels", "=", "train_pipeline", ".", "progress", "(", "combined_iterator", ")", "\n", "preds", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "auroc", "(", "preds", ",", "labels", ")", "\n", "accuracy", "(", "preds", ",", "labels", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "break", "\n", "", "", "", "auroc_result", "=", "auroc", ".", "compute", "(", ")", ".", "item", "(", ")", "\n", "accuracy_result", "=", "accuracy", ".", "compute", "(", ")", ".", "item", "(", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", ":", "\n", "        ", "print", "(", "f\"AUROC over {stage} set: {auroc_result}.\"", ")", "\n", "print", "(", "f\"Accuracy over {stage} set: {accuracy_result}.\"", ")", "\n", "", "return", "auroc_result", ",", "accuracy_result", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._train": [[327, 425], ["train_pipeline._model.train", "itertools.chain", "tqdm.tqdm", "itertools.islice", "itertools.count", "itertools.islice", "torch.distributed.get_world_size", "train_pipeline.progress", "print", "dlrm_main._evaluate", "train_pipeline._model.train", "iter"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._evaluate"], ["", "def", "_train", "(", "\n", "train_pipeline", ":", "TrainPipelineSparseDist", ",", "\n", "iterator", ":", "Iterator", "[", "Batch", "]", ",", "\n", "next_iterator", ":", "Iterator", "[", "Batch", "]", ",", "\n", "within_epoch_val_dataloader", ":", "DataLoader", ",", "\n", "epoch", ":", "int", ",", "\n", "epochs", ":", "int", ",", "\n", "change_lr", ":", "bool", ",", "\n", "lr_change_point", ":", "float", ",", "\n", "lr_after_change_point", ":", "float", ",", "\n", "validation_freq_within_epoch", ":", "Optional", "[", "int", "]", ",", "\n", "limit_train_batches", ":", "Optional", "[", "int", "]", ",", "\n", "limit_val_batches", ":", "Optional", "[", "int", "]", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Trains model for 1 epoch. Helper function for train_val_test.\n\n    Args:\n        args (argparse.Namespace): parsed command line args.\n        train_pipeline (TrainPipelineSparseDist): pipelined model.\n        iterator (Iterator[Batch]): Iterator used for training batches.\n        next_iterator (Iterator[Batch]): Iterator used for validation batches\n            in between epochs. Used to queue up the next TRAIN_PIPELINE_STAGES - 1\n            batches before train_val_test switches to validation mode. This is done\n            so that when validation starts, the first output train_pipeline generates\n            an output for is the 1st validation batch (as opposed to a buffered train\n            batch).\n        within_epoch_val_dataloader (DataLoader): Dataloader to create iterators for\n            validation within an epoch. This is only used if\n            validation_freq_within_epoch is specified.\n        epoch (int): Which epoch the model is being trained on.\n        epochs (int): Number of epochs to train.\n        change_lr (bool): Whether learning rate should be changed part way through\n            training.\n        lr_change_point (float): The point through training at which learning rate\n            should change to the value set by lr_after_change_point.\n            Applied only if change_lr is set to True.\n        lr_after_change_point (float): Learning rate after change point in first epoch.\n            Applied only if change_lr is set to True.\n        validation_freq_within_epoch (Optional[int]): Frequency at which validation\n            will be run within an epoch.\n        limit_train_batches (Optional[int]): Number of train batches.\n        limit_val_batches (Optional[int]): Number of validation batches.\n\n\n\n    Returns:\n        None.\n    \"\"\"", "\n", "train_pipeline", ".", "_model", ".", "train", "(", ")", "\n", "\n", "# For the first epoch, train_pipeline has no buffered batches, but for all other", "\n", "# epochs, train_pipeline will have TRAIN_PIPELINE_STAGES - 1 from iterator already", "\n", "# present in its buffer.", "\n", "if", "limit_train_batches", "is", "not", "None", "and", "epoch", ">", "0", ":", "\n", "        ", "limit_train_batches", "-=", "TRAIN_PIPELINE_STAGES", "-", "1", "\n", "\n", "# Because TrainPipelineSparseDist buffer batches internally, we load in", "\n", "# TRAIN_PIPELINE_STAGES - 1 batches from the next_iterator into the buffers so that", "\n", "# when train_val_test switches to the next phase, train_pipeline will start", "\n", "# producing results for the TRAIN_PIPELINE_STAGES - 1 buffered batches (as opposed", "\n", "# to the last TRAIN_PIPELINE_STAGES - 1 batches from iterator).", "\n", "", "combined_iterator", "=", "itertools", ".", "chain", "(", "\n", "iterator", "\n", "if", "limit_train_batches", "is", "None", "\n", "else", "itertools", ".", "islice", "(", "iterator", ",", "limit_train_batches", ")", ",", "\n", "itertools", ".", "islice", "(", "next_iterator", ",", "TRAIN_PIPELINE_STAGES", "-", "1", ")", ",", "\n", ")", "\n", "samples_per_trainer", "=", "TOTAL_TRAINING_SAMPLES", "/", "dist", ".", "get_world_size", "(", ")", "*", "epochs", "\n", "\n", "# Infinite iterator instead of while-loop to leverage tqdm progress bar.", "\n", "for", "it", "in", "tqdm", "(", "itertools", ".", "count", "(", ")", ",", "desc", "=", "f\"Epoch {epoch}\"", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "train_pipeline", ".", "progress", "(", "combined_iterator", ")", "\n", "if", "change_lr", "and", "(", "\n", "(", "it", "*", "(", "epoch", "+", "1", ")", "/", "samples_per_trainer", ")", ">", "lr_change_point", "\n", ")", ":", "# progress made through the epoch", "\n", "                ", "print", "(", "f\"Changing learning rate to: {lr_after_change_point}\"", ")", "\n", "optimizer", "=", "train_pipeline", ".", "_optimizer", "\n", "lr", "=", "lr_after_change_point", "\n", "for", "g", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "g", "[", "\"lr\"", "]", "=", "lr", "\n", "\n", "", "", "if", "(", "\n", "validation_freq_within_epoch", "\n", "and", "it", ">", "0", "\n", "and", "it", "%", "validation_freq_within_epoch", "==", "0", "\n", ")", ":", "\n", "                ", "_evaluate", "(", "\n", "limit_val_batches", ",", "\n", "train_pipeline", ",", "\n", "iter", "(", "within_epoch_val_dataloader", ")", ",", "\n", "iterator", ",", "\n", "\"val\"", ",", "\n", ")", "\n", "train_pipeline", ".", "_model", ".", "train", "(", ")", "\n", "", "", "except", "StopIteration", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.train_val_test": [[435, 506], ["dlrm_main.TrainValTestResults", "iter", "iter", "range", "dlrm_main._evaluate", "iter", "dlrm_main._train", "iter", "dlrm_main._evaluate", "TrainValTestResults.val_accuracies.append", "TrainValTestResults.val_aurocs.append", "iter"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._evaluate", "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._train", "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main._evaluate"], ["", "def", "train_val_test", "(", "\n", "args", ":", "argparse", ".", "Namespace", ",", "\n", "train_pipeline", ":", "TrainPipelineSparseDist", ",", "\n", "train_dataloader", ":", "DataLoader", ",", "\n", "val_dataloader", ":", "DataLoader", ",", "\n", "test_dataloader", ":", "DataLoader", ",", "\n", ")", "->", "TrainValTestResults", ":", "\n", "    ", "\"\"\"\n    Train/validation/test loop. Contains customized logic to ensure each dataloader's\n    batches are used for the correct designated purpose (train, val, test). This logic\n    is necessary because TrainPipelineSparseDist buffers batches internally (so we\n    avoid batches designated for one purpose like training getting buffered and used for\n    another purpose like validation).\n\n    Args:\n        args (argparse.Namespace): parsed command line args.\n        train_pipeline (TrainPipelineSparseDist): pipelined model.\n        train_dataloader (DataLoader): DataLoader used for training.\n        val_dataloader (DataLoader): DataLoader used for validation.\n        test_dataloader (DataLoader): DataLoader used for testing.\n\n    Returns:\n        TrainValTestResults.\n    \"\"\"", "\n", "\n", "train_val_test_results", "=", "TrainValTestResults", "(", ")", "\n", "\n", "train_iterator", "=", "iter", "(", "train_dataloader", ")", "\n", "test_iterator", "=", "iter", "(", "test_dataloader", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "val_iterator", "=", "iter", "(", "val_dataloader", ")", "\n", "_train", "(", "\n", "train_pipeline", ",", "\n", "train_iterator", ",", "\n", "val_iterator", ",", "\n", "val_dataloader", ",", "\n", "epoch", ",", "\n", "args", ".", "epochs", ",", "\n", "args", ".", "change_lr", ",", "\n", "args", ".", "lr_change_point", ",", "\n", "args", ".", "lr_after_change_point", ",", "\n", "args", ".", "validation_freq_within_epoch", ",", "\n", "args", ".", "limit_train_batches", ",", "\n", "args", ".", "limit_val_batches", ",", "\n", ")", "\n", "train_iterator", "=", "iter", "(", "train_dataloader", ")", "\n", "val_next_iterator", "=", "(", "\n", "test_iterator", "if", "epoch", "==", "args", ".", "epochs", "-", "1", "else", "train_iterator", "\n", ")", "\n", "val_accuracy", ",", "val_auroc", "=", "_evaluate", "(", "\n", "args", ".", "limit_val_batches", ",", "\n", "train_pipeline", ",", "\n", "val_iterator", ",", "\n", "val_next_iterator", ",", "\n", "\"val\"", ",", "\n", ")", "\n", "\n", "train_val_test_results", ".", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "train_val_test_results", ".", "val_aurocs", ".", "append", "(", "val_auroc", ")", "\n", "\n", "", "test_accuracy", ",", "test_auroc", "=", "_evaluate", "(", "\n", "args", ".", "limit_test_batches", ",", "\n", "train_pipeline", ",", "\n", "test_iterator", ",", "\n", "iter", "(", "test_dataloader", ")", ",", "\n", "\"test\"", ",", "\n", ")", "\n", "train_val_test_results", ".", "test_accuracy", "=", "test_accuracy", "\n", "train_val_test_results", ".", "test_auroc", "=", "test_auroc", "\n", "\n", "return", "train_val_test_results", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.main": [[508, 648], ["dlrm_main.parse_args", "int", "torch.cuda.is_available", "get_dataloader", "get_dataloader", "get_dataloader", "torchrec.models.dlrm.DLRMTrain", "torchrec.distributed.model_parallel.DistributedModelParallel", "torchrec.optim.keyed.KeyedOptimizerWrapper", "torchrec.optim.keyed.CombinedOptimizer", "torchrec.distributed.TrainPipelineSparseDist", "dlrm_main.train_val_test", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.is_initialized", "torch.distributed.init_process_group", "list", "torchrec.modules.embedding_configs.EmbeddingBagConfig", "list", "torchrec.models.dlrm.DLRMV2", "torchrec.models.dlrm.DLRM", "torchrec.distributed.embeddingbag.EmbeddingBagCollectionSharder", "dict", "dlrm_main.main.optimizer_with_params"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.parse_args", "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader.get_dataloader", "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader.get_dataloader", "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader.get_dataloader", "home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.train_val_test"], ["", "def", "main", "(", "argv", ":", "List", "[", "str", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Trains, validates, and tests a Deep Learning Recommendation Model (DLRM)\n    (https://arxiv.org/abs/1906.00091). The DLRM model contains both data parallel\n    components (e.g. multi-layer perceptrons & interaction arch) and model parallel\n    components (e.g. embedding tables). The DLRM model is pipelined so that dataloading,\n    data-parallel to model-parallel comms, and forward/backward are overlapped. Can be\n    run with either a random dataloader or an in-memory Criteo 1 TB click logs dataset\n    (https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/).\n\n    Args:\n        argv (List[str]): command line args.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "args", "=", "parse_args", "(", "argv", ")", "\n", "\n", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"LOCAL_RANK\"", "]", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", ":", "torch", ".", "device", "=", "torch", ".", "device", "(", "f\"cuda:{rank}\"", ")", "\n", "backend", "=", "\"nccl\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "device", ":", "torch", ".", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "backend", "=", "\"gloo\"", "\n", "\n", "", "if", "not", "torch", ".", "distributed", ".", "is_initialized", "(", ")", ":", "\n", "        ", "dist", ".", "init_process_group", "(", "backend", "=", "backend", ")", "\n", "\n", "", "if", "args", ".", "num_embeddings_per_feature", "is", "not", "None", ":", "\n", "        ", "args", ".", "num_embeddings_per_feature", "=", "list", "(", "\n", "map", "(", "int", ",", "args", ".", "num_embeddings_per_feature", ".", "split", "(", "\",\"", ")", ")", "\n", ")", "\n", "args", ".", "num_embeddings", "=", "None", "\n", "\n", "# TODO add CriteoIterDataPipe support and add random_dataloader arg", "\n", "", "train_dataloader", "=", "get_dataloader", "(", "args", ",", "backend", ",", "\"train\"", ")", "\n", "val_dataloader", "=", "get_dataloader", "(", "args", ",", "backend", ",", "\"val\"", ")", "\n", "test_dataloader", "=", "get_dataloader", "(", "args", ",", "backend", ",", "\"test\"", ")", "\n", "\n", "# Sets default limits for random dataloader iterations when left unspecified.", "\n", "if", "args", ".", "in_memory_binary_criteo_path", "is", "None", ":", "\n", "        ", "for", "stage", "in", "STAGES", ":", "\n", "            ", "attr", "=", "f\"limit_{stage}_batches\"", "\n", "if", "getattr", "(", "args", ",", "attr", ")", "is", "None", ":", "\n", "                ", "setattr", "(", "args", ",", "attr", ",", "10", ")", "\n", "\n", "", "", "", "eb_configs", "=", "[", "\n", "EmbeddingBagConfig", "(", "\n", "name", "=", "f\"t_{feature_name}\"", ",", "\n", "embedding_dim", "=", "args", ".", "embedding_dim", ",", "\n", "num_embeddings", "=", "none_throws", "(", "args", ".", "num_embeddings_per_feature", ")", "[", "feature_idx", "]", "\n", "if", "args", ".", "num_embeddings", "is", "None", "\n", "else", "args", ".", "num_embeddings", ",", "\n", "feature_names", "=", "[", "feature_name", "]", ",", "\n", ")", "\n", "for", "feature_idx", ",", "feature_name", "in", "enumerate", "(", "DEFAULT_CAT_NAMES", ")", "\n", "]", "\n", "sharded_module_kwargs", "=", "{", "}", "\n", "if", "args", ".", "over_arch_layer_sizes", "is", "not", "None", ":", "\n", "        ", "sharded_module_kwargs", "[", "\"over_arch_layer_sizes\"", "]", "=", "list", "(", "\n", "map", "(", "int", ",", "args", ".", "over_arch_layer_sizes", ".", "split", "(", "\",\"", ")", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "dlrmv2", ":", "\n", "        ", "dlrm_model", "=", "DLRMV2", "(", "\n", "embedding_bag_collection", "=", "EmbeddingBagCollection", "(", "\n", "tables", "=", "eb_configs", ",", "device", "=", "torch", ".", "device", "(", "\"meta\"", ")", "\n", ")", ",", "\n", "dense_in_features", "=", "len", "(", "DEFAULT_INT_NAMES", ")", ",", "\n", "dense_arch_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "dense_arch_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "over_arch_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "over_arch_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "interaction_branch1_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "interaction_branch1_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "interaction_branch2_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "interaction_branch2_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "dense_device", "=", "device", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "dlrm_model", "=", "DLRM", "(", "\n", "embedding_bag_collection", "=", "EmbeddingBagCollection", "(", "\n", "tables", "=", "eb_configs", ",", "device", "=", "torch", ".", "device", "(", "\"meta\"", ")", "\n", ")", ",", "\n", "dense_in_features", "=", "len", "(", "DEFAULT_INT_NAMES", ")", ",", "\n", "dense_arch_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "dense_arch_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "over_arch_layer_sizes", "=", "list", "(", "map", "(", "int", ",", "args", ".", "over_arch_layer_sizes", ".", "split", "(", "\",\"", ")", ")", ")", ",", "\n", "dense_device", "=", "device", ",", "\n", ")", "\n", "", "train_model", "=", "DLRMTrain", "(", "dlrm_model", ")", "\n", "fused_params", "=", "{", "\n", "\"learning_rate\"", ":", "args", ".", "learning_rate", ",", "\n", "\"optimizer\"", ":", "OptimType", ".", "EXACT_ROWWISE_ADAGRAD", "\n", "if", "args", ".", "adagrad", "\n", "else", "OptimType", ".", "EXACT_SGD", ",", "\n", "}", "\n", "sharders", "=", "[", "\n", "EmbeddingBagCollectionSharder", "(", "fused_params", "=", "fused_params", ")", ",", "\n", "]", "\n", "\n", "model", "=", "DistributedModelParallel", "(", "\n", "module", "=", "train_model", ",", "\n", "device", "=", "device", ",", "\n", "sharders", "=", "cast", "(", "List", "[", "ModuleSharder", "[", "nn", ".", "Module", "]", "]", ",", "sharders", ")", ",", "\n", ")", "\n", "\n", "def", "optimizer_with_params", "(", ")", ":", "\n", "        ", "if", "args", ".", "adagrad", ":", "\n", "            ", "return", "lambda", "params", ":", "torch", ".", "optim", ".", "Adagrad", "(", "params", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "", "else", ":", "\n", "            ", "return", "lambda", "params", ":", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "\n", "", "", "dense_optimizer", "=", "KeyedOptimizerWrapper", "(", "\n", "dict", "(", "model", ".", "named_parameters", "(", ")", ")", ",", "\n", "optimizer_with_params", "(", ")", ",", "\n", ")", "\n", "optimizer", "=", "CombinedOptimizer", "(", "[", "model", ".", "fused_optimizer", ",", "dense_optimizer", "]", ")", "\n", "\n", "train_pipeline", "=", "TrainPipelineSparseDist", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "device", ",", "\n", ")", "\n", "\n", "if", "1", "<", "args", ".", "multi_hot_size", ":", "\n", "        ", "multihot", "=", "Multihot", "(", "\n", "args", ".", "multi_hot_size", ",", "\n", "args", ".", "multi_hot_min_table_size", ",", "\n", "args", ".", "num_embeddings_per_feature", ",", "\n", "args", ".", "batch_size", ",", "\n", "collect_freqs_stats", "=", "args", ".", "collect_multi_hot_freqs_stats", ",", "\n", "type", "=", "args", ".", "multi_hot_distribution_type", ",", "\n", ")", "\n", "multihot", ".", "pause_stats_collection_during_val_and_test", "(", "train_pipeline", ".", "_model", ")", "\n", "train_dataloader", "=", "RestartableMap", "(", "multihot", ".", "convert_to_multi_hot", ",", "train_dataloader", ")", "\n", "val_dataloader", "=", "RestartableMap", "(", "multihot", ".", "convert_to_multi_hot", ",", "val_dataloader", ")", "\n", "test_dataloader", "=", "RestartableMap", "(", "multihot", ".", "convert_to_multi_hot", ",", "test_dataloader", ")", "\n", "", "train_val_test", "(", "\n", "args", ",", "train_pipeline", ",", "train_dataloader", ",", "val_dataloader", ",", "test_dataloader", "\n", ")", "\n", "if", "1", "<", "args", ".", "multi_hot_size", "and", "multihot", ".", "collect_freqs_stats", ":", "\n", "        ", "multihot", ".", "save_freqs_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tests.test_dlrm_main.MainTest._run_trainer_random": [[21, 39], ["dlrm_main.main"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.main"], ["    ", "@", "classmethod", "\n", "def", "_run_trainer_random", "(", "cls", ")", "->", "None", ":", "\n", "        ", "main", "(", "\n", "[", "\n", "\"--limit_train_batches\"", ",", "\n", "\"10\"", ",", "\n", "\"--limit_val_batches\"", ",", "\n", "\"8\"", ",", "\n", "\"--limit_test_batches\"", ",", "\n", "\"6\"", ",", "\n", "\"--over_arch_layer_sizes\"", ",", "\n", "\"8,1\"", ",", "\n", "\"--dense_arch_layer_sizes\"", ",", "\n", "\"8,8\"", ",", "\n", "\"--embedding_dim\"", ",", "\n", "\"8\"", ",", "\n", "\"--num_embeddings\"", ",", "\n", "\"8\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tests.test_dlrm_main.MainTest.test_main_function": [[42, 59], ["tempfile.TemporaryDirectory", "torch.distributed.launcher.api.LaunchConfig", "torch.distributed.launcher.api.elastic_launch", "str", "os.path.join", "uuid.uuid4"], "methods", ["None"], ["", "@", "test_utils", ".", "skip_if_asan", "\n", "def", "test_main_function", "(", "self", ")", "->", "None", ":", "\n", "        ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "lc", "=", "LaunchConfig", "(", "\n", "min_nodes", "=", "1", ",", "\n", "max_nodes", "=", "1", ",", "\n", "nproc_per_node", "=", "2", ",", "\n", "run_id", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ",", "\n", "rdzv_backend", "=", "\"c10d\"", ",", "\n", "rdzv_endpoint", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"rdzv\"", ")", ",", "\n", "rdzv_configs", "=", "{", "\"store_type\"", ":", "\"file\"", "}", ",", "\n", "start_method", "=", "\"spawn\"", ",", "\n", "monitor_interval", "=", "1", ",", "\n", "max_restarts", "=", "0", ",", "\n", ")", "\n", "\n", "elastic_launch", "(", "config", "=", "lc", ",", "entrypoint", "=", "self", ".", "_run_trainer_random", ")", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tests.test_dlrm_main.MainTest._run_trainer_criteo_in_memory": [[60, 81], ["torchrec.datasets.test_utils.criteo_test_utils.CriteoTest._create_dataset_npys", "dlrm_main.main", "os.path.dirname", "range"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.torchrec_dlrm.dlrm_main.main"], ["", "", "@", "classmethod", "\n", "def", "_run_trainer_criteo_in_memory", "(", "cls", ")", "->", "None", ":", "\n", "        ", "with", "CriteoTest", ".", "_create_dataset_npys", "(", "\n", "num_rows", "=", "50", ",", "filenames", "=", "[", "f\"day_{i}\"", "for", "i", "in", "range", "(", "24", ")", "]", "\n", ")", "as", "files", ":", "\n", "            ", "main", "(", "\n", "[", "\n", "\"--over_arch_layer_sizes\"", ",", "\n", "\"8,1\"", ",", "\n", "\"--dense_arch_layer_sizes\"", ",", "\n", "\"8,8\"", ",", "\n", "\"--embedding_dim\"", ",", "\n", "\"8\"", ",", "\n", "\"--num_embeddings\"", ",", "\n", "\"64\"", ",", "\n", "\"--batch_size\"", ",", "\n", "\"2\"", ",", "\n", "\"--in_memory_binary_criteo_path\"", ",", "\n", "os", ".", "path", ".", "dirname", "(", "files", "[", "0", "]", ")", ",", "\n", "\"--epochs\"", ",", "\n", "\"2\"", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tests.test_dlrm_main.MainTest.test_main_function_criteo_in_memory": [[84, 101], ["tempfile.TemporaryDirectory", "torch.distributed.launcher.api.LaunchConfig", "torch.distributed.launcher.api.elastic_launch", "str", "os.path.join", "uuid.uuid4"], "methods", ["None"], ["", "", "@", "test_utils", ".", "skip_if_asan", "\n", "def", "test_main_function_criteo_in_memory", "(", "self", ")", "->", "None", ":", "\n", "        ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "lc", "=", "LaunchConfig", "(", "\n", "min_nodes", "=", "1", ",", "\n", "max_nodes", "=", "1", ",", "\n", "nproc_per_node", "=", "2", ",", "\n", "run_id", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ",", "\n", "rdzv_backend", "=", "\"c10d\"", ",", "\n", "rdzv_endpoint", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"rdzv\"", ")", ",", "\n", "rdzv_configs", "=", "{", "\"store_type\"", ":", "\"file\"", "}", ",", "\n", "start_method", "=", "\"spawn\"", ",", "\n", "monitor_interval", "=", "1", ",", "\n", "max_restarts", "=", "0", ",", "\n", ")", "\n", "\n", "elastic_launch", "(", "config", "=", "lc", ",", "entrypoint", "=", "self", ".", "_run_trainer_criteo_in_memory", ")", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader._get_random_dataloader": [[26, 45], ["torch.utils.data.DataLoader", "torchrec.datasets.random.RandomRecDataset", "len", "hasattr", "hasattr"], "function", ["None"], ["def", "_get_random_dataloader", "(", "\n", "args", ":", "argparse", ".", "Namespace", ",", "\n", ")", "->", "DataLoader", ":", "\n", "    ", "return", "DataLoader", "(", "\n", "RandomRecDataset", "(", "\n", "keys", "=", "DEFAULT_CAT_NAMES", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "hash_size", "=", "args", ".", "num_embeddings", ",", "\n", "hash_sizes", "=", "args", ".", "num_embeddings_per_feature", "\n", "if", "hasattr", "(", "args", ",", "\"num_embeddings_per_feature\"", ")", "\n", "else", "None", ",", "\n", "manual_seed", "=", "args", ".", "seed", "if", "hasattr", "(", "args", ",", "\"seed\"", ")", "else", "None", ",", "\n", "ids_per_feature", "=", "1", ",", "\n", "num_dense", "=", "len", "(", "DEFAULT_INT_NAMES", ")", ",", "\n", ")", ",", "\n", "batch_size", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "\n", "num_workers", "=", "0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader._get_in_memory_dataloader": [[48, 103], ["os.listdir", "torch.utils.data.DataLoader", "list", "torch.distributed.get_rank", "torch.distributed.get_world_size", "list", "sorted", "torchrec.datasets.criteo.InMemoryBinaryCriteoIterDataPipe", "filter", "filter", "torch.distributed.get_rank", "torch.distributed.get_world_size", "map", "torch.distributed.get_rank", "torch.distributed.get_world_size", "filter", "os.path.join", "dlrm_dataloader._get_in_memory_dataloader.is_final_day"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank", "home.repos.pwc.inspect_result.facebookresearch_dlrm.None.mlperf_logger.get_rank"], ["", "def", "_get_in_memory_dataloader", "(", "\n", "args", ":", "argparse", ".", "Namespace", ",", "\n", "stage", ":", "str", ",", "\n", ")", "->", "DataLoader", ":", "\n", "    ", "files", "=", "os", ".", "listdir", "(", "args", ".", "in_memory_binary_criteo_path", ")", "\n", "\n", "def", "is_final_day", "(", "s", ":", "str", ")", "->", "bool", ":", "\n", "        ", "return", "f\"day_{DAYS - 1}\"", "in", "s", "\n", "\n", "", "if", "stage", "==", "\"train\"", ":", "\n", "# Train set gets all data except from the final day.", "\n", "        ", "files", "=", "list", "(", "filter", "(", "lambda", "s", ":", "not", "is_final_day", "(", "s", ")", ",", "files", ")", ")", "\n", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "", "else", ":", "\n", "# Validation set gets the first half of the final day's samples. Test set get", "\n", "# the other half.", "\n", "        ", "files", "=", "list", "(", "filter", "(", "is_final_day", ",", "files", ")", ")", "\n", "rank", "=", "(", "\n", "dist", ".", "get_rank", "(", ")", "\n", "if", "stage", "==", "\"val\"", "\n", "else", "dist", ".", "get_rank", "(", ")", "+", "dist", ".", "get_world_size", "(", ")", "\n", ")", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "*", "2", "\n", "batch_size", "=", "(", "\n", "args", ".", "batch_size", "if", "args", ".", "test_batch_size", "is", "None", "else", "args", ".", "test_batch_size", "\n", ")", "\n", "\n", "", "stage_files", ":", "List", "[", "List", "[", "str", "]", "]", "=", "[", "\n", "sorted", "(", "\n", "map", "(", "\n", "lambda", "x", ":", "os", ".", "path", ".", "join", "(", "args", ".", "in_memory_binary_criteo_path", ",", "x", ")", ",", "\n", "filter", "(", "lambda", "s", ":", "kind", "in", "s", ",", "files", ")", ",", "\n", ")", "\n", ")", "\n", "for", "kind", "in", "[", "\"dense\"", ",", "\"sparse\"", ",", "\"labels\"", "]", "\n", "]", "\n", "dataloader", "=", "DataLoader", "(", "\n", "InMemoryBinaryCriteoIterDataPipe", "(", "\n", "*", "stage_files", ",", "# pyre-ignore[6]", "\n", "batch_size", "=", "batch_size", ",", "\n", "rank", "=", "rank", ",", "\n", "world_size", "=", "world_size", ",", "\n", "shuffle_batches", "=", "args", ".", "shuffle_batches", ",", "\n", "mmap_mode", "=", "args", ".", "mmap_mode", ",", "\n", "hashes", "=", "args", ".", "num_embeddings_per_feature", "\n", "if", "args", ".", "num_embeddings", "is", "None", "\n", "else", "(", "[", "args", ".", "num_embeddings", "]", "*", "CAT_FEATURE_COUNT", ")", ",", "\n", ")", ",", "\n", "batch_size", "=", "None", ",", "\n", "pin_memory", "=", "args", ".", "pin_memory", ",", "\n", "collate_fn", "=", "lambda", "x", ":", "x", ",", "\n", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader.get_dataloader": [[105, 136], ["stage.lower.lower", "ValueError", "dlrm_dataloader._get_random_dataloader", "dlrm_dataloader._get_in_memory_dataloader", "hasattr", "hasattr"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader._get_random_dataloader", "home.repos.pwc.inspect_result.facebookresearch_dlrm.data.dlrm_dataloader._get_in_memory_dataloader"], ["", "def", "get_dataloader", "(", "args", ":", "argparse", ".", "Namespace", ",", "backend", ":", "str", ",", "stage", ":", "str", ")", "->", "DataLoader", ":", "\n", "    ", "\"\"\"\n    Gets desired dataloader from dlrm_main command line options. Currently, this\n    function is able to return either a DataLoader wrapped around a RandomRecDataset or\n    a Dataloader wrapped around an InMemoryBinaryCriteoIterDataPipe.\n\n    Args:\n        args (argparse.Namespace): Command line options supplied to dlrm_main.py's main\n            function.\n        backend (str): \"nccl\" or \"gloo\".\n        stage (str): \"train\", \"val\", or \"test\".\n\n    Returns:\n        dataloader (DataLoader): PyTorch dataloader for the specified options.\n\n    \"\"\"", "\n", "stage", "=", "stage", ".", "lower", "(", ")", "\n", "if", "stage", "not", "in", "STAGES", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Supplied stage was {stage}. Must be one of {STAGES}.\"", ")", "\n", "\n", "", "args", ".", "pin_memory", "=", "(", "\n", "(", "backend", "==", "\"nccl\"", ")", "if", "not", "hasattr", "(", "args", ",", "\"pin_memory\"", ")", "else", "args", ".", "pin_memory", "\n", ")", "\n", "\n", "if", "(", "\n", "not", "hasattr", "(", "args", ",", "\"in_memory_binary_criteo_path\"", ")", "\n", "or", "args", ".", "in_memory_binary_criteo_path", "is", "None", "\n", ")", ":", "\n", "        ", "return", "_get_random_dataloader", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "return", "_get_in_memory_dataloader", "(", "args", ",", "stage", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.qr_embedding_bag.QREmbeddingBag.__init__": [[112, 151], ["torch.Module.__init__", "isinstance", "int", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "qr_embedding_bag.QREmbeddingBag.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "len", "numpy.ceil", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "list", "list"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.qr_embedding_bag.QREmbeddingBag.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_categories", ",", "embedding_dim", ",", "num_collisions", ",", "\n", "operation", "=", "'mult'", ",", "max_norm", "=", "None", ",", "norm_type", "=", "2.", ",", "\n", "scale_grad_by_freq", "=", "False", ",", "mode", "=", "'mean'", ",", "sparse", "=", "False", ",", "\n", "_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", "QREmbeddingBag", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "operation", "in", "[", "'concat'", ",", "'mult'", ",", "'add'", "]", ",", "'Not valid operation!'", "\n", "\n", "self", ".", "num_categories", "=", "num_categories", "\n", "if", "isinstance", "(", "embedding_dim", ",", "int", ")", "or", "len", "(", "embedding_dim", ")", "==", "1", ":", "\n", "            ", "self", ".", "embedding_dim", "=", "[", "embedding_dim", ",", "embedding_dim", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "", "self", ".", "num_collisions", "=", "num_collisions", "\n", "self", ".", "operation", "=", "operation", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "scale_grad_by_freq", "=", "scale_grad_by_freq", "\n", "\n", "if", "self", ".", "operation", "==", "'add'", "or", "self", ".", "operation", "==", "'mult'", ":", "\n", "            ", "assert", "self", ".", "embedding_dim", "[", "0", "]", "==", "self", ".", "embedding_dim", "[", "1", "]", ",", "'Embedding dimensions do not match!'", "\n", "\n", "", "self", ".", "num_embeddings", "=", "[", "int", "(", "np", ".", "ceil", "(", "num_categories", "/", "num_collisions", ")", ")", ",", "\n", "num_collisions", "]", "\n", "\n", "if", "_weight", "is", "None", ":", "\n", "            ", "self", ".", "weight_q", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_embeddings", "[", "0", "]", ",", "self", ".", "embedding_dim", "[", "0", "]", ")", ")", "\n", "self", ".", "weight_r", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_embeddings", "[", "1", "]", ",", "self", ".", "embedding_dim", "[", "1", "]", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "list", "(", "_weight", "[", "0", "]", ".", "shape", ")", "==", "[", "self", ".", "num_embeddings", "[", "0", "]", ",", "self", ".", "embedding_dim", "[", "0", "]", "]", ",", "'Shape of weight for quotient table does not match num_embeddings and embedding_dim'", "\n", "assert", "list", "(", "_weight", "[", "1", "]", ".", "shape", ")", "==", "[", "self", ".", "num_embeddings", "[", "1", "]", ",", "self", ".", "embedding_dim", "[", "1", "]", "]", ",", "'Shape of weight for remainder table does not match num_embeddings and embedding_dim'", "\n", "self", ".", "weight_q", "=", "Parameter", "(", "_weight", "[", "0", "]", ")", "\n", "self", ".", "weight_r", "=", "Parameter", "(", "_weight", "[", "1", "]", ")", "\n", "", "self", ".", "mode", "=", "mode", "\n", "self", ".", "sparse", "=", "sparse", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.qr_embedding_bag.QREmbeddingBag.reset_parameters": [[152, 155], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight_q", ",", "np", ".", "sqrt", "(", "1", "/", "self", ".", "num_categories", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight_r", ",", "np", ".", "sqrt", "(", "1", "/", "self", ".", "num_categories", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.qr_embedding_bag.QREmbeddingBag.forward": [[156, 175], ["torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.remainder().long", "torch.embedding_bag", "torch.embedding_bag", "torch.embedding_bag", "torch.embedding_bag", "torch.embedding_bag", "torch.embedding_bag", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder", "torch.remainder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "offsets", "=", "None", ",", "per_sample_weights", "=", "None", ")", ":", "\n", "        ", "input_q", "=", "(", "input", "/", "self", ".", "num_collisions", ")", ".", "long", "(", ")", "\n", "input_r", "=", "torch", ".", "remainder", "(", "input", ",", "self", ".", "num_collisions", ")", ".", "long", "(", ")", "\n", "\n", "embed_q", "=", "F", ".", "embedding_bag", "(", "input_q", ",", "self", ".", "weight_q", ",", "offsets", ",", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "self", ".", "scale_grad_by_freq", ",", "self", ".", "mode", ",", "\n", "self", ".", "sparse", ",", "per_sample_weights", ")", "\n", "embed_r", "=", "F", ".", "embedding_bag", "(", "input_r", ",", "self", ".", "weight_r", ",", "offsets", ",", "self", ".", "max_norm", ",", "\n", "self", ".", "norm_type", ",", "self", ".", "scale_grad_by_freq", ",", "self", ".", "mode", ",", "\n", "self", ".", "sparse", ",", "per_sample_weights", ")", "\n", "\n", "if", "self", ".", "operation", "==", "'concat'", ":", "\n", "            ", "embed", "=", "torch", ".", "cat", "(", "(", "embed_q", ",", "embed_r", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "operation", "==", "'add'", ":", "\n", "            ", "embed", "=", "embed_q", "+", "embed_r", "\n", "", "elif", "self", ".", "operation", "==", "'mult'", ":", "\n", "            ", "embed", "=", "embed_q", "*", "embed_r", "\n", "\n", "", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.qr_embedding_bag.QREmbeddingBag.extra_repr": [[176, 186], ["s.format"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{num_embeddings}, {embedding_dim}'", "\n", "if", "self", ".", "max_norm", "is", "not", "None", ":", "\n", "            ", "s", "+=", "', max_norm={max_norm}'", "\n", "", "if", "self", ".", "norm_type", "!=", "2", ":", "\n", "            ", "s", "+=", "', norm_type={norm_type}'", "\n", "", "if", "self", ".", "scale_grad_by_freq", "is", "not", "False", ":", "\n", "            ", "s", "+=", "', scale_grad_by_freq={scale_grad_by_freq}'", "\n", "", "s", "+=", "', mode={mode}'", "\n", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__": [[64, 77], ["torch.Module.__init__", "torch.EmbeddingBag", "torch.EmbeddingBag", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Linear", "torch.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Identity", "torch.Identity", "ValueError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ",", "base_dim", ")", ":", "\n", "        ", "super", "(", "PrEmbeddingBag", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embs", "=", "nn", ".", "EmbeddingBag", "(", "\n", "num_embeddings", ",", "embedding_dim", ",", "mode", "=", "\"sum\"", ",", "sparse", "=", "True", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "embs", ".", "weight", ")", "\n", "if", "embedding_dim", "<", "base_dim", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "embedding_dim", ",", "base_dim", ",", "bias", "=", "False", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "proj", ".", "weight", ")", "\n", "", "elif", "embedding_dim", "==", "base_dim", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Embedding dim \"", "+", "str", "(", "embedding_dim", ")", "+", "\" > base dim \"", "+", "str", "(", "base_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.PrEmbeddingBag.forward": [[79, 82], ["md_embedding_bag.PrEmbeddingBag.proj", "md_embedding_bag.PrEmbeddingBag.embs"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "offsets", "=", "None", ",", "per_sample_weights", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "proj", "(", "self", ".", "embs", "(", "\n", "input", ",", "offsets", "=", "offsets", ",", "per_sample_weights", "=", "per_sample_weights", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.md_solver": [[20, 41], ["torch.sort", "torch.sort", "md_embedding_bag.alpha_power_rule", "enumerate", "torch.ones", "torch.ones", "md_embedding_bag.pow_2_round", "len", "len", "n.type"], "function", ["home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.alpha_power_rule", "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.pow_2_round"], ["def", "md_solver", "(", "n", ",", "alpha", ",", "d0", "=", "None", ",", "B", "=", "None", ",", "round_dim", "=", "True", ",", "k", "=", "None", ")", ":", "\n", "    ", "'''\n    An external facing function call for mixed-dimension assignment\n    with the alpha power temperature heuristic\n    Inputs:\n    n -- (torch.LongTensor) ; Vector of num of rows for each embedding matrix\n    alpha -- (torch.FloatTensor); Scalar, non-negative, controls dim. skew\n    d0 -- (torch.FloatTensor); Scalar, baseline embedding dimension\n    B -- (torch.FloatTensor); Scalar, parameter budget for embedding layer\n    round_dim -- (bool); flag for rounding dims to nearest pow of 2\n    k -- (torch.LongTensor) ; Vector of average number of queries per inference\n    '''", "\n", "n", ",", "indices", "=", "torch", ".", "sort", "(", "n", ")", "\n", "k", "=", "k", "[", "indices", "]", "if", "k", "is", "not", "None", "else", "torch", ".", "ones", "(", "len", "(", "n", ")", ")", "\n", "d", "=", "alpha_power_rule", "(", "n", ".", "type", "(", "torch", ".", "float", ")", "/", "k", ",", "alpha", ",", "d0", "=", "d0", ",", "B", "=", "B", ")", "\n", "if", "round_dim", ":", "\n", "        ", "d", "=", "pow_2_round", "(", "d", ")", "\n", "", "undo_sort", "=", "[", "0", "]", "*", "len", "(", "indices", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "indices", ")", ":", "\n", "        ", "undo_sort", "[", "v", "]", "=", "i", "\n", "", "return", "d", "[", "undo_sort", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.alpha_power_rule": [[43, 57], ["range", "torch.round().type", "torch.round().type", "len", "ValueError", "torch.ones", "torch.ones", "n.type", "torch.round", "torch.round", "n[].type", "torch.sum", "torch.sum", "len", "n.type"], "function", ["None"], ["", "def", "alpha_power_rule", "(", "n", ",", "alpha", ",", "d0", "=", "None", ",", "B", "=", "None", ")", ":", "\n", "    ", "if", "d0", "is", "not", "None", ":", "\n", "        ", "lamb", "=", "d0", "*", "(", "n", "[", "0", "]", ".", "type", "(", "torch", ".", "float", ")", "**", "alpha", ")", "\n", "", "elif", "B", "is", "not", "None", ":", "\n", "        ", "lamb", "=", "B", "/", "torch", ".", "sum", "(", "n", ".", "type", "(", "torch", ".", "float", ")", "**", "(", "1", "-", "alpha", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must specify either d0 or B\"", ")", "\n", "", "d", "=", "torch", ".", "ones", "(", "len", "(", "n", ")", ")", "*", "lamb", "*", "(", "n", ".", "type", "(", "torch", ".", "float", ")", "**", "(", "-", "alpha", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "d", ")", ")", ":", "\n", "        ", "if", "i", "==", "0", "and", "d0", "is", "not", "None", ":", "\n", "            ", "d", "[", "i", "]", "=", "d0", "\n", "", "else", ":", "\n", "            ", "d", "[", "i", "]", "=", "1", "if", "d", "[", "i", "]", "<", "1", "else", "d", "[", "i", "]", "\n", "", "", "return", "(", "torch", ".", "round", "(", "d", ")", ".", "type", "(", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_dlrm.tricks.md_embedding_bag.pow_2_round": [[59, 61], ["torch.round", "torch.round", "torch.log2", "torch.log2", "dims.type"], "function", ["None"], ["", "def", "pow_2_round", "(", "dims", ")", ":", "\n", "    ", "return", "2", "**", "torch", ".", "round", "(", "torch", ".", "log2", "(", "dims", ".", "type", "(", "torch", ".", "float", ")", ")", ")", "\n", "\n"]]}