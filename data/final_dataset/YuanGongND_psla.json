{"home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.train": [[20, 231], ["torch.device", "print", "torch.set_grad_enabled", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "AverageMeter", "time.time", "nn.DataParallel.to", "print", "print", "torch.optim.Adam", "torch.optim.lr_scheduler.MultiStepLR", "print", "print", "print", "print", "numpy.zeros", "nn.DataParallel.train", "progress.append", "isinstance", "torch.nn.DataParallel", "list", "torch.nn.BCELoss", "time.time", "time.time", "nn.DataParallel.train", "print", "print", "print", "enumerate", "print", "traintest.validate", "traintest.validate_ensemble", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "print", "print", "print", "print", "print", "print", "numpy.savetxt", "print", "torch.save", "torch.optim.lr_scheduler.MultiStepLR.step", "print", "traintest.train._save_progress"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.train", "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.train", "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate", "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate_ensemble"], ["def", "train", "(", "audio_model", ",", "train_loader", ",", "test_loader", ",", "args", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "print", "(", "'running on '", "+", "str", "(", "device", ")", ")", "\n", "torch", ".", "set_grad_enabled", "(", "True", ")", "\n", "\n", "# Initialize all of the statistics we want to keep track of", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "per_sample_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "per_sample_data_time", "=", "AverageMeter", "(", ")", "\n", "loss_meter", "=", "AverageMeter", "(", ")", "\n", "per_sample_dnn_time", "=", "AverageMeter", "(", ")", "\n", "progress", "=", "[", "]", "\n", "# best_ensemble_mAP is checkpoint ensemble from the first epoch to the best epoch", "\n", "best_epoch", ",", "best_ensemble_epoch", ",", "best_mAP", ",", "best_acc", ",", "best_ensemble_mAP", "=", "0", ",", "0", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", ",", "-", "np", ".", "inf", "\n", "global_step", ",", "epoch", "=", "0", ",", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "\n", "def", "_save_progress", "(", ")", ":", "\n", "        ", "progress", ".", "append", "(", "[", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_mAP", ",", "time", ".", "time", "(", ")", "-", "start_time", "]", ")", "\n", "with", "open", "(", "\"%s/progress.pkl\"", "%", "exp_dir", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "progress", ",", "f", ")", "\n", "\n", "", "", "if", "not", "isinstance", "(", "audio_model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "audio_model", "=", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "\n", "", "audio_model", "=", "audio_model", ".", "to", "(", "device", ")", "\n", "# Set up the optimizer", "\n", "trainables", "=", "[", "p", "for", "p", "in", "audio_model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "print", "(", "'Total parameter number is : {:.3f} million'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "audio_model", ".", "parameters", "(", ")", ")", "/", "1e6", ")", ")", "\n", "print", "(", "'Total trainable parameter number is : {:.3f} million'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "trainables", ")", "/", "1e6", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "trainables", ",", "args", ".", "lr", ",", "weight_decay", "=", "5e-7", ",", "betas", "=", "(", "0.95", ",", "0.999", ")", ")", "\n", "\n", "# dataset specific settings", "\n", "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=args.lr_patience, verbose=True)", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "list", "(", "range", "(", "args", ".", "lrscheduler_start", ",", "1000", ",", "5", ")", ")", ",", "gamma", "=", "args", ".", "lrscheduler_decay", ",", "last_epoch", "=", "epoch", "-", "1", ")", "\n", "main_metrics", "=", "args", ".", "metrics", "\n", "if", "args", ".", "loss", "==", "'BCE'", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "BCELoss", "(", ")", "\n", "", "elif", "args", ".", "loss", "==", "'CE'", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "warmup", "=", "args", ".", "warmup", "\n", "args", ".", "loss_fn", "=", "loss_fn", "\n", "print", "(", "'now training with {:s}, main metrics: {:s}, loss function: {:s}, learning rate scheduler: {:s}'", ".", "format", "(", "str", "(", "args", ".", "dataset", ")", ",", "str", "(", "main_metrics", ")", ",", "str", "(", "loss_fn", ")", ",", "str", "(", "scheduler", ")", ")", ")", "\n", "print", "(", "'The learning rate scheduler starts at {:d} epoch with decay rate of {:.3f} '", ".", "format", "(", "args", ".", "lrscheduler_start", ",", "args", ".", "lrscheduler_decay", ")", ")", "\n", "\n", "epoch", "+=", "1", "\n", "\n", "print", "(", "\"current #steps=%s, #epochs=%s\"", "%", "(", "global_step", ",", "epoch", ")", ")", "\n", "print", "(", "\"start training...\"", ")", "\n", "result", "=", "np", ".", "zeros", "(", "[", "args", ".", "n_epochs", ",", "10", "]", ")", "\n", "audio_model", ".", "train", "(", ")", "\n", "while", "epoch", "<", "args", ".", "n_epochs", "+", "1", ":", "\n", "        ", "begin_time", "=", "time", ".", "time", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "audio_model", ".", "train", "(", ")", "\n", "print", "(", "'---------------'", ")", "\n", "print", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "print", "(", "\"current #epochs=%s, #steps=%s\"", "%", "(", "epoch", ",", "global_step", ")", ")", "\n", "\n", "for", "i", ",", "(", "audio_input", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "\n", "            ", "B", "=", "audio_input", ".", "size", "(", "0", ")", "\n", "audio_input", "=", "audio_input", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "per_sample_data_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "dnn_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# first several steps for warm-up", "\n", "if", "global_step", "<=", "1000", "and", "global_step", "%", "50", "==", "0", "and", "warmup", "==", "True", ":", "\n", "                ", "warm_lr", "=", "(", "global_step", "/", "1000", ")", "*", "args", ".", "lr", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "warm_lr", "\n", "", "print", "(", "'warm-up learning rate is {:f}'", ".", "format", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "", "audio_output", "=", "audio_model", "(", "audio_input", ")", "\n", "if", "isinstance", "(", "loss_fn", ",", "torch", ".", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "                ", "loss", "=", "loss_fn", "(", "audio_output", ",", "torch", ".", "argmax", "(", "labels", ".", "long", "(", ")", ",", "axis", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "epsilon", "=", "1e-7", "\n", "audio_output", "=", "torch", ".", "clamp", "(", "audio_output", ",", "epsilon", ",", "1.", "-", "epsilon", ")", "\n", "loss", "=", "loss_fn", "(", "audio_output", ",", "labels", ")", "\n", "\n", "# optimization if amp is not used", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# record loss", "\n", "loss_meter", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "B", ")", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "per_sample_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "per_sample_dnn_time", ".", "update", "(", "(", "time", ".", "time", "(", ")", "-", "dnn_start_time", ")", "/", "audio_input", ".", "shape", "[", "0", "]", ")", "\n", "\n", "print_step", "=", "global_step", "%", "args", ".", "n_print_steps", "==", "0", "\n", "early_print_step", "=", "epoch", "==", "0", "and", "global_step", "%", "(", "args", ".", "n_print_steps", "/", "10", ")", "==", "0", "\n", "print_step", "=", "print_step", "or", "early_print_step", "\n", "\n", "if", "print_step", "and", "global_step", "!=", "0", ":", "\n", "                ", "print", "(", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'Per Sample Total Time {per_sample_time.avg:.5f}\\t'", "\n", "'Per Sample Data Time {per_sample_data_time.avg:.5f}\\t'", "\n", "'Per Sample DNN Time {per_sample_dnn_time.avg:.5f}\\t'", "\n", "'Train Loss {loss_meter.avg:.4f}\\t'", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "per_sample_time", "=", "per_sample_time", ",", "per_sample_data_time", "=", "per_sample_data_time", ",", "\n", "per_sample_dnn_time", "=", "per_sample_dnn_time", ",", "loss_meter", "=", "loss_meter", ")", ",", "flush", "=", "True", ")", "\n", "if", "np", ".", "isnan", "(", "loss_meter", ".", "avg", ")", ":", "\n", "                    ", "print", "(", "\"training diverged...\"", ")", "\n", "return", "\n", "\n", "", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "", "print", "(", "'start validation'", ")", "\n", "stats", ",", "valid_loss", "=", "validate", "(", "audio_model", ",", "test_loader", ",", "args", ",", "epoch", ")", "\n", "\n", "# ensemble results", "\n", "ensemble_stats", "=", "validate_ensemble", "(", "args", ",", "epoch", ")", "\n", "ensemble_mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "ensemble_stats", "]", ")", "\n", "ensemble_mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "ensemble_stats", "]", ")", "\n", "ensemble_acc", "=", "ensemble_stats", "[", "0", "]", "[", "'acc'", "]", "\n", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "acc", "=", "stats", "[", "0", "]", "[", "'acc'", "]", "\n", "\n", "middle_ps", "=", "[", "stat", "[", "'precisions'", "]", "[", "int", "(", "len", "(", "stat", "[", "'precisions'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "middle_rs", "=", "[", "stat", "[", "'recalls'", "]", "[", "int", "(", "len", "(", "stat", "[", "'recalls'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "average_precision", "=", "np", ".", "mean", "(", "middle_ps", ")", "\n", "average_recall", "=", "np", ".", "mean", "(", "middle_rs", ")", "\n", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "            ", "print", "(", "\"mAP: {:.6f}\"", ".", "format", "(", "mAP", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"acc: {:.6f}\"", ".", "format", "(", "acc", ")", ")", "\n", "", "print", "(", "\"AUC: {:.6f}\"", ".", "format", "(", "mAUC", ")", ")", "\n", "print", "(", "\"Avg Precision: {:.6f}\"", ".", "format", "(", "average_precision", ")", ")", "\n", "print", "(", "\"Avg Recall: {:.6f}\"", ".", "format", "(", "average_recall", ")", ")", "\n", "print", "(", "\"d_prime: {:.6f}\"", ".", "format", "(", "d_prime", "(", "mAUC", ")", ")", ")", "\n", "print", "(", "\"train_loss: {:.6f}\"", ".", "format", "(", "loss_meter", ".", "avg", ")", ")", "\n", "print", "(", "\"valid_loss: {:.6f}\"", ".", "format", "(", "valid_loss", ")", ")", "\n", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "            ", "result", "[", "epoch", "-", "1", ",", ":", "]", "=", "[", "mAP", ",", "mAUC", ",", "average_precision", ",", "average_recall", ",", "d_prime", "(", "mAUC", ")", ",", "loss_meter", ".", "avg", ",", "valid_loss", ",", "ensemble_mAP", ",", "ensemble_mAUC", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "]", "\n", "", "else", ":", "\n", "            ", "result", "[", "epoch", "-", "1", ",", ":", "]", "=", "[", "acc", ",", "mAUC", ",", "average_precision", ",", "average_recall", ",", "d_prime", "(", "mAUC", ")", ",", "loss_meter", ".", "avg", ",", "valid_loss", ",", "ensemble_acc", ",", "ensemble_mAUC", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "]", "\n", "", "np", ".", "savetxt", "(", "exp_dir", "+", "'/result.csv'", ",", "result", ",", "delimiter", "=", "','", ")", "\n", "print", "(", "'validation finished'", ")", "\n", "\n", "if", "mAP", ">", "best_mAP", ":", "\n", "            ", "best_mAP", "=", "mAP", "\n", "if", "main_metrics", "==", "'mAP'", ":", "\n", "                ", "best_epoch", "=", "epoch", "\n", "\n", "", "", "if", "acc", ">", "best_acc", ":", "\n", "            ", "best_acc", "=", "acc", "\n", "if", "main_metrics", "==", "'acc'", ":", "\n", "                ", "best_epoch", "=", "epoch", "\n", "\n", "", "", "if", "ensemble_mAP", ">", "best_ensemble_mAP", ":", "\n", "            ", "best_ensemble_epoch", "=", "epoch", "\n", "best_ensemble_mAP", "=", "ensemble_mAP", "\n", "\n", "", "if", "best_epoch", "==", "epoch", ":", "\n", "            ", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "\"%s/models/best_audio_model.pth\"", "%", "(", "exp_dir", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "\"%s/models/best_optim_state.pth\"", "%", "(", "exp_dir", ")", ")", "\n", "\n", "", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "\"%s/models/audio_model.%d.pth\"", "%", "(", "exp_dir", ",", "epoch", ")", ")", "\n", "if", "len", "(", "train_loader", ".", "dataset", ")", ">", "2e5", ":", "\n", "            ", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "\"%s/models/optim_state.%d.pth\"", "%", "(", "exp_dir", ",", "epoch", ")", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "print", "(", "'Epoch-{0} lr: {1}'", ".", "format", "(", "epoch", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", ")", "\n", "\n", "with", "open", "(", "exp_dir", "+", "'/stats_'", "+", "str", "(", "epoch", ")", "+", "'.pickle'", ",", "'wb'", ")", "as", "handle", ":", "\n", "            ", "pickle", ".", "dump", "(", "stats", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "_save_progress", "(", ")", "\n", "\n", "finish_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'epoch {:d} training time: {:.3f}'", ".", "format", "(", "epoch", ",", "finish_time", "-", "begin_time", ")", ")", "\n", "\n", "epoch", "+=", "1", "\n", "\n", "batch_time", ".", "reset", "(", ")", "\n", "per_sample_time", ".", "reset", "(", ")", "\n", "data_time", ".", "reset", "(", ")", "\n", "per_sample_data_time", ".", "reset", "(", ")", "\n", "loss_meter", ".", "reset", "(", ")", "\n", "per_sample_dnn_time", ".", "reset", "(", ")", "\n", "\n", "# if test weight averaging", "\n", "", "if", "args", ".", "wa", "==", "True", ":", "\n", "        ", "stats", "=", "validate_wa", "(", "audio_model", ",", "test_loader", ",", "args", ",", "args", ".", "wa_start", ",", "args", ".", "wa_end", ")", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "middle_ps", "=", "[", "stat", "[", "'precisions'", "]", "[", "int", "(", "len", "(", "stat", "[", "'precisions'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "middle_rs", "=", "[", "stat", "[", "'recalls'", "]", "[", "int", "(", "len", "(", "stat", "[", "'recalls'", "]", ")", "/", "2", ")", "]", "for", "stat", "in", "stats", "]", "\n", "average_precision", "=", "np", ".", "mean", "(", "middle_ps", ")", "\n", "average_recall", "=", "np", ".", "mean", "(", "middle_rs", ")", "\n", "wa_result", "=", "[", "mAP", ",", "mAUC", "]", "\n", "print", "(", "'---------------Training Finished---------------'", ")", "\n", "# print('On Validation Set')", "\n", "# print('weighted averaged model results')", "\n", "# print(\"mAP: {:.6f}\".format(mAP))", "\n", "# print(\"AUC: {:.6f}\".format(mAUC))", "\n", "# print(\"d_prime: {:.6f}\".format(d_prime(mAUC)))", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/wa_result.csv'", ",", "wa_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate": [[232, 277], ["torch.device", "AverageMeter", "nn.DataParallel.to", "nn.DataParallel.eval", "time.time", "isinstance", "torch.nn.DataParallel", "torch.no_grad", "enumerate", "torch.cat", "torch.cat", "numpy.mean", "calculate_stats", "numpy.savetxt", "torch.cuda.is_available", "audio_input.to.to", "nn.DataParallel.", "torch.clamp.to().detach", "A_predictions.append", "A_targets.append", "labels.to.to", "torch.clamp", "isinstance", "A_loss.append", "AverageMeter.update", "time.time", "os.path.exists", "os.mkdir", "numpy.savetxt", "numpy.savetxt", "args.loss_fn", "args.loss_fn", "args.loss_fn.to().detach", "os.path.exists", "torch.clamp.to", "torch.argmax", "time.time", "str", "labels.to.long", "args.loss_fn.to"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.calculate_stats", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update"], ["", "", "def", "validate", "(", "audio_model", ",", "val_loader", ",", "args", ",", "epoch", ",", "eval_target", "=", "False", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "if", "not", "isinstance", "(", "audio_model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "audio_model", "=", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "", "audio_model", "=", "audio_model", ".", "to", "(", "device", ")", "\n", "# switch to evaluate mode   ", "\n", "audio_model", ".", "eval", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "A_predictions", "=", "[", "]", "\n", "A_targets", "=", "[", "]", "\n", "A_loss", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "audio_input", ",", "labels", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "            ", "audio_input", "=", "audio_input", ".", "to", "(", "device", ")", "\n", "# compute output    ", "\n", "audio_output", "=", "audio_model", "(", "audio_input", ")", "\n", "predictions", "=", "audio_output", ".", "to", "(", "'cpu'", ")", ".", "detach", "(", ")", "\n", "A_predictions", ".", "append", "(", "predictions", ")", "\n", "A_targets", ".", "append", "(", "labels", ")", "\n", "# compute the loss  ", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "epsilon", "=", "1e-7", "\n", "audio_output", "=", "torch", ".", "clamp", "(", "audio_output", ",", "epsilon", ",", "1.", "-", "epsilon", ")", "\n", "if", "isinstance", "(", "args", ".", "loss_fn", ",", "torch", ".", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "                ", "loss", "=", "args", ".", "loss_fn", "(", "audio_output", ",", "torch", ".", "argmax", "(", "labels", ".", "long", "(", ")", ",", "axis", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "args", ".", "loss_fn", "(", "audio_output", ",", "labels", ")", "\n", "", "A_loss", ".", "append", "(", "loss", ".", "to", "(", "'cpu'", ")", ".", "detach", "(", ")", ")", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "", "audio_output", "=", "torch", ".", "cat", "(", "A_predictions", ")", "\n", "target", "=", "torch", ".", "cat", "(", "A_targets", ")", "\n", "loss", "=", "np", ".", "mean", "(", "A_loss", ")", "\n", "stats", "=", "calculate_stats", "(", "audio_output", ",", "target", ")", "\n", "# save the prediction here  ", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "if", "os", ".", "path", ".", "exists", "(", "exp_dir", "+", "'/predictions'", ")", "==", "False", ":", "\n", "            ", "os", ".", "mkdir", "(", "exp_dir", "+", "'/predictions'", ")", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/target.csv'", ",", "target", ",", "delimiter", "=", "','", ")", "\n", "", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", ")", "+", "'.csv'", ",", "audio_output", ",", "delimiter", "=", "','", ")", "\n", "# save the target for the separate eval set if there's one. ", "\n", "if", "eval_target", "==", "True", "and", "os", ".", "path", ".", "exists", "(", "exp_dir", "+", "'/predictions/eval_target.csv'", ")", "==", "False", ":", "\n", "            ", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/eval_target.csv'", ",", "target", ",", "delimiter", "=", "','", ")", "\n", "", "", "return", "stats", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate_ensemble": [[278, 295], ["numpy.loadtxt", "numpy.savetxt", "calculate_stats", "numpy.loadtxt", "numpy.loadtxt", "os.remove", "numpy.loadtxt", "str", "str"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.calculate_stats"], ["", "def", "validate_ensemble", "(", "args", ",", "epoch", ")", ":", "\n", "    ", "exp_dir", "=", "args", ".", "exp_dir", "\n", "target", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/target.csv'", ",", "delimiter", "=", "','", ")", "\n", "if", "epoch", "==", "1", ":", "\n", "        ", "ensemble_predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/predictions_1.csv'", ",", "delimiter", "=", "','", ")", "\n", "", "else", ":", "\n", "        ", "ensemble_predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/ensemble_predictions.csv'", ",", "delimiter", "=", "','", ")", "*", "(", "epoch", "-", "1", ")", "\n", "predictions", "=", "np", ".", "loadtxt", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", ")", "+", "'.csv'", ",", "delimiter", "=", "','", ")", "\n", "ensemble_predictions", "=", "ensemble_predictions", "+", "predictions", "\n", "# remove the prediction file to save storage space", "\n", "os", ".", "remove", "(", "exp_dir", "+", "'/predictions/predictions_'", "+", "str", "(", "epoch", "-", "1", ")", "+", "'.csv'", ")", "\n", "\n", "", "ensemble_predictions", "=", "ensemble_predictions", "/", "epoch", "\n", "np", ".", "savetxt", "(", "exp_dir", "+", "'/predictions/ensemble_predictions.csv'", ",", "ensemble_predictions", ",", "delimiter", "=", "','", ")", "\n", "\n", "stats", "=", "calculate_stats", "(", "ensemble_predictions", ",", "target", ")", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate_wa": [[296, 323], ["torch.device", "torch.load", "range", "audio_model.load_state_dict", "torch.save", "traintest.validate", "torch.load", "audio_model.state_dict", "torch.cuda.is_available", "os.remove", "float", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate"], ["", "def", "validate_wa", "(", "audio_model", ",", "val_loader", ",", "args", ",", "start_epoch", ",", "end_epoch", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "exp_dir", "=", "args", ".", "exp_dir", "\n", "\n", "sdA", "=", "torch", ".", "load", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "start_epoch", ")", "+", "'.pth'", ",", "map_location", "=", "device", ")", "\n", "\n", "model_cnt", "=", "1", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "end_epoch", "+", "1", ")", ":", "\n", "        ", "sdB", "=", "torch", ".", "load", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "epoch", ")", "+", "'.pth'", ",", "map_location", "=", "device", ")", "\n", "for", "key", "in", "sdA", ":", "\n", "            ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "+", "sdB", "[", "key", "]", "\n", "", "model_cnt", "+=", "1", "\n", "\n", "# if choose not to save models of epoch, remove to save space", "\n", "if", "args", ".", "save_model", "==", "False", ":", "\n", "            ", "os", ".", "remove", "(", "exp_dir", "+", "'/models/audio_model.'", "+", "str", "(", "epoch", ")", "+", "'.pth'", ")", "\n", "\n", "# averaging", "\n", "", "", "for", "key", "in", "sdA", ":", "\n", "        ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "/", "float", "(", "model_cnt", ")", "\n", "\n", "", "audio_model", ".", "load_state_dict", "(", "sdA", ")", "\n", "\n", "torch", ".", "save", "(", "audio_model", ".", "state_dict", "(", ")", ",", "exp_dir", "+", "'/models/audio_model_wa.pth'", ")", "\n", "\n", "stats", ",", "loss", "=", "validate", "(", "audio_model", ",", "val_loader", ",", "args", ",", "'wa'", ")", "\n", "return", "stats", "", "", ""]], "home.repos.pwc.inspect_result.YuanGongND_psla.src.gen_weight_file.make_index_dict": [[21, 30], ["open", "csv.DictReader"], "function", ["None"], ["def", "make_index_dict", "(", "label_csv", ")", ":", "\n", "    ", "index_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "index_lookup", "[", "row", "[", "'mid'", "]", "]", "=", "row", "[", "'index'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "index_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.ensemble.weight_averaging.get_wa_res": [[19, 61], ["numpy.zeros", "torch.device", "enumerate", "models.EffNetAttention", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "traintest.validate", "numpy.mean", "numpy.mean", "weight_averaging.d_prime", "print", "os.path.exists", "os.mkdir", "print", "print", "sd.keys", "torch.save", "torch.cuda.is_available", "torch.load", "torch.load", "float", "len"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.d_prime"], ["def", "get_wa_res", "(", "mdl_list", ",", "base_path", ",", "dataset", "=", "'audioset'", ")", ":", "\n", "    ", "num_class", "=", "527", "if", "dataset", "==", "'audioset'", "else", "200", "\n", "# the 0-len(mdl_list) rows record the results of single models, the last row record the result of the ensemble model.", "\n", "ensemble_res", "=", "np", ".", "zeros", "(", "[", "len", "(", "mdl_list", ")", "+", "1", ",", "3", "]", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "base_path", ")", "==", "False", ":", "\n", "        ", "os", ".", "mkdir", "(", "base_path", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "for", "model_idx", ",", "mdl", "in", "enumerate", "(", "mdl_list", ")", ":", "\n", "        ", "print", "(", "'-----------------------'", ")", "\n", "print", "(", "'now loading model {:d}: {:s}'", ".", "format", "(", "model_idx", ",", "mdl", ")", ")", "\n", "\n", "if", "model_idx", "==", "0", ":", "\n", "            ", "sdA", "=", "torch", ".", "load", "(", "mdl", ",", "map_location", "=", "device", ")", "\n", "model_cnt", "=", "1", "\n", "", "else", ":", "\n", "            ", "sdB", "=", "torch", ".", "load", "(", "mdl", ",", "map_location", "=", "device", ")", "\n", "for", "key", "in", "sdA", ":", "\n", "                ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "+", "sdB", "[", "key", "]", "\n", "", "model_cnt", "+=", "1", "\n", "\n", "", "", "for", "key", "in", "sdA", ":", "\n", "        ", "sdA", "[", "key", "]", "=", "sdA", "[", "key", "]", "/", "float", "(", "model_cnt", ")", "\n", "\n", "", "sd", "=", "sdA", "\n", "if", "'module.effnet._fc.weight'", "in", "sd", ".", "keys", "(", ")", ":", "\n", "        ", "del", "sd", "[", "'module.effnet._fc.weight'", "]", "\n", "del", "sd", "[", "'module.effnet._fc.bias'", "]", "\n", "torch", ".", "save", "(", "sd", ",", "'../../pretrained_models/audioset/as_mdl_0_wa.pth'", ")", "\n", "\n", "", "audio_model", "=", "models", ".", "EffNetAttention", "(", "label_dim", "=", "num_class", ",", "b", "=", "2", ",", "pretrain", "=", "False", ",", "head_num", "=", "4", ")", "\n", "audio_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "audio_model", ".", "load_state_dict", "(", "sd", ",", "strict", "=", "True", ")", "\n", "\n", "args", ".", "exp_dir", "=", "base_path", "\n", "\n", "stats", ",", "_", "=", "validate", "(", "audio_model", ",", "eval_loader", ",", "args", ",", "'wa'", ")", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "dprime", "=", "d_prime", "(", "mAUC", ")", "\n", "ensemble_res", "[", "model_idx", ",", ":", "]", "=", "[", "mAP", ",", "mAUC", ",", "dprime", "]", "\n", "print", "(", "\"Model {:d} {:s} mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "model_idx", ",", "mdl", ",", "mAP", ",", "mAUC", ",", "dprime", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.ensemble.weight_averaging.d_prime": [[62, 66], ["scipy.stats.norm", "stats.norm.ppf", "numpy.sqrt"], "function", ["None"], ["", "def", "d_prime", "(", "auc", ")", ":", "\n", "    ", "standard_normal", "=", "stats", ".", "norm", "(", ")", "\n", "d_prime", "=", "standard_normal", ".", "ppf", "(", "auc", ")", "*", "np", ".", "sqrt", "(", "2.0", ")", "\n", "return", "d_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.ensemble.ensemble.get_ensemble_res": [[21, 74], ["numpy.zeros", "torch.device", "enumerate", "numpy.loadtxt", "numpy.loadtxt", "numpy.zeros", "range", "numpy.mean", "calculate_stats", "numpy.mean", "numpy.mean", "ensemble.d_prime", "print", "range", "print", "numpy.savetxt", "os.path.exists", "os.mkdir", "print", "print", "torch.load", "models.EffNetAttention", "torch.nn.DataParallel", "torch.nn.DataParallel.load_state_dict", "traintest.validate", "numpy.mean", "numpy.mean", "ensemble.d_prime", "print", "len", "numpy.loadtxt", "len", "print", "torch.cuda.is_available", "torch.load.keys", "torch.save", "len", "len", "len", "str"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.calculate_stats", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.d_prime", "home.repos.pwc.inspect_result.YuanGongND_psla.src.traintest.validate", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.d_prime"], ["def", "get_ensemble_res", "(", "mdl_list", ",", "base_path", ",", "dataset", "=", "'audioset'", ")", ":", "\n", "    ", "num_class", "=", "527", "if", "dataset", "==", "'audioset'", "else", "200", "\n", "# the 0-len(mdl_list) rows record the results of single models, the last row record the result of the ensemble model.", "\n", "ensemble_res", "=", "np", ".", "zeros", "(", "[", "len", "(", "mdl_list", ")", "+", "1", ",", "3", "]", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "base_path", ")", "==", "False", ":", "\n", "        ", "os", ".", "mkdir", "(", "base_path", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "for", "model_idx", ",", "mdl", "in", "enumerate", "(", "mdl_list", ")", ":", "\n", "        ", "print", "(", "'-----------------------'", ")", "\n", "print", "(", "'now loading model {:d}: {:s}'", ".", "format", "(", "model_idx", ",", "mdl", ")", ")", "\n", "\n", "# sd = torch.load('/Users/yuan/Documents/ast/pretrained_models/audio_model_wa.pth', map_location=device)", "\n", "sd", "=", "torch", ".", "load", "(", "mdl", ",", "map_location", "=", "device", ")", "\n", "if", "'module.effnet._fc.weight'", "in", "sd", ".", "keys", "(", ")", ":", "\n", "            ", "del", "sd", "[", "'module.effnet._fc.weight'", "]", "\n", "del", "sd", "[", "'module.effnet._fc.bias'", "]", "\n", "torch", ".", "save", "(", "sd", ",", "mdl", ")", "\n", "", "audio_model", "=", "models", ".", "EffNetAttention", "(", "label_dim", "=", "num_class", ",", "b", "=", "2", ",", "pretrain", "=", "False", ",", "head_num", "=", "4", ")", "\n", "audio_model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "audio_model", ")", "\n", "audio_model", ".", "load_state_dict", "(", "sd", ",", "strict", "=", "True", ")", "\n", "\n", "args", ".", "exp_dir", "=", "base_path", "\n", "\n", "stats", ",", "_", "=", "validate", "(", "audio_model", ",", "eval_loader", ",", "args", ",", "model_idx", ")", "\n", "mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "dprime", "=", "d_prime", "(", "mAUC", ")", "\n", "ensemble_res", "[", "model_idx", ",", ":", "]", "=", "[", "mAP", ",", "mAUC", ",", "dprime", "]", "\n", "print", "(", "\"Model {:d} {:s} mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "model_idx", ",", "mdl", ",", "mAP", ",", "mAUC", ",", "dprime", ")", ")", "\n", "\n", "# calculate the ensemble result", "\n", "# get the ground truth label", "\n", "", "target", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/target.csv'", ",", "delimiter", "=", "','", ")", "\n", "# get the ground truth label", "\n", "prediction_sample", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/predictions_0.csv'", ",", "delimiter", "=", "','", ")", "\n", "# allocate memory space for the ensemble prediction", "\n", "predictions_table", "=", "np", ".", "zeros", "(", "[", "len", "(", "mdl_list", ")", ",", "prediction_sample", ".", "shape", "[", "0", "]", ",", "prediction_sample", ".", "shape", "[", "1", "]", "]", ")", "\n", "for", "model_idx", "in", "range", "(", "0", ",", "len", "(", "mdl_list", ")", ")", ":", "\n", "        ", "predictions_table", "[", "model_idx", ",", ":", ",", ":", "]", "=", "np", ".", "loadtxt", "(", "base_path", "+", "'/predictions/predictions_'", "+", "str", "(", "model_idx", ")", "+", "'.csv'", ",", "delimiter", "=", "','", ")", "\n", "model_idx", "+=", "1", "\n", "\n", "", "ensemble_predictions", "=", "np", ".", "mean", "(", "predictions_table", ",", "axis", "=", "0", ")", "\n", "stats", "=", "calculate_stats", "(", "ensemble_predictions", ",", "target", ")", "\n", "ensemble_mAP", "=", "np", ".", "mean", "(", "[", "stat", "[", "'AP'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "ensemble_mAUC", "=", "np", ".", "mean", "(", "[", "stat", "[", "'auc'", "]", "for", "stat", "in", "stats", "]", ")", "\n", "ensemble_dprime", "=", "d_prime", "(", "ensemble_mAUC", ")", "\n", "ensemble_res", "[", "-", "1", ",", ":", "]", "=", "[", "ensemble_mAP", ",", "ensemble_mAUC", ",", "ensemble_dprime", "]", "\n", "print", "(", "'---------------Ensemble Result Summary---------------'", ")", "\n", "for", "model_idx", "in", "range", "(", "len", "(", "mdl_list", ")", ")", ":", "\n", "        ", "print", "(", "\"Model {:d} {:s} mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "model_idx", ",", "mdl_list", "[", "model_idx", "]", ",", "ensemble_res", "[", "model_idx", ",", "0", "]", ",", "ensemble_res", "[", "model_idx", ",", "1", "]", ",", "ensemble_res", "[", "model_idx", ",", "2", "]", ")", ")", "\n", "", "print", "(", "\"Ensemble {:d} Models mAP: {:.6f}, AUC: {:.6f}, d-prime: {:.6f}\"", ".", "format", "(", "len", "(", "mdl_list", ")", ",", "ensemble_mAP", ",", "ensemble_mAUC", ",", "ensemble_dprime", ")", ")", "\n", "np", ".", "savetxt", "(", "base_path", "+", "'/ensemble_result.csv'", ",", "ensemble_res", ",", "delimiter", "=", "','", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.ensemble.ensemble.d_prime": [[75, 79], ["scipy.stats.norm", "stats.norm.ppf", "numpy.sqrt"], "function", ["None"], ["", "def", "d_prime", "(", "auc", ")", ":", "\n", "    ", "standard_normal", "=", "stats", ".", "norm", "(", ")", "\n", "d_prime", "=", "standard_normal", ".", "ppf", "(", "auc", ")", "*", "np", ".", "sqrt", "(", "2.0", ")", "\n", "return", "d_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.ResNetAttention.__init__": [[8, 31], ["torch.Module.__init__", "torchvision.models.resnet50", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "HigherModels.Attention", "torch.AvgPool2d", "torch.AvgPool2d", "print", "print"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_dim", "=", "527", ",", "pretrain", "=", "True", ")", ":", "\n", "        ", "super", "(", "ResNetAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "\n", "if", "pretrain", "==", "False", ":", "\n", "            ", "print", "(", "'ResNet50 Model Trained from Scratch (ImageNet Pretraining NOT Used).'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Now Use ImageNet Pretrained ResNet50 Model.'", ")", "\n", "\n", "", "self", ".", "model", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "3", ",", "3", ")", ",", "bias", "=", "False", ")", "\n", "\n", "# remove the original ImageNet classification layers to save space.", "\n", "self", ".", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "model", ".", "avgpool", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "\n", "# attention pooling module", "\n", "self", ".", "attention", "=", "Attention", "(", "\n", "2048", ",", "\n", "label_dim", ",", "\n", "att_activation", "=", "'sigmoid'", ",", "\n", "cla_activation", "=", "'sigmoid'", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "(", "4", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.ResNetAttention.forward": [[32, 44], ["x.transpose.transpose.unsqueeze", "x.transpose.transpose.transpose", "Models.ResNetAttention.model", "x.transpose.transpose.reshape", "Models.ResNetAttention.avgpool", "x.transpose.transpose.transpose", "Models.ResNetAttention.attention"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "batch_size", ",", "2048", ",", "4", ",", "33", "]", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "out", ",", "norm_att", "=", "self", ".", "attention", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.MBNet.__init__": [[46, 53], ["torch.Module.__init__", "torchvision.models.mobilenet_v2", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_dim", "=", "527", ",", "pretrain", "=", "True", ")", ":", "\n", "        ", "super", "(", "MBNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "torchvision", ".", "models", ".", "mobilenet_v2", "(", "pretrained", "=", "pretrain", ")", "\n", "\n", "self", ".", "model", ".", "features", "[", "0", "]", "[", "0", "]", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "model", ".", "classifier", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", "=", "1280", ",", "out_features", "=", "label_dim", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.MBNet.forward": [[54, 61], ["x.transpose.transpose.unsqueeze", "x.transpose.transpose.transpose", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "Models.MBNet.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "nframes", ")", ":", "\n", "# expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "\n", "out", "=", "torch", ".", "sigmoid", "(", "self", ".", "model", "(", "x", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.EffNetAttention.__init__": [[64, 103], ["torch.Module.__init__", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Identity", "torch.Identity", "print", "efficientnet_pytorch.EfficientNet.from_name", "print", "efficientnet_pytorch.EfficientNet.from_pretrained", "print", "HigherModels.MHeadAttention", "print", "HigherModels.Attention", "str", "str", "print", "HigherModels.MeanPooling", "ValueError"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_dim", "=", "527", ",", "b", "=", "0", ",", "pretrain", "=", "True", ",", "head_num", "=", "4", ")", ":", "\n", "        ", "super", "(", "EffNetAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "middim", "=", "[", "1280", ",", "1280", ",", "1408", ",", "1536", ",", "1792", ",", "2048", ",", "2304", ",", "2560", "]", "\n", "if", "pretrain", "==", "False", ":", "\n", "            ", "print", "(", "'EfficientNet Model Trained from Scratch (ImageNet Pretraining NOT Used).'", ")", "\n", "self", ".", "effnet", "=", "EfficientNet", ".", "from_name", "(", "'efficientnet-b'", "+", "str", "(", "b", ")", ",", "in_channels", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Now Use ImageNet Pretrained EfficientNet-B{:d} Model.'", ".", "format", "(", "b", ")", ")", "\n", "self", ".", "effnet", "=", "EfficientNet", ".", "from_pretrained", "(", "'efficientnet-b'", "+", "str", "(", "b", ")", ",", "in_channels", "=", "1", ")", "\n", "# multi-head attention pooling", "\n", "", "if", "head_num", ">", "1", ":", "\n", "            ", "print", "(", "'Model with {:d} attention heads'", ".", "format", "(", "head_num", ")", ")", "\n", "self", ".", "attention", "=", "MHeadAttention", "(", "\n", "self", ".", "middim", "[", "b", "]", ",", "\n", "label_dim", ",", "\n", "att_activation", "=", "'sigmoid'", ",", "\n", "cla_activation", "=", "'sigmoid'", ")", "\n", "# single-head attention pooling", "\n", "", "elif", "head_num", "==", "1", ":", "\n", "            ", "print", "(", "'Model with single attention heads'", ")", "\n", "self", ".", "attention", "=", "Attention", "(", "\n", "self", ".", "middim", "[", "b", "]", ",", "\n", "label_dim", ",", "\n", "att_activation", "=", "'sigmoid'", ",", "\n", "cla_activation", "=", "'sigmoid'", ")", "\n", "# mean pooling (no attention)", "\n", "", "elif", "head_num", "==", "0", ":", "\n", "            ", "print", "(", "'Model with mean pooling (NO Attention Heads)'", ")", "\n", "self", ".", "attention", "=", "MeanPooling", "(", "\n", "self", ".", "middim", "[", "b", "]", ",", "\n", "label_dim", ",", "\n", "att_activation", "=", "'sigmoid'", ",", "\n", "cla_activation", "=", "'sigmoid'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Attention head must be integer >= 0, 0=mean pooling, 1=single-head attention, >1=multi-head attention.'", ")", "\n", "\n", "", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "(", "4", ",", "1", ")", ")", "\n", "#remove the original ImageNet classification layers to save space.", "\n", "self", ".", "effnet", ".", "_fc", "=", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.Models.EffNetAttention.forward": [[104, 114], ["x.transpose.transpose.unsqueeze", "x.transpose.transpose.transpose", "Models.EffNetAttention.effnet.extract_features", "Models.EffNetAttention.avgpool", "x.transpose.transpose.transpose", "Models.EffNetAttention.attention"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "nframes", "=", "1056", ")", ":", "\n", "# expect input x = (batch_size, time_frame_num, frequency_bins), e.g., (12, 1024, 128)", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "\n", "x", "=", "self", ".", "effnet", ".", "extract_features", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "2", ",", "3", ")", "\n", "out", ",", "norm_att", "=", "self", ".", "attention", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.Attention.__init__": [[24, 43], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "HigherModels.Attention.init_weights"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__", "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "att_activation", ",", "cla_activation", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "att_activation", "=", "att_activation", "\n", "self", ".", "cla_activation", "=", "cla_activation", "\n", "\n", "self", ".", "att", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "n_in", ",", "out_channels", "=", "n_out", ",", "kernel_size", "=", "(", "\n", "1", ",", "1", ")", ",", "stride", "=", "(", "\n", "1", ",", "1", ")", ",", "padding", "=", "(", "\n", "0", ",", "0", ")", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "cla", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "n_in", ",", "out_channels", "=", "n_out", ",", "kernel_size", "=", "(", "\n", "1", ",", "1", ")", ",", "stride", "=", "(", "\n", "1", ",", "1", ")", ",", "padding", "=", "(", "\n", "0", ",", "0", ")", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.Attention.init_weights": [[45, 48], ["HigherModels.init_layer", "HigherModels.init_layer"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.init_layer", "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.init_layer"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_layer", "(", "self", ".", "att", ")", "\n", "init_layer", "(", "self", ".", "cla", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.Attention.activate": [[49, 62], ["torch.relu", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "activate", "(", "self", ",", "x", ",", "activation", ")", ":", "\n", "\n", "        ", "if", "activation", "==", "'linear'", ":", "\n", "            ", "return", "x", "\n", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "return", "F", ".", "relu", "(", "x", ")", "\n", "\n", "", "elif", "activation", "==", "'sigmoid'", ":", "\n", "            ", "return", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n", "", "elif", "activation", "==", "'softmax'", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.Attention.forward": [[63, 83], ["HigherModels.Attention.att", "HigherModels.Attention.activate", "HigherModels.Attention.cla", "HigherModels.Attention.activate", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate", "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"input: (samples_num, freq_bins, time_steps, 1)\n        \"\"\"", "\n", "\n", "att", "=", "self", ".", "att", "(", "x", ")", "\n", "att", "=", "self", ".", "activate", "(", "att", ",", "self", ".", "att_activation", ")", "\n", "\n", "cla", "=", "self", ".", "cla", "(", "x", ")", "\n", "cla", "=", "self", ".", "activate", "(", "cla", ",", "self", ".", "cla_activation", ")", "\n", "\n", "att", "=", "att", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# (samples_num, classes_num, time_steps)", "\n", "cla", "=", "cla", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# (samples_num, classes_num, time_steps)", "\n", "\n", "epsilon", "=", "1e-7", "\n", "att", "=", "torch", ".", "clamp", "(", "att", ",", "epsilon", ",", "1.", "-", "epsilon", ")", "\n", "\n", "norm_att", "=", "att", "/", "torch", ".", "sum", "(", "att", ",", "dim", "=", "2", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "x", "=", "torch", ".", "sum", "(", "norm_att", "*", "cla", ",", "dim", "=", "2", ")", "\n", "\n", "return", "x", ",", "norm_att", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.__init__": [[85, 97], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "HigherModels.MeanPooling.init_weights"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__", "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "att_activation", ",", "cla_activation", ")", ":", "\n", "        ", "super", "(", "MeanPooling", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cla_activation", "=", "cla_activation", "\n", "\n", "self", ".", "cla", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "n_in", ",", "out_channels", "=", "n_out", ",", "kernel_size", "=", "(", "\n", "1", ",", "1", ")", ",", "stride", "=", "(", "\n", "1", ",", "1", ")", ",", "padding", "=", "(", "\n", "0", ",", "0", ")", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.init_weights": [[98, 100], ["HigherModels.init_layer"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.init_layer"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "init_layer", "(", "self", ".", "cla", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.activate": [[101, 103], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "activate", "(", "self", ",", "x", ",", "activation", ")", ":", "\n", "        ", "return", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MeanPooling.forward": [[104, 116], ["HigherModels.MeanPooling.cla", "HigherModels.MeanPooling.activate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"input: (samples_num, freq_bins, time_steps, 1)\n        \"\"\"", "\n", "\n", "cla", "=", "self", ".", "cla", "(", "x", ")", "\n", "cla", "=", "self", ".", "activate", "(", "cla", ",", "self", ".", "cla_activation", ")", "\n", "\n", "cla", "=", "cla", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# (samples_num, classes_num, time_steps)", "\n", "\n", "x", "=", "torch", ".", "mean", "(", "cla", ",", "dim", "=", "2", ")", "\n", "\n", "return", "x", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.__init__": [[118, 133], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Parameter", "torch.Parameter", "torch.Parameter", "HigherModels.MHeadAttention.att.append", "HigherModels.MHeadAttention.cla.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "att_activation", ",", "cla_activation", ",", "head_num", "=", "4", ")", ":", "\n", "        ", "super", "(", "MHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "head_num", "=", "head_num", "\n", "\n", "self", ".", "att_activation", "=", "att_activation", "\n", "self", ".", "cla_activation", "=", "cla_activation", "\n", "\n", "self", ".", "att", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "cla", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "head_num", ")", ":", "\n", "            ", "self", ".", "att", ".", "append", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "n_in", ",", "out_channels", "=", "n_out", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "True", ")", ")", "\n", "self", ".", "cla", ".", "append", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "n_in", ",", "out_channels", "=", "n_out", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "True", ")", ")", "\n", "\n", "", "self", ".", "head_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "1.0", "/", "self", ".", "head_num", "]", "*", "self", ".", "head_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate": [[134, 143], ["torch.relu", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "activate", "(", "self", ",", "x", ",", "activation", ")", ":", "\n", "        ", "if", "activation", "==", "'linear'", ":", "\n", "            ", "return", "x", "\n", "", "elif", "activation", "==", "'relu'", ":", "\n", "            ", "return", "F", ".", "relu", "(", "x", ")", "\n", "", "elif", "activation", "==", "'sigmoid'", ":", "\n", "            ", "return", "torch", ".", "sigmoid", "(", "x", ")", "\n", "", "elif", "activation", "==", "'softmax'", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.forward": [[144, 168], ["range", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "HigherModels.MHeadAttention.activate", "HigherModels.MHeadAttention.activate", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "x_out.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate", "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.MHeadAttention.activate"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"input: (samples_num, freq_bins, time_steps, 1)\n        \"\"\"", "\n", "\n", "x_out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "head_num", ")", ":", "\n", "            ", "att", "=", "self", ".", "att", "[", "i", "]", "(", "x", ")", "\n", "att", "=", "self", ".", "activate", "(", "att", ",", "self", ".", "att_activation", ")", "\n", "\n", "cla", "=", "self", ".", "cla", "[", "i", "]", "(", "x", ")", "\n", "cla", "=", "self", ".", "activate", "(", "cla", ",", "self", ".", "cla_activation", ")", "\n", "\n", "att", "=", "att", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# (samples_num, classes_num, time_steps)", "\n", "cla", "=", "cla", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# (samples_num, classes_num, time_steps)", "\n", "\n", "epsilon", "=", "1e-7", "\n", "att", "=", "torch", ".", "clamp", "(", "att", ",", "epsilon", ",", "1.", "-", "epsilon", ")", "\n", "\n", "norm_att", "=", "att", "/", "torch", ".", "sum", "(", "att", ",", "dim", "=", "2", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "x_out", ".", "append", "(", "torch", ".", "sum", "(", "norm_att", "*", "cla", ",", "dim", "=", "2", ")", "*", "self", ".", "head_weight", "[", "i", "]", ")", "\n", "\n", "", "x", "=", "(", "torch", ".", "stack", "(", "x_out", ",", "dim", "=", "0", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "return", "x", ",", "[", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.init_layer": [[6, 19], ["math.sqrt", "layer.weight.data.uniform_", "layer.weight.ndimension", "layer.weight.size", "math.sqrt", "layer.bias.data.fill_", "layer.weight.ndimension", "layer.weight.size"], "function", ["None"], ["def", "init_layer", "(", "layer", ")", ":", "\n", "    ", "if", "layer", ".", "weight", ".", "ndimension", "(", ")", "==", "4", ":", "\n", "        ", "(", "n_out", ",", "n_in", ",", "height", ",", "width", ")", "=", "layer", ".", "weight", ".", "size", "(", ")", "\n", "n", "=", "n_in", "*", "height", "*", "width", "\n", "", "elif", "layer", ".", "weight", ".", "ndimension", "(", ")", "==", "2", ":", "\n", "        ", "(", "n_out", ",", "n", ")", "=", "layer", ".", "weight", ".", "size", "(", ")", "\n", "\n", "", "std", "=", "math", ".", "sqrt", "(", "2.", "/", "n", ")", "\n", "scale", "=", "std", "*", "math", ".", "sqrt", "(", "3.", ")", "\n", "layer", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "scale", ",", "scale", ")", "\n", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "layer", ".", "bias", ".", "data", ".", "fill_", "(", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.models.HigherModels.init_bn": [[20, 22], ["bn.weight.data.fill_"], "function", ["None"], ["", "", "def", "init_bn", "(", "bn", ")", ":", "\n", "    ", "bn", ".", "weight", ".", "data", ".", "fill_", "(", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset.__init__": [[48, 87], ["print", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "print", "audioset_dataset.AudiosetDataset.audio_conf.get", "print", "audioset_dataset.AudiosetDataset.audio_conf.get", "print", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.make_index_dict", "len", "print", "open", "json.load", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "print", "print", "print", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get", "audioset_dataset.AudiosetDataset.audio_conf.get"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.make_index_dict"], ["    ", "def", "__init__", "(", "self", ",", "dataset_json_file", ",", "audio_conf", ",", "label_csv", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Dataset that manages audio recordings\n        :param audio_conf: Dictionary containing the audio loading and preprocessing settings\n        :param dataset_json_file\n        \"\"\"", "\n", "self", ".", "datapath", "=", "dataset_json_file", "\n", "with", "open", "(", "dataset_json_file", ",", "'r'", ")", "as", "fp", ":", "\n", "            ", "data_json", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "self", ".", "data", "=", "data_json", "[", "'data'", "]", "\n", "self", ".", "audio_conf", "=", "audio_conf", "\n", "print", "(", "'---------------the {:s} dataloader---------------'", ".", "format", "(", "self", ".", "audio_conf", ".", "get", "(", "'mode'", ")", ")", ")", "\n", "self", ".", "melbins", "=", "self", ".", "audio_conf", ".", "get", "(", "'num_mel_bins'", ")", "\n", "self", ".", "freqm", "=", "self", ".", "audio_conf", ".", "get", "(", "'freqm'", ")", "\n", "self", ".", "timem", "=", "self", ".", "audio_conf", ".", "get", "(", "'timem'", ")", "\n", "print", "(", "'now using following mask: {:d} freq, {:d} time'", ".", "format", "(", "self", ".", "audio_conf", ".", "get", "(", "'freqm'", ")", ",", "self", ".", "audio_conf", ".", "get", "(", "'timem'", ")", ")", ")", "\n", "self", ".", "mixup", "=", "self", ".", "audio_conf", ".", "get", "(", "'mixup'", ")", "\n", "print", "(", "'now using mix-up with rate {:f}'", ".", "format", "(", "self", ".", "mixup", ")", ")", "\n", "self", ".", "dataset", "=", "self", ".", "audio_conf", ".", "get", "(", "'dataset'", ")", "\n", "print", "(", "'now process '", "+", "self", ".", "dataset", ")", "\n", "# dataset spectrogram mean and std, used to normalize the input", "\n", "self", ".", "norm_mean", "=", "self", ".", "audio_conf", ".", "get", "(", "'mean'", ")", "\n", "self", ".", "norm_std", "=", "self", ".", "audio_conf", ".", "get", "(", "'std'", ")", "\n", "# skip_norm is a flag that if you want to skip normalization to compute the normalization stats using src/get_norm_stats.py, if Ture, input normalization will be skipped for correctly calculating the stats.", "\n", "# set it as True ONLY when you are getting the normalization stats.", "\n", "self", ".", "skip_norm", "=", "self", ".", "audio_conf", ".", "get", "(", "'skip_norm'", ")", "if", "self", ".", "audio_conf", ".", "get", "(", "'skip_norm'", ")", "else", "False", "\n", "if", "self", ".", "skip_norm", ":", "\n", "            ", "print", "(", "'now skip normalization (use it ONLY when you are computing the normalization stats).'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'use dataset mean {:.3f} and std {:.3f} to normalize the input.'", ".", "format", "(", "self", ".", "norm_mean", ",", "self", ".", "norm_std", ")", ")", "\n", "# if add noise for data augmentation", "\n", "", "self", ".", "noise", "=", "self", ".", "audio_conf", ".", "get", "(", "'noise'", ")", "\n", "if", "self", ".", "noise", "==", "True", ":", "\n", "            ", "print", "(", "'now use noise augmentation'", ")", "\n", "\n", "", "self", ".", "index_dict", "=", "make_index_dict", "(", "label_csv", ")", "\n", "self", ".", "label_num", "=", "len", "(", "self", ".", "index_dict", ")", "\n", "print", "(", "'number of classes is {:d}'", ".", "format", "(", "self", ".", "label_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset._wav2fbank": [[88, 138], ["torchaudio.compliance.kaldi.fbank", "audioset_dataset.AudiosetDataset.audio_conf.get", "torchaudio.load", "torchaudio.load", "torchaudio.load", "numpy.random.beta", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d.", "torch.nn.ZeroPad2d.", "waveform.mean", "waveform1.mean", "waveform2.mean", "mix_waveform.mean", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_wav2fbank", "(", "self", ",", "filename", ",", "filename2", "=", "None", ")", ":", "\n", "# mixup", "\n", "        ", "if", "filename2", "==", "None", ":", "\n", "            ", "waveform", ",", "sr", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "waveform", "=", "waveform", "-", "waveform", ".", "mean", "(", ")", "\n", "# mixup", "\n", "", "else", ":", "\n", "            ", "waveform1", ",", "sr", "=", "torchaudio", ".", "load", "(", "filename", ")", "\n", "waveform2", ",", "_", "=", "torchaudio", ".", "load", "(", "filename2", ")", "\n", "\n", "waveform1", "=", "waveform1", "-", "waveform1", ".", "mean", "(", ")", "\n", "waveform2", "=", "waveform2", "-", "waveform2", ".", "mean", "(", ")", "\n", "\n", "if", "waveform1", ".", "shape", "[", "1", "]", "!=", "waveform2", ".", "shape", "[", "1", "]", ":", "\n", "                ", "if", "waveform1", ".", "shape", "[", "1", "]", ">", "waveform2", ".", "shape", "[", "1", "]", ":", "\n", "# padding", "\n", "                    ", "temp_wav", "=", "torch", ".", "zeros", "(", "1", ",", "waveform1", ".", "shape", "[", "1", "]", ")", "\n", "temp_wav", "[", "0", ",", "0", ":", "waveform2", ".", "shape", "[", "1", "]", "]", "=", "waveform2", "\n", "waveform2", "=", "temp_wav", "\n", "", "else", ":", "\n", "# cutting", "\n", "                    ", "waveform2", "=", "waveform2", "[", "0", ",", "0", ":", "waveform1", ".", "shape", "[", "1", "]", "]", "\n", "\n", "# sample lambda from uniform distribution", "\n", "#mix_lambda = random.random()", "\n", "# sample lambda from beta distribtion", "\n", "", "", "mix_lambda", "=", "np", ".", "random", ".", "beta", "(", "10", ",", "10", ")", "\n", "\n", "mix_waveform", "=", "mix_lambda", "*", "waveform1", "+", "(", "1", "-", "mix_lambda", ")", "*", "waveform2", "\n", "waveform", "=", "mix_waveform", "-", "mix_waveform", ".", "mean", "(", ")", "\n", "\n", "", "fbank", "=", "torchaudio", ".", "compliance", ".", "kaldi", ".", "fbank", "(", "waveform", ",", "htk_compat", "=", "True", ",", "sample_frequency", "=", "sr", ",", "use_energy", "=", "False", ",", "\n", "window_type", "=", "'hanning'", ",", "num_mel_bins", "=", "self", ".", "melbins", ",", "dither", "=", "0.0", ",", "frame_shift", "=", "10", ")", "\n", "\n", "target_length", "=", "self", ".", "audio_conf", ".", "get", "(", "'target_length'", ")", "\n", "n_frames", "=", "fbank", ".", "shape", "[", "0", "]", "\n", "\n", "p", "=", "target_length", "-", "n_frames", "\n", "\n", "# cut and pad", "\n", "if", "p", ">", "0", ":", "\n", "            ", "m", "=", "torch", ".", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "0", ",", "0", ",", "p", ")", ")", "\n", "fbank", "=", "m", "(", "fbank", ")", "\n", "", "elif", "p", "<", "0", ":", "\n", "            ", "fbank", "=", "fbank", "[", "0", ":", "target_length", ",", ":", "]", "\n", "\n", "", "if", "filename2", "==", "None", ":", "\n", "            ", "return", "fbank", ",", "0", "\n", "", "else", ":", "\n", "            ", "return", "fbank", ",", "mix_lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset.__getitem__": [[139, 203], ["torchaudio.transforms.FrequencyMasking", "torchaudio.transforms.TimeMasking", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.roll.unsqueeze", "torch.roll.unsqueeze", "torch.roll.squeeze", "torch.roll.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "random.random", "random.randint", "audioset_dataset.AudiosetDataset._wav2fbank", "numpy.zeros", "datum[].split", "mix_datum[].split", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.zeros", "audioset_dataset.AudiosetDataset._wav2fbank", "datum[].split", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torchaudio.transforms.FrequencyMasking.", "torchaudio.transforms.TimeMasking.", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "numpy.random.randint", "len", "int", "int", "int", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset._wav2fbank", "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset._wav2fbank"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        returns: image, audio, nframes\n        where image is a FloatTensor of size (3, H, W)\n        audio is a FloatTensor of size (N_freq, N_frames) for spectrogram, or (N_frames) for waveform\n        nframes is an integer\n        \"\"\"", "\n", "# do mix-up for this sample (controlled by the given mixup rate)", "\n", "if", "random", ".", "random", "(", ")", "<", "self", ".", "mixup", ":", "\n", "            ", "datum", "=", "self", ".", "data", "[", "index", "]", "\n", "# find another sample to mix, also do balance sampling", "\n", "# sample the other sample from the multinomial distribution, will make the performance worse", "\n", "# mix_sample_idx = np.random.choice(len(self.data), p=self.sample_weight_file)", "\n", "# sample the other sample from the uniform distribution", "\n", "mix_sample_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "data", ")", "-", "1", ")", "\n", "mix_datum", "=", "self", ".", "data", "[", "mix_sample_idx", "]", "\n", "# get the mixed fbank", "\n", "fbank", ",", "mix_lambda", "=", "self", ".", "_wav2fbank", "(", "datum", "[", "'wav'", "]", ",", "mix_datum", "[", "'wav'", "]", ")", "\n", "# initialize the label", "\n", "label_indices", "=", "np", ".", "zeros", "(", "self", ".", "label_num", ")", "\n", "# add sample 1 labels", "\n", "for", "label_str", "in", "datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "+=", "mix_lambda", "\n", "# add sample 2 labels", "\n", "", "for", "label_str", "in", "mix_datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "+=", "(", "1.0", "-", "mix_lambda", ")", "\n", "", "label_indices", "=", "torch", ".", "FloatTensor", "(", "label_indices", ")", "\n", "# if not do mixup", "\n", "", "else", ":", "\n", "            ", "datum", "=", "self", ".", "data", "[", "index", "]", "\n", "label_indices", "=", "np", ".", "zeros", "(", "self", ".", "label_num", ")", "\n", "fbank", ",", "mix_lambda", "=", "self", ".", "_wav2fbank", "(", "datum", "[", "'wav'", "]", ")", "\n", "for", "label_str", "in", "datum", "[", "'labels'", "]", ".", "split", "(", "','", ")", ":", "\n", "                ", "label_indices", "[", "int", "(", "self", ".", "index_dict", "[", "label_str", "]", ")", "]", "=", "1.0", "\n", "\n", "", "label_indices", "=", "torch", ".", "FloatTensor", "(", "label_indices", ")", "\n", "\n", "# SpecAug, not do for eval set", "\n", "", "freqm", "=", "torchaudio", ".", "transforms", ".", "FrequencyMasking", "(", "self", ".", "freqm", ")", "\n", "timem", "=", "torchaudio", ".", "transforms", ".", "TimeMasking", "(", "self", ".", "timem", ")", "\n", "fbank", "=", "torch", ".", "transpose", "(", "fbank", ",", "0", ",", "1", ")", "\n", "# this is just to satisfy new torchaudio version.", "\n", "fbank", "=", "fbank", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "freqm", "!=", "0", ":", "\n", "            ", "fbank", "=", "freqm", "(", "fbank", ")", "\n", "", "if", "self", ".", "timem", "!=", "0", ":", "\n", "            ", "fbank", "=", "timem", "(", "fbank", ")", "\n", "# squeeze back", "\n", "", "fbank", "=", "fbank", ".", "squeeze", "(", "0", ")", "\n", "fbank", "=", "torch", ".", "transpose", "(", "fbank", ",", "0", ",", "1", ")", "\n", "\n", "# normalize the input for both training and test", "\n", "if", "not", "self", ".", "skip_norm", ":", "\n", "            ", "fbank", "=", "(", "fbank", "-", "self", ".", "norm_mean", ")", "/", "(", "self", ".", "norm_std", ")", "\n", "# skip normalization the input if you are trying to get the normalization stats.", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "self", ".", "noise", "==", "True", ":", "\n", "            ", "fbank", "=", "fbank", "+", "torch", ".", "rand", "(", "fbank", ".", "shape", "[", "0", "]", ",", "fbank", ".", "shape", "[", "1", "]", ")", "*", "np", ".", "random", ".", "rand", "(", ")", "/", "10", "\n", "fbank", "=", "torch", ".", "roll", "(", "fbank", ",", "np", ".", "random", ".", "randint", "(", "-", "10", ",", "10", ")", ",", "0", ")", "\n", "\n", "# the output fbank shape is [time_frame_num, frequency_bins], e.g., [1024, 128]", "\n", "", "return", "fbank", ",", "label_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.AudiosetDataset.__len__": [[204, 206], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.make_index_dict": [[12, 21], ["open", "csv.DictReader"], "function", ["None"], ["def", "make_index_dict", "(", "label_csv", ")", ":", "\n", "    ", "index_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "index_lookup", "[", "row", "[", "'mid'", "]", "]", "=", "row", "[", "'index'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "index_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.make_name_dict": [[22, 31], ["open", "csv.DictReader"], "function", ["None"], ["", "def", "make_name_dict", "(", "label_csv", ")", ":", "\n", "    ", "name_lookup", "=", "{", "}", "\n", "with", "open", "(", "label_csv", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "name_lookup", "[", "row", "[", "'index'", "]", "]", "=", "row", "[", "'display_name'", "]", "\n", "line_count", "+=", "1", "\n", "", "", "return", "name_lookup", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.lookup_list": [[32, 38], ["audioset_dataset.make_name_dict", "label_list.append"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.make_name_dict"], ["", "def", "lookup_list", "(", "index_list", ",", "label_csv", ")", ":", "\n", "    ", "label_list", "=", "[", "]", "\n", "table", "=", "make_name_dict", "(", "label_csv", ")", "\n", "for", "item", "in", "index_list", ":", "\n", "        ", "label_list", ".", "append", "(", "table", "[", "item", "]", ")", "\n", "", "return", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.dataloaders.audioset_dataset.preemphasis": [[39, 46], ["numpy.append"], "function", ["None"], ["", "def", "preemphasis", "(", "signal", ",", "coeff", "=", "0.97", ")", ":", "\n", "    ", "\"\"\"perform preemphasis on the input signal.\n    :param signal: The signal to filter.\n    :param coeff: The preemphasis coefficient. 0 is none, default 0.97.\n    :returns: the filtered signal.\n    \"\"\"", "\n", "return", "np", ".", "append", "(", "signal", "[", "0", "]", ",", "signal", "[", "1", ":", "]", "-", "coeff", "*", "signal", "[", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.d_prime": [[6, 10], ["scipy.stats.norm", "stats.norm.ppf", "numpy.sqrt"], "function", ["None"], ["def", "d_prime", "(", "auc", ")", ":", "\n", "    ", "standard_normal", "=", "stats", ".", "norm", "(", ")", "\n", "d_prime", "=", "standard_normal", ".", "ppf", "(", "auc", ")", "*", "np", ".", "sqrt", "(", "2.0", ")", "\n", "return", "d_prime", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.stats.calculate_stats": [[11, 58], ["range", "sklearn.metrics.average_precision_score", "sklearn.metrics.roc_auc_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_curve", "sklearn.metrics.roc_curve", "scipy.stats.append", "numpy.argmax", "numpy.argmax"], "function", ["None"], ["", "def", "calculate_stats", "(", "output", ",", "target", ")", ":", "\n", "    ", "\"\"\"Calculate statistics including mAP, AUC, etc.\n\n    Args:\n      output: 2d array, (samples_num, classes_num)\n      target: 2d array, (samples_num, classes_num)\n\n    Returns:\n      stats: list of statistic of each class.\n    \"\"\"", "\n", "\n", "classes_num", "=", "target", ".", "shape", "[", "-", "1", "]", "\n", "stats", "=", "[", "]", "\n", "\n", "# Class-wise statistics", "\n", "for", "k", "in", "range", "(", "classes_num", ")", ":", "\n", "\n", "# Average precision", "\n", "        ", "avg_precision", "=", "metrics", ".", "average_precision_score", "(", "\n", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ",", "average", "=", "None", ")", "\n", "\n", "# AUC", "\n", "auc", "=", "metrics", ".", "roc_auc_score", "(", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ",", "average", "=", "None", ")", "\n", "\n", "# Accuracy", "\n", "# this is only used for single-label classification such as esc-50, not for multiple label one such as AudioSet", "\n", "acc", "=", "metrics", ".", "accuracy_score", "(", "np", ".", "argmax", "(", "target", ",", "1", ")", ",", "np", ".", "argmax", "(", "output", ",", "1", ")", ")", "\n", "\n", "# Precisions, recalls", "\n", "(", "precisions", ",", "recalls", ",", "thresholds", ")", "=", "metrics", ".", "precision_recall_curve", "(", "\n", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ")", "\n", "\n", "# FPR, TPR", "\n", "(", "fpr", ",", "tpr", ",", "thresholds", ")", "=", "metrics", ".", "roc_curve", "(", "target", "[", ":", ",", "k", "]", ",", "output", "[", ":", ",", "k", "]", ")", "\n", "\n", "save_every_steps", "=", "1000", "# Sample statistics to reduce size", "\n", "dict", "=", "{", "'precisions'", ":", "precisions", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'recalls'", ":", "recalls", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'AP'", ":", "avg_precision", ",", "\n", "'fpr'", ":", "fpr", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'fnr'", ":", "1.", "-", "tpr", "[", "0", ":", ":", "save_every_steps", "]", ",", "\n", "'auc'", ":", "auc", ",", "\n", "'acc'", ":", "acc", "\n", "}", "\n", "stats", ".", "append", "(", "dict", ")", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.__init__": [[240, 242], ["util.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.reset": [[243, 248], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update": [[249, 254], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.calc_recalls": [[9, 68], ["isinstance", "S.size", "S.topk", "S.topk", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "util.AverageMeter", "range", "S.dim", "S.size", "S.size", "range", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update", "util.AverageMeter.update"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.AverageMeter.update"], ["def", "calc_recalls", "(", "S", ")", ":", "\n", "    ", "\"\"\"\n    Computes recall at 1, 5, and 10 given a similarity matrix S.\n    By convention, rows of S are assumed to correspond to images and columns are captions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "if", "isinstance", "(", "S", ",", "torch", ".", "autograd", ".", "Variable", ")", ":", "\n", "        ", "S", "=", "S", ".", "data", "\n", "", "n", "=", "S", ".", "size", "(", "0", ")", "\n", "A2I_scores", ",", "A2I_ind", "=", "S", ".", "topk", "(", "10", ",", "0", ")", "\n", "I2A_scores", ",", "I2A_ind", "=", "S", ".", "topk", "(", "10", ",", "1", ")", "\n", "A_r1", "=", "AverageMeter", "(", ")", "\n", "A_r5", "=", "AverageMeter", "(", ")", "\n", "A_r10", "=", "AverageMeter", "(", ")", "\n", "I_r1", "=", "AverageMeter", "(", ")", "\n", "I_r5", "=", "AverageMeter", "(", ")", "\n", "I_r10", "=", "AverageMeter", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "A_foundind", "=", "-", "1", "\n", "I_foundind", "=", "-", "1", "\n", "for", "ind", "in", "range", "(", "10", ")", ":", "\n", "            ", "if", "A2I_ind", "[", "ind", ",", "i", "]", "==", "i", ":", "\n", "                ", "I_foundind", "=", "ind", "\n", "", "if", "I2A_ind", "[", "i", ",", "ind", "]", "==", "i", ":", "\n", "                ", "A_foundind", "=", "ind", "\n", "# do r1s", "\n", "", "", "if", "A_foundind", "==", "0", ":", "\n", "            ", "A_r1", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r1", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", "==", "0", ":", "\n", "            ", "I_r1", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r1", ".", "update", "(", "0", ")", "\n", "# do r5s", "\n", "", "if", "A_foundind", ">=", "0", "and", "A_foundind", "<", "5", ":", "\n", "            ", "A_r5", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r5", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", ">=", "0", "and", "I_foundind", "<", "5", ":", "\n", "            ", "I_r5", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r5", ".", "update", "(", "0", ")", "\n", "# do r10s", "\n", "", "if", "A_foundind", ">=", "0", "and", "A_foundind", "<", "10", ":", "\n", "            ", "A_r10", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "A_r10", ".", "update", "(", "0", ")", "\n", "", "if", "I_foundind", ">=", "0", "and", "I_foundind", "<", "10", ":", "\n", "            ", "I_r10", ".", "update", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "I_r10", ".", "update", "(", "0", ")", "\n", "\n", "", "", "recalls", "=", "{", "'A_r1'", ":", "A_r1", ".", "avg", ",", "'A_r5'", ":", "A_r5", ".", "avg", ",", "'A_r10'", ":", "A_r10", ".", "avg", ",", "\n", "'I_r1'", ":", "I_r1", ".", "avg", ",", "'I_r5'", ":", "I_r5", ".", "avg", ",", "'I_r10'", ":", "I_r10", ".", "avg", "}", "\n", "#'A_meanR':A_meanR.avg, 'I_meanR':I_meanR.avg}", "\n", "\n", "return", "recalls", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.computeMatchmap": [[69, 80], ["I.size", "I.size", "I.size", "A.size", "I.view().t", "torch.mm", "torch.mm", "matchmap.view.view", "I.dim", "A.dim", "I.view"], "function", ["None"], ["", "def", "computeMatchmap", "(", "I", ",", "A", ")", ":", "\n", "    ", "assert", "(", "I", ".", "dim", "(", ")", "==", "3", ")", "\n", "assert", "(", "A", ".", "dim", "(", ")", "==", "2", ")", "\n", "D", "=", "I", ".", "size", "(", "0", ")", "\n", "H", "=", "I", ".", "size", "(", "1", ")", "\n", "W", "=", "I", ".", "size", "(", "2", ")", "\n", "T", "=", "A", ".", "size", "(", "1", ")", "\n", "Ir", "=", "I", ".", "view", "(", "D", ",", "-", "1", ")", ".", "t", "(", ")", "\n", "matchmap", "=", "torch", ".", "mm", "(", "Ir", ",", "A", ")", "\n", "matchmap", "=", "matchmap", ".", "view", "(", "H", ",", "W", ",", "T", ")", "\n", "return", "matchmap", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.matchmapSim": [[81, 94], ["M.dim", "M.mean", "M.max", "M_maxH.max", "M_maxHW.mean", "M.max", "M_maxT.mean"], "function", ["None"], ["", "def", "matchmapSim", "(", "M", ",", "simtype", ")", ":", "\n", "    ", "assert", "(", "M", ".", "dim", "(", ")", "==", "3", ")", "\n", "if", "simtype", "==", "'SISA'", ":", "\n", "        ", "return", "M", ".", "mean", "(", ")", "\n", "", "elif", "simtype", "==", "'MISA'", ":", "\n", "        ", "M_maxH", ",", "_", "=", "M", ".", "max", "(", "0", ")", "\n", "M_maxHW", ",", "_", "=", "M_maxH", ".", "max", "(", "0", ")", "\n", "return", "M_maxHW", ".", "mean", "(", ")", "\n", "", "elif", "simtype", "==", "'SIMA'", ":", "\n", "        ", "M_maxT", ",", "_", "=", "M", ".", "max", "(", "2", ")", "\n", "return", "M_maxT", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.sampled_margin_rank_loss": [[95, 124], ["image_outputs.size", "torch.zeros", "torch.zeros", "range", "image_outputs.dim", "audio_outputs.dim", "util.matchmapSim", "util.matchmapSim", "util.matchmapSim", "numpy.random.randint", "numpy.random.randint", "util.computeMatchmap", "util.computeMatchmap", "util.computeMatchmap"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.computeMatchmap", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.computeMatchmap", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.computeMatchmap"], ["", "", "def", "sampled_margin_rank_loss", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ",", "margin", "=", "1.", ",", "simtype", "=", "'MISA'", ")", ":", "\n", "    ", "\"\"\"\n    Computes the triplet margin ranking loss for each anchor image/caption pair\n    The impostor image/caption is randomly sampled from the minibatch\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "3", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "image_outputs", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "I_imp_ind", "=", "i", "\n", "A_imp_ind", "=", "i", "\n", "while", "I_imp_ind", "==", "i", ":", "\n", "            ", "I_imp_ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n", ")", "\n", "", "while", "A_imp_ind", "==", "i", ":", "\n", "            ", "A_imp_ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n", ")", "\n", "", "nF", "=", "nframes", "[", "i", "]", "\n", "nFimp", "=", "nframes", "[", "A_imp_ind", "]", "\n", "anchorsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "i", "]", ",", "audio_outputs", "[", "i", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "Iimpsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "I_imp_ind", "]", ",", "audio_outputs", "[", "i", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "Aimpsim", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "i", "]", ",", "audio_outputs", "[", "A_imp_ind", "]", "[", ":", ",", "0", ":", "nFimp", "]", ")", ",", "simtype", ")", "\n", "A2I_simdif", "=", "margin", "+", "Iimpsim", "-", "anchorsim", "\n", "if", "(", "A2I_simdif", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "A2I_simdif", "\n", "", "I2A_simdif", "=", "margin", "+", "Aimpsim", "-", "anchorsim", "\n", "if", "(", "I2A_simdif", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "I2A_simdif", "\n", "", "", "loss", "=", "loss", "/", "n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.compute_matchmap_similarity_matrix": [[125, 140], ["image_outputs.size", "torch.zeros", "torch.zeros", "range", "image_outputs.dim", "audio_outputs.dim", "range", "max", "util.matchmapSim", "util.computeMatchmap"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.matchmapSim", "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.computeMatchmap"], ["", "def", "compute_matchmap_similarity_matrix", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ",", "simtype", "=", "'MISA'", ")", ":", "\n", "    ", "\"\"\"\n    Assumes image_outputs is a (batchsize, embedding_dim, rows, height) tensor\n    Assumes audio_outputs is a (batchsize, embedding_dim, 1, time) tensor\n    Returns similarity matrix S where images are rows and audios are along the columns\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "3", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "S", "=", "torch", ".", "zeros", "(", "n", ",", "n", ",", "device", "=", "image_outputs", ".", "device", ")", "\n", "for", "image_idx", "in", "range", "(", "n", ")", ":", "\n", "            ", "for", "audio_idx", "in", "range", "(", "n", ")", ":", "\n", "                ", "nF", "=", "max", "(", "1", ",", "nframes", "[", "audio_idx", "]", ")", "\n", "S", "[", "image_idx", ",", "audio_idx", "]", "=", "matchmapSim", "(", "computeMatchmap", "(", "image_outputs", "[", "image_idx", "]", ",", "audio_outputs", "[", "audio_idx", "]", "[", ":", ",", "0", ":", "nF", "]", ")", ",", "simtype", ")", "\n", "", "", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.compute_pooldot_similarity_matrix": [[141, 162], ["image_outputs.size", "torch.AdaptiveAvgPool2d", "nn.AdaptiveAvgPool2d.squeeze().squeeze", "torch.AdaptiveAvgPool2d", "range", "torch.cat().squeeze().squeeze", "torch.cat().squeeze().squeeze", "torch.mm", "torch.mm", "image_outputs.dim", "audio_outputs.dim", "max", "pooled_audio_outputs_list.append", "torch.cat().squeeze().squeeze.t", "nn.AdaptiveAvgPool2d.squeeze", "nn.AdaptiveAvgPool2d.unsqueeze", "torch.cat().squeeze", "torch.cat().squeeze", "nn.AdaptiveAvgPool2d.", "nn.AdaptiveAvgPool2d.", "torch.cat", "torch.cat"], "function", ["None"], ["", "def", "compute_pooldot_similarity_matrix", "(", "image_outputs", ",", "audio_outputs", ",", "nframes", ")", ":", "\n", "    ", "\"\"\"\n    Assumes image_outputs is a (batchsize, embedding_dim, rows, height) tensor\n    Assumes audio_outputs is a (batchsize, embedding_dim, 1, time) tensor\n    Returns similarity matrix S where images are rows and audios are along the columns\n    S[i][j] is computed as the dot product between the meanpooled embeddings of\n    the ith image output and jth audio output\n    \"\"\"", "\n", "assert", "(", "image_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "assert", "(", "audio_outputs", ".", "dim", "(", ")", "==", "4", ")", "\n", "n", "=", "image_outputs", ".", "size", "(", "0", ")", "\n", "imagePoolfunc", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "pooled_image_outputs", "=", "imagePoolfunc", "(", "image_outputs", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "audioPoolfunc", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "pooled_audio_outputs_list", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n", ")", ":", "\n", "        ", "nF", "=", "max", "(", "1", ",", "nframes", "[", "idx", "]", ")", "\n", "pooled_audio_outputs_list", ".", "append", "(", "audioPoolfunc", "(", "audio_outputs", "[", "idx", "]", "[", ":", ",", ":", ",", "0", ":", "nF", "]", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "pooled_audio_outputs", "=", "torch", ".", "cat", "(", "pooled_audio_outputs_list", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "S", "=", "torch", ".", "mm", "(", "pooled_image_outputs", ",", "pooled_audio_outputs", ".", "t", "(", ")", ")", "\n", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.one_imposter_index": [[163, 168], ["random.randint"], "function", ["None"], ["", "def", "one_imposter_index", "(", "i", ",", "N", ")", ":", "\n", "    ", "imp_ind", "=", "random", ".", "randint", "(", "0", ",", "N", "-", "2", ")", "\n", "if", "imp_ind", "==", "i", ":", "\n", "        ", "imp_ind", "=", "N", "-", "1", "\n", "", "return", "imp_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.basic_get_imposter_indices": [[169, 176], ["range", "util.one_imposter_index", "imposter_idc.append"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.one_imposter_index"], ["", "def", "basic_get_imposter_indices", "(", "N", ")", ":", "\n", "    ", "imposter_idc", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "# Select an imposter index for example i:", "\n", "        ", "imp_ind", "=", "one_imposter_index", "(", "i", ",", "N", ")", "\n", "imposter_idc", ".", "append", "(", "imp_ind", ")", "\n", "", "return", "imposter_idc", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.semihardneg_triplet_loss_from_S": [[177, 214], ["S.size", "torch.autograd.Variable", "torch.autograd.Variable", "mask.type_as", "Sp.max", "idc.data.cpu.data.cpu", "torch.LongTensor", "torch.LongTensor", "enumerate", "S.dim", "S.size", "S.size", "torch.zeros().type", "torch.zeros().type", "torch.diag().view", "torch.diag().view", "util.basic_get_imposter_indices", "S.data.type", "torch.min().detach", "torch.min().detach", "torch.zeros", "torch.zeros", "torch.diag", "torch.diag", "torch.min", "torch.min", "mask.sum"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.basic_get_imposter_indices"], ["", "def", "semihardneg_triplet_loss_from_S", "(", "S", ",", "margin", ")", ":", "\n", "    ", "\"\"\"\n    Input: Similarity matrix S as an autograd.Variable\n    Output: The one-way triplet loss from rows of S to columns of S. Impostors are taken\n    to be the most similar point to the anchor that is still less similar to the anchor\n    than the positive example.\n    You would need to run this function twice, once with S and once with S.t(),\n    in order to compute the triplet loss in both directions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ".", "type", "(", "S", ".", "data", ".", "type", "(", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Imposter - ground truth", "\n", "Sdiff", "=", "S", "-", "torch", ".", "diag", "(", "S", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "eps", "=", "1e-12", "\n", "# All examples less similar than ground truth", "\n", "mask", "=", "(", "Sdiff", "<", "-", "eps", ")", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "maskf", "=", "mask", ".", "type_as", "(", "S", ")", "\n", "# Mask out all examples >= gt with minimum similarity", "\n", "Sp", "=", "maskf", "*", "Sdiff", "+", "(", "1", "-", "maskf", ")", "*", "torch", ".", "min", "(", "Sdiff", ")", ".", "detach", "(", ")", "\n", "# Find the index maximum similar of the remaining", "\n", "_", ",", "idc", "=", "Sp", ".", "max", "(", "dim", "=", "1", ")", "\n", "idc", "=", "idc", ".", "data", ".", "cpu", "(", ")", "\n", "# Vector mask: 1 iff there exists an example < gt", "\n", "has_neg", "=", "(", "mask", ".", "sum", "(", "dim", "=", "1", ")", ">", "0", ")", ".", "data", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "# Random imposter indices", "\n", "random_imp_ind", "=", "torch", ".", "LongTensor", "(", "basic_get_imposter_indices", "(", "N", ")", ")", "\n", "# Use hardneg if there exists an example < gt, otherwise use random imposter", "\n", "imp_idc", "=", "has_neg", "*", "idc", "+", "(", "1", "-", "has_neg", ")", "*", "random_imp_ind", "\n", "# This could probably be vectorized too, but I haven't.", "\n", "for", "i", ",", "imp", "in", "enumerate", "(", "imp_idc", ")", ":", "\n", "        ", "local_loss", "=", "Sdiff", "[", "i", ",", "imp", "]", "+", "margin", "\n", "if", "(", "local_loss", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "local_loss", "\n", "", "", "loss", "=", "loss", "/", "N", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.sampled_triplet_loss_from_S": [[215, 237], ["S.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor", "enumerate", "S.dim", "S.size", "S.size", "torch.zeros().type", "torch.zeros().type", "torch.diag().view", "torch.diag().view", "util.basic_get_imposter_indices", "S.data.type", "torch.zeros", "torch.zeros", "torch.diag", "torch.diag"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.basic_get_imposter_indices"], ["", "def", "sampled_triplet_loss_from_S", "(", "S", ",", "margin", ")", ":", "\n", "    ", "\"\"\"\n    Input: Similarity matrix S as an autograd.Variable\n    Output: The one-way triplet loss from rows of S to columns of S. Imposters are\n    randomly sampled from the columns of S.\n    You would need to run this function twice, once with S and once with S.t(),\n    in order to compute the triplet loss in both directions.\n    \"\"\"", "\n", "assert", "(", "S", ".", "dim", "(", ")", "==", "2", ")", "\n", "assert", "(", "S", ".", "size", "(", "0", ")", "==", "S", ".", "size", "(", "1", ")", ")", "\n", "N", "=", "S", ".", "size", "(", "0", ")", "\n", "loss", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ".", "type", "(", "S", ".", "data", ".", "type", "(", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Imposter - ground truth", "\n", "Sdiff", "=", "S", "-", "torch", ".", "diag", "(", "S", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "imp_ind", "=", "torch", ".", "LongTensor", "(", "basic_get_imposter_indices", "(", "N", ")", ")", "\n", "# This could probably be vectorized too, but I haven't.", "\n", "for", "i", ",", "imp", "in", "enumerate", "(", "imp_ind", ")", ":", "\n", "        ", "local_loss", "=", "Sdiff", "[", "i", ",", "imp", "]", "+", "margin", "\n", "if", "(", "local_loss", ".", "data", ">", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "loss", "=", "loss", "+", "local_loss", "\n", "", "", "loss", "=", "loss", "/", "N", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.adjust_learning_rate": [[255, 261], ["print"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "base_lr", ",", "lr_decay", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay epochs\"\"\"", "\n", "lr", "=", "base_lr", "*", "(", "0.1", "**", "(", "epoch", "//", "lr_decay", ")", ")", "\n", "print", "(", "'now learning rate changed to {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.adjust_learning_rate2": [[262, 271], ["print", "print"], "function", ["None"], ["", "", "def", "adjust_learning_rate2", "(", "base_lr", ",", "lr_decay", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every lr_decay epochs\"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "cur_lr", "=", "param_group", "[", "'lr'", "]", "\n", "print", "(", "'current learing rate is {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "", "lr", "=", "cur_lr", "*", "0.1", "\n", "print", "(", "'now learning rate changed to {:f}'", ".", "format", "(", "lr", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.load_progress": [[273, 297], ["util.load_progress._print"], "function", ["None"], ["", "", "def", "load_progress", "(", "prog_pkl", ",", "quiet", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    load progress pkl file\n    Args:\n        prog_pkl(str): path to progress pkl file\n    Return:\n        progress(list):\n        epoch(int):\n        global_step(int):\n        best_epoch(int):\n        best_avg_r10(float):\n    \"\"\"", "\n", "def", "_print", "(", "msg", ")", ":", "\n", "        ", "if", "not", "quiet", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "\n", "", "", "with", "open", "(", "prog_pkl", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "prog", "=", "pickle", ".", "load", "(", "f", ")", "\n", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_avg_r10", ",", "_", "=", "prog", "[", "-", "1", "]", "\n", "\n", "", "_print", "(", "\"\\nPrevious Progress:\"", ")", "\n", "msg", "=", "\"[%5s %7s %5s %7s %6s]\"", "%", "(", "\"epoch\"", ",", "\"step\"", ",", "\"best_epoch\"", ",", "\"best_avg_r10\"", ",", "\"time\"", ")", "\n", "_print", "(", "msg", ")", "\n", "return", "prog", ",", "epoch", ",", "global_step", ",", "best_epoch", ",", "best_avg_r10", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.utilities.util.count_parameters": [[298, 300], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "[", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.check_label_error.check_type1_error": [[18, 39], ["print", "print", "open", "json.load", "enumerate", "sample[].split"], "function", ["None"], ["def", "check_type1_error", "(", "json_path", ")", ":", "\n", "    ", "total_speech_cnt", "=", "0", "\n", "male_cnt", "=", "0", "\n", "female_cnt", "=", "0", "\n", "child_cnt", "=", "0", "\n", "with", "open", "(", "json_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data", "=", "data_file", "[", "'data'", "]", "\n", "# for each sample", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "sample_labels", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "if", "'/m/09x0r'", "in", "sample_labels", ":", "\n", "                ", "total_speech_cnt", "+=", "1", "\n", "", "if", "'/m/05zppz'", "in", "sample_labels", ":", "\n", "                ", "male_cnt", "+=", "1", "\n", "", "if", "'/m/02zsn'", "in", "sample_labels", ":", "\n", "                ", "female_cnt", "+=", "1", "\n", "", "if", "'/m/0ytgt'", "in", "sample_labels", ":", "\n", "                ", "child_cnt", "+=", "1", "\n", "", "", "", "print", "(", "'Type-I Error:'", ")", "\n", "print", "(", "'There are {:d}, {:d}, {:d} samples that are labeled as male, female, and child speech (sum: {:d}), but there are {:d} samples labeled as speech in {:s}.'", ".", "format", "(", "male_cnt", ",", "female_cnt", ",", "child_cnt", ",", "(", "male_cnt", "+", "female_cnt", "+", "child_cnt", ")", ",", "total_speech_cnt", ",", "json_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.check_label_error.check_type2_error": [[41, 59], ["print", "print", "open", "json.load", "enumerate", "sample[].split"], "function", ["None"], ["", "def", "check_type2_error", "(", "json_path", ")", ":", "\n", "    ", "miss_male_cnt", "=", "0", "\n", "miss_female_cnt", "=", "0", "\n", "miss_child_cnt", "=", "0", "\n", "with", "open", "(", "json_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data", "=", "data_file", "[", "'data'", "]", "\n", "# for each sample", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "sample_labels", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "if", "'/m/05zppz'", "in", "sample_labels", "and", "'/m/09x0r'", "not", "in", "sample_labels", ":", "\n", "                ", "miss_male_cnt", "+=", "1", "\n", "", "if", "'/m/02zsn'", "in", "sample_labels", "and", "'/m/09x0r'", "not", "in", "sample_labels", ":", "\n", "                ", "miss_female_cnt", "+=", "1", "\n", "", "if", "'/m/0ytgt'", "in", "sample_labels", "and", "'/m/09x0r'", "not", "in", "sample_labels", ":", "\n", "                ", "miss_child_cnt", "+=", "1", "\n", "", "", "", "print", "(", "'Type-II Error:'", ")", "\n", "print", "(", "'There are {:d}, {:d}, {:d} samples that are labeled as male, female, and child speech, respectively, but are not labeled as speech in {:s}.'", ".", "format", "(", "miss_male_cnt", ",", "miss_female_cnt", ",", "miss_child_cnt", ",", "json_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.generate_parent_dict": [[17, 36], ["open", "json.load", "parent_dict[].append"], "function", ["None"], ["def", "generate_parent_dict", "(", ")", ":", "\n", "    ", "with", "open", "(", "'/data/sls/scratch/yuangong/aed-pc/src/utilities/ontology.json'", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "ontology", "=", "json", ".", "load", "(", "fp", ")", "\n", "# label: direct parent class, none if it is root", "\n", "", "parent_dict", "=", "{", "}", "\n", "for", "audio_class", "in", "ontology", ":", "\n", "        ", "cur_id", "=", "audio_class", "[", "'id'", "]", "\n", "# avoid abstract and discountinued class", "\n", "cur_restriction", "=", "audio_class", "[", "'restrictions'", "]", "\n", "if", "cur_restriction", "!=", "[", "'abstract'", "]", ":", "\n", "            ", "if", "cur_id", "not", "in", "parent_dict", ":", "\n", "                ", "parent_dict", "[", "cur_id", "]", "=", "None", "\n", "", "cur_child", "=", "audio_class", "[", "'child_ids'", "]", "\n", "for", "child", "in", "cur_child", ":", "\n", "                ", "if", "(", "child", "not", "in", "parent_dict", ")", "or", "parent_dict", "[", "child", "]", "==", "None", ":", "\n", "                    ", "parent_dict", "[", "child", "]", "=", "[", "cur_id", "]", "\n", "", "else", ":", "\n", "                    ", "parent_dict", "[", "child", "]", ".", "append", "(", "cur_id", ")", "\n", "", "", "", "", "return", "parent_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.dfs": [[37, 42], ["par_list.append", "fix_type2.dfs"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.dfs"], ["", "def", "dfs", "(", "cur_node", ",", "par_list", ",", "parent_dict", ")", ":", "\n", "    ", "par_list", ".", "append", "(", "cur_node", ")", "\n", "if", "parent_dict", "[", "cur_node", "]", "!=", "None", ":", "\n", "        ", "for", "par", "in", "parent_dict", "[", "cur_node", "]", ":", "\n", "            ", "dfs", "(", "par", ",", "par_list", ",", "parent_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.dfs_dict": [[44, 54], ["parent_dict.keys", "fix_type2.dfs", "list", "set"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.dfs"], ["", "", "", "def", "dfs_dict", "(", "parent_dict", ")", ":", "\n", "    ", "dfs_parent_dict", "=", "{", "}", "\n", "for", "label", "in", "parent_dict", ".", "keys", "(", ")", ":", "\n", "        ", "if", "parent_dict", "[", "label", "]", "!=", "None", ":", "\n", "            ", "par_list", "=", "[", "]", "\n", "dfs", "(", "label", ",", "par_list", ",", "parent_dict", ")", "\n", "dfs_parent_dict", "[", "label", "]", "=", "list", "(", "set", "(", "par_list", ")", ")", "\n", "", "else", ":", "\n", "            ", "dfs_parent_dict", "[", "label", "]", "=", "None", "\n", "", "", "return", "dfs_parent_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type2.enhance_label_type2": [[56, 107], ["print", "open", "json.load", "enumerate", "open", "json.dump", "sample[].split", "sample[].split.copy", "len", "len", "list", "list", "set", "set", "sample_labels.copy.append", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "enhance_label_type2", "(", "json_path", ",", "output_path", ",", "par_dict", ",", "labels_code_list", ",", "score_threshold", ",", "pred", ",", "dataset", "=", "'audioset'", ")", ":", "\n", "    ", "num_class", "=", "527", "if", "dataset", "==", "'audioset'", "else", "200", "\n", "original_label_num", ",", "fixed_label_num", ",", "fix_case_num", "=", "0", ",", "0", ",", "0", "\n", "# these are just to track the change for analysis", "\n", "child_case_cnt", ",", "par_case_cnt", ",", "class_sample_cnt", "=", "[", "0", "]", "*", "num_class", ",", "[", "0", "]", "*", "num_class", ",", "[", "0", "]", "*", "num_class", "\n", "child_par_dict", "=", "{", "}", "\n", "with", "open", "(", "json_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data", "=", "data_file", "[", "'data'", "]", "\n", "# for each audio sample", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "sample_labels", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "new_labels", "=", "sample_labels", ".", "copy", "(", ")", "\n", "original_label_num", "+=", "len", "(", "sample_labels", ")", "\n", "# for each label of the audio sample", "\n", "for", "label", "in", "sample_labels", ":", "\n", "                ", "class_sample_cnt", "[", "code2idx", "[", "label", "]", "]", "+=", "1", "\n", "# there are some FSD50K classes not included in the AudioSet ontology, ingore them", "\n", "if", "label", "not", "in", "[", "'/m/09l8g'", ",", "'/m/0bm0k'", ",", "'/t/dd00012'", ",", "'/m/09hlz4'", ",", "'/t/dd00071'", "]", "or", "dataset", "==", "'audioset'", ":", "\n", "# if this label has parent class", "\n", "                    ", "if", "par_dict", "[", "label", "]", "!=", "None", ":", "\n", "# one label might have multiple parent classes", "\n", "                        ", "for", "par_label", "in", "par_dict", "[", "label", "]", ":", "\n", "#if the parent class is in 527-class list (i.e., not abstract, not discontinued, etc)", "\n", "                            ", "if", "par_label", "in", "labels_code_list", ":", "\n", "# if the parent label not already in the original label set", "\n", "                                ", "if", "par_label", "not", "in", "new_labels", ":", "\n", "# get the index of the parent class", "\n", "                                    ", "par_label_idx", "=", "code2idx", "[", "par_label", "]", "\n", "# the model prediction score on the parent class of this sample", "\n", "pred_score", "=", "pred", "[", "i", ",", "par_label_idx", "]", "\n", "# if the prediction score is higher than the threshold", "\n", "if", "pred_score", ">", "score_threshold", "[", "par_label_idx", "]", ":", "\n", "# add the parent label", "\n", "                                        ", "new_labels", ".", "append", "(", "par_label", ")", "\n", "# below are just to track the change for analysis", "\n", "fix_case_num", "+=", "1", "\n", "child_case_cnt", "[", "code2idx", "[", "label", "]", "]", "+=", "1", "\n", "par_case_cnt", "[", "code2idx", "[", "par_label", "]", "]", "+=", "1", "\n", "if", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "par_label", "]", ")", "not", "in", "child_par_dict", ":", "\n", "                                            ", "child_par_dict", "[", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "par_label", "]", ")", "]", "=", "1", "\n", "", "else", ":", "\n", "                                            ", "child_par_dict", "[", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "par_label", "]", ")", "]", "+=", "1", "\n", "# remove repeated labels and add the new labels to the dataset", "\n", "", "", "", "", "", "", "", "", "data", "[", "i", "]", "[", "'labels'", "]", "=", "','", ".", "join", "(", "list", "(", "set", "(", "new_labels", ")", ")", ")", "\n", "fixed_label_num", "+=", "len", "(", "list", "(", "set", "(", "new_labels", ")", ")", ")", "\n", "", "", "output", "=", "{", "'data'", ":", "data", "}", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output", ",", "f", ",", "indent", "=", "1", ")", "\n", "", "print", "(", "'Added {:d} ({:.1f}%) labels to original {:d} original labels'", ".", "format", "(", "(", "fixed_label_num", "-", "original_label_num", ")", ",", "(", "fixed_label_num", "/", "original_label_num", "-", "1", ")", "*", "100", ",", "original_label_num", ")", ")", "\n", "return", "child_case_cnt", ",", "par_case_cnt", ",", "child_par_dict", ",", "class_sample_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type1.generate_child_dict": [[18, 30], ["open", "json.load"], "function", ["None"], ["def", "generate_child_dict", "(", ")", ":", "\n", "    ", "with", "open", "(", "'../utilities/ontology.json'", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "ontology", "=", "json", ".", "load", "(", "fp", ")", "\n", "# map each class to its children classes", "\n", "", "child_dict", "=", "{", "}", "\n", "for", "audio_class", "in", "ontology", ":", "\n", "        ", "cur_id", "=", "audio_class", "[", "'id'", "]", "\n", "# avoid abstract and discountinued class", "\n", "cur_restriction", "=", "audio_class", "[", "'restrictions'", "]", "\n", "if", "cur_restriction", "!=", "[", "'abstract'", "]", ":", "\n", "            ", "child_dict", "[", "cur_id", "]", "=", "audio_class", "[", "'child_ids'", "]", "\n", "", "", "return", "child_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.fix_type1.enhance_label_type1": [[31, 82], ["print", "open", "json.load", "enumerate", "open", "json.dump", "sample[].split", "sample[].split.copy", "len", "len", "list", "list", "set", "set", "sample_labels.copy.append", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "enhance_label_type1", "(", "json_path", ",", "output_path", ",", "child_dict", ",", "labels_code_list", ",", "score_threshold", ",", "pred", ",", "dataset", "=", "'audioset'", ")", ":", "\n", "    ", "num_class", "=", "527", "if", "dataset", "==", "'audioset'", "else", "200", "\n", "original_label_num", ",", "fixed_label_num", ",", "fix_case_num", "=", "0", ",", "0", ",", "0", "\n", "# these are just to track the change for analysis", "\n", "child_case_cnt", ",", "par_case_cnt", ",", "class_sample_cnt", "=", "[", "0", "]", "*", "num_class", ",", "[", "0", "]", "*", "num_class", ",", "[", "0", "]", "*", "num_class", "\n", "par_child_dict", "=", "{", "}", "\n", "with", "open", "(", "json_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data", "=", "data_file", "[", "'data'", "]", "\n", "# for each audio sample", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "sample_labels", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "new_labels", "=", "sample_labels", ".", "copy", "(", ")", "\n", "original_label_num", "+=", "len", "(", "sample_labels", ")", "\n", "# fpr each label of the audio sample", "\n", "for", "label", "in", "sample_labels", ":", "\n", "                ", "class_sample_cnt", "[", "code2idx", "[", "label", "]", "]", "+=", "1", "\n", "# there are some FSD50K classes not included in the AudioSet ontology, ingore them", "\n", "if", "label", "not", "in", "[", "'/m/09l8g'", ",", "'/m/0bm0k'", ",", "'/t/dd00012'", ",", "'/m/09hlz4'", ",", "'/t/dd00071'", "]", "or", "dataset", "==", "'audioset'", ":", "\n", "# if this label has child class(es)", "\n", "                    ", "if", "child_dict", "[", "label", "]", "!=", "None", ":", "\n", "# one label might have multiple child classes", "\n", "                        ", "for", "child_label", "in", "child_dict", "[", "label", "]", ":", "\n", "#if the child class is in 527-class list (i.e., not abstract, not discontinued, etc)", "\n", "                            ", "if", "child_label", "in", "labels_code_list", ":", "\n", "# if the child label not already in the original label set", "\n", "                                ", "if", "child_label", "not", "in", "new_labels", ":", "\n", "# get the index of the child class", "\n", "                                    ", "child_label_idx", "=", "code2idx", "[", "child_label", "]", "\n", "# the model prediction score on the child class of this sample", "\n", "pred_score", "=", "pred", "[", "i", ",", "child_label_idx", "]", "\n", "# if the prediction score is higher than the threshold", "\n", "if", "pred_score", ">", "score_threshold", "[", "child_label_idx", "]", ":", "\n", "# add the child label", "\n", "                                        ", "new_labels", ".", "append", "(", "child_label", ")", "\n", "# below are just to track the change for analysis", "\n", "fix_case_num", "+=", "1", "\n", "par_case_cnt", "[", "code2idx", "[", "label", "]", "]", "+=", "1", "\n", "child_case_cnt", "[", "code2idx", "[", "child_label", "]", "]", "+=", "1", "\n", "if", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "child_label", "]", ")", "not", "in", "par_child_dict", ":", "\n", "                                            ", "par_child_dict", "[", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "child_label", "]", ")", "]", "=", "1", "\n", "", "else", ":", "\n", "                                            ", "par_child_dict", "[", "str", "(", "code2idx", "[", "label", "]", ")", "+", "'_'", "+", "str", "(", "code2idx", "[", "child_label", "]", ")", "]", "+=", "1", "\n", "# remove repeated labels and add the new labels to the dataset", "\n", "", "", "", "", "", "", "", "", "data", "[", "i", "]", "[", "'labels'", "]", "=", "','", ".", "join", "(", "list", "(", "set", "(", "new_labels", ")", ")", ")", "\n", "fixed_label_num", "+=", "len", "(", "list", "(", "set", "(", "new_labels", ")", ")", ")", "\n", "", "", "output", "=", "{", "'data'", ":", "data", "}", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output", ",", "f", ",", "indent", "=", "1", ")", "\n", "", "print", "(", "'Added {:d} ({:.1f}%) labels to original {:d} original labels'", ".", "format", "(", "(", "fixed_label_num", "-", "original_label_num", ")", ",", "(", "fixed_label_num", "/", "original_label_num", "-", "1", ")", "*", "100", ",", "original_label_num", ")", ")", "\n", "return", "child_case_cnt", ",", "par_case_cnt", ",", "par_child_dict", ",", "class_sample_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.merge_type_1_2.count_label": [[14, 23], ["open", "json.load", "enumerate", "sample[].split", "len"], "function", ["None"], ["def", "count_label", "(", "js", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "with", "open", "(", "js", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data", "=", "data_file", "[", "'data'", "]", "\n", "for", "i", ",", "sample", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "sample_labels", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "cnt", "+=", "len", "(", "sample_labels", ")", "\n", "", "", "return", "cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.merge_type_1_2.merge_label": [[25, 45], ["enumerate", "print", "print", "print", "open", "json.load", "open", "json.load", "sample[].split", "[].split", "list", "len", "open", "json.dump", "set", "list", "list", "merge_type_1_2.count_label", "merge_type_1_2.count_label", "set", "set"], "function", ["home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.merge_type_1_2.count_label", "home.repos.pwc.inspect_result.YuanGongND_psla.label_enhancement.merge_type_1_2.count_label"], ["", "def", "merge_label", "(", "js1", ",", "js2", ",", "output_path", ")", ":", "\n", "    ", "total_label_cnt", "=", "0", "\n", "with", "open", "(", "js1", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data1", "=", "data_file", "[", "'data'", "]", "\n", "", "with", "open", "(", "js2", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "fp", ":", "\n", "        ", "data_file", "=", "json", ".", "load", "(", "fp", ")", "\n", "data2", "=", "data_file", "[", "'data'", "]", "\n", "", "for", "i", ",", "sample", "in", "enumerate", "(", "data1", ")", ":", "\n", "        ", "sample_labels1", "=", "sample", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "sample_labels2", "=", "data2", "[", "i", "]", "[", "'labels'", "]", ".", "split", "(", "','", ")", "\n", "merge_label", "=", "list", "(", "set", "(", "sample_labels1", "+", "sample_labels2", ")", ")", "\n", "data1", "[", "i", "]", "[", "'labels'", "]", "=", "','", ".", "join", "(", "list", "(", "set", "(", "merge_label", ")", ")", ")", "\n", "total_label_cnt", "+=", "len", "(", "list", "(", "set", "(", "merge_label", ")", ")", ")", "\n", "", "output", "=", "{", "'data'", ":", "data1", "}", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "output", ",", "f", ",", "indent", "=", "1", ")", "\n", "", "print", "(", "'Input Json file 1 has {:d} labels'", ".", "format", "(", "count_label", "(", "js1", ")", ")", ")", "\n", "print", "(", "'Input Json file 2 has {:d} labels'", ".", "format", "(", "count_label", "(", "js2", ")", ")", ")", "\n", "print", "(", "'Merged Json file has {:d} labels'", ".", "format", "(", "total_label_cnt", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YuanGongND_psla.fsd50k.prep_fsd.get_immediate_files": [[19, 21], ["os.listdir", "os.path.isfile", "os.path.join"], "function", ["None"], ["def", "get_immediate_files", "(", "a_dir", ")", ":", "\n", "    ", "return", "[", "name", "for", "name", "in", "os", ".", "listdir", "(", "a_dir", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "a_dir", ",", "name", ")", ")", "]", "\n", "\n"]]}