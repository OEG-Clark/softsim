{"home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.SQADevDataset.__init__": [[97, 156], ["pandas.read_csv", "df[].apply", "os.path.join", "os.path.join", "tqdm.auto.tqdm.auto.tqdm", "os.path.join", "open", "json.load", "zip", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "encoding.update", "evaluate-dev.SQADevDataset.encodings.append", "os.path.join", "print", "numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt", "len", "len", "list", "print", "torch.LongTensor", "os.path.join", "os.path.join", "os.path.join", "list", "len", "len", "len", "list", "list", "list", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev_code_answer.csv'", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev-hash2question.json'", ")", ")", "as", "f", ":", "\n", "            ", "h2q", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "df", "[", "'question'", "]", "=", "df", "[", "'hash'", "]", ".", "apply", "(", "lambda", "x", ":", "h2q", "[", "x", "]", ")", "\n", "\n", "code_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev-hubert-128-22'", ")", "\n", "code_passage_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev-hubert-128-22'", ")", "\n", "context_id", "=", "df", "[", "'context_id'", "]", ".", "values", "\n", "question", "=", "df", "[", "'question'", "]", ".", "values", "\n", "code_start", "=", "df", "[", "'code_start'", "]", ".", "values", "\n", "code_end", "=", "df", "[", "'code_end'", "]", ".", "values", "\n", "\n", "self", ".", "encodings", "=", "[", "]", "\n", "for", "context_id", ",", "question_id", ",", "start_idx", ",", "end_idx", "in", "tqdm", "(", "zip", "(", "context_id", ",", "question", ",", "code_start", ",", "code_end", ")", ")", ":", "\n", "            ", "context", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_passage_dir", ",", "'context-'", "+", "context_id", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "question", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_dir", ",", "question_id", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "context_cnt", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_passage_dir", ",", "'context-'", "+", "context_id", "+", "'.cnt'", ")", ")", ".", "astype", "(", "int", ")", "\n", "# question_cnt = np.loadtxt(os.path.join(code_dir, question_id+'.cnt')).astype(int)", "\n", "# 0~4 index is the special token, so start from index 5", "\n", "# the size of discrete token is 128, indexing from 5~132", "\n", "context", "+=", "5", "\n", "question", "+=", "5", "\n", "\n", "'''\n            <s> question</s></s> context</s>\n            ---------------------------------\n            <s>: 0\n            </s>: 2\n\n            '''", "\n", "tot_len", "=", "len", "(", "question", ")", "+", "len", "(", "context", ")", "+", "4", "\n", "\n", "start_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "start_idx", "\n", "end_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "end_idx", "\n", "if", "end_positions", ">", "4096", ":", "\n", "                ", "print", "(", "'end position: '", ",", "end_positions", ")", "\n", "start_positions", ",", "end_positions", "=", "0", ",", "0", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "\n", "", "elif", "tot_len", ">", "4096", "and", "end_positions", "<=", "4096", ":", "\n", "                ", "print", "(", "'length longer than 4096: '", ",", "tot_len", ")", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "+", "[", "2", "]", "\n", "\n", "\n", "", "encoding", "=", "{", "}", "\n", "\n", "encoding", ".", "update", "(", "{", "'input_ids'", ":", "torch", ".", "LongTensor", "(", "code_pair", ")", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'context_begin'", ":", "len", "(", "question", ")", "+", "3", ",", "# [0] [2] [2]", "\n", "'context_cnt'", ":", "context_cnt", ",", "\n", "}", ")", "\n", "self", ".", "encodings", ".", "append", "(", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.SQADevDataset.__len__": [[157, 159], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encodings", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.SQADevDataset.__getitem__": [[159, 161], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "encodings", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev._get_best_indexes": [[34, 47], ["sorted", "range", "enumerate", "len", "best_indexes.append", "torch.topk"], "function", ["None"], ["def", "_get_best_indexes", "(", "probs", ",", "context_offset", ",", "n_best_size", ")", ":", "\n", "# use torch for faster inference", "\n", "# do not need to consider indexes for question", "\n", "    ", "best_indexes", "=", "torch", ".", "topk", "(", "probs", "[", "context_offset", ":", "]", ",", "n_best_size", ")", ".", "indices", "+", "context_offset", "\n", "return", "best_indexes", "\n", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "probs", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.post_process_prediction": [[49, 93], ["start_prob.squeeze.squeeze", "end_prob.squeeze.squeeze", "input_id.squeeze.squeeze", "evaluate-dev._get_best_indexes", "evaluate-dev._get_best_indexes", "sorted", "len", "torch.argmax().cpu", "torch.argmax().cpu", "sorted.append", "torch.argmax", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test._get_best_indexes", "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test._get_best_indexes"], ["", "def", "post_process_prediction", "(", "start_prob", ",", "end_prob", ",", "context_offset", ",", "n_best_size", "=", "10", ",", "max_answer_length", "=", "500", ",", "weight", "=", "0.6", ")", ":", "\n", "    ", "prelim_predictions", "=", "[", "]", "\n", "start_prob", "=", "start_prob", ".", "squeeze", "(", ")", "\n", "end_prob", "=", "end_prob", ".", "squeeze", "(", ")", "\n", "input_id", "=", "input_id", ".", "squeeze", "(", ")", "\n", "\n", "start_indexes", "=", "_get_best_indexes", "(", "start_prob", ",", "context_offset", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "end_prob", ",", "context_offset", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "\n", "for", "start_index", "in", "start_indexes", ":", "\n", "        ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions. This is taken care in _get_best_indexes", "\n", "# if start_index >= len(input_id):", "\n", "#     continue", "\n", "# if end_index >= len(input_id):", "\n", "#     continue", "\n", "            ", "if", "end_index", "<", "start_index", ":", "\n", "                ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                ", "continue", "\n", "\n", "", "predict", "=", "{", "\n", "'start_prob'", ":", "start_prob", "[", "start_index", "]", ",", "\n", "'end_prob'", ":", "end_prob", "[", "end_index", "]", ",", "\n", "'start_idx'", ":", "start_index", ",", "\n", "'end_idx'", ":", "end_index", ",", "\n", "}", "\n", "\n", "prelim_predictions", ".", "append", "(", "predict", ")", "\n", "\n", "", "", "prelim_predictions", "=", "sorted", "(", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "(", "1", "-", "weight", ")", "*", "x", "[", "'start_prob'", "]", "+", "weight", "*", "x", "[", "'end_prob'", "]", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "if", "len", "(", "prelim_predictions", ")", ">", "0", ":", "\n", "        ", "final_start_idx", "=", "prelim_predictions", "[", "0", "]", "[", "'start_idx'", "]", "\n", "final_end_idx", "=", "prelim_predictions", "[", "0", "]", "[", "'end_idx'", "]", "\n", "", "else", ":", "\n", "        ", "final_start_idx", "=", "torch", ".", "argmax", "(", "start_prob", ")", ".", "cpu", "(", ")", "\n", "final_end_idx", "=", "torch", ".", "argmax", "(", "end_prob", ")", ".", "cpu", "(", ")", "\n", "", "return", "final_start_idx", ",", "final_end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.collate_dev_fn": [[163, 187], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.stack", "torch.stack", "torch.nn.utils.rnn.pad_sequence", "len", "print", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "", "def", "collate_dev_fn", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Take a list of samples from a Dataset and collate them into a batch.\n    Returns:\n        A dictionary of tensors\n    \"\"\"", "\n", "# padding", "\n", "for", "example", "in", "batch", ":", "\n", "        ", "if", "len", "(", "example", "[", "'input_ids'", "]", ")", ">", "4096", ":", "\n", "            ", "print", "(", "'too long:'", ",", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "\n", "", "", "input_ids", "=", "pad_sequence", "(", "[", "example", "[", "'input_ids'", "]", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "1", ")", "\n", "attention_mask", "=", "pad_sequence", "(", "[", "torch", ".", "ones", "(", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "start_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'start_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "end_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'end_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "context_begin", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'context_begin'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "context_cnt", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'context_cnt'", "]", ")", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "\n", "return", "{", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'attention_mask'", ":", "attention_mask", ",", "\n", "'context_begin'", ":", "context_begin", ",", "\n", "'context_cnt'", ":", "context_cnt", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-dev.idx2sec": [[190, 197], ["context_cnt.squeeze.squeeze", "torch.repeat_interleave", "torch.repeat_interleave", "torch.ones", "torch.ones", "torch.sum", "torch.sum", "float", "float", "context_cnt[].size", "context_cnt[].size"], "function", ["None"], ["", "def", "idx2sec", "(", "pred_start_idx", ",", "pred_end_idx", ",", "context_begin", ",", "context_cnt", ")", ":", "\n", "    ", "context_cnt", "=", "context_cnt", ".", "squeeze", "(", ")", "\n", "start_frame_idx", "=", "torch", ".", "repeat_interleave", "(", "torch", ".", "ones", "(", "context_cnt", "[", ":", "pred_start_idx", "-", "context_begin", "]", ".", "size", "(", ")", ")", ",", "context_cnt", "[", ":", "pred_start_idx", "-", "context_begin", "]", ")", "\n", "end_frame_idx", "=", "torch", ".", "repeat_interleave", "(", "torch", ".", "ones", "(", "context_cnt", "[", ":", "pred_end_idx", "-", "context_begin", "]", ".", "size", "(", ")", ")", ",", "context_cnt", "[", ":", "pred_end_idx", "-", "context_begin", "]", ")", "\n", "start_idx", ",", "end_idx", "=", "torch", ".", "sum", "(", "start_frame_idx", ")", ",", "torch", ".", "sum", "(", "end_frame_idx", ")", "\n", "\n", "return", "float", "(", "start_idx", "*", "0.02", ")", ",", "float", "(", "end_idx", "*", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.SQAlxtDataset.__init__": [[97, 153], ["pandas.read_csv", "os.path.join", "os.path.join", "tqdm.auto.tqdm.auto.tqdm", "os.path.join", "zip", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "encoding.update", "evaluate-test.SQAlxtDataset.encodings.append", "print", "context_id.split", "numpy.loadtxt", "context_id.split", "numpy.loadtxt", "numpy.loadtxt", "len", "len", "list", "print", "torch.LongTensor", "os.path.join", "os.path.join", "os.path.join", "list", "len", "len", "len", "list", "list", "list", "context_id.split", "context_id.split", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test_squad_code_answer.csv'", ")", ")", "\n", "\n", "code_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test-hubert-128-22'", ")", "\n", "code_passage_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test-hubert-128-22'", ")", "\n", "context_id", "=", "df", "[", "'name_id'", "]", ".", "values", "\n", "code_start", "=", "df", "[", "'code_start'", "]", ".", "values", "\n", "code_end", "=", "df", "[", "'code_end'", "]", ".", "values", "\n", "\n", "self", ".", "encodings", "=", "[", "]", "\n", "for", "context_id", ",", "start_idx", ",", "end_idx", "in", "tqdm", "(", "zip", "(", "context_id", ",", "code_start", ",", "code_end", ")", ")", ":", "\n", "            ", "context_id", "=", "'-'", ".", "join", "(", "context_id", ".", "split", "(", "'-'", ")", "[", ":", "-", "1", "]", ")", "\n", "context", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_passage_dir", ",", "'-'", ".", "join", "(", "context_id", ".", "split", "(", "'-'", ")", "+", "[", "'c'", "]", ")", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "question_id", "=", "'-'", ".", "join", "(", "context_id", ".", "split", "(", "'-'", ")", "+", "[", "'q'", "]", ")", "\n", "question", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_dir", ",", "question_id", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "context_cnt", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_passage_dir", ",", "'-'", ".", "join", "(", "context_id", ".", "split", "(", "'-'", ")", "+", "[", "'c'", "]", ")", "+", "'.cnt'", ")", ")", ".", "astype", "(", "int", ")", "\n", "# question_cnt = np.loadtxt(os.path.join(code_dir, question_id+'.cnt')).astype(int)", "\n", "# 0~4 index is the special token, so start from index 5", "\n", "# the size of discrete token is 128, indexing from 5~132", "\n", "context", "+=", "5", "\n", "question", "+=", "5", "\n", "\n", "'''\n            <s> question</s></s> context</s>\n            ---------------------------------\n            <s>: 0\n            </s>: 2\n\n            '''", "\n", "tot_len", "=", "len", "(", "question", ")", "+", "len", "(", "context", ")", "+", "4", "\n", "\n", "start_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "start_idx", "\n", "end_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "end_idx", "\n", "if", "end_positions", ">", "4096", ":", "\n", "                ", "print", "(", "'end position: '", ",", "end_positions", ")", "\n", "start_positions", ",", "end_positions", "=", "0", ",", "0", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "\n", "", "elif", "tot_len", ">", "4096", "and", "end_positions", "<=", "4096", ":", "\n", "                ", "print", "(", "'length longer than 4096: '", ",", "tot_len", ")", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "+", "[", "2", "]", "\n", "\n", "\n", "", "encoding", "=", "{", "}", "\n", "\n", "encoding", ".", "update", "(", "{", "'input_ids'", ":", "torch", ".", "LongTensor", "(", "code_pair", ")", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'context_begin'", ":", "len", "(", "question", ")", "+", "3", ",", "# [0] [2] [2]", "\n", "'context_cnt'", ":", "context_cnt", ",", "\n", "}", ")", "\n", "self", ".", "encodings", ".", "append", "(", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.SQAlxtDataset.__len__": [[154, 156], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encodings", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.SQAlxtDataset.__getitem__": [[156, 158], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "encodings", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test._get_best_indexes": [[34, 47], ["sorted", "range", "enumerate", "len", "best_indexes.append", "torch.topk"], "function", ["None"], ["def", "_get_best_indexes", "(", "probs", ",", "context_offset", ",", "n_best_size", ")", ":", "\n", "# use torch for faster inference", "\n", "# do not need to consider indexes for question", "\n", "    ", "best_indexes", "=", "torch", ".", "topk", "(", "probs", "[", "context_offset", ":", "]", ",", "n_best_size", ")", ".", "indices", "+", "context_offset", "\n", "return", "best_indexes", "\n", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "probs", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.post_process_prediction": [[49, 93], ["start_prob.squeeze.squeeze", "end_prob.squeeze.squeeze", "input_id.squeeze.squeeze", "evaluate-test._get_best_indexes", "evaluate-test._get_best_indexes", "sorted", "len", "torch.argmax().cpu", "torch.argmax().cpu", "sorted.append", "torch.argmax", "torch.argmax"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test._get_best_indexes", "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test._get_best_indexes"], ["", "def", "post_process_prediction", "(", "start_prob", ",", "end_prob", ",", "context_offset", ",", "n_best_size", "=", "10", ",", "max_answer_length", "=", "500", ",", "weight", "=", "0.6", ")", ":", "\n", "    ", "prelim_predictions", "=", "[", "]", "\n", "start_prob", "=", "start_prob", ".", "squeeze", "(", ")", "\n", "end_prob", "=", "end_prob", ".", "squeeze", "(", ")", "\n", "input_id", "=", "input_id", ".", "squeeze", "(", ")", "\n", "\n", "start_indexes", "=", "_get_best_indexes", "(", "start_prob", ",", "context_offset", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "end_prob", ",", "context_offset", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "\n", "for", "start_index", "in", "start_indexes", ":", "\n", "        ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions. This is taken care in _get_best_indexes", "\n", "# if start_index >= len(input_id):", "\n", "#     continue", "\n", "# if end_index >= len(input_id):", "\n", "#     continue", "\n", "            ", "if", "end_index", "<", "start_index", ":", "\n", "                ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                ", "continue", "\n", "\n", "", "predict", "=", "{", "\n", "'start_prob'", ":", "start_prob", "[", "start_index", "]", ",", "\n", "'end_prob'", ":", "end_prob", "[", "end_index", "]", ",", "\n", "'start_idx'", ":", "start_index", ",", "\n", "'end_idx'", ":", "end_index", ",", "\n", "}", "\n", "\n", "prelim_predictions", ".", "append", "(", "predict", ")", "\n", "\n", "", "", "prelim_predictions", "=", "sorted", "(", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "(", "1", "-", "weight", ")", "*", "x", "[", "'start_prob'", "]", "+", "weight", "*", "x", "[", "'end_prob'", "]", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "if", "len", "(", "prelim_predictions", ")", ">", "0", ":", "\n", "        ", "final_start_idx", "=", "prelim_predictions", "[", "0", "]", "[", "'start_idx'", "]", "\n", "final_end_idx", "=", "prelim_predictions", "[", "0", "]", "[", "'end_idx'", "]", "\n", "", "else", ":", "\n", "        ", "final_start_idx", "=", "torch", ".", "argmax", "(", "start_prob", ")", ".", "cpu", "(", ")", "\n", "final_end_idx", "=", "torch", ".", "argmax", "(", "end_prob", ")", ".", "cpu", "(", ")", "\n", "", "return", "final_start_idx", ",", "final_end_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.collate_dev_fn": [[159, 183], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.stack", "torch.stack", "torch.nn.utils.rnn.pad_sequence", "len", "print", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "", "def", "collate_dev_fn", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Take a list of samples from a Dataset and collate them into a batch.\n    Returns:\n        A dictionary of tensors\n    \"\"\"", "\n", "# padding", "\n", "for", "example", "in", "batch", ":", "\n", "        ", "if", "len", "(", "example", "[", "'input_ids'", "]", ")", ">", "4096", ":", "\n", "            ", "print", "(", "'too long:'", ",", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "\n", "", "", "input_ids", "=", "pad_sequence", "(", "[", "example", "[", "'input_ids'", "]", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "1", ")", "\n", "attention_mask", "=", "pad_sequence", "(", "[", "torch", ".", "ones", "(", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "start_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'start_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "end_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'end_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "context_begin", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'context_begin'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "context_cnt", "=", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'context_cnt'", "]", ")", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "\n", "return", "{", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'attention_mask'", ":", "attention_mask", ",", "\n", "'context_begin'", ":", "context_begin", ",", "\n", "'context_cnt'", ":", "context_cnt", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.evaluate-test.idx2sec": [[186, 193], ["context_cnt.squeeze.squeeze", "torch.repeat_interleave", "torch.repeat_interleave", "torch.ones", "torch.ones", "torch.sum", "torch.sum", "float", "float", "context_cnt[].size", "context_cnt[].size"], "function", ["None"], ["", "def", "idx2sec", "(", "pred_start_idx", ",", "pred_end_idx", ",", "context_begin", ",", "context_cnt", ")", ":", "\n", "    ", "context_cnt", "=", "context_cnt", ".", "squeeze", "(", ")", "\n", "start_frame_idx", "=", "torch", ".", "repeat_interleave", "(", "torch", ".", "ones", "(", "context_cnt", "[", ":", "pred_start_idx", "-", "context_begin", "]", ".", "size", "(", ")", ")", ",", "context_cnt", "[", ":", "pred_start_idx", "-", "context_begin", "]", ")", "\n", "end_frame_idx", "=", "torch", ".", "repeat_interleave", "(", "torch", ".", "ones", "(", "context_cnt", "[", ":", "pred_end_idx", "-", "context_begin", "]", ".", "size", "(", ")", ")", ",", "context_cnt", "[", ":", "pred_end_idx", "-", "context_begin", "]", ")", "\n", "start_idx", ",", "end_idx", "=", "torch", ".", "sum", "(", "start_frame_idx", ")", ",", "torch", ".", "sum", "(", "end_frame_idx", ")", "\n", "\n", "return", "float", "(", "start_idx", "*", "0.02", ")", ",", "float", "(", "end_idx", "*", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.train.SQADataset.__init__": [[19, 78], ["pandas.read_csv", "df[].apply", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "tqdm.tqdm.tqdm", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "json.load", "json.load", "json.load", "json.load", "zip", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "numpy.loadtxt().astype", "encoding.update", "train.SQADataset.encodings.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "print", "numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt", "numpy.loadtxt", "len", "len", "list", "print", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "list", "len", "len", "list", "list", "list", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "mode", "=", "'train'", ",", "idx_offset", "=", "5", ")", ":", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "mode", "+", "'_code_answer.csv'", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "mode", "+", "'-hash2question.json'", ")", ")", "as", "f", ":", "\n", "            ", "h2q", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "df", "[", "'question'", "]", "=", "df", "[", "'hash'", "]", ".", "apply", "(", "lambda", "x", ":", "h2q", "[", "x", "]", ")", "\n", "\n", "code_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "mode", "+", "'-hubert-128-22'", ")", "\n", "code_passage_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "mode", "+", "'-hubert-128-22'", ")", "\n", "context_id", "=", "df", "[", "'context_id'", "]", ".", "values", "\n", "question", "=", "df", "[", "'question'", "]", ".", "values", "\n", "code_start", "=", "df", "[", "'code_start'", "]", ".", "values", "\n", "code_end", "=", "df", "[", "'code_end'", "]", ".", "values", "\n", "\n", "self", ".", "encodings", "=", "[", "]", "\n", "for", "context_id", ",", "question_id", ",", "start_idx", ",", "end_idx", "in", "tqdm", "(", "zip", "(", "context_id", ",", "question", ",", "code_start", ",", "code_end", ")", ",", "total", "=", "len", "(", "context_id", ")", ")", ":", "\n", "            ", "context", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_passage_dir", ",", "'context-'", "+", "context_id", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "question", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "code_dir", ",", "question_id", "+", "'.code'", ")", ")", ".", "astype", "(", "int", ")", "\n", "if", "context", ".", "shape", "==", "(", ")", ":", "\n", "                ", "context", "=", "np", ".", "expand_dims", "(", "context", ",", "axis", "=", "-", "1", ")", "\n", "", "if", "question", ".", "shape", "==", "(", ")", ":", "\n", "                ", "question", "=", "np", ".", "expand_dims", "(", "question", ",", "axis", "=", "-", "1", ")", "\n", "# 0~4 index is the special token, so start from index 5", "\n", "# the size of discrete token is 128, indexing from 5~132", "\n", "", "context", "+=", "idx_offset", "\n", "question", "+=", "idx_offset", "\n", "\n", "'''\n            <s> question</s></s> context</s>\n            ---------------------------------\n            <s>: 0\n            </s>: 2\n\n            '''", "\n", "tot_len", "=", "len", "(", "question", ")", "+", "len", "(", "context", ")", "+", "4", "\n", "\n", "start_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "start_idx", "\n", "end_positions", "=", "1", "+", "len", "(", "question", ")", "+", "1", "+", "1", "+", "end_idx", "\n", "if", "end_positions", ">", "4096", ":", "\n", "                ", "print", "(", "'end position: '", ",", "end_positions", ")", "\n", "start_positions", ",", "end_positions", "=", "0", ",", "0", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "\n", "", "elif", "tot_len", ">", "4096", "and", "end_positions", "<=", "4096", ":", "\n", "                ", "print", "(", "'length longer than 4096: '", ",", "tot_len", ")", "\n", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "\n", "code_pair", "=", "code_pair", "[", ":", "4095", "]", "+", "[", "2", "]", "\n", "", "else", ":", "\n", "                ", "code_pair", "=", "[", "0", "]", "+", "list", "(", "question", ")", "+", "[", "2", "]", "+", "[", "2", "]", "+", "list", "(", "context", ")", "+", "[", "2", "]", "\n", "\n", "\n", "", "encoding", "=", "{", "}", "\n", "\n", "encoding", ".", "update", "(", "{", "'input_ids'", ":", "torch", ".", "LongTensor", "(", "code_pair", ")", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "}", ")", "\n", "self", ".", "encodings", ".", "append", "(", "encoding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.train.SQADataset.__len__": [[79, 81], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encodings", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.train.SQADataset.__getitem__": [[81, 83], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "encodings", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.train.collate_batch": [[85, 105], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "print", "torch.ones", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "", "def", "collate_batch", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Take a list of samples from a Dataset and collate them into a batch.\n    Returns:\n        A dictionary of tensors\n    \"\"\"", "\n", "# padding", "\n", "for", "example", "in", "batch", ":", "\n", "        ", "if", "len", "(", "example", "[", "'input_ids'", "]", ")", ">", "4096", ":", "\n", "            ", "print", "(", "'too long:'", ",", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "\n", "", "", "input_ids", "=", "pad_sequence", "(", "[", "example", "[", "'input_ids'", "]", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "1", ")", "\n", "attention_mask", "=", "pad_sequence", "(", "[", "torch", ".", "ones", "(", "len", "(", "example", "[", "'input_ids'", "]", ")", ")", "for", "example", "in", "batch", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "start_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'start_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "end_positions", "=", "torch", ".", "stack", "(", "[", "torch", ".", "tensor", "(", "example", "[", "'end_positions'", "]", ",", "dtype", "=", "torch", ".", "long", ")", "for", "example", "in", "batch", "]", ")", "\n", "\n", "return", "{", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'start_positions'", ":", "start_positions", ",", "\n", "'end_positions'", ":", "end_positions", ",", "\n", "'attention_mask'", ":", "attention_mask", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.train.main": [[156, 247], ["transformers.HfArgumentParser", "transformers.HfArgumentParser.parse_json_file", "logging.basicConfig", "logger.warning", "logger.info", "transformers.set_seed", "transformers.LongformerTokenizerFast.from_pretrained", "transformers.LongformerForQuestionAnswering.from_pretrained", "print", "train.SQADataset", "train.SQADataset", "print", "transformers.Trainer", "os.path.exists", "os.path.exists", "os.listdir", "os.listdir", "ValueError", "bool", "transformers.Trainer.train", "transformers.Trainer.save_model", "logger.info", "transformers.Trainer.evaluate", "os.path.join", "os.path.join", "results.update", "os.path.abspath", "os.path.abspath", "open", "logger.info", "sorted", "trainer.evaluate.keys", "logger.info", "writer.write", "os.path.isdir", "os.path.isdir", "str", "str"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "\n", "# we will load the arguments from a json file, ", "\n", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "'args.json'", ")", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "tokenizer", "=", "LongformerTokenizerFast", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "model", "=", "LongformerForQuestionAnswering", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "# reset input embedding", "\n", "#     selected_emb = model.longformer.embeddings.word_embeddings.weight[:128+5, :]", "\n", "#     embedding = torch.nn.Embedding.from_pretrained(selected_emb)", "\n", "#     model.longformer.set_input_embeddings(embedding)", "\n", "# if train from scratch", "\n", "#     print('train from scratch!')", "\n", "#     model.init_weights()", "\n", "# Get datasets", "\n", "print", "(", "'[INFO]    loading data'", ")", "\n", "\n", "train_dataset", "=", "SQADataset", "(", "data_dir", ",", "mode", "=", "'train'", ")", "\n", "dev_dataset", "=", "SQADataset", "(", "data_dir", ",", "mode", "=", "'dev'", ")", "\n", "\n", "print", "(", "'[INFO]    loading done'", ")", "\n", "\n", "# Initialize our Trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", ",", "\n", "eval_dataset", "=", "dev_dataset", ",", "\n", "data_collator", "=", "collate_batch", ",", "\n", ")", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "model_name_or_path", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "else", "None", "\n", ")", "\n", "trainer", ".", "save_model", "(", ")", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", "and", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "eval_output", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "eval_output", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "eval_output", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "results", ".", "update", "(", "eval_output", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.alignment.find_timespan": [[6, 43], ["str", "textgrid.TextGrid.fromFile", "utils.text_preprocess", "utils.text_preprocess", "len", "range", "range", "range", "enumerate", "range", "sentence.startswith", "match_span.split", "start_times.append", "end_times.append", "len", "len", "len", "len", "res.index", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.text_preprocess", "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.text_preprocess"], ["def", "find_timespan", "(", "tg_file", ",", "answer", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "tg", "=", "textgrid", ".", "TextGrid", ".", "fromFile", "(", "tg_file", ")", "\n", "", "except", ":", "\n", "        ", "return", "[", "0", "]", ",", "[", "0", "]", "\n", "", "space_idx", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "tg", "[", "0", "]", ")", ")", "if", "tg", "[", "0", "]", "[", "i", "]", ".", "mark", "==", "''", "]", "\n", "words", "=", "[", "text_preprocess", "(", "tg", "[", "0", "]", "[", "i", "]", ".", "mark", ")", "for", "i", "in", "range", "(", "len", "(", "tg", "[", "0", "]", ")", ")", "if", "tg", "[", "0", "]", "[", "i", "]", ".", "mark", "!=", "''", "]", "\n", "\n", "words_SIL", "=", "[", "text_preprocess", "(", "tg", "[", "0", "]", "[", "i", "]", ".", "mark", ")", "for", "i", "in", "range", "(", "len", "(", "tg", "[", "0", "]", ")", ")", "]", "\n", "\n", "pos_map", "=", "[", "i", "for", "i", ",", "word", "in", "enumerate", "(", "words_SIL", ")", "if", "word", "!=", "''", "]", "\n", "answer", "=", "str", "(", "answer", ")", "\n", "\n", "sentence", "=", "' '", ".", "join", "(", "words", ")", "\n", "\n", "# print(sentence)", "\n", "match_idxs", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "sentence", ")", ")", "if", "sentence", ".", "startswith", "(", "answer", ",", "i", ")", "]", "\n", "# print(match_idxs)", "\n", "if", "len", "(", "match_idxs", ")", "==", "0", ":", "\n", "        ", "return", "[", "0", "]", ",", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "start_times", ",", "end_times", "=", "[", "]", ",", "[", "]", "\n", "for", "match_idx", "in", "match_idxs", ":", "\n", "            ", "match_span", "=", "sentence", "[", "match_idx", ":", "match_idx", "+", "len", "(", "answer", ")", "]", "\n", "\n", "span", "=", "match_span", ".", "split", "(", ")", "\n", "\n", "res", "=", "[", "words", "[", "idx", ":", "idx", "+", "len", "(", "span", ")", "]", "==", "span", "for", "idx", "in", "range", "(", "len", "(", "words", ")", ")", "]", "\n", "try", ":", "\n", "                ", "index", "=", "res", ".", "index", "(", "True", ")", "\n", "", "except", ":", "\n", "                ", "return", "[", "0", "]", ",", "[", "0", "]", "\n", "", "start_times", ".", "append", "(", "tg", "[", "0", "]", "[", "pos_map", "[", "index", "]", "]", ".", "minTime", ")", "\n", "end_times", ".", "append", "(", "tg", "[", "0", "]", "[", "pos_map", "[", "index", "+", "len", "(", "span", ")", "-", "1", "]", "]", ".", "maxTime", ")", "\n", "\n", "\n", "", "return", "start_times", ",", "end_times", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.text_preprocess": [[6, 19], ["builtins.str", "utils.normalize_numbers", "re.sub.lower", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.normalize_numbers"], ["def", "text_preprocess", "(", "text", ")", ":", "\n", "    ", "text", "=", "unicode", "(", "text", ")", "\n", "\n", "text", "=", "normalize_numbers", "(", "text", ")", "\n", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"i.e.\"", ",", "\"that is\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"e.g.\"", ",", "\"for example\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "r\"\\%\"", ",", "\"percent\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "\"-\"", ",", "\" \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "\"[^ a-z]\"", ",", "\"\"", ",", "text", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils._remove_commas": [[33, 35], ["m.group().replace", "m.group"], "function", ["None"], ["def", "_remove_commas", "(", "m", ")", ":", "\n", "    ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "','", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils._expand_decimal_point": [[37, 39], ["m.group().replace", "m.group"], "function", ["None"], ["", "def", "_expand_decimal_point", "(", "m", ")", ":", "\n", "    ", "return", "m", ".", "group", "(", "1", ")", ".", "replace", "(", "'.'", ",", "' point '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils._expand_dollars": [[41, 60], ["m.group", "m.group.split", "len", "int", "int", "len"], "function", ["None"], ["", "def", "_expand_dollars", "(", "m", ")", ":", "\n", "    ", "match", "=", "m", ".", "group", "(", "1", ")", "\n", "parts", "=", "match", ".", "split", "(", "'.'", ")", "\n", "if", "len", "(", "parts", ")", ">", "2", ":", "\n", "        ", "return", "match", "+", "' dollars'", "# Unexpected format", "\n", "", "dollars", "=", "int", "(", "parts", "[", "0", "]", ")", "if", "parts", "[", "0", "]", "else", "0", "\n", "cents", "=", "int", "(", "parts", "[", "1", "]", ")", "if", "len", "(", "parts", ")", ">", "1", "and", "parts", "[", "1", "]", "else", "0", "\n", "if", "dollars", "and", "cents", ":", "\n", "        ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s, %s %s'", "%", "(", "dollars", ",", "dollar_unit", ",", "cents", ",", "cent_unit", ")", "\n", "", "elif", "dollars", ":", "\n", "        ", "dollar_unit", "=", "'dollar'", "if", "dollars", "==", "1", "else", "'dollars'", "\n", "return", "'%s %s'", "%", "(", "dollars", ",", "dollar_unit", ")", "\n", "", "elif", "cents", ":", "\n", "        ", "cent_unit", "=", "'cent'", "if", "cents", "==", "1", "else", "'cents'", "\n", "return", "'%s %s'", "%", "(", "cents", ",", "cent_unit", ")", "\n", "", "else", ":", "\n", "        ", "return", "'zero dollars'", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils._expand_ordinal": [[62, 64], ["_inflect.number_to_words", "m.group"], "function", ["None"], ["", "", "def", "_expand_ordinal", "(", "m", ")", ":", "\n", "    ", "return", "_inflect", ".", "number_to_words", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils._expand_number": [[66, 79], ["int", "m.group", "_inflect.number_to_words", "_inflect.number_to_words", "_inflect.number_to_words().replace", "_inflect.number_to_words", "_inflect.number_to_words"], "function", ["None"], ["", "def", "_expand_number", "(", "m", ")", ":", "\n", "    ", "num", "=", "int", "(", "m", ".", "group", "(", "0", ")", ")", "\n", "if", "num", ">", "1000", "and", "num", "<", "3000", ":", "\n", "        ", "if", "num", "==", "2000", ":", "\n", "            ", "return", "'two thousand'", "\n", "", "elif", "num", ">", "2000", "and", "num", "<", "2010", ":", "\n", "            ", "return", "'two thousand '", "+", "_inflect", ".", "number_to_words", "(", "num", "%", "100", ")", "\n", "", "elif", "num", "%", "100", "==", "0", ":", "\n", "            ", "return", "_inflect", ".", "number_to_words", "(", "num", "//", "100", ")", "+", "' hundred'", "\n", "", "else", ":", "\n", "            ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ",", "zero", "=", "'oh'", ",", "group", "=", "2", ")", ".", "replace", "(", "', '", ",", "' '", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "_inflect", ".", "number_to_words", "(", "num", ",", "andword", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.normalize_numbers": [[81, 89], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub"], "function", ["None"], ["", "", "def", "normalize_numbers", "(", "text", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "_comma_number_re", ",", "_remove_commas", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_pounds_re", ",", "r'\\1 pounds'", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_dollars_re", ",", "_expand_dollars", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_decimal_number_re", ",", "_expand_decimal_point", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_ordinal_re", ",", "_expand_ordinal", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "_number_re", ",", "_expand_number", ",", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.compare": [[94, 130], ["None"], "function", ["None"], ["def", "compare", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", ":", "\n", "    ", "if", "pred_start", ">=", "pred_end", ":", "\n", "        ", "overlap_start", "=", "0", "\n", "overlap_end", "=", "0", "\n", "Max", "=", "0", "\n", "Min", "=", "0", "\n", "no_overlap", "=", "True", "\n", "", "elif", "pred_end", "<=", "gold_start", "or", "pred_start", ">=", "gold_end", ":", "\n", "        ", "overlap_start", "=", "0", "\n", "overlap_end", "=", "0", "\n", "Max", "=", "0", "\n", "Min", "=", "0", "\n", "no_overlap", "=", "True", "\n", "", "elif", "gold_end", "==", "gold_start", ":", "\n", "        ", "overlap_start", "=", "0", "\n", "overlap_end", "=", "0", "\n", "Max", "=", "0", "\n", "Min", "=", "0", "\n", "no_overlap", "=", "True", "\n", "", "else", ":", "\n", "        ", "no_overlap", "=", "False", "\n", "if", "pred_start", "<=", "gold_start", ":", "\n", "            ", "Min", "=", "pred_start", "\n", "overlap_start", "=", "gold_start", "\n", "", "else", ":", "\n", "            ", "Min", "=", "gold_start", "\n", "overlap_start", "=", "pred_start", "\n", "\n", "", "if", "pred_end", "<=", "gold_end", ":", "\n", "            ", "Max", "=", "gold_end", "\n", "overlap_end", "=", "pred_end", "\n", "", "else", ":", "\n", "            ", "Max", "=", "pred_end", "\n", "overlap_end", "=", "gold_end", "\n", "\n", "", "", "return", "overlap_start", ",", "overlap_end", ",", "Min", ",", "Max", ",", "no_overlap", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.Frame_F1_scores": [[131, 146], ["zip", "utils.compare", "F1s.append", "float"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.compare"], ["", "def", "Frame_F1_scores", "(", "pred_starts", ",", "pred_ends", ",", "gold_starts", ",", "gold_ends", ")", ":", "\n", "    ", "F1s", "=", "[", "]", "\n", "for", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", "in", "zip", "(", "pred_starts", ",", "pred_ends", ",", "gold_starts", ",", "gold_ends", ")", ":", "\n", "        ", "overlap_start", ",", "overlap_end", ",", "Min", ",", "Max", ",", "no_overlap", "=", "compare", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", "\n", "if", "no_overlap", ":", "\n", "            ", "if", "pred_start", "==", "gold_start", "and", "pred_end", "==", "gold_end", ":", "\n", "                ", "F1", "=", "1", "\n", "", "else", ":", "\n", "                ", "F1", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "Precision", "=", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "pred_end", "-", "pred_start", ")", "\n", "Recall", "=", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "gold_end", "-", "gold_start", ")", "\n", "F1", "=", "float", "(", "2", "*", "Precision", "*", "Recall", "/", "(", "Precision", "+", "Recall", ")", ")", "\n", "", "F1s", ".", "append", "(", "F1", ")", "\n", "", "return", "F1s", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.Frame_F1_score": [[147, 159], ["utils.compare"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.compare"], ["", "def", "Frame_F1_score", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", ":", "\n", "    ", "overlap_start", ",", "overlap_end", ",", "Min", ",", "Max", ",", "no_overlap", "=", "compare", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", "\n", "if", "no_overlap", ":", "\n", "        ", "if", "pred_start", "==", "gold_start", "and", "pred_end", "==", "gold_end", ":", "\n", "            ", "F1", "=", "1", "\n", "", "else", ":", "\n", "            ", "F1", "=", "0", "\n", "", "", "else", ":", "\n", "        ", "Precision", "=", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "pred_end", "-", "pred_start", ")", "\n", "Recall", "=", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "gold_end", "-", "gold_start", ")", "\n", "F1", "=", "2", "*", "Precision", "*", "Recall", "/", "(", "Precision", "+", "Recall", ")", "\n", "", "return", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.AOS_scores": [[160, 171], ["zip", "utils.compare", "AOSs.append", "float"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.compare"], ["", "def", "AOS_scores", "(", "pred_starts", ",", "pred_ends", ",", "gold_starts", ",", "gold_ends", ")", ":", "\n", "    ", "AOSs", "=", "[", "]", "\n", "for", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", "in", "zip", "(", "pred_starts", ",", "pred_ends", ",", "gold_starts", ",", "gold_ends", ")", ":", "\n", "        ", "overlap_start", ",", "overlap_end", ",", "Min", ",", "Max", ",", "no_overlap", "=", "compare", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", "\n", "\n", "if", "no_overlap", ":", "\n", "            ", "AOS", "=", "0", "\n", "", "else", ":", "\n", "            ", "AOS", "=", "float", "(", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "Max", "-", "Min", ")", ")", "\n", "", "AOSs", ".", "append", "(", "AOS", ")", "\n", "", "return", "AOSs", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.AOS_score": [[172, 180], ["utils.compare"], "function", ["home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.compare"], ["", "def", "AOS_score", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", ":", "\n", "    ", "overlap_start", ",", "overlap_end", ",", "Min", ",", "Max", ",", "no_overlap", "=", "compare", "(", "pred_start", ",", "pred_end", ",", "gold_start", ",", "gold_end", ")", "\n", "\n", "if", "no_overlap", ":", "\n", "        ", "AOS", "=", "0", "\n", "", "else", ":", "\n", "        ", "AOS", "=", "(", "overlap_end", "-", "overlap_start", ")", "/", "(", "Max", "-", "Min", ")", "\n", "", "return", "AOS", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.aggregate_dev_result": [[183, 199], ["range", "len", "sum", "len", "buff.append", "len", "aggregate_result.append", "aggregate_result.append", "max"], "function", ["None"], ["", "def", "aggregate_dev_result", "(", "dup", ",", "metric", ")", ":", "\n", "    ", "aggregate_result", "=", "[", "]", "\n", "buff", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dup", ")", ")", ":", "\n", "        ", "if", "not", "dup", "[", "i", "]", ":", "\n", "            ", "if", "len", "(", "buff", ")", "==", "0", ":", "\n", "                ", "aggregate_result", ".", "append", "(", "metric", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "aggregate_result", ".", "append", "(", "max", "(", "buff", ")", ")", "\n", "\n", "", "buff", "=", "[", "]", "# clear buffer", "\n", "\n", "", "else", ":", "\n", "            ", "buff", ".", "append", "(", "metric", "[", "i", "]", ")", "\n", "\n", "", "", "return", "sum", "(", "aggregate_result", ")", "/", "len", "(", "aggregate_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.None.utils.calc_overlap": [[200, 215], ["min", "max", "max", "min", "float", "print"], "function", ["None"], ["", "def", "calc_overlap", "(", "pred_starts", ",", "pred_ends", ",", "gold_starts", ",", "gold_ends", ")", ":", "\n", "    ", "x", "=", "[", "pred_starts", ",", "pred_ends", "]", "\n", "y", "=", "[", "gold_starts", ",", "gold_ends", "]", "\n", "if", "x", "[", "1", "]", "<=", "y", "[", "0", "]", "or", "x", "[", "0", "]", ">=", "y", "[", "1", "]", ":", "\n", "        ", "return", "0.0", ",", "0.0", "\n", "", "minest", ",", "maxest", "=", "min", "(", "x", "[", "0", "]", ",", "y", "[", "0", "]", ")", ",", "max", "(", "x", "[", "1", "]", ",", "y", "[", "1", "]", ")", "\n", "left", ",", "right", "=", "max", "(", "x", "[", "0", "]", ",", "y", "[", "0", "]", ")", ",", "min", "(", "x", "[", "1", "]", ",", "y", "[", "1", "]", ")", "\n", "try", ":", "\n", "        ", "aos", "=", "(", "right", "-", "left", ")", "/", "(", "maxest", "-", "minest", ")", "\n", "precision", "=", "(", "right", "-", "left", ")", "/", "(", "x", "[", "1", "]", "-", "x", "[", "0", "]", ")", "\n", "recall", "=", "(", "right", "-", "left", ")", "/", "(", "y", "[", "1", "]", "-", "y", "[", "0", "]", ")", "\n", "f1", "=", "float", "(", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "right", ",", "left", ",", "maxest", ",", "minest", ")", "\n", "", "return", "f1", ",", "aos", "\n", "", ""]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_train_dev.ApplyKmeans.__init__": [[13, 23], ["joblib.load", "S2U_train_dev.ApplyKmeans.km_model.cluster_centers_.transpose", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "S2U_train_dev.ApplyKmeans.C.cuda", "S2U_train_dev.ApplyKmeans.Cnorm.cuda"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "km_path", ",", "return_diff", "=", "False", ")", ":", "\n", "        ", "self", ".", "km_model", "=", "joblib", ".", "load", "(", "km_path", ")", "\n", "self", ".", "C_np", "=", "self", ".", "km_model", ".", "cluster_centers_", ".", "transpose", "(", ")", "\n", "self", ".", "Cnorm_np", "=", "(", "self", ".", "C_np", "**", "2", ")", ".", "sum", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "self", ".", "return_diff", "=", "return_diff", "\n", "self", ".", "C", "=", "torch", ".", "from_numpy", "(", "self", ".", "C_np", ")", "\n", "self", ".", "Cnorm", "=", "torch", ".", "from_numpy", "(", "self", ".", "Cnorm_np", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "C", "=", "self", ".", "C", ".", "cuda", "(", ")", "\n", "self", ".", "Cnorm", "=", "self", ".", "Cnorm", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_train_dev.ApplyKmeans.__call__": [[24, 46], ["isinstance", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "numpy.sqrt.detach().min", "numpy.sqrt", "np.sqrt.detach().min.indices.cpu().numpy", "numpy.argmin", "numpy.sqrt.detach", "np.sqrt.detach().min.indices.cpu().numpy", "np.sqrt.detach().min.values.cpu().numpy", "numpy.argmin", "numpy.min", "x.pow().sum", "np.sqrt.detach().min.indices.cpu", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "np.sqrt.detach().min.indices.cpu", "np.sqrt.detach().min.values.cpu", "numpy.matmul", "x.pow"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "dist", "=", "torch", ".", "sqrt", "(", "\n", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "x", ",", "self", ".", "C", ")", "\n", "+", "self", ".", "Cnorm", "\n", ")", "\n", "min_dist", "=", "dist", ".", "detach", "(", ")", ".", "min", "(", "dim", "=", "1", ")", "\n", "if", "self", ".", "return_diff", ":", "\n", "                ", "return", "min_dist", ".", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "min_dist", ".", "values", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "min_dist", ".", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "dist", "=", "np", ".", "sqrt", "(", "\n", "(", "x", "**", "2", ")", ".", "sum", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "-", "2", "*", "np", ".", "matmul", "(", "x", ",", "self", ".", "C_np", ")", "\n", "+", "self", ".", "Cnorm_np", "\n", ")", "\n", "if", "self", ".", "return_diff", ":", "\n", "                ", "return", "np", ".", "argmin", "(", "dist", ",", "axis", "=", "1", ")", ",", "np", ".", "min", "(", "dist", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "np", ".", "argmin", "(", "dist", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_train_dev.reader": [[47, 52], ["torchaudio.load", "wav.squeeze", "torchaudio.transforms.Resample"], "function", ["None"], ["", "", "", "", "def", "reader", "(", "fname", ")", ":", "\n", "    ", "wav", ",", "ori_sr", "=", "torchaudio", ".", "load", "(", "fname", ")", "\n", "if", "ori_sr", "!=", "SAMPLE_RATE", ":", "\n", "        ", "wav", "=", "torchaudio", ".", "transforms", ".", "Resample", "(", "ori_sr", ",", "SAMPLE_RATE", ")", "(", "wav", ")", "\n", "", "return", "wav", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_test.ApplyKmeans.__init__": [[12, 22], ["joblib.load", "S2U_test.ApplyKmeans.km_model.cluster_centers_.transpose", "torch.from_numpy", "torch.from_numpy", "torch.cuda.is_available", "S2U_test.ApplyKmeans.C.cuda", "S2U_test.ApplyKmeans.Cnorm.cuda"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "km_path", ",", "return_diff", "=", "False", ")", ":", "\n", "        ", "self", ".", "km_model", "=", "joblib", ".", "load", "(", "km_path", ")", "\n", "self", ".", "C_np", "=", "self", ".", "km_model", ".", "cluster_centers_", ".", "transpose", "(", ")", "\n", "self", ".", "Cnorm_np", "=", "(", "self", ".", "C_np", "**", "2", ")", ".", "sum", "(", "0", ",", "keepdims", "=", "True", ")", "\n", "self", ".", "return_diff", "=", "return_diff", "\n", "self", ".", "C", "=", "torch", ".", "from_numpy", "(", "self", ".", "C_np", ")", "\n", "self", ".", "Cnorm", "=", "torch", ".", "from_numpy", "(", "self", ".", "Cnorm_np", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "C", "=", "self", ".", "C", ".", "cuda", "(", ")", "\n", "self", ".", "Cnorm", "=", "self", ".", "Cnorm", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_test.ApplyKmeans.__call__": [[23, 45], ["isinstance", "torch.sqrt", "numpy.sqrt.detach().min", "numpy.sqrt", "np.sqrt.detach().min.indices.cpu().numpy", "numpy.argmin", "numpy.sqrt.detach", "np.sqrt.detach().min.indices.cpu().numpy", "np.sqrt.detach().min.values.cpu().numpy", "numpy.argmin", "numpy.min", "x.pow().sum", "np.sqrt.detach().min.indices.cpu", "torch.matmul", "np.sqrt.detach().min.indices.cpu", "np.sqrt.detach().min.values.cpu", "numpy.matmul", "x.pow"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "dist", "=", "torch", ".", "sqrt", "(", "\n", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "-", "2", "*", "torch", ".", "matmul", "(", "x", ",", "self", ".", "C", ")", "\n", "+", "self", ".", "Cnorm", "\n", ")", "\n", "min_dist", "=", "dist", ".", "detach", "(", ")", ".", "min", "(", "dim", "=", "1", ")", "\n", "if", "self", ".", "return_diff", ":", "\n", "                ", "return", "min_dist", ".", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "min_dist", ".", "values", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "min_dist", ".", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "dist", "=", "np", ".", "sqrt", "(", "\n", "(", "x", "**", "2", ")", ".", "sum", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "-", "2", "*", "np", ".", "matmul", "(", "x", ",", "self", ".", "C_np", ")", "\n", "+", "self", ".", "Cnorm_np", "\n", ")", "\n", "if", "self", ".", "return_diff", ":", "\n", "                ", "return", "np", ".", "argmin", "(", "dist", ",", "axis", "=", "1", ")", ",", "np", ".", "min", "(", "dist", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "return", "np", ".", "argmin", "(", "dist", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.daniellin94144_dual-textless-sqa.speeech-content-encoder.S2U_test.reader": [[46, 51], ["torchaudio.load", "wav.squeeze", "torchaudio.transforms.Resample"], "function", ["None"], ["", "", "", "", "def", "reader", "(", "fname", ")", ":", "\n", "    ", "wav", ",", "ori_sr", "=", "torchaudio", ".", "load", "(", "fname", ")", "\n", "if", "ori_sr", "!=", "SAMPLE_RATE", ":", "\n", "        ", "wav", "=", "torchaudio", ".", "transforms", ".", "Resample", "(", "ori_sr", ",", "SAMPLE_RATE", ")", "(", "wav", ")", "\n", "", "return", "wav", ".", "squeeze", "(", ")", "\n", "\n"]]}