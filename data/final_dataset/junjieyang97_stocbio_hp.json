{"home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.__init__": [[6, 19], ["hasattr", "itertools.repeat"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "loss_f", ",", "dim_mult", ",", "data_or_iter", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss_f: callable with signature (params, hparams, [data optional]) -> loss tensor\n            data_or_iter: (x, y) or iterator over the data needed for loss_f\n        \"\"\"", "\n", "self", ".", "data_iterator", "=", "None", "\n", "if", "data_or_iter", ":", "\n", "            ", "self", ".", "data_iterator", "=", "data_or_iter", "if", "hasattr", "(", "data_or_iter", ",", "'__next__'", ")", "else", "repeat", "(", "data_or_iter", ")", "\n", "\n", "", "self", ".", "loss_f", "=", "loss_f", "\n", "self", ".", "dim_mult", "=", "dim_mult", "\n", "self", ".", "curr_loss", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.get_opt_params": [[20, 24], ["opt_params.extend", "torch.zeros_like", "range"], "methods", ["None"], ["", "def", "get_opt_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "opt_params", "=", "[", "p", "for", "p", "in", "params", "]", "\n", "opt_params", ".", "extend", "(", "[", "torch", ".", "zeros_like", "(", "p", ")", "for", "p", "in", "params", "for", "_", "in", "range", "(", "self", ".", "dim_mult", "-", "1", ")", "]", ")", "\n", "return", "opt_params", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.step": [[25, 27], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "params", ",", "hparams", ",", "create_graph", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.__call__": [[28, 31], ["torch.enable_grad", "diff_optimizers.DifferentiableOptimizer.step"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step"], ["", "def", "__call__", "(", "self", ",", "params", ",", "hparams", ",", "create_graph", "=", "True", ")", ":", "\n", "        ", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "step", "(", "params", ",", "hparams", ",", "create_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.get_loss": [[32, 39], ["next", "diff_optimizers.DifferentiableOptimizer.loss_f", "diff_optimizers.DifferentiableOptimizer.loss_f"], "methods", ["None"], ["", "", "def", "get_loss", "(", "self", ",", "params", ",", "hparams", ")", ":", "\n", "        ", "if", "self", ".", "data_iterator", ":", "\n", "            ", "data", "=", "next", "(", "self", ".", "data_iterator", ")", "\n", "self", ".", "curr_loss", "=", "self", ".", "loss_f", "(", "params", ",", "hparams", ",", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "curr_loss", "=", "self", ".", "loss_f", "(", "params", ",", "hparams", ")", "\n", "", "return", "self", ".", "curr_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.HeavyBall.__init__": [[42, 47], ["diff_optimizers.DifferentiableOptimizer.__init__", "callable", "callable"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["    ", "def", "__init__", "(", "self", ",", "loss_f", ",", "step_size", ",", "momentum", ",", "data_or_iter", "=", "None", ")", ":", "\n", "        ", "super", "(", "HeavyBall", ",", "self", ")", ".", "__init__", "(", "loss_f", ",", "dim_mult", "=", "2", ",", "data_or_iter", "=", "data_or_iter", ")", "\n", "self", ".", "loss_f", "=", "loss_f", "\n", "self", ".", "step_size_f", "=", "step_size", "if", "callable", "(", "step_size", ")", "else", "lambda", "x", ":", "step_size", "\n", "self", ".", "momentum_f", "=", "momentum", "if", "callable", "(", "momentum", ")", "else", "lambda", "x", ":", "momentum", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.HeavyBall.step": [[48, 55], ["diff_optimizers.HeavyBall.get_loss", "diff_optimizers.heavy_ball_step", "len", "diff_optimizers.HeavyBall.step_size_f", "diff_optimizers.HeavyBall.momentum_f"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.get_loss", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.heavy_ball_step"], ["", "def", "step", "(", "self", ",", "params", ",", "hparams", ",", "create_graph", ")", ":", "\n", "        ", "n", "=", "len", "(", "params", ")", "//", "2", "\n", "p", ",", "p_aux", "=", "params", "[", ":", "n", "]", ",", "params", "[", "n", ":", "]", "\n", "loss", "=", "self", ".", "get_loss", "(", "p", ",", "hparams", ")", "\n", "sz", ",", "mu", "=", "self", ".", "step_size_f", "(", "hparams", ")", ",", "self", ".", "momentum_f", "(", "hparams", ")", "\n", "p_new", ",", "p_new_aux", "=", "heavy_ball_step", "(", "p", ",", "p_aux", ",", "loss", ",", "sz", ",", "mu", ",", "create_graph", "=", "create_graph", ")", "\n", "return", "[", "*", "p_new", ",", "*", "p_new_aux", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.Momentum.__init__": [[64, 69], ["diff_optimizers.DifferentiableOptimizer.__init__", "callable", "callable"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["def", "__init__", "(", "self", ",", "loss_f", ",", "step_size", ",", "momentum", ",", "data_or_iter", "=", "None", ")", ":", "\n", "        ", "super", "(", "Momentum", ",", "self", ")", ".", "__init__", "(", "loss_f", ",", "dim_mult", "=", "2", ",", "data_or_iter", "=", "data_or_iter", ")", "\n", "self", ".", "loss_f", "=", "loss_f", "\n", "self", ".", "step_size_f", "=", "step_size", "if", "callable", "(", "step_size", ")", "else", "lambda", "x", ":", "step_size", "\n", "self", ".", "momentum_f", "=", "momentum", "if", "callable", "(", "momentum", ")", "else", "lambda", "x", ":", "momentum", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.Momentum.step": [[70, 77], ["diff_optimizers.Momentum.get_loss", "diff_optimizers.torch_momentum_step", "len", "diff_optimizers.Momentum.step_size_f", "diff_optimizers.Momentum.momentum_f"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.get_loss", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.torch_momentum_step"], ["", "def", "step", "(", "self", ",", "params", ",", "hparams", ",", "create_graph", ")", ":", "\n", "        ", "n", "=", "len", "(", "params", ")", "//", "2", "\n", "p", ",", "p_aux", "=", "params", "[", ":", "n", "]", ",", "params", "[", "n", ":", "]", "\n", "loss", "=", "self", ".", "get_loss", "(", "p", ",", "hparams", ")", "\n", "sz", ",", "mu", "=", "self", ".", "step_size_f", "(", "hparams", ")", ",", "self", ".", "momentum_f", "(", "hparams", ")", "\n", "p_new", ",", "p_new_aux", "=", "torch_momentum_step", "(", "p", ",", "p_aux", ",", "loss", ",", "sz", ",", "mu", ",", "create_graph", "=", "create_graph", ")", "\n", "return", "[", "*", "p_new", ",", "*", "p_new_aux", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.__init__": [[80, 83], ["diff_optimizers.DifferentiableOptimizer.__init__", "callable"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["    ", "def", "__init__", "(", "self", ",", "loss_f", ",", "step_size", ",", "data_or_iter", "=", "None", ")", ":", "\n", "        ", "super", "(", "GradientDescent", ",", "self", ")", ".", "__init__", "(", "loss_f", ",", "dim_mult", "=", "1", ",", "data_or_iter", "=", "data_or_iter", ")", "\n", "self", ".", "step_size_f", "=", "step_size", "if", "callable", "(", "step_size", ")", "else", "lambda", "x", ":", "step_size", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step": [[84, 88], ["diff_optimizers.GradientDescent.get_loss", "diff_optimizers.GradientDescent.step_size_f", "diff_optimizers.gd_step"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.DifferentiableOptimizer.get_loss", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.gd_step"], ["", "def", "step", "(", "self", ",", "params", ",", "hparams", ",", "create_graph", ")", ":", "\n", "        ", "loss", "=", "self", ".", "get_loss", "(", "params", ",", "hparams", ")", "\n", "sz", "=", "self", ".", "step_size_f", "(", "hparams", ")", "\n", "return", "gd_step", "(", "params", ",", "loss", ",", "sz", ",", "create_graph", "=", "create_graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.gd_step": [[90, 93], ["torch.autograd.grad", "zip"], "function", ["None"], ["", "", "def", "gd_step", "(", "params", ",", "loss", ",", "step_size", ",", "create_graph", "=", "True", ")", ":", "\n", "    ", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ",", "create_graph", "=", "create_graph", ")", "\n", "return", "[", "w", "-", "step_size", "*", "g", "for", "w", ",", "g", "in", "zip", "(", "params", ",", "grads", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.heavy_ball_step": [[95, 98], ["torch.autograd.grad", "zip"], "function", ["None"], ["", "def", "heavy_ball_step", "(", "params", ",", "aux_params", ",", "loss", ",", "step_size", ",", "momentum", ",", "create_graph", "=", "True", ")", ":", "\n", "    ", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ",", "create_graph", "=", "create_graph", ")", "\n", "return", "[", "w", "-", "step_size", "*", "g", "+", "momentum", "*", "(", "w", "-", "v", ")", "for", "g", ",", "w", ",", "v", "in", "zip", "(", "grads", ",", "params", ",", "aux_params", ")", "]", ",", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.torch_momentum_step": [[100, 110], ["torch.autograd.grad", "zip", "zip"], "function", ["None"], ["", "def", "torch_momentum_step", "(", "params", ",", "aux_params", ",", "loss", ",", "step_size", ",", "momentum", ",", "create_graph", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    GD with momentum step as implemented in torch.optim.SGD\n    .. math::\n              v_{t+1} = \\mu * v_{t} + g_{t+1} \\\\\n              p_{t+1} = p_{t} - lr * v_{t+1}\n    \"\"\"", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ",", "create_graph", "=", "create_graph", ")", "\n", "new_aux_params", "=", "[", "momentum", "*", "v", "+", "g", "for", "v", ",", "g", "in", "zip", "(", "aux_params", ",", "grads", ")", "]", "\n", "return", "[", "w", "-", "step_size", "*", "nv", "for", "w", ",", "nv", "in", "zip", "(", "params", ",", "new_aux_params", ")", "]", ",", "new_aux_params", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.CG_torch.cg": [[6, 42], ["range", "torch.zeros_like", "torch.zeros_like().copy_", "torch.zeros_like().copy_", "Ax", "CG_torch.cat_list_to_tensor", "CG_torch.cat_list_to_tensor", "CG_torch.cat_list_to_tensor", "torch.sum", "torch.sum", "CG_torch.cat_list_to_tensor", "float", "torch.sum", "torch.zeros_like", "torch.zeros_like", "zip", "zip", "torch.norm", "zip"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor"], ["def", "cg", "(", "Ax", ",", "b", ",", "max_iter", "=", "100", ",", "epsilon", "=", "1.0e-5", ")", ":", "\n", "    ", "\"\"\" Conjugate Gradient\n      Args:\n        Ax: function, takes list of tensors as input\n        b: list of tensors\n      Returns:\n        x_star: list of tensors\n    \"\"\"", "\n", "x_last", "=", "[", "torch", ".", "zeros_like", "(", "bb", ")", "for", "bb", "in", "b", "]", "\n", "r_last", "=", "[", "torch", ".", "zeros_like", "(", "bb", ")", ".", "copy_", "(", "bb", ")", "for", "bb", "in", "b", "]", "\n", "p_last", "=", "[", "torch", ".", "zeros_like", "(", "rr", ")", ".", "copy_", "(", "rr", ")", "for", "rr", "in", "r_last", "]", "\n", "\n", "for", "ii", "in", "range", "(", "max_iter", ")", ":", "\n", "        ", "Ap", "=", "Ax", "(", "p_last", ")", "\n", "Ap_vec", "=", "cat_list_to_tensor", "(", "Ap", ")", "\n", "p_last_vec", "=", "cat_list_to_tensor", "(", "p_last", ")", "\n", "r_last_vec", "=", "cat_list_to_tensor", "(", "r_last", ")", "\n", "rTr", "=", "torch", ".", "sum", "(", "r_last_vec", "*", "r_last_vec", ")", "\n", "pAp", "=", "torch", ".", "sum", "(", "p_last_vec", "*", "Ap_vec", ")", "\n", "alpha", "=", "rTr", "/", "pAp", "\n", "\n", "x", "=", "[", "xx", "+", "alpha", "*", "pp", "for", "xx", ",", "pp", "in", "zip", "(", "x_last", ",", "p_last", ")", "]", "\n", "r", "=", "[", "rr", "-", "alpha", "*", "pp", "for", "rr", ",", "pp", "in", "zip", "(", "r_last", ",", "Ap", ")", "]", "\n", "r_vec", "=", "cat_list_to_tensor", "(", "r", ")", "\n", "\n", "if", "float", "(", "torch", ".", "norm", "(", "r_vec", ")", ")", "<", "epsilon", ":", "\n", "            ", "break", "\n", "\n", "", "beta", "=", "torch", ".", "sum", "(", "r_vec", "*", "r_vec", ")", "/", "rTr", "\n", "p", "=", "[", "rr", "+", "beta", "*", "pp", "for", "rr", ",", "pp", "in", "zip", "(", "r", ",", "p_last", ")", "]", "\n", "\n", "x_last", "=", "x", "\n", "p_last", "=", "p", "\n", "r_last", "=", "r", "\n", "\n", "", "return", "x_last", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.CG_torch.cat_list_to_tensor": [[44, 46], ["torch.cat", "xx.view"], "function", ["None"], ["", "def", "cat_list_to_tensor", "(", "list_tx", ")", ":", "\n", "    ", "return", "torch", ".", "cat", "(", "[", "xx", ".", "view", "(", "[", "-", "1", "]", ")", "for", "xx", "in", "list_tx", "]", ")", "", "", ""]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.reverse_unroll": [[9, 30], ["outer_loss", "torch.autograd.grad", "hypergradients.update_tensor_grads"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["def", "reverse_unroll", "(", "params", ":", "List", "[", "Tensor", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "set_grad", "=", "True", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Computes the hypergradient by backpropagating through a previously employed inner solver procedure.\n\n    Args:\n        params: the output of a torch differentiable inner solver (it must depend on hparams in the torch graph)\n        hparams: the outer variables (or hyperparameters), each element needs requires_grad=True\n        outer_loss: computes the outer objective taking parameters and hyperparameters as inputs\n        set_grad: if True set t.grad to the hypergradient for every t in hparams\n\n    Returns:\n        the list of hypergradients for each element in hparams\n    \"\"\"", "\n", "o_loss", "=", "outer_loss", "(", "params", ",", "hparams", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "o_loss", ",", "hparams", ",", "retain_graph", "=", "True", ")", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.reverse": [[33, 74], ["outer_loss", "hypergradients.get_outer_gradients", "range", "torch.zeros_like", "len", "hypergradients.grad_unused_zero", "torch.autograd.grad", "hypergradients.update_tensor_grads", "w.detach().requires_grad_", "zip", "zip", "w.detach"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grad_unused_zero", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["", "def", "reverse", "(", "params_history", ":", "List", "[", "List", "[", "Tensor", "]", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "update_map_history", ":", "List", "[", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "set_grad", "=", "True", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Computes the hypergradient by recomputing and backpropagating through each inner update\n    using the inner iterates and the update maps previously employed by the inner solver.\n    Similarly to checkpointing, this allows to save memory w.r.t. reverse_unroll by increasing computation time.\n    Truncated reverse can be performed by passing only part of the trajectory information, i.e. only the\n    last k inner iterates and updates.\n\n    Args:\n        params_history: the inner iterates (from first to last)\n        hparams: the outer variables (or hyperparameters), each element needs requires_grad=True\n        update_map_history: updates used to solve the inner problem (from first to last)\n        outer_loss: computes the outer objective taking parameters and hyperparameters as inputs\n        set_grad: if True set t.grad to the hypergradient for every t in hparams\n\n    Returns:\n         the list of hypergradients for each element in hparams\n\n    \"\"\"", "\n", "params_history", "=", "[", "[", "w", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "for", "w", "in", "params", "]", "for", "params", "in", "params_history", "]", "\n", "o_loss", "=", "outer_loss", "(", "params_history", "[", "-", "1", "]", ",", "hparams", ")", "\n", "grad_outer_w", ",", "grad_outer_hparams", "=", "get_outer_gradients", "(", "o_loss", ",", "params_history", "[", "-", "1", "]", ",", "hparams", ")", "\n", "\n", "alphas", "=", "grad_outer_w", "\n", "grads", "=", "[", "torch", ".", "zeros_like", "(", "w", ")", "for", "w", "in", "hparams", "]", "\n", "K", "=", "len", "(", "params_history", ")", "-", "1", "\n", "for", "k", "in", "range", "(", "-", "2", ",", "-", "(", "K", "+", "2", ")", ",", "-", "1", ")", ":", "\n", "        ", "w_mapped", "=", "update_map_history", "[", "k", "+", "1", "]", "(", "params_history", "[", "k", "]", ",", "hparams", ")", "\n", "bs", "=", "grad_unused_zero", "(", "w_mapped", ",", "hparams", ",", "grad_outputs", "=", "alphas", ",", "retain_graph", "=", "True", ")", "\n", "grads", "=", "[", "g", "+", "b", "for", "g", ",", "b", "in", "zip", "(", "grads", ",", "bs", ")", "]", "\n", "alphas", "=", "torch_grad", "(", "w_mapped", ",", "params_history", "[", "k", "]", ",", "grad_outputs", "=", "alphas", ")", "\n", "\n", "", "grads", "=", "[", "g", "+", "v", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "grad_outer_hparams", ")", "]", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.fixed_point": [[76, 134], ["outer_loss", "hypergradients.get_outer_gradients", "hypergradients.cat_list_to_tensor", "range", "torch.autograd.grad", "w.detach().requires_grad_", "fp_map", "torch.zeros_like", "hypergradients.cat_list_to_tensor", "fp_map", "hypergradients.update_tensor_grads", "fp_map", "torch.autograd.grad", "torch.autograd.grad", "float", "zip", "w.detach", "zip", "torch.norm"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["", "def", "fixed_point", "(", "params", ":", "List", "[", "Tensor", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "K", ":", "int", ",", "\n", "fp_map", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "tol", "=", "1e-10", ",", "\n", "set_grad", "=", "True", ",", "\n", "stochastic", "=", "False", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Computes the hypergradient by applying K steps of the fixed point method (it can end earlier when tol is reached).\n\n    Args:\n        params: the output of the inner solver procedure.\n        hparams: the outer variables (or hyperparameters), each element needs requires_grad=True\n        K: the maximum number of fixed point iterations\n        fp_map: the fixed point map which defines the inner problem\n        outer_loss: computes the outer objective taking parameters and hyperparameters as inputs\n        tol: end the method earlier when  the normed difference between two iterates is less than tol\n        set_grad: if True set t.grad to the hypergradient for every t in hparams\n        stochastic: set this to True when fp_map is not a deterministic function of its inputs\n\n    Returns:\n        the list of hypergradients for each element in hparams\n    \"\"\"", "\n", "\n", "params", "=", "[", "w", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "for", "w", "in", "params", "]", "\n", "o_loss", "=", "outer_loss", "(", "params", ",", "hparams", ")", "\n", "grad_outer_w", ",", "grad_outer_hparams", "=", "get_outer_gradients", "(", "o_loss", ",", "params", ",", "hparams", ")", "\n", "\n", "if", "not", "stochastic", ":", "\n", "        ", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "\n", "", "vs", "=", "[", "torch", ".", "zeros_like", "(", "w", ")", "for", "w", "in", "params", "]", "\n", "vs_vec", "=", "cat_list_to_tensor", "(", "vs", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "vs_prev_vec", "=", "vs_vec", "\n", "\n", "if", "stochastic", ":", "\n", "            ", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "vs", "=", "torch_grad", "(", "w_mapped", ",", "params", ",", "grad_outputs", "=", "vs", ",", "retain_graph", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "vs", "=", "torch_grad", "(", "w_mapped", ",", "params", ",", "grad_outputs", "=", "vs", ",", "retain_graph", "=", "True", ")", "\n", "\n", "", "vs", "=", "[", "v", "+", "gow", "for", "v", ",", "gow", "in", "zip", "(", "vs", ",", "grad_outer_w", ")", "]", "\n", "vs_vec", "=", "cat_list_to_tensor", "(", "vs", ")", "\n", "if", "float", "(", "torch", ".", "norm", "(", "vs_vec", "-", "vs_prev_vec", ")", ")", "<", "tol", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "stochastic", ":", "\n", "        ", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "\n", "", "grads", "=", "torch_grad", "(", "w_mapped", ",", "hparams", ",", "grad_outputs", "=", "vs", ",", "allow_unused", "=", "True", ")", "\n", "grads", "=", "[", "g", "+", "v", "if", "g", "is", "not", "None", "else", "v", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "grad_outer_hparams", ")", "]", "\n", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.CG": [[136, 188], ["outer_loss", "hypergradients.get_outer_gradients", "hypergrad.CG_torch.cg", "torch.autograd.grad", "w.detach().requires_grad_", "fp_map", "fp_map", "hypergradients.update_tensor_grads", "fp_map", "torch.autograd.grad", "torch.autograd.grad", "zip", "w.detach", "zip"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.CG_torch.cg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["", "def", "CG", "(", "params", ":", "List", "[", "Tensor", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "K", ":", "int", ",", "\n", "fp_map", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "tol", "=", "1e-10", ",", "\n", "set_grad", "=", "True", ",", "\n", "stochastic", "=", "False", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n     Computes the hypergradient by applying K steps of the conjugate gradient method (CG).\n     It can end earlier when tol is reached.\n\n     Args:\n         params: the output of the inner solver procedure.\n         hparams: the outer variables (or hyperparameters), each element needs requires_grad=True\n         K: the maximum number of conjugate gradient iterations\n         fp_map: the fixed point map which defines the inner problem\n         outer_loss: computes the outer objective taking parameters and hyperparameters as inputs\n         tol: end the method earlier when the norm of the residual is less than tol\n         set_grad: if True set t.grad to the hypergradient for every t in hparams\n         stochastic: set this to True when fp_map is not a deterministic function of its inputs\n\n     Returns:\n         the list of hypergradients for each element in hparams\n     \"\"\"", "\n", "params", "=", "[", "w", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "for", "w", "in", "params", "]", "\n", "o_loss", "=", "outer_loss", "(", "params", ",", "hparams", ")", "\n", "grad_outer_w", ",", "grad_outer_hparams", "=", "get_outer_gradients", "(", "o_loss", ",", "params", ",", "hparams", ")", "\n", "\n", "if", "not", "stochastic", ":", "\n", "        ", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "\n", "", "def", "dfp_map_dw", "(", "xs", ")", ":", "\n", "        ", "if", "stochastic", ":", "\n", "            ", "w_mapped_in", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "Jfp_mapTv", "=", "torch_grad", "(", "w_mapped_in", ",", "params", ",", "grad_outputs", "=", "xs", ",", "retain_graph", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "Jfp_mapTv", "=", "torch_grad", "(", "w_mapped", ",", "params", ",", "grad_outputs", "=", "xs", ",", "retain_graph", "=", "True", ")", "\n", "", "return", "[", "v", "-", "j", "for", "v", ",", "j", "in", "zip", "(", "xs", ",", "Jfp_mapTv", ")", "]", "\n", "\n", "", "vs", "=", "CG_torch", ".", "cg", "(", "dfp_map_dw", ",", "grad_outer_w", ",", "max_iter", "=", "K", ",", "epsilon", "=", "tol", ")", "# K steps of conjugate gradient", "\n", "\n", "if", "stochastic", ":", "\n", "        ", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "\n", "", "grads", "=", "torch_grad", "(", "w_mapped", ",", "hparams", ",", "grad_outputs", "=", "vs", ")", "\n", "grads", "=", "[", "g", "+", "v", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "grad_outer_hparams", ")", "]", "\n", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.CG_normaleq": [[190, 223], ["outer_loss", "hypergradients.get_outer_gradients", "fp_map", "hypergrad.CG_torch.cg", "torch.autograd.grad", "w.detach().requires_grad_", "torch.autograd.grad", "hypergradients.jvp", "hypergradients.update_tensor_grads", "zip", "zip", "w.detach", "zip", "fp_map", "zip", "hypergradients.jvp", "fp_map"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.CG_torch.cg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.jvp", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.jvp"], ["", "def", "CG_normaleq", "(", "params", ":", "List", "[", "Tensor", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "K", ":", "int", ",", "\n", "fp_map", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "tol", "=", "1e-10", ",", "\n", "set_grad", "=", "True", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\" Similar to CG but the conjugate gradient is applied on the normal equation (has a higher time complexity)\"\"\"", "\n", "params", "=", "[", "w", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "for", "w", "in", "params", "]", "\n", "o_loss", "=", "outer_loss", "(", "params", ",", "hparams", ")", "\n", "grad_outer_w", ",", "grad_outer_hparams", "=", "get_outer_gradients", "(", "o_loss", ",", "params", ",", "hparams", ")", "\n", "\n", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "\n", "def", "dfp_map_dw", "(", "xs", ")", ":", "\n", "        ", "Jfp_mapTv", "=", "torch_grad", "(", "w_mapped", ",", "params", ",", "grad_outputs", "=", "xs", ",", "retain_graph", "=", "True", ")", "\n", "v_minus_Jfp_mapTv", "=", "[", "v", "-", "j", "for", "v", ",", "j", "in", "zip", "(", "xs", ",", "Jfp_mapTv", ")", "]", "\n", "\n", "# normal equation part", "\n", "Jfp_mapv_minus_Jfp_mapJfp_mapTv", "=", "jvp", "(", "lambda", "_params", ":", "fp_map", "(", "_params", ",", "hparams", ")", ",", "params", ",", "v_minus_Jfp_mapTv", ")", "\n", "return", "[", "v", "-", "vv", "for", "v", ",", "vv", "in", "zip", "(", "v_minus_Jfp_mapTv", ",", "Jfp_mapv_minus_Jfp_mapJfp_mapTv", ")", "]", "\n", "\n", "", "v_minus_Jfp_mapv", "=", "[", "g", "-", "jfp_mapv", "for", "g", ",", "jfp_mapv", "in", "zip", "(", "grad_outer_w", ",", "jvp", "(", "\n", "lambda", "_params", ":", "fp_map", "(", "_params", ",", "hparams", ")", ",", "params", ",", "grad_outer_w", ")", ")", "]", "\n", "vs", "=", "CG_torch", ".", "cg", "(", "dfp_map_dw", ",", "v_minus_Jfp_mapv", ",", "max_iter", "=", "K", ",", "epsilon", "=", "tol", ")", "# K steps of conjugate gradient", "\n", "\n", "grads", "=", "torch_grad", "(", "w_mapped", ",", "hparams", ",", "grad_outputs", "=", "vs", ",", "allow_unused", "=", "True", ")", "\n", "grads", "=", "[", "g", "+", "v", "if", "g", "is", "not", "None", "else", "v", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "grad_outer_hparams", ")", "]", "\n", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.neumann": [[225, 255], ["outer_loss", "hypergradients.get_outer_gradients", "fp_map", "hypergradients.cat_list_to_tensor", "range", "torch.autograd.grad", "w.detach().requires_grad_", "torch.autograd.grad", "hypergradients.cat_list_to_tensor", "hypergradients.update_tensor_grads", "float", "zip", "w.detach", "zip", "torch.norm"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["", "def", "neumann", "(", "params", ":", "List", "[", "Tensor", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "K", ":", "int", ",", "\n", "fp_map", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "tol", "=", "1e-10", ",", "\n", "set_grad", "=", "True", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\" Saves one iteration from the fixed point method\"\"\"", "\n", "\n", "# from https://arxiv.org/pdf/1803.06396.pdf,  should return the same gradient of fixed point K+1", "\n", "params", "=", "[", "w", ".", "detach", "(", ")", ".", "requires_grad_", "(", "True", ")", "for", "w", "in", "params", "]", "\n", "o_loss", "=", "outer_loss", "(", "params", ",", "hparams", ")", "\n", "grad_outer_w", ",", "grad_outer_hparams", "=", "get_outer_gradients", "(", "o_loss", ",", "params", ",", "hparams", ")", "\n", "\n", "w_mapped", "=", "fp_map", "(", "params", ",", "hparams", ")", "\n", "vs", ",", "gs", "=", "grad_outer_w", ",", "grad_outer_w", "\n", "gs_vec", "=", "cat_list_to_tensor", "(", "gs", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "gs_prev_vec", "=", "gs_vec", "\n", "vs", "=", "torch_grad", "(", "w_mapped", ",", "params", ",", "grad_outputs", "=", "vs", ",", "retain_graph", "=", "True", ")", "\n", "gs", "=", "[", "g", "+", "v", "for", "g", ",", "v", "in", "zip", "(", "gs", ",", "vs", ")", "]", "\n", "gs_vec", "=", "cat_list_to_tensor", "(", "gs", ")", "\n", "if", "float", "(", "torch", ".", "norm", "(", "gs_vec", "-", "gs_prev_vec", ")", ")", "<", "tol", ":", "\n", "            ", "break", "\n", "\n", "", "", "grads", "=", "torch_grad", "(", "w_mapped", ",", "hparams", ",", "grad_outputs", "=", "gs", ")", "\n", "grads", "=", "[", "g", "+", "v", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "grad_outer_hparams", ")", "]", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.exact": [[257, 269], ["torch.autograd.grad", "outer_loss", "hypergradients.update_tensor_grads", "opt_params_f"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads"], ["", "def", "exact", "(", "opt_params_f", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", "]", ",", "List", "[", "Tensor", "]", "]", ",", "\n", "hparams", ":", "List", "[", "Tensor", "]", ",", "\n", "outer_loss", ":", "Callable", "[", "[", "List", "[", "Tensor", "]", ",", "List", "[", "Tensor", "]", "]", ",", "Tensor", "]", ",", "\n", "set_grad", "=", "True", ")", "->", "List", "[", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Computes the exact hypergradient using backpropagation and exploting the closed form torch differentiable function\n    that computes the optimal parameters given the hyperparameters (opt_params_f).\n    \"\"\"", "\n", "grads", "=", "torch_grad", "(", "outer_loss", "(", "opt_params_f", "(", "hparams", ")", ",", "hparams", ")", ",", "hparams", ")", "\n", "if", "set_grad", ":", "\n", "        ", "update_tensor_grads", "(", "hparams", ",", "grads", ")", "\n", "", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grd": [[273, 275], ["torch.autograd.grad"], "function", ["None"], ["", "def", "grd", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "torch", ".", "autograd", ".", "grad", "(", "a", ",", "b", ",", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.list_dot": [[277, 279], ["torch.stack().sum", "torch.stack", "zip"], "function", ["None"], ["", "def", "list_dot", "(", "l1", ",", "l2", ")", ":", "# extended dot product for lists", "\n", "    ", "return", "torch", ".", "stack", "(", "[", "(", "a", "*", "b", ")", ".", "sum", "(", ")", "for", "a", ",", "b", "in", "zip", "(", "l1", ",", "l2", ")", "]", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.jvp": [[281, 285], ["hypergradients.grd", "hypergradients.grd", "torch.ones_like().requires_grad_", "hypergradients.list_dot", "hypergradients.list_dot", "fp_map", "fp_map", "torch.ones_like"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grd", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grd", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.list_dot", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.list_dot"], ["", "def", "jvp", "(", "fp_map", ",", "params", ",", "vs", ")", ":", "\n", "    ", "dummy", "=", "[", "torch", ".", "ones_like", "(", "phw", ")", ".", "requires_grad_", "(", "True", ")", "for", "phw", "in", "fp_map", "(", "params", ")", "]", "\n", "g1", "=", "grd", "(", "list_dot", "(", "fp_map", "(", "params", ")", ",", "dummy", ")", ",", "params", ")", "\n", "return", "grd", "(", "list_dot", "(", "vs", ",", "g1", ")", ",", "dummy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.get_outer_gradients": [[287, 292], ["hypergradients.grad_unused_zero", "hypergradients.grad_unused_zero"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grad_unused_zero", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grad_unused_zero"], ["", "def", "get_outer_gradients", "(", "outer_loss", ",", "params", ",", "hparams", ",", "retain_graph", "=", "True", ")", ":", "\n", "    ", "grad_outer_w", "=", "grad_unused_zero", "(", "outer_loss", ",", "params", ",", "retain_graph", "=", "retain_graph", ")", "\n", "grad_outer_hparams", "=", "grad_unused_zero", "(", "outer_loss", ",", "hparams", ",", "retain_graph", "=", "retain_graph", ")", "\n", "\n", "return", "grad_outer_w", ",", "grad_outer_hparams", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.cat_list_to_tensor": [[294, 296], ["torch.cat", "xx.view"], "function", ["None"], ["", "def", "cat_list_to_tensor", "(", "list_tx", ")", ":", "\n", "    ", "return", "torch", ".", "cat", "(", "[", "xx", ".", "view", "(", "[", "-", "1", "]", ")", "for", "xx", "in", "list_tx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.update_tensor_grads": [[298, 304], ["zip", "torch.zeros_like"], "function", ["None"], ["", "def", "update_tensor_grads", "(", "hparams", ",", "grads", ")", ":", "\n", "    ", "for", "l", ",", "g", "in", "zip", "(", "hparams", ",", "grads", ")", ":", "\n", "        ", "if", "l", ".", "grad", "is", "None", ":", "\n", "            ", "l", ".", "grad", "=", "torch", ".", "zeros_like", "(", "l", ")", "\n", "", "if", "g", "is", "not", "None", ":", "\n", "            ", "l", ".", "grad", "+=", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.hypergradients.grad_unused_zero": [[306, 314], ["torch.autograd.grad", "tuple", "torch.zeros_like", "hypergradients.grad_unused_zero.grad_or_zeros"], "function", ["None"], ["", "", "", "def", "grad_unused_zero", "(", "output", ",", "inputs", ",", "grad_outputs", "=", "None", ",", "retain_graph", "=", "False", ",", "create_graph", "=", "False", ")", ":", "\n", "    ", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "output", ",", "inputs", ",", "grad_outputs", "=", "grad_outputs", ",", "allow_unused", "=", "True", ",", "\n", "retain_graph", "=", "retain_graph", ",", "create_graph", "=", "create_graph", ")", "\n", "\n", "def", "grad_or_zeros", "(", "grad", ",", "var", ")", ":", "\n", "        ", "return", "torch", ".", "zeros_like", "(", "var", ")", "if", "grad", "is", "None", "else", "grad", "\n", "\n", "", "return", "tuple", "(", "grad_or_zeros", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "zip", "(", "grads", ",", "inputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.CustomTensorIterator.__init__": [[19, 22], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "iter", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tensor_list", ",", "batch_size", ",", "**", "loader_kwargs", ")", ":", "\n", "        ", "self", ".", "loader", "=", "DataLoader", "(", "TensorDataset", "(", "*", "tensor_list", ")", ",", "batch_size", "=", "batch_size", ",", "**", "loader_kwargs", ")", "\n", "self", ".", "iterator", "=", "iter", "(", "self", ".", "loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.CustomTensorIterator.__next__": [[23, 30], ["next", "iter", "next"], "methods", ["None"], ["", "def", "__next__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "idx", "=", "next", "(", "self", ".", "iterator", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "self", ".", "iterator", "=", "iter", "(", "self", ".", "loader", ")", "\n", "idx", "=", "next", "(", "self", ".", "iterator", ")", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.parse_args": [[32, 71], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.isdir", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "50", ",", "type", "=", "int", ",", "help", "=", "'epoch numbers'", ")", "\n", "parser", ".", "add_argument", "(", "'--T'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "'inner update iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--val_size'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--eta'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'used in Hessian'", ")", "\n", "parser", ".", "add_argument", "(", "'--hessian_q'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'number of steps to approximate hessian'", ")", "\n", "# Only when alg == minibatch, we apply stochastic, otherwise, alg training with full batch", "\n", "parser", ".", "add_argument", "(", "'--alg'", ",", "type", "=", "str", ",", "default", "=", "'reverse'", ",", "choices", "=", "[", "'stocBiO'", ",", "'reverse'", ",", "'AID-FP'", ",", "'AID-CG'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--training_size'", ",", "type", "=", "int", ",", "default", "=", "2000", ")", "\n", "parser", ".", "add_argument", "(", "'--inner_lr'", ",", "type", "=", "float", ",", "default", "=", "100.0", ")", "\n", "parser", ".", "add_argument", "(", "'--inner_mu'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--outer_lr'", ",", "type", "=", "float", ",", "default", "=", "100.0", ")", "\n", "parser", ".", "add_argument", "(", "'--outer_mu'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--save_folder'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'path to save result'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'Experiment name'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "# outer_lr, outer_mu = 100.0, 0.0  # nice with 100.0, 0.0 (torch.SGD) tested with T, K = 5, 10 and CG", "\n", "# inner_lr, inner_mu = 100., 0.9   # nice with 100., 0.9 (HeavyBall) tested with T, K = 5, 10 and CG", "\n", "# parser.add_argument('--seed', type=int, default=0)", "\n", "\n", "if", "args", ".", "alg", "==", "'stocBiO'", ":", "\n", "        ", "args", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "", "else", ":", "\n", "        ", "args", ".", "batch_size", "=", "args", ".", "training_size", "\n", "args", ".", "val_size", "=", "args", ".", "training_size", "\n", "\n", "", "if", "not", "args", ".", "save_folder", ":", "\n", "        ", "args", ".", "save_folder", "=", "'./save_results'", "\n", "", "args", ".", "model_name", "=", "'{}_bs_{}_vbs_{}_olrmu_{}_{}_ilrmu_{}_{}_eta_{}_T_{}_hessianq_{}'", ".", "format", "(", "args", ".", "alg", ",", "\n", "args", ".", "batch_size", ",", "args", ".", "val_size", ",", "args", ".", "outer_lr", ",", "args", ".", "outer_mu", ",", "args", ".", "inner_lr", ",", "\n", "args", ".", "inner_mu", ",", "args", ".", "eta", ",", "args", ".", "T", ",", "args", ".", "hessian_q", ")", "\n", "args", ".", "save_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_folder", ",", "args", ".", "model_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "save_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_folder", ")", "\n", "# parser.add_argument('--save_folder', type=str, default='', help='path to save result')", "\n", "# parser.add_argument('--model_name', type=str, default='', help='Experiment name')", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.train_model": [[73, 309], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "sklearn.datasets.fetch_20newsgroups_vectorized", "sklearn.datasets.fetch_20newsgroups_vectorized", "sklearn.model_selection.train_test_split", "print", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "hypergrad.GradientDescent", "numpy.zeros", "l2reg_on_twentynews.train_model.eval"], "function", ["None"], ["", "def", "train_model", "(", "args", ")", ":", "\n", "\n", "# Constant", "\n", "    ", "tol", "=", "1e-12", "\n", "warm_start", "=", "True", "\n", "bias", "=", "False", "# without bias outer_lr can be bigger (much faster convergence)", "\n", "train_log_interval", "=", "100", "\n", "val_log_interval", "=", "1", "\n", "\n", "# Basic Setting ", "\n", "seed", "=", "0", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "cuda", "=", "True", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "default_tensor_str", "=", "'torch.cuda.FloatTensor'", "if", "cuda", "else", "'torch.FloatTensor'", "\n", "kwargs", "=", "{", "'num_workers'", ":", "1", ",", "'pin_memory'", ":", "True", "}", "if", "cuda", "else", "{", "}", "\n", "torch", ".", "set_default_tensor_type", "(", "default_tensor_str", ")", "\n", "#torch.multiprocessing.set_start_method('forkserver')", "\n", "\n", "# Functions ", "\n", "def", "frnp", "(", "x", ")", ":", "return", "torch", ".", "from_numpy", "(", "x", ")", ".", "cuda", "(", ")", ".", "float", "(", ")", "if", "cuda", "else", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", "\n", "def", "tonp", "(", "x", ",", "cuda", "=", "cuda", ")", ":", "return", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "if", "cuda", "else", "x", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "def", "train_loss", "(", "params", ",", "hparams", ",", "data", ")", ":", "\n", "        ", "x_mb", ",", "y_mb", "=", "data", "\n", "# print(x_mb.size()) = torch.Size([5657, 130107])", "\n", "out", "=", "out_f", "(", "x_mb", ",", "params", ")", "\n", "return", "F", ".", "cross_entropy", "(", "out", ",", "y_mb", ")", "+", "reg_f", "(", "params", ",", "*", "hparams", ")", "\n", "", "def", "val_loss", "(", "opt_params", ",", "hparams", ")", ":", "\n", "        ", "x_mb", ",", "y_mb", "=", "next", "(", "val_iterator", ")", "\n", "# print(x_mb.size()) = torch.Size([5657, 130107])", "\n", "out", "=", "out_f", "(", "x_mb", ",", "opt_params", "[", ":", "len", "(", "parameters", ")", "]", ")", "\n", "val_loss", "=", "F", ".", "cross_entropy", "(", "out", ",", "y_mb", ")", "\n", "pred", "=", "out", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "acc", "=", "pred", ".", "eq", "(", "y_mb", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "y_mb", ")", "\n", "\n", "val_losses", ".", "append", "(", "tonp", "(", "val_loss", ")", ")", "\n", "val_accs", ".", "append", "(", "acc", ")", "\n", "return", "val_loss", "\n", "", "def", "reg_f", "(", "params", ",", "l2_reg_params", ",", "l1_reg_params", "=", "None", ")", ":", "\n", "        ", "r", "=", "0.5", "*", "(", "(", "params", "[", "0", "]", "**", "2", ")", "*", "torch", ".", "exp", "(", "l2_reg_params", ".", "unsqueeze", "(", "1", ")", "*", "ones_dxc", ")", ")", ".", "mean", "(", ")", "\n", "if", "l1_reg_params", "is", "not", "None", ":", "\n", "            ", "r", "+=", "(", "params", "[", "0", "]", ".", "abs", "(", ")", "*", "torch", ".", "exp", "(", "l1_reg_params", ".", "unsqueeze", "(", "1", ")", "*", "ones_dxc", ")", ")", ".", "mean", "(", ")", "\n", "", "return", "r", "\n", "", "def", "out_f", "(", "x", ",", "params", ")", ":", "\n", "        ", "out", "=", "x", "@", "params", "[", "0", "]", "\n", "out", "+=", "params", "[", "1", "]", "if", "len", "(", "params", ")", "==", "2", "else", "0", "\n", "return", "out", "\n", "", "def", "eval", "(", "params", ",", "x", ",", "y", ")", ":", "\n", "        ", "out", "=", "out_f", "(", "x", ",", "params", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "out", ",", "y", ")", "\n", "pred", "=", "out", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "acc", "=", "pred", ".", "eq", "(", "y", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "y", ")", "\n", "\n", "return", "loss", ",", "acc", "\n", "\n", "\n", "# load twentynews and preprocess", "\n", "", "val_size_ratio", "=", "0.5", "\n", "X", ",", "y", "=", "fetch_20newsgroups_vectorized", "(", "subset", "=", "'train'", ",", "return_X_y", "=", "True", ",", "\n", "#remove=('headers', 'footers', 'quotes')", "\n", ")", "\n", "x_test", ",", "y_test", "=", "fetch_20newsgroups_vectorized", "(", "subset", "=", "'test'", ",", "return_X_y", "=", "True", ",", "\n", "#remove=('headers', 'footers', 'quotes')", "\n", ")", "\n", "x_train", ",", "x_val", ",", "y_train", ",", "y_val", "=", "train_test_split", "(", "X", ",", "y", ",", "stratify", "=", "y", ",", "test_size", "=", "val_size_ratio", ")", "\n", "train_samples", ",", "n_features", "=", "x_train", ".", "shape", "\n", "test_samples", ",", "n_features", "=", "x_test", ".", "shape", "\n", "val_samples", ",", "n_features", "=", "x_val", ".", "shape", "\n", "n_classes", "=", "np", ".", "unique", "(", "y_train", ")", ".", "shape", "[", "0", "]", "\n", "# train_samples=5657, val_samples=5657, test_samples=7532, n_features=130107, n_classes=20", "\n", "print", "(", "'Dataset 20newsgroup, train_samples=%i, val_samples=%i, test_samples=%i, n_features=%i, n_classes=%i'", "\n", "%", "(", "train_samples", ",", "val_samples", ",", "test_samples", ",", "n_features", ",", "n_classes", ")", ")", "\n", "ys", "=", "[", "frnp", "(", "y_train", ")", ".", "long", "(", ")", ",", "frnp", "(", "y_val", ")", ".", "long", "(", ")", ",", "frnp", "(", "y_test", ")", ".", "long", "(", ")", "]", "\n", "xs", "=", "[", "x_train", ",", "x_val", ",", "x_test", "]", "\n", "\n", "if", "cuda", ":", "\n", "        ", "xs", "=", "[", "from_sparse", "(", "x", ")", ".", "cuda", "(", ")", "for", "x", "in", "xs", "]", "\n", "", "else", ":", "\n", "        ", "xs", "=", "[", "from_sparse", "(", "x", ")", "for", "x", "in", "xs", "]", "\n", "\n", "# x_train.size() = torch.Size([5657, 130107])", "\n", "# y_train.size() = torch.Size([5657])", "\n", "", "x_train", ",", "x_val", ",", "x_test", "=", "xs", "\n", "y_train", ",", "y_val", ",", "y_test", "=", "ys", "\n", "\n", "# torch.DataLoader has problems with sparse tensor on GPU    ", "\n", "iterators", ",", "train_list", ",", "val_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "xmb_train", ",", "xmb_val", ",", "ymb_train", ",", "ymb_val", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "# For minibatch method, we build the list to store the splited tensor", "\n", "if", "args", ".", "alg", "==", "'stocBiO'", ":", "\n", "        ", "for", "bs", ",", "x", ",", "y", "in", "[", "(", "len", "(", "y_train", ")", ",", "x_train", ",", "y_train", ")", ",", "(", "len", "(", "y_val", ")", ",", "x_val", ",", "y_val", ")", "]", ":", "\n", "            ", "iterators", ".", "append", "(", "CustomTensorIterator", "(", "[", "x", ",", "y", "]", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", ")", "\n", "", "train_iterator", ",", "val_iterator", "=", "iterators", "\n", "for", "_", "in", "range", "(", "train_samples", "//", "args", ".", "batch_size", "+", "1", ")", ":", "\n", "            ", "data_temp", "=", "next", "(", "train_iterator", ")", "\n", "x_mb", ",", "y_mb", "=", "data_temp", "\n", "xmb_train", ".", "append", "(", "x_mb", ")", "\n", "ymb_train", ".", "append", "(", "y_mb", ")", "\n", "# train_list.append(next(train_iterator))", "\n", "", "for", "_", "in", "range", "(", "val_samples", "//", "args", ".", "val_size", "+", "1", ")", ":", "\n", "            ", "data_temp", "=", "next", "(", "val_iterator", ")", "\n", "x_mb", ",", "y_mb", "=", "data_temp", "\n", "xmb_val", ".", "append", "(", "x_mb", ")", "\n", "ymb_val", ".", "append", "(", "y_mb", ")", "\n", "# val_list.append(next(val_iterator))", "\n", "", "train_list", ",", "val_list", "=", "[", "xmb_train", ",", "ymb_train", "]", ",", "[", "xmb_val", ",", "ymb_val", "]", "\n", "train_list_len", ",", "val_list_len", "=", "len", "(", "ymb_train", ")", ",", "len", "(", "ymb_val", ")", "\n", "\n", "# set up another train_iterator & val_iterator to make sure train_list and val_list are full", "\n", "iterators", "=", "[", "]", "\n", "for", "bs", ",", "x", ",", "y", "in", "[", "(", "len", "(", "y_train", ")", ",", "x_train", ",", "y_train", ")", ",", "(", "len", "(", "y_val", ")", ",", "x_val", ",", "y_val", ")", "]", ":", "\n", "            ", "iterators", ".", "append", "(", "repeat", "(", "[", "x", ",", "y", "]", ")", ")", "\n", "", "train_iterator", ",", "val_iterator", "=", "iterators", "\n", "", "else", ":", "\n", "        ", "for", "bs", ",", "x", ",", "y", "in", "[", "(", "len", "(", "y_train", ")", ",", "x_train", ",", "y_train", ")", ",", "(", "len", "(", "y_val", ")", ",", "x_val", ",", "y_val", ")", "]", ":", "\n", "            ", "iterators", ".", "append", "(", "repeat", "(", "[", "x", ",", "y", "]", ")", ")", "\n", "", "train_iterator", ",", "val_iterator", "=", "iterators", "\n", "\n", "\n", "# Initialize parameters", "\n", "", "l2_reg_params", "=", "torch", ".", "zeros", "(", "n_features", ")", ".", "requires_grad_", "(", "True", ")", "# one hp per feature", "\n", "l1_reg_params", "=", "(", "0.", "*", "torch", ".", "ones", "(", "1", ")", ")", ".", "requires_grad_", "(", "True", ")", "# one l1 hp only (best when really low)", "\n", "#l2_reg_params = (-20.*torch.ones(1)).requires_grad_(True)  # one l2 hp only (best when really low)", "\n", "#l1_reg_params = (-1.*torch.ones(n_features)).requires_grad_(True)", "\n", "hparams", "=", "[", "l2_reg_params", "]", "\n", "# hparams: the outer variables (or hyperparameters)", "\n", "ones_dxc", "=", "torch", ".", "ones", "(", "n_features", ",", "n_classes", ")", "\n", "\n", "outer_opt", "=", "torch", ".", "optim", ".", "SGD", "(", "lr", "=", "args", ".", "outer_lr", ",", "momentum", "=", "args", ".", "outer_mu", ",", "params", "=", "hparams", ")", "\n", "# outer_opt = torch.optim.Adam(lr=0.01, params=hparams)", "\n", "\n", "params_history", "=", "[", "]", "\n", "val_losses", ",", "val_accs", "=", "[", "]", ",", "[", "]", "\n", "test_losses", ",", "test_accs", "=", "[", "]", ",", "[", "]", "\n", "w", "=", "torch", ".", "zeros", "(", "n_features", ",", "n_classes", ")", ".", "requires_grad_", "(", "True", ")", "\n", "parameters", "=", "[", "w", "]", "\n", "\n", "# params_history: the inner iterates (from first to last)", "\n", "if", "bias", ":", "\n", "        ", "b", "=", "torch", ".", "zeros", "(", "n_classes", ")", ".", "requires_grad_", "(", "True", ")", "\n", "parameters", ".", "append", "(", "b", ")", "\n", "\n", "", "if", "args", ".", "inner_mu", ">", "0", ":", "\n", "#inner_opt = hg.Momentum(train_loss, inner_lr, inner_mu, data_or_iter=train_iterator)", "\n", "        ", "inner_opt", "=", "hg", ".", "HeavyBall", "(", "train_loss", ",", "args", ".", "inner_lr", ",", "args", ".", "inner_mu", ",", "data_or_iter", "=", "train_iterator", ")", "\n", "", "else", ":", "\n", "        ", "inner_opt", "=", "hg", ".", "GradientDescent", "(", "train_loss", ",", "args", ".", "inner_lr", ",", "data_or_iter", "=", "train_iterator", ")", "\n", "", "inner_opt_cg", "=", "hg", ".", "GradientDescent", "(", "train_loss", ",", "1.", ",", "data_or_iter", "=", "train_iterator", ")", "\n", "\n", "total_time", "=", "0", "\n", "loss_acc_time_results", "=", "np", ".", "zeros", "(", "(", "args", ".", "epochs", "+", "1", ",", "3", ")", ")", "\n", "test_loss", ",", "test_acc", "=", "eval", "(", "parameters", ",", "x_test", ",", "y_test", ")", "\n", "loss_acc_time_results", "[", "0", ",", "0", "]", "=", "test_loss", "\n", "loss_acc_time_results", "[", "0", ",", "1", "]", "=", "test_acc", "\n", "loss_acc_time_results", "[", "0", ",", "2", "]", "=", "0.0", "\n", "\n", "for", "o_step", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "alg", "==", "'stocBiO'", ":", "\n", "# train_index_list = torch.randperm(train_list_len)", "\n", "# val_index = torch.randperm(val_list_len)", "\n", "            ", "inner_losses", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "args", ".", "T", ")", ":", "\n", "# loss_train = train_loss(parameters, hparams, train_list[train_index_list[t%train_list_len]])", "\n", "                ", "loss_train", "=", "train_loss", "(", "parameters", ",", "hparams", ",", "[", "xmb_train", "[", "t", "%", "train_list_len", "]", ",", "ymb_train", "[", "t", "%", "train_list_len", "]", "]", ")", "\n", "inner_grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_train", ",", "parameters", ")", "\n", "parameters", "[", "0", "]", "=", "parameters", "[", "0", "]", "-", "args", ".", "inner_lr", "*", "inner_grad", "[", "0", "]", "\n", "inner_losses", ".", "append", "(", "loss_train", ")", "\n", "\n", "if", "t", "%", "train_log_interval", "==", "0", "or", "t", "==", "args", ".", "T", "-", "1", ":", "\n", "                    ", "print", "(", "'t={} loss: {}'", ".", "format", "(", "t", ",", "inner_losses", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "", "outer_update", "=", "stocbio", "(", "parameters", ",", "hparams", ",", "val_list", ",", "args", ",", "out_f", ",", "reg_fs", ")", "\n", "\n", "hparams", "[", "0", "]", "=", "hparams", "[", "0", "]", "-", "args", ".", "outer_lr", "*", "outer_update", "\n", "final_params", "=", "parameters", "\n", "for", "p", ",", "new_p", "in", "zip", "(", "parameters", ",", "final_params", "[", ":", "len", "(", "parameters", ")", "]", ")", ":", "\n", "                ", "if", "warm_start", ":", "\n", "                    ", "p", ".", "data", "=", "new_p", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "", "", "val_loss", "(", "final_params", ",", "hparams", ")", "\n", "\n", "", "else", ":", "\n", "            ", "inner_losses", "=", "[", "]", "\n", "if", "params_history", ":", "\n", "                ", "params_history", "=", "[", "params_history", "[", "-", "1", "]", "]", "\n", "", "else", ":", "\n", "                ", "params_history", "=", "[", "inner_opt", ".", "get_opt_params", "(", "parameters", ")", "]", "\n", "", "for", "t", "in", "range", "(", "args", ".", "T", ")", ":", "\n", "                ", "params_history", ".", "append", "(", "inner_opt", "(", "params_history", "[", "-", "1", "]", ",", "hparams", ",", "create_graph", "=", "False", ")", ")", "\n", "inner_losses", ".", "append", "(", "inner_opt", ".", "curr_loss", ")", "\n", "\n", "if", "t", "%", "train_log_interval", "==", "0", "or", "t", "==", "args", ".", "T", "-", "1", ":", "\n", "                    ", "print", "(", "'t={} loss: {}'", ".", "format", "(", "t", ",", "inner_losses", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "", "final_params", "=", "params_history", "[", "-", "1", "]", "\n", "outer_opt", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "alg", "==", "'reverse'", ":", "\n", "                ", "hg", ".", "reverse", "(", "params_history", "[", "-", "args", ".", "hessian_q", "-", "1", ":", "]", ",", "hparams", ",", "[", "inner_opt", "]", "*", "args", ".", "hessian_q", ",", "val_loss", ")", "\n", "", "elif", "args", ".", "alg", "==", "'AID-FP'", ":", "\n", "                ", "hg", ".", "fixed_point", "(", "final_params", ",", "hparams", ",", "args", ".", "hessian_q", ",", "inner_opt", ",", "val_loss", ",", "stochastic", "=", "False", ",", "tol", "=", "tol", ")", "\n", "# elif args.alg == 'neuman':", "\n", "#     hg.neumann(final_params, hparams, args.K, inner_opt, val_loss, tol=tol)", "\n", "", "elif", "args", ".", "alg", "==", "'AID-CG'", ":", "\n", "                ", "hg", ".", "CG", "(", "final_params", "[", ":", "len", "(", "parameters", ")", "]", ",", "hparams", ",", "args", ".", "hessian_q", ",", "inner_opt_cg", ",", "val_loss", ",", "stochastic", "=", "False", ",", "tol", "=", "tol", ")", "\n", "", "outer_opt", ".", "step", "(", ")", "\n", "\n", "for", "p", ",", "new_p", "in", "zip", "(", "parameters", ",", "final_params", "[", ":", "len", "(", "parameters", ")", "]", ")", ":", "\n", "                ", "if", "warm_start", ":", "\n", "                    ", "p", ".", "data", "=", "new_p", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", "=", "torch", ".", "zeros_like", "(", "p", ")", "\n", "\n", "", "", "", "iter_time", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "total_time", "+=", "iter_time", "\n", "if", "o_step", "%", "val_log_interval", "==", "0", "or", "o_step", "==", "args", ".", "T", "-", "1", ":", "\n", "            ", "test_loss", ",", "test_acc", "=", "eval", "(", "final_params", "[", ":", "len", "(", "parameters", ")", "]", ",", "x_test", ",", "y_test", ")", "\n", "loss_acc_time_results", "[", "o_step", "+", "1", ",", "0", "]", "=", "test_loss", "\n", "loss_acc_time_results", "[", "o_step", "+", "1", ",", "1", "]", "=", "test_acc", "\n", "loss_acc_time_results", "[", "o_step", "+", "1", ",", "2", "]", "=", "total_time", "\n", "print", "(", "'o_step={} ({:.2e}s) Val loss: {:.4e}, Val Acc: {:.2f}%'", ".", "format", "(", "o_step", ",", "iter_time", ",", "val_losses", "[", "-", "1", "]", ",", "\n", "100", "*", "val_accs", "[", "-", "1", "]", ")", ")", "\n", "print", "(", "'          Test loss: {:.4e}, Test Acc: {:.2f}%'", ".", "format", "(", "test_loss", ",", "100", "*", "test_acc", ")", ")", "\n", "print", "(", "'          l2_hp norm: {:.4e}'", ".", "format", "(", "torch", ".", "norm", "(", "hparams", "[", "0", "]", ")", ")", ")", "\n", "if", "len", "(", "hparams", ")", "==", "2", ":", "\n", "                ", "print", "(", "'          l1_hp : '", ",", "torch", ".", "norm", "(", "hparams", "[", "1", "]", ")", ")", "\n", "\n", "", "", "", "file_name", "=", "'results.npy'", "\n", "file_addr", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_folder", ",", "file_name", ")", "\n", "with", "open", "(", "file_addr", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "np", ".", "save", "(", "f", ",", "loss_acc_time_results", ")", "\n", "\n", "", "print", "(", "loss_acc_time_results", ")", "\n", "print", "(", "'HPO ended in {:.2e} seconds\\n'", ".", "format", "(", "total_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.from_sparse": [[311, 321], ["x.tocoo.tocoo", "numpy.vstack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.sparse.FloatTensor", "torch.Size", "torch.Size", "torch.Size", "torch.Size"], "function", ["None"], ["", "def", "from_sparse", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "tocoo", "(", ")", "\n", "values", "=", "x", ".", "data", "\n", "indices", "=", "np", ".", "vstack", "(", "(", "x", ".", "row", ",", "x", ".", "col", ")", ")", "\n", "\n", "i", "=", "torch", ".", "LongTensor", "(", "indices", ")", "\n", "v", "=", "torch", ".", "FloatTensor", "(", "values", ")", "\n", "shape", "=", "x", ".", "shape", "\n", "\n", "return", "torch", ".", "sparse", ".", "FloatTensor", "(", "i", ",", "v", ",", "torch", ".", "Size", "(", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.train_loss": [[323, 327], ["l2reg_on_twentynews.out_f", "torch.cross_entropy", "l2reg_on_twentynews.reg_f"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.reg_f"], ["", "def", "train_loss", "(", "params", ",", "hparams", ",", "data", ")", ":", "\n", "    ", "x_mb", ",", "y_mb", "=", "data", "\n", "out", "=", "out_f", "(", "x_mb", ",", "params", ")", "\n", "return", "F", ".", "cross_entropy", "(", "out", ",", "y_mb", ")", "+", "reg_f", "(", "params", ",", "*", "hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.val_loss": [[328, 338], ["next", "l2reg_on_twentynews.out_f", "torch.cross_entropy", "out_f.argmax", "val_losses.append", "val_accs.append", "out.argmax.eq().sum().item", "len", "l2reg_on_twentynews.train_model.tonp", "len", "out.argmax.eq().sum", "out.argmax.eq", "y_mb.view_as"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f"], ["", "def", "val_loss", "(", "opt_params", ",", "hparams", ")", ":", "\n", "    ", "x_mb", ",", "y_mb", "=", "next", "(", "val_iterator", ")", "\n", "out", "=", "out_f", "(", "x_mb", ",", "opt_params", "[", ":", "len", "(", "parameters", ")", "]", ")", "\n", "val_loss", "=", "F", ".", "cross_entropy", "(", "out", ",", "y_mb", ")", "\n", "pred", "=", "out", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "acc", "=", "pred", ".", "eq", "(", "y_mb", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "len", "(", "y_mb", ")", "\n", "\n", "val_losses", ".", "append", "(", "tonp", "(", "val_loss", ")", ")", "\n", "val_accs", ".", "append", "(", "acc", ")", "\n", "return", "val_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.reg_f": [[339, 345], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "params[].size", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "params[].abs", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "l2_reg_params.unsqueeze", "l1_reg_params.unsqueeze"], "function", ["None"], ["", "def", "reg_f", "(", "params", ",", "l2_reg_params", ",", "l1_reg_params", "=", "None", ")", ":", "\n", "    ", "ones_dxc", "=", "torch", ".", "ones", "(", "params", "[", "0", "]", ".", "size", "(", ")", ")", "\n", "r", "=", "0.5", "*", "(", "(", "params", "[", "0", "]", "**", "2", ")", "*", "torch", ".", "exp", "(", "l2_reg_params", ".", "unsqueeze", "(", "1", ")", "*", "ones_dxc", ")", ")", ".", "mean", "(", ")", "\n", "if", "l1_reg_params", "is", "not", "None", ":", "\n", "        ", "r", "+=", "(", "params", "[", "0", "]", ".", "abs", "(", ")", "*", "torch", ".", "exp", "(", "l1_reg_params", ".", "unsqueeze", "(", "1", ")", "*", "ones_dxc", ")", ")", ".", "mean", "(", ")", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.reg_fs": [[346, 349], ["l2reg_on_twentynews.reg_f"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.reg_f"], ["", "def", "reg_fs", "(", "params", ",", "hparams", ",", "loss", ")", ":", "\n", "    ", "reg", "=", "reg_f", "(", "params", ",", "*", "hparams", ")", "\n", "return", "loss", "+", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f": [[350, 354], ["len"], "function", ["None"], ["", "def", "out_f", "(", "x", ",", "params", ")", ":", "\n", "    ", "out", "=", "x", "@", "params", "[", "0", "]", "\n", "out", "+=", "params", "[", "1", "]", "if", "len", "(", "params", ")", "==", "2", "else", "0", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.main": [[356, 360], ["l2reg_on_twentynews.parse_args", "print", "l2reg_on_twentynews.train_model"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.parse_args", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.train_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "train_model", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.stocbio": [[6, 35], ["out_f", "stocBiO.gradient_fy", "torch.unsqueeze().detach", "out_f", "stocBiO.gradient_gy", "range", "out_f", "stocBiO.gradient_gy", "torch.reshape", "torch.reshape", "torch.matmul", "torch.unsqueeze().detach", "z_list.append", "torch.sum", "torch.autograd.grad", "torch.unsqueeze", "torch.reshape", "torch.autograd.grad", "torch.stack", "torch.matmul", "torch.reshape", "torch.unsqueeze", "v_Q.detach", "torch.reshape"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.gradient_fy", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.gradient_gy", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.gradient_gy"], ["def", "stocbio", "(", "params", ",", "hparams", ",", "val_data_list", ",", "args", ",", "out_f", ",", "reg_f", ")", ":", "\n", "        ", "data_list", ",", "labels_list", "=", "val_data_list", "\n", "# Fy_gradient", "\n", "output", "=", "out_f", "(", "data_list", "[", "0", "]", ",", "params", ")", "\n", "Fy_gradient", "=", "gradient_fy", "(", "args", ",", "labels_list", "[", "0", "]", ",", "params", ",", "data_list", "[", "0", "]", ",", "output", ")", "\n", "v_0", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "reshape", "(", "Fy_gradient", ",", "[", "-", "1", "]", ")", ",", "1", ")", ".", "detach", "(", ")", "\n", "\n", "# Hessian", "\n", "z_list", "=", "[", "]", "\n", "output", "=", "out_f", "(", "data_list", "[", "1", "]", ",", "params", ")", "\n", "Gy_gradient", "=", "gradient_gy", "(", "args", ",", "labels_list", "[", "1", "]", ",", "params", ",", "data_list", "[", "1", "]", ",", "hparams", ",", "output", ",", "reg_f", ")", "\n", "\n", "G_gradient", "=", "torch", ".", "reshape", "(", "params", "[", "0", "]", ",", "[", "-", "1", "]", ")", "-", "args", ".", "eta", "*", "torch", ".", "reshape", "(", "Gy_gradient", ",", "[", "-", "1", "]", ")", "\n", "\n", "for", "_", "in", "range", "(", "args", ".", "hessian_q", ")", ":", "\n", "            ", "Jacobian", "=", "torch", ".", "matmul", "(", "G_gradient", ",", "v_0", ")", "\n", "v_new", "=", "torch", ".", "autograd", ".", "grad", "(", "Jacobian", ",", "params", ",", "retain_graph", "=", "True", ")", "[", "0", "]", "\n", "v_0", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "reshape", "(", "v_new", ",", "[", "-", "1", "]", ")", ",", "1", ")", ".", "detach", "(", ")", "\n", "z_list", ".", "append", "(", "v_0", ")", "\n", "", "v_Q", "=", "args", ".", "eta", "*", "v_0", "+", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "z_list", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# Gyx_gradient", "\n", "output", "=", "out_f", "(", "data_list", "[", "2", "]", ",", "params", ")", "\n", "Gy_gradient", "=", "gradient_gy", "(", "args", ",", "labels_list", "[", "2", "]", ",", "params", ",", "data_list", "[", "2", "]", ",", "hparams", ",", "output", ",", "reg_f", ")", "\n", "Gy_gradient", "=", "torch", ".", "reshape", "(", "Gy_gradient", ",", "[", "-", "1", "]", ")", "\n", "Gyx_gradient", "=", "torch", ".", "autograd", ".", "grad", "(", "torch", ".", "matmul", "(", "Gy_gradient", ",", "v_Q", ".", "detach", "(", ")", ")", ",", "hparams", ",", "retain_graph", "=", "True", ")", "[", "0", "]", "\n", "outer_update", "=", "-", "Gyx_gradient", "\n", "\n", "return", "outer_update", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.gradient_fy": [[36, 40], ["torch.nn.functional.cross_entropy", "torch.autograd.grad"], "function", ["None"], ["", "def", "gradient_fy", "(", "args", ",", "labels", ",", "params", ",", "data", ",", "output", ")", ":", "\n", "    ", "loss", "=", "F", ".", "cross_entropy", "(", "output", ",", "labels", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "params", ")", "[", "0", "]", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.gradient_gy": [[41, 49], ["torch.nn.functional.cross_entropy", "reg_f", "torch.autograd.grad"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.reg_f"], ["", "def", "gradient_gy", "(", "args", ",", "labels_cp", ",", "params", ",", "data", ",", "hparams", ",", "output", ",", "reg_f", ")", ":", "\n", "# For MNIST data-hyper cleaning experiments", "\n", "    ", "loss", "=", "F", ".", "cross_entropy", "(", "output", ",", "labels_cp", ",", "reduction", "=", "'none'", ")", "\n", "# For NewsGroup l2reg expriments", "\n", "# loss = F.cross_entropy(output, labels_cp)", "\n", "loss_regu", "=", "reg_f", "(", "params", ",", "hparams", ",", "loss", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_regu", ",", "params", ",", "create_graph", "=", "True", ")", "[", "0", "]", "\n", "return", "grad", "\n", "", ""]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.parse_args": [[16, 57], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.path.isdir", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--num_classes'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--test_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'K'", ")", "\n", "parser", ".", "add_argument", "(", "'--iterations'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'T'", ")", "\n", "parser", ".", "add_argument", "(", "'--outer_lr'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'beta'", ")", "\n", "parser", ".", "add_argument", "(", "'--inner_lr'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'alpha'", ")", "\n", "parser", ".", "add_argument", "(", "'--eta'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'used in Hessian'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'data/'", ",", "help", "=", "'The temporary data storage path'", ")", "\n", "parser", ".", "add_argument", "(", "'--training_size'", ",", "type", "=", "int", ",", "default", "=", "20000", ")", "\n", "parser", ".", "add_argument", "(", "'--validation_size'", ",", "type", "=", "int", ",", "default", "=", "5000", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_rate'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'--hessian_q'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--save_folder'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'path to save result'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'Experiment name'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--alg'", ",", "type", "=", "str", ",", "default", "=", "'stocBiO'", ",", "choices", "=", "[", "'stocBiO'", ",", "'HOAG'", ",", "'TTSA'", ",", "'BSA'", ",", "\n", "'reverse'", ",", "'AID-CG'", ",", "'AID-FP'", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "alg", "==", "'stocBiO'", ":", "\n", "        ", "args", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "", "elif", "args", ".", "alg", "==", "'BSA'", ":", "\n", "        ", "args", ".", "batch_size", "=", "1", "\n", "", "elif", "args", ".", "alg", "==", "'TTSA'", ":", "\n", "        ", "args", ".", "batch_size", "=", "1", "\n", "args", ".", "iterations", "=", "1", "\n", "", "else", ":", "\n", "        ", "args", ".", "batch_size", "=", "args", ".", "training_size", "\n", "\n", "", "if", "not", "args", ".", "save_folder", ":", "\n", "        ", "args", ".", "save_folder", "=", "'./save_tb_results'", "\n", "", "args", ".", "model_name", "=", "'{}_{}_bs_{}_olr_{}_ilr_{}_eta_{}_noiser_{}_q_{}_ite_{}'", ".", "format", "(", "args", ".", "alg", ",", "\n", "args", ".", "training_size", ",", "args", ".", "batch_size", ",", "args", ".", "outer_lr", ",", "args", ".", "inner_lr", ",", "args", ".", "eta", ",", "\n", "args", ".", "noise_rate", ",", "args", ".", "hessian_q", ",", "args", ".", "iterations", ")", "\n", "args", ".", "save_folder", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_folder", ",", "args", ".", "model_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "save_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save_folder", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.get_data_loaders": [[59, 75], ["torchvision.datasets.MNIST", "torch.utils.data.sampler.SequentialSampler", "torch.utils.data.sampler.SequentialSampler", "torch.utils.data.sampler.SequentialSampler", "torch.utils.data.sampler.SequentialSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torchvision.Compose", "torchvision.Compose", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.ToTensor", "torchvision.Normalize"], "function", ["None"], ["", "def", "get_data_loaders", "(", "args", ")", ":", "\n", "    ", "kwargs", "=", "{", "'num_workers'", ":", "0", ",", "'pin_memory'", ":", "True", "}", "\n", "dataset", "=", "datasets", ".", "MNIST", "(", "root", "=", "args", ".", "data_path", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", "\n", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "SequentialSampler", "(", "dataset", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "datasets", ".", "MNIST", "(", "root", "=", "args", ".", "data_path", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", ",", "batch_size", "=", "args", ".", "test_size", ")", "\n", "return", "train_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.train_model": [[77, 255], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.init.kaiming_normal_().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "numpy.zeros", "mnist_exp.loss_train_avg", "mnist_exp.loss_test_avg", "print", "enumerate", "itertools.repeat", "hypergrad.GradientDescent", "hypergrad.GradientDescent", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "time.time", "range", "print", "os.path.join", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "images_list.append", "labels_list.append", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "nositify().to", "torch.nn.functional.cross_entropy", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.cross_entropy", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "time.time", "print", "str", "open", "numpy.save", "torch.init.kaiming_normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "range", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "mnist_exp.build_val_data", "stocBiO.stocbio", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mnist_exp.loss_train_avg", "mnist_exp.loss_test_avg", "mnist_exp.loss_train_avg", "mnist_exp.loss_test_avg", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "mnist_exp.nositify", "torch.t", "torch.t", "torch.t", "torch.t", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.t", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "nositify().to", "mnist_exp.train_model.out_f"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_train_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_test_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.build_val_data", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.stocBiO.stocbio", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_train_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_test_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_train_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_test_avg", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.nositify", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.l2reg_on_twentynews.out_f"], ["", "def", "train_model", "(", "args", ",", "train_loader", ",", "test_loader", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "parameters", "=", "torch", ".", "randn", "(", "(", "args", ".", "num_classes", ",", "785", ")", ",", "requires_grad", "=", "True", ")", "\n", "parameters", "=", "nn", ".", "init", ".", "kaiming_normal_", "(", "parameters", ",", "mode", "=", "'fan_out'", ")", ".", "to", "(", "device", ")", "\n", "lambda_x", "=", "torch", ".", "zeros", "(", "(", "args", ".", "training_size", ")", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "loss_time_results", "=", "np", ".", "zeros", "(", "(", "args", ".", "epochs", "+", "1", ",", "4", ")", ")", "\n", "batch_num", "=", "args", ".", "training_size", "//", "args", ".", "batch_size", "\n", "train_loss_avg", "=", "loss_train_avg", "(", "train_loader", ",", "parameters", ",", "device", ",", "batch_num", ")", "\n", "test_loss_avg", "=", "loss_test_avg", "(", "test_loader", ",", "parameters", ",", "device", ")", "\n", "loss_time_results", "[", "0", ",", ":", "]", "=", "[", "train_loss_avg", ",", "test_loss_avg", ",", "(", "0.0", ")", ",", "(", "0.0", ")", "]", "\n", "print", "(", "'Epoch: {:d} Train Loss: {:.4f} Test Loss: {:.4f}'", ".", "format", "(", "0", ",", "train_loss_avg", ",", "test_loss_avg", ")", ")", "\n", "\n", "images_list", ",", "labels_list", "=", "[", "]", ",", "[", "]", "\n", "for", "index", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "images_list", ".", "append", "(", "images", ")", "\n", "labels_list", ".", "append", "(", "labels", ")", "\n", "\n", "# setting for reverse, fixed_point & CG", "\n", "", "def", "loss_inner", "(", "parameters", ",", "weight", ",", "data_all", ")", ":", "\n", "        ", "data", "=", "data_all", "[", "0", "]", "\n", "labels", "=", "data_all", "[", "1", "]", "\n", "data", "=", "torch", ".", "reshape", "(", "data", ",", "(", "data", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "args", ".", "noise_rate", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "data", ",", "torch", ".", "t", "(", "parameters", "[", "0", "]", "[", ":", ",", "0", ":", "784", "]", ")", ")", "+", "parameters", "[", "0", "]", "[", ":", ",", "784", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "output", ",", "labels_cp", ",", "reduction", "=", "'none'", ")", "\n", "loss_regu", "=", "torch", ".", "mean", "(", "torch", ".", "mul", "(", "loss", ",", "torch", ".", "sigmoid", "(", "weight", "[", "0", "]", ")", ")", ")", "+", "0.001", "*", "torch", ".", "pow", "(", "torch", ".", "norm", "(", "parameters", "[", "0", "]", ")", ",", "2", ")", "\n", "return", "loss_regu", "\n", "\n", "", "def", "loss_outer", "(", "parameters", ",", "lambda_x", ")", ":", "\n", "        ", "images", ",", "labels", "=", "images_list", "[", "-", "1", "]", ",", "labels_list", "[", "-", "1", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "images_temp", ",", "labels_temp", "=", "images", "[", "0", ":", "args", ".", "validation_size", ",", ":", "]", ",", "labels", "[", "0", ":", "args", ".", "validation_size", "]", "\n", "images", "=", "torch", ".", "cat", "(", "[", "images_temp", "]", "*", "(", "args", ".", "training_size", "//", "args", ".", "validation_size", ")", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "labels_temp", "]", "*", "(", "args", ".", "training_size", "//", "args", ".", "validation_size", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "images", ",", "torch", ".", "t", "(", "parameters", "[", "0", "]", "[", ":", ",", "0", ":", "784", "]", ")", ")", "+", "parameters", "[", "0", "]", "[", ":", ",", "784", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "output", ",", "labels", ")", "\n", "return", "loss", "\n", "\n", "", "def", "out_f", "(", "data", ",", "parameters", ")", ":", "\n", "        ", "output", "=", "torch", ".", "matmul", "(", "data", ",", "torch", ".", "t", "(", "parameters", "[", "0", "]", "[", ":", ",", "0", ":", "784", "]", ")", ")", "+", "parameters", "[", "0", "]", "[", ":", ",", "784", "]", "\n", "return", "output", "\n", "\n", "", "def", "reg_f", "(", "params", ",", "hparams", ",", "loss", ")", ":", "\n", "        ", "loss_regu", "=", "torch", ".", "mean", "(", "torch", ".", "mul", "(", "loss", ",", "torch", ".", "sigmoid", "(", "hparams", ")", ")", ")", "+", "0.001", "*", "torch", ".", "pow", "(", "torch", ".", "norm", "(", "params", "[", "0", "]", ")", ",", "2", ")", "\n", "return", "loss_regu", "\n", "\n", "", "tol", "=", "1e-12", "\n", "warm_start", "=", "True", "\n", "params_history", "=", "[", "]", "\n", "train_iterator", "=", "repeat", "(", "[", "images_list", "[", "0", "]", ",", "labels_list", "[", "0", "]", "]", ")", "\n", "inner_opt", "=", "hg", ".", "GradientDescent", "(", "loss_inner", ",", "args", ".", "inner_lr", ",", "data_or_iter", "=", "train_iterator", ")", "\n", "inner_opt_cg", "=", "hg", ".", "GradientDescent", "(", "loss_inner", ",", "1.", ",", "data_or_iter", "=", "train_iterator", ")", "\n", "outer_opt", "=", "torch", ".", "optim", ".", "SGD", "(", "lr", "=", "args", ".", "outer_lr", ",", "params", "=", "[", "lambda_x", "]", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "lambda_index_outer", "=", "0", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "grad_norm_inner", "=", "0.0", "\n", "if", "args", ".", "alg", "==", "'stocBiO'", "or", "args", ".", "alg", "==", "'HOAG'", ":", "\n", "            ", "train_index_list", "=", "torch", ".", "randperm", "(", "batch_num", ")", "\n", "for", "index", "in", "range", "(", "args", ".", "iterations", ")", ":", "\n", "                ", "index_rn", "=", "train_index_list", "[", "index", "%", "batch_num", "]", "\n", "images", ",", "labels", "=", "images_list", "[", "index_rn", "]", ",", "labels_list", "[", "index_rn", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "args", ".", "noise_rate", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "weight", "=", "lambda_x", "[", "index_rn", "*", "args", ".", "batch_size", ":", "(", "index_rn", "+", "1", ")", "*", "args", ".", "batch_size", "]", "\n", "output", "=", "out_f", "(", "images", ",", "[", "parameters", "]", ")", "\n", "inner_update", "=", "gradient_gy", "(", "args", ",", "labels_cp", ",", "parameters", ",", "images", ",", "weight", ",", "output", ",", "reg_f", ")", "\n", "parameters", "=", "parameters", "-", "args", ".", "inner_lr", "*", "inner_update", "\n", "\n", "", "", "if", "args", ".", "alg", "==", "'stocBiO'", ":", "\n", "            ", "val_index", "=", "torch", ".", "randperm", "(", "args", ".", "validation_size", "//", "args", ".", "batch_size", ")", "\n", "val_data_list", "=", "build_val_data", "(", "args", ",", "val_index", ",", "images_list", ",", "labels_list", ",", "device", ")", "\n", "hparams", "=", "lambda_x", "[", "lambda_index_outer", ":", "lambda_index_outer", "+", "args", ".", "batch_size", "]", "\n", "outer_update", "=", "stocbio", "(", "[", "parameters", "]", ",", "hparams", ",", "val_data_list", ",", "args", ",", "out_f", ",", "reg_f", ")", "\n", "\n", "", "elif", "args", ".", "alg", "==", "'HOAG'", ":", "\n", "            ", "images", ",", "labels", "=", "images_list", "[", "-", "1", "]", ",", "labels_list", "[", "-", "1", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "images_temp", ",", "labels_temp", "=", "images", "[", "0", ":", "args", ".", "validation_size", ",", ":", "]", ",", "labels", "[", "0", ":", "args", ".", "validation_size", "]", "\n", "images", "=", "torch", ".", "cat", "(", "[", "images_temp", "]", "*", "(", "args", ".", "training_size", "//", "args", ".", "validation_size", ")", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "labels_temp", "]", "*", "(", "args", ".", "training_size", "//", "args", ".", "validation_size", ")", ")", "\n", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "args", ".", "noise_rate", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ",", "val_labels_list", "=", "[", "images", ",", "images", ",", "images", "]", ",", "[", "labels", ",", "labels_cp", ",", "labels_cp", "]", "\n", "val_data_list", "=", "[", "val_images_list", ",", "val_labels_list", "]", "\n", "outer_update", "=", "stocbio", "(", "[", "parameters", "]", ",", "lambda_x", ",", "val_data_list", ",", "args", ",", "out_f", ",", "reg_f", ")", "\n", "\n", "", "elif", "args", ".", "alg", "==", "'BSA'", "or", "args", ".", "alg", "==", "'TTSA'", ":", "\n", "            ", "train_index_list", "=", "torch", ".", "randperm", "(", "args", ".", "training_size", ")", "\n", "random_list", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "[", "args", ".", "training_size", "]", ")", "\n", "noise_rate_list", "=", "np", ".", "where", "(", "(", "random_list", ">", "args", ".", "noise_rate", ")", ",", "0", ",", "1", ")", "\n", "for", "index", "in", "range", "(", "args", ".", "iterations", ")", ":", "\n", "                ", "images", ",", "labels", "=", "images_list", "[", "train_index_list", "[", "index", "]", "]", ",", "labels_list", "[", "train_index_list", "[", "index", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "noise_rate_list", "[", "index", "]", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "weight", "=", "lambda_x", "[", "train_index_list", "[", "index", "]", ":", "train_index_list", "[", "index", "]", "+", "1", "]", "\n", "output", "=", "out_f", "(", "images", ",", "[", "parameters", "]", ")", "\n", "inner_update", "=", "gradient_gy", "(", "args", ",", "labels_cp", ",", "parameters", ",", "images", ",", "weight", ",", "output", ",", "reg_f", ")", "\n", "parameters", "=", "parameters", "-", "args", ".", "inner_lr", "*", "inner_update", "\n", "\n", "", "val_index", "=", "-", "torch", ".", "randperm", "(", "args", ".", "validation_size", ")", "\n", "random_list", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "[", "args", ".", "hessian_q", "+", "2", "]", ")", "\n", "noise_rate_list", "=", "np", ".", "where", "(", "(", "random_list", ">", "args", ".", "noise_rate", ")", ",", "0", ",", "1", ")", "\n", "\n", "val_images_list", ",", "val_labels_list", "=", "[", "]", ",", "[", "]", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "1", "]", "]", ",", "labels_list", "[", "val_index", "[", "1", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels", ".", "to", "(", "device", ")", ")", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "2", "]", "]", ",", "labels_list", "[", "val_index", "[", "2", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "noise_rate_list", "[", "1", "]", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels", ")", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "3", "]", "]", ",", "labels_list", "[", "val_index", "[", "3", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "noise_rate_list", "[", "2", "]", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels", ")", "\n", "val_data_list", "=", "[", "val_images_list", ",", "val_labels_list", "]", "\n", "\n", "hyparams", "=", "lambda_x", "[", "lambda_index_outer", ":", "lambda_index_outer", "+", "args", ".", "batch_size", "]", "\n", "outer_update", "=", "stocbio", "(", "[", "parameters", "]", ",", "hyparams", ",", "val_data_list", ",", "args", ",", "out_f", ",", "reg_f", ")", "\n", "\n", "", "else", ":", "\n", "            ", "inner_losses", "=", "[", "]", "\n", "if", "params_history", ":", "\n", "                ", "params_history", "=", "[", "params_history", "[", "-", "1", "]", "]", "\n", "", "else", ":", "\n", "                ", "params_history", "=", "[", "[", "parameters", "]", "]", "\n", "", "for", "index", "in", "range", "(", "args", ".", "iterations", ")", ":", "\n", "                ", "params_history", ".", "append", "(", "inner_opt", "(", "params_history", "[", "-", "1", "]", ",", "[", "lambda_x", "]", ",", "create_graph", "=", "False", ")", ")", "\n", "inner_losses", ".", "append", "(", "inner_opt", ".", "curr_loss", ")", "\n", "\n", "", "final_params", "=", "params_history", "[", "-", "1", "]", "\n", "outer_opt", ".", "zero_grad", "(", ")", "\n", "if", "args", ".", "alg", "==", "'reverse'", ":", "\n", "                ", "hg", ".", "reverse", "(", "params_history", "[", "-", "args", ".", "hessian_q", "-", "1", ":", "]", ",", "[", "lambda_x", "]", ",", "[", "inner_opt", "]", "*", "args", ".", "hessian_q", ",", "loss_outer", ")", "\n", "", "elif", "args", ".", "alg", "==", "'AID-FP'", ":", "\n", "                ", "hg", ".", "fixed_point", "(", "final_params", ",", "[", "lambda_x", "]", ",", "args", ".", "hessian_q", ",", "inner_opt", ",", "loss_outer", ",", "stochastic", "=", "False", ",", "tol", "=", "tol", ")", "\n", "", "elif", "args", ".", "alg", "==", "'AID-CG'", ":", "\n", "                ", "hg", ".", "CG", "(", "final_params", "[", ":", "len", "(", "parameters", ")", "]", ",", "[", "lambda_x", "]", ",", "args", ".", "hessian_q", ",", "inner_opt_cg", ",", "loss_outer", ",", "stochastic", "=", "False", ",", "tol", "=", "tol", ")", "\n", "", "outer_update", "=", "lambda_x", ".", "grad", "\n", "weight", "=", "lambda_x", "[", "lambda_index_outer", ":", "lambda_index_outer", "+", "args", ".", "batch_size", "]", "\n", "\n", "", "outer_update", "=", "torch", ".", "squeeze", "(", "outer_update", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "weight", "=", "weight", "-", "args", ".", "outer_lr", "*", "outer_update", "\n", "lambda_x", "[", "lambda_index_outer", ":", "lambda_index_outer", "+", "args", ".", "batch_size", "]", "=", "weight", "\n", "\n", "", "lambda_index_outer", "=", "(", "lambda_index_outer", "+", "args", ".", "batch_size", ")", "%", "args", ".", "training_size", "\n", "\n", "if", "args", ".", "alg", "==", "'reverse'", "or", "args", ".", "alg", "==", "'AID-CG'", "or", "args", ".", "alg", "==", "'AID-FP'", ":", "\n", "            ", "train_loss_avg", "=", "loss_train_avg", "(", "train_loader", ",", "final_params", "[", "0", "]", ",", "device", ",", "batch_num", ")", "\n", "test_loss_avg", "=", "loss_test_avg", "(", "test_loader", ",", "final_params", "[", "0", "]", ",", "device", ")", "\n", "", "else", ":", "\n", "            ", "train_loss_avg", "=", "loss_train_avg", "(", "train_loader", ",", "parameters", ",", "device", ",", "batch_num", ")", "\n", "test_loss_avg", "=", "loss_test_avg", "(", "test_loader", ",", "parameters", ",", "device", ")", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Epoch: {:d} Train Loss: {:.4f} Test Loss: {:.4f} Time: {:.4f}'", ".", "format", "(", "epoch", "+", "1", ",", "train_loss_avg", ",", "test_loss_avg", ",", "\n", "(", "end_time", "-", "start_time", ")", ")", ")", "\n", "\n", "loss_time_results", "[", "epoch", "+", "1", ",", "0", "]", "=", "train_loss_avg", "\n", "loss_time_results", "[", "epoch", "+", "1", ",", "1", "]", "=", "test_loss_avg", "\n", "loss_time_results", "[", "epoch", "+", "1", ",", "2", "]", "=", "(", "end_time", "-", "start_time", ")", "\n", "loss_time_results", "[", "epoch", "+", "1", ",", "3", "]", "=", "grad_norm_inner", "\n", "\n", "", "print", "(", "loss_time_results", ")", "\n", "file_name", "=", "str", "(", "args", ".", "seed", ")", "+", "'.npy'", "\n", "file_addr", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_folder", ",", "file_name", ")", "\n", "with", "open", "(", "file_addr", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "np", ".", "save", "(", "f", ",", "loss_time_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_train_avg": [[256, 269], ["enumerate", "loss_avg.detach", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "labels.to.to", "mnist_exp.loss_f_funciton", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape().to.size"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_f_funciton"], ["", "", "def", "loss_train_avg", "(", "data_loader", ",", "parameters", ",", "device", ",", "batch_num", ")", ":", "\n", "    ", "loss_avg", ",", "num", "=", "0.0", ",", "0", "\n", "for", "index", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "if", "index", ">=", "batch_num", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "loss", "=", "loss_f_funciton", "(", "labels", ",", "parameters", ",", "images", ")", "\n", "loss_avg", "+=", "loss", "\n", "num", "+=", "1", "\n", "", "", "loss_avg", "=", "loss_avg", "/", "num", "\n", "return", "loss_avg", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_test_avg": [[270, 281], ["enumerate", "loss_avg.detach", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "labels.to.to", "mnist_exp.loss_f_funciton", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape().to.size"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_f_funciton"], ["", "def", "loss_test_avg", "(", "data_loader", ",", "parameters", ",", "device", ")", ":", "\n", "    ", "loss_avg", ",", "num", "=", "0.0", ",", "0", "\n", "for", "_", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "# images = torch.cat((images, torch.ones(images.size()[0],1)),1)", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "loss", "=", "loss_f_funciton", "(", "labels", ",", "parameters", ",", "images", ")", "\n", "loss_avg", "+=", "loss", "\n", "num", "+=", "1", "\n", "", "loss_avg", "=", "loss_avg", "/", "num", "\n", "return", "loss_avg", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.loss_f_funciton": [[282, 286], ["torch.nn.functional.cross_entropy", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.t", "torch.t", "torch.t", "torch.t"], "function", ["None"], ["", "def", "loss_f_funciton", "(", "labels", ",", "parameters", ",", "data", ")", ":", "\n", "    ", "output", "=", "torch", ".", "matmul", "(", "data", ",", "torch", ".", "t", "(", "parameters", "[", ":", ",", "0", ":", "784", "]", ")", ")", "+", "parameters", "[", ":", ",", "784", "]", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "output", ",", "labels", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.nositify": [[287, 294], ["int", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "labels.size", "labels.size"], "function", ["None"], ["", "def", "nositify", "(", "labels", ",", "noise_rate", ",", "n_class", ")", ":", "\n", "    ", "num", "=", "noise_rate", "*", "(", "labels", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "num", "=", "int", "(", "num", ")", "\n", "randint", "=", "torch", ".", "randint", "(", "1", ",", "10", ",", "(", "num", ",", ")", ")", "\n", "index", "=", "torch", ".", "randperm", "(", "labels", ".", "size", "(", ")", "[", "0", "]", ")", "[", ":", "num", "]", "\n", "labels", "[", "index", "]", "=", "(", "labels", "[", "index", "]", "+", "randint", ")", "%", "n_class", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.build_val_data": [[295, 318], ["torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "labels.to.to", "val_images_list.append", "val_labels_list.append", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "nositify().to", "val_images_list.append", "val_labels_list.append", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "torch.reshape().to", "nositify().to", "val_images_list.append", "val_labels_list.append", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "mnist_exp.nositify", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "mnist_exp.nositify", "torch.reshape().to.size", "torch.reshape().to.size", "torch.reshape().to.size"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.nositify", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.nositify"], ["", "def", "build_val_data", "(", "args", ",", "val_index", ",", "images_list", ",", "labels_list", ",", "device", ")", ":", "\n", "    ", "val_index", "=", "-", "(", "val_index", ")", "\n", "val_images_list", ",", "val_labels_list", "=", "[", "]", ",", "[", "]", "\n", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "0", "]", "]", ",", "labels_list", "[", "val_index", "[", "0", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels", ")", "\n", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "1", "]", "]", ",", "labels_list", "[", "val_index", "[", "1", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "args", ".", "noise_rate", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels_cp", ")", "\n", "\n", "images", ",", "labels", "=", "images_list", "[", "val_index", "[", "2", "]", "]", ",", "labels_list", "[", "val_index", "[", "2", "]", "]", "\n", "images", "=", "torch", ".", "reshape", "(", "images", ",", "(", "images", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", ")", ".", "to", "(", "device", ")", "\n", "labels_cp", "=", "nositify", "(", "labels", ",", "args", ".", "noise_rate", ",", "args", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "val_images_list", ".", "append", "(", "images", ")", "\n", "val_labels_list", ".", "append", "(", "labels_cp", ")", "\n", "\n", "return", "[", "val_images_list", ",", "val_labels_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.main": [[320, 325], ["mnist_exp.parse_args", "print", "mnist_exp.get_data_loaders", "mnist_exp.train_model"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.parse_args", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.get_data_loaders", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.experimental.mnist_exp.train_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "train_loader", ",", "test_loader", "=", "get_data_loaders", "(", "args", ")", "\n", "train_model", "(", "args", ",", "train_loader", ",", "test_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.anil.Lambda.__init__": [[29, 32], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["    ", "def", "__init__", "(", "self", ",", "fn", ")", ":", "\n", "        ", "super", "(", "Lambda", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fn", "=", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.anil.Lambda.forward": [[33, 35], ["anil.Lambda.fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.anil.accuracy": [[37, 40], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["", "", "def", "accuracy", "(", "predictions", ",", "targets", ")", ":", "\n", "    ", "predictions", "=", "predictions", ".", "argmax", "(", "dim", "=", "1", ")", ".", "view", "(", "targets", ".", "shape", ")", "\n", "return", "(", "predictions", "==", "targets", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "/", "targets", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.anil.fast_adapt": [[42, 78], ["features", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "learner", "loss", "anil.accuracy", "features.to", "labels.to", "features.size", "learner.parameters", "learner.adapt", "p.norm", "loss", "numpy.arange", "learner"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy"], ["", "def", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "# print('before_data_size=' + str(data.size(0)))", "\n", "\n", "data", "=", "features", "(", "data", ")", "\n", "\n", "# Separate data into adaptation/evaluation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n", "# print('data_size=' + str(data.size(0)))", "\n", "adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n", "evaluation_data", ",", "evaluation_labels", "=", "data", "[", "evaluation_indices", "]", ",", "labels", "[", "evaluation_indices", "]", "\n", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "l2_reg", "=", "0", "\n", "for", "p", "in", "learner", ".", "parameters", "(", ")", ":", "\n", "            ", "l2_reg", "+=", "p", ".", "norm", "(", "2", ")", "\n", "", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "+", "reg_lambda", "*", "l2_reg", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n", "", "predictions", "=", "learner", "(", "evaluation_data", ")", "\n", "valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.anil.main": [[80, 308], ["print", "bool", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.ConvBase", "torch.nn.Sequential", "torch.nn.Sequential.to", "torch.nn.Linear", "learn2learn.algorithms.MAML", "l2l.algorithms.MAML.to", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "anil.Lambda", "list", "list", "torch.optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "torch.optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "str", "torch.nn.Sequential.parameters", "l2l.algorithms.MAML.parameters", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_", "x.view", "list", "list", "str", "l2l.algorithms.MAML.parameters", "torch.nn.Sequential.parameters", "str"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "# meta_lr=0.001, ", "\n", "meta_head_lr", "=", "0.002", ",", "# Different lr for head and feature parameters", "\n", "meta_feature_lr", "=", "0.002", ",", "\n", "fast_lr", "=", "0.1", ",", "# original 0.1", "\n", "reg_lambda", "=", "0", ",", "\n", "adapt_steps", "=", "5", ",", "# original: 5", "\n", "meta_bsz", "=", "32", ",", "\n", "iters", "=", "1000", ",", "# orginal: 1000", "\n", "cuda", "=", "1", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "\n", "    ", "print", "(", "'hlr='", "+", "str", "(", "meta_head_lr", ")", "+", "' flr='", "+", "str", "(", "fast_lr", ")", "+", "' reg='", "+", "str", "(", "reg_lambda", ")", ")", "\n", "\n", "cuda", "=", "bool", "(", "cuda", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# Create Datasets", "\n", "# train_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                           mode='train')", "\n", "# valid_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                           mode='validation')", "\n", "# test_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                          mode='test')", "\n", "# train_dataset = l2l.data.MetaDataset(train_dataset)", "\n", "# valid_dataset = l2l.data.MetaDataset(valid_dataset)", "\n", "# test_dataset = l2l.data.MetaDataset(test_dataset)", "\n", "\n", "# train_transforms = [", "\n", "#     FusedNWaysKShots(train_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(train_dataset),", "\n", "#     RemapLabels(train_dataset),", "\n", "#     ConsecutiveLabels(train_dataset),", "\n", "# ]", "\n", "# train_tasks = l2l.data.TaskDataset(train_dataset,", "\n", "#                                   task_transforms=train_transforms,", "\n", "#                                   num_tasks=20000)", "\n", "\n", "# valid_transforms = [", "\n", "#     FusedNWaysKShots(valid_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(valid_dataset),", "\n", "#     ConsecutiveLabels(valid_dataset),", "\n", "#     RemapLabels(valid_dataset),", "\n", "# ]", "\n", "# valid_tasks = l2l.data.TaskDataset(valid_dataset,", "\n", "#                                   task_transforms=valid_transforms,", "\n", "#                                   num_tasks=600)", "\n", "\n", "# test_transforms = [", "\n", "#     FusedNWaysKShots(test_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(test_dataset),", "\n", "#     RemapLabels(test_dataset),", "\n", "#     ConsecutiveLabels(test_dataset),", "\n", "# ]", "\n", "# test_tasks = l2l.data.TaskDataset(test_dataset,", "\n", "#                                   task_transforms=test_transforms,", "\n", "#                                   num_tasks=600)", "\n", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n", "test_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "test_dataset", ")", "\n", "\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n", "RemapLabels", "(", "train_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "\n", "# Create model", "\n", "# features = l2l.vision.models.MiniImagenetCNN(ways)", "\n", "features", "=", "l2l", ".", "vision", ".", "models", ".", "ConvBase", "(", "output_size", "=", "32", ",", "channels", "=", "3", ",", "max_pool", "=", "True", ")", "\n", "# for p in  features.parameters():", "\n", "#     print(p.shape)", "\n", "features", "=", "torch", ".", "nn", ".", "Sequential", "(", "features", ",", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "-", "1", ",", "1600", ")", ")", ")", "\n", "features", ".", "to", "(", "device", ")", "\n", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "1600", ",", "ways", ")", "\n", "head", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "head", ",", "lr", "=", "fast_lr", ")", "\n", "head", ".", "to", "(", "device", ")", "\n", "\n", "# Setup optimization", "\n", "all_parameters", "=", "list", "(", "features", ".", "parameters", "(", ")", ")", "+", "list", "(", "head", ".", "parameters", "(", ")", ")", "\n", "\n", "# optimizer = torch.optim.Adam(all_parameters, lr=meta_lr)", "\n", "\n", "## use different learning rates for w and theta", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "list", "(", "head", ".", "parameters", "(", ")", ")", ",", "'lr'", ":", "meta_head_lr", "}", ",", "\n", "{", "'params'", ":", "list", "(", "features", ".", "parameters", "(", ")", ")", ",", "'lr'", ":", "meta_feature_lr", "}", "]", ")", "\n", "\n", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "iters", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "iters", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "\n", "for", "task", "in", "range", "(", "meta_bsz", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-testing loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "test_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_test_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_test_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "", "training_accuracy", "[", "iteration", "]", "=", "meta_train_accuracy", "/", "meta_bsz", "\n", "test_accuracy", "[", "iteration", "]", "=", "meta_test_accuracy", "/", "meta_bsz", "\n", "\n", "# Print some metrics", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Iteration'", ",", "iteration", ")", "\n", "print", "(", "'Meta Train Error'", ",", "meta_train_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Train Accuracy'", ",", "meta_train_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Error'", ",", "meta_valid_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Accuracy'", ",", "meta_valid_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Error'", ",", "meta_test_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Accuracy'", ",", "meta_test_accuracy", "/", "meta_bsz", ")", "\n", "\n", "# Average the accumulated gradients and optimize", "\n", "for", "p", "in", "all_parameters", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "1.0", "/", "meta_bsz", ")", "\n", "\n", "# print('head')", "\n", "# for p in list(head.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "# print('feature')", "\n", "# for p in list(features.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "running_time", "[", "iteration", "]", "=", "end_time", "-", "start_time", "\n", "print", "(", "'total running time'", ",", "end_time", "-", "start_time", ")", "\n", "\n", "", "return", "training_accuracy", ".", "numpy", "(", ")", ",", "test_accuracy", ".", "numpy", "(", ")", ",", "running_time", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.Lambda.__init__": [[32, 35], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.Lambda.forward": [[36, 38], ["ITD-BiO.Lambda.fn"], "methods", ["None"], ["\n", "", "", "def", "accuracy", "(", "predictions", ",", "targets", ")", ":", "\n", "    ", "predictions", "=", "predictions", ".", "argmax", "(", "dim", "=", "1", ")", ".", "view", "(", "targets", ".", "shape", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.accuracy": [[40, 43], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["\n", "\n", "", "def", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.fast_adapt": [[75, 113], ["torch.nn.Linear", "torch.nn.Linear.to", "features", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "torch.nn.Linear.", "loss", "ITD-BiO.accuracy", "features.to", "labels.to", "features.size", "loss", "ITD-BiO.task_adapt", "torch.nn.Linear.", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.task_adapt"], ["valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n", "\n", "", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "meta_lr", "=", "0.002", ",", "\n", "fast_lr", "=", "0.1", ",", "# original 0.1", "\n", "reg_lambda", "=", "0", ",", "\n", "adapt_steps", "=", "5", ",", "# original: 5", "\n", "meta_bsz", "=", "32", ",", "\n", "iters", "=", "1000", ",", "# orginal: 1000", "\n", "cuda", "=", "1", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "\n", "    ", "cuda", "=", "bool", "(", "cuda", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n", "test_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "test_dataset", ")", "\n", "\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.main": [[115, 288], ["print", "bool", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.ConvBase", "torch.nn.Sequential", "torch.nn.Sequential.to", "list", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "ITD-BiO.Lambda", "torch.nn.Sequential.parameters", "torch.optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "torch.optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "str", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_", "x.view", "str", "str"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "\n", "# Create model", "\n", "# features = l2l.vision.models.MiniImagenetCNN(ways)", "\n", "features", "=", "l2l", ".", "vision", ".", "models", ".", "ConvBase", "(", "output_size", "=", "32", ",", "channels", "=", "3", ",", "max_pool", "=", "True", ")", "\n", "# for p in  features.parameters():", "\n", "#     print(p.shape)", "\n", "features", "=", "torch", ".", "nn", ".", "Sequential", "(", "features", ",", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "-", "1", ",", "1600", ")", ")", ")", "\n", "features", ".", "to", "(", "device", ")", "\n", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "1600", ",", "ways", ")", "\n", "head", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "head", ",", "lr", "=", "fast_lr", ")", "\n", "head", ".", "to", "(", "device", ")", "\n", "\n", "# Setup optimization", "\n", "all_parameters", "=", "list", "(", "features", ".", "parameters", "(", ")", ")", "\n", "\n", "# optimizer = torch.optim.Adam(all_parameters, lr=meta_lr)", "\n", "\n", "## use different learning rates for w and theta", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "all_parameters", ",", "lr", "=", "meta_lr", ")", "\n", "\n", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "iters", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "iters", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "\n", "for", "task", "in", "range", "(", "meta_bsz", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-testing loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "test_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_test_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_test_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "", "training_accuracy", "[", "iteration", "]", "=", "meta_train_accuracy", "/", "meta_bsz", "\n", "test_accuracy", "[", "iteration", "]", "=", "meta_test_accuracy", "/", "meta_bsz", "\n", "\n", "# Print some metrics", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Iteration'", ",", "iteration", ")", "\n", "print", "(", "'Meta Train Error'", ",", "meta_train_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Train Accuracy'", ",", "meta_train_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Error'", ",", "meta_valid_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Accuracy'", ",", "meta_valid_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Error'", ",", "meta_test_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Accuracy'", ",", "meta_test_accuracy", "/", "meta_bsz", ")", "\n", "\n", "# Average the accumulated gradients and optimize", "\n", "for", "p", "in", "all_parameters", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "1.0", "/", "meta_bsz", ")", "\n", "\n", "# print('head')", "\n", "# for p in list(head.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "# print('feature')", "\n", "# for p in list(features.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "running_time", "[", "iteration", "]", "=", "end_time", "-", "start_time", "\n", "print", "(", "'total running time'", ",", "end_time", "-", "start_time", ")", "\n", "\n", "", "return", "training_accuracy", ".", "numpy", "(", ")", ",", "test_accuracy", ".", "numpy", "(", ")", ",", "running_time", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "train_accuracy", "=", "[", "]", "\n", "test_accuracy", "=", "[", "]", "\n", "run_time", "=", "[", "]", "\n", "\n", "seeds", "=", "[", "42", ",", "52", ",", "62", ",", "72", ",", "82", "]", "\n", "stp", "=", "10", "# 10 -> fastlr=0.05, 5 -> fastlr=0.1", "\n", "lr", "=", "0.002", "\n", "fastlr", "=", "0.05", "\n", "reg", "=", "0", "\n", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "training_accuracy", ",", "testing_accuracy", ",", "running_time", "=", "main", "(", "meta_lr", "=", "lr", ",", "\n", "adapt_steps", "=", "stp", ",", "\n", "fast_lr", "=", "fastlr", ",", "\n", "reg_lambda", "=", "reg", ",", "\n", "iters", "=", "2000", ",", "\n", "seed", "=", "seed", ")", "\n", "train_accuracy", ".", "append", "(", "training_accuracy", ")", "\n", "test_accuracy", ".", "append", "(", "testing_accuracy", ")", "\n", "run_time", ".", "append", "(", "running_time", ")", "\n", "\n", "# save ", "\n", "# from datetime import datetime", "\n", "# now = datetime.now()", "\n", "# current_time = now.strftime(\"%H:%M:%S\")", "\n", "\n", "", "pstr", "=", "'_lr_'", "+", "str", "(", "lr", ")", "+", "'_fastlr_'", "+", "str", "(", "fastlr", ")", "+", "'_steps_'", "+", "str", "(", "stp", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.maml.accuracy": [[15, 18], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["def", "accuracy", "(", "predictions", ",", "targets", ")", ":", "\n", "    ", "predictions", "=", "predictions", ".", "argmax", "(", "dim", "=", "1", ")", ".", "view", "(", "targets", ".", "shape", ")", "\n", "return", "(", "predictions", "==", "targets", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "/", "targets", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.maml.fast_adapt": [[20, 44], ["numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "learner", "loss", "len", "maml.accuracy", "data.to", "labels.to", "data.size", "loss", "len", "learner.adapt", "learner", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy"], ["", "def", "fast_adapt", "(", "batch", ",", "learner", ",", "loss", ",", "adaptation_steps", ",", "shots", ",", "ways", ",", "device", ")", ":", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "\n", "# Separate data into adaptation/evalutation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n", "adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n", "evaluation_data", ",", "evaluation_labels", "=", "data", "[", "evaluation_indices", "]", ",", "labels", "[", "evaluation_indices", "]", "\n", "\n", "# Adapt the model", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "\n", "train_error", "/=", "len", "(", "adaptation_data", ")", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n", "# Evaluate the adapted model", "\n", "", "predictions", "=", "learner", "(", "evaluation_data", ")", "\n", "valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_error", "/=", "len", "(", "evaluation_data", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.maml.main": [[46, 209], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.vision.datasets.MiniImagenet", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.MiniImagenetCNN", "l2l.vision.models.MiniImagenetCNN.to", "learn2learn.algorithms.MAML", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.NWays", "learn2learn.data.transforms.KShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "l2l.algorithms.MAML.parameters", "optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "l2l.algorithms.MAML.parameters", "optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "meta_lr", "=", "0.003", ",", "\n", "fast_lr", "=", "0.5", ",", "\n", "meta_batch_size", "=", "32", ",", "\n", "adaptation_steps", "=", "1", ",", "\n", "num_iterations", "=", "60000", ",", "\n", "cuda", "=", "True", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# Create Datasets", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n", "test_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "test_dataset", ")", "\n", "\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n", "RemapLabels", "(", "train_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "# Create model", "\n", "model", "=", "l2l", ".", "vision", ".", "models", ".", "MiniImagenetCNN", "(", "ways", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "maml", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "model", ",", "lr", "=", "fast_lr", ",", "first_order", "=", "False", ")", "\n", "opt", "=", "optim", ".", "Adam", "(", "maml", ".", "parameters", "(", ")", ",", "meta_lr", ")", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "num_iterations", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "num_iterations", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "num_iterations", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "num_iterations", ")", ":", "\n", "        ", "opt", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "for", "task", "in", "range", "(", "meta_batch_size", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-test loss", "\n", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "test_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_test_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_test_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "", "training_accuracy", "[", "iteration", "]", "=", "meta_train_accuracy", "/", "meta_batch_size", "\n", "test_accuracy", "[", "iteration", "]", "=", "meta_test_accuracy", "/", "meta_batch_size", "\n", "\n", "# Print some metrics", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Iteration'", ",", "iteration", ")", "\n", "print", "(", "'Meta Train Error'", ",", "meta_train_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Train Accuracy'", ",", "meta_train_accuracy", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Valid Error'", ",", "meta_valid_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Valid Accuracy'", ",", "meta_valid_accuracy", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Test Error'", ",", "meta_test_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Test Accuracy'", ",", "meta_test_accuracy", "/", "meta_batch_size", ")", "\n", "\n", "# Average the accumulated gradients and optimize", "\n", "for", "p", "in", "maml", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "1.0", "/", "meta_batch_size", ")", "\n", "", "opt", ".", "step", "(", ")", "\n", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "running_time", "[", "iteration", "]", "=", "end_time", "-", "start_time", "\n", "print", "(", "'total running time'", ",", "end_time", "-", "start_time", ")", "\n", "\n", "# meta_test_error = 0.0", "\n", "# meta_test_accuracy = 0.0", "\n", "# for task in range(meta_batch_size):", "\n", "#     # Compute meta-testing loss", "\n", "#     learner = maml.clone()", "\n", "#     batch = test_tasks.sample()", "\n", "#     evaluation_error, evaluation_accuracy = fast_adapt(batch,", "\n", "#                                                       learner,", "\n", "#                                                       loss,", "\n", "#                                                       adaptation_steps,", "\n", "#                                                       shots,", "\n", "#                                                       ways,", "\n", "#                                                       device)", "\n", "#     meta_test_error += evaluation_error.item()", "\n", "#     meta_test_accuracy += evaluation_accuracy.item()", "\n", "# print('Meta Test Error', meta_test_error / meta_batch_size)", "\n", "# print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)", "\n", "\n", "", "return", "training_accuracy", ".", "numpy", "(", ")", ",", "test_accuracy", ".", "numpy", "(", ")", ",", "running_time", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.miniimagenet.ITD-BiO.task_adapt": [[45, 73], ["model._apply", "torch.autograd.grad", "list", "zip", "model.parameters", "traceback.print_exc", "model.parameters", "print", "len", "len", "list", "str", "str", "len", "len"], "function", ["None"], ["loss", ",", "\n", "reg_lambda", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "# print('before_data_size=' + str(data.size(0)))", "\n", "\n", "data", "=", "features", "(", "data", ")", "\n", "\n", "# Separate data into adaptation/evaluation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n", "# print('data_size=' + str(data.size(0)))", "\n", "adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n", "evaluation_data", ",", "evaluation_labels", "=", "data", "[", "evaluation_indices", "]", ",", "labels", "[", "evaluation_indices", "]", "\n", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "l2_reg", "=", "0", "\n", "for", "p", "in", "learner", ".", "parameters", "(", ")", ":", "\n", "            ", "l2_reg", "+=", "p", ".", "norm", "(", "2", ")", "\n", "", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "+", "reg_lambda", "*", "l2_reg", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.anil.Lambda.__init__": [[27, 30], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["class", "Lambda", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "fn", ")", ":", "\n", "        ", "super", "(", "Lambda", ",", "self", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.anil.Lambda.forward": [[31, 33], ["anil.Lambda.fn"], "methods", ["None"], ["self", ".", "fn", "=", "fn", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.anil.accuracy": [[35, 38], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["\n", "\n", "", "", "def", "accuracy", "(", "predictions", ",", "targets", ")", ":", "\n", "    ", "predictions", "=", "predictions", ".", "argmax", "(", "dim", "=", "1", ")", ".", "view", "(", "targets", ".", "shape", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.anil.fast_adapt": [[40, 73], ["features", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "learner", "loss", "anil.accuracy", "features.to", "labels.to", "features.size", "learner.parameters", "learner.adapt", "p.norm", "loss", "numpy.arange", "learner"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy"], ["\n", "\n", "", "def", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "# print('before_data_size=' + str(data.size(0)))", "\n", "\n", "data", "=", "features", "(", "data", ")", "\n", "\n", "# Separate data into adaptation/evaluation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n", "# print('data_size=' + str(data.size(0)))", "\n", "adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n", "evaluation_data", ",", "evaluation_labels", "=", "data", "[", "evaluation_indices", "]", ",", "labels", "[", "evaluation_indices", "]", "\n", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "l2_reg", "=", "0", "\n", "for", "p", "in", "learner", ".", "parameters", "(", ")", ":", "\n", "            ", "l2_reg", "+=", "p", ".", "norm", "(", "2", ")", "\n", "", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "+", "reg_lambda", "*", "l2_reg", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.anil.main": [[75, 262], ["print", "bool", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.ConvBase", "torch.nn.Sequential", "torch.nn.Sequential.to", "torch.nn.Linear", "learn2learn.algorithms.MAML", "l2l.algorithms.MAML.to", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "anil.Lambda", "list", "list", "torch.optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "torch.optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "str", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torch.nn.Sequential.parameters", "l2l.algorithms.MAML.parameters", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "anil.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_", "x.view", "list", "list", "str", "l2l.algorithms.MAML.parameters", "torch.nn.Sequential.parameters", "str"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n", "\n", "", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "# meta_lr=0.001, ", "\n", "meta_head_lr", "=", "0.002", ",", "# Different lr for head and feature parameters", "\n", "meta_feature_lr", "=", "0.002", ",", "\n", "fast_lr", "=", "0.1", ",", "# original 0.1", "\n", "reg_lambda", "=", "0", ",", "\n", "adapt_steps", "=", "5", ",", "# original: 5", "\n", "meta_bsz", "=", "32", ",", "\n", "iters", "=", "1000", ",", "# orginal: 1000", "\n", "cuda", "=", "1", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "\n", "    ", "print", "(", "'hlr='", "+", "str", "(", "meta_head_lr", ")", "+", "' flr='", "+", "str", "(", "fast_lr", ")", "+", "' reg='", "+", "str", "(", "reg_lambda", ")", ")", "\n", "\n", "cuda", "=", "bool", "(", "cuda", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# Create Datasets", "\n", "# train_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                           mode='train')", "\n", "# valid_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                           mode='validation')", "\n", "# test_dataset = l2l.vision.datasets.FC100(root='~/data',", "\n", "#                                           transform=tv.transforms.ToTensor(),", "\n", "#                                          mode='test')", "\n", "# train_dataset = l2l.data.MetaDataset(train_dataset)", "\n", "# valid_dataset = l2l.data.MetaDataset(valid_dataset)", "\n", "# test_dataset = l2l.data.MetaDataset(test_dataset)", "\n", "\n", "# train_transforms = [", "\n", "#     FusedNWaysKShots(train_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(train_dataset),", "\n", "#     RemapLabels(train_dataset),", "\n", "#     ConsecutiveLabels(train_dataset),", "\n", "# ]", "\n", "# train_tasks = l2l.data.TaskDataset(train_dataset,", "\n", "#                                   task_transforms=train_transforms,", "\n", "#                                   num_tasks=20000)", "\n", "\n", "# valid_transforms = [", "\n", "#     FusedNWaysKShots(valid_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(valid_dataset),", "\n", "#     ConsecutiveLabels(valid_dataset),", "\n", "#     RemapLabels(valid_dataset),", "\n", "# ]", "\n", "# valid_tasks = l2l.data.TaskDataset(valid_dataset,", "\n", "#                                   task_transforms=valid_transforms,", "\n", "#                                   num_tasks=600)", "\n", "\n", "# test_transforms = [", "\n", "#     FusedNWaysKShots(test_dataset, n=ways, k=2*shots),", "\n", "#     LoadData(test_dataset),", "\n", "#     RemapLabels(test_dataset),", "\n", "#     ConsecutiveLabels(test_dataset),", "\n", "# ]", "\n", "# test_tasks = l2l.data.TaskDataset(test_dataset,", "\n", "#                                   task_transforms=test_transforms,", "\n", "#                                   num_tasks=600)", "\n", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n", "test_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "test_dataset", ")", "\n", "\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n", "RemapLabels", "(", "train_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "\n", "# Create model", "\n", "# features = l2l.vision.models.MiniImagenetCNN(ways)", "\n", "features", "=", "l2l", ".", "vision", ".", "models", ".", "ConvBase", "(", "output_size", "=", "32", ",", "channels", "=", "3", ",", "max_pool", "=", "True", ")", "\n", "# for p in  features.parameters():", "\n", "#     print(p.shape)", "\n", "features", "=", "torch", ".", "nn", ".", "Sequential", "(", "features", ",", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "-", "1", ",", "1600", ")", ")", ")", "\n", "features", ".", "to", "(", "device", ")", "\n", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "1600", ",", "ways", ")", "\n", "head", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "head", ",", "lr", "=", "fast_lr", ")", "\n", "head", ".", "to", "(", "device", ")", "\n", "\n", "# Setup optimization", "\n", "all_parameters", "=", "list", "(", "features", ".", "parameters", "(", ")", ")", "+", "list", "(", "head", ".", "parameters", "(", ")", ")", "\n", "\n", "# optimizer = torch.optim.Adam(all_parameters, lr=meta_lr)", "\n", "\n", "## use different learning rates for w and theta", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "list", "(", "head", ".", "parameters", "(", ")", ")", ",", "'lr'", ":", "meta_head_lr", "}", ",", "\n", "{", "'params'", ":", "list", "(", "features", ".", "parameters", "(", ")", ")", ",", "'lr'", ":", "meta_feature_lr", "}", "]", ")", "\n", "\n", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "iters", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "iters", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "\n", "for", "task", "in", "range", "(", "meta_bsz", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-testing loss", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.Lambda.__init__": [[28, 31], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["\n", "    ", "def", "__init__", "(", "self", ",", "fn", ")", ":", "\n", "        ", "super", "(", "Lambda", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fn", "=", "fn", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.Lambda.forward": [[32, 34], ["ITD-BiO.Lambda.fn"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "fn", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.accuracy": [[36, 39], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["\n", "", "", "def", "accuracy", "(", "predictions", ",", "targets", ")", ":", "\n", "    ", "predictions", "=", "predictions", ".", "argmax", "(", "dim", "=", "1", ")", ".", "view", "(", "targets", ".", "shape", ")", "\n", "return", "(", "predictions", "==", "targets", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "/", "targets", ".", "size", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.fast_adapt": [[69, 107], ["torch.nn.Linear", "torch.nn.Linear.to", "features", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "torch.nn.Linear.", "loss", "ITD-BiO.accuracy", "features.to", "labels.to", "features.size", "loss", "ITD-BiO.task_adapt", "torch.nn.Linear.", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.task_adapt"], ["for", "p", "in", "learner", ".", "parameters", "(", ")", ":", "\n", "            ", "l2_reg", "+=", "p", ".", "norm", "(", "2", ")", "\n", "", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "+", "reg_lambda", "*", "l2_reg", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n", "", "predictions", "=", "learner", "(", "evaluation_data", ")", "\n", "valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n", "\n", "", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "meta_lr", "=", "0.002", ",", "\n", "fast_lr", "=", "0.1", ",", "# original 0.1", "\n", "reg_lambda", "=", "0", ",", "\n", "adapt_steps", "=", "5", ",", "# original: 5", "\n", "meta_bsz", "=", "32", ",", "\n", "iters", "=", "1000", ",", "# orginal: 1000", "\n", "cuda", "=", "1", ",", "\n", "seed", "=", "42", ",", "\n", ")", ":", "\n", "\n", "    ", "cuda", "=", "bool", "(", "cuda", ")", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.main": [[109, 280], ["print", "bool", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.ConvBase", "torch.nn.Sequential", "torch.nn.Sequential.to", "list", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "ITD-BiO.Lambda", "torch.nn.Sequential.parameters", "torch.optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "torch.optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "str", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.data.TaskDataset.sample", "ITD-BiO.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_", "x.view", "str", "str"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n", "RemapLabels", "(", "train_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "\n", "# Create model", "\n", "# features = l2l.vision.models.MiniImagenetCNN(ways)", "\n", "features", "=", "l2l", ".", "vision", ".", "models", ".", "ConvBase", "(", "output_size", "=", "32", ",", "channels", "=", "3", ",", "max_pool", "=", "True", ")", "\n", "# for p in  features.parameters():", "\n", "#     print(p.shape)", "\n", "features", "=", "torch", ".", "nn", ".", "Sequential", "(", "features", ",", "Lambda", "(", "lambda", "x", ":", "x", ".", "view", "(", "-", "1", ",", "1600", ")", ")", ")", "\n", "features", ".", "to", "(", "device", ")", "\n", "head", "=", "torch", ".", "nn", ".", "Linear", "(", "1600", ",", "ways", ")", "\n", "head", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "head", ",", "lr", "=", "fast_lr", ")", "\n", "head", ".", "to", "(", "device", ")", "\n", "\n", "# Setup optimization", "\n", "all_parameters", "=", "list", "(", "features", ".", "parameters", "(", ")", ")", "\n", "\n", "# optimizer = torch.optim.Adam(all_parameters, lr=meta_lr)", "\n", "\n", "## use different learning rates for w and theta", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "all_parameters", ",", "lr", "=", "meta_lr", ")", "\n", "\n", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "iters", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "iters", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "iters", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "\n", "for", "task", "in", "range", "(", "meta_bsz", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-testing loss", "\n", "learner", "=", "head", ".", "clone", "(", ")", "\n", "batch", "=", "test_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adapt_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_test_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_test_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "", "training_accuracy", "[", "iteration", "]", "=", "meta_train_accuracy", "/", "meta_bsz", "\n", "test_accuracy", "[", "iteration", "]", "=", "meta_test_accuracy", "/", "meta_bsz", "\n", "\n", "# Print some metrics", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Iteration'", ",", "iteration", ")", "\n", "print", "(", "'Meta Train Error'", ",", "meta_train_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Train Accuracy'", ",", "meta_train_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Error'", ",", "meta_valid_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Valid Accuracy'", ",", "meta_valid_accuracy", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Error'", ",", "meta_test_error", "/", "meta_bsz", ")", "\n", "print", "(", "'Meta Test Accuracy'", ",", "meta_test_accuracy", "/", "meta_bsz", ")", "\n", "\n", "# Average the accumulated gradients and optimize", "\n", "for", "p", "in", "all_parameters", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "1.0", "/", "meta_bsz", ")", "\n", "\n", "# print('head')", "\n", "# for p in list(head.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "# print('feature')", "\n", "# for p in list(features.parameters()):", "\n", "#     print(torch.max(torch.abs(p.grad.data)))", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "running_time", "[", "iteration", "]", "=", "end_time", "-", "start_time", "\n", "print", "(", "'total running time'", ",", "end_time", "-", "start_time", ")", "\n", "\n", "", "return", "training_accuracy", ".", "numpy", "(", ")", ",", "test_accuracy", ".", "numpy", "(", ")", ",", "running_time", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "train_accuracy", "=", "[", "]", "\n", "test_accuracy", "=", "[", "]", "\n", "run_time", "=", "[", "]", "\n", "\n", "seeds", "=", "[", "42", ",", "52", ",", "62", ",", "72", ",", "82", "]", "\n", "stp", "=", "10", "# 10 -> fastlr=0.05, 5 -> fastlr=0.1", "\n", "lr", "=", "0.002", "\n", "fastlr", "=", "0.05", "\n", "reg", "=", "0", "\n", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "training_accuracy", ",", "testing_accuracy", ",", "running_time", "=", "main", "(", "meta_lr", "=", "lr", ",", "\n", "adapt_steps", "=", "stp", ",", "\n", "fast_lr", "=", "fastlr", ",", "\n", "reg_lambda", "=", "reg", ",", "\n", "iters", "=", "2000", ",", "\n", "seed", "=", "seed", ")", "\n", "train_accuracy", ".", "append", "(", "training_accuracy", ")", "\n", "test_accuracy", ".", "append", "(", "testing_accuracy", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__": [[19, 22], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.__init__"], ["\n", "", "def", "fast_adapt", "(", "batch", ",", "learner", ",", "loss", ",", "adaptation_steps", ",", "shots", ",", "ways", ",", "device", ")", ":", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.Lambda.forward": [[23, 25], ["maml.Lambda.fn"], "methods", ["None"], ["\n", "# Separate data into adaptation/evalutation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy": [[26, 29], ["predictions.argmax().view.argmax().view", "targets.size", "predictions.argmax().view.argmax"], "function", ["None"], ["adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt": [[31, 55], ["numpy.zeros", "torch.from_numpy", "torch.from_numpy", "range", "learner", "loss", "len", "maml.accuracy", "data.to", "labels.to", "data.size", "loss", "len", "learner.adapt", "learner", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.accuracy"], ["\n", "# Adapt the model", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "train_error", "=", "loss", "(", "learner", "(", "adaptation_data", ")", ",", "adaptation_labels", ")", "\n", "train_error", "/=", "len", "(", "adaptation_data", ")", "\n", "learner", ".", "adapt", "(", "train_error", ")", "\n", "\n", "# Evaluate the adapted model", "\n", "", "predictions", "=", "learner", "(", "evaluation_data", ")", "\n", "valid_error", "=", "loss", "(", "predictions", ",", "evaluation_labels", ")", "\n", "valid_error", "/=", "len", "(", "evaluation_data", ")", "\n", "valid_accuracy", "=", "accuracy", "(", "predictions", ",", "evaluation_labels", ")", "\n", "return", "valid_error", ",", "valid_accuracy", "\n", "\n", "\n", "", "def", "main", "(", "\n", "ways", "=", "5", ",", "\n", "shots", "=", "5", ",", "\n", "meta_lr", "=", "0.003", ",", "\n", "fast_lr", "=", "0.5", ",", "\n", "meta_batch_size", "=", "32", ",", "\n", "adaptation_steps", "=", "1", ",", "\n", "num_iterations", "=", "60000", ",", "\n", "cuda", "=", "True", ",", "\n", "seed", "=", "42", ",", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.main": [[57, 226], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.device", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.vision.datasets.FC100", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.MetaDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.data.TaskDataset", "learn2learn.vision.models.ConvBase", "torch.nn.Sequential", "torch.nn.Sequential.to", "learn2learn.algorithms.MAML", "torch.optim.Adam", "torch.nn.CrossEntropyLoss", "torch.ones", "torch.ones", "numpy.ones", "time.time", "range", "torch.cuda.device_count", "torch.cuda.manual_seed", "torch.device", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.ConsecutiveLabels", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.FusedNWaysKShots", "learn2learn.data.transforms.LoadData", "learn2learn.data.transforms.RemapLabels", "learn2learn.data.transforms.ConsecutiveLabels", "maml.Lambda", "torch.nn.Linear", "l2l.algorithms.MAML.parameters", "optim.Adam.zero_grad", "range", "print", "print", "print", "print", "print", "print", "print", "print", "l2l.algorithms.MAML.parameters", "optim.Adam.step", "time.time", "print", "torch.ones.numpy", "torch.ones.numpy", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.backward", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "l2l.algorithms.MAML.clone", "l2l.data.TaskDataset.sample", "maml.fast_adapt", "evaluation_error.item", "evaluation_accuracy.item", "p.grad.data.mul_", "x.view"], "function", ["home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.hypergrad.diff_optimizers.GradientDescent.step", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt", "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.maml.fast_adapt"], ["    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "cuda", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# Create Datasets", "\n", "", "train_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'train'", ")", "\n", "valid_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'validation'", ")", "\n", "test_dataset", "=", "l2l", ".", "vision", ".", "datasets", ".", "MiniImagenet", "(", "root", "=", "'~/data'", ",", "mode", "=", "'test'", ")", "\n", "train_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "train_dataset", ")", "\n", "valid_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "valid_dataset", ")", "\n", "test_dataset", "=", "l2l", ".", "data", ".", "MetaDataset", "(", "test_dataset", ")", "\n", "\n", "train_transforms", "=", "[", "\n", "NWays", "(", "train_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "train_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "train_dataset", ")", ",", "\n", "RemapLabels", "(", "train_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "train_dataset", ")", ",", "\n", "]", "\n", "train_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "train_dataset", ",", "\n", "task_transforms", "=", "train_transforms", ",", "\n", "num_tasks", "=", "20000", ")", "\n", "\n", "valid_transforms", "=", "[", "\n", "NWays", "(", "valid_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "valid_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "valid_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "valid_dataset", ")", ",", "\n", "RemapLabels", "(", "valid_dataset", ")", ",", "\n", "]", "\n", "valid_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "valid_dataset", ",", "\n", "task_transforms", "=", "valid_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "test_transforms", "=", "[", "\n", "NWays", "(", "test_dataset", ",", "ways", ")", ",", "\n", "KShots", "(", "test_dataset", ",", "2", "*", "shots", ")", ",", "\n", "LoadData", "(", "test_dataset", ")", ",", "\n", "RemapLabels", "(", "test_dataset", ")", ",", "\n", "ConsecutiveLabels", "(", "test_dataset", ")", ",", "\n", "]", "\n", "test_tasks", "=", "l2l", ".", "data", ".", "TaskDataset", "(", "test_dataset", ",", "\n", "task_transforms", "=", "test_transforms", ",", "\n", "num_tasks", "=", "600", ")", "\n", "\n", "# Create model", "\n", "model", "=", "l2l", ".", "vision", ".", "models", ".", "MiniImagenetCNN", "(", "ways", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "maml", "=", "l2l", ".", "algorithms", ".", "MAML", "(", "model", ",", "lr", "=", "fast_lr", ",", "first_order", "=", "False", ")", "\n", "opt", "=", "optim", ".", "Adam", "(", "maml", ".", "parameters", "(", ")", ",", "meta_lr", ")", "\n", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "\n", "training_accuracy", "=", "torch", ".", "ones", "(", "num_iterations", ")", "\n", "test_accuracy", "=", "torch", ".", "ones", "(", "num_iterations", ")", "\n", "running_time", "=", "np", ".", "ones", "(", "num_iterations", ")", "\n", "import", "time", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "iteration", "in", "range", "(", "num_iterations", ")", ":", "\n", "        ", "opt", ".", "zero_grad", "(", ")", "\n", "meta_train_error", "=", "0.0", "\n", "meta_train_accuracy", "=", "0.0", "\n", "meta_valid_error", "=", "0.0", "\n", "meta_valid_accuracy", "=", "0.0", "\n", "meta_test_error", "=", "0.0", "\n", "meta_test_accuracy", "=", "0.0", "\n", "for", "task", "in", "range", "(", "meta_batch_size", ")", ":", "\n", "# Compute meta-training loss", "\n", "            ", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "train_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "evaluation_error", ".", "backward", "(", ")", "\n", "meta_train_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_train_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-validation loss", "\n", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "valid_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_valid_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_valid_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "# Compute meta-test loss", "\n", "learner", "=", "maml", ".", "clone", "(", ")", "\n", "batch", "=", "test_tasks", ".", "sample", "(", ")", "\n", "evaluation_error", ",", "evaluation_accuracy", "=", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "loss", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", ")", "\n", "meta_test_error", "+=", "evaluation_error", ".", "item", "(", ")", "\n", "meta_test_accuracy", "+=", "evaluation_accuracy", ".", "item", "(", ")", "\n", "\n", "", "training_accuracy", "[", "iteration", "]", "=", "meta_train_accuracy", "/", "meta_batch_size", "\n", "test_accuracy", "[", "iteration", "]", "=", "meta_test_accuracy", "/", "meta_batch_size", "\n", "\n", "# Print some metrics", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Iteration'", ",", "iteration", ")", "\n", "print", "(", "'Meta Train Error'", ",", "meta_train_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Train Accuracy'", ",", "meta_train_accuracy", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Valid Error'", ",", "meta_valid_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Valid Accuracy'", ",", "meta_valid_accuracy", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Test Error'", ",", "meta_test_error", "/", "meta_batch_size", ")", "\n", "print", "(", "'Meta Test Accuracy'", ",", "meta_test_accuracy", "/", "meta_batch_size", ")", "\n", "\n", "# Average the accumulated gradients and optimize", "\n", "for", "p", "in", "maml", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "grad", ".", "data", ".", "mul_", "(", "1.0", "/", "meta_batch_size", ")", "\n", "", "opt", ".", "step", "(", ")", "\n", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "running_time", "[", "iteration", "]", "=", "end_time", "-", "start_time", "\n", "print", "(", "'total running time'", ",", "end_time", "-", "start_time", ")", "\n", "\n", "# meta_test_error = 0.0", "\n", "# meta_test_accuracy = 0.0", "\n", "# for task in range(meta_batch_size):", "\n", "#     # Compute meta-testing loss", "\n", "#     learner = maml.clone()", "\n", "#     batch = test_tasks.sample()", "\n", "#     evaluation_error, evaluation_accuracy = fast_adapt(batch,", "\n", "#                                                       learner,", "\n", "#                                                       loss,", "\n", "#                                                       adaptation_steps,", "\n", "#                                                       shots,", "\n", "#                                                       ways,", "\n", "#                                                       device)", "\n", "#     meta_test_error += evaluation_error.item()", "\n", "#     meta_test_accuracy += evaluation_accuracy.item()", "\n", "# print('Meta Test Error', meta_test_error / meta_batch_size)", "\n", "# print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)", "\n", "\n", "", "return", "training_accuracy", ".", "numpy", "(", ")", ",", "test_accuracy", ".", "numpy", "(", ")", ",", "running_time", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "train_accuracy", "=", "[", "]", "\n", "test_accuracy", "=", "[", "]", "\n", "run_time", "=", "[", "]", "\n", "\n", "seeds", "=", "[", "42", ",", "52", ",", "62", ",", "72", ",", "82", "]", "\n", "lr", "=", "0.003", "\n", "fastlr", "=", "0.01", "# before: fastlr=0.5 & step=3 ", "\n", "stp", "=", "5", "\n", "\n", "for", "seed", "in", "seeds", ":", "\n", "        ", "training_accuracy", ",", "testing_accuracy", ",", "running_time", "=", "main", "(", "meta_lr", "=", "lr", ",", "\n", "fast_lr", "=", "fastlr", ",", "\n", "adaptation_steps", "=", "stp", ",", "\n", "num_iterations", "=", "1200", ",", "\n", "seed", "=", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.junjieyang97_stocbio_hp.fc100.ITD-BiO.task_adapt": [[40, 68], ["model._apply", "torch.autograd.grad", "list", "zip", "model.parameters", "traceback.print_exc", "model.parameters", "print", "len", "len", "list", "str", "str", "len", "len"], "function", ["None"], ["\n", "\n", "", "def", "fast_adapt", "(", "batch", ",", "\n", "learner", ",", "\n", "features", ",", "\n", "loss", ",", "\n", "reg_lambda", ",", "\n", "adaptation_steps", ",", "\n", "shots", ",", "\n", "ways", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "data", ",", "labels", "=", "batch", "\n", "data", ",", "labels", "=", "data", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "# print('before_data_size=' + str(data.size(0)))", "\n", "\n", "data", "=", "features", "(", "data", ")", "\n", "\n", "# Separate data into adaptation/evaluation sets", "\n", "adaptation_indices", "=", "np", ".", "zeros", "(", "data", ".", "size", "(", "0", ")", ",", "dtype", "=", "bool", ")", "\n", "# print('data_size=' + str(data.size(0)))", "\n", "adaptation_indices", "[", "np", ".", "arange", "(", "shots", "*", "ways", ")", "*", "2", "]", "=", "True", "\n", "evaluation_indices", "=", "torch", ".", "from_numpy", "(", "~", "adaptation_indices", ")", "\n", "adaptation_indices", "=", "torch", ".", "from_numpy", "(", "adaptation_indices", ")", "\n", "adaptation_data", ",", "adaptation_labels", "=", "data", "[", "adaptation_indices", "]", ",", "labels", "[", "adaptation_indices", "]", "\n", "evaluation_data", ",", "evaluation_labels", "=", "data", "[", "evaluation_indices", "]", ",", "labels", "[", "evaluation_indices", "]", "\n", "\n", "for", "step", "in", "range", "(", "adaptation_steps", ")", ":", "\n", "        ", "l2_reg", "=", "0", "\n"]]}