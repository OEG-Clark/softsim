{"home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.Aug_dataset.__init__": [[179, 221], ["root_seg.replace", "range", "print", "len", "print", "print", "imgaug.Sequential", "imgaug.Sequential", "len", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "len", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "f.endswith", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "range", "str", "imgaug.Resize", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Crop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_seg", ",", "transform", ",", "transform_seg", ",", "train", "=", "True", ",", "hflip", "=", "False", ",", "ext", "=", "'.jpg'", ",", "prefix", "=", "''", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "transform_seg", "=", "transform_seg", "\n", "self", ".", "hflip", "=", "hflip", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "pad_factor", "=", "pad_factor", "\n", "\n", "self", ".", "root_dir", "=", "root_seg", ".", "replace", "(", "\"_seg\"", ",", "\"\"", ")", "\n", "self", ".", "seg_dir", "=", "root_seg", "\n", "\n", "dir_imgs", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "seg_dir", ")", "if", "f", ".", "endswith", "(", "self", ".", "ext", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dir_imgs", ")", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", ")", ")", ":", "\n", "                ", "start", "=", "i", "\n", "break", "\n", "\n", "", "", "assert", "start", ">=", "0", "\n", "print", "(", "\"start \"", "+", "str", "(", "start", ")", ")", "\n", "end", "=", "len", "(", "dir_imgs", ")", "\n", "print", "(", "\"end \"", "+", "str", "(", "end", ")", ")", "\n", "self", ".", "imgs", "=", "[", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", "for", "i", "in", "range", "(", "start", ",", "start", "+", "end", ")", "]", "\n", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "imgs", ")", "-", "1", "\n", "print", "(", "\"Data size is \"", "+", "str", "(", "self", ".", "size", ")", ")", "\n", "\n", "self", ".", "seq", "=", "iaa", ".", "Sequential", "(", "[", "\n", "iaa", ".", "Resize", "(", "(", "0.8", ",", "1.1", ")", ")", ",", "\n", "iaa", ".", "Affine", "(", "rotate", "=", "(", "-", "20", ",", "20", ")", ")", ",", "\n", "iaa", ".", "Affine", "(", "translate_px", "=", "{", "\"x\"", ":", "(", "-", "50", ",", "50", ")", ",", "\"y\"", ":", "(", "-", "50", ",", "50", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "shear", "=", "{", "\"x\"", ":", "(", "-", "15", ",", "15", ")", ",", "\"y\"", ":", "(", "-", "15", ",", "15", ")", "}", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "seq2", "=", "iaa", ".", "Sequential", "(", "[", "\n", "#iaa.PerspectiveTransform(scale=(0.01, 0.05)),  # CHange max to 0.1? Could be bit excessive", "\n", "iaa", ".", "Affine", "(", "scale", "=", "{", "\"x\"", ":", "(", "0.8", ",", "1.2", ")", ",", "\"y\"", ":", "(", "0.8", ",", "1.2", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "translate_px", "=", "{", "\"x\"", ":", "(", "-", "50", ",", "50", ")", ",", "\"y\"", ":", "(", "-", "50", ",", "50", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "shear", "=", "{", "\"x\"", ":", "(", "-", "20", ",", "20", ")", ",", "\"y\"", ":", "(", "-", "20", ",", "20", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "rotate", "=", "(", "-", "20", ",", "20", ")", ")", ",", "\n", "iaa", ".", "Crop", "(", "percent", "=", "(", "0.0001", ",", "0.05", ")", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.Aug_dataset.__len__": [[223, 225], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.Aug_dataset.__getitem__": [[226, 261], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "random.random", "seg1.transpose.transpose.convert", "seg2.transpose.transpose.convert", "train_second_stage.Aug_dataset.transform", "train_second_stage.Aug_dataset.transform", "train_second_stage.Aug_dataset.transform_seg", "train_second_stage.Aug_dataset.transform_seg", "train_second_stage.augment", "train_second_stage.augment", "pair1.transpose.transpose.transpose", "seg1.transpose.transpose.transpose", "pair2.transpose.transpose.transpose", "seg2.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "name1", "=", "self", ".", "imgs", "[", "idx", "]", "\n", "name2", "=", "self", ".", "imgs", "[", "idx", "+", "1", "]", "\n", "img1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "name1", ")", "\n", "img2_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "name2", ")", "\n", "seg1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "name1", ")", "\n", "seg2_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "name2", ")", "\n", "\n", "r_", "=", "random", ".", "random", "(", ")", "\n", "if", "r_", ">", "0.6", ":", "\n", "            ", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "=", "augment", "(", "img1_path", ",", "img2_path", ",", "seg1_path", ",", "seg2_path", ",", "self", ".", "seq2", ",", "pad_factor", "=", "self", ".", "pad_factor", ")", "\n", "", "else", ":", "\n", "            ", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "=", "augment", "(", "img1_path", ",", "img2_path", ",", "seg1_path", ",", "seg2_path", ",", "self", ".", "seq", ",", "pad_factor", "=", "self", ".", "pad_factor", ")", "\n", "\n", "", "seg1", "=", "seg1", ".", "convert", "(", "'RGB'", ")", "\n", "seg2", "=", "seg2", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "self", ".", "hflip", "and", "self", ".", "train", ":", "\n", "            ", "pair1", "=", "pair1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "seg1", "=", "seg1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "pair2", "=", "pair2", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "seg2", "=", "seg2", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "", "pair1", "=", "self", ".", "transform", "(", "pair1", ")", "\n", "pair2", "=", "self", ".", "transform", "(", "pair2", ")", "\n", "seg1", "=", "self", ".", "transform_seg", "(", "seg1", ")", "\n", "seg2", "=", "self", ".", "transform_seg", "(", "seg2", ")", "\n", "\n", "seg1", "=", "(", "seg1", ">", "0.5", ")", ".", "float", "(", ")", "\n", "seg2", "=", "(", "seg2", ">", "0.5", ")", ".", "float", "(", ")", "\n", "\n", "pair1", "=", "pair1", "*", "seg1", "\n", "pair2", "=", "pair2", "*", "seg2", "\n", "\n", "return", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.save_model": [[26, 38], ["torch.save", "torch.save", "G_A.state_dict", "R_A.state_dict", "R_B.state_dict", "KP.state_dict", "g_opt2.state_dict"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save"], ["def", "save_model", "(", "out_file", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ",", "g_opt2", ",", "learned_t", ",", "epoch", ")", ":", "\n", "    ", "state", "=", "{", "\n", "'G_A'", ":", "G_A", ".", "state_dict", "(", ")", ",", "\n", "'R_A'", ":", "R_A", ".", "state_dict", "(", ")", ",", "\n", "'R_B'", ":", "R_B", ".", "state_dict", "(", ")", ",", "\n", "'KP'", ":", "KP", ".", "state_dict", "(", ")", ",", "\n", "'g_opt2'", ":", "g_opt2", ".", "state_dict", "(", ")", ",", "\n", "'learned_t'", ":", "learned_t", ",", "\n", "'epoch'", ":", "epoch", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "out_file", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.load_first_stage": [[40, 45], ["torch.load", "torch.load", "G_A.load_state_dict", "KP.load_state_dict"], "function", ["None"], ["", "def", "load_first_stage", "(", "load_path", ",", "G_A", ",", "KP", ")", ":", "\n", "    ", "state", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "G_A", ".", "load_state_dict", "(", "state", "[", "'G_A'", "]", ")", "\n", "KP", ".", "load_state_dict", "(", "state", "[", "'KP'", "]", ")", "\n", "return", "state", "[", "'epoch'", "]", ",", "state", "[", "'learned_t'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.load_model": [[47, 55], ["torch.load", "torch.load", "G_A.load_state_dict", "R_A.load_state_dict", "R_B.load_state_dict", "KP.load_state_dict", "g_opt2.load_state_dict"], "function", ["None"], ["", "def", "load_model", "(", "load_path", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ",", "g_opt2", ")", ":", "\n", "    ", "state", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "G_A", ".", "load_state_dict", "(", "state", "[", "'G_A'", "]", ")", "\n", "R_A", ".", "load_state_dict", "(", "state", "[", "'R_A'", "]", ")", "\n", "R_B", ".", "load_state_dict", "(", "state", "[", "'R_B'", "]", ")", "\n", "KP", ".", "load_state_dict", "(", "state", "[", "'KP'", "]", ")", "\n", "g_opt2", ".", "load_state_dict", "(", "state", "[", "'g_opt2'", "]", ")", "\n", "return", "state", "[", "'epoch'", "]", ",", "state", "[", "'learned_t'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.make_coordinate_grid": [[56, 73], ["torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type.view().repeat", "torch.arange().type.view().repeat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().type.view", "torch.arange().type.view", "x.view().repeat.unsqueeze_", "y.view().repeat.unsqueeze_", "torch.float", "torch.float"], "function", ["None"], ["", "def", "make_coordinate_grid", "(", "spatial_size", ",", "type", ")", ":", "\n", "    ", "\"\"\"\n    Create a meshgrid [-1,1] x [-1,1] of given spatial_size.\n    \"\"\"", "\n", "h", ",", "w", "=", "spatial_size", "\n", "x", "=", "torch", ".", "arange", "(", "w", ")", ".", "type", "(", "type", ")", "\n", "y", "=", "torch", ".", "arange", "(", "h", ")", ".", "type", "(", "type", ")", "\n", "\n", "x", "=", "(", "2", "*", "(", "x", "/", "(", "w", "-", "1", ")", ")", "-", "1", ")", "\n", "y", "=", "(", "2", "*", "(", "y", "/", "(", "h", "-", "1", ")", ")", "-", "1", ")", "\n", "\n", "yy", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "w", ")", "\n", "xx", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "h", ",", "1", ")", "\n", "\n", "meshed", "=", "torch", ".", "cat", "(", "[", "xx", ".", "unsqueeze_", "(", "2", ")", ",", "yy", ".", "unsqueeze_", "(", "2", ")", "]", ",", "2", ")", "\n", "\n", "return", "meshed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.norm": [[74, 80], ["var.cpu().detach.cpu().detach", "var.cpu().detach.cpu"], "function", ["None"], ["", "def", "norm", "(", "var", ")", ":", "\n", "    ", "var", "=", "var", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "var", "=", "(", "(", "var", "+", "1", ")", "/", "2", ")", "\n", "var", "[", "var", "<", "0", "]", "=", "0", "\n", "var", "[", "var", ">", "1", "]", "=", "1", "\n", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.kp_to_heatmap": [[82, 106], ["x.unsqueeze().unsqueeze", "make_coordinate_grid().unsqueeze().unsqueeze().repeat().cuda", "torch.abs", "torch.abs", "torch.exp", "torch.exp", "x.unsqueeze().unsqueeze.size", "x.unsqueeze().unsqueeze.size", "torch.max", "torch.max", "x.unsqueeze", "make_coordinate_grid().unsqueeze().unsqueeze().repeat", "z.size", "z.size", "z.size", "z.size", "make_coordinate_grid().unsqueeze().unsqueeze", "make_coordinate_grid().unsqueeze", "train_second_stage.make_coordinate_grid"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["", "def", "kp_to_heatmap", "(", "x", ",", "spatial_size", "=", "256", ",", "std", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n\n    :param kp: bs X num_kp X 2\n    :param spatial_size: int\n    :param std: float\n    :return: bs X num_kp X spatial_size X spatial_size\n    \"\"\"", "\n", "kp", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "#print(kp.size())", "\n", "ss", "=", "spatial_size", "\n", "bs", ",", "num_kp", "=", "kp", ".", "size", "(", "0", ")", ",", "kp", ".", "size", "(", "1", ")", "\n", "grid", "=", "make_coordinate_grid", "(", "(", "ss", ",", "ss", ")", ",", "torch", ".", "float", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "bs", ",", "num_kp", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", "# Range -1, 1", "\n", "#kp = (kp / float(ss)) * 2 - 1", "\n", "#print(kp.size())", "\n", "#print(grid.size())", "\n", "y", "=", "torch", ".", "abs", "(", "grid", "-", "kp", ")", "\n", "y", "=", "torch", ".", "exp", "(", "-", "y", "/", "(", "std", "**", "2", ")", ")", "\n", "z", "=", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "*", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "z", "=", "z", "/", "torch", ".", "max", "(", "z", ")", "\n", "\n", "assert", "bs", "==", "z", ".", "size", "(", "0", ")", "and", "num_kp", "==", "z", ".", "size", "(", "1", ")", "and", "ss", "==", "z", ".", "size", "(", "2", ")", "and", "ss", "==", "z", ".", "size", "(", "3", ")", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.transform_kp": [[108, 115], ["theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "transformed.squeeze.squeeze", "torch.matmul", "torch.matmul", "coordinates.unsqueeze"], "function", ["None"], ["", "def", "transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "    ", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "torch", ".", "matmul", "(", "theta", "[", ":", ",", ":", ",", ":", ",", ":", "2", "]", ",", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", ")", "+", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.inverse_transform_kp": [[116, 128], ["torch.inverse", "torch.inverse", "theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "inverse.unsqueeze.repeat", "inverse.unsqueeze.unsqueeze", "torch.matmul", "torch.matmul", "transformed.squeeze.squeeze", "coordinates.unsqueeze"], "function", ["None"], ["", "def", "inverse_transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "\n", "    ", "inverse", "=", "torch", ".", "inverse", "(", "theta", "[", ":", ",", ":", ",", ":", "2", "]", ")", "\n", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "inverse", "=", "inverse", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "inverse", "=", "inverse", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", "-", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "torch", ".", "matmul", "(", "inverse", ",", "transformed", ")", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.augment": [[129, 174], ["cv2.imread", "cv2.imread", "aug.to_deterministic", "aug.to_deterministic.", "aug.to_deterministic.", "numpy.stack", "numpy.stack", "cv2.cvtColor", "PIL.Image.fromarray", "cv2.cvtColor", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "cv2.imread", "cv2.imread", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "cv2.imread", "cv2.imread", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "function", ["None"], ["", "def", "augment", "(", "path", ",", "path2", ",", "seg_path", ",", "seg_path2", ",", "aug", ",", "pad", "=", "True", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "\n", "    ", "img", "=", "cv2", ".", "imread", "(", "path", ")", "\n", "img2", "=", "cv2", ".", "imread", "(", "path2", ")", "\n", "\n", "\n", "if", "pad", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "\n", "seg2", "=", "cv2", ".", "imread", "(", "seg_path2", ")", "\n", "w", ",", "h", "=", "img", ".", "shape", "[", "0", "]", ",", "img", ".", "shape", "[", "1", "]", "\n", "img", "=", "cv2", ".", "copyMakeBorder", "(", "img", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "img2", "=", "cv2", ".", "copyMakeBorder", "(", "img2", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "seg", "=", "cv2", ".", "copyMakeBorder", "(", "seg", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "\n", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg2", "=", "cv2", ".", "copyMakeBorder", "(", "seg2", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "\n", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg", "=", "seg", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "seg2", "=", "seg2", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "seg2", "=", "cv2", ".", "imread", "(", "seg_path2", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "\n", "\n", "", "aug_i", "=", "aug", ".", "to_deterministic", "(", ")", "\n", "img", ",", "seg", "=", "aug_i", "(", "images", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "0", ")", ",", "segmentation_maps", "=", "np", ".", "expand_dims", "(", "seg", ",", "axis", "=", "0", ")", ")", "\n", "img2", ",", "seg2", "=", "aug_i", "(", "images", "=", "np", ".", "expand_dims", "(", "img2", ",", "axis", "=", "0", ")", ",", "segmentation_maps", "=", "np", ".", "expand_dims", "(", "seg2", ",", "axis", "=", "0", ")", ")", "\n", "\n", "img", "=", "img", "[", "0", "]", "\n", "seg", "=", "seg", "[", "0", "]", "\n", "img2", "=", "img2", "[", "0", "]", "\n", "seg2", "=", "seg2", "[", "0", "]", "\n", "\n", "seg", "=", "np", ".", "stack", "(", "(", "seg", "[", ":", ",", ":", ",", "0", "]", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "seg2", "=", "np", ".", "stack", "(", "(", "seg2", "[", ":", ",", ":", ",", "0", "]", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "im_pil", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "img2", "=", "cv2", ".", "cvtColor", "(", "img2", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "im_pil2", "=", "Image", ".", "fromarray", "(", "img2", ")", "\n", "\n", "seg_pil", "=", "Image", ".", "fromarray", "(", "seg", ")", "\n", "seg_pil2", "=", "Image", ".", "fromarray", "(", "seg2", ")", "\n", "\n", "return", "im_pil", ",", "im_pil2", ",", "seg_pil", ",", "seg_pil2", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.vis_points": [[263, 269], ["train_second_stage.norm", "kpoints.data.cpu().numpy", "numpy.transpose", "viz.create_image_column_with_kp", "kpoints.data.cpu"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column_with_kp"], ["", "", "def", "vis_points", "(", "viz", ",", "img", ",", "kpoints", ")", ":", "\n", "    ", "source", "=", "norm", "(", "img", ".", "data", ")", "\n", "kp_source", "=", "kpoints", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "source", "=", "np", ".", "transpose", "(", "source", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "viz", ".", "create_image_column_with_kp", "(", "source", ",", "kp_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.train": [[273, 462], ["print", "tran_list.append", "tran_list.append", "tran_list.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "train_second_stage.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_second_stage.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "modules.keypoint_detector_strong.KPDetector_strong.requires_grad_", "models.define_G", "G_A.eval.requires_grad_", "models.define_G", "models.define_G", "torch.nn.L1Loss().cuda", "lpips.LPIPS().cuda", "lpips.LPIPS().cuda.requires_grad_", "G_A.eval.cuda", "modules.keypoint_detector_strong.KPDetector_strong.cuda", "R_A.train.cuda", "R_B.train.cuda", "torch.optim.Adam", "util.visualizer_kp.Visualizer", "modules.keypoint_detector_strong.KPDetector_strong.train", "G_A.eval.eval", "R_A.train.train", "R_B.train.train", "print", "range", "print", "os.path.join", "os.path.join", "train_second_stage.save_model", "print", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize", "modules.keypoint_detector_heatmap.KPDetector", "modules.keypoint_detector_strong.KPDetector_strong", "list", "list", "train_second_stage.load_model", "print", "train_second_stage.load_first_stage", "zip", "torch.nn.L1Loss", "lpips.LPIPS", "R_A.train.parameters", "R_B.train.parameters", "img_a.cuda.cuda", "img_b.cuda.cuda", "seg_a.cuda.cuda", "seg_b.cuda.cuda", "optim.Adam.zero_grad", "R_A.train.", "R_B.train.", "loss_g.backward", "optim.Adam.step", "str", "torch.no_grad", "torch.no_grad", "modules.keypoint_detector_strong.KPDetector_strong.", "modules.keypoint_detector_strong.KPDetector_strong.", "train_second_stage.kp_to_heatmap", "train_second_stage.kp_to_heatmap", "G_A.eval.", "G_A.eval.", "print", "print", "sys.stdout.flush", "print", "sys.stdout.flush", "torch.cat", "torch.cat", "torchvision.save_image", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "torch.cat", "torch.cat", "torchvision.save_image", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "os.path.join", "os.path.join", "train_second_stage.save_model", "print", "img_a.cuda.size", "img_b.cuda.size", "nn.L1Loss().cuda.", "nn.L1Loss().cuda.", "lpips.LPIPS().cuda.mean", "lpips.LPIPS().cuda.mean", "os.join", "train_second_stage.vis_points", "train_second_stage.vis_points", "os.join", "torch.no_grad", "torch.no_grad", "train_second_stage.transform_kp", "train_second_stage.inverse_transform_kp", "train_second_stage.kp_to_heatmap", "train_second_stage.kp_to_heatmap", "G_A.eval.", "G_A.eval.", "R_B.train.", "R_A.train.", "os.join", "train_second_stage.vis_points", "train_second_stage.vis_points", "os.join", "img_b.cuda.size", "img_a.cuda.size", "str", "lpips.LPIPS().cuda.", "lpips.LPIPS().cuda.", "float", "float", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.save_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.load_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_second_stage.load_first_stage", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.save_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.inverse_transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points"], ["", "def", "train", "(", "args", ",", "opt", "=", "None", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "out", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "out", ")", "\n", "\n", "", "print", "(", "sys", ".", "argv", ")", "\n", "\n", "tran_list", "=", "[", "]", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Resize", "(", "(", "args", ".", "resize_w", ",", "args", ".", "resize_h", ")", ")", ")", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ")", "\n", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", ")", "\n", "transform_seg", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", "[", ":", "-", "1", "]", ")", "\n", "\n", "dataset_a", "=", "Aug_dataset", "(", "args", ".", "root_a", ",", "transform", ",", "transform_seg", ",", "hflip", "=", "args", ".", "hflip", ",", "ext", "=", "args", ".", "ext_a", ",", "prefix", "=", "args", ".", "prefix_a", ",", "pad_factor", "=", "args", ".", "pad_factor_a", ")", "\n", "data_loader_a", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_a", ",", "shuffle", "=", "True", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "True", ")", "\n", "\n", "dataset_b", "=", "Aug_dataset", "(", "args", ".", "root_b", ",", "transform", ",", "transform_seg", ",", "ext", "=", "args", ".", "ext_b", ",", "prefix", "=", "args", ".", "prefix_b", ",", "pad_factor", "=", "args", ".", "pad_factor_b", ")", "\n", "data_loader_b", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_b", ",", "shuffle", "=", "True", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "True", ")", "\n", "\n", "if", "not", "args", ".", "strong_kp", ":", "\n", "        ", "KP", "=", "KPDetector", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ")", "\n", "", "else", ":", "\n", "        ", "KP", "=", "KPDetector_strong", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ",", "args", "=", "args", ")", "\n", "\n", "", "KP", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "ch_size", "=", "args", ".", "num_kp", "\n", "\n", "G_A", "=", "nets", ".", "define_G", "(", "ch_size", ",", "2", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ",", "not_mask", "=", "False", ",", "only_mask", "=", "True", ")", "\n", "G_A", ".", "requires_grad_", "(", "False", ")", "\n", "R_A", "=", "nets", ".", "define_G", "(", "args", ".", "input_nc", ",", "args", ".", "output_nc", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "new_norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ")", "\n", "\n", "R_B", "=", "nets", ".", "define_G", "(", "args", ".", "input_nc", ",", "args", ".", "output_nc", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "new_norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ")", "\n", "\n", "\n", "l1", "=", "nn", ".", "L1Loss", "(", ")", ".", "cuda", "(", ")", "\n", "#l2 = nn.MSELoss().cuda()", "\n", "criterionVGG", "=", "lpips", ".", "LPIPS", "(", "net", "=", "'vgg'", ")", ".", "cuda", "(", ")", "\n", "criterionVGG", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "G_A", "=", "G_A", ".", "cuda", "(", ")", "\n", "KP", "=", "KP", ".", "cuda", "(", ")", "\n", "R_A", "=", "R_A", ".", "cuda", "(", ")", "\n", "R_B", "=", "R_B", ".", "cuda", "(", ")", "\n", "\n", "g_params2", "=", "list", "(", "R_A", ".", "parameters", "(", ")", ")", "+", "list", "(", "R_B", ".", "parameters", "(", ")", ")", "\n", "g_opt2", "=", "optim", ".", "Adam", "(", "g_params2", ",", "lr", "=", "args", ".", "g_lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "viz", "=", "visualizer_kp", ".", "Visualizer", "(", "kp_size", "=", "args", ".", "num_kp", ")", "\n", "\n", "assert", "args", ".", "load", "!=", "''", "\n", "\n", "if", "args", ".", "load_second_stage", ":", "\n", "        ", "load_epoch", ",", "learned_t", "=", "load_model", "(", "args", ".", "load", ",", "G_A", ",", "G_B", ",", "R_A", ",", "R_B", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ",", "g_opt2", ")", "\n", "print", "(", "\"Loaded successfully, epoch=\"", "+", "str", "(", "load_epoch", ")", ")", "\n", "", "else", ":", "\n", "        ", "load_epoch", ",", "learned_t", "=", "load_first_stage", "(", "args", ".", "load", ",", "G_A", ",", "KP", ")", "\n", "\n", "\n", "", "KP", "=", "KP", ".", "train", "(", ")", "\n", "G_A", "=", "G_A", ".", "eval", "(", ")", "\n", "R_A", "=", "R_A", ".", "train", "(", ")", "\n", "R_B", "=", "R_B", ".", "train", "(", ")", "\n", "\n", "iter_cnt", "=", "0", "\n", "\n", "print", "(", "'Started training...'", ")", "\n", "for", "epoch", "in", "range", "(", "0", ",", "args", ".", "epoch", ")", ":", "\n", "\n", "        ", "if", "iter_cnt", ">", "args", ".", "iters", ":", "\n", "            ", "break", "\n", "\n", "", "for", "data_a", ",", "data_b", "in", "zip", "(", "data_loader_a", ",", "data_loader_b", ")", ":", "\n", "\n", "            ", "img_a", ",", "pair_a", ",", "seg_a", ",", "seg_pair_a", "=", "data_a", "\n", "img_b", ",", "pair_b", ",", "seg_b", ",", "seg_pair_b", "=", "data_b", "\n", "\n", "img_a", "=", "img_a", ".", "cuda", "(", ")", "\n", "img_b", "=", "img_b", ".", "cuda", "(", ")", "\n", "\n", "seg_a", "=", "seg_a", ".", "cuda", "(", ")", "\n", "seg_b", "=", "seg_b", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "                ", "kpoints_a", ",", "heatmap_a", "=", "KP", "(", "img_a", ")", "\n", "kpoints_b", ",", "heatmap_b", "=", "KP", "(", "img_b", ")", "\n", "\n", "new_heatmap_a", "=", "kp_to_heatmap", "(", "kpoints_a", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "new_heatmap_b", "=", "kp_to_heatmap", "(", "kpoints_b", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "decoded_a", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "decoded_b", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "", "g_opt2", ".", "zero_grad", "(", ")", "\n", "\n", "refined_a", "=", "R_A", "(", "decoded_a", ")", "\n", "refined_b", "=", "R_B", "(", "decoded_b", ")", "\n", "\n", "l1_rec", "=", "args", ".", "lambda_l1", "*", "(", "l1", "(", "img_a", ",", "refined_a", ")", "+", "l1", "(", "img_b", ",", "refined_b", ")", ")", "\n", "\n", "vgg_rec", "=", "args", ".", "lambda_vgg", "*", "(", "criterionVGG", "(", "img_a", ",", "refined_a", ")", ".", "mean", "(", ")", "+", "criterionVGG", "(", "img_b", ",", "refined_b", ")", ".", "mean", "(", ")", ")", "\n", "\n", "loss_g", "=", "l1_rec", "+", "vgg_rec", "\n", "\n", "loss_g", ".", "backward", "(", ")", "\n", "g_opt2", ".", "step", "(", ")", "\n", "\n", "\n", "if", "iter_cnt", "%", "args", ".", "print_loss", "==", "0", ":", "\n", "                ", "print", "(", "'Outfile: %s <<>> Iteration %d'", "%", "(", "args", ".", "out", ",", "iter_cnt", ")", ")", "\n", "print", "(", "'<<<< vgg_rec=%f <<<< l1_rec=%f'", "%", "(", "float", "(", "vgg_rec", ")", ",", "float", "(", "l1_rec", ")", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "iter_cnt", "%", "args", ".", "save_img", "==", "0", ":", "\n", "                ", "print", "(", "\"Saving imgs\"", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "exps", "=", "torch", ".", "cat", "(", "[", "seg_a", ",", "decoded_a", ",", "img_a", ",", "refined_a", ",", "seg_b", ",", "decoded_b", ",", "img_b", ",", "refined_b", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"reconstruction_\"", "+", "str", "(", "iter_cnt", ")", "+", "\".png\"", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b", ")", ")", "\n", "\n", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"%s-kp.png\"", "%", "str", "(", "iter_cnt", ")", ")", ",", "to_print", ")", "\n", "\n", "", "if", "iter_cnt", "%", "args", ".", "eval_test", "==", "0", ":", "\n", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# kpoints_a, heatmap_a = KP(img_a)", "\n", "# new_heatmap_a = kp_to_heatmap(kpoints_a, img_a.size(-1))", "\n", "#", "\n", "# kpoints_b, heatmap_b = KP(img_b)", "\n", "# new_heatmap_b = kp_to_heatmap(kpoints_b, img_b.size(-1))", "\n", "\n", "                    ", "kpoints_b_transformed", "=", "transform_kp", "(", "kpoints_b", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "kpoints_a_transformed", "=", "inverse_transform_kp", "(", "kpoints_a", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "new_heatmap_b_transformed", "=", "kp_to_heatmap", "(", "kpoints_b_transformed", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "new_heatmap_a_transformed", "=", "kp_to_heatmap", "(", "kpoints_a_transformed", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "new_heatmap_a", "=", "new_heatmap_a_transformed", "\n", "new_heatmap_b", "=", "new_heatmap_b_transformed", "\n", "\n", "_", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "_", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "refined_ab", "=", "R_B", "(", "decoded_ab", ")", "\n", "refined_ba", "=", "R_A", "(", "decoded_ba", ")", "\n", "\n", "", "exps", "=", "torch", ".", "cat", "(", "[", "img_a", ",", "decoded_ab", ",", "refined_ab", ",", "img_b", ",", "decoded_ba", ",", "refined_ba", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"test_\"", "+", "str", "(", "iter_cnt", ")", "+", "\".png\"", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ab", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ba", ",", "kpoints_b", ")", ")", "\n", "\n", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"%s-kp_test_.png\"", "%", "str", "(", "iter_cnt", ")", ")", ",", "to_print", ")", "\n", "\n", "", "if", "iter_cnt", "%", "args", ".", "save_check", "==", "0", ":", "\n", "                ", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out", ",", "'checkpoint_'", "+", "str", "(", "iter_cnt", ")", ")", "\n", "save_model", "(", "save_file", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ",", "g_opt2", ",", "learned_t", ",", "epoch", ")", "\n", "print", "(", "\"Checkpoint saved\"", ")", "\n", "\n", "", "iter_cnt", "+=", "1", "\n", "if", "iter_cnt", ">", "args", ".", "iters", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "", "print", "(", "\"Training is done\"", ")", "\n", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out", ",", "'checkpoint'", ")", "\n", "save_model", "(", "save_file", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ",", "g_opt2", ",", "learned_t", ",", "epoch", ")", "\n", "print", "(", "\"Final checkpoint saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.gen_vid.torch_to_cv2_image": [[15, 21], ["numpy.array", "open_cv_image[].copy", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToPILImage"], "function", ["None"], ["def", "torch_to_cv2_image", "(", "image", ")", ":", "\n", "    ", "pil_image", "=", "torchvision", ".", "transforms", ".", "ToPILImage", "(", ")", "(", "image", ")", "\n", "open_cv_image", "=", "np", ".", "array", "(", "pil_image", ")", "\n", "# Convert RGB to BGR", "\n", "open_cv_image", "=", "open_cv_image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "copy", "(", ")", "\n", "return", "open_cv_image", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.gen_vid.parse_args": [[22, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.gen_vid.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--img_path'", ",", "type", "=", "str", ",", "default", "=", "'./'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'vid.avi'", ")", "\n", "parser", ".", "add_argument", "(", "'--ext_a'", ",", "type", "=", "str", ",", "default", "=", "'.jpg'", ")", "\n", "parser", ".", "add_argument", "(", "'--ext_b'", ",", "type", "=", "str", ",", "default", "=", "'.jpg'", ")", "\n", "parser", ".", "add_argument", "(", "'--out'", ",", "type", "=", "str", ",", "default", "=", "'./'", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix_a'", ",", "type", "=", "str", ",", "default", "=", "'a_'", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix_b'", ",", "type", "=", "str", ",", "default", "=", "'b_'", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix_c'", ",", "type", "=", "str", ",", "default", "=", "'a_'", ")", "\n", "parser", ".", "add_argument", "(", "'--prefix_d'", ",", "type", "=", "str", ",", "default", "=", "'b_'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--start_a'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--end_a'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--start_b'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--end_b'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--stride_a'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--stride_b'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--w'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--h'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fps'", ",", "type", "=", "float", ",", "default", "=", "15.0", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--resize'", ",", "dest", "=", "'resize'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "resize", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--same_length'", ",", "dest", "=", "'same_length'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "same_length", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--crop'", ",", "dest", "=", "'crop'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "set_defaults", "(", "crop", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--crop_w'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_h'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.Aug_dataset.__init__": [[95, 126], ["root_seg.replace", "range", "print", "len", "print", "len", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "len", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "f.endswith", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "range", "str", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_seg", ",", "transform", ",", "transform_seg", ",", "args", ",", "train", "=", "True", ",", "hflip", "=", "False", ",", "ext", "=", "'.jpg'", ",", "prefix", "=", "''", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "transform_seg", "=", "transform_seg", "\n", "self", ".", "hflip", "=", "hflip", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "pad_factor", "=", "pad_factor", "\n", "\n", "self", ".", "root_dir", "=", "root_seg", ".", "replace", "(", "\"_seg\"", ",", "\"\"", ")", "\n", "self", ".", "seg_dir", "=", "root_seg", "\n", "\n", "dir_imgs", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "seg_dir", ")", "if", "f", ".", "endswith", "(", "self", ".", "ext", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dir_imgs", ")", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", ")", ")", ":", "\n", "                ", "start", "=", "i", "\n", "break", "\n", "\n", "", "", "assert", "start", ">=", "0", "\n", "print", "(", "\"start \"", "+", "str", "(", "start", ")", ")", "\n", "\n", "self", ".", "imgs", "=", "[", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", "for", "i", "in", "range", "(", "start", ",", "start", "+", "len", "(", "dir_imgs", ")", ")", "]", "\n", "\n", "if", "args", ".", "data_size", ">", "0", ":", "\n", "            ", "self", ".", "size", "=", "args", ".", "data_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "len", "(", "self", ".", "imgs", ")", "\n", "\n", "", "self", ".", "real_size", "=", "len", "(", "self", ".", "imgs", ")", "\n", "print", "(", "\"Data size is \"", "+", "str", "(", "self", ".", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.Aug_dataset.__len__": [[128, 130], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.Aug_dataset.__getitem__": [[131, 153], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "inference.augment", "seg1.transpose.transpose.convert", "inference.Aug_dataset.transform", "inference.Aug_dataset.transform_seg", "img1.transpose.transpose.transpose", "seg1.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "name1", "=", "self", ".", "imgs", "[", "idx", "%", "self", ".", "real_size", "]", "\n", "img1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "name1", ")", "\n", "seg1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "name1", ")", "\n", "\n", "print", "(", "img1_path", ",", "seg1_path", ")", "\n", "\n", "img1", ",", "seg1", "=", "augment", "(", "img1_path", ",", "seg1_path", ",", "pad_factor", "=", "self", ".", "pad_factor", ")", "\n", "seg1", "=", "seg1", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "self", ".", "hflip", "and", "self", ".", "train", ":", "\n", "            ", "img1", "=", "img1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "seg1", "=", "seg1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "", "img1", "=", "self", ".", "transform", "(", "img1", ")", "\n", "seg1", "=", "self", ".", "transform_seg", "(", "seg1", ")", "\n", "\n", "seg1", "=", "(", "seg1", ">", "0.5", ")", ".", "float", "(", ")", "\n", "\n", "img1", "=", "img1", "*", "seg1", "\n", "\n", "return", "img1", ",", "seg1", ",", "name1", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.load_model": [[22, 30], ["torch.load", "torch.load", "G_A.load_state_dict", "R_A.load_state_dict", "R_B.load_state_dict", "KP.load_state_dict"], "function", ["None"], ["def", "load_model", "(", "load_path", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ")", ":", "\n", "    ", "state", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "G_A", ".", "load_state_dict", "(", "state", "[", "'G_A'", "]", ")", "\n", "R_A", ".", "load_state_dict", "(", "state", "[", "'R_A'", "]", ")", "\n", "R_B", ".", "load_state_dict", "(", "state", "[", "'R_B'", "]", ")", "\n", "KP", ".", "load_state_dict", "(", "state", "[", "'KP'", "]", ")", "\n", "\n", "return", "state", "[", "'epoch'", "]", ",", "state", "[", "'learned_t'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.norm": [[32, 38], ["var.cpu().detach.cpu().detach", "var.cpu().detach.cpu"], "function", ["None"], ["", "def", "norm", "(", "var", ")", ":", "\n", "    ", "var", "=", "var", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "var", "=", "(", "(", "var", "+", "1", ")", "/", "2", ")", "\n", "var", "[", "var", "<", "0", "]", "=", "0", "\n", "var", "[", "var", ">", "1", "]", "=", "1", "\n", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.vis_points": [[39, 45], ["inference.norm", "kpoints.data.cpu().numpy", "numpy.transpose", "viz.create_image_column_with_kp", "kpoints.data.cpu"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column_with_kp"], ["", "def", "vis_points", "(", "viz", ",", "img", ",", "kpoints", ")", ":", "\n", "    ", "source", "=", "norm", "(", "img", ".", "data", ")", "\n", "kp_source", "=", "kpoints", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "source", "=", "np", ".", "transpose", "(", "source", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "viz", ".", "create_image_column_with_kp", "(", "source", ",", "kp_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.transform_kp": [[47, 55], ["theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "transformed.squeeze.squeeze", "torch.matmul", "torch.matmul", "coordinates.unsqueeze"], "function", ["None"], ["", "def", "transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "    ", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "torch", ".", "matmul", "(", "theta", "[", ":", ",", ":", ",", ":", ",", ":", "2", "]", ",", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", ")", "+", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.inverse_transform_kp": [[57, 69], ["torch.inverse", "torch.inverse", "theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "inverse.unsqueeze.repeat", "inverse.unsqueeze.unsqueeze", "torch.matmul", "torch.matmul", "transformed.squeeze.squeeze", "coordinates.unsqueeze"], "function", ["None"], ["", "def", "inverse_transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "\n", "    ", "inverse", "=", "torch", ".", "inverse", "(", "theta", "[", ":", ",", ":", ",", ":", "2", "]", ")", "\n", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "inverse", "=", "inverse", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "inverse", "=", "inverse", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", "-", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "torch", ".", "matmul", "(", "inverse", ",", "transformed", ")", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.augment": [[71, 92], ["cv2.imread", "numpy.stack", "cv2.cvtColor", "PIL.Image.fromarray", "PIL.Image.fromarray", "cv2.imread", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "int", "int", "int", "int", "int", "int", "int", "int", "cv2.imread"], "function", ["None"], ["", "def", "augment", "(", "path", ",", "seg_path", ",", "pad", "=", "True", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "\n", "    ", "img", "=", "cv2", ".", "imread", "(", "path", ")", "\n", "\n", "if", "pad", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "\n", "w", ",", "h", "=", "img", ".", "shape", "[", "0", "]", ",", "img", ".", "shape", "[", "1", "]", "\n", "img", "=", "cv2", ".", "copyMakeBorder", "(", "img", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg", "=", "cv2", ".", "copyMakeBorder", "(", "seg", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "\n", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg", "=", "seg", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "\n", "", "seg", "=", "np", ".", "stack", "(", "(", "seg", "[", ":", ",", ":", ",", "0", "]", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "im_pil", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "seg_pil", "=", "Image", ".", "fromarray", "(", "seg", ")", "\n", "\n", "return", "im_pil", ",", "seg_pil", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.kp_to_heatmap": [[155, 179], ["x.unsqueeze().unsqueeze", "modules.util.make_coordinate_grid().unsqueeze().unsqueeze().repeat().cuda", "torch.abs", "torch.abs", "torch.exp", "torch.exp", "x.unsqueeze().unsqueeze.size", "x.unsqueeze().unsqueeze.size", "torch.max", "torch.max", "x.unsqueeze", "modules.util.make_coordinate_grid().unsqueeze().unsqueeze().repeat", "z.size", "z.size", "z.size", "z.size", "modules.util.make_coordinate_grid().unsqueeze().unsqueeze", "modules.util.make_coordinate_grid().unsqueeze", "modules.util.make_coordinate_grid"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["", "", "def", "kp_to_heatmap", "(", "x", ",", "spatial_size", "=", "256", ",", "std", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n\n    :param kp: bs X num_kp X 2\n    :param spatial_size: int\n    :param std: float\n    :return: bs X num_kp X spatial_size X spatial_size\n    \"\"\"", "\n", "kp", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "#print(kp.size())", "\n", "ss", "=", "spatial_size", "\n", "bs", ",", "num_kp", "=", "kp", ".", "size", "(", "0", ")", ",", "kp", ".", "size", "(", "1", ")", "\n", "grid", "=", "make_coordinate_grid", "(", "(", "ss", ",", "ss", ")", ",", "torch", ".", "float", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "bs", ",", "num_kp", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", "# Range -1, 1", "\n", "#kp = (kp / float(ss)) * 2 - 1", "\n", "#print(kp.size())", "\n", "#print(grid.size())", "\n", "y", "=", "torch", ".", "abs", "(", "grid", "-", "kp", ")", "\n", "y", "=", "torch", ".", "exp", "(", "-", "y", "/", "(", "std", "**", "2", ")", ")", "\n", "z", "=", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "*", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "z", "=", "z", "/", "torch", ".", "max", "(", "z", ")", "\n", "\n", "assert", "bs", "==", "z", ".", "size", "(", "0", ")", "and", "num_kp", "==", "z", ".", "size", "(", "1", ")", "and", "ss", "==", "z", ".", "size", "(", "2", ")", "and", "ss", "==", "z", ".", "size", "(", "3", ")", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize": [[180, 186], ["new_img.unsqueeze.unsqueeze", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToPILImage", "torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "resize", "(", "img", ",", "w", ",", "h", ")", ":", "\n", "   ", "img_PIL", "=", "torchvision", ".", "transforms", ".", "ToPILImage", "(", ")", "(", "img", "[", "0", "]", ")", "\n", "img_PIL", "=", "torchvision", ".", "transforms", ".", "Resize", "(", "[", "h", ",", "w", "]", ")", "(", "img_PIL", ")", "\n", "new_img", "=", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", "(", "img_PIL", ")", "\n", "new_img", "=", "new_img", ".", "unsqueeze", "(", "0", ")", "\n", "return", "new_img", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.eval": [[188, 370], ["tran_list.append", "tran_list.append", "tran_list.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "inference.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "inference.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "models.define_G", "models.define_G", "models.define_G", "G_A.eval.cuda", "modules.keypoint_detector_strong.KPDetector_strong.cuda", "R_A.eval.cuda", "R_B.eval.cuda", "util.visualizer_kp.Visualizer", "inference.load_model", "print", "modules.keypoint_detector_strong.KPDetector_strong.train", "G_A.eval.eval", "R_A.eval.eval", "R_B.eval.eval", "print", "print", "zip", "print", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize", "modules.keypoint_detector_heatmap.KPDetector", "modules.keypoint_detector_strong.KPDetector_strong", "print", "norm.cuda", "norm.cuda", "resize.cuda", "resize.cuda", "print", "str", "torch.no_grad", "torch.no_grad", "modules.keypoint_detector_strong.KPDetector_strong.", "inference.kp_to_heatmap", "modules.keypoint_detector_strong.KPDetector_strong.", "inference.kp_to_heatmap", "R_A.eval.", "R_B.eval.", "R_B.eval.", "R_A.eval.", "torch.cat", "torch.cat", "torchvision.save_image", "torch.cat", "torch.cat", "torchvision.save_image", "torch.cat", "torch.cat", "torchvision.save_image", "torch.cat", "torch.cat", "torchvision.save_image", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "torchvision.save_image", "norm.size", "norm.size", "inference.transform_kp", "inference.inverse_transform_kp", "inference.kp_to_heatmap", "inference.kp_to_heatmap", "G_A.eval.", "G_A.eval.", "G_A.eval.", "G_A.eval.", "G_A.eval.", "G_A.eval.", "os.join", "os.join", "os.join", "os.join", "inference.vis_points", "inference.vis_points", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "os.join", "inference.vis_points", "inference.vis_points", "inference.vis_points", "os.join", "inference.vis_points", "inference.vis_points", "inference.vis_points", "os.join", "inference.resize", "inference.resize", "inference.resize", "inference.resize", "inference.resize", "inference.resize", "inference.resize", "inference.resize", "inference.norm", "inference.norm", "inference.norm", "inference.norm", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "len", "len", "norm.size", "norm.size", "inference.vis_points", "inference.vis_points", "inference.norm", "inference.norm", "inference.norm", "inference.norm", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "inference.vis_points", "inference.vis_points", "inference.vis_points", "inference.vis_points", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "norm.size", "norm.size"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.load_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.inverse_transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points"], ["", "def", "eval", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "out", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "out", ")", "\n", "\n", "", "tran_list", "=", "[", "]", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Resize", "(", "(", "args", ".", "resize_w", ",", "args", ".", "resize_h", ")", ")", ")", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ")", "\n", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", ")", "\n", "transform_seg", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", "[", ":", "-", "1", "]", ")", "\n", "\n", "\n", "dataset_a", "=", "Aug_dataset", "(", "args", ".", "root_a", ",", "transform", ",", "transform_seg", ",", "args", ",", "hflip", "=", "args", ".", "hflip", ",", "ext", "=", "args", ".", "ext_a", ",", "prefix", "=", "args", ".", "prefix_a", ",", "pad_factor", "=", "args", ".", "pad_factor_a", ")", "\n", "data_loader_a", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_a", ",", "shuffle", "=", "False", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "False", ")", "\n", "\n", "dataset_b", "=", "Aug_dataset", "(", "args", ".", "root_b", ",", "transform", ",", "transform_seg", ",", "args", ",", "ext", "=", "args", ".", "ext_b", ",", "prefix", "=", "args", ".", "prefix_b", ",", "pad_factor", "=", "args", ".", "pad_factor_b", ")", "\n", "data_loader_b", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_b", ",", "shuffle", "=", "False", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "False", ")", "\n", "\n", "if", "not", "args", ".", "strong_kp", ":", "\n", "        ", "KP", "=", "KPDetector", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ")", "\n", "", "else", ":", "\n", "        ", "KP", "=", "KPDetector_strong", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ",", "args", "=", "args", ")", "\n", "\n", "", "ch_size", "=", "args", ".", "num_kp", "\n", "\n", "G_A", "=", "nets", ".", "define_G", "(", "ch_size", ",", "2", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ",", "not_mask", "=", "False", ",", "only_mask", "=", "True", ")", "\n", "\n", "R_A", "=", "nets", ".", "define_G", "(", "args", ".", "input_nc", ",", "args", ".", "output_nc", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "new_norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ")", "\n", "\n", "R_B", "=", "nets", ".", "define_G", "(", "args", ".", "input_nc", ",", "args", ".", "output_nc", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "new_norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ")", "\n", "\n", "G_A", "=", "G_A", ".", "cuda", "(", ")", "\n", "KP", "=", "KP", ".", "cuda", "(", ")", "\n", "R_A", "=", "R_A", ".", "cuda", "(", ")", "\n", "R_B", "=", "R_B", ".", "cuda", "(", ")", "\n", "\n", "viz", "=", "visualizer_kp", ".", "Visualizer", "(", "kp_size", "=", "args", ".", "num_kp", ")", "\n", "\n", "load_epoch", ",", "learned_t", "=", "load_model", "(", "args", ".", "load", ",", "G_A", ",", "R_A", ",", "R_B", ",", "KP", ")", "\n", "print", "(", "\"Loaded successfully, epoch=\"", "+", "str", "(", "load_epoch", ")", ")", "\n", "\n", "KP", "=", "KP", ".", "train", "(", ")", "\n", "G_A", "=", "G_A", ".", "eval", "(", ")", "\n", "R_A", "=", "R_A", ".", "eval", "(", ")", "\n", "R_B", "=", "R_B", ".", "eval", "(", ")", "\n", "\n", "iter_cnt", "=", "0", "\n", "\n", "print", "(", "'Started Inference...'", ")", "\n", "\n", "print", "(", "f'lengths: {len(dataset_a), len(dataset_b)}'", ")", "\n", "for", "data_a", ",", "data_b", "in", "zip", "(", "data_loader_a", ",", "data_loader_b", ")", ":", "\n", "\n", "        ", "print", "(", "iter_cnt", ")", "\n", "\n", "img_a", ",", "seg_a", ",", "name_a", "=", "data_a", "\n", "img_b", ",", "seg_b", ",", "name_b", "=", "data_b", "\n", "\n", "img_a", "=", "img_a", ".", "cuda", "(", ")", "\n", "img_b", "=", "img_b", ".", "cuda", "(", ")", "\n", "\n", "seg_a", "=", "seg_a", ".", "cuda", "(", ")", "\n", "seg_b", "=", "seg_b", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "kpoints_a", ",", "heatmap_a", "=", "KP", "(", "img_a", ")", "\n", "new_heatmap_a", "=", "kp_to_heatmap", "(", "kpoints_a", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "kpoints_b", ",", "heatmap_b", "=", "KP", "(", "img_b", ")", "\n", "new_heatmap_b", "=", "kp_to_heatmap", "(", "kpoints_b", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "\n", "if", "args", ".", "affine", ":", "\n", "                ", "kpoints_b_transformed", "=", "transform_kp", "(", "kpoints_b", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "kpoints_a_transformed", "=", "inverse_transform_kp", "(", "kpoints_a", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "new_heatmap_b_transformed", "=", "kp_to_heatmap", "(", "kpoints_b_transformed", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "new_heatmap_a_transformed", "=", "kp_to_heatmap", "(", "kpoints_a_transformed", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "decoded_a", ",", "_", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "_", ",", "decoded_b", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "new_heatmap_a", "=", "new_heatmap_a_transformed", "\n", "new_heatmap_b", "=", "new_heatmap_b_transformed", "\n", "\n", "_", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "_", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "", "else", ":", "\n", "                ", "decoded_a", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "decoded_b", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "", "refined_a", "=", "R_A", "(", "decoded_a", ")", "\n", "refined_b", "=", "R_B", "(", "decoded_b", ")", "\n", "\n", "refined_ab", "=", "R_B", "(", "decoded_ab", ")", "\n", "refined_ba", "=", "R_A", "(", "decoded_ba", ")", "\n", "\n", "", "if", "not", "args", ".", "splitted", ":", "\n", "\n", "            ", "exps", "=", "torch", ".", "cat", "(", "[", "img_a", ",", "seg_a", ",", "decoded_a", ",", "refined_a", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"recon_a_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "exps", "=", "torch", ".", "cat", "(", "[", "img_b", ",", "seg_b", ",", "decoded_b", ",", "refined_b", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"recon_b_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "exps", "=", "torch", ".", "cat", "(", "[", "img_a", ",", "refined_ab", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"bab_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "exps", "=", "torch", ".", "cat", "(", "[", "img_b", ",", "refined_ba", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"aba_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b", ")", ")", "\n", "if", "args", ".", "affine", ":", "\n", "                ", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_b_transformed", ")", ")", "\n", "to_print", ".", "append", "(", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_b_transformed", ")", "+", "vis_points", "(", "viz", ",", "torch", ".", "zeros", "(", "img_a", ".", "size", "(", ")", ")", ",", "kpoints_b", ")", ")", "/", "2", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_a_transformed", ")", ")", "\n", "to_print", ".", "append", "(", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_a_transformed", ")", "+", "vis_points", "(", "viz", ",", "torch", ".", "zeros", "(", "img_a", ".", "size", "(", ")", ")", ",", "kpoints_a", ")", ")", "/", "2", ")", "\n", "\n", "", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"kp_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "to_print", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ab", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "refined_ab", ",", "kpoints_a", ")", ")", "\n", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"kp_test_a\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "to_print", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ba", ",", "kpoints_b", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "refined_ba", ",", "kpoints_b", ")", ")", "\n", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"kp_test_b\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "to_print", ")", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "w", ">", "0", "and", "args", ".", "h", ">", "0", ":", "\n", "                ", "img_a", "=", "resize", "(", "norm", "(", "img_a", ")", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "seg_a", "=", "resize", "(", "seg_a", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "img_b", "=", "resize", "(", "norm", "(", "img_b", ")", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "seg_b", "=", "resize", "(", "seg_b", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "refined_ab", "=", "resize", "(", "norm", "(", "refined_ab", ")", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "refined_ba", "=", "resize", "(", "norm", "(", "refined_ba", ")", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "decoded_ba", "=", "resize", "(", "decoded_ba", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "decoded_ab", "=", "resize", "(", "decoded_ab", ",", "args", ".", "w", ",", "args", ".", "h", ")", "\n", "", "else", ":", "\n", "                ", "img_a", "=", "norm", "(", "img_a", ")", "\n", "img_b", "=", "norm", "(", "img_b", ")", "\n", "refined_ab", "=", "norm", "(", "refined_ab", ")", "\n", "refined_ba", "=", "norm", "(", "refined_ba", ")", "\n", "\n", "", "vutils", ".", "save_image", "(", "img_a", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"a_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "\n", "vutils", ".", "save_image", "(", "seg_a", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"seg_a_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "\n", "vutils", ".", "save_image", "(", "refined_ab", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"refined_ab_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "vutils", ".", "save_image", "(", "decoded_ab", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"decoded_ab_\"", "+", "str", "(", "name_a", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "vutils", ".", "save_image", "(", "img_b", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"b_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "\n", "vutils", ".", "save_image", "(", "seg_b", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"seg_b_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "\n", "vutils", ".", "save_image", "(", "refined_ba", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"refined_ba_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "False", ")", "\n", "vutils", ".", "save_image", "(", "decoded_ba", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"decoded_ba_\"", "+", "str", "(", "name_b", "[", "0", "]", ")", ")", ",", "normalize", "=", "True", ")", "\n", "\n", "", "iter_cnt", "+=", "1", "\n", "\n", "print", "(", "name_a", "[", "0", "]", ",", "name_b", "[", "0", "]", ")", "\n", "\n", "", "print", "(", "\"Inference is done\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_disc.__init__": [[30, 44], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kp_num", ",", "bottleneck", "=", "512", ")", ":", "\n", "        ", "super", "(", "kp_disc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kp_num", "=", "kp_num", "\n", "self", ".", "bottleneck", "=", "bottleneck", "\n", "\n", "self", ".", "classify", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "kp_num", "*", "2", ",", "self", ".", "bottleneck", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "bottleneck", ",", "self", ".", "bottleneck", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "bottleneck", ",", "64", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "64", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_disc.forward": [[46, 51], ["net.view.view.view", "train_first_stage.kp_disc.classify", "net.view.view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "net", ")", ":", "\n", "        ", "net", "=", "net", ".", "view", "(", "-", "1", ",", "self", ".", "kp_num", "*", "2", ")", "\n", "net", "=", "self", ".", "classify", "(", "net", ")", "\n", "net", "=", "net", ".", "view", "(", "-", "1", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.__init__": [[151, 164], ["torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.eye().view", "train_first_stage.make_coordinate_grid", "train_first_stage.Transform.control_points.unsqueeze", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.normal", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.normal.type", "torch.normal.type", "torch.normal.type", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["def", "__init__", "(", "self", ",", "bs", ",", "sigma_affine", "=", "0.05", ",", "sigma_tps", "=", "0.005", ",", "points_tps", "=", "5", ")", ":", "\n", "        ", "noise", "=", "torch", ".", "normal", "(", "mean", "=", "0", ",", "std", "=", "sigma_affine", "*", "torch", ".", "ones", "(", "[", "bs", ",", "2", ",", "3", "]", ")", ")", "\n", "self", ".", "theta", "=", "noise", "+", "torch", ".", "eye", "(", "2", ",", "3", ")", ".", "view", "(", "1", ",", "2", ",", "3", ")", "\n", "self", ".", "bs", "=", "bs", "\n", "\n", "if", "sigma_tps", "and", "points_tps", ":", "\n", "            ", "self", ".", "tps", "=", "True", "\n", "self", ".", "control_points", "=", "make_coordinate_grid", "(", "(", "points_tps", ",", "points_tps", ")", ",", "type", "=", "noise", ".", "type", "(", ")", ")", "\n", "self", ".", "control_points", "=", "self", ".", "control_points", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "control_params", "=", "torch", ".", "normal", "(", "mean", "=", "0", ",", "\n", "std", "=", "sigma_tps", "*", "torch", ".", "ones", "(", "[", "bs", ",", "1", ",", "points_tps", "**", "2", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tps", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.transform_frame": [[165, 170], ["make_coordinate_grid().unsqueeze", "train_first_stage.Transform.view", "train_first_stage.Transform.warp_coordinates().view", "torch.grid_sample", "torch.grid_sample", "torch.grid_sample", "train_first_stage.make_coordinate_grid", "train_first_stage.Transform.warp_coordinates", "frame.type"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.warp_coordinates"], ["", "", "def", "transform_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "grid", "=", "make_coordinate_grid", "(", "frame", ".", "shape", "[", "2", ":", "]", ",", "type", "=", "frame", ".", "type", "(", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "grid", "=", "grid", ".", "view", "(", "1", ",", "frame", ".", "shape", "[", "2", "]", "*", "frame", ".", "shape", "[", "3", "]", ",", "2", ")", "\n", "grid", "=", "self", ".", "warp_coordinates", "(", "grid", ")", ".", "view", "(", "self", ".", "bs", ",", "frame", ".", "shape", "[", "2", "]", ",", "frame", ".", "shape", "[", "3", "]", ",", "2", ")", "\n", "return", "F", ".", "grid_sample", "(", "frame", ",", "grid", ",", "padding_mode", "=", "\"reflection\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.warp_coordinates": [[171, 190], ["train_first_stage.Transform.theta.type", "theta.unsqueeze.unsqueeze.unsqueeze", "transformed.squeeze.squeeze.squeeze", "coordinates.type", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "train_first_stage.Transform.control_points.type", "train_first_stage.Transform.control_params.type", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "torch.abs().sum", "result.sum().view.sum().view.sum().view", "coordinates.unsqueeze", "coordinates.type", "coordinates.type", "coordinates.view", "train_first_stage.Transform.view", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "result.sum().view.sum().view.sum"], "methods", ["None"], ["", "def", "warp_coordinates", "(", "self", ",", "coordinates", ")", ":", "\n", "        ", "theta", "=", "self", ".", "theta", ".", "type", "(", "coordinates", ".", "type", "(", ")", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "torch", ".", "matmul", "(", "theta", "[", ":", ",", ":", ",", ":", ",", ":", "2", "]", ",", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", ")", "+", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "self", ".", "tps", ":", "\n", "            ", "control_points", "=", "self", ".", "control_points", ".", "type", "(", "coordinates", ".", "type", "(", ")", ")", "\n", "control_params", "=", "self", ".", "control_params", ".", "type", "(", "coordinates", ".", "type", "(", ")", ")", "\n", "distances", "=", "coordinates", ".", "view", "(", "coordinates", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ",", "2", ")", "-", "control_points", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "2", ")", "\n", "distances", "=", "torch", ".", "abs", "(", "distances", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n", "result", "=", "distances", "**", "2", "\n", "result", "=", "result", "*", "torch", ".", "log", "(", "distances", "+", "1e-6", ")", "\n", "result", "=", "result", "*", "control_params", "\n", "result", "=", "result", ".", "sum", "(", "dim", "=", "2", ")", ".", "view", "(", "self", ".", "bs", ",", "coordinates", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "transformed", "=", "transformed", "+", "result", "\n", "\n", "", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.jacobian": [[191, 197], ["train_first_stage.Transform.warp_coordinates", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_coordinates[].sum", "new_coordinates[].sum", "grad_x[].unsqueeze", "grad_y[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.warp_coordinates"], ["", "def", "jacobian", "(", "self", ",", "coordinates", ")", ":", "\n", "        ", "new_coordinates", "=", "self", ".", "warp_coordinates", "(", "coordinates", ")", "\n", "grad_x", "=", "grad", "(", "new_coordinates", "[", "...", ",", "0", "]", ".", "sum", "(", ")", ",", "coordinates", ",", "create_graph", "=", "True", ")", "\n", "grad_y", "=", "grad", "(", "new_coordinates", "[", "...", ",", "1", "]", ".", "sum", "(", ")", ",", "coordinates", ",", "create_graph", "=", "True", ")", "\n", "jacobian", "=", "torch", ".", "cat", "(", "[", "grad_x", "[", "0", "]", ".", "unsqueeze", "(", "-", "2", ")", ",", "grad_y", "[", "0", "]", ".", "unsqueeze", "(", "-", "2", ")", "]", ",", "dim", "=", "-", "2", ")", "\n", "return", "jacobian", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Aug_dataset.__init__": [[262, 304], ["root_seg.replace", "range", "print", "len", "print", "print", "imgaug.Sequential", "imgaug.Sequential", "len", "os.path.isfile", "os.path.isfile", "os.path.isfile", "os.path.isfile", "len", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "f.endswith", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "range", "str", "imgaug.Resize", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Affine", "imgaug.Crop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_seg", ",", "transform", ",", "transform_seg", ",", "train", "=", "True", ",", "hflip", "=", "False", ",", "ext", "=", "'.jpg'", ",", "prefix", "=", "''", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "transform_seg", "=", "transform_seg", "\n", "self", ".", "hflip", "=", "hflip", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "ext", "=", "ext", "\n", "self", ".", "prefix", "=", "prefix", "\n", "self", ".", "pad_factor", "=", "pad_factor", "\n", "\n", "self", ".", "root_dir", "=", "root_seg", ".", "replace", "(", "\"_seg\"", ",", "\"\"", ")", "\n", "self", ".", "seg_dir", "=", "root_seg", "\n", "\n", "dir_imgs", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "seg_dir", ")", "if", "f", ".", "endswith", "(", "self", ".", "ext", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "dir_imgs", ")", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", ")", ")", ":", "\n", "                ", "start", "=", "i", "\n", "break", "\n", "\n", "", "", "assert", "start", ">=", "0", "\n", "print", "(", "\"start \"", "+", "str", "(", "start", ")", ")", "\n", "end", "=", "len", "(", "dir_imgs", ")", "\n", "print", "(", "\"end \"", "+", "str", "(", "end", ")", ")", "\n", "self", ".", "imgs", "=", "[", "self", ".", "prefix", "+", "\"%0d%s\"", "%", "(", "i", ",", "self", ".", "ext", ")", "for", "i", "in", "range", "(", "start", ",", "start", "+", "end", ")", "]", "\n", "\n", "self", ".", "size", "=", "len", "(", "self", ".", "imgs", ")", "-", "1", "\n", "print", "(", "\"Data size is \"", "+", "str", "(", "self", ".", "size", ")", ")", "\n", "\n", "#Augmentations", "\n", "self", ".", "seq", "=", "iaa", ".", "Sequential", "(", "[", "\n", "iaa", ".", "Resize", "(", "(", "0.8", ",", "1.1", ")", ")", ",", "\n", "iaa", ".", "Affine", "(", "rotate", "=", "(", "-", "20", ",", "20", ")", ")", ",", "\n", "iaa", ".", "Affine", "(", "translate_px", "=", "{", "\"x\"", ":", "(", "-", "50", ",", "50", ")", ",", "\"y\"", ":", "(", "-", "50", ",", "50", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "shear", "=", "{", "\"x\"", ":", "(", "-", "15", ",", "15", ")", ",", "\"y\"", ":", "(", "-", "15", ",", "15", ")", "}", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "seq2", "=", "iaa", ".", "Sequential", "(", "[", "\n", "iaa", ".", "Affine", "(", "scale", "=", "{", "\"x\"", ":", "(", "0.8", ",", "1.2", ")", ",", "\"y\"", ":", "(", "0.8", ",", "1.2", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "translate_px", "=", "{", "\"x\"", ":", "(", "-", "50", ",", "50", ")", ",", "\"y\"", ":", "(", "-", "50", ",", "50", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "shear", "=", "{", "\"x\"", ":", "(", "-", "20", ",", "20", ")", ",", "\"y\"", ":", "(", "-", "20", ",", "20", ")", "}", ")", ",", "\n", "iaa", ".", "Affine", "(", "rotate", "=", "(", "-", "20", ",", "20", ")", ")", ",", "\n", "iaa", ".", "Crop", "(", "percent", "=", "(", "0.0001", ",", "0.05", ")", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Aug_dataset.__len__": [[306, 308], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Aug_dataset.__getitem__": [[309, 344], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "random.random", "seg1.transpose.transpose.convert", "seg2.transpose.transpose.convert", "train_first_stage.Aug_dataset.transform", "train_first_stage.Aug_dataset.transform", "train_first_stage.Aug_dataset.transform_seg", "train_first_stage.Aug_dataset.transform_seg", "train_first_stage.augment", "train_first_stage.augment", "pair1.transpose.transpose.transpose", "seg1.transpose.transpose.transpose", "pair2.transpose.transpose.transpose", "seg2.transpose.transpose.transpose"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "name1", "=", "self", ".", "imgs", "[", "idx", "]", "\n", "name2", "=", "self", ".", "imgs", "[", "idx", "+", "1", "]", "\n", "img1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "name1", ")", "\n", "img2_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "name2", ")", "\n", "seg1_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "name1", ")", "\n", "seg2_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "seg_dir", ",", "name2", ")", "\n", "\n", "r_", "=", "random", ".", "random", "(", ")", "\n", "if", "r_", ">", "0.6", ":", "\n", "            ", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "=", "augment", "(", "img1_path", ",", "img2_path", ",", "seg1_path", ",", "seg2_path", ",", "self", ".", "seq2", ",", "pad_factor", "=", "self", ".", "pad_factor", ")", "\n", "", "else", ":", "\n", "            ", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "=", "augment", "(", "img1_path", ",", "img2_path", ",", "seg1_path", ",", "seg2_path", ",", "self", ".", "seq", ",", "pad_factor", "=", "self", ".", "pad_factor", ")", "\n", "\n", "", "seg1", "=", "seg1", ".", "convert", "(", "'RGB'", ")", "\n", "seg2", "=", "seg2", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "self", ".", "hflip", "and", "self", ".", "train", ":", "\n", "            ", "pair1", "=", "pair1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "seg1", "=", "seg1", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "pair2", "=", "pair2", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "seg2", "=", "seg2", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "\n", "", "pair1", "=", "self", ".", "transform", "(", "pair1", ")", "\n", "pair2", "=", "self", ".", "transform", "(", "pair2", ")", "\n", "seg1", "=", "self", ".", "transform_seg", "(", "seg1", ")", "\n", "seg2", "=", "self", ".", "transform_seg", "(", "seg2", ")", "\n", "\n", "seg1", "=", "(", "seg1", ">", "0.5", ")", ".", "float", "(", ")", "\n", "seg2", "=", "(", "seg2", ">", "0.5", ")", ".", "float", "(", ")", "\n", "\n", "pair1", "=", "pair1", "*", "seg1", "\n", "pair2", "=", "pair2", "*", "seg2", "\n", "\n", "return", "pair1", ",", "pair2", ",", "seg1", ",", "seg2", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.make_coordinate_grid": [[52, 69], ["torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type.view().repeat", "torch.arange().type.view().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().type.view", "torch.arange().type.view", "x.view().repeat.unsqueeze_", "y.view().repeat.unsqueeze_", "torch.float", "torch.float", "torch.float"], "function", ["None"], ["", "", "def", "make_coordinate_grid", "(", "spatial_size", ",", "type", ")", ":", "\n", "    ", "\"\"\"\n    Create a meshgrid [-1,1] x [-1,1] of given spatial_size.\n    \"\"\"", "\n", "h", ",", "w", "=", "spatial_size", "\n", "x", "=", "torch", ".", "arange", "(", "w", ")", ".", "type", "(", "type", ")", "\n", "y", "=", "torch", ".", "arange", "(", "h", ")", ".", "type", "(", "type", ")", "\n", "\n", "x", "=", "(", "2", "*", "(", "x", "/", "(", "w", "-", "1", ")", ")", "-", "1", ")", "\n", "y", "=", "(", "2", "*", "(", "y", "/", "(", "h", "-", "1", ")", ")", "-", "1", ")", "\n", "\n", "yy", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "w", ")", "\n", "xx", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "h", ",", "1", ")", "\n", "\n", "meshed", "=", "torch", ".", "cat", "(", "[", "xx", ".", "unsqueeze_", "(", "2", ")", ",", "yy", ".", "unsqueeze_", "(", "2", ")", "]", ",", "2", ")", "\n", "\n", "return", "meshed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.save_model": [[71, 83], ["torch.save", "torch.save", "torch.save", "G_A.state_dict", "Disc.state_dict", "KP.state_dict", "g_opt.state_dict", "d_opt.state_dict"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save"], ["", "def", "save_model", "(", "out_file", ",", "G_A", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ",", "learned_t", ",", "epoch", ")", ":", "\n", "    ", "state", "=", "{", "\n", "'G_A'", ":", "G_A", ".", "state_dict", "(", ")", ",", "\n", "'Disc'", ":", "Disc", ".", "state_dict", "(", ")", ",", "\n", "'KP'", ":", "KP", ".", "state_dict", "(", ")", ",", "\n", "'g_opt'", ":", "g_opt", ".", "state_dict", "(", ")", ",", "\n", "'d_opt'", ":", "d_opt", ".", "state_dict", "(", ")", ",", "\n", "'learned_t'", ":", "learned_t", ",", "\n", "'epoch'", ":", "epoch", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "out_file", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.load_model": [[85, 93], ["torch.load", "torch.load", "torch.load", "G_A.load_state_dict", "Disc.load_state_dict", "KP.load_state_dict", "g_opt.load_state_dict", "d_opt.load_state_dict"], "function", ["None"], ["", "def", "load_model", "(", "load_path", ",", "G_A", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ")", ":", "\n", "    ", "state", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "G_A", ".", "load_state_dict", "(", "state", "[", "'G_A'", "]", ")", "\n", "Disc", ".", "load_state_dict", "(", "state", "[", "'Disc'", "]", ")", "\n", "KP", ".", "load_state_dict", "(", "state", "[", "'KP'", "]", ")", "\n", "g_opt", ".", "load_state_dict", "(", "state", "[", "'g_opt'", "]", ")", "\n", "d_opt", ".", "load_state_dict", "(", "state", "[", "'d_opt'", "]", ")", "\n", "return", "state", "[", "'epoch'", "]", ",", "state", "[", "'learned_t'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm": [[96, 102], ["var.cpu().detach.cpu().detach", "var.cpu().detach.cpu"], "function", ["None"], ["", "def", "norm", "(", "var", ")", ":", "\n", "    ", "var", "=", "var", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "var", "=", "(", "(", "var", "+", "1", ")", "/", "2", ")", "\n", "var", "[", "var", "<", "0", "]", "=", "0", "\n", "var", "[", "var", ">", "1", "]", "=", "1", "\n", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.equi_loss": [[104, 111], ["train_first_stage.Transform", "train_first_stage.Transform.transform_frame", "kp_extractor", "torch.abs().mean", "torch.abs().mean", "torch.abs().mean", "torch.abs", "torch.abs", "torch.abs", "train_first_stage.Transform.warp_coordinates"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.transform_frame", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.warp_coordinates"], ["", "def", "equi_loss", "(", "frame", ",", "kp", ",", "kp_extractor", ")", ":", "\n", "    ", "transform", "=", "Transform", "(", "frame", ".", "shape", "[", "0", "]", ",", "sigma_affine", "=", "0.1", ",", "points_tps", "=", "None", ")", "\n", "transformed_frame", "=", "transform", ".", "transform_frame", "(", "frame", ")", "\n", "transformed_kp", ",", "_", "=", "kp_extractor", "(", "transformed_frame", ")", "\n", "\n", "value", "=", "torch", ".", "abs", "(", "kp", "-", "transform", ".", "warp_coordinates", "(", "transformed_kp", ")", ")", ".", "mean", "(", ")", "\n", "return", "value", ",", "transformed_frame", ",", "transformed_kp", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap": [[113, 137], ["x.unsqueeze().unsqueeze", "make_coordinate_grid().unsqueeze().unsqueeze().repeat().cuda", "torch.abs", "torch.abs", "torch.abs", "torch.exp", "torch.exp", "torch.exp", "x.unsqueeze().unsqueeze.size", "x.unsqueeze().unsqueeze.size", "torch.max", "torch.max", "torch.max", "x.unsqueeze", "make_coordinate_grid().unsqueeze().unsqueeze().repeat", "z.size", "z.size", "z.size", "z.size", "make_coordinate_grid().unsqueeze().unsqueeze", "make_coordinate_grid().unsqueeze", "train_first_stage.make_coordinate_grid"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["", "def", "kp_to_heatmap", "(", "x", ",", "spatial_size", "=", "256", ",", "std", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n\n    :param kp: bs X num_kp X 2\n    :param spatial_size: int\n    :param std: float\n    :return: bs X num_kp X spatial_size X spatial_size\n    \"\"\"", "\n", "kp", "=", "x", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "#print(kp.size())", "\n", "ss", "=", "spatial_size", "\n", "bs", ",", "num_kp", "=", "kp", ".", "size", "(", "0", ")", ",", "kp", ".", "size", "(", "1", ")", "\n", "grid", "=", "make_coordinate_grid", "(", "(", "ss", ",", "ss", ")", ",", "torch", ".", "float", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "bs", ",", "num_kp", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", "# Range -1, 1", "\n", "#kp = (kp / float(ss)) * 2 - 1", "\n", "#print(kp.size())", "\n", "#print(grid.size())", "\n", "y", "=", "torch", ".", "abs", "(", "grid", "-", "kp", ")", "\n", "y", "=", "torch", ".", "exp", "(", "-", "y", "/", "(", "std", "**", "2", ")", ")", "\n", "z", "=", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "*", "y", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "z", "=", "z", "/", "torch", ".", "max", "(", "z", ")", "\n", "\n", "assert", "bs", "==", "z", ".", "size", "(", "0", ")", "and", "num_kp", "==", "z", ".", "size", "(", "1", ")", "and", "ss", "==", "z", ".", "size", "(", "2", ")", "and", "ss", "==", "z", ".", "size", "(", "3", ")", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.transform_kp": [[139, 146], ["theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "transformed.squeeze.squeeze", "torch.matmul", "torch.matmul", "torch.matmul", "coordinates.unsqueeze"], "function", ["None"], ["", "def", "transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "    ", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "torch", ".", "matmul", "(", "theta", "[", ":", ",", ":", ",", ":", ",", ":", "2", "]", ",", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", ")", "+", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.inverse_transform_kp": [[199, 211], ["torch.inverse", "torch.inverse", "torch.inverse", "theta.unsqueeze.repeat", "theta.unsqueeze.unsqueeze", "inverse.unsqueeze.repeat", "inverse.unsqueeze.unsqueeze", "torch.matmul", "torch.matmul", "torch.matmul", "transformed.squeeze.squeeze", "coordinates.unsqueeze"], "function", ["None"], ["", "", "def", "inverse_transform_kp", "(", "coordinates", ",", "theta", ",", "bs", ")", ":", "\n", "\n", "    ", "inverse", "=", "torch", ".", "inverse", "(", "theta", "[", ":", ",", ":", ",", ":", "2", "]", ")", "\n", "theta", "=", "theta", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "theta", "=", "theta", ".", "unsqueeze", "(", "1", ")", "\n", "inverse", "=", "inverse", ".", "repeat", "(", "bs", ",", "1", ",", "1", ")", "\n", "inverse", "=", "inverse", ".", "unsqueeze", "(", "1", ")", "\n", "transformed", "=", "coordinates", ".", "unsqueeze", "(", "-", "1", ")", "-", "theta", "[", ":", ",", ":", ",", ":", ",", "2", ":", "]", "\n", "transformed", "=", "torch", ".", "matmul", "(", "inverse", ",", "transformed", ")", "\n", "transformed", "=", "transformed", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "transformed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.augment": [[213, 257], ["cv2.imread", "cv2.imread", "aug.to_deterministic", "aug.to_deterministic.", "aug.to_deterministic.", "numpy.stack", "numpy.stack", "cv2.cvtColor", "PIL.Image.fromarray", "cv2.cvtColor", "PIL.Image.fromarray", "PIL.Image.fromarray", "PIL.Image.fromarray", "cv2.imread", "cv2.imread", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "cv2.copyMakeBorder", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int", "cv2.imread", "cv2.imread", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims"], "function", ["None"], ["", "def", "augment", "(", "path", ",", "path2", ",", "seg_path", ",", "seg_path2", ",", "aug", ",", "pad", "=", "True", ",", "pad_factor", "=", "0.2", ")", ":", "\n", "\n", "    ", "img", "=", "cv2", ".", "imread", "(", "path", ")", "\n", "img2", "=", "cv2", ".", "imread", "(", "path2", ")", "\n", "\n", "if", "pad", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "\n", "seg2", "=", "cv2", ".", "imread", "(", "seg_path2", ")", "\n", "w", ",", "h", "=", "img", ".", "shape", "[", "0", "]", ",", "img", ".", "shape", "[", "1", "]", "\n", "img", "=", "cv2", ".", "copyMakeBorder", "(", "img", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "img2", "=", "cv2", ".", "copyMakeBorder", "(", "img2", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "\n", "seg", "=", "cv2", ".", "copyMakeBorder", "(", "seg", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "\n", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg2", "=", "cv2", ".", "copyMakeBorder", "(", "seg2", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "w", "*", "pad_factor", ")", ",", "int", "(", "h", "*", "pad_factor", ")", ",", "\n", "int", "(", "h", "*", "pad_factor", ")", ",", "borderType", "=", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "seg", "=", "seg", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "seg2", "=", "seg2", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "", "else", ":", "\n", "        ", "seg", "=", "cv2", ".", "imread", "(", "seg_path", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "seg2", "=", "cv2", ".", "imread", "(", "seg_path2", ")", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "\n", "\n", "", "aug_i", "=", "aug", ".", "to_deterministic", "(", ")", "\n", "img", ",", "seg", "=", "aug_i", "(", "images", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "0", ")", ",", "segmentation_maps", "=", "np", ".", "expand_dims", "(", "seg", ",", "axis", "=", "0", ")", ")", "\n", "img2", ",", "seg2", "=", "aug_i", "(", "images", "=", "np", ".", "expand_dims", "(", "img2", ",", "axis", "=", "0", ")", ",", "segmentation_maps", "=", "np", ".", "expand_dims", "(", "seg2", ",", "axis", "=", "0", ")", ")", "\n", "\n", "img", "=", "img", "[", "0", "]", "\n", "seg", "=", "seg", "[", "0", "]", "\n", "img2", "=", "img2", "[", "0", "]", "\n", "seg2", "=", "seg2", "[", "0", "]", "\n", "\n", "seg", "=", "np", ".", "stack", "(", "(", "seg", "[", ":", ",", ":", ",", "0", "]", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "seg2", "=", "np", ".", "stack", "(", "(", "seg2", "[", ":", ",", ":", ",", "0", "]", ",", ")", "*", "3", ",", "axis", "=", "-", "1", ")", "\n", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "im_pil", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "img2", "=", "cv2", ".", "cvtColor", "(", "img2", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "im_pil2", "=", "Image", ".", "fromarray", "(", "img2", ")", "\n", "\n", "seg_pil", "=", "Image", ".", "fromarray", "(", "seg", ")", "\n", "seg_pil2", "=", "Image", ".", "fromarray", "(", "seg2", ")", "\n", "\n", "return", "im_pil", ",", "im_pil2", ",", "seg_pil", ",", "seg_pil2", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.separation_loss_p": [[346, 366], ["x.size", "x.size", "x.repeat", "x.repeat().view", "torch.sum", "torch.sum", "torch.sum", "x.repeat.size", "torch.sum", "torch.sum", "torch.sum", "float", "x.repeat", "torch.max", "torch.max", "torch.max", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum.size"], "function", ["None"], ["", "", "def", "separation_loss_p", "(", "x", ",", "delta", ")", ":", "\n", "    ", "\"\"\"Computes the separation loss.\n    Args:\n      xyz: [batch, num_kp, 3] Input keypoints.\n      delta: A separation threshold. Incur 0 cost if the distance >= delta.\n    Returns:\n      The seperation loss.\n    \"\"\"", "\n", "\n", "bs", "=", "x", ".", "size", "(", "0", ")", "\n", "num_kp_p", "=", "x", ".", "size", "(", "1", ")", "\n", "t1_p", "=", "x", ".", "repeat", "(", "1", ",", "num_kp_p", ",", "1", ")", "\n", "\n", "t2_p", "=", "x", ".", "repeat", "(", "1", ",", "1", ",", "num_kp_p", ")", ".", "view", "(", "t1_p", ".", "size", "(", ")", ")", "\n", "diffsq_p", "=", "(", "t1_p", "-", "t2_p", ")", "**", "2", "\n", "\n", "# -> [batch, num_kp ^ 2]", "\n", "lensqr_p", "=", "torch", ".", "sum", "(", "diffsq_p", ",", "dim", "=", "2", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "torch", ".", "max", "(", "delta", "-", "lensqr_p", ",", "torch", ".", "zeros", "(", "lensqr_p", ".", "size", "(", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", ")", "/", "(", "float", "(", "num_kp_p", "*", "bs", "*", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.sill_loss": [[368, 382], ["heatmap.size", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["", "def", "sill_loss", "(", "heatmap", ",", "seg", ")", ":", "\n", "\n", "    ", "hm_size", "=", "heatmap", ".", "size", "(", "2", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "seg", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "seg", ",", "(", "hm_size", ",", "hm_size", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "seg", "=", "(", "seg", ">", "0.5", ")", ".", "float", "(", ")", "\n", "\n", "", "mul", "=", "heatmap", "*", "seg", "[", ":", ",", ":", "1", "]", "\n", "sum", "=", "torch", ".", "sum", "(", "mul", ",", "dim", "=", "[", "2", ",", "3", "]", ")", "\n", "log_", "=", "-", "torch", ".", "log", "(", "sum", "+", "1e-12", ")", "\n", "res", "=", "torch", ".", "mean", "(", "log_", ")", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points": [[384, 390], ["train_first_stage.norm", "kpoints.data.cpu().numpy", "numpy.transpose", "viz.create_image_column_with_kp", "kpoints.data.cpu"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column_with_kp"], ["", "def", "vis_points", "(", "viz", ",", "img", ",", "kpoints", ")", ":", "\n", "    ", "source", "=", "norm", "(", "img", ".", "data", ")", "\n", "kp_source", "=", "kpoints", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "source", "=", "np", ".", "transpose", "(", "source", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "viz", ".", "create_image_column_with_kp", "(", "source", ",", "kp_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.temp_loss": [[392, 400], ["torch.abs", "torch.abs", "torch.abs", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "torch.max", "torch.max", "torch.max", "torch.mean.size", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float().cuda", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.mean.size"], "function", ["None"], ["", "def", "temp_loss", "(", "kp1", ",", "kp2", ",", "alpha", ")", ":", "\n", "\n", "    ", "kp_diff", "=", "torch", ".", "abs", "(", "kp2", "-", "kp1", ")", "\n", "kp_diff", "=", "kp_diff", "**", "2", "\n", "kp_diff", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "kp_diff", ",", "dim", "=", "2", ")", ")", "\n", "kp_diff", "=", "torch", ".", "mean", "(", "kp_diff", ",", "dim", "=", "1", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "torch", ".", "max", "(", "alpha", "*", "kp_diff", ",", "torch", ".", "zeros", "(", "kp_diff", ".", "size", "(", ")", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ")", ")", "/", "(", "float", "(", "kp_diff", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train": [[402, 640], ["print", "tran_list.append", "tran_list.append", "tran_list.append", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "train_first_stage.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_first_stage.Aug_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "models.define_G", "train_first_stage.kp_disc", "torch.nn.MSELoss().cuda", "torch.nn.BCELoss().cuda", "G_A.train.cuda", "modules.keypoint_detector_strong.KPDetector_strong.cuda", "Disc.train.cuda", "torch.optim.Adam", "list", "torch.optim.Adam", "util.visualizer_kp.Visualizer", "modules.keypoint_detector_strong.KPDetector_strong.train", "G_A.train.train", "Disc.train.train", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "torch.full().cuda", "print", "range", "print", "os.path.join", "os.path.join", "train_first_stage.save_model", "print", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "torchvision.transforms.Resize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize", "modules.keypoint_detector_heatmap.KPDetector", "modules.keypoint_detector_strong.KPDetector_strong", "torch.normal", "torch.normal", "torch.normal", "torch.autograd.Variable.cuda", "torch.autograd.Variable", "list", "list", "Disc.train.parameters", "train_first_stage.load_model", "print", "zip", "torch.eye().view", "torch.eye().view", "torch.eye().view", "torch.nn.MSELoss", "torch.nn.BCELoss", "G_A.train.parameters", "modules.keypoint_detector_strong.KPDetector_strong.parameters", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "img_a.cuda.cuda", "img_b.cuda.cuda", "seg_a.cuda.cuda", "seg_b.cuda.cuda", "pair_a.cuda.cuda", "pair_b.cuda.cuda", "optim.Adam.zero_grad", "modules.keypoint_detector_strong.KPDetector_strong.", "modules.keypoint_detector_strong.KPDetector_strong.", "train_first_stage.kp_to_heatmap", "train_first_stage.kp_to_heatmap", "G_A.train.", "G_A.train.", "train_first_stage.equi_loss", "train_first_stage.equi_loss", "Disc.train.", "loss_g.backward", "optim.Adam.step", "optim.Adam.zero_grad", "Disc.train.", "nn.BCELoss().cuda.", "nn.BCELoss().cuda.", "loss_d.backward", "optim.Adam.step", "str", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "img_a.cuda.size", "img_b.cuda.size", "train_first_stage.transform_kp", "Disc.train.", "Disc.train.", "train_first_stage.temp_loss", "train_first_stage.temp_loss", "kpoints_a.detach", "Disc.train.", "Disc.train.", "print", "print", "print", "print", "print", "print", "print", "sys.stdout.flush", "print", "sys.stdout.flush", "torch.cat", "torch.cat", "torch.cat", "torchvision.save_image", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "torch.cat", "torch.cat", "torch.cat", "torchvision.save_image", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "imageio.imsave", "os.path.join", "os.path.join", "train_first_stage.save_model", "print", "torch.ones", "torch.ones", "torch.ones", "torch.eye", "torch.eye", "torch.eye", "train_first_stage.sill_loss", "train_first_stage.sill_loss", "nn.MSELoss().cuda.", "nn.MSELoss().cuda.", "train_first_stage.separation_loss_p", "train_first_stage.separation_loss_p", "nn.BCELoss().cuda.", "nn.BCELoss().cuda.", "transform_kp.detach", "kpoints_b.detach", "os.join", "train_first_stage.vis_points", "train_first_stage.vis_points", "train_first_stage.vis_points", "train_first_stage.vis_points", "train_first_stage.vis_points", "train_first_stage.vis_points", "np.concatenate.append", "np.concatenate.append", "os.join", "os.join", "train_first_stage.vis_points", "train_first_stage.vis_points", "os.join", "train_first_stage.vis_points", "torch.no_grad", "torch.no_grad", "torch.no_grad", "train_first_stage.transform_kp", "train_first_stage.inverse_transform_kp", "train_first_stage.kp_to_heatmap", "train_first_stage.kp_to_heatmap", "G_A.train.", "G_A.train.", "str", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "str", "img_b.cuda.size", "img_a.cuda.size", "str", "str", "train_first_stage.vis_points", "train_first_stage.vis_points", "str", "torch.zeros", "torch.zeros", "torch.zeros", "img_b.cuda.size"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.train", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.save_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.load_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.equi_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.equi_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.temp_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.temp_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.save_model", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.sill_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.sill_loss", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.separation_loss_p", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.separation_loss_p", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.inverse_transform_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.kp_to_heatmap", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.vis_points"], ["", "def", "train", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "out", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "out", ")", "\n", "\n", "", "print", "(", "sys", ".", "argv", ")", "\n", "\n", "tran_list", "=", "[", "]", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Resize", "(", "(", "args", ".", "resize_w", ",", "args", ".", "resize_h", ")", ")", ")", "\n", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "tran_list", ".", "append", "(", "torchvision", ".", "transforms", ".", "Normalize", "(", "[", "0.5", ",", "0.5", ",", "0.5", "]", ",", "[", "0.5", ",", "0.5", ",", "0.5", "]", ")", ")", "\n", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", ")", "\n", "transform_seg", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "tran_list", "[", ":", "-", "1", "]", ")", "\n", "\n", "dataset_a", "=", "Aug_dataset", "(", "args", ".", "root_a", ",", "transform", ",", "transform_seg", ",", "hflip", "=", "args", ".", "hflip", ",", "ext", "=", "args", ".", "ext_a", ",", "prefix", "=", "args", ".", "prefix_a", ",", "pad_factor", "=", "args", ".", "pad_factor_a", ")", "\n", "data_loader_a", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_a", ",", "shuffle", "=", "True", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "True", ")", "\n", "\n", "dataset_b", "=", "Aug_dataset", "(", "args", ".", "root_b", ",", "transform", ",", "transform_seg", ",", "ext", "=", "args", ".", "ext_b", ",", "prefix", "=", "args", ".", "prefix_b", ",", "pad_factor", "=", "args", ".", "pad_factor_b", ")", "\n", "data_loader_b", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset_b", ",", "shuffle", "=", "True", ",", "batch_size", "=", "args", ".", "bs", ",", "drop_last", "=", "True", ")", "\n", "\n", "if", "not", "args", ".", "strong_kp", ":", "\n", "        ", "KP", "=", "KPDetector", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ")", "\n", "", "else", ":", "\n", "        ", "KP", "=", "KPDetector_strong", "(", "block_expansion", "=", "32", ",", "num_kp", "=", "args", ".", "num_kp", ",", "num_channels", "=", "3", ",", "max_features", "=", "1024", ",", "\n", "num_blocks", "=", "5", ",", "temperature", "=", "0.1", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "args", ".", "scale_kp", ",", "args", "=", "args", ")", "\n", "\n", "", "ch_size", "=", "args", ".", "num_kp", "\n", "\n", "\n", "G_A", "=", "nets", ".", "define_G", "(", "ch_size", ",", "2", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ",", "not_mask", "=", "False", ",", "only_mask", "=", "True", ")", "\n", "\n", "Disc", "=", "kp_disc", "(", "kp_num", "=", "args", ".", "num_kp", ")", "\n", "\n", "if", "args", ".", "affine", ":", "\n", "        ", "noise", "=", "torch", ".", "normal", "(", "mean", "=", "0", ",", "std", "=", "0.05", "*", "torch", ".", "ones", "(", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "learned_t", "=", "noise", "+", "torch", ".", "eye", "(", "2", ",", "3", ")", ".", "view", "(", "1", ",", "2", ",", "3", ")", "\n", "learned_t", "=", "learned_t", ".", "cuda", "(", ")", "\n", "learned_t", "=", "Variable", "(", "learned_t", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "learned_t", "=", "None", "\n", "\n", "#l1 = nn.L1Loss().cuda()", "\n", "", "l2", "=", "nn", ".", "MSELoss", "(", ")", ".", "cuda", "(", ")", "\n", "bce", "=", "nn", ".", "BCELoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "G_A", "=", "G_A", ".", "cuda", "(", ")", "\n", "KP", "=", "KP", ".", "cuda", "(", ")", "\n", "Disc", "=", "Disc", ".", "cuda", "(", ")", "\n", "\n", "g_params", "=", "list", "(", "G_A", ".", "parameters", "(", ")", ")", "+", "list", "(", "KP", ".", "parameters", "(", ")", ")", "\n", "if", "args", ".", "affine", ":", "\n", "        ", "g_params", "+=", "[", "learned_t", "]", "\n", "", "g_opt", "=", "optim", ".", "Adam", "(", "g_params", ",", "lr", "=", "args", ".", "g_lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "d_params", "=", "list", "(", "Disc", ".", "parameters", "(", ")", ")", "\n", "d_opt", "=", "optim", ".", "Adam", "(", "d_params", ",", "lr", "=", "args", ".", "d_lr", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "viz", "=", "visualizer_kp", ".", "Visualizer", "(", "kp_size", "=", "args", ".", "num_kp", ")", "\n", "\n", "if", "args", ".", "load", "!=", "''", ":", "\n", "        ", "load_epoch", "=", "load_model", "(", "args", ".", "load", ",", "G_A", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ")", "\n", "print", "(", "\"Loaded successfully, epoch=\"", "+", "str", "(", "load_epoch", ")", ")", "\n", "", "else", ":", "\n", "        ", "load_epoch", "=", "0", "\n", "\n", "", "KP", "=", "KP", ".", "train", "(", ")", "\n", "G_A", "=", "G_A", ".", "train", "(", ")", "\n", "Disc", "=", "Disc", ".", "train", "(", ")", "\n", "\n", "A_label", "=", "torch", ".", "full", "(", "(", "args", ".", "bs", ",", ")", ",", "1.0", ")", ".", "cuda", "(", ")", "\n", "B_label", "=", "torch", ".", "full", "(", "(", "args", ".", "bs", ",", ")", ",", "0.0", ")", ".", "cuda", "(", ")", "\n", "\n", "iter_cnt", "=", "0", "\n", "\n", "print", "(", "'Started training...'", ")", "\n", "for", "epoch", "in", "range", "(", "load_epoch", ",", "args", ".", "epoch", ")", ":", "\n", "\n", "        ", "if", "iter_cnt", ">", "args", ".", "iters", ":", "\n", "            ", "break", "\n", "\n", "", "for", "data_a", ",", "data_b", "in", "zip", "(", "data_loader_a", ",", "data_loader_b", ")", ":", "\n", "\n", "            ", "img_a", ",", "pair_a", ",", "seg_a", ",", "seg_pair_a", "=", "data_a", "\n", "img_b", ",", "pair_b", ",", "seg_b", ",", "seg_pair_b", "=", "data_b", "\n", "\n", "img_a", "=", "img_a", ".", "cuda", "(", ")", "\n", "img_b", "=", "img_b", ".", "cuda", "(", ")", "\n", "\n", "seg_a", "=", "seg_a", ".", "cuda", "(", ")", "\n", "seg_b", "=", "seg_b", ".", "cuda", "(", ")", "\n", "\n", "pair_a", "=", "pair_a", ".", "cuda", "(", ")", "\n", "pair_b", "=", "pair_b", ".", "cuda", "(", ")", "\n", "\n", "#", "\n", "# Generators", "\n", "#", "\n", "\n", "g_opt", ".", "zero_grad", "(", ")", "\n", "\n", "kp_a", ",", "heatmap_a", "=", "KP", "(", "torch", ".", "cat", "(", "[", "img_a", ",", "pair_a", "]", ",", "dim", "=", "0", ")", ")", "\n", "kp_b", ",", "heatmap_b", "=", "KP", "(", "torch", ".", "cat", "(", "[", "img_b", ",", "pair_b", "]", ",", "dim", "=", "0", ")", ")", "\n", "\n", "kpoints_a", ",", "kpoints_pair_a", "=", "kp_a", "[", ":", "args", ".", "bs", "]", ",", "kp_a", "[", "args", ".", "bs", ":", "]", "\n", "kpoints_b", ",", "kpoints_pair_b", "=", "kp_b", "[", ":", "args", ".", "bs", "]", ",", "kp_b", "[", "args", ".", "bs", ":", "]", "\n", "\n", "new_heatmap_a", "=", "kp_to_heatmap", "(", "kpoints_a", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "new_heatmap_b", "=", "kp_to_heatmap", "(", "kpoints_b", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "decoded_a", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "decoded_b", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "loss_sill", "=", "(", "sill_loss", "(", "heatmap_a", "[", ":", "args", ".", "bs", "]", ",", "seg_a", ")", "+", "sill_loss", "(", "heatmap_b", "[", ":", "args", ".", "bs", "]", ",", "seg_b", ")", ")", "*", "args", ".", "lambda_sill", "\n", "\n", "l2_rec", "=", "args", ".", "lambda_l2", "*", "(", "l2", "(", "seg_a", ",", "decoded_a", ")", "+", "l2", "(", "seg_b", ",", "decoded_b", ")", ")", "\n", "\n", "loss_eq_a", ",", "transformed_frame_a", ",", "transformed_kp_a", "=", "equi_loss", "(", "img_a", ",", "kpoints_a", ",", "KP", ")", "\n", "loss_eq_a", "*=", "args", ".", "lambda_eq", "\n", "\n", "loss_eq_b", ",", "transformed_frame_b", ",", "transformed_kp_b", "=", "equi_loss", "(", "img_b", ",", "kpoints_b", ",", "KP", ")", "\n", "loss_eq_b", "*=", "args", ".", "lambda_eq", "\n", "\n", "loss_sep", "=", "args", ".", "lambda_sep", "*", "(", "separation_loss_p", "(", "kpoints_a", "[", ":", ",", ":", "10", "]", ",", "args", ".", "delta", ")", "+", "separation_loss_p", "(", "kpoints_b", "[", ":", ",", ":", "10", "]", ",", "args", ".", "delta", ")", ")", "\n", "\n", "preds_A", "=", "Disc", "(", "kpoints_a", ")", "\n", "if", "args", ".", "affine", ":", "\n", "                ", "kpoints_b_transformed", "=", "transform_kp", "(", "kpoints_b", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "preds_B", "=", "Disc", "(", "kpoints_b_transformed", ")", "\n", "", "else", ":", "\n", "                ", "preds_B", "=", "Disc", "(", "kpoints_b", ")", "\n", "\n", "", "loss_disc", "=", "args", ".", "lambda_disc", "*", "(", "bce", "(", "preds_A", ",", "A_label", ")", "+", "bce", "(", "preds_B", ",", "A_label", ")", ")", "\n", "\n", "loss_pred_a", "=", "args", ".", "lambda_pred", "*", "temp_loss", "(", "kpoints_a", ",", "kpoints_pair_a", ",", "args", ".", "new_alpha", ")", "\n", "loss_pred_b", "=", "args", ".", "lambda_pred", "*", "temp_loss", "(", "kpoints_b", ",", "kpoints_pair_b", ",", "args", ".", "new_alpha", ")", "\n", "\n", "loss_g", "=", "l2_rec", "+", "loss_eq_a", "+", "loss_eq_b", "+", "loss_sep", "+", "loss_disc", "+", "loss_sill", "+", "loss_pred_a", "+", "loss_pred_b", "\n", "\n", "loss_g", ".", "backward", "(", ")", "\n", "g_opt", ".", "step", "(", ")", "\n", "\n", "\n", "#", "\n", "# Discriminator", "\n", "#", "\n", "\n", "d_opt", ".", "zero_grad", "(", ")", "\n", "\n", "disc_A", "=", "Disc", "(", "kpoints_a", ".", "detach", "(", ")", ")", "\n", "if", "args", ".", "affine", ":", "\n", "                ", "disc_B", "=", "Disc", "(", "kpoints_b_transformed", ".", "detach", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "disc_B", "=", "Disc", "(", "kpoints_b", ".", "detach", "(", ")", ")", "\n", "\n", "", "loss_d_a", "=", "bce", "(", "disc_A", ",", "A_label", ")", "\n", "loss_d_b", "=", "bce", "(", "disc_B", ",", "B_label", ")", "\n", "\n", "loss_d", "=", "loss_d_a", "+", "loss_d_b", "\n", "\n", "loss_d", ".", "backward", "(", ")", "\n", "\n", "d_opt", ".", "step", "(", ")", "\n", "\n", "\n", "if", "iter_cnt", "%", "args", ".", "print_loss", "==", "0", ":", "\n", "                ", "print", "(", "'Outfile: %s <<>> Iteration %d'", "%", "(", "args", ".", "out", ",", "iter_cnt", ")", ")", "\n", "print", "(", "'loss_pred_a=%f, loss_pred_b=%f'", "%", "(", "float", "(", "loss_pred_a", ")", ",", "float", "(", "loss_pred_b", ")", ")", ")", "\n", "print", "(", "'<<< l2_rec=%f <<<< loss_eq_a=%f <<<< loss_eq_b=%f <<<< loss_sep=%f'", "%", "(", "float", "(", "l2_rec", ")", ",", "float", "(", "loss_eq_a", ")", ",", "float", "(", "loss_eq_b", ")", ",", "float", "(", "loss_sep", ")", ")", ")", "\n", "print", "(", "'G: loss_disc=%f, loss_sill=%f'", "%", "(", "float", "(", "loss_disc", ")", ",", "float", "(", "loss_sill", ")", ")", ")", "\n", "print", "(", "'D_confusion: loss_d_a=%f, loss_d_b=%f'", "%", "(", "float", "(", "loss_d_a", ")", ",", "float", "(", "loss_d_b", ")", ")", ")", "\n", "print", "(", "'DEBUG: disc_A=%f, disc_B=%f'", "%", "(", "float", "(", "disc_A", "[", "0", "]", ")", ",", "float", "(", "disc_B", "[", "0", "]", ")", ")", ")", "\n", "print", "(", "learned_t", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "iter_cnt", "%", "args", ".", "save_img", "==", "0", ":", "\n", "                ", "print", "(", "\"Saving imgs\"", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "exps", "=", "torch", ".", "cat", "(", "[", "img_a", ",", "seg_a", ",", "decoded_a", ",", "img_b", ",", "seg_b", ",", "decoded_b", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"reconstruction_\"", "+", "str", "(", "iter_cnt", ")", "+", "\".png\"", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_a", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "pair_a", ",", "kpoints_pair_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "transformed_frame_a", ",", "transformed_kp_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "pair_b", ",", "kpoints_pair_b", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "transformed_frame_b", ",", "transformed_kp_b", ")", ")", "\n", "if", "args", ".", "affine", ":", "\n", "                    ", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b_transformed", ")", ")", "\n", "to_print", ".", "append", "(", "(", "vis_points", "(", "viz", ",", "img_b", ",", "kpoints_b_transformed", ")", "+", "vis_points", "(", "viz", ",", "torch", ".", "zeros", "(", "img_b", ".", "size", "(", ")", ")", ",", "kpoints_b", ")", ")", "/", "2", ")", "\n", "\n", "", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"%s-kp.png\"", "%", "str", "(", "iter_cnt", ")", ")", ",", "to_print", ")", "\n", "\n", "if", "args", ".", "affine", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "kpoints_b_transformed", "=", "transform_kp", "(", "kpoints_b", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "kpoints_a_transformed", "=", "inverse_transform_kp", "(", "kpoints_a", ",", "learned_t", ",", "args", ".", "bs", ")", "\n", "new_heatmap_b_transformed", "=", "kp_to_heatmap", "(", "kpoints_b_transformed", ",", "img_b", ".", "size", "(", "-", "1", ")", ")", "\n", "new_heatmap_a_transformed", "=", "kp_to_heatmap", "(", "kpoints_a_transformed", ",", "img_a", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "new_heatmap_a", "=", "new_heatmap_a_transformed", "\n", "new_heatmap_b", "=", "new_heatmap_b_transformed", "\n", "\n", "_", ",", "decoded_ab", "=", "G_A", "(", "new_heatmap_a", ")", "\n", "decoded_ba", ",", "_", "=", "G_A", "(", "new_heatmap_b", ")", "\n", "\n", "\n", "", "", "exps", "=", "torch", ".", "cat", "(", "[", "img_a", ",", "decoded_ab", ",", "img_b", ",", "decoded_ba", "]", ",", "0", ")", "\n", "vutils", ".", "save_image", "(", "exps", ",", "osp", ".", "join", "(", "args", ".", "out", ",", "\"test_\"", "+", "str", "(", "iter_cnt", ")", "+", "\".png\"", ")", ",", "normalize", "=", "True", ",", "nrow", "=", "args", ".", "bs", ")", "\n", "\n", "to_print", "=", "[", "]", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ab", ",", "kpoints_a", ")", ")", "\n", "to_print", ".", "append", "(", "vis_points", "(", "viz", ",", "decoded_ba", ",", "kpoints_b", ")", ")", "\n", "to_print", "=", "np", ".", "concatenate", "(", "to_print", ",", "axis", "=", "1", ")", "\n", "to_print", "=", "(", "255", "*", "to_print", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "imageio", ".", "imsave", "(", "osp", ".", "join", "(", "args", ".", "out", ",", "\"%s-kp_test.png\"", "%", "str", "(", "iter_cnt", ")", ")", ",", "to_print", ")", "\n", "\n", "", "if", "iter_cnt", "%", "args", ".", "save_check", "==", "0", ":", "\n", "                ", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out", ",", "'checkpoint_'", "+", "str", "(", "iter_cnt", ")", ")", "\n", "save_model", "(", "save_file", ",", "G_A", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ",", "learned_t", ",", "epoch", ")", "\n", "print", "(", "\"Checkpoint saved\"", ")", "\n", "\n", "", "iter_cnt", "+=", "1", "\n", "if", "iter_cnt", ">", "args", ".", "iters", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "print", "(", "\"Training is done\"", ")", "\n", "save_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out", ",", "'checkpoint'", ")", "\n", "save_model", "(", "save_file", ",", "G_A", ",", "Disc", ",", "KP", ",", "g_opt", ",", "d_opt", ",", "learned_t", ",", "epoch", ")", "\n", "print", "(", "\"Final checkpoint saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.DataParallelWithCallback.replicate": [[64, 68], ["super().replicate", "replicate.execute_replication_callbacks"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.DataParallelWithCallback.replicate", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.execute_replication_callbacks"], ["def", "replicate", "(", "self", ",", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "super", "(", "DataParallelWithCallback", ",", "self", ")", ".", "replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.execute_replication_callbacks": [[27, 48], ["len", "enumerate", "list", "replicate.CallbackContext", "enumerate", "master_copy.modules", "range", "module.modules", "hasattr", "m.__data_parallel_replicate__"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__"], ["", "def", "execute_replication_callbacks", "(", "modules", ")", ":", "\n", "    ", "\"\"\"\n    Execute an replication callback `__data_parallel_replicate__` on each module created by original replication.\n\n    The callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\n    Note that, as all modules are isomorphism, we assign each sub-module with a context\n    (shared among multiple copies of this module on different devices).\n    Through this context, different copies can share some information.\n\n    We guarantee that the callback on the master copy (the first copy) will be called ahead of calling the callback\n    of any slave copies.\n    \"\"\"", "\n", "master_copy", "=", "modules", "[", "0", "]", "\n", "nr_modules", "=", "len", "(", "list", "(", "master_copy", ".", "modules", "(", ")", ")", ")", "\n", "ctxs", "=", "[", "CallbackContext", "(", ")", "for", "_", "in", "range", "(", "nr_modules", ")", "]", "\n", "\n", "for", "i", ",", "module", "in", "enumerate", "(", "modules", ")", ":", "\n", "        ", "for", "j", ",", "m", "in", "enumerate", "(", "module", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'__data_parallel_replicate__'", ")", ":", "\n", "                ", "m", ".", "__data_parallel_replicate__", "(", "ctxs", "[", "j", "]", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.patch_replication_callback": [[70, 95], ["isinstance", "functools.wraps", "old_replicate", "replicate.execute_replication_callbacks"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.replicate.execute_replication_callbacks"], ["", "", "def", "patch_replication_callback", "(", "data_parallel", ")", ":", "\n", "    ", "\"\"\"\n    Monkey-patch an existing `DataParallel` object. Add the replication callback.\n    Useful when you have customized `DataParallel` implementation.\n\n    Examples:\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n        > patch_replication_callback(sync_bn)\n        # this is equivalent to\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n    \"\"\"", "\n", "\n", "assert", "isinstance", "(", "data_parallel", ",", "DataParallel", ")", "\n", "\n", "old_replicate", "=", "data_parallel", ".", "replicate", "\n", "\n", "@", "functools", ".", "wraps", "(", "old_replicate", ")", "\n", "def", "new_replicate", "(", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "old_replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n", "", "data_parallel", ".", "replicate", "=", "new_replicate", "\n", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.__init__": [[21, 25], ["threading.Lock", "threading.Condition"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_result", "=", "None", "\n", "self", ".", "_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "_cond", "=", "threading", ".", "Condition", "(", "self", ".", "_lock", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.put": [[26, 31], ["comm.FutureResult._cond.notify"], "methods", ["None"], ["", "def", "put", "(", "self", ",", "result", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "assert", "self", ".", "_result", "is", "None", ",", "'Previous result has\\'t been fetched.'", "\n", "self", ".", "_result", "=", "result", "\n", "self", ".", "_cond", ".", "notify", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.get": [[32, 40], ["comm.FutureResult._cond.wait"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "if", "self", ".", "_result", "is", "None", ":", "\n", "                ", "self", ".", "_cond", ".", "wait", "(", ")", "\n", "\n", "", "res", "=", "self", ".", "_result", "\n", "self", ".", "_result", "=", "None", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SlavePipe.run_slave": [[49, 54], ["comm.SlavePipe.queue.put", "comm.SlavePipe.result.get", "comm.SlavePipe.queue.put"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.put"], ["def", "run_slave", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "queue", ".", "put", "(", "(", "self", ".", "identifier", ",", "msg", ")", ")", "\n", "ret", "=", "self", ".", "result", ".", "get", "(", ")", "\n", "self", ".", "queue", ".", "put", "(", "True", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.__init__": [[67, 77], ["queue.Queue", "collections.OrderedDict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "master_callback", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            master_callback: a callback to be invoked after having collected messages from slave devices.\n        \"\"\"", "\n", "self", ".", "_master_callback", "=", "master_callback", "\n", "self", ".", "_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "self", ".", "_registry", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_activated", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.__getstate__": [[78, 80], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "{", "'master_callback'", ":", "self", ".", "_master_callback", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.__setstate__": [[81, 83], ["comm.SyncMaster.__init__"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__init__", "(", "state", "[", "'master_callback'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.register_slave": [[84, 101], ["comm.FutureResult", "_MasterRegistry", "comm.SlavePipe", "comm.SyncMaster._queue.empty", "comm.SyncMaster._registry.clear"], "methods", ["None"], ["", "def", "register_slave", "(", "self", ",", "identifier", ")", ":", "\n", "        ", "\"\"\"\n        Register an slave device.\n\n        Args:\n            identifier: an identifier, usually is the device id.\n\n        Returns: a `SlavePipe` object which can be used to communicate with the master device.\n\n        \"\"\"", "\n", "if", "self", ".", "_activated", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "empty", "(", ")", ",", "'Queue is not clean before next initialization.'", "\n", "self", ".", "_activated", "=", "False", "\n", "self", ".", "_registry", ".", "clear", "(", ")", "\n", "", "future", "=", "FutureResult", "(", ")", "\n", "self", ".", "_registry", "[", "identifier", "]", "=", "_MasterRegistry", "(", "future", ")", "\n", "return", "SlavePipe", "(", "identifier", ",", "self", ".", "_queue", ",", "future", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.run_master": [[102, 134], ["range", "comm.SyncMaster._master_callback", "range", "intermediates.append", "comm.SyncMaster._registry[].result.put", "comm.SyncMaster._queue.get", "comm.SyncMaster._queue.get"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.FutureResult.get"], ["", "def", "run_master", "(", "self", ",", "master_msg", ")", ":", "\n", "        ", "\"\"\"\n        Main entry for the master device in each forward pass.\n        The messages were first collected from each devices (including the master device), and then\n        an callback will be invoked to compute the message to be sent back to each devices\n        (including the master device).\n\n        Args:\n            master_msg: the message that the master want to send to itself. This will be placed as the first\n            message when calling `master_callback`. For detailed usage, see `_SynchronizedBatchNorm` for an example.\n\n        Returns: the message to be sent back to the master device.\n\n        \"\"\"", "\n", "self", ".", "_activated", "=", "True", "\n", "\n", "intermediates", "=", "[", "(", "0", ",", "master_msg", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "intermediates", ".", "append", "(", "self", ".", "_queue", ".", "get", "(", ")", ")", "\n", "\n", "", "results", "=", "self", ".", "_master_callback", "(", "intermediates", ")", "\n", "assert", "results", "[", "0", "]", "[", "0", "]", "==", "0", ",", "'The first result should belongs to the master.'", "\n", "\n", "for", "i", ",", "res", "in", "results", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "_registry", "[", "i", "]", ".", "result", ".", "put", "(", "res", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "get", "(", ")", "is", "True", "\n", "\n", "", "return", "results", "[", "0", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.nr_slaves": [[135, 138], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "nr_slaves", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_registry", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.unittest.TorchTestCase.assertTensorClose": [[24, 29], ["unittest.TorchTestCase.assertTrue", "unittest.as_numpy", "unittest.as_numpy", "numpy.allclose", "numpy.abs().max", "numpy.abs().max", "numpy.abs", "numpy.abs", "numpy.fmax"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.unittest.as_numpy", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.unittest.as_numpy"], ["    ", "def", "assertTensorClose", "(", "self", ",", "a", ",", "b", ",", "atol", "=", "1e-3", ",", "rtol", "=", "1e-3", ")", ":", "\n", "        ", "npa", ",", "npb", "=", "as_numpy", "(", "a", ")", ",", "as_numpy", "(", "b", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "npa", ",", "npb", ",", "atol", "=", "atol", ")", ",", "\n", "'Tensor close check failed\\n{}\\n{}\\nadiff={}, rdiff={}'", ".", "format", "(", "a", ",", "b", ",", "np", ".", "abs", "(", "npa", "-", "npb", ")", ".", "max", "(", ")", ",", "np", ".", "abs", "(", "(", "npa", "-", "npb", ")", "/", "np", ".", "fmax", "(", "npa", ",", "1e-5", ")", ")", ".", "max", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.unittest.as_numpy": [[17, 21], ["isinstance", "v.cpu().numpy", "v.cpu"], "function", ["None"], ["def", "as_numpy", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "Variable", ")", ":", "\n", "        ", "v", "=", "v", ".", "data", "\n", "", "return", "v", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__init__": [[39, 47], ["torch.nn.modules.batchnorm._BatchNorm.__init__", "comm.SyncMaster"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ")", ":", "\n", "        ", "super", "(", "_SynchronizedBatchNorm", ",", "self", ")", ".", "__init__", "(", "num_features", ",", "eps", "=", "eps", ",", "momentum", "=", "momentum", ",", "affine", "=", "affine", ")", "\n", "\n", "self", ".", "_sync_master", "=", "SyncMaster", "(", "self", ".", "_data_parallel_master", ")", "\n", "\n", "self", ".", "_is_parallel", "=", "False", "\n", "self", ".", "_parallel_id", "=", "None", "\n", "self", ".", "_slave_pipe", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm.forward": [[48, 79], ["input.view.view.size", "input.view.view.view", "batchnorm._sum_ft", "batchnorm._sum_ft", "output.view", "torch.batch_norm", "torch.batch_norm", "input.view.view.size", "input.view.view.size", "input.view.view.size", "batchnorm._SynchronizedBatchNorm._sync_master.run_master", "batchnorm._SynchronizedBatchNorm._slave_pipe.run_slave", "_ChildMessage", "_ChildMessage", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.run_master", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SlavePipe.run_slave", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# If it is not parallel computation or is in evaluation mode, use PyTorch's implementation.", "\n", "        ", "if", "not", "(", "self", ".", "_is_parallel", "and", "self", ".", "training", ")", ":", "\n", "            ", "return", "F", ".", "batch_norm", "(", "\n", "input", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "\n", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n", "# Resize the input to (B, C, -1).", "\n", "", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "input", "=", "input", ".", "view", "(", "input", ".", "size", "(", "0", ")", ",", "self", ".", "num_features", ",", "-", "1", ")", "\n", "\n", "# Compute the sum and square-sum.", "\n", "sum_size", "=", "input", ".", "size", "(", "0", ")", "*", "input", ".", "size", "(", "2", ")", "\n", "input_sum", "=", "_sum_ft", "(", "input", ")", "\n", "input_ssum", "=", "_sum_ft", "(", "input", "**", "2", ")", "\n", "\n", "# Reduce-and-broadcast the statistics.", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_sync_master", ".", "run_master", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_slave_pipe", ".", "run_slave", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "\n", "# Compute the output.", "\n", "", "if", "self", ".", "affine", ":", "\n", "# MJY:: Fuse the multiplication for speed.", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", "*", "self", ".", "weight", ")", "+", "_unsqueeze_ft", "(", "self", ".", "bias", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", ")", "\n", "\n", "# Reshape it.", "\n", "", "return", "output", ".", "view", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__": [[80, 89], ["ctx.sync_master.register_slave"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.comm.SyncMaster.register_slave"], ["", "def", "__data_parallel_replicate__", "(", "self", ",", "ctx", ",", "copy_id", ")", ":", "\n", "        ", "self", ".", "_is_parallel", "=", "True", "\n", "self", ".", "_parallel_id", "=", "copy_id", "\n", "\n", "# parallel_id == 0 means master device.", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "ctx", ".", "sync_master", "=", "self", ".", "_sync_master", "\n", "", "else", ":", "\n", "            ", "self", ".", "_slave_pipe", "=", "ctx", ".", "sync_master", ".", "register_slave", "(", "copy_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm._data_parallel_master": [[90, 112], ["sorted", "sum", "torch.nn.parallel._functions.ReduceAddCoalesced.apply", "torch.nn.parallel._functions.ReduceAddCoalesced.apply", "batchnorm._SynchronizedBatchNorm._compute_mean_std", "torch.nn.parallel._functions.Broadcast.apply", "torch.nn.parallel._functions.Broadcast.apply", "enumerate", "i[].sum.get_device", "outputs.append", "i[].sum.get_device", "_MasterMessage"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std"], ["", "", "def", "_data_parallel_master", "(", "self", ",", "intermediates", ")", ":", "\n", "        ", "\"\"\"Reduce the sum and square-sum, compute the statistics, and broadcast it.\"\"\"", "\n", "\n", "# Always using same \"device order\" makes the ReduceAdd operation faster.", "\n", "# Thanks to:: Tete Xiao (http://tetexiao.com/)", "\n", "intermediates", "=", "sorted", "(", "intermediates", ",", "key", "=", "lambda", "i", ":", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", ")", "\n", "\n", "to_reduce", "=", "[", "i", "[", "1", "]", "[", ":", "2", "]", "for", "i", "in", "intermediates", "]", "\n", "to_reduce", "=", "[", "j", "for", "i", "in", "to_reduce", "for", "j", "in", "i", "]", "# flatten", "\n", "target_gpus", "=", "[", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", "for", "i", "in", "intermediates", "]", "\n", "\n", "sum_size", "=", "sum", "(", "[", "i", "[", "1", "]", ".", "sum_size", "for", "i", "in", "intermediates", "]", ")", "\n", "sum_", ",", "ssum", "=", "ReduceAddCoalesced", ".", "apply", "(", "target_gpus", "[", "0", "]", ",", "2", ",", "*", "to_reduce", ")", "\n", "mean", ",", "inv_std", "=", "self", ".", "_compute_mean_std", "(", "sum_", ",", "ssum", ",", "sum_size", ")", "\n", "\n", "broadcasted", "=", "Broadcast", ".", "apply", "(", "target_gpus", ",", "mean", ",", "inv_std", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "rec", "in", "enumerate", "(", "intermediates", ")", ":", "\n", "            ", "outputs", ".", "append", "(", "(", "rec", "[", "0", "]", ",", "_MasterMessage", "(", "*", "broadcasted", "[", "i", "*", "2", ":", "i", "*", "2", "+", "2", "]", ")", ")", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std": [[113, 126], ["bias_var.clamp"], "methods", ["None"], ["", "def", "_compute_mean_std", "(", "self", ",", "sum_", ",", "ssum", ",", "size", ")", ":", "\n", "        ", "\"\"\"Compute the mean and standard-deviation with sum and square-sum. This method\n        also maintains the moving average on the master device.\"\"\"", "\n", "assert", "size", ">", "1", ",", "'BatchNorm computes unbiased standard-deviation, which requires size > 1.'", "\n", "mean", "=", "sum_", "/", "size", "\n", "sumvar", "=", "ssum", "-", "sum_", "*", "mean", "\n", "unbias_var", "=", "sumvar", "/", "(", "size", "-", "1", ")", "\n", "bias_var", "=", "sumvar", "/", "size", "\n", "\n", "self", ".", "running_mean", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "+", "self", ".", "momentum", "*", "mean", ".", "data", "\n", "self", ".", "running_var", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "+", "self", ".", "momentum", "*", "unbias_var", ".", "data", "\n", "\n", "return", "mean", ",", "bias_var", ".", "clamp", "(", "self", ".", "eps", ")", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm1d._check_input_dim": [[184, 189], ["super()._check_input_dim", "ValueError", "input.dim", "input.dim", "input.dim"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "2", "and", "input", ".", "dim", "(", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 2D or 3D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm1d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm2d._check_input_dim": [[247, 252], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 4D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm2d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim": [[311, 316], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "5", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 5D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm3d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._sum_ft": [[24, 27], ["tensor.sum().sum", "tensor.sum"], "function", ["None"], ["def", "_sum_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"sum over the first and last dimention\"\"\"", "\n", "return", "tensor", ".", "sum", "(", "dim", "=", "0", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.sync_batchnorm.batchnorm._unsqueeze_ft": [[29, 32], ["tensor.unsqueeze().unsqueeze", "tensor.unsqueeze"], "function", ["None"], ["", "def", "_unsqueeze_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"add new dementions at the front and the tail\"\"\"", "\n", "return", "tensor", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_heatmap.KPDetector.__init__": [[13, 37], ["torch.nn.Module.__init__", "modules.util.Hourglass", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "keypoint_detector_heatmap.KPDetector.jacobian.weight.data.zero_", "keypoint_detector_heatmap.KPDetector.jacobian.bias.data.copy_", "modules.util.AntiAliasInterpolation2d", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "block_expansion", ",", "num_kp", ",", "num_channels", ",", "max_features", ",", "\n", "num_blocks", ",", "temperature", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "1", ",", "\n", "single_jacobian_map", "=", "False", ",", "pad", "=", "0", ")", ":", "\n", "        ", "super", "(", "KPDetector", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "predictor", "=", "Hourglass", "(", "block_expansion", ",", "in_features", "=", "num_channels", ",", "\n", "max_features", "=", "max_features", ",", "num_blocks", "=", "num_blocks", ")", "\n", "\n", "self", ".", "kp", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "predictor", ".", "out_filters", ",", "out_channels", "=", "num_kp", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "\n", "padding", "=", "pad", ")", "\n", "\n", "if", "estimate_jacobian", ":", "\n", "            ", "self", ".", "num_jacobian_maps", "=", "1", "if", "single_jacobian_map", "else", "num_kp", "\n", "self", ".", "jacobian", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "predictor", ".", "out_filters", ",", "\n", "out_channels", "=", "4", "*", "self", ".", "num_jacobian_maps", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "padding", "=", "pad", ")", "\n", "self", ".", "jacobian", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "jacobian", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "tensor", "(", "[", "1", ",", "0", ",", "0", ",", "1", "]", "*", "self", ".", "num_jacobian_maps", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "jacobian", "=", "None", "\n", "\n", "", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "if", "self", ".", "scale_factor", "!=", "1", ":", "\n", "            ", "self", ".", "down", "=", "AntiAliasInterpolation2d", "(", "num_channels", ",", "self", ".", "scale_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_heatmap.KPDetector.gaussian2kp": [[38, 53], ["heatmap.unsqueeze.unsqueeze.unsqueeze", "modules.util.make_coordinate_grid().unsqueeze_().unsqueeze_", "modules.util.make_coordinate_grid().unsqueeze_", "modules.util.make_coordinate_grid", "heatmap.unsqueeze.unsqueeze.type"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["", "", "def", "gaussian2kp", "(", "self", ",", "heatmap", ")", ":", "\n", "        ", "\"\"\"\n        Extract the mean and from a heatmap\n        \"\"\"", "\n", "shape", "=", "heatmap", ".", "shape", "\n", "heatmap", "=", "heatmap", ".", "unsqueeze", "(", "-", "1", ")", "\n", "grid", "=", "make_coordinate_grid", "(", "shape", "[", "2", ":", "]", ",", "heatmap", ".", "type", "(", ")", ")", ".", "unsqueeze_", "(", "0", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "value", "=", "(", "heatmap", "*", "grid", ")", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "\n", "#kp = {'value': value}", "\n", "#print(\"value\")", "\n", "#print(heatmap.sum(dim=(2, 3))[0])", "\n", "#print(\"value2\")", "\n", "#print(value[0])", "\n", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_heatmap.KPDetector.forward": [[54, 106], ["keypoint_detector_heatmap.KPDetector.predictor", "keypoint_detector_heatmap.KPDetector.kp", "keypoint_detector_heatmap.KPDetector.view", "torch.softmax", "torch.softmax", "heatmap.unsqueeze.unsqueeze.view", "keypoint_detector_heatmap.KPDetector.gaussian2kp", "keypoint_detector_heatmap.KPDetector.down", "keypoint_detector_heatmap.KPDetector.jacobian", "jacobian_map.reshape.reshape.reshape", "heatmap.unsqueeze.unsqueeze.unsqueeze", "jacobian.view.view.view", "jacobian.view.view.sum", "jacobian.view.view.view"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_strong.KPDetector_strong.gaussian2kp", "home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.Transform.jacobian"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "scale_factor", "!=", "1", ":", "\n", "            ", "x", "=", "self", ".", "down", "(", "x", ")", "\n", "\n", "\n", "#print(\"input\")", "\n", "\n", "#check = int((x != x).sum())", "\n", "#print(\"check \" + str(check))", "\n", "#print(torch.sum(torch.isnan(x)))", "\n", "#print(x.sum(dim=(1,2,3)))", "\n", "\n", "#print(x.shape)", "\n", "\n", "", "feature_map", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "#print(\"features\")", "\n", "#print(feature_map.sum(dim=(1, 2, 3)))", "\n", "\n", "#print(feature_map.shape)", "\n", "\n", "prediction", "=", "self", ".", "kp", "(", "feature_map", ")", "\n", "\n", "#print(\"prediction\")", "\n", "#print(prediction.sum(dim=(1, 2, 3)))", "\n", "#print(prediction.shape)", "\n", "\n", "final_shape", "=", "prediction", ".", "shape", "\n", "heatmap", "=", "prediction", ".", "view", "(", "final_shape", "[", "0", "]", ",", "final_shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "#print(\"before softmax\")", "\n", "#print(heatmap.size())", "\n", "#print(heatmap.sum(dim=2)[0])", "\n", "\n", "heatmap", "=", "F", ".", "softmax", "(", "heatmap", "/", "self", ".", "temperature", ",", "dim", "=", "2", ")", "\n", "heatmap", "=", "heatmap", ".", "view", "(", "*", "final_shape", ")", "\n", "\n", "out", "=", "self", ".", "gaussian2kp", "(", "heatmap", ")", "\n", "\n", "if", "self", ".", "jacobian", "is", "not", "None", ":", "\n", "            ", "jacobian_map", "=", "self", ".", "jacobian", "(", "feature_map", ")", "\n", "jacobian_map", "=", "jacobian_map", ".", "reshape", "(", "final_shape", "[", "0", "]", ",", "self", ".", "num_jacobian_maps", ",", "4", ",", "final_shape", "[", "2", "]", ",", "\n", "final_shape", "[", "3", "]", ")", "\n", "heatmap", "=", "heatmap", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "jacobian", "=", "heatmap", "*", "jacobian_map", "\n", "jacobian", "=", "jacobian", ".", "view", "(", "final_shape", "[", "0", "]", ",", "final_shape", "[", "1", "]", ",", "4", ",", "-", "1", ")", "\n", "jacobian", "=", "jacobian", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "jacobian", "=", "jacobian", ".", "view", "(", "jacobian", ".", "shape", "[", "0", "]", ",", "jacobian", ".", "shape", "[", "1", "]", ",", "2", ",", "2", ")", "\n", "out", "[", "'jacobian'", "]", "=", "jacobian", "\n", "\n", "", "return", "out", ",", "heatmap", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_strong.KPDetector_strong.__init__": [[13, 31], ["torch.nn.Module.__init__", "models.define_G", "modules.util.AntiAliasInterpolation2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G"], ["def", "__init__", "(", "self", ",", "block_expansion", ",", "num_kp", ",", "num_channels", ",", "max_features", ",", "\n", "num_blocks", ",", "temperature", ",", "estimate_jacobian", "=", "False", ",", "scale_factor", "=", "1", ",", "\n", "single_jacobian_map", "=", "False", ",", "pad", "=", "0", ",", "args", "=", "None", ")", ":", "\n", "        ", "super", "(", "KPDetector_strong", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "#self.predictor = Hourglass(block_expansion, in_features=num_channels,", "\n", "#                           max_features=max_features, num_blocks=num_blocks)", "\n", "\n", "#self.kp = nn.Conv2d(in_channels=self.predictor.out_filters, out_channels=num_kp, kernel_size=(7, 7),", "\n", "#                    padding=pad)", "\n", "\n", "self", ".", "predictor", "=", "nets", ".", "define_G", "(", "num_channels", ",", "num_kp", ",", "args", ".", "ngf", ",", "args", ".", "netG", ",", "args", ".", "norm", ",", "\n", "not", "args", ".", "no_dropout", ",", "args", ".", "init_type", ",", "args", ".", "init_gain", ")", "#, not_mask=False, only_mask=True)", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "if", "self", ".", "scale_factor", "!=", "1", ":", "\n", "            ", "self", ".", "down", "=", "AntiAliasInterpolation2d", "(", "num_channels", ",", "self", ".", "scale_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_strong.KPDetector_strong.gaussian2kp": [[32, 43], ["heatmap.unsqueeze.unsqueeze.unsqueeze", "modules.util.make_coordinate_grid().unsqueeze_().unsqueeze_", "modules.util.make_coordinate_grid().unsqueeze_", "modules.util.make_coordinate_grid", "heatmap.unsqueeze.unsqueeze.type"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["", "", "def", "gaussian2kp", "(", "self", ",", "heatmap", ")", ":", "\n", "        ", "\"\"\"\n        Extract the mean and from a heatmap\n        \"\"\"", "\n", "shape", "=", "heatmap", ".", "shape", "\n", "heatmap", "=", "heatmap", ".", "unsqueeze", "(", "-", "1", ")", "\n", "grid", "=", "make_coordinate_grid", "(", "shape", "[", "2", ":", "]", ",", "heatmap", ".", "type", "(", ")", ")", ".", "unsqueeze_", "(", "0", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "value", "=", "(", "heatmap", "*", "grid", ")", ".", "sum", "(", "dim", "=", "(", "2", ",", "3", ")", ")", "\n", "#kp = {'value': value}", "\n", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_strong.KPDetector_strong.forward": [[44, 61], ["keypoint_detector_strong.KPDetector_strong.predictor", "keypoint_detector_strong.KPDetector_strong.view", "torch.softmax", "heatmap.view.view.view", "keypoint_detector_strong.KPDetector_strong.gaussian2kp", "keypoint_detector_strong.KPDetector_strong.down"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.keypoint_detector_strong.KPDetector_strong.gaussian2kp"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "scale_factor", "!=", "1", ":", "\n", "            ", "x", "=", "self", ".", "down", "(", "x", ")", "\n", "\n", "#feature_map = self.predictor(x)", "\n", "#prediction = self.kp(feature_map)", "\n", "\n", "", "prediction", "=", "self", ".", "predictor", "(", "x", ")", "\n", "\n", "final_shape", "=", "prediction", ".", "shape", "\n", "heatmap", "=", "prediction", ".", "view", "(", "final_shape", "[", "0", "]", ",", "final_shape", "[", "1", "]", ",", "-", "1", ")", "\n", "heatmap", "=", "F", ".", "softmax", "(", "heatmap", "/", "self", ".", "temperature", ",", "dim", "=", "2", ")", "\n", "heatmap", "=", "heatmap", ".", "view", "(", "*", "final_shape", ")", "\n", "\n", "out", "=", "self", ".", "gaussian2kp", "(", "heatmap", ")", "\n", "\n", "return", "out", ",", "heatmap", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.ResBlock2d.__init__": [[56, 64], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "sync_batchnorm.SynchronizedBatchNorm2d", "sync_batchnorm.SynchronizedBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "kernel_size", ",", "padding", ")", ":", "\n", "        ", "super", "(", "ResBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "in_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "in_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ")", "\n", "self", ".", "norm1", "=", "BatchNorm2d", "(", "in_features", ",", "affine", "=", "True", ")", "\n", "self", ".", "norm2", "=", "BatchNorm2d", "(", "in_features", ",", "affine", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.ResBlock2d.forward": [[65, 74], ["util.ResBlock2d.norm1", "torch.relu", "torch.relu", "util.ResBlock2d.conv1", "util.ResBlock2d.norm2", "torch.relu", "torch.relu", "util.ResBlock2d.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "norm1", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "out", "=", "self", ".", "norm2", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "+=", "x", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.UpBlock2d.__init__": [[81, 87], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "sync_batchnorm.SynchronizedBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "UpBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "out_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm", "=", "BatchNorm2d", "(", "out_features", ",", "affine", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.UpBlock2d.forward": [[88, 94], ["torch.interpolate", "torch.interpolate", "util.UpBlock2d.conv", "util.UpBlock2d.norm", "torch.relu", "torch.relu"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "interpolate", "(", "x", ",", "scale_factor", "=", "2", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "out", "=", "self", ".", "norm", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.DownBlock2d.__init__": [[101, 107], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "sync_batchnorm.SynchronizedBatchNorm2d", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "DownBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "out_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm", "=", "BatchNorm2d", "(", "out_features", ",", "affine", "=", "True", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "(", "2", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.DownBlock2d.forward": [[108, 114], ["util.DownBlock2d.conv", "util.DownBlock2d.norm", "torch.relu", "torch.relu", "util.DownBlock2d.pool"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "x", ")", "\n", "out", "=", "self", ".", "norm", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "pool", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.SameBlock2d.__init__": [[121, 126], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "sync_batchnorm.SynchronizedBatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "groups", "=", "1", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ":", "\n", "        ", "super", "(", "SameBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "out_features", ",", "\n", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm", "=", "BatchNorm2d", "(", "out_features", ",", "affine", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.SameBlock2d.forward": [[127, 132], ["util.SameBlock2d.conv", "util.SameBlock2d.norm", "torch.relu", "torch.relu"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.None.train_first_stage.norm"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv", "(", "x", ")", "\n", "out", "=", "self", ".", "norm", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Encoder.__init__": [[139, 148], ["torch.nn.Module.__init__", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "down_blocks.append", "util.DownBlock2d", "min", "min"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "block_expansion", ",", "in_features", ",", "num_blocks", "=", "3", ",", "max_features", "=", "256", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "down_blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "down_blocks", ".", "append", "(", "DownBlock2d", "(", "in_features", "if", "i", "==", "0", "else", "min", "(", "max_features", ",", "block_expansion", "*", "(", "2", "**", "i", ")", ")", ",", "\n", "min", "(", "max_features", ",", "block_expansion", "*", "(", "2", "**", "(", "i", "+", "1", ")", ")", ")", ",", "\n", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ")", "\n", "", "self", ".", "down_blocks", "=", "nn", ".", "ModuleList", "(", "down_blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Encoder.forward": [[149, 154], ["outs.append", "down_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outs", "=", "[", "x", "]", "\n", "for", "down_block", "in", "self", ".", "down_blocks", ":", "\n", "            ", "outs", ".", "append", "(", "down_block", "(", "outs", "[", "-", "1", "]", ")", ")", "\n", "", "return", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Decoder.__init__": [[161, 173], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "min", "up_blocks.append", "min", "util.UpBlock2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "block_expansion", ",", "in_features", ",", "num_blocks", "=", "3", ",", "max_features", "=", "256", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "up_blocks", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "in_filters", "=", "(", "1", "if", "i", "==", "num_blocks", "-", "1", "else", "2", ")", "*", "min", "(", "max_features", ",", "block_expansion", "*", "(", "2", "**", "(", "i", "+", "1", ")", ")", ")", "\n", "out_filters", "=", "min", "(", "max_features", ",", "block_expansion", "*", "(", "2", "**", "i", ")", ")", "\n", "up_blocks", ".", "append", "(", "UpBlock2d", "(", "in_filters", ",", "out_filters", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ")", "\n", "\n", "", "self", ".", "up_blocks", "=", "nn", ".", "ModuleList", "(", "up_blocks", ")", "\n", "self", ".", "out_filters", "=", "block_expansion", "+", "in_features", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Decoder.forward": [[174, 181], ["x.pop", "up_block", "x.pop", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "x", ".", "pop", "(", ")", "\n", "for", "up_block", "in", "self", ".", "up_blocks", ":", "\n", "            ", "out", "=", "up_block", "(", "out", ")", "\n", "skip", "=", "x", ".", "pop", "(", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "out", ",", "skip", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Hourglass.__init__": [[188, 193], ["torch.nn.Module.__init__", "util.Encoder", "util.Decoder"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "block_expansion", ",", "in_features", ",", "num_blocks", "=", "3", ",", "max_features", "=", "256", ")", ":", "\n", "        ", "super", "(", "Hourglass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "Encoder", "(", "block_expansion", ",", "in_features", ",", "num_blocks", ",", "max_features", ")", "\n", "self", ".", "decoder", "=", "Decoder", "(", "block_expansion", ",", "in_features", ",", "num_blocks", ",", "max_features", ")", "\n", "self", ".", "out_filters", "=", "self", ".", "decoder", ".", "out_filters", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.Hourglass.forward": [[194, 196], ["util.Hourglass.decoder", "util.Hourglass.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "self", ".", "encoder", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.AntiAliasInterpolation2d.__init__": [[202, 235], ["torch.nn.Module.__init__", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "zip", "kernel.repeat.repeat.view", "kernel.repeat.repeat.repeat", "util.AntiAliasInterpolation2d.register_buffer", "int", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "round", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "kernel.repeat.repeat.size", "kernel.repeat.repeat.dim"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "channels", ",", "scale", ")", ":", "\n", "        ", "super", "(", "AntiAliasInterpolation2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "sigma", "=", "(", "1", "/", "scale", "-", "1", ")", "/", "2", "\n", "kernel_size", "=", "2", "*", "round", "(", "sigma", "*", "4", ")", "+", "1", "\n", "self", ".", "ka", "=", "kernel_size", "//", "2", "\n", "self", ".", "kb", "=", "self", ".", "ka", "-", "1", "if", "kernel_size", "%", "2", "==", "0", "else", "self", ".", "ka", "\n", "\n", "kernel_size", "=", "[", "kernel_size", ",", "kernel_size", "]", "\n", "sigma", "=", "[", "sigma", ",", "sigma", "]", "\n", "# The gaussian kernel is the product of the", "\n", "# gaussian function of each dimension.", "\n", "kernel", "=", "1", "\n", "meshgrids", "=", "torch", ".", "meshgrid", "(", "\n", "[", "\n", "torch", ".", "arange", "(", "size", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "size", "in", "kernel_size", "\n", "]", "\n", ")", "\n", "for", "size", ",", "std", ",", "mgrid", "in", "zip", "(", "kernel_size", ",", "sigma", ",", "meshgrids", ")", ":", "\n", "            ", "mean", "=", "(", "size", "-", "1", ")", "/", "2", "\n", "kernel", "*=", "torch", ".", "exp", "(", "-", "(", "mgrid", "-", "mean", ")", "**", "2", "/", "(", "2", "*", "std", "**", "2", ")", ")", "\n", "\n", "# Make sure sum of values in gaussian kernel equals 1.", "\n", "", "kernel", "=", "kernel", "/", "torch", ".", "sum", "(", "kernel", ")", "\n", "# Reshape to depthwise convolutional weight", "\n", "kernel", "=", "kernel", ".", "view", "(", "1", ",", "1", ",", "*", "kernel", ".", "size", "(", ")", ")", "\n", "kernel", "=", "kernel", ".", "repeat", "(", "channels", ",", "*", "[", "1", "]", "*", "(", "kernel", ".", "dim", "(", ")", "-", "1", ")", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'weight'", ",", "kernel", ")", "\n", "self", ".", "groups", "=", "channels", "\n", "self", ".", "scale", "=", "scale", "\n", "inv_scale", "=", "1", "/", "scale", "\n", "self", ".", "int_inv_scale", "=", "int", "(", "inv_scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.AntiAliasInterpolation2d.forward": [[236, 245], ["torch.pad", "torch.pad", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "scale", "==", "1.0", ":", "\n", "            ", "return", "input", "\n", "\n", "", "out", "=", "F", ".", "pad", "(", "input", ",", "(", "self", ".", "ka", ",", "self", ".", "kb", ",", "self", ".", "ka", ",", "self", ".", "kb", ")", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "out", ",", "weight", "=", "self", ".", "weight", ",", "groups", "=", "self", ".", "groups", ")", "\n", "out", "=", "out", "[", ":", ",", ":", ",", ":", ":", "self", ".", "int_inv_scale", ",", ":", ":", "self", ".", "int_inv_scale", "]", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.kp2gaussian": [[8, 30], ["util.make_coordinate_grid", "coordinate_grid.repeat.view", "coordinate_grid.repeat.repeat", "mean.view.view", "torch.exp", "torch.exp", "mean.view.type", "len"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid"], ["def", "kp2gaussian", "(", "kp", ",", "spatial_size", ",", "kp_variance", ")", ":", "\n", "    ", "\"\"\"\n    Transform a keypoint into gaussian like representation\n    \"\"\"", "\n", "mean", "=", "kp", "[", "'value'", "]", "\n", "\n", "coordinate_grid", "=", "make_coordinate_grid", "(", "spatial_size", ",", "mean", ".", "type", "(", ")", ")", "\n", "number_of_leading_dimensions", "=", "len", "(", "mean", ".", "shape", ")", "-", "1", "\n", "shape", "=", "(", "1", ",", ")", "*", "number_of_leading_dimensions", "+", "coordinate_grid", ".", "shape", "\n", "coordinate_grid", "=", "coordinate_grid", ".", "view", "(", "*", "shape", ")", "\n", "repeats", "=", "mean", ".", "shape", "[", ":", "number_of_leading_dimensions", "]", "+", "(", "1", ",", "1", ",", "1", ")", "\n", "coordinate_grid", "=", "coordinate_grid", ".", "repeat", "(", "*", "repeats", ")", "\n", "\n", "# Preprocess kp shape", "\n", "shape", "=", "mean", ".", "shape", "[", ":", "number_of_leading_dimensions", "]", "+", "(", "1", ",", "1", ",", "2", ")", "\n", "mean", "=", "mean", ".", "view", "(", "*", "shape", ")", "\n", "\n", "mean_sub", "=", "(", "coordinate_grid", "-", "mean", ")", "\n", "\n", "out", "=", "torch", ".", "exp", "(", "-", "0.5", "*", "(", "mean_sub", "**", "2", ")", ".", "sum", "(", "-", "1", ")", "/", "kp_variance", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.modules.util.make_coordinate_grid": [[32, 49], ["torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type", "torch.arange().type.view().repeat", "torch.arange().type.view().repeat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().type.view", "torch.arange().type.view", "x.view().repeat.unsqueeze_", "y.view().repeat.unsqueeze_"], "function", ["None"], ["", "def", "make_coordinate_grid", "(", "spatial_size", ",", "type", ")", ":", "\n", "    ", "\"\"\"\n    Create a meshgrid [-1,1] x [-1,1] of given spatial_size.\n    \"\"\"", "\n", "h", ",", "w", "=", "spatial_size", "\n", "x", "=", "torch", ".", "arange", "(", "w", ")", ".", "type", "(", "type", ")", "\n", "y", "=", "torch", ".", "arange", "(", "h", ")", ".", "type", "(", "type", ")", "\n", "\n", "x", "=", "(", "2", "*", "(", "x", "/", "(", "w", "-", "1", ")", ")", "-", "1", ")", "\n", "y", "=", "(", "2", "*", "(", "y", "/", "(", "h", "-", "1", ")", ")", "-", "1", ")", "\n", "\n", "yy", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "w", ")", "\n", "xx", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "h", ",", "1", ")", "\n", "\n", "meshed", "=", "torch", ".", "cat", "(", "[", "xx", ".", "unsqueeze_", "(", "2", ")", ",", "yy", ".", "unsqueeze_", "(", "2", ")", "]", ",", "2", ")", "\n", "\n", "return", "meshed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.__init__": [[15, 35], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "dominate.tags.meta", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "        ", "\"\"\"Initialize the HTML classes\n\n        Parameters:\n            web_dir (str) -- a directory that stores the webpage. HTML file will be created at <web_dir>/index.html; images will be saved at <web_dir/images/\n            title (str)   -- the webpage name\n            refresh (int) -- how often the website refresh itself; if 0; no refreshing\n        \"\"\"", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "refresh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.get_image_dir": [[36, 39], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the directory that stores images\"\"\"", "\n", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_header": [[40, 48], ["dominate.tags.h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Insert a header to the HTML file\n\n        Parameters:\n            text (str) -- the header text\n        \"\"\"", "\n", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_images": [[49, 68], ["dominate.tags.table", "html.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "dominate.tags.br", "dominate.tags.p", "dominate.tags.a", "dominate.tags.img", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "        ", "\"\"\"add images to the HTML file\n\n        Parameters:\n            ims (str list)   -- a list of image paths\n            txts (str list)  -- a list of image names shown on the website\n            links (str list) --  a list of hyperref links; when you click an image, it will redirect you to a new page\n        \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "with", "td", "(", "style", "=", "\"word-wrap: break-word;\"", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "style", "=", "\"width:%dpx\"", "%", "width", ",", "src", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "im", ")", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save": [[69, 75], ["open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "\"\"\"save the current content to the HMTL file\"\"\"", "\n", "html_file", "=", "'%s/index.html'", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.__init__": [[53, 87], ["os.path.join", "visdom.Visdom", "os.path.join", "os.path.join", "print", "util.mkdirs", "open", "time.strftime", "log_file.write", "visualizer.Visualizer.vis.check_connection", "visualizer.Visualizer.create_visdom_connections"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.util.mkdirs", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.create_visdom_connections"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the Visualizer class\n\n        Parameters:\n            opt -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        Step 1: Cache the training/test options\n        Step 2: connect to a visdom server\n        Step 3: create an HTML object for saveing HTML filters\n        Step 4: create a logging file to store training losses\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "# cache the option", "\n", "self", ".", "display_id", "=", "opt", ".", "display_id", "\n", "self", ".", "use_html", "=", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_html", "\n", "self", ".", "win_size", "=", "opt", ".", "display_winsize", "\n", "self", ".", "name", "=", "opt", ".", "name", "\n", "self", ".", "port", "=", "opt", ".", "display_port", "\n", "self", ".", "saved", "=", "False", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# connect to a visdom server given <display_port> and <display_server>", "\n", "            ", "import", "visdom", "\n", "self", ".", "ncols", "=", "opt", ".", "display_ncols", "\n", "self", ".", "vis", "=", "visdom", ".", "Visdom", "(", "server", "=", "opt", ".", "display_server", ",", "port", "=", "opt", ".", "display_port", ",", "env", "=", "opt", ".", "display_env", ")", "\n", "if", "not", "self", ".", "vis", ".", "check_connection", "(", ")", ":", "\n", "                ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "if", "self", ".", "use_html", ":", "# create an HTML object at <checkpoints_dir>/web/; images will be saved under <checkpoints_dir>/web/images/", "\n", "            ", "self", ".", "web_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'web'", ")", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "print", "(", "'create web directory %s...'", "%", "self", ".", "web_dir", ")", "\n", "util", ".", "mkdirs", "(", "[", "self", ".", "web_dir", ",", "self", ".", "img_dir", "]", ")", "\n", "# create a logging file to store training losses", "\n", "", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.reset": [[88, 91], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the self.saved status\"\"\"", "\n", "self", ".", "saved", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.create_visdom_connections": [[92, 98], ["print", "print", "subprocess.Popen"], "methods", ["None"], ["", "def", "create_visdom_connections", "(", "self", ")", ":", "\n", "        ", "\"\"\"If the program could not connect to Visdom server, this function will start a new server at port < self.port > \"\"\"", "\n", "cmd", "=", "sys", ".", "executable", "+", "' -m visdom.server -p %d &>/dev/null &'", "%", "self", ".", "port", "\n", "print", "(", "'\\n\\nCould not connect to Visdom server. \\n Trying to start a server....'", ")", "\n", "print", "(", "'Command: %s'", "%", "cmd", ")", "\n", "Popen", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.display_current_results": [[99, 179], ["visuals.items", "html.HTML", "range", "html.HTML.save", "min", "visuals.items", "util.tensor2im", "os.path.join", "util.save_image", "html.HTML.add_header", "visuals.items", "html.HTML.add_images", "len", "util.tensor2im", "images.append", "numpy.ones_like", "images.append", "visualizer.Visualizer.vis.images", "visualizer.Visualizer.vis.text", "visuals.items", "util.tensor2im", "ims.append", "txts.append", "links.append", "next", "util.tensor2im.transpose", "util.tensor2im.transpose", "visualizer.Visualizer.create_visdom_connections", "util.tensor2im", "visualizer.Visualizer.vis.image", "visualizer.Visualizer.create_visdom_connections", "iter", "dict", "dict", "util.tensor2im.transpose", "visuals.values", "dict"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_header", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_images", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.create_visdom_connections", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.create_visdom_connections"], ["", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "save_result", ")", ":", "\n", "        ", "\"\"\"Display current results on visdom; save current results to an HTML file.\n\n        Parameters:\n            visuals (OrderedDict) - - dictionary of images to display or save\n            epoch (int) - - the current epoch\n            save_result (bool) - - if save the current results to an HTML file\n        \"\"\"", "\n", "if", "self", ".", "display_id", ">", "0", ":", "# show images in the browser using visdom", "\n", "            ", "ncols", "=", "self", ".", "ncols", "\n", "if", "ncols", ">", "0", ":", "# show all the images in one visdom panel", "\n", "                ", "ncols", "=", "min", "(", "ncols", ",", "len", "(", "visuals", ")", ")", "\n", "h", ",", "w", "=", "next", "(", "iter", "(", "visuals", ".", "values", "(", ")", ")", ")", ".", "shape", "[", ":", "2", "]", "\n", "table_css", "=", "\"\"\"<style>\n                        table {border-collapse: separate; border-spacing: 4px; white-space: nowrap; text-align: center}\n                        table td {width: % dpx; height: % dpx; padding: 4px; outline: 4px solid black}\n                        </style>\"\"\"", "%", "(", "w", ",", "h", ")", "# create a table css", "\n", "# create a table of images.", "\n", "title", "=", "self", ".", "name", "\n", "label_html", "=", "''", "\n", "label_html_row", "=", "''", "\n", "images", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "label_html_row", "+=", "'<td>%s</td>'", "%", "label", "\n", "images", ".", "append", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "\n", "idx", "+=", "1", "\n", "if", "idx", "%", "ncols", "==", "0", ":", "\n", "                        ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "label_html_row", "=", "''", "\n", "", "", "white_image", "=", "np", ".", "ones_like", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ")", "*", "255", "\n", "while", "idx", "%", "ncols", "!=", "0", ":", "\n", "                    ", "images", ".", "append", "(", "white_image", ")", "\n", "label_html_row", "+=", "'<td></td>'", "\n", "idx", "+=", "1", "\n", "", "if", "label_html_row", "!=", "''", ":", "\n", "                    ", "label_html", "+=", "'<tr>%s</tr>'", "%", "label_html_row", "\n", "", "try", ":", "\n", "                    ", "self", ".", "vis", ".", "images", "(", "images", ",", "nrow", "=", "ncols", ",", "win", "=", "self", ".", "display_id", "+", "1", ",", "\n", "padding", "=", "2", ",", "opts", "=", "dict", "(", "title", "=", "title", "+", "' images'", ")", ")", "\n", "label_html", "=", "'<table>%s</table>'", "%", "label_html", "\n", "self", ".", "vis", ".", "text", "(", "table_css", "+", "label_html", ",", "win", "=", "self", ".", "display_id", "+", "2", ",", "\n", "opts", "=", "dict", "(", "title", "=", "title", "+", "' labels'", ")", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "else", ":", "# show each image in a separate visdom panel;", "\n", "                ", "idx", "=", "1", "\n", "try", ":", "\n", "                    ", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                        ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "self", ".", "vis", ".", "image", "(", "image_numpy", ".", "transpose", "(", "[", "2", ",", "0", ",", "1", "]", ")", ",", "opts", "=", "dict", "(", "title", "=", "label", ")", ",", "\n", "win", "=", "self", ".", "display_id", "+", "idx", ")", "\n", "idx", "+=", "1", "\n", "", "", "except", "VisdomExceptionBase", ":", "\n", "                    ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n", "", "", "", "if", "self", ".", "use_html", "and", "(", "save_result", "or", "not", "self", ".", "saved", ")", ":", "# save images to an HTML file if they haven't been saved.", "\n", "            ", "self", ".", "saved", "=", "True", "\n", "# save images to the disk", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_%s.png'", "%", "(", "epoch", ",", "label", ")", ")", "\n", "util", ".", "save_image", "(", "image_numpy", ",", "img_path", ")", "\n", "\n", "# update website", "\n", "", "webpage", "=", "html", ".", "HTML", "(", "self", ".", "web_dir", ",", "'Experiment name = %s'", "%", "self", ".", "name", ",", "refresh", "=", "1", ")", "\n", "for", "n", "in", "range", "(", "epoch", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "webpage", ".", "add_header", "(", "'epoch [%d]'", "%", "n", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "image_numpy", "=", "util", ".", "tensor2im", "(", "image", ")", "\n", "img_path", "=", "'epoch%.3d_%s.png'", "%", "(", "n", ",", "label", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "webpage", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.plot_current_losses": [[180, 204], ["visualizer.Visualizer.plot_data[].append", "visualizer.Visualizer.plot_data[].append", "hasattr", "visualizer.Visualizer.vis.line", "list", "visualizer.Visualizer.create_visdom_connections", "losses.keys", "numpy.stack", "numpy.array", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.create_visdom_connections"], ["", "", "def", "plot_current_losses", "(", "self", ",", "epoch", ",", "counter_ratio", ",", "losses", ")", ":", "\n", "        ", "\"\"\"display the current losses on visdom display: dictionary of error labels and values\n\n        Parameters:\n            epoch (int)           -- current epoch\n            counter_ratio (float) -- progress (percentage) in the current epoch, between 0 to 1\n            losses (OrderedDict)  -- training losses stored in the format of (name, float) pairs\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'plot_data'", ")", ":", "\n", "            ", "self", ".", "plot_data", "=", "{", "'X'", ":", "[", "]", ",", "'Y'", ":", "[", "]", ",", "'legend'", ":", "list", "(", "losses", ".", "keys", "(", ")", ")", "}", "\n", "", "self", ".", "plot_data", "[", "'X'", "]", ".", "append", "(", "epoch", "+", "counter_ratio", ")", "\n", "self", ".", "plot_data", "[", "'Y'", "]", ".", "append", "(", "[", "losses", "[", "k", "]", "for", "k", "in", "self", ".", "plot_data", "[", "'legend'", "]", "]", ")", "\n", "try", ":", "\n", "            ", "self", ".", "vis", ".", "line", "(", "\n", "X", "=", "np", ".", "stack", "(", "[", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'X'", "]", ")", "]", "*", "len", "(", "self", ".", "plot_data", "[", "'legend'", "]", ")", ",", "1", ")", ",", "\n", "Y", "=", "np", ".", "array", "(", "self", ".", "plot_data", "[", "'Y'", "]", ")", ",", "\n", "opts", "=", "{", "\n", "'title'", ":", "self", ".", "name", "+", "' loss over time'", ",", "\n", "'legend'", ":", "self", ".", "plot_data", "[", "'legend'", "]", ",", "\n", "'xlabel'", ":", "'epoch'", ",", "\n", "'ylabel'", ":", "'loss'", "}", ",", "\n", "win", "=", "self", ".", "display_id", ")", "\n", "", "except", "VisdomExceptionBase", ":", "\n", "            ", "self", ".", "create_visdom_connections", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.Visualizer.print_current_losses": [[206, 223], ["losses.items", "print", "open", "log_file.write"], "methods", ["None"], ["", "", "def", "print_current_losses", "(", "self", ",", "epoch", ",", "iters", ",", "losses", ",", "t_comp", ",", "t_data", ")", ":", "\n", "        ", "\"\"\"print current losses on console; also save the losses to the disk\n\n        Parameters:\n            epoch (int) -- current epoch\n            iters (int) -- current training iteration during this epoch (reset to 0 at the end of every epoch)\n            losses (OrderedDict) -- training losses stored in the format of (name, float) pairs\n            t_comp (float) -- computational time per data point (normalized by batch_size)\n            t_data (float) -- data loading time per data point (normalized by batch_size)\n        \"\"\"", "\n", "message", "=", "'(epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "epoch", ",", "iters", ",", "t_comp", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "# print the message", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "# save the message", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer.save_images": [[17, 45], ["webpage.get_image_dir", "ntpath.basename", "webpage.add_header", "visuals.items", "webpage.add_images", "os.path.splitext", "util.tensor2im", "os.path.join", "util.save_image", "ims.append", "txts.append", "links.append"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.get_image_dir", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_header", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.add_images", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image"], ["", "def", "save_images", "(", "webpage", ",", "visuals", ",", "image_path", ",", "aspect_ratio", "=", "1.0", ",", "width", "=", "256", ")", ":", "\n", "    ", "\"\"\"Save images to the disk.\n\n    Parameters:\n        webpage (the HTML class) -- the HTML webpage class that stores these imaegs (see html.py for more details)\n        visuals (OrderedDict)    -- an ordered dictionary that stores (name, images (either tensor or numpy) ) pairs\n        image_path (str)         -- the string is used to create image paths\n        aspect_ratio (float)     -- the aspect ratio of saved images\n        width (int)              -- the images will be resized to width x width\n\n    This function will save images stored in 'visuals' to the HTML file specified by 'webpage'.\n    \"\"\"", "\n", "image_dir", "=", "webpage", ".", "get_image_dir", "(", ")", "\n", "short_path", "=", "ntpath", ".", "basename", "(", "image_path", "[", "0", "]", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "short_path", ")", "[", "0", "]", "\n", "\n", "webpage", ".", "add_header", "(", "name", ")", "\n", "ims", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "label", ",", "im_data", "in", "visuals", ".", "items", "(", ")", ":", "\n", "        ", "im", "=", "util", ".", "tensor2im", "(", "im_data", ")", "\n", "image_name", "=", "'%s_%s.png'", "%", "(", "name", ",", "label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "image_name", ")", "\n", "util", ".", "save_image", "(", "im", ",", "save_path", ",", "aspect_ratio", "=", "aspect_ratio", ")", "\n", "ims", ".", "append", "(", "image_name", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "image_name", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.tensor2im": [[11, 30], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].cpu().float().numpy", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["\n", "mean", "=", "kp", "[", "'value'", "]", "\n", "\n", "coordinate_grid", "=", "make_coordinate_grid", "(", "spatial_size", ",", "mean", ".", "type", "(", ")", ")", "\n", "number_of_leading_dimensions", "=", "len", "(", "mean", ".", "shape", ")", "-", "1", "\n", "shape", "=", "(", "1", ",", ")", "*", "number_of_leading_dimensions", "+", "coordinate_grid", ".", "shape", "\n", "coordinate_grid", "=", "coordinate_grid", ".", "view", "(", "*", "shape", ")", "\n", "repeats", "=", "mean", ".", "shape", "[", ":", "number_of_leading_dimensions", "]", "+", "(", "1", ",", "1", ",", "1", ")", "\n", "coordinate_grid", "=", "coordinate_grid", ".", "repeat", "(", "*", "repeats", ")", "\n", "\n", "# Preprocess kp shape", "\n", "shape", "=", "mean", ".", "shape", "[", ":", "number_of_leading_dimensions", "]", "+", "(", "1", ",", "1", ",", "2", ")", "\n", "mean", "=", "mean", ".", "view", "(", "*", "shape", ")", "\n", "\n", "mean_sub", "=", "(", "coordinate_grid", "-", "mean", ")", "\n", "\n", "out", "=", "torch", ".", "exp", "(", "-", "0.5", "*", "(", "mean_sub", "**", "2", ")", ".", "sum", "(", "-", "1", ")", "/", "kp_variance", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.diagnose_network": [[32, 49], ["net.parameters", "print", "print", "torch.mean", "torch.abs"], "function", ["None"], ["", "def", "make_coordinate_grid", "(", "spatial_size", ",", "type", ")", ":", "\n", "    ", "\"\"\"\n    Create a meshgrid [-1,1] x [-1,1] of given spatial_size.\n    \"\"\"", "\n", "h", ",", "w", "=", "spatial_size", "\n", "x", "=", "torch", ".", "arange", "(", "w", ")", ".", "type", "(", "type", ")", "\n", "y", "=", "torch", ".", "arange", "(", "h", ")", ".", "type", "(", "type", ")", "\n", "\n", "x", "=", "(", "2", "*", "(", "x", "/", "(", "w", "-", "1", ")", ")", "-", "1", ")", "\n", "y", "=", "(", "2", "*", "(", "y", "/", "(", "h", "-", "1", ")", ")", "-", "1", ")", "\n", "\n", "yy", "=", "y", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "w", ")", "\n", "xx", "=", "x", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "h", ",", "1", ")", "\n", "\n", "meshed", "=", "torch", ".", "cat", "(", "[", "xx", ".", "unsqueeze_", "(", "2", ")", ",", "yy", ".", "unsqueeze_", "(", "2", ")", "]", ",", "2", ")", "\n", "\n", "return", "meshed", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.save_image": [[51, 67], ["PIL.Image.fromarray", "image_pil.resize.save", "image_pil.resize.resize", "image_pil.resize.resize", "int", "int"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize", "home.repos.pwc.inspect_result.rmokady_JOKR.None.inference.resize"], ["", "class", "ResBlock2d", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Res block, preserve spatial resolution.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "in_features", ",", "kernel_size", ",", "padding", ")", ":", "\n", "        ", "super", "(", "ResBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "in_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "in_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ")", "\n", "self", ".", "norm1", "=", "BatchNorm2d", "(", "in_features", ",", "affine", "=", "True", ")", "\n", "self", ".", "norm2", "=", "BatchNorm2d", "(", "in_features", ",", "affine", "=", "True", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "norm1", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.print_numpy": [[69, 83], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["out", "=", "self", ".", "norm2", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "+=", "x", "\n", "return", "out", "\n", "\n", "\n", "", "", "class", "UpBlock2d", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Upsampling block for use in decoder.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "UpBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.mkdirs": [[85, 96], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.util.mkdir", "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.mkdir"], ["padding", "=", "padding", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm", "=", "BatchNorm2d", "(", "out_features", ",", "affine", "=", "True", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "interpolate", "(", "x", ",", "scale_factor", "=", "2", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "out", "=", "self", ".", "norm", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n", "\n", "", "", "class", "DownBlock2d", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.util.mkdir": [[98, 106], ["os.path.exists", "os.makedirs"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "        ", "super", "(", "DownBlock2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_features", ",", "out_channels", "=", "out_features", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "groups", "=", "groups", ")", "\n", "self", ".", "norm", "=", "BatchNorm2d", "(", "out_features", ",", "affine", "=", "True", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "(", "2", ",", "2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.__init__": [[15, 19], ["matplotlib.get_cmap"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "kp_size", "=", "5", ",", "draw_border", "=", "False", ",", "colormap", "=", "'gist_rainbow'", ")", ":", "\n", "        ", "self", ".", "kp_size", "=", "kp_size", "\n", "self", ".", "draw_border", "=", "draw_border", "\n", "self", ".", "colormap", "=", "plt", ".", "get_cmap", "(", "colormap", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.draw_image_with_kp": [[20, 29], ["numpy.copy", "enumerate", "numpy.array", "skimage.draw.circle", "numpy.array", "visualizer_kp.Visualizer.colormap"], "methods", ["None"], ["", "def", "draw_image_with_kp", "(", "self", ",", "image", ",", "kp_array", ")", ":", "\n", "        ", "image", "=", "np", ".", "copy", "(", "image", ")", "\n", "spatial_size", "=", "np", ".", "array", "(", "image", ".", "shape", "[", ":", "2", "]", "[", ":", ":", "-", "1", "]", ")", "[", "np", ".", "newaxis", "]", "\n", "kp_array", "=", "spatial_size", "*", "(", "kp_array", "+", "1", ")", "/", "2", "\n", "num_kp", "=", "kp_array", ".", "shape", "[", "0", "]", "\n", "for", "kp_ind", ",", "kp", "in", "enumerate", "(", "kp_array", ")", ":", "\n", "            ", "rr", ",", "cc", "=", "circle", "(", "kp", "[", "1", "]", ",", "kp", "[", "0", "]", ",", "self", ".", "kp_size", ",", "shape", "=", "image", ".", "shape", "[", ":", "2", "]", ")", "\n", "image", "[", "rr", ",", "cc", "]", "=", "np", ".", "array", "(", "self", ".", "colormap", "(", "kp_ind", "/", "num_kp", ")", ")", "[", ":", "3", "]", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column_with_kp": [[30, 33], ["numpy.array", "visualizer_kp.Visualizer.create_image_column", "visualizer_kp.Visualizer.draw_image_with_kp", "zip"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.draw_image_with_kp"], ["", "def", "create_image_column_with_kp", "(", "self", ",", "images", ",", "kp", ")", ":", "\n", "        ", "image_array", "=", "np", ".", "array", "(", "[", "self", ".", "draw_image_with_kp", "(", "v", ",", "k", ")", "for", "v", ",", "k", "in", "zip", "(", "images", ",", "kp", ")", "]", ")", "\n", "return", "self", ".", "create_image_column", "(", "image_array", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column": [[34, 40], ["numpy.concatenate", "numpy.copy", "list"], "methods", ["None"], ["", "def", "create_image_column", "(", "self", ",", "images", ")", ":", "\n", "        ", "if", "self", ".", "draw_border", ":", "\n", "            ", "images", "=", "np", ".", "copy", "(", "images", ")", "\n", "images", "[", ":", ",", ":", ",", "[", "0", ",", "-", "1", "]", "]", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "images", "[", ":", ",", ":", ",", "[", "0", ",", "-", "1", "]", "]", "=", "(", "1", ",", "1", ",", "1", ")", "\n", "", "return", "np", ".", "concatenate", "(", "list", "(", "images", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_grid": [[41, 49], ["numpy.concatenate", "type", "out.append", "out.append", "visualizer_kp.Visualizer.create_image_column_with_kp", "visualizer_kp.Visualizer.create_image_column"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column_with_kp", "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_column"], ["", "def", "create_image_grid", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "arg", "in", "args", ":", "\n", "            ", "if", "type", "(", "arg", ")", "==", "tuple", ":", "\n", "                ", "out", ".", "append", "(", "self", ".", "create_image_column_with_kp", "(", "arg", "[", "0", "]", ",", "arg", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", ".", "append", "(", "self", ".", "create_image_column", "(", "arg", ")", ")", "\n", "", "", "return", "np", ".", "concatenate", "(", "out", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.visualize": [[50, 125], ["numpy.transpose.data.cpu", "[].data.cpu().numpy", "numpy.transpose", "images.append", "[].data.cpu().numpy", "numpy.transpose.data.cpu().numpy", "numpy.transpose", "images.append", "out[].data.cpu().numpy", "numpy.transpose", "images.append", "visualizer_kp.Visualizer.create_image_grid", "out[].data.cpu().numpy", "numpy.transpose", "[].data.cpu().numpy", "images.append", "out[].data.cpu().numpy", "numpy.transpose", "images.append", "[].data.cpu().numpy", "images.append", "out[].data.cpu().repeat", "torch.interpolate().numpy", "torch.interpolate().numpy", "numpy.transpose", "images.append", "range", "images.append", "[].data.cpu", "[].data.cpu", "numpy.transpose.data.cpu", "out[].data.cpu", "[].data.cpu", "torch.interpolate", "torch.interpolate", "[].data.cpu().repeat", "torch.interpolate", "torch.interpolate", "numpy.transpose", "numpy.transpose", "numpy.array.reshape", "images.append", "full_mask.append", "sum", "out[].data.cpu", "[].data.cpu", "out[].data.cpu", "[].data.cpu", "out[].data.cpu", "torch.interpolate", "torch.interpolate", "numpy.transpose.numpy", "numpy.transpose.numpy", "numpy.array", "images.append", "images.append", "[].data.cpu", "numpy.array", "visualizer_kp.Visualizer.colormap"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.visualizer_kp.Visualizer.create_image_grid"], ["", "def", "visualize", "(", "self", ",", "driving", ",", "source", ",", "out", ")", ":", "\n", "        ", "images", "=", "[", "]", "\n", "\n", "# Source image with keypoints", "\n", "source", "=", "source", ".", "data", ".", "cpu", "(", ")", "\n", "kp_source", "=", "out", "[", "'kp_source'", "]", "[", "'value'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "source", "=", "np", ".", "transpose", "(", "source", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "images", ".", "append", "(", "(", "source", ",", "kp_source", ")", ")", "\n", "\n", "# Equivariance visualization", "\n", "if", "'transformed_frame'", "in", "out", ":", "\n", "            ", "transformed", "=", "out", "[", "'transformed_frame'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "transformed", "=", "np", ".", "transpose", "(", "transformed", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "transformed_kp", "=", "out", "[", "'transformed_kp'", "]", "[", "'value'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "images", ".", "append", "(", "(", "transformed", ",", "transformed_kp", ")", ")", "\n", "\n", "# Driving image with keypoints", "\n", "", "kp_driving", "=", "out", "[", "'kp_driving'", "]", "[", "'value'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "driving", "=", "driving", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "driving", "=", "np", ".", "transpose", "(", "driving", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "images", ".", "append", "(", "(", "driving", ",", "kp_driving", ")", ")", "\n", "\n", "# Deformed image", "\n", "if", "'deformed'", "in", "out", ":", "\n", "            ", "deformed", "=", "out", "[", "'deformed'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "deformed", "=", "np", ".", "transpose", "(", "deformed", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "images", ".", "append", "(", "deformed", ")", "\n", "\n", "# Result with and without keypoints", "\n", "", "prediction", "=", "out", "[", "'prediction'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "prediction", "=", "np", ".", "transpose", "(", "prediction", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "if", "'kp_norm'", "in", "out", ":", "\n", "            ", "kp_norm", "=", "out", "[", "'kp_norm'", "]", "[", "'value'", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "images", ".", "append", "(", "(", "prediction", ",", "kp_norm", ")", ")", "\n", "", "images", ".", "append", "(", "prediction", ")", "\n", "\n", "\n", "## Occlusion map", "\n", "if", "'occlusion_map'", "in", "out", ":", "\n", "            ", "occlusion_map", "=", "out", "[", "'occlusion_map'", "]", ".", "data", ".", "cpu", "(", ")", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "occlusion_map", "=", "F", ".", "interpolate", "(", "occlusion_map", ",", "size", "=", "source", ".", "shape", "[", "1", ":", "3", "]", ")", ".", "numpy", "(", ")", "\n", "occlusion_map", "=", "np", ".", "transpose", "(", "occlusion_map", ",", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "images", ".", "append", "(", "occlusion_map", ")", "\n", "\n", "# Deformed images according to each individual transform", "\n", "", "if", "'sparse_deformed'", "in", "out", ":", "\n", "            ", "full_mask", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "out", "[", "'sparse_deformed'", "]", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "image", "=", "out", "[", "'sparse_deformed'", "]", "[", ":", ",", "i", "]", ".", "data", ".", "cpu", "(", ")", "\n", "image", "=", "F", ".", "interpolate", "(", "image", ",", "size", "=", "source", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "mask", "=", "out", "[", "'mask'", "]", "[", ":", ",", "i", ":", "(", "i", "+", "1", ")", "]", ".", "data", ".", "cpu", "(", ")", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "mask", "=", "F", ".", "interpolate", "(", "mask", ",", "size", "=", "source", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "image", "=", "np", ".", "transpose", "(", "image", ".", "numpy", "(", ")", ",", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "mask", "=", "np", ".", "transpose", "(", "mask", ".", "numpy", "(", ")", ",", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "\n", "if", "i", "!=", "0", ":", "\n", "                    ", "color", "=", "np", ".", "array", "(", "self", ".", "colormap", "(", "(", "i", "-", "1", ")", "/", "(", "out", "[", "'sparse_deformed'", "]", ".", "shape", "[", "1", "]", "-", "1", ")", ")", ")", "[", ":", "3", "]", "\n", "", "else", ":", "\n", "                    ", "color", "=", "np", ".", "array", "(", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "\n", "", "color", "=", "color", ".", "reshape", "(", "(", "1", ",", "1", ",", "1", ",", "3", ")", ")", "\n", "\n", "images", ".", "append", "(", "image", ")", "\n", "if", "i", "!=", "0", ":", "\n", "                    ", "images", ".", "append", "(", "mask", "*", "color", ")", "\n", "", "else", ":", "\n", "                    ", "images", ".", "append", "(", "mask", ")", "\n", "\n", "", "full_mask", ".", "append", "(", "mask", "*", "color", ")", "\n", "\n", "", "images", ".", "append", "(", "sum", "(", "full_mask", ")", ")", "\n", "\n", "", "image", "=", "self", ".", "create_image_grid", "(", "*", "images", ")", "\n", "image", "=", "(", "255", "*", "image", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "return", "image", "", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.Identity.forward": [[15, 17], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.GANLoss.__init__": [[225, 248], ["torch.Module.__init__", "networks.GANLoss.register_buffer", "networks.GANLoss.register_buffer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.MSELoss", "torch.MSELoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ")", ":", "\n", "        ", "\"\"\" Initialize the GANLoss class.\n\n        Parameters:\n            gan_mode (str) - - the type of GAN objective. It currently supports vanilla, lsgan, and wgangp.\n            target_real_label (bool) - - label for a real image\n            target_fake_label (bool) - - label of a fake image\n\n        Note: Do not use sigmoid as the last layer of Discriminator.\n        LSGAN needs no sigmoid. vanilla GANs will handle it with BCEWithLogitsLoss.\n        \"\"\"", "\n", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'real_label'", ",", "torch", ".", "tensor", "(", "target_real_label", ")", ")", "\n", "self", ".", "register_buffer", "(", "'fake_label'", ",", "torch", ".", "tensor", "(", "target_fake_label", ")", ")", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "if", "gan_mode", "==", "'lsgan'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "gan_mode", "==", "'vanilla'", ":", "\n", "            ", "self", ".", "loss", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "", "elif", "gan_mode", "in", "[", "'wgangp'", "]", ":", "\n", "            ", "self", ".", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'gan mode %s not implemented'", "%", "gan_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.GANLoss.get_target_tensor": [[249, 265], ["target_tensor.expand_as"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Create label tensors with the same size as the input.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            A label tensor filled with ground truth label, and with the size of the input\n        \"\"\"", "\n", "\n", "if", "target_is_real", ":", "\n", "            ", "target_tensor", "=", "self", ".", "real_label", "\n", "", "else", ":", "\n", "            ", "target_tensor", "=", "self", ".", "fake_label", "\n", "", "return", "target_tensor", ".", "expand_as", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.GANLoss.__call__": [[266, 285], ["networks.GANLoss.get_target_tensor", "networks.GANLoss.loss", "prediction.mean", "prediction.mean"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.GANLoss.get_target_tensor"], ["", "def", "__call__", "(", "self", ",", "prediction", ",", "target_is_real", ")", ":", "\n", "        ", "\"\"\"Calculate loss given Discriminator's output and grount truth labels.\n\n        Parameters:\n            prediction (tensor) - - tpyically the prediction output from a discriminator\n            target_is_real (bool) - - if the ground truth label is for real images or fake images\n\n        Returns:\n            the calculated loss.\n        \"\"\"", "\n", "if", "self", ".", "gan_mode", "in", "[", "'lsgan'", ",", "'vanilla'", "]", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "prediction", ",", "target_is_real", ")", "\n", "loss", "=", "self", ".", "loss", "(", "prediction", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'wgangp'", ":", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "loss", "=", "-", "prediction", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "prediction", ".", "mean", "(", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator.__init__": [[330, 384], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Tanh", "torch.Tanh", "int", "int"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "not_mask", "=", "True", ",", "only_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "\n", "if", "not_mask", ":", "\n", "            ", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "", "self", ".", "not_mask", "=", "not_mask", "\n", "self", ".", "only_mask", "=", "only_mask", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator.forward": [[385, 403], ["networks.ResnetGenerator.model", "networks.ResnetGenerator.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "mask.repeat.repeat.repeat", "networks.ResnetGenerator.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "mask.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "if", "self", ".", "not_mask", ":", "\n", "            ", "return", "self", ".", "model", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "only_mask", ":", "\n", "                ", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "mask", "=", "torch", ".", "sigmoid", "(", "output", ")", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "return", "mask", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "mask", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", ":", "1", "]", ")", "\n", "oimg", "=", "torch", ".", "tanh", "(", "output", "[", ":", ",", "1", ":", "]", ")", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "#oimg = oimg * mask + my_input * (1 - mask)", "\n", "\n", "return", "oimg", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator_double.__init__": [[413, 467], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Tanh", "torch.Tanh", "int", "int"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "not_mask", "=", "True", ",", "only_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "super", "(", "ResnetGenerator_double", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "\n", "if", "not_mask", ":", "\n", "            ", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "", "self", ".", "not_mask", "=", "not_mask", "\n", "self", ".", "only_mask", "=", "only_mask", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator_double.forward": [[468, 488], ["networks.ResnetGenerator_double.model", "networks.ResnetGenerator_double.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "mask1.repeat.repeat.repeat", "mask2.repeat.repeat.repeat", "networks.ResnetGenerator_double.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "mask.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "if", "self", ".", "not_mask", ":", "\n", "            ", "return", "self", ".", "model", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "only_mask", ":", "\n", "                ", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "mask1", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", ":", "1", "]", ")", "\n", "mask2", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", "1", ":", "]", ")", "\n", "mask1", "=", "mask1", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "mask2", "=", "mask2", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "return", "mask1", ",", "mask2", "\n", "", "else", ":", "\n", "                ", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "mask", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", ":", "1", "]", ")", "\n", "oimg", "=", "torch", ".", "tanh", "(", "output", "[", ":", ",", "1", ":", "]", ")", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "#oimg = oimg * mask + my_input * (1 - mask)", "\n", "\n", "return", "oimg", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator_quad.__init__": [[498, 555], ["torch.Module.__init__", "range", "range", "range", "torch.Sequential", "torch.Sequential", "type", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "networks.ResnetBlock", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Tanh", "torch.Tanh", "int", "int"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ",", "n_blocks", "=", "6", ",", "padding_type", "=", "'reflect'", ",", "not_mask", "=", "True", ",", "only_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Resnet-based generator\n\n        Parameters:\n            input_nc (int)      -- the number of channels in input images\n            output_nc (int)     -- the number of channels in output images\n            ngf (int)           -- the number of filters in the last conv layer\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers\n            n_blocks (int)      -- the number of ResNet blocks\n            padding_type (str)  -- the name of padding layer in conv layers: reflect | replicate | zero\n        \"\"\"", "\n", "assert", "(", "n_blocks", ">=", "0", ")", "\n", "\n", "assert", "output_nc", "==", "4", "\n", "\n", "super", "(", "ResnetGenerator_quad", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "model", "=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ngf", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "n_downsampling", "=", "2", "\n", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add downsampling layers", "\n", "            ", "mult", "=", "2", "**", "i", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", "*", "mult", ",", "ngf", "*", "mult", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ngf", "*", "mult", "*", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "\n", "", "mult", "=", "2", "**", "n_downsampling", "\n", "for", "i", "in", "range", "(", "n_blocks", ")", ":", "# add ResNet blocks", "\n", "\n", "            ", "model", "+=", "[", "ResnetBlock", "(", "ngf", "*", "mult", ",", "padding_type", "=", "padding_type", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "use_bias", "=", "use_bias", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "n_downsampling", ")", ":", "# add upsampling layers", "\n", "            ", "mult", "=", "2", "**", "(", "n_downsampling", "-", "i", ")", "\n", "model", "+=", "[", "nn", ".", "ConvTranspose2d", "(", "ngf", "*", "mult", ",", "int", "(", "ngf", "*", "mult", "/", "2", ")", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "output_padding", "=", "1", ",", "\n", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "int", "(", "ngf", "*", "mult", "/", "2", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "", "model", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "3", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "ngf", ",", "output_nc", ",", "kernel_size", "=", "7", ",", "padding", "=", "0", ")", "]", "\n", "\n", "if", "not_mask", ":", "\n", "            ", "model", "+=", "[", "nn", ".", "Tanh", "(", ")", "]", "\n", "\n", "", "self", ".", "not_mask", "=", "not_mask", "\n", "self", ".", "only_mask", "=", "only_mask", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "output_nc", "=", "output_nc", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetGenerator_quad.forward": [[556, 569], ["networks.ResnetGenerator_quad.model", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "mask1.repeat.repeat.repeat", "mask2.repeat.repeat.repeat", "mask3.repeat.repeat.repeat", "mask4.repeat.repeat.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "output", "=", "self", ".", "model", "(", "input", ")", "\n", "mask1", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", "0", ":", "1", "]", ")", "\n", "mask2", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", "1", ":", "2", "]", ")", "\n", "mask3", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", "2", ":", "3", "]", ")", "\n", "mask4", "=", "torch", ".", "sigmoid", "(", "output", "[", ":", ",", "3", ":", "4", "]", ")", "\n", "\n", "mask1", "=", "mask1", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "mask2", "=", "mask2", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "mask3", "=", "mask3", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "mask4", "=", "mask4", ".", "repeat", "(", "1", ",", "3", ",", "1", ",", "1", ")", "\n", "return", "mask1", ",", "mask2", ",", "mask3", ",", "mask4", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetBlock.__init__": [[574, 584], ["torch.Module.__init__", "networks.ResnetBlock.build_conv_block"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetBlock.build_conv_block"], ["def", "__init__", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Initialize the Resnet block\n\n        A resnet block is a conv block with skip connections\n        We construct a conv block with build_conv_block function,\n        and implement skip connections in <forward> function.\n        Original Resnet paper: https://arxiv.org/pdf/1512.03385.pdf\n        \"\"\"", "\n", "super", "(", "ResnetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "self", ".", "build_conv_block", "(", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetBlock.build_conv_block": [[585, 624], ["torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.Dropout", "torch.Dropout", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "NotImplementedError"], "methods", ["None"], ["", "def", "build_conv_block", "(", "self", ",", "dim", ",", "padding_type", ",", "norm_layer", ",", "use_dropout", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"Construct a convolutional block.\n\n        Parameters:\n            dim (int)           -- the number of channels in the conv layer.\n            padding_type (str)  -- the name of padding layer: reflect | replicate | zero\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n            use_bias (bool)     -- if the conv layer uses bias or not\n\n        Returns a conv block (with a conv layer, a normalization layer, and a non-linearity layer (ReLU))\n        \"\"\"", "\n", "conv_block", "=", "[", "]", "\n", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", ",", "nn", ".", "ReLU", "(", "True", ")", "]", "\n", "if", "use_dropout", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "\n", "", "p", "=", "0", "\n", "if", "padding_type", "==", "'reflect'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReflectionPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'replicate'", ":", "\n", "            ", "conv_block", "+=", "[", "nn", ".", "ReplicationPad2d", "(", "1", ")", "]", "\n", "", "elif", "padding_type", "==", "'zero'", ":", "\n", "            ", "p", "=", "1", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'padding [%s] is not implemented'", "%", "padding_type", ")", "\n", "", "conv_block", "+=", "[", "nn", ".", "Conv2d", "(", "dim", ",", "dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "p", ",", "bias", "=", "use_bias", ")", ",", "norm_layer", "(", "dim", ")", "]", "\n", "\n", "return", "nn", ".", "Sequential", "(", "*", "conv_block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.ResnetBlock.forward": [[625, 629], ["networks.ResnetBlock.conv_block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward function (with skip connections)\"\"\"", "\n", "out", "=", "x", "+", "self", ".", "conv_block", "(", "x", ")", "# add skip connections", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.UnetGenerator.__init__": [[634, 657], ["torch.Module.__init__", "networks.UnetSkipConnectionBlock", "range", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock", "networks.UnetSkipConnectionBlock"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "None", ",", "norm_layer", "=", "norm_layer", ",", "innermost", "=", "True", ")", "# add the innermost layer", "\n", "for", "i", "in", "range", "(", "num_downs", "-", "5", ")", ":", "# add intermediate layers with ngf * 8 filters", "\n", "            ", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "# gradually reduce the number of filters from ngf * 8 to ngf", "\n", "", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "unet_block", "=", "UnetSkipConnectionBlock", "(", "ngf", ",", "ngf", "*", "2", ",", "input_nc", "=", "None", ",", "submodule", "=", "unet_block", ",", "norm_layer", "=", "norm_layer", ")", "\n", "self", ".", "model", "=", "UnetSkipConnectionBlock", "(", "output_nc", ",", "ngf", ",", "input_nc", "=", "input_nc", ",", "submodule", "=", "unet_block", ",", "outermost", "=", "True", ",", "norm_layer", "=", "norm_layer", ")", "# add the outermost layer", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.UnetGenerator.forward": [[658, 661], ["networks.UnetGenerator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.UnetSkipConnectionBlock.__init__": [[669, 725], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "norm_layer", "torch.ReLU", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "type", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "outer_nc", ",", "inner_nc", ",", "input_nc", "=", "None", ",", "\n", "submodule", "=", "None", ",", "outermost", "=", "False", ",", "innermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ",", "use_dropout", "=", "False", ")", ":", "\n", "        ", "\"\"\"Construct a Unet submodule with skip connections.\n\n        Parameters:\n            outer_nc (int) -- the number of filters in the outer conv layer\n            inner_nc (int) -- the number of filters in the inner conv layer\n            input_nc (int) -- the number of channels in input images/features\n            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n            outermost (bool)    -- if this module is the outermost module\n            innermost (bool)    -- if this module is the innermost module\n            norm_layer          -- normalization layer\n            use_dropout (bool)  -- if use dropout layers.\n        \"\"\"", "\n", "super", "(", "UnetSkipConnectionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "outermost", "=", "outermost", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "", "if", "input_nc", "is", "None", ":", "\n", "            ", "input_nc", "=", "outer_nc", "\n", "", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "inner_nc", ",", "kernel_size", "=", "4", ",", "\n", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "inner_nc", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "outer_nc", ")", "\n", "\n", "if", "outermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ")", "\n", "down", "=", "[", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "nn", ".", "Tanh", "(", ")", "]", "\n", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "", "elif", "innermost", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "model", "=", "down", "+", "up", "\n", "", "else", ":", "\n", "            ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "inner_nc", "*", "2", ",", "outer_nc", ",", "\n", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "bias", "=", "use_bias", ")", "\n", "down", "=", "[", "downrelu", ",", "downconv", ",", "downnorm", "]", "\n", "up", "=", "[", "uprelu", ",", "upconv", ",", "upnorm", "]", "\n", "\n", "if", "use_dropout", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "+", "[", "nn", ".", "Dropout", "(", "0.5", ")", "]", "\n", "", "else", ":", "\n", "                ", "model", "=", "down", "+", "[", "submodule", "]", "+", "up", "\n", "\n", "", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.UnetSkipConnectionBlock.forward": [[726, 731], ["networks.UnetSkipConnectionBlock.model", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.UnetSkipConnectionBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "outermost", ":", "\n", "            ", "return", "self", ".", "model", "(", "x", ")", "\n", "", "else", ":", "# add skip connections", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "x", ",", "self", ".", "model", "(", "x", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.NLayerDiscriminator.__init__": [[736, 775], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.NLayerDiscriminator.forward": [[776, 780], ["networks.NLayerDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "out", "=", "self", ".", "model", "(", "input", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.SinganDiscriminator.__init__": [[784, 823], ["torch.Module.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "n_layers", "=", "6", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "SinganDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.SinganDiscriminator.forward": [[824, 828], ["networks.SinganDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "out", "=", "self", ".", "model", "(", "input", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.PixelDiscriminator.__init__": [[833, 856], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "type", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__"], ["def", "__init__", "(", "self", ",", "input_nc", ",", "ndf", "=", "64", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a 1x1 PatchGAN discriminator\n\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "PixelDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "type", "(", "norm_layer", ")", "==", "functools", ".", "partial", ":", "# no need to use bias as BatchNorm2d has affine parameters", "\n", "            ", "use_bias", "=", "norm_layer", ".", "func", "==", "nn", ".", "InstanceNorm2d", "\n", "", "else", ":", "\n", "            ", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "\n", "", "self", ".", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "1", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "use_bias", ")", "]", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "net", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.PixelDiscriminator.forward": [[857, 860], ["networks.PixelDiscriminator.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "net", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.get_norm_layer": [[19, 37], ["functools.partial", "functools.partial", "NotImplementedError", "networks.Identity"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "norm_type", "=", "'instance'", ")", ":", "\n", "    ", "\"\"\"Return a normalization layer\n\n    Parameters:\n        norm_type (str) -- the name of the normalization layer: batch | instance | none\n\n    For BatchNorm, we use learnable affine parameters and track running statistics (mean/stddev).\n    For InstanceNorm, we do not use learnable affine parameters. We do not track running statistics.\n    \"\"\"", "\n", "if", "norm_type", "==", "'batch'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "BatchNorm2d", ",", "affine", "=", "True", ",", "track_running_stats", "=", "True", ")", "\n", "", "elif", "norm_type", "==", "'instance'", ":", "\n", "        ", "norm_layer", "=", "functools", ".", "partial", "(", "nn", ".", "InstanceNorm2d", ",", "affine", "=", "False", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm_type", "==", "'none'", ":", "\n", "        ", "def", "norm_layer", "(", "x", ")", ":", "return", "Identity", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'normalization layer [%s] is not found'", "%", "norm_type", ")", "\n", "", "return", "norm_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.get_scheduler": [[39, 66], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "max", "float", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "n_epochs", ")", "/", "float", "(", "opt", ".", "n_epochs_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.2", ",", "threshold", "=", "0.01", ",", "patience", "=", "5", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "n_epochs", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.init_weights": [[68, 100], ["print", "net.apply", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "print", "(", "'initialize network with %s'", "%", "init_type", ")", "\n", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.init_net": [[102, 118], ["networks.init_weights", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.DataParallel.to", "torch.nn.DataParallel", "torch.nn.DataParallel"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "gpu_ids", "[", "0", "]", ")", "\n", "net", "=", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "gpu_ids", ")", "# multi-GPUs", "\n", "", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_G": [[120, 166], ["networks.get_norm_layer", "networks.init_net", "print", "networks.ResnetGenerator_quad", "print", "networks.ResnetGenerator_double", "networks.ResnetGenerator", "networks.ResnetGenerator", "networks.UnetGenerator", "networks.UnetGenerator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.init_net"], ["", "def", "define_G", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ",", "not_mask", "=", "True", ",", "only_mask", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n\n    Our current implementation provides two types of generators:\n        U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n        The original U-Net paper: https://arxiv.org/abs/1505.04597\n\n        Resnet-based generator: [resnet_6blocks] (with 6 Resnet blocks) and [resnet_9blocks] (with 9 Resnet blocks)\n        Resnet-based generator consists of several Resnet blocks between a few downsampling/upsampling operations.\n        We adapt Torch code from Justin Johnson's neural style transfer project (https://github.com/jcjohnson/fast-neural-style).\n\n\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "if", "netG", "==", "'resnet_9blocks_quad'", ":", "\n", "        ", "print", "(", "\"resnet_9blocks_quad\"", ")", "\n", "net", "=", "ResnetGenerator_quad", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ",", "not_mask", "=", "not_mask", ",", "only_mask", "=", "only_mask", ")", "\n", "", "elif", "netG", "==", "'resnet_9blocks_double'", ":", "\n", "        ", "print", "(", "\"resnet_9blocks_double\"", ")", "\n", "net", "=", "ResnetGenerator_double", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ",", "not_mask", "=", "not_mask", ",", "only_mask", "=", "only_mask", ")", "\n", "", "elif", "netG", "==", "'resnet_9blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "9", ",", "not_mask", "=", "not_mask", ",", "only_mask", "=", "only_mask", ")", "\n", "", "elif", "netG", "==", "'resnet_6blocks'", ":", "\n", "        ", "net", "=", "ResnetGenerator", "(", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ",", "n_blocks", "=", "6", ")", "\n", "", "elif", "netG", "==", "'unet_128'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "7", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "elif", "netG", "==", "'unet_256'", ":", "\n", "        ", "net", "=", "UnetGenerator", "(", "input_nc", ",", "output_nc", ",", "8", ",", "ngf", ",", "norm_layer", "=", "norm_layer", ",", "use_dropout", "=", "use_dropout", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.define_D": [[168, 213], ["networks.get_norm_layer", "networks.init_net", "networks.NLayerDiscriminator", "networks.NLayerDiscriminator", "print", "networks.SinganDiscriminator", "networks.PixelDiscriminator", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.init_net"], ["", "def", "define_D", "(", "input_nc", ",", "ndf", ",", "netD", ",", "n_layers_D", "=", "9", ",", "norm", "=", "'batch'", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Create a discriminator\n\n    Parameters:\n        input_nc (int)     -- the number of channels in input images\n        ndf (int)          -- the number of filters in the first conv layer\n        netD (str)         -- the architecture's name: basic | n_layers | pixel\n        n_layers_D (int)   -- the number of conv layers in the discriminator; effective when netD=='n_layers'\n        norm (str)         -- the type of normalization layers used in the network.\n        init_type (str)    -- the name of the initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a discriminator\n\n    Our current implementation provides three types of discriminators:\n        [basic]: 'PatchGAN' classifier described in the original pix2pix paper.\n        It can classify whether 70\u00d770 overlapping patches are real or fake.\n        Such a patch-level discriminator architecture has fewer parameters\n        than a full-image discriminator and can work on arbitrarily-sized images\n        in a fully convolutional fashion.\n\n        [n_layers]: With this mode, you cna specify the number of conv layers in the discriminator\n        with the parameter <n_layers_D> (default=3 as used in [basic] (PatchGAN).)\n\n        [pixel]: 1x1 PixelGAN discriminator can classify whether a pixel is real or not.\n        It encourages greater color diversity but has no effect on spatial statistics.\n\n    The discriminator has been initialized by <init_net>. It uses Leakly RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "norm_layer", "=", "get_norm_layer", "(", "norm_type", "=", "norm", ")", "\n", "\n", "if", "netD", "==", "'basic'", ":", "# default PatchGAN classifier", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'n_layers'", ":", "# more options", "\n", "        ", "net", "=", "NLayerDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'singan'", ":", "# more options", "\n", "        ", "print", "(", "\"SinGAN it is !\"", ")", "\n", "net", "=", "SinganDiscriminator", "(", "input_nc", ",", "ndf", ",", "n_layers_D", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "elif", "netD", "==", "'pixel'", ":", "# classify if each pixel is real or fake", "\n", "        ", "net", "=", "PixelDiscriminator", "(", "input_nc", ",", "ndf", ",", "norm_layer", "=", "norm_layer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Discriminator model name [%s] is not recognized'", "%", "netD", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.cal_gradient_penalty": [[287, 322], ["interpolatesv.requires_grad_", "netD", "torch.autograd.grad", "torch.autograd.grad", "gradients[].view", "real_data.size", "torch.ones().to", "torch.ones().to", "torch.rand", "torch.rand", "alpha.expand().contiguous().view.expand().contiguous().view", "NotImplementedError", "torch.ones", "torch.ones", "alpha.expand().contiguous().view.expand().contiguous", "netD.size", "alpha.expand().contiguous().view.expand", "real_data.nelement"], "function", ["None"], ["", "", "def", "cal_gradient_penalty", "(", "netD", ",", "real_data", ",", "fake_data", ",", "device", ",", "type", "=", "'mixed'", ",", "constant", "=", "1.0", ",", "lambda_gp", "=", "10.0", ")", ":", "\n", "    ", "\"\"\"Calculate the gradient penalty loss, used in WGAN-GP paper https://arxiv.org/abs/1704.00028\n\n    Arguments:\n        netD (network)              -- discriminator network\n        real_data (tensor array)    -- real images\n        fake_data (tensor array)    -- generated images from the generator\n        device (str)                -- GPU / CPU: from torch.device('cuda:{}'.format(self.gpu_ids[0])) if self.gpu_ids else torch.device('cpu')\n        type (str)                  -- if we mix real and fake data or not [real | fake | mixed].\n        constant (float)            -- the constant used in formula ( | |gradient||_2 - constant)^2\n        lambda_gp (float)           -- weight for this loss\n\n    Returns the gradient penalty loss\n    \"\"\"", "\n", "if", "lambda_gp", ">", "0.0", ":", "\n", "        ", "if", "type", "==", "'real'", ":", "# either use real images, fake images, or a linear interpolation of two.", "\n", "            ", "interpolatesv", "=", "real_data", "\n", "", "elif", "type", "==", "'fake'", ":", "\n", "            ", "interpolatesv", "=", "fake_data", "\n", "", "elif", "type", "==", "'mixed'", ":", "\n", "            ", "alpha", "=", "torch", ".", "rand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "1", ",", "device", "=", "device", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "real_data", ".", "shape", "[", "0", "]", ",", "real_data", ".", "nelement", "(", ")", "//", "real_data", ".", "shape", "[", "0", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "real_data", ".", "shape", ")", "\n", "interpolatesv", "=", "alpha", "*", "real_data", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'{} not implemented'", ".", "format", "(", "type", ")", ")", "\n", "", "interpolatesv", ".", "requires_grad_", "(", "True", ")", "\n", "disc_interpolates", "=", "netD", "(", "interpolatesv", ")", "\n", "gradients", "=", "torch", ".", "autograd", ".", "grad", "(", "outputs", "=", "disc_interpolates", ",", "inputs", "=", "interpolatesv", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "disc_interpolates", ".", "size", "(", ")", ")", ".", "to", "(", "device", ")", ",", "\n", "create_graph", "=", "True", ",", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "\n", "gradients", "=", "gradients", "[", "0", "]", ".", "view", "(", "real_data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# flat the data", "\n", "gradient_penalty", "=", "(", "(", "(", "gradients", "+", "1e-16", ")", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "constant", ")", "**", "2", ")", ".", "mean", "(", ")", "*", "lambda_gp", "# added eps", "\n", "return", "gradient_penalty", ",", "gradients", "\n", "", "else", ":", "\n", "        ", "return", "0.0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.__init__.find_model_using_name": [[26, 47], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.rmokady_JOKR.models.__init__.get_option_setter": [[49, 53], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.rmokady_JOKR.models.__init__.create_model": [[55, 69], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__init__": [[20, 47], ["os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "if", "opt", ".", "preprocess", "!=", "'scale_width'", ":", "# with [scale_width], input images might have different sizes, which hurts the performance of cudnn.benchmark.", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "metric", "=", "0", "# used for learning rate policy 'plateau'", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.modify_commandline_options": [[48, 60], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.set_input": [[61, 69], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.forward": [[70, 74], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.optimize_parameters": [[75, 79], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.setup": [[80, 92], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.rmokady_JOKR.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "            ", "load_suffix", "=", "'iter_%d'", "%", "opt", ".", "load_iter", "if", "opt", ".", "load_iter", ">", "0", "else", "opt", ".", "epoch", "\n", "self", ".", "load_networks", "(", "load_suffix", ")", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval": [[93, 99], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.test": [[100, 109], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.forward", "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.compute_visuals"], ["", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.compute_visuals": [[110, 113], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images for visdom and HTML visualization\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.get_image_paths": [[114, 117], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.update_learning_rate": [[118, 128], ["print", "scheduler.step", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "self", ".", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.get_current_visuals": [[129, 136], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization images. train.py will display these images with visdom, and save the images to a HTML\"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.get_current_losses": [[137, 144], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.save_networks": [[145, 162], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "torch.save", "getattr.cuda", "torch.save", "len", "getattr.module.cpu().state_dict", "getattr.cpu().state_dict", "getattr.module.cpu", "getattr.cpu"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save", "home.repos.pwc.inspect_result.rmokady_JOKR.util.html.HTML.save"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "module", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[163, 176], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.load_networks": [[177, 201], ["isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "hasattr", "list", "getattr.load_state_dict", "torch.load.keys", "base_model.BaseModel.__patch_instance_norm_state_dict", "str", "key.split"], "methods", ["home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "load_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "# patch InstanceNorm checkpoints prior to 0.4", "\n", "", "for", "key", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "# need to copy keys here because we mutate in loop", "\n", "                    ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "net", ",", "key", ".", "split", "(", "'.'", ")", ")", "\n", "", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.print_networks": [[202, 219], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print"], "methods", ["None"], ["", "", "", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %.3f M'", "%", "(", "name", ",", "num_params", "/", "1e6", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rmokady_JOKR.models.base_model.BaseModel.set_requires_grad": [[220, 232], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "", "", "", "", "", ""]]}