{"home.repos.pwc.inspect_result.sumitsk_matrl.None.main.train": [[19, 115], ["tensorboardX.SummaryWriter", "utils.make_parallel_envs", "learner.setup_master", "learner.setup_master", "utils.make_parallel_envs.reset", "learner.setup_master.initialize_obs", "len", "torch.zeros", "torch.zeros", "datetime.datetime.now", "range", "tensorboardX.SummaryWriter.close", "range", "learner.setup_master.wrap_horizon", "learner.setup_master.update", "learner.setup_master.after_update", "numpy.transpose", "utils.make_parallel_envs.step", "torch.from_numpy().float().to", "torch.FloatTensor().to", "learner.setup_master.update_rollout", "torch.save", "datetime.datetime.now", "torch.zeros.mean().cpu().numpy", "print", "print", "eval.evaluate", "print", "print", "print", "torch.no_grad", "learner.setup_master.act", "numpy.array", "range", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "print", "print", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "range", "torch.save", "print", "print", "print", "torch.from_numpy().float", "torch.FloatTensor", "agent.actor_critic.state_dict", "str", "torch.zeros.mean().cpu", "str", "int", "tensorboardX.SummaryWriter.add_scalar", "eval_perstep_rewards.mean", "tensorboardX.SummaryWriter.add_scalar", "numpy.stack().mean", "numpy.stack().var", "tensorboardX.SummaryWriter.add_scalar", "agent.actor_critic.state_dict", "str", "torch.from_numpy", "torch.zeros.mean", "eval_perstep_rewards.mean", "numpy.stack", "str", "numpy.stack", "numpy.stack", "str", "numpy.stack().mean", "str", "numpy.stack"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_parallel_envs", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.setup_master", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.setup_master", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.initialize_obs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.wrap_horizon", "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.update", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.after_update", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.update_rollout", "home.repos.pwc.inspect_result.sumitsk_matrl.None.eval.evaluate", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.act"], ["def", "train", "(", "args", ",", "return_early", "=", "False", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "args", ".", "log_dir", ")", "\n", "envs", "=", "utils", ".", "make_parallel_envs", "(", "args", ")", "\n", "master", "=", "setup_master", "(", "args", ")", "\n", "# used during evaluation only", "\n", "eval_master", ",", "eval_env", "=", "setup_master", "(", "args", ",", "return_env", "=", "True", ")", "\n", "obs", "=", "envs", ".", "reset", "(", ")", "# shape - num_processes x num_agents x obs_dim", "\n", "master", ".", "initialize_obs", "(", "obs", ")", "\n", "n", "=", "len", "(", "master", ".", "all_agents", ")", "\n", "episode_rewards", "=", "torch", ".", "zeros", "(", "[", "args", ".", "num_processes", ",", "n", "]", ",", "device", "=", "args", ".", "device", ")", "\n", "final_rewards", "=", "torch", ".", "zeros", "(", "[", "args", ".", "num_processes", ",", "n", "]", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "# start simulations", "\n", "start", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "for", "j", "in", "range", "(", "args", ".", "num_updates", ")", ":", "\n", "        ", "for", "step", "in", "range", "(", "args", ".", "num_steps", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "actions_list", "=", "master", ".", "act", "(", "step", ")", "\n", "", "agent_actions", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "actions_list", ")", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "envs", ".", "step", "(", "agent_actions", ")", "\n", "reward", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "reward", ")", ")", ".", "float", "(", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "episode_rewards", "+=", "reward", "\n", "masks", "=", "torch", ".", "FloatTensor", "(", "1", "-", "1.0", "*", "done", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "final_rewards", "*=", "masks", "\n", "final_rewards", "+=", "(", "1", "-", "masks", ")", "*", "episode_rewards", "\n", "episode_rewards", "*=", "masks", "\n", "\n", "master", ".", "update_rollout", "(", "obs", ",", "reward", ",", "masks", ")", "\n", "\n", "", "master", ".", "wrap_horizon", "(", ")", "\n", "return_vals", "=", "master", ".", "update", "(", ")", "\n", "value_loss", "=", "return_vals", "[", ":", ",", "0", "]", "\n", "action_loss", "=", "return_vals", "[", ":", ",", "1", "]", "\n", "dist_entropy", "=", "return_vals", "[", ":", ",", "2", "]", "\n", "master", ".", "after_update", "(", ")", "\n", "\n", "if", "j", "%", "args", ".", "save_interval", "==", "0", "and", "not", "args", ".", "test", ":", "\n", "            ", "savedict", "=", "{", "'models'", ":", "[", "agent", ".", "actor_critic", ".", "state_dict", "(", ")", "for", "agent", "in", "master", ".", "all_agents", "]", "}", "\n", "ob_rms", "=", "(", "None", ",", "None", ")", "if", "envs", ".", "ob_rms", "is", "None", "else", "(", "envs", ".", "ob_rms", "[", "0", "]", ".", "mean", ",", "envs", ".", "ob_rms", "[", "0", "]", ".", "var", ")", "\n", "savedict", "[", "'ob_rms'", "]", "=", "ob_rms", "\n", "savedir", "=", "args", ".", "save_dir", "+", "'/ep'", "+", "str", "(", "j", ")", "+", "'.pt'", "\n", "torch", ".", "save", "(", "savedict", ",", "savedir", ")", "\n", "\n", "", "total_num_steps", "=", "(", "j", "+", "1", ")", "*", "args", ".", "num_processes", "*", "args", ".", "num_steps", "\n", "\n", "if", "j", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "end", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "seconds", "=", "(", "end", "-", "start", ")", ".", "total_seconds", "(", ")", "\n", "mean_reward", "=", "final_rewards", ".", "mean", "(", "dim", "=", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "print", "(", "\"Updates {} | Num timesteps {} | Time {} | FPS {}\\nMean reward {}\\nEntropy {:.4f} Value loss {:.4f} Policy loss {:.4f}\\n\"", ".", "\n", "format", "(", "j", ",", "total_num_steps", ",", "str", "(", "end", "-", "start", ")", ",", "int", "(", "total_num_steps", "/", "seconds", ")", ",", "\n", "mean_reward", ",", "dist_entropy", "[", "0", "]", ",", "value_loss", "[", "0", "]", ",", "action_loss", "[", "0", "]", ")", ")", "\n", "if", "not", "args", ".", "test", ":", "\n", "                ", "for", "idx", "in", "range", "(", "n", ")", ":", "\n", "                    ", "writer", ".", "add_scalar", "(", "'agent'", "+", "str", "(", "idx", ")", "+", "'/training_reward'", ",", "mean_reward", "[", "idx", "]", ",", "j", ")", "\n", "\n", "", "writer", ".", "add_scalar", "(", "'all/value_loss'", ",", "value_loss", "[", "0", "]", ",", "j", ")", "\n", "writer", ".", "add_scalar", "(", "'all/action_loss'", ",", "action_loss", "[", "0", "]", ",", "j", ")", "\n", "writer", ".", "add_scalar", "(", "'all/dist_entropy'", ",", "dist_entropy", "[", "0", "]", ",", "j", ")", "\n", "\n", "", "", "if", "args", ".", "eval_interval", "is", "not", "None", "and", "j", "%", "args", ".", "eval_interval", "==", "0", ":", "\n", "            ", "ob_rms", "=", "(", "None", ",", "None", ")", "if", "envs", ".", "ob_rms", "is", "None", "else", "(", "envs", ".", "ob_rms", "[", "0", "]", ".", "mean", ",", "envs", ".", "ob_rms", "[", "0", "]", ".", "var", ")", "\n", "print", "(", "'==========================================================================================='", ")", "\n", "_", ",", "eval_perstep_rewards", ",", "final_min_dists", ",", "num_success", ",", "eval_episode_len", "=", "evaluate", "(", "args", ",", "None", ",", "master", ".", "all_policies", ",", "\n", "ob_rms", "=", "ob_rms", ",", "env", "=", "eval_env", ",", "\n", "master", "=", "eval_master", ")", "\n", "print", "(", "'Evaluation {:d} | Mean per-step reward {:.2f}'", ".", "format", "(", "j", "//", "args", ".", "eval_interval", ",", "eval_perstep_rewards", ".", "mean", "(", ")", ")", ")", "\n", "print", "(", "'Num success {:d}/{:d} | Episode Length {:.2f}'", ".", "format", "(", "num_success", ",", "args", ".", "num_eval_episodes", ",", "eval_episode_len", ")", ")", "\n", "if", "final_min_dists", ":", "\n", "                ", "print", "(", "'Final_dists_mean {}'", ".", "format", "(", "np", ".", "stack", "(", "final_min_dists", ")", ".", "mean", "(", "0", ")", ")", ")", "\n", "print", "(", "'Final_dists_var {}'", ".", "format", "(", "np", ".", "stack", "(", "final_min_dists", ")", ".", "var", "(", "0", ")", ")", ")", "\n", "", "print", "(", "'===========================================================================================\\n'", ")", "\n", "\n", "if", "not", "args", ".", "test", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "'all/eval_success'", ",", "100.0", "*", "num_success", "/", "args", ".", "num_eval_episodes", ",", "j", ")", "\n", "writer", ".", "add_scalar", "(", "'all/episode_length'", ",", "eval_episode_len", ",", "j", ")", "\n", "for", "idx", "in", "range", "(", "n", ")", ":", "\n", "                    ", "writer", ".", "add_scalar", "(", "'agent'", "+", "str", "(", "idx", ")", "+", "'/eval_per_step_reward'", ",", "eval_perstep_rewards", ".", "mean", "(", "0", ")", "[", "idx", "]", ",", "j", ")", "\n", "if", "final_min_dists", ":", "\n", "                        ", "writer", ".", "add_scalar", "(", "'agent'", "+", "str", "(", "idx", ")", "+", "'/eval_min_dist'", ",", "np", ".", "stack", "(", "final_min_dists", ")", ".", "mean", "(", "0", ")", "[", "idx", "]", ",", "j", ")", "\n", "\n", "", "", "", "curriculum_success_thres", "=", "0.9", "\n", "if", "return_early", "and", "num_success", "*", "1.", "/", "args", ".", "num_eval_episodes", ">", "curriculum_success_thres", ":", "\n", "                ", "savedict", "=", "{", "'models'", ":", "[", "agent", ".", "actor_critic", ".", "state_dict", "(", ")", "for", "agent", "in", "master", ".", "all_agents", "]", "}", "\n", "ob_rms", "=", "(", "None", ",", "None", ")", "if", "envs", ".", "ob_rms", "is", "None", "else", "(", "envs", ".", "ob_rms", "[", "0", "]", ".", "mean", ",", "envs", ".", "ob_rms", "[", "0", "]", ".", "var", ")", "\n", "savedict", "[", "'ob_rms'", "]", "=", "ob_rms", "\n", "savedir", "=", "args", ".", "save_dir", "+", "'/ep'", "+", "str", "(", "j", ")", "+", "'.pt'", "\n", "torch", ".", "save", "(", "savedict", ",", "savedir", ")", "\n", "print", "(", "'===========================================================================================\\n'", ")", "\n", "print", "(", "'{} agents: training complete. Breaking.\\n'", ".", "format", "(", "args", ".", "num_agents", ")", ")", "\n", "print", "(", "'===========================================================================================\\n'", ")", "\n", "break", "\n", "\n", "", "", "", "writer", ".", "close", "(", ")", "\n", "if", "return_early", ":", "\n", "        ", "return", "savedir", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.arguments.get_args": [[8, 98], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "torch.cuda.is_available", "os.path.exists", "os.makedirs", "int", "os.path.exists", "print", "input", "sys.exit", "os.rename", "shutil.rmtree", "NotImplementedError"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'RL'", ")", "\n", "\n", "# environment", "\n", "parser", ".", "add_argument", "(", "'--env-name'", ",", "default", "=", "'simple_spread'", ",", "help", "=", "'one from {simple_spread, simple_formation, simple_line})'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-agents'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'--masking'", ",", "action", "=", "'store_true'", ",", "help", "=", "'restrict communication to within some threshold'", ")", "\n", "parser", ".", "add_argument", "(", "'--mask-dist'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'distance to restrict comms'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout-masking'", ",", "action", "=", "'store_true'", ",", "help", "=", "'dropout masking enabled'", ")", "\n", "parser", ".", "add_argument", "(", "'--entity-mp'", ",", "action", "=", "'store_true'", ",", "help", "=", "'enable entity message passing'", ")", "\n", "parser", ".", "add_argument", "(", "'--identity-size'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "'size of identity vector'", ")", "\n", "\n", "# training ", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'random seed (default: None)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-processes'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'how many training CPU processes to use (default: 32)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-steps'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'number of forward steps in PPO (default: 128)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'disables CUDA training'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-frames'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "50e6", ")", ",", "help", "=", "'number of frames to train (default: 50e6)'", ")", "\n", "parser", ".", "add_argument", "(", "'--arena-size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'size of arena'", ")", "\n", "\n", "# evaluation", "\n", "parser", ".", "add_argument", "(", "'--num-eval-episodes'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "'number of episodes to evaluate with'", ")", "\n", "parser", ".", "add_argument", "(", "'--dist-threshold'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'distance within landmark is considered covered (for simple_spread)'", ")", "\n", "parser", ".", "add_argument", "(", "'--render'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--record-video'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'record evaluation video'", ")", "\n", "\n", "# PPO", "\n", "parser", ".", "add_argument", "(", "'--algo'", ",", "default", "=", "'ppo'", ",", "help", "=", "'algorithm to use: a2c | ppo | acktr'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "help", "=", "'learning rate (default: 1e-4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.99", ",", "help", "=", "'discount factor for rewards (default: 0.99)'", ")", "\n", "parser", ".", "add_argument", "(", "'--tau'", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "help", "=", "'gae parameter (default: 0.95)'", ")", "\n", "parser", ".", "add_argument", "(", "'--entropy-coef'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'entropy term coefficient (default: 0.01)'", ")", "\n", "parser", ".", "add_argument", "(", "'--value-loss-coef'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'value loss coefficient (default: 0.05)'", ")", "\n", "parser", ".", "add_argument", "(", "'--max-grad-norm'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'max norm of gradients (default: 0.5)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ppo-epoch'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'number of ppo epochs (default: 4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--num-mini-batch'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'number of batches for ppo (default: 32)'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip-param'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'ppo clip parameter (default: 0.2)'", ")", "\n", "\n", "# logging", "\n", "parser", ".", "add_argument", "(", "'--save-dir'", ",", "default", "=", "'tmp'", ",", "help", "=", "'directory to save models (default: tmp)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-dir'", ",", "default", "=", "'logs'", ",", "help", "=", "'directory to save logs'", ")", "\n", "parser", ".", "add_argument", "(", "'--save-interval'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'save interval, one save per n updates (default: 200)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'log interval, one log per n updates (default: 10)'", ")", "\n", "\n", "# Miscellaneous", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--load-dir'", ",", "default", "=", "None", ",", "help", "=", "'filename to load all policies from'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-interval'", ",", "default", "=", "50", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--continue-training'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "# we always set these to TRUE, so automating this", "\n", "parser", ".", "add_argument", "(", "'--no-clipped-value-loss'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "clipped_value_loss", "=", "not", "args", ".", "no_clipped_value_loss", "\n", "\n", "args", ".", "cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "args", ".", "cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "save_dir", "=", "'../marlsave/save_new/'", "+", "args", ".", "save_dir", "\n", "args", ".", "log_dir", "=", "args", ".", "save_dir", "+", "'/'", "+", "args", ".", "log_dir", "\n", "\n", "if", "args", ".", "continue_training", ":", "\n", "        ", "assert", "args", ".", "load_dir", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "load_dir", ")", ",", "\"Please specify valid model file to load if you want to continue training\"", "\n", "\n", "", "if", "args", ".", "identity_size", ">", "0", ":", "\n", "        ", "assert", "args", ".", "identity_size", ">=", "args", ".", "num_agents", ",", "'identity size should either be 0 or >= number of agents!'", "\n", "\n", "", "if", "not", "args", ".", "masking", ":", "\n", "        ", "args", ".", "mask_dist", "=", "None", "\n", "", "elif", "args", ".", "masking", "and", "args", ".", "dropout_masking", ":", "\n", "        ", "args", ".", "mask_dist", "=", "-", "10", "\n", "\n", "# raise warning if save directory already exists", "\n", "", "if", "not", "args", ".", "test", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "save_dir", ")", ":", "\n", "            ", "print", "(", "'\\nSave directory exists already! Enter'", ")", "\n", "ch", "=", "input", "(", "'c (rename the existing directory with _old and continue)\\ns (stop)!\\ndel (delete existing dir): '", ")", "\n", "if", "ch", "==", "'s'", ":", "\n", "                ", "sys", ".", "exit", "(", "0", ")", "\n", "", "elif", "ch", "==", "'c'", ":", "\n", "                ", "os", ".", "rename", "(", "args", ".", "save_dir", ",", "args", ".", "save_dir", "+", "'_old'", ")", "\n", "", "elif", "ch", "==", "'del'", ":", "\n", "                ", "shutil", ".", "rmtree", "(", "args", ".", "save_dir", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Unknown input'", ")", "\n", "", "", "os", ".", "makedirs", "(", "args", ".", "save_dir", ")", "\n", "\n", "", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.eval.evaluate": [[9, 92], ["print", "env.seed", "master.load_models", "master.set_eval_mode", "numpy.full", "numpy.full", "range", "learner.setup_master", "numpy.random.randint", "env.reset", "utils.normalize_obs", "numpy.full", "env.render", "numpy.all", "env.step", "utils.normalize_obs", "numpy.array", "final_min_dists.append", "print", "input", "attn.max.max", "torch.no_grad", "master.eval_act", "env.render", "final_min_dists.append", "len", "attn.max.max", "time.sleep", "len"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.seed", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.load_models", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.set_eval_mode", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.setup_master", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.normalize_obs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.normalize_obs", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.eval_act", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render"], ["def", "evaluate", "(", "args", ",", "seed", ",", "policies_list", ",", "ob_rms", "=", "None", ",", "render", "=", "False", ",", "env", "=", "None", ",", "master", "=", "None", ",", "render_attn", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    RL evaluation: supports eval through training code as well as independently\n    policies_list should be a list of policies of all the agents;\n    len(policies_list) = num agents\n    \"\"\"", "\n", "if", "env", "is", "None", "or", "master", "is", "None", ":", "# if any one of them is None, generate both of them", "\n", "        ", "master", ",", "env", "=", "setup_master", "(", "args", ",", "return_env", "=", "True", ")", "\n", "\n", "", "if", "seed", "is", "None", ":", "# ensure env eval seed is different from training seed", "\n", "        ", "seed", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "100000", ")", "\n", "", "print", "(", "\"Evaluation Seed: \"", ",", "seed", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "\n", "if", "ob_rms", "is", "not", "None", ":", "\n", "        ", "obs_mean", ",", "obs_std", "=", "ob_rms", "\n", "", "else", ":", "\n", "        ", "obs_mean", "=", "None", "\n", "obs_std", "=", "None", "\n", "", "master", ".", "load_models", "(", "policies_list", ")", "\n", "master", ".", "set_eval_mode", "(", ")", "\n", "\n", "num_eval_episodes", "=", "args", ".", "num_eval_episodes", "\n", "all_episode_rewards", "=", "np", ".", "full", "(", "(", "num_eval_episodes", ",", "env", ".", "n", ")", ",", "0.0", ")", "\n", "per_step_rewards", "=", "np", ".", "full", "(", "(", "num_eval_episodes", ",", "env", ".", "n", ")", ",", "0.0", ")", "\n", "\n", "# TODO: provide support for recurrent policies and mask", "\n", "recurrent_hidden_states", "=", "None", "\n", "mask", "=", "None", "\n", "\n", "# world.dists at the end of episode for simple_spread", "\n", "final_min_dists", "=", "[", "]", "\n", "num_success", "=", "0", "\n", "episode_length", "=", "0", "\n", "\n", "for", "t", "in", "range", "(", "num_eval_episodes", ")", ":", "\n", "        ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "obs", "=", "normalize_obs", "(", "obs", ",", "obs_mean", ",", "obs_std", ")", "\n", "done", "=", "[", "False", "]", "*", "env", ".", "n", "\n", "episode_rewards", "=", "np", ".", "full", "(", "env", ".", "n", ",", "0.0", ")", "\n", "episode_steps", "=", "0", "\n", "if", "render", ":", "\n", "            ", "attn", "=", "None", "if", "not", "render_attn", "else", "master", ".", "team_attn", "\n", "if", "attn", "is", "not", "None", "and", "len", "(", "attn", ".", "shape", ")", "==", "3", ":", "\n", "                ", "attn", "=", "attn", ".", "max", "(", "0", ")", "\n", "", "env", ".", "render", "(", "attn", "=", "attn", ")", "\n", "\n", "", "while", "not", "np", ".", "all", "(", "done", ")", ":", "\n", "            ", "actions", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "actions", "=", "master", ".", "eval_act", "(", "obs", ",", "recurrent_hidden_states", ",", "mask", ")", "\n", "", "episode_steps", "+=", "1", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "obs", "=", "normalize_obs", "(", "obs", ",", "obs_mean", ",", "obs_std", ")", "\n", "episode_rewards", "+=", "np", ".", "array", "(", "reward", ")", "\n", "if", "render", ":", "\n", "                ", "attn", "=", "None", "if", "not", "render_attn", "else", "master", ".", "team_attn", "\n", "if", "attn", "is", "not", "None", "and", "len", "(", "attn", ".", "shape", ")", "==", "3", ":", "\n", "                    ", "attn", "=", "attn", ".", "max", "(", "0", ")", "\n", "", "env", ".", "render", "(", "attn", "=", "attn", ")", "\n", "if", "args", ".", "record_video", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.08", ")", "\n", "\n", "", "", "", "per_step_rewards", "[", "t", "]", "=", "episode_rewards", "/", "episode_steps", "\n", "num_success", "+=", "info", "[", "'n'", "]", "[", "0", "]", "[", "'is_success'", "]", "\n", "episode_length", "=", "(", "episode_length", "*", "t", "+", "info", "[", "'n'", "]", "[", "0", "]", "[", "'world_steps'", "]", ")", "/", "(", "t", "+", "1", ")", "\n", "\n", "# for simple spread env only", "\n", "if", "args", ".", "env_name", "==", "'simple_spread'", ":", "\n", "            ", "final_min_dists", ".", "append", "(", "env", ".", "world", ".", "min_dists", ")", "\n", "", "elif", "args", ".", "env_name", "==", "'simple_formation'", "or", "args", ".", "env_name", "==", "'simple_line'", ":", "\n", "            ", "final_min_dists", ".", "append", "(", "env", ".", "world", ".", "dists", ")", "\n", "\n", "", "if", "render", ":", "\n", "            ", "print", "(", "\"Ep {} | Success: {} \\n Av per-step reward: {:.2f} | Ep Length {}\"", ".", "format", "(", "t", ",", "info", "[", "'n'", "]", "[", "0", "]", "[", "'is_success'", "]", ",", "\n", "per_step_rewards", "[", "t", "]", "[", "0", "]", ",", "info", "[", "'n'", "]", "[", "0", "]", "[", "'world_steps'", "]", ")", ")", "\n", "", "all_episode_rewards", "[", "t", ",", ":", "]", "=", "episode_rewards", "# all_episode_rewards shape: num_eval_episodes x num agents", "\n", "\n", "if", "args", ".", "record_video", ":", "\n", "# print(attn)", "\n", "            ", "input", "(", "'Press enter to continue: '", ")", "\n", "\n", "", "", "return", "all_episode_rewards", ",", "per_step_rewards", ",", "final_min_dists", ",", "num_success", ",", "episode_length", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.__init__": [[7, 18], ["object.__init__", "rlcore.storage.RolloutStorage", "rlcore.algo.PPO"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ",", "policy", ",", "obs_shape", ",", "action_space", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "obs_shape", "=", "obs_shape", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "actor_critic", "=", "policy", "\n", "self", ".", "rollouts", "=", "RolloutStorage", "(", "args", ".", "num_steps", ",", "args", ".", "num_processes", ",", "self", ".", "obs_shape", ",", "self", ".", "action_space", ",", "\n", "recurrent_hidden_state_size", "=", "1", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "trainer", "=", "PPO", "(", "self", ".", "actor_critic", ",", "args", ".", "clip_param", ",", "args", ".", "ppo_epoch", ",", "args", ".", "num_mini_batch", ",", "args", ".", "value_loss_coef", ",", "\n", "args", ".", "entropy_coef", ",", "lr", "=", "args", ".", "lr", ",", "max_grad_norm", "=", "args", ".", "max_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.load_model": [[19, 21], ["rlagent.Neo.actor_critic.load_state_dict"], "methods", ["None"], ["", "def", "load_model", "(", "self", ",", "policy_state", ")", ":", "\n", "      ", "self", ".", "actor_critic", ".", "load_state_dict", "(", "policy_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.initialize_obs": [[22, 25], ["rlagent.Neo.rollouts.obs[].copy_"], "methods", ["None"], ["", "def", "initialize_obs", "(", "self", ",", "obs", ")", ":", "\n", "# this function is called at the start of episode", "\n", "    ", "self", ".", "rollouts", ".", "obs", "[", "0", "]", ".", "copy_", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.update_rollout": [[26, 28], ["rlagent.Neo.rollouts.insert"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.insert"], ["", "def", "update_rollout", "(", "self", ",", "obs", ",", "reward", ",", "mask", ")", ":", "\n", "    ", "self", ".", "rollouts", ".", "insert", "(", "obs", ",", "self", ".", "states", ",", "self", ".", "action", ",", "self", ".", "action_log_prob", ",", "self", ".", "value", ",", "reward", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.act": [[29, 33], ["rlagent.Neo.actor_critic.act"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.act"], ["", "def", "act", "(", "self", ",", "step", ",", "deterministic", "=", "False", ")", ":", "\n", "    ", "self", ".", "value", ",", "self", ".", "action", ",", "self", ".", "action_log_prob", ",", "self", ".", "states", "=", "self", ".", "actor_critic", ".", "act", "(", "self", ".", "rollouts", ".", "obs", "[", "step", "]", ",", "\n", "self", ".", "rollouts", ".", "recurrent_hidden_states", "[", "step", "]", ",", "self", ".", "rollouts", ".", "masks", "[", "step", "]", ",", "deterministic", "=", "deterministic", ")", "\n", "return", "self", ".", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.wrap_horizon": [[34, 36], ["rlagent.Neo.rollouts.compute_returns"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.compute_returns"], ["", "def", "wrap_horizon", "(", "self", ",", "next_value", ")", ":", "\n", "    ", "self", ".", "rollouts", ".", "compute_returns", "(", "next_value", ",", "True", ",", "self", ".", "args", ".", "gamma", ",", "self", ".", "args", ".", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.after_update": [[37, 39], ["rlagent.Neo.rollouts.after_update"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.after_update"], ["", "def", "after_update", "(", "self", ")", ":", "\n", "    ", "self", ".", "rollouts", ".", "after_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.update": [[40, 42], ["rlagent.Neo.trainer.update"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.update"], ["", "def", "update", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "trainer", ".", "update", "(", "self", ".", "rollouts", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.__init__": [[18, 75], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mpnn.MultiHeadAttention", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "rlcore.distributions.Categorical", "mpnn.MPNN.apply", "numpy.ones", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mpnn.MultiHeadAttention", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "mpnn.MPNN.in_fn.weight.data.fill_", "mpnn.MPNN.in_fn.bias.data.fill_", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin", "torch.Linear", "torch.Linear", "torch.Linear", "mpnn.MPNN.nonlin"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "action_space", ",", "num_agents", ",", "num_entities", ",", "input_size", "=", "16", ",", "hidden_dim", "=", "128", ",", "embed_dim", "=", "None", ",", "\n", "pos_index", "=", "2", ",", "norm_in", "=", "False", ",", "nonlin", "=", "nn", ".", "ReLU", ",", "n_heads", "=", "1", ",", "mask_dist", "=", "None", ",", "entity_mp", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "h_dim", "=", "hidden_dim", "\n", "self", ".", "nonlin", "=", "nonlin", "\n", "self", ".", "num_agents", "=", "num_agents", "# number of agents", "\n", "self", ".", "num_entities", "=", "num_entities", "# number of entities", "\n", "self", ".", "K", "=", "3", "# message passing rounds", "\n", "self", ".", "embed_dim", "=", "self", ".", "h_dim", "if", "embed_dim", "is", "None", "else", "embed_dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "mask_dist", "=", "mask_dist", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "entity_mp", "=", "entity_mp", "\n", "# this index must be from the beginning of observation vector", "\n", "self", ".", "pos_index", "=", "pos_index", "\n", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "input_size", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "self", ".", "messages", "=", "MultiHeadAttention", "(", "n_heads", "=", "self", ".", "n_heads", ",", "input_dim", "=", "self", ".", "h_dim", ",", "embed_dim", "=", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "update", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "h_dim", "+", "self", ".", "embed_dim", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "self", ".", "value_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "h_dim", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "h_dim", ",", "1", ")", ")", "\n", "\n", "self", ".", "policy_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "h_dim", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "if", "self", ".", "entity_mp", ":", "\n", "            ", "self", ".", "entity_encoder", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "2", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "self", ".", "entity_messages", "=", "MultiHeadAttention", "(", "n_heads", "=", "1", ",", "input_dim", "=", "self", ".", "h_dim", ",", "embed_dim", "=", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "entity_update", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "h_dim", "+", "self", ".", "embed_dim", ",", "self", ".", "h_dim", ")", ",", "\n", "self", ".", "nonlin", "(", "inplace", "=", "True", ")", ")", "\n", "\n", "", "num_actions", "=", "action_space", ".", "n", "\n", "self", ".", "dist", "=", "Categorical", "(", "self", ".", "h_dim", ",", "num_actions", ")", "\n", "\n", "self", ".", "is_recurrent", "=", "False", "\n", "\n", "if", "norm_in", ":", "\n", "            ", "self", ".", "in_fn", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "input_size", ")", "\n", "self", ".", "in_fn", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "in_fn", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "in_fn", "=", "lambda", "x", ":", "x", "\n", "", "self", ".", "apply", "(", "weights_init", ")", "\n", "\n", "self", ".", "attn_mat", "=", "np", ".", "ones", "(", "(", "num_agents", ",", "num_agents", ")", ")", "\n", "\n", "self", ".", "dropout_mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.calculate_mask": [[76, 99], ["torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "inp.size", "range", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.roll", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "range", "torch.full.copy_", "torch.full.copy_", "torch.full.copy_", "mask[].copy_", "temp.diagonal().fill_", "numpy.random.random_sample", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.full.size", "torch.full.size", "torch.full.size", "temp.diagonal", "temp.transpose"], "methods", ["None"], ["", "def", "calculate_mask", "(", "self", ",", "inp", ")", ":", "\n", "# inp is batch_size x self.input_size where batch_size is num_processes*num_agents", "\n", "\n", "        ", "pos", "=", "inp", "[", ":", ",", "self", ".", "pos_index", ":", "self", ".", "pos_index", "+", "2", "]", "\n", "bsz", "=", "inp", ".", "size", "(", "0", ")", "//", "self", ".", "num_agents", "\n", "mask", "=", "torch", ".", "full", "(", "size", "=", "(", "bsz", ",", "self", ".", "num_agents", ",", "self", ".", "num_agents", ")", ",", "fill_value", "=", "0", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "if", "self", ".", "mask_dist", "is", "not", "None", "and", "self", ".", "mask_dist", ">", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "1", ",", "self", ".", "num_agents", ")", ":", "\n", "                ", "shifted", "=", "torch", ".", "roll", "(", "pos", ",", "-", "bsz", "*", "i", ",", "0", ")", "\n", "dists", "=", "torch", ".", "norm", "(", "pos", "-", "shifted", ",", "dim", "=", "1", ")", "\n", "restrict", "=", "dists", ">", "self", ".", "mask_dist", "\n", "for", "x", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "                    ", "mask", "[", ":", ",", "x", ",", "(", "x", "+", "i", ")", "%", "self", ".", "num_agents", "]", ".", "copy_", "(", "restrict", "[", "bsz", "*", "x", ":", "bsz", "*", "(", "x", "+", "1", ")", "]", ")", "\n", "\n", "", "", "", "elif", "self", ".", "mask_dist", "is", "not", "None", "and", "self", ".", "mask_dist", "==", "-", "10", ":", "\n", "           ", "if", "self", ".", "dropout_mask", "is", "None", "or", "bsz", "!=", "self", ".", "dropout_mask", ".", "shape", "[", "0", "]", "or", "np", ".", "random", ".", "random_sample", "(", ")", "<", "0.1", ":", "# sample new dropout mask", "\n", "               ", "temp", "=", "torch", ".", "rand", "(", "mask", ".", "size", "(", ")", ")", ">", "0.85", "\n", "temp", ".", "diagonal", "(", "dim1", "=", "1", ",", "dim2", "=", "2", ")", ".", "fill_", "(", "0", ")", "\n", "self", ".", "dropout_mask", "=", "(", "temp", "+", "temp", ".", "transpose", "(", "1", ",", "2", ")", ")", "!=", "0", "\n", "", "mask", ".", "copy_", "(", "self", ".", "dropout_mask", ")", "\n", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._fwd": [[101, 124], ["mpnn.MPNN.calculate_mask", "mpnn.MPNN.encoder", "mpnn.MPNN.view().transpose", "range", "mpnn.MPNN.transpose().contiguous().view", "attn.squeeze().detach().cpu().numpy", "mpnn.MPNN.entity_encoder().view", "mpnn.MPNN.entity_messages().squeeze", "mpnn.MPNN.entity_update", "mpnn.MPNN.messages", "mpnn.MPNN.update", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mpnn.MPNN.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mpnn.MPNN.transpose().contiguous", "attn.squeeze().detach().cpu", "mpnn.MPNN.entity_encoder", "mpnn.MPNN.entity_messages", "landmark_inp.contiguous().view", "mpnn.MPNN.unsqueeze", "mpnn.MPNN.transpose", "attn.squeeze().detach", "landmark_inp.contiguous", "attn.squeeze"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.calculate_mask", "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.update"], ["", "def", "_fwd", "(", "self", ",", "inp", ")", ":", "\n", "# inp should be (batch_size,input_size)", "\n", "# inp - {iden, vel(2), pos(2), entities(...)}", "\n", "        ", "agent_inp", "=", "inp", "[", ":", ",", ":", "self", ".", "input_size", "]", "\n", "mask", "=", "self", ".", "calculate_mask", "(", "agent_inp", ")", "# shape <batch_size/N,N,N> with 0 for comm allowed, 1 for restricted", "\n", "\n", "h", "=", "self", ".", "encoder", "(", "agent_inp", ")", "# should be (batch_size,self.h_dim)", "\n", "if", "self", ".", "entity_mp", ":", "\n", "            ", "landmark_inp", "=", "inp", "[", ":", ",", "self", ".", "input_size", ":", "]", "# x,y pos of landmarks wrt agents", "\n", "# should be (batch_size,self.num_entities,self.h_dim)", "\n", "he", "=", "self", ".", "entity_encoder", "(", "landmark_inp", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "2", ")", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_entities", ",", "self", ".", "h_dim", ")", "\n", "entity_message", "=", "self", ".", "entity_messages", "(", "h", ".", "unsqueeze", "(", "1", ")", ",", "he", ")", ".", "squeeze", "(", "1", ")", "# should be (batch_size,self.h_dim)", "\n", "h", "=", "self", ".", "entity_update", "(", "torch", ".", "cat", "(", "(", "h", ",", "entity_message", ")", ",", "1", ")", ")", "# should be (batch_size,self.h_dim)", "\n", "\n", "", "h", "=", "h", ".", "view", "(", "self", ".", "num_agents", ",", "-", "1", ",", "self", ".", "h_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "# should be (batch_size/N,N,self.h_dim)", "\n", "\n", "for", "k", "in", "range", "(", "self", ".", "K", ")", ":", "\n", "            ", "m", ",", "attn", "=", "self", ".", "messages", "(", "h", ",", "mask", "=", "mask", ",", "return_attn", "=", "True", ")", "# should be <batch_size/N,N,self.embed_dim>", "\n", "h", "=", "self", ".", "update", "(", "torch", ".", "cat", "(", "(", "h", ",", "m", ")", ",", "2", ")", ")", "# should be <batch_size/N,N,self.h_dim>", "\n", "", "h", "=", "h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "h_dim", ")", "\n", "\n", "self", ".", "attn_mat", "=", "attn", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "h", "# should be <batch_size, self.h_dim> again", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.forward": [[125, 127], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ",", "state", ",", "mask", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._value": [[128, 130], ["mpnn.MPNN.value_head"], "methods", ["None"], ["", "def", "_value", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "value_head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._policy": [[131, 133], ["mpnn.MPNN.policy_head"], "methods", ["None"], ["", "def", "_policy", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "policy_head", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.act": [[134, 144], ["mpnn.MPNN._fwd", "mpnn.MPNN._value", "mpnn.MPNN.dist", "mpnn.MPNN.log_probs().view", "mpnn.MPNN._policy", "mpnn.MPNN.mode", "mpnn.MPNN.sample", "mpnn.MPNN.log_probs"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._fwd", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._value", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._policy", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.sample"], ["", "def", "act", "(", "self", ",", "inp", ",", "state", ",", "mask", "=", "None", ",", "deterministic", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "_fwd", "(", "inp", ")", "\n", "value", "=", "self", ".", "_value", "(", "x", ")", "\n", "dist", "=", "self", ".", "dist", "(", "self", ".", "_policy", "(", "x", ")", ")", "\n", "if", "deterministic", ":", "\n", "            ", "action", "=", "dist", ".", "mode", "(", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "dist", ".", "sample", "(", ")", "\n", "", "action_log_probs", "=", "dist", ".", "log_probs", "(", "action", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "return", "value", ",", "action", ",", "action_log_probs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.evaluate_actions": [[145, 152], ["mpnn.MPNN._fwd", "mpnn.MPNN._value", "mpnn.MPNN.dist", "mpnn.MPNN.log_probs", "mpnn.MPNN.entropy().mean", "mpnn.MPNN._policy", "mpnn.MPNN.entropy"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._fwd", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._value", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._policy"], ["", "def", "evaluate_actions", "(", "self", ",", "inp", ",", "state", ",", "mask", ",", "action", ")", ":", "\n", "        ", "x", "=", "self", ".", "_fwd", "(", "inp", ")", "\n", "value", "=", "self", ".", "_value", "(", "x", ")", "\n", "dist", "=", "self", ".", "dist", "(", "self", ".", "_policy", "(", "x", ")", ")", "\n", "action_log_probs", "=", "dist", ".", "log_probs", "(", "action", ")", "\n", "dist_entropy", "=", "dist", ".", "entropy", "(", ")", ".", "mean", "(", ")", "\n", "return", "value", ",", "action_log_probs", ",", "dist_entropy", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.get_value": [[153, 157], ["mpnn.MPNN._fwd", "mpnn.MPNN._value"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._fwd", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN._value"], ["", "def", "get_value", "(", "self", ",", "inp", ",", "state", ",", "mask", ")", ":", "\n", "        ", "x", "=", "self", ".", "_fwd", "(", "inp", ")", "\n", "value", "=", "self", ".", "_value", "(", "x", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MultiHeadAttention.__init__": [[161, 193], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "mpnn.MultiHeadAttention.init_parameters", "math.sqrt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MultiHeadAttention.init_parameters"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_heads", ",", "\n", "input_dim", ",", "\n", "embed_dim", "=", "None", ",", "\n", "val_dim", "=", "None", ",", "\n", "key_dim", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "val_dim", "is", "None", ":", "\n", "            ", "assert", "embed_dim", "is", "not", "None", ",", "\"Provide either embed_dim or val_dim\"", "\n", "val_dim", "=", "embed_dim", "//", "n_heads", "\n", "", "if", "key_dim", "is", "None", ":", "\n", "            ", "key_dim", "=", "val_dim", "\n", "\n", "", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "val_dim", "=", "val_dim", "\n", "self", ".", "key_dim", "=", "key_dim", "\n", "\n", "self", ".", "norm_factor", "=", "1", "/", "math", ".", "sqrt", "(", "key_dim", ")", "# See Attention is all you need", "\n", "\n", "self", ".", "W_query", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "n_heads", ",", "input_dim", ",", "key_dim", ")", ")", "\n", "self", ".", "W_key", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "n_heads", ",", "input_dim", ",", "key_dim", ")", ")", "\n", "self", ".", "W_val", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "n_heads", ",", "input_dim", ",", "val_dim", ")", ")", "\n", "\n", "if", "embed_dim", "is", "not", "None", ":", "\n", "            ", "self", ".", "W_out", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "n_heads", ",", "key_dim", ",", "embed_dim", ")", ")", "\n", "\n", "", "self", ".", "init_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MultiHeadAttention.init_parameters": [[194, 199], ["mpnn.MultiHeadAttention.parameters", "param.data.uniform_", "math.sqrt", "param.size"], "methods", ["None"], ["", "def", "init_parameters", "(", "self", ")", ":", "\n", "\n", "        ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "param", ".", "size", "(", "-", "1", ")", ")", "\n", "param", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MultiHeadAttention.forward": [[200, 256], ["h.size", "q.size", "h.contiguous().view", "q.contiguous().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "q.size", "q.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "mask.view().expand_as.view().expand_as.view().expand_as", "torch.softmax.clone", "h.contiguous", "q.contiguous", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul().view.transpose", "torch.matmul().view.transpose", "torch.matmul().view.transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "mask.view().expand_as.view().expand_as.view", "torch.matmul.permute().contiguous().view", "torch.matmul.permute().contiguous().view", "torch.matmul.permute().contiguous().view", "mpnn.MultiHeadAttention.W_out.view", "torch.matmul.permute().contiguous", "torch.matmul.permute().contiguous", "torch.matmul.permute().contiguous", "torch.matmul.permute", "torch.matmul.permute", "torch.matmul.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "q", ",", "h", "=", "None", ",", "mask", "=", "None", ",", "return_attn", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param q: queries (batch_size, n_query, input_dim)\n        :param h: data (batch_size, graph_size, input_dim)\n        :param mask: mask (batch_size, n_query, graph_size) or viewable as that (i.e. can be 2 dim if n_query == 1)\n        Mask should contain 1 if attention is not possible (i.e. mask is negative adjacency)\n        :return:\n        \"\"\"", "\n", "if", "h", "is", "None", ":", "\n", "            ", "h", "=", "q", "# compute self-attention", "\n", "\n", "# h should be (batch_size, graph_size, input_dim)", "\n", "", "batch_size", ",", "graph_size", ",", "input_dim", "=", "h", ".", "size", "(", ")", "\n", "n_query", "=", "q", ".", "size", "(", "1", ")", "\n", "assert", "q", ".", "size", "(", "0", ")", "==", "batch_size", "\n", "assert", "q", ".", "size", "(", "2", ")", "==", "input_dim", "\n", "assert", "input_dim", "==", "self", ".", "input_dim", ",", "\"Wrong embedding dimension of input\"", "\n", "\n", "hflat", "=", "h", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "input_dim", ")", "\n", "qflat", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "input_dim", ")", "\n", "\n", "# last dimension can be different for keys and values", "\n", "shp", "=", "(", "self", ".", "n_heads", ",", "batch_size", ",", "graph_size", ",", "-", "1", ")", "\n", "shp_q", "=", "(", "self", ".", "n_heads", ",", "batch_size", ",", "n_query", ",", "-", "1", ")", "\n", "\n", "# Calculate queries, (n_heads, n_query, graph_size, key/val_size)", "\n", "Q", "=", "torch", ".", "matmul", "(", "qflat", ",", "self", ".", "W_query", ")", ".", "view", "(", "shp_q", ")", "\n", "# Calculate keys and values (n_heads, batch_size, graph_size, key/val_size)", "\n", "K", "=", "torch", ".", "matmul", "(", "hflat", ",", "self", ".", "W_key", ")", ".", "view", "(", "shp", ")", "\n", "V", "=", "torch", ".", "matmul", "(", "hflat", ",", "self", ".", "W_val", ")", ".", "view", "(", "shp", ")", "\n", "\n", "# Calculate compatibility (n_heads, batch_size, n_query, graph_size)", "\n", "compatibility", "=", "self", ".", "norm_factor", "*", "torch", ".", "matmul", "(", "Q", ",", "K", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "# Optionally apply mask to prevent attention", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "view", "(", "1", ",", "batch_size", ",", "n_query", ",", "graph_size", ")", ".", "expand_as", "(", "compatibility", ")", "\n", "compatibility", "[", "mask", "]", "=", "-", "math", ".", "inf", "\n", "\n", "", "attn", "=", "F", ".", "softmax", "(", "compatibility", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# If there are nodes with no neighbours then softmax returns nan so we fix them to 0", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attnc", "=", "attn", ".", "clone", "(", ")", "\n", "attnc", "[", "mask", "]", "=", "0", "\n", "attn", "=", "attnc", "\n", "\n", "", "heads", "=", "torch", ".", "matmul", "(", "attn", ",", "V", ")", "\n", "\n", "out", "=", "torch", ".", "mm", "(", "\n", "heads", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "n_heads", "*", "self", ".", "val_dim", ")", ",", "\n", "self", ".", "W_out", ".", "view", "(", "-", "1", ",", "self", ".", "embed_dim", ")", "\n", ")", ".", "view", "(", "batch_size", ",", "n_query", ",", "self", ".", "embed_dim", ")", "\n", "\n", "if", "return_attn", ":", "\n", "            ", "return", "out", ",", "attn", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.weights_init": [[9, 15], ["torch.init.orthogonal_", "classname.find", "classname.find", "m.bias.data.fill_"], "function", ["None"], ["def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.normalize_obs": [[7, 12], ["numpy.divide"], "function", ["None"], ["def", "normalize_obs", "(", "obs", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "mean", "is", "not", "None", ":", "\n", "        ", "return", "np", ".", "divide", "(", "(", "obs", "-", "mean", ")", ",", "std", ")", "\n", "", "else", ":", "\n", "        ", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_env": [[14, 20], ["utils.make_multiagent_env", "make_multiagent_env.seed"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_multiagent_env", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.seed"], ["", "", "def", "make_env", "(", "env_id", ",", "seed", ",", "rank", ",", "num_agents", ",", "dist_threshold", ",", "arena_size", ",", "identity_size", ")", ":", "\n", "    ", "def", "_thunk", "(", ")", ":", "\n", "        ", "env", "=", "make_multiagent_env", "(", "env_id", ",", "num_agents", ",", "dist_threshold", ",", "arena_size", ",", "identity_size", ")", "\n", "env", ".", "seed", "(", "seed", "+", "rank", ")", "# seed not implemented", "\n", "return", "env", "\n", "", "return", "_thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_multiagent_env": [[22, 37], ["multiagent.load().Scenario", "scenarios.load().Scenario.make_world", "multiagent.environment.MultiAgentEnv", "multiagent.load", "hasattr"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.make_world", "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.__init__.load"], ["", "def", "make_multiagent_env", "(", "env_id", ",", "num_agents", ",", "dist_threshold", ",", "arena_size", ",", "identity_size", ")", ":", "\n", "    ", "scenario", "=", "scenarios", ".", "load", "(", "env_id", "+", "\".py\"", ")", ".", "Scenario", "(", "num_agents", "=", "num_agents", ",", "dist_threshold", "=", "dist_threshold", ",", "\n", "arena_size", "=", "arena_size", ",", "identity_size", "=", "identity_size", ")", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "\n", "env", "=", "MultiAgentEnv", "(", "world", "=", "world", ",", "\n", "reset_callback", "=", "scenario", ".", "reset_world", ",", "\n", "reward_callback", "=", "scenario", ".", "reward", ",", "\n", "observation_callback", "=", "scenario", ".", "observation", ",", "\n", "info_callback", "=", "scenario", ".", "info", "if", "hasattr", "(", "scenario", ",", "'info'", ")", "else", "None", ",", "\n", "discrete_action", "=", "True", ",", "\n", "done_callback", "=", "scenario", ".", "done", ",", "\n", "cam_range", "=", "arena_size", "\n", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_parallel_envs": [[39, 50], ["gym_vecenv.MultiAgentVecNormalize", "utils.make_env", "gym_vecenv.SubprocVecEnv", "gym_vecenv.DummyVecEnv", "range"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.mape.make_env.make_env"], ["", "def", "make_parallel_envs", "(", "args", ")", ":", "\n", "# make parallel environments", "\n", "    ", "envs", "=", "[", "make_env", "(", "args", ".", "env_name", ",", "args", ".", "seed", ",", "i", ",", "args", ".", "num_agents", ",", "\n", "args", ".", "dist_threshold", ",", "args", ".", "arena_size", ",", "args", ".", "identity_size", ")", "for", "i", "in", "range", "(", "args", ".", "num_processes", ")", "]", "\n", "if", "args", ".", "num_processes", ">", "1", ":", "\n", "        ", "envs", "=", "gym_vecenv", ".", "SubprocVecEnv", "(", "envs", ")", "\n", "", "else", ":", "\n", "        ", "envs", "=", "gym_vecenv", ".", "DummyVecEnv", "(", "envs", ")", "\n", "\n", "", "envs", "=", "gym_vecenv", ".", "MultiAgentVecNormalize", "(", "envs", ",", "ob", "=", "False", ",", "ret", "=", "True", ")", "\n", "return", "envs", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.init": [[52, 56], ["weight_init", "bias_init"], "function", ["None"], ["", "def", "init", "(", "module", ",", "weight_init", ",", "bias_init", ",", "gain", "=", "1", ")", ":", "\n", "    ", "weight_init", "(", "module", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "bias_init", "(", "module", ".", "bias", ".", "data", ")", "\n", "return", "module", "\n", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.__init__": [[71, 80], ["rlcore.algo.JointPPO", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "teams_list", ",", "policies_list", ",", "env", ")", ":", "\n", "        ", "self", ".", "teams_list", "=", "[", "x", "for", "x", "in", "teams_list", "if", "len", "(", "x", ")", "!=", "0", "]", "\n", "self", ".", "all_agents", "=", "[", "agent", "for", "team", "in", "teams_list", "for", "agent", "in", "team", "]", "\n", "self", ".", "policies_list", "=", "[", "x", "for", "x", "in", "policies_list", "if", "x", "is", "not", "None", "]", "\n", "self", ".", "trainers_list", "=", "[", "JointPPO", "(", "policy", ",", "args", ".", "clip_param", ",", "args", ".", "ppo_epoch", ",", "args", ".", "num_mini_batch", ",", "args", ".", "value_loss_coef", ",", "\n", "args", ".", "entropy_coef", ",", "lr", "=", "args", ".", "lr", ",", "max_grad_norm", "=", "args", ".", "max_grad_norm", ",", "\n", "use_clipped_value_loss", "=", "args", ".", "clipped_value_loss", ")", "for", "policy", "in", "self", ".", "policies_list", "]", "\n", "self", ".", "device", "=", "args", ".", "device", "\n", "self", ".", "env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.all_policies": [[81, 84], ["agent.actor_critic.state_dict"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_policies", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", ".", "actor_critic", ".", "state_dict", "(", ")", "for", "agent", "in", "self", ".", "all_agents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.team_attn": [[85, 88], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "team_attn", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "policies_list", "[", "0", "]", ".", "attn_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.initialize_obs": [[89, 94], ["enumerate", "agent.initialize_obs", "agent.rollouts.to", "torch.from_numpy().float().to", "torch.from_numpy().float", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.initialize_obs", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to"], ["", "def", "initialize_obs", "(", "self", ",", "obs", ")", ":", "\n", "# obs - num_processes x num_agents x obs_dim", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "all_agents", ")", ":", "\n", "            ", "agent", ".", "initialize_obs", "(", "torch", ".", "from_numpy", "(", "obs", "[", ":", ",", "i", ",", ":", "]", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "agent", ".", "rollouts", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.act": [[95, 116], ["zip", "torch.cat", "torch.cat", "torch.cat", "policy.act", "len", "range", "torch.chunk", "actions_list.append", "all_action[].cpu().numpy", "all_action[].cpu"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.act"], ["", "", "def", "act", "(", "self", ",", "step", ")", ":", "\n", "        ", "actions_list", "=", "[", "]", "\n", "for", "team", ",", "policy", "in", "zip", "(", "self", ".", "teams_list", ",", "self", ".", "policies_list", ")", ":", "\n", "# concatenate all inputs", "\n", "            ", "all_obs", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "obs", "[", "step", "]", "for", "agent", "in", "team", "]", ")", "\n", "all_hidden", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "recurrent_hidden_states", "[", "step", "]", "for", "agent", "in", "team", "]", ")", "\n", "all_masks", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "masks", "[", "step", "]", "for", "agent", "in", "team", "]", ")", "\n", "\n", "props", "=", "policy", ".", "act", "(", "all_obs", ",", "all_hidden", ",", "all_masks", ",", "deterministic", "=", "False", ")", "# a single forward pass ", "\n", "\n", "# split all outputs", "\n", "n", "=", "len", "(", "team", ")", "\n", "all_value", ",", "all_action", ",", "all_action_log_prob", ",", "all_states", "=", "[", "torch", ".", "chunk", "(", "x", ",", "n", ")", "for", "x", "in", "props", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "team", "[", "i", "]", ".", "value", "=", "all_value", "[", "i", "]", "\n", "team", "[", "i", "]", ".", "action", "=", "all_action", "[", "i", "]", "\n", "team", "[", "i", "]", ".", "action_log_prob", "=", "all_action_log_prob", "[", "i", "]", "\n", "team", "[", "i", "]", ".", "states", "=", "all_states", "[", "i", "]", "\n", "actions_list", ".", "append", "(", "all_action", "[", "i", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "return", "actions_list", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.update": [[117, 126], ["enumerate", "numpy.stack().reshape", "trainer.update", "return_vals.append", "numpy.stack", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.update"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "return_vals", "=", "[", "]", "\n", "# use joint ppo for training each team", "\n", "for", "i", ",", "trainer", "in", "enumerate", "(", "self", ".", "trainers_list", ")", ":", "\n", "            ", "rollouts_list", "=", "[", "agent", ".", "rollouts", "for", "agent", "in", "self", ".", "teams_list", "[", "i", "]", "]", "\n", "vals", "=", "trainer", ".", "update", "(", "rollouts_list", ")", "\n", "return_vals", ".", "append", "(", "[", "np", ".", "array", "(", "vals", ")", "]", "*", "len", "(", "rollouts_list", ")", ")", "\n", "\n", "", "return", "np", ".", "stack", "(", "[", "x", "for", "v", "in", "return_vals", "for", "x", "in", "v", "]", ")", ".", "reshape", "(", "-", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.wrap_horizon": [[127, 139], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.chunk", "range", "torch.no_grad", "policy.get_value", "len", "len", "team[].wrap_horizon"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.get_value", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.wrap_horizon"], ["", "def", "wrap_horizon", "(", "self", ")", ":", "\n", "        ", "for", "team", ",", "policy", "in", "zip", "(", "self", ".", "teams_list", ",", "self", ".", "policies_list", ")", ":", "\n", "            ", "last_obs", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "obs", "[", "-", "1", "]", "for", "agent", "in", "team", "]", ")", "\n", "last_hidden", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "recurrent_hidden_states", "[", "-", "1", "]", "for", "agent", "in", "team", "]", ")", "\n", "last_masks", "=", "torch", ".", "cat", "(", "[", "agent", ".", "rollouts", ".", "masks", "[", "-", "1", "]", "for", "agent", "in", "team", "]", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "next_value", "=", "policy", ".", "get_value", "(", "last_obs", ",", "last_hidden", ",", "last_masks", ")", "\n", "\n", "", "all_value", "=", "torch", ".", "chunk", "(", "next_value", ",", "len", "(", "team", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "team", ")", ")", ":", "\n", "                ", "team", "[", "i", "]", ".", "wrap_horizon", "(", "all_value", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.after_update": [[140, 143], ["agent.after_update"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.after_update"], ["", "", "", "def", "after_update", "(", "self", ")", ":", "\n", "        ", "for", "agent", "in", "self", ".", "all_agents", ":", "\n", "            ", "agent", ".", "after_update", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.update_rollout": [[144, 149], ["torch.from_numpy().float().to", "enumerate", "agent.update_rollout", "torch.from_numpy().float", "reward[].unsqueeze", "masks[].unsqueeze", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.update_rollout"], ["", "", "def", "update_rollout", "(", "self", ",", "obs", ",", "reward", ",", "masks", ")", ":", "\n", "        ", "obs_t", "=", "torch", ".", "from_numpy", "(", "obs", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "all_agents", ")", ":", "\n", "            ", "agent_obs", "=", "obs_t", "[", ":", ",", "i", ",", ":", "]", "\n", "agent", ".", "update_rollout", "(", "agent_obs", ",", "reward", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ",", "masks", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.load_models": [[150, 153], ["zip", "agent.load_model"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.rlagent.Neo.load_model"], ["", "", "def", "load_models", "(", "self", ",", "policies_list", ")", ":", "\n", "        ", "for", "agent", ",", "policy", "in", "zip", "(", "self", ".", "all_agents", ",", "policies_list", ")", ":", "\n", "            ", "agent", ".", "load_model", "(", "policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.eval_act": [[154, 177], ["range", "zip", "numpy.hstack", "len", "len", "all_obs.append", "len", "all_obs.append", "hasattr", "obs1.append", "obs2.append", "len", "policy.act", "actions.append", "torch.as_tensor().view", "torch.as_tensor().view", "torch.cat().to", "action.squeeze().cpu().numpy", "torch.as_tensor", "torch.as_tensor", "torch.cat", "action.squeeze().cpu", "action.squeeze"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.act", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to"], ["", "", "def", "eval_act", "(", "self", ",", "obs", ",", "recurrent_hidden_states", ",", "mask", ")", ":", "\n", "# used only while evaluating policies. Assuming that agents are in order of team!", "\n", "        ", "obs1", "=", "[", "]", "\n", "obs2", "=", "[", "]", "\n", "all_obs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "obs", ")", ")", ":", "\n", "            ", "agent", "=", "self", ".", "env", ".", "world", ".", "policy_agents", "[", "i", "]", "\n", "if", "hasattr", "(", "agent", ",", "'adversary'", ")", "and", "agent", ".", "adversary", ":", "\n", "                ", "obs1", ".", "append", "(", "torch", ".", "as_tensor", "(", "obs", "[", "i", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "obs2", ".", "append", "(", "torch", ".", "as_tensor", "(", "obs", "[", "i", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "", "", "if", "len", "(", "obs1", ")", "!=", "0", ":", "\n", "            ", "all_obs", ".", "append", "(", "obs1", ")", "\n", "", "if", "len", "(", "obs2", ")", "!=", "0", ":", "\n", "            ", "all_obs", ".", "append", "(", "obs2", ")", "\n", "\n", "", "actions", "=", "[", "]", "\n", "for", "team", ",", "policy", ",", "obs", "in", "zip", "(", "self", ".", "teams_list", ",", "self", ".", "policies_list", ",", "all_obs", ")", ":", "\n", "            ", "if", "len", "(", "obs", ")", "!=", "0", ":", "\n", "                ", "_", ",", "action", ",", "_", ",", "_", "=", "policy", ".", "act", "(", "torch", ".", "cat", "(", "obs", ")", ".", "to", "(", "self", ".", "device", ")", ",", "None", ",", "None", ",", "deterministic", "=", "True", ")", "\n", "actions", ".", "append", "(", "action", ".", "squeeze", "(", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "return", "np", ".", "hstack", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.set_eval_mode": [[178, 181], ["agent.actor_critic.eval"], "methods", ["None"], ["", "def", "set_eval_mode", "(", "self", ")", ":", "\n", "        ", "for", "agent", "in", "self", ".", "all_agents", ":", "\n", "            ", "agent", ".", "actor_critic", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.set_train_mode": [[182, 185], ["agent.actor_critic.train"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.main.train"], ["", "", "def", "set_train_mode", "(", "self", ")", ":", "\n", "        ", "for", "agent", "in", "self", ".", "all_agents", ":", "\n", "            ", "agent", ".", "actor_critic", ".", "train", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.setup_master": [[9, 67], ["enumerate", "enumerate", "learner.Learner", "utils.make_multiagent_env", "print", "learner.Learner.load_models", "hasattr", "hasattr", "team1.append", "team2.append", "NotImplementedError", "mpnn.MPNN().to", "rlagent.Neo", "mpnn.MPNN().to", "rlagent.Neo", "torch.load", "mpnn.MPNN", "mpnn.MPNN"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.make_multiagent_env", "home.repos.pwc.inspect_result.sumitsk_matrl.None.learner.Learner.load_models", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.__init__.load"], ["def", "setup_master", "(", "args", ",", "env", "=", "None", ",", "return_env", "=", "False", ")", ":", "\n", "    ", "if", "env", "is", "None", ":", "\n", "        ", "env", "=", "make_multiagent_env", "(", "args", ".", "env_name", ",", "num_agents", "=", "args", ".", "num_agents", ",", "dist_threshold", "=", "args", ".", "dist_threshold", ",", "\n", "arena_size", "=", "args", ".", "arena_size", ",", "identity_size", "=", "args", ".", "identity_size", ")", "\n", "", "policy1", "=", "None", "\n", "policy2", "=", "None", "\n", "team1", "=", "[", "]", "\n", "team2", "=", "[", "]", "\n", "\n", "num_adversary", "=", "0", "\n", "num_friendly", "=", "0", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "env", ".", "world", ".", "policy_agents", ")", ":", "\n", "        ", "if", "hasattr", "(", "agent", ",", "'adversary'", ")", "and", "agent", ".", "adversary", ":", "\n", "            ", "num_adversary", "+=", "1", "\n", "", "else", ":", "\n", "            ", "num_friendly", "+=", "1", "\n", "\n", "# share a common policy in a team", "\n", "", "", "action_space", "=", "env", ".", "action_space", "[", "i", "]", "\n", "entity_mp", "=", "args", ".", "entity_mp", "\n", "if", "args", ".", "env_name", "==", "'simple_spread'", ":", "\n", "        ", "num_entities", "=", "args", ".", "num_agents", "\n", "", "elif", "args", ".", "env_name", "==", "'simple_formation'", ":", "\n", "        ", "num_entities", "=", "1", "\n", "", "elif", "args", ".", "env_name", "==", "'simple_line'", ":", "\n", "        ", "num_entities", "=", "2", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Unknown environment, define entity_mp for this!'", ")", "\n", "\n", "", "if", "entity_mp", ":", "\n", "        ", "pol_obs_dim", "=", "env", ".", "observation_space", "[", "i", "]", ".", "shape", "[", "0", "]", "-", "2", "*", "num_entities", "\n", "", "else", ":", "\n", "        ", "pol_obs_dim", "=", "env", ".", "observation_space", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# index at which agent's position is present in its observation", "\n", "", "pos_index", "=", "args", ".", "identity_size", "+", "2", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "env", ".", "world", ".", "policy_agents", ")", ":", "\n", "        ", "obs_dim", "=", "env", ".", "observation_space", "[", "i", "]", ".", "shape", "[", "0", "]", "\n", "\n", "if", "hasattr", "(", "agent", ",", "'adversary'", ")", "and", "agent", ".", "adversary", ":", "\n", "            ", "if", "policy1", "is", "None", ":", "\n", "                ", "policy1", "=", "MPNN", "(", "input_size", "=", "pol_obs_dim", ",", "num_agents", "=", "num_adversary", ",", "num_entities", "=", "num_entities", ",", "action_space", "=", "action_space", ",", "\n", "pos_index", "=", "pos_index", ",", "mask_dist", "=", "args", ".", "mask_dist", ",", "entity_mp", "=", "entity_mp", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "", "team1", ".", "append", "(", "Neo", "(", "args", ",", "policy1", ",", "(", "obs_dim", ",", ")", ",", "action_space", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "policy2", "is", "None", ":", "\n", "                ", "policy2", "=", "MPNN", "(", "input_size", "=", "pol_obs_dim", ",", "num_agents", "=", "num_friendly", ",", "num_entities", "=", "num_entities", ",", "action_space", "=", "action_space", ",", "\n", "pos_index", "=", "pos_index", ",", "mask_dist", "=", "args", ".", "mask_dist", ",", "entity_mp", "=", "entity_mp", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "", "team2", ".", "append", "(", "Neo", "(", "args", ",", "policy2", ",", "(", "obs_dim", ",", ")", ",", "action_space", ")", ")", "\n", "", "", "master", "=", "Learner", "(", "args", ",", "[", "team1", ",", "team2", "]", ",", "[", "policy1", ",", "policy2", "]", ",", "env", ")", "\n", "\n", "if", "args", ".", "continue_training", ":", "\n", "        ", "print", "(", "\"Loading pretrained model\"", ")", "\n", "master", ".", "load_models", "(", "torch", ".", "load", "(", "args", ".", "load_dir", ")", "[", "'models'", "]", ")", "\n", "\n", "", "if", "return_env", ":", "\n", "        ", "return", "master", ",", "env", "\n", "", "return", "master", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.mape.make_env.make_env": [[15, 45], ["scenarios.load().Scenario", "scenarios.load().Scenario.make_world", "MultiAgentEnv", "MultiAgentEnv", "scenarios.load"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.make_world", "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.__init__.load"], ["def", "make_env", "(", "scenario_name", ",", "benchmark", "=", "False", ")", ":", "\n", "    ", "'''\n    Creates a MultiAgentEnv object as env. This can be used similar to a gym\n    environment by calling env.reset() and env.step().\n    Use env.render() to view the environment on the screen.\n\n    Input:\n        scenario_name   :   name of the scenario from ./scenarios/ to be Returns\n                            (without the .py extension)\n        benchmark       :   whether you want to produce benchmarking data\n                            (usually only done during evaluation)\n\n    Some useful env properties (see environment.py):\n        .observation_space  :   Returns the observation space for each agent\n        .action_space       :   Returns the action space for each agent\n        .n                  :   Returns the number of Agents\n    '''", "\n", "from", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "import", "multiagent", ".", "scenarios", "as", "scenarios", "\n", "\n", "# load scenario from script", "\n", "scenario", "=", "scenarios", ".", "load", "(", "scenario_name", "+", "\".py\"", ")", ".", "Scenario", "(", ")", "\n", "# create world", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "if", "benchmark", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ",", "scenario", ".", "benchmark_data", ",", "done_callback", "=", "scenario", ".", "done", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ",", "done_callback", "=", "scenario", ".", "done", ")", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.EntityState.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical position", "\n", "        ", "self", ".", "p_pos", "=", "None", "\n", "# physical velocity", "\n", "self", ".", "p_vel", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.AgentState.__init__": [[13, 17], ["core.EntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# communication utterance", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.Action.__init__": [[20, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical action", "\n", "        ", "self", ".", "u", "=", "None", "\n", "# communication action", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.Entity.__init__": [[28, 48], ["core.EntityState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# name ", "\n", "        ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# entity collides with others", "\n", "self", ".", "collide", "=", "True", "\n", "# material density (affects mass)", "\n", "self", ".", "density", "=", "25.0", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# max speed and accel", "\n", "self", ".", "max_speed", "=", "None", "\n", "self", ".", "accel", "=", "None", "\n", "# state", "\n", "self", ".", "state", "=", "EntityState", "(", ")", "\n", "# mass", "\n", "self", ".", "initial_mass", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.Entity.mass": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mass", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "initial_mass", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.Landmark.__init__": [[55, 58], ["core.Entity.__init__"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["     ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Landmark", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "0.05", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.Agent.__init__": [[61, 83], ["core.Entity.__init__", "core.AgentState", "core.Action"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "iden", "=", "None", ")", ":", "\n", "        ", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "True", "\n", "# cannot send communication signals", "\n", "self", ".", "silent", "=", "False", "\n", "# cannot observe the world", "\n", "self", ".", "blind", "=", "False", "\n", "# physical motor noise amount", "\n", "self", ".", "u_noise", "=", "None", "\n", "# communication noise amount", "\n", "self", ".", "c_noise", "=", "None", "\n", "# control range", "\n", "self", ".", "u_range", "=", "1.0", "\n", "# state", "\n", "self", ".", "state", "=", "AgentState", "(", ")", "\n", "# action", "\n", "self", ".", "action", "=", "Action", "(", ")", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "if", "iden", "is", "not", "None", ":", "\n", "            ", "self", ".", "iden", "=", "iden", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.__init__": [[86, 106], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "        ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "landmarks", "=", "[", "]", "\n", "# communication channel dimensionality", "\n", "self", ".", "dim_c", "=", "0", "\n", "# position dimensionality", "\n", "self", ".", "dim_p", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# simulation timestep", "\n", "self", ".", "dt", "=", "0.1", "\n", "# physical damping", "\n", "self", ".", "damping", "=", "0.25", "\n", "# contact response parameters", "\n", "self", ".", "contact_force", "=", "1e+2", "\n", "self", ".", "contact_margin", "=", "1e-3", "\n", "# number of steps that have been taken", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "max_steps_episode", "=", "50", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.entities": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "agents", "+", "self", ".", "landmarks", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.policy_agents": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.scripted_agents": [[118, 121], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.step": [[123, 139], ["core.World.apply_action_force", "core.World.apply_environment_force", "core.World.integrate_state", "agent.action_callback", "len", "core.World.update_agent_state"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.apply_action_force", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.apply_environment_force", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.integrate_state", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.update_agent_state"], ["", "def", "step", "(", "self", ")", ":", "\n", "# set actions for scripted agents ", "\n", "        ", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "            ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "# gather forces applied to entities", "\n", "", "p_force", "=", "[", "None", "]", "*", "len", "(", "self", ".", "entities", ")", "\n", "# apply agent physical controls", "\n", "p_force", "=", "self", ".", "apply_action_force", "(", "p_force", ")", "\n", "# apply environment forces", "\n", "p_force", "=", "self", ".", "apply_environment_force", "(", "p_force", ")", "\n", "# integrate physical state", "\n", "self", ".", "integrate_state", "(", "p_force", ")", "\n", "# update agent state", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "", "self", ".", "steps", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.apply_action_force": [[141, 148], ["enumerate", "numpy.random.randn"], "methods", ["None"], ["", "def", "apply_action_force", "(", "self", ",", "p_force", ")", ":", "\n", "# set applied forces", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "if", "agent", ".", "movable", ":", "\n", "                ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "u", ".", "shape", ")", "*", "agent", ".", "u_noise", "if", "agent", ".", "u_noise", "else", "0.0", "\n", "p_force", "[", "i", "]", "=", "agent", ".", "action", ".", "u", "+", "noise", "\n", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.apply_environment_force": [[150, 163], ["enumerate", "enumerate", "core.World.get_collision_force"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.get_collision_force"], ["", "def", "apply_environment_force", "(", "self", ",", "p_force", ")", ":", "\n", "# simple (but inefficient) collision response", "\n", "        ", "for", "a", ",", "entity_a", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "for", "b", ",", "entity_b", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "                ", "if", "(", "b", "<=", "a", ")", ":", "continue", "\n", "[", "f_a", ",", "f_b", "]", "=", "self", ".", "get_collision_force", "(", "entity_a", ",", "entity_b", ")", "\n", "if", "(", "f_a", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "a", "]", "is", "None", ")", ":", "p_force", "[", "a", "]", "=", "0.0", "\n", "p_force", "[", "a", "]", "=", "f_a", "+", "p_force", "[", "a", "]", "\n", "", "if", "(", "f_b", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "b", "]", "is", "None", ")", ":", "p_force", "[", "b", "]", "=", "0.0", "\n", "p_force", "[", "b", "]", "=", "f_b", "+", "p_force", "[", "b", "]", "\n", "", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.integrate_state": [[165, 177], ["enumerate", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.sqrt", "numpy.square", "numpy.square"], "methods", ["None"], ["", "def", "integrate_state", "(", "self", ",", "p_force", ")", ":", "\n", "        ", "for", "i", ",", "entity", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "if", "not", "entity", ".", "movable", ":", "continue", "\n", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "*", "(", "1", "-", "self", ".", "damping", ")", "\n", "if", "(", "p_force", "[", "i", "]", "is", "not", "None", ")", ":", "\n", "                ", "entity", ".", "state", ".", "p_vel", "+=", "(", "p_force", "[", "i", "]", "/", "entity", ".", "mass", ")", "*", "self", ".", "dt", "\n", "", "if", "entity", ".", "max_speed", "is", "not", "None", ":", "\n", "                ", "speed", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "\n", "if", "speed", ">", "entity", ".", "max_speed", ":", "\n", "                    ", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "\n", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "*", "entity", ".", "max_speed", "\n", "", "", "entity", ".", "state", ".", "p_pos", "+=", "entity", ".", "state", ".", "p_vel", "*", "self", ".", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.update_agent_state": [[178, 185], ["numpy.zeros", "numpy.random.randn"], "methods", ["None"], ["", "", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "# set communication state (directly for now)", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "c", ".", "shape", ")", "*", "agent", ".", "c_noise", "if", "agent", ".", "c_noise", "else", "0.0", "\n", "agent", ".", "state", ".", "c", "=", "agent", ".", "action", ".", "c", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.core.World.get_collision_force": [[187, 204], ["numpy.sqrt", "numpy.sum", "numpy.logaddexp", "numpy.square"], "methods", ["None"], ["", "", "def", "get_collision_force", "(", "self", ",", "entity_a", ",", "entity_b", ")", ":", "\n", "        ", "if", "(", "not", "entity_a", ".", "collide", ")", "or", "(", "not", "entity_b", ".", "collide", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# not a collider", "\n", "", "if", "(", "entity_a", "is", "entity_b", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# don't collide against itself", "\n", "# compute actual distance between entities", "\n", "", "delta_pos", "=", "entity_a", ".", "state", ".", "p_pos", "-", "entity_b", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "# minimum allowable distance", "\n", "dist_min", "=", "entity_a", ".", "size", "+", "entity_b", ".", "size", "\n", "# softmax penetration", "\n", "k", "=", "self", ".", "contact_margin", "\n", "penetration", "=", "np", ".", "logaddexp", "(", "0", ",", "-", "(", "dist", "-", "dist_min", ")", "/", "k", ")", "*", "k", "\n", "force", "=", "self", ".", "contact_force", "*", "delta_pos", "/", "dist", "*", "penetration", "\n", "force_a", "=", "+", "force", "if", "entity_a", ".", "movable", "else", "None", "\n", "force_b", "=", "-", "force", "if", "entity_b", ".", "movable", "else", "None", "\n", "return", "[", "force_a", ",", "force_b", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.__init__": [[46, 65], ["rendering.get_display", "pyglet.window.Window", "rendering.Transform", "glEnable", "glEnable", "glHint", "glLineWidth", "glBlendFunc"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.get_display"], ["    ", "def", "__init__", "(", "self", ",", "width", ",", "height", ",", "display", "=", "None", ")", ":", "\n", "        ", "display", "=", "get_display", "(", "display", ")", "\n", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "display", ")", "\n", "self", ".", "window", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "geoms", "=", "[", "]", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "self", ".", "transform", "=", "Transform", "(", ")", "\n", "\n", "glEnable", "(", "GL_BLEND", ")", "\n", "# glEnable(GL_MULTISAMPLE)", "\n", "glEnable", "(", "GL_LINE_SMOOTH", ")", "\n", "# glHint(GL_LINE_SMOOTH_HINT, GL_DONT_CARE)", "\n", "glHint", "(", "GL_LINE_SMOOTH_HINT", ",", "GL_NICEST", ")", "\n", "glLineWidth", "(", "2.0", ")", "\n", "glBlendFunc", "(", "GL_SRC_ALPHA", ",", "GL_ONE_MINUS_SRC_ALPHA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.close": [[66, 68], ["rendering.Viewer.window.close"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.window_closed_by_user": [[69, 71], ["rendering.Viewer.close"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "window_closed_by_user", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.set_bounds": [[72, 79], ["rendering.Transform"], "methods", ["None"], ["", "def", "set_bounds", "(", "self", ",", "left", ",", "right", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "assert", "right", ">", "left", "and", "top", ">", "bottom", "\n", "scalex", "=", "self", ".", "width", "/", "(", "right", "-", "left", ")", "\n", "scaley", "=", "self", ".", "height", "/", "(", "top", "-", "bottom", ")", "\n", "self", ".", "transform", "=", "Transform", "(", "\n", "translation", "=", "(", "-", "left", "*", "scalex", ",", "-", "bottom", "*", "scaley", ")", ",", "\n", "scale", "=", "(", "scalex", ",", "scaley", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_geom": [[80, 82], ["rendering.Viewer.geoms.append"], "methods", ["None"], ["", "def", "add_geom", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_onetime": [[83, 85], ["rendering.Viewer.onetime_geoms.append"], "methods", ["None"], ["", "def", "add_onetime", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "onetime_geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.render": [[86, 113], ["glClearColor", "rendering.Viewer.window.clear", "rendering.Viewer.window.switch_to", "rendering.Viewer.window.dispatch_events", "rendering.Viewer.transform.enable", "rendering.Viewer.transform.disable", "rendering.Viewer.window.flip", "geom.render", "geom.render", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineStyle.disable", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "render", "(", "self", ",", "return_rgb_array", "=", "False", ")", ":", "\n", "        ", "glClearColor", "(", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "self", ".", "transform", ".", "enable", "(", ")", "\n", "for", "geom", "in", "self", ".", "geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "for", "geom", "in", "self", ".", "onetime_geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "self", ".", "transform", ".", "disable", "(", ")", "\n", "arr", "=", "None", "\n", "if", "return_rgb_array", ":", "\n", "            ", "buffer", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", "\n", "image_data", "=", "buffer", ".", "get_image_data", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "# In https://github.com/openai/gym-http-api/issues/2, we", "\n", "# discovered that someone using Xmonad on Arch was having", "\n", "# a window of size 598 x 398, though a 600 x 400 window", "\n", "# was requested. (Guess Xmonad was preserving a pixel for", "\n", "# the boundary.) So we use the buffer height/width rather", "\n", "# than the requested one.", "\n", "arr", "=", "arr", ".", "reshape", "(", "buffer", ".", "height", ",", "buffer", ".", "width", ",", "4", ")", "\n", "arr", "=", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "", "self", ".", "window", ".", "flip", "(", ")", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.draw_circle": [[115, 120], ["rendering.make_circle", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_circle", "(", "self", ",", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_circle", "(", "radius", "=", "radius", ",", "res", "=", "res", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.draw_polygon": [[121, 126], ["rendering.make_polygon", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polygon", "(", "self", ",", "v", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polygon", "(", "v", "=", "v", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.draw_polyline": [[127, 132], ["rendering.make_polyline", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_polyline", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polyline", "(", "self", ",", "v", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polyline", "(", "v", "=", "v", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.draw_line": [[133, 138], ["rendering.Line", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_line", "(", "self", ",", "start", ",", "end", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "Line", "(", "start", ",", "end", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.get_array": [[139, 146], ["rendering.Viewer.window.flip", "pyglet.image.get_buffer_manager().get_color_buffer().get_image_data", "rendering.Viewer.window.flip", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager"], "methods", ["None"], ["", "def", "get_array", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "flip", "(", ")", "\n", "image_data", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", ".", "get_image_data", "(", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "arr", "=", "arr", ".", "reshape", "(", "self", ".", "height", ",", "self", ".", "width", ",", "4", ")", "\n", "return", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.__init__": [[154, 157], ["rendering.Color"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_color", "=", "Color", "(", "(", "0", ",", "0", ",", "0", ",", "1.0", ")", ")", "\n", "self", ".", "attrs", "=", "[", "self", ".", "_color", "]", "\n", "", "def", "render", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.render": [[157, 163], ["reversed", "rendering.Geom.render1", "attr.enable", "attr.disable"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Image.render1", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineStyle.disable"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "for", "attr", "in", "reversed", "(", "self", ".", "attrs", ")", ":", "\n", "            ", "attr", ".", "enable", "(", ")", "\n", "", "self", ".", "render1", "(", ")", "\n", "for", "attr", "in", "self", ".", "attrs", ":", "\n", "            ", "attr", ".", "disable", "(", ")", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.render1": [[163, 165], ["None"], "methods", ["None"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.add_attr": [[165, 167], ["rendering.Geom.attrs.append"], "methods", ["None"], ["", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n", "        ", "self", ".", "attrs", ".", "append", "(", "attr", ")", "\n", "", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color": [[167, 169], ["None"], "methods", ["None"], ["", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n", "        ", "self", ".", "_color", ".", "vec4", "=", "(", "r", ",", "g", ",", "b", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Attr.enable": [[171, 173], ["None"], "methods", ["None"], ["    ", "def", "enable", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Attr.disable": [[173, 175], ["None"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.__init__": [[177, 181], ["rendering.Transform.set_translation", "rendering.Transform.set_rotation", "rendering.Transform.set_scale"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_rotation", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_scale"], ["    ", "def", "__init__", "(", "self", ",", "translation", "=", "(", "0.0", ",", "0.0", ")", ",", "rotation", "=", "0.0", ",", "scale", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "        ", "self", ".", "set_translation", "(", "*", "translation", ")", "\n", "self", ".", "set_rotation", "(", "rotation", ")", "\n", "self", ".", "set_scale", "(", "*", "scale", ")", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.enable": [[181, 186], ["glPushMatrix", "glTranslatef", "glRotatef", "glScalef"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glPushMatrix", "(", ")", "\n", "glTranslatef", "(", "self", ".", "translation", "[", "0", "]", ",", "self", ".", "translation", "[", "1", "]", ",", "0", ")", "# translate to GL loc ppint", "\n", "glRotatef", "(", "RAD2DEG", "*", "self", ".", "rotation", ",", "0", ",", "0", ",", "1.0", ")", "\n", "glScalef", "(", "self", ".", "scale", "[", "0", "]", ",", "self", ".", "scale", "[", "1", "]", ",", "1", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.disable": [[186, 188], ["glPopMatrix"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glPopMatrix", "(", ")", "\n", "", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_translation": [[188, 190], ["float", "float"], "methods", ["None"], ["", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "translation", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_rotation": [[190, 192], ["float"], "methods", ["None"], ["", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n", "        ", "self", ".", "rotation", "=", "float", "(", "new", ")", "\n", "", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_scale": [[192, 194], ["float", "float"], "methods", ["None"], ["", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "scale", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Color.__init__": [[196, 198], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vec4", ")", ":", "\n", "        ", "self", ".", "vec4", "=", "vec4", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Color.enable": [[198, 200], ["glColor4f"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glColor4f", "(", "*", "self", ".", "vec4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineStyle.__init__": [[202, 204], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "style", ")", ":", "\n", "        ", "self", ".", "style", "=", "style", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineStyle.enable": [[204, 207], ["glEnable", "glLineStipple"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glEnable", "(", "GL_LINE_STIPPLE", ")", "\n", "glLineStipple", "(", "1", ",", "self", ".", "style", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineStyle.disable": [[207, 209], ["glDisable"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glDisable", "(", "GL_LINE_STIPPLE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineWidth.__init__": [[211, 213], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "stroke", ")", ":", "\n", "        ", "self", ".", "stroke", "=", "stroke", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.LineWidth.enable": [[213, 215], ["glLineWidth"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glLineWidth", "(", "self", ".", "stroke", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Point.__init__": [[217, 219], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Point.render1": [[219, 223], ["glBegin", "glVertex3f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_POINTS", ")", "# draw point", "\n", "glVertex3f", "(", "0.0", ",", "0.0", ",", "0.0", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.FilledPolygon.__init__": [[225, 228], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "v", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.FilledPolygon.render1": [[228, 242], ["glEnd", "glColor4f", "glBegin", "glEnd", "len", "glBegin", "glVertex3f", "glVertex3f", "len", "glBegin", "glBegin"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "v", ")", "==", "4", ":", "glBegin", "(", "GL_QUADS", ")", "\n", "elif", "len", "(", "self", ".", "v", ")", ">", "4", ":", "glBegin", "(", "GL_POLYGON", ")", "\n", "else", ":", "glBegin", "(", "GL_TRIANGLES", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n", "color", "=", "(", "self", ".", "_color", ".", "vec4", "[", "0", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "1", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "2", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "3", "]", "*", "0.5", ")", "\n", "glColor4f", "(", "*", "color", ")", "\n", "glBegin", "(", "GL_LINE_LOOP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Compound.__init__": [[270, 275], ["rendering.Geom.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gs", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "gs", "=", "gs", "\n", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "attrs", "=", "[", "a", "for", "a", "in", "g", ".", "attrs", "if", "not", "isinstance", "(", "a", ",", "Color", ")", "]", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Compound.render1": [[275, 278], ["g.render"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.PolyLine.__init__": [[280, 286], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.PolyLine.add_attr"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "v", ",", "close", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "close", "=", "close", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "1", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.PolyLine.render1": [[286, 291], ["glBegin", "glEnd", "glVertex3f"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINE_LOOP", "if", "self", ".", "close", "else", "GL_LINE_STRIP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.PolyLine.set_linewidth": [[291, 293], ["None"], "methods", ["None"], ["", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "linewidth", ".", "stroke", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Line.__init__": [[295, 301], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.Line.add_attr"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "(", "0.0", ",", "0.0", ")", ",", "end", "=", "(", "0.0", ",", "0.0", ")", ",", "linewidth", "=", "1", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "linewidth", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Line.set_linewidth": [[302, 304], ["rendering.LineWidth"], "methods", ["None"], ["", "def", "set_linewidth", "(", "self", ",", "linewidth", ")", ":", "\n", "        ", "self", ".", "linewidth", "=", "LineWidth", "(", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Line.render1": [[305, 310], ["glBegin", "glVertex2f", "glVertex2f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINES", ")", "\n", "glVertex2f", "(", "*", "self", ".", "start", ")", "\n", "glVertex2f", "(", "*", "self", ".", "end", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Image.__init__": [[312, 319], ["rendering.Geom.__init__", "pyglet.image.load"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__", "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.__init__.load"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "width", ",", "height", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "img", "=", "pyglet", ".", "image", ".", "load", "(", "fname", ")", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "flip", "=", "False", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Image.render1": [[319, 321], ["rendering.Image.img.blit"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "self", ".", "img", ".", "blit", "(", "-", "self", ".", "width", "/", "2", ",", "-", "self", ".", "height", "/", "2", ",", "width", "=", "self", ".", "width", ",", "height", "=", "self", ".", "height", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.__init__": [[325, 329], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "display", "=", "None", ")", ":", "\n", "        ", "self", ".", "window", "=", "None", "\n", "self", ".", "isopen", "=", "False", "\n", "self", ".", "display", "=", "display", "\n", "", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.imshow": [[329, 343], ["pyglet.image.ImageData", "rendering.SimpleImageViewer.window.clear", "rendering.SimpleImageViewer.window.switch_to", "rendering.SimpleImageViewer.window.dispatch_events", "pyglet.image.ImageData.blit", "rendering.SimpleImageViewer.window.flip", "pyglet.window.Window", "arr.tobytes"], "methods", ["None"], ["", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n", "        ", "if", "self", ".", "window", "is", "None", ":", "\n", "            ", "height", ",", "width", ",", "channels", "=", "arr", ".", "shape", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "self", ".", "display", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "isopen", "=", "True", "\n", "", "assert", "arr", ".", "shape", "==", "(", "self", ".", "height", ",", "self", ".", "width", ",", "3", ")", ",", "\"You passed in an image with the wrong number shape\"", "\n", "image", "=", "pyglet", ".", "image", ".", "ImageData", "(", "self", ".", "width", ",", "self", ".", "height", ",", "'RGB'", ",", "arr", ".", "tobytes", "(", ")", ",", "pitch", "=", "self", ".", "width", "*", "-", "3", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "image", ".", "blit", "(", "0", ",", "0", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "", "def", "close", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close": [[343, 347], ["rendering.SimpleImageViewer.window.close"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "isopen", ":", "\n", "            ", "self", ".", "window", ".", "close", "(", ")", "\n", "self", ".", "isopen", "=", "False", "\n", "", "", "def", "__del__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.__del__": [[347, 349], ["rendering.SimpleImageViewer.close"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.SimpleImageViewer.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.get_display": [[32, 44], ["isinstance", "pyglet.canvas.Display", "gym.error.Error"], "function", ["None"], ["def", "get_display", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Convert a display specification (such as :0) into an actual Display\n    object.\n\n    Pyglet only supports multiple Displays on Linux.\n    \"\"\"", "\n", "if", "spec", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "isinstance", "(", "spec", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "return", "pyglet", ".", "canvas", ".", "Display", "(", "spec", ")", "\n", "", "else", ":", "\n", "        ", "raise", "error", ".", "Error", "(", "'Invalid display specification: {}. (Must be a string like :0 or None.)'", ".", "format", "(", "spec", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering._add_attrs": [[147, 152], ["geom.set_color", "geom.set_linewidth"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Line.set_linewidth"], ["", "", "def", "_add_attrs", "(", "geom", ",", "attrs", ")", ":", "\n", "    ", "if", "\"color\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_color", "(", "*", "attrs", "[", "\"color\"", "]", ")", "\n", "", "if", "\"linewidth\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_linewidth", "(", "attrs", "[", "\"linewidth\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_circle": [[243, 252], ["range", "points.append", "rendering.FilledPolygon", "rendering.PolyLine", "math.cos", "math.sin"], "function", ["None"], ["", "", "def", "make_circle", "(", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ")", ":", "\n", "    ", "points", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "res", ")", ":", "\n", "        ", "ang", "=", "2", "*", "math", ".", "pi", "*", "i", "/", "res", "\n", "points", ".", "append", "(", "(", "math", ".", "cos", "(", "ang", ")", "*", "radius", ",", "math", ".", "sin", "(", "ang", ")", "*", "radius", ")", ")", "\n", "", "if", "filled", ":", "\n", "        ", "return", "FilledPolygon", "(", "points", ")", "\n", "", "else", ":", "\n", "        ", "return", "PolyLine", "(", "points", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_polygon": [[253, 256], ["rendering.FilledPolygon", "rendering.PolyLine"], "function", ["None"], ["", "", "def", "make_polygon", "(", "v", ",", "filled", "=", "True", ")", ":", "\n", "    ", "if", "filled", ":", "return", "FilledPolygon", "(", "v", ")", "\n", "else", ":", "return", "PolyLine", "(", "v", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_polyline": [[257, 259], ["rendering.PolyLine"], "function", ["None"], ["", "def", "make_polyline", "(", "v", ")", ":", "\n", "    ", "return", "PolyLine", "(", "v", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_capsule": [[260, 268], ["rendering.make_polygon", "rendering.make_circle", "rendering.make_circle", "make_circle.add_attr", "rendering.Compound", "rendering.Transform"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.add_attr"], ["", "def", "make_capsule", "(", "length", ",", "width", ")", ":", "\n", "    ", "l", ",", "r", ",", "t", ",", "b", "=", "0", ",", "length", ",", "width", "/", "2", ",", "-", "width", "/", "2", "\n", "box", "=", "make_polygon", "(", "[", "(", "l", ",", "b", ")", ",", "(", "l", ",", "t", ")", ",", "(", "r", ",", "t", ")", ",", "(", "r", ",", "b", ")", "]", ")", "\n", "circ0", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", ".", "add_attr", "(", "Transform", "(", "translation", "=", "(", "length", ",", "0", ")", ")", ")", "\n", "geom", "=", "Compound", "(", "[", "box", ",", "circ0", ",", "circ1", "]", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.__init__": [[25, 29], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "array_of_param_array", ")", ":", "\n", "        ", "self", ".", "low", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "high", "=", "np", ".", "array", "(", "[", "x", "[", "1", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "num_discrete_space", "=", "self", ".", "low", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.sample": [[30, 35], ["gym.spaces.prng.np_random.rand", "int", "numpy.floor", "numpy.multiply"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a array with one sample from each discrete action space \"\"\"", "\n", "# For each row: round(random .* (max - min) + min, 0)", "\n", "random_array", "=", "prng", ".", "np_random", ".", "rand", "(", "self", ".", "num_discrete_space", ")", "\n", "return", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "floor", "(", "np", ".", "multiply", "(", "(", "self", ".", "high", "-", "self", ".", "low", "+", "1.", ")", ",", "random_array", ")", "+", "self", ".", "low", ")", "]", "\n", "", "def", "contains", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.contains": [[35, 37], ["len", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "len", "(", "x", ")", "==", "self", ".", "num_discrete_space", "and", "(", "np", ".", "array", "(", "x", ")", ">=", "self", ".", "low", ")", ".", "all", "(", ")", "and", "(", "np", ".", "array", "(", "x", ")", "<=", "self", ".", "high", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.shape": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_discrete_space", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.__repr__": [[41, 43], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"MultiDiscrete\"", "+", "str", "(", "self", ".", "num_discrete_space", ")", "\n", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.multi_discrete.MultiDiscrete.__eq__": [[43, 45], ["numpy.array_equal", "numpy.array_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "np", ".", "array_equal", "(", "self", ".", "low", ",", "other", ".", "low", ")", "and", "np", ".", "array_equal", "(", "self", ".", "high", ",", "other", ".", "high", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.Policy.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "action", "(", "self", ",", "obs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.Policy.action": [[8, 10], ["NotImplementedError"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.InteractivePolicy.__init__": [[14, 23], ["policy.Policy.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "agent_index", ")", ":", "\n", "        ", "super", "(", "InteractivePolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "env", "=", "env", "\n", "# hard-coded keyboard events", "\n", "self", ".", "move", "=", "[", "False", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "self", ".", "comm", "=", "[", "False", "for", "i", "in", "range", "(", "env", ".", "world", ".", "dim_c", ")", "]", "\n", "# register keyboard events with this environment's window", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_press", "=", "self", ".", "key_press", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_release", "=", "self", ".", "key_release", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.InteractivePolicy.action": [[24, 41], ["numpy.concatenate", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "# ignore observation and just act based on keyboard events", "\n", "        ", "if", "self", ".", "env", ".", "discrete_action_input", ":", "\n", "            ", "u", "=", "0", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "=", "1", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "=", "2", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "=", "4", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "=", "3", "\n", "", "else", ":", "\n", "            ", "u", "=", "np", ".", "zeros", "(", "5", ")", "# 5-d because of no-move action", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "[", "1", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "[", "2", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "[", "3", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "[", "4", "]", "+=", "1.0", "\n", "if", "True", "not", "in", "self", ".", "move", ":", "\n", "                ", "u", "[", "0", "]", "+=", "1.0", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "u", ",", "np", ".", "zeros", "(", "self", ".", "env", ".", "world", ".", "dim_c", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.InteractivePolicy.key_press": [[43, 48], ["None"], "methods", ["None"], ["", "def", "key_press", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "True", "\n", "", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.policy.InteractivePolicy.key_release": [[48, 53], ["None"], "methods", ["None"], ["", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.scenario.BaseScenario.make_world": [[6, 8], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "# create initial conditions of the world", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.scenario.BaseScenario.reset_world": [[9, 11], ["NotImplementedError"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.__init__": [[15, 83], ["len", "environment.MultiAgentEnv.seed", "environment.MultiAgentEnv._reset_render", "hasattr", "hasattr", "len", "environment.MultiAgentEnv.observation_space.append", "numpy.zeros", "gym.spaces.Discrete", "gym.spaces.Box", "total_action_space.append", "gym.spaces.Discrete", "gym.spaces.Box", "total_action_space.append", "len", "all", "environment.MultiAgentEnv.action_space.append", "environment.MultiAgentEnv.action_space.append", "observation_callback", "gym.spaces.Box", "multiagent.multi_discrete.MultiDiscrete", "gym.spaces.Tuple", "isinstance"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.seed", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._reset_render"], ["def", "__init__", "(", "self", ",", "world", ",", "reset_callback", "=", "None", ",", "reward_callback", "=", "None", ",", "\n", "observation_callback", "=", "None", ",", "info_callback", "=", "None", ",", "\n", "done_callback", "=", "None", ",", "discrete_action", "=", "False", ",", "shared_viewer", "=", "True", ",", "\n", "cam_range", "=", "1", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "world", "=", "world", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set required vectorized gym env property", "\n", "self", ".", "n", "=", "len", "(", "world", ".", "policy_agents", ")", "\n", "# scenario callbacks", "\n", "self", ".", "reset_callback", "=", "reset_callback", "\n", "self", ".", "reward_callback", "=", "reward_callback", "\n", "self", ".", "observation_callback", "=", "observation_callback", "\n", "self", ".", "info_callback", "=", "info_callback", "\n", "self", ".", "done_callback", "=", "done_callback", "\n", "# environment parameters", "\n", "self", ".", "discrete_action_space", "=", "True", "\n", "# if true, action is a number 0...N, otherwise action is a one-hot N-dimensional vector", "\n", "self", ".", "discrete_action_input", "=", "discrete_action", "\n", "# if true, even the action is continuous, action will be performed discretely", "\n", "self", ".", "force_discrete_action", "=", "world", ".", "discrete_action", "if", "hasattr", "(", "world", ",", "'discrete_action'", ")", "else", "False", "\n", "# if true, every agent has the same reward", "\n", "self", ".", "shared_reward", "=", "world", ".", "collaborative", "if", "hasattr", "(", "world", ",", "'collaborative'", ")", "else", "False", "\n", "self", ".", "time", "=", "0", "\n", "self", ".", "seed", "(", ")", "\n", "# configure spaces", "\n", "self", ".", "action_space", "=", "[", "]", "\n", "self", ".", "observation_space", "=", "[", "]", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "total_action_space", "=", "[", "]", "\n", "# physical action space", "\n", "if", "self", ".", "discrete_action_space", ":", "\n", "                ", "u_action_space", "=", "spaces", ".", "Discrete", "(", "world", ".", "dim_p", "*", "2", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "u_action_space", "=", "spaces", ".", "Box", "(", "low", "=", "-", "agent", ".", "u_range", ",", "high", "=", "+", "agent", ".", "u_range", ",", "shape", "=", "(", "world", ".", "dim_p", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "if", "agent", ".", "movable", ":", "\n", "                ", "total_action_space", ".", "append", "(", "u_action_space", ")", "\n", "# communication action space", "\n", "", "if", "self", ".", "discrete_action_space", ":", "\n", "                ", "c_action_space", "=", "spaces", ".", "Discrete", "(", "world", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "                ", "c_action_space", "=", "spaces", ".", "Box", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ",", "shape", "=", "(", "world", ".", "dim_c", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "if", "not", "agent", ".", "silent", ":", "\n", "                ", "total_action_space", ".", "append", "(", "c_action_space", ")", "\n", "# total action space", "\n", "", "if", "len", "(", "total_action_space", ")", ">", "1", ":", "\n", "# all action spaces are discrete, so simplify to MultiDiscrete action space", "\n", "                ", "if", "all", "(", "[", "isinstance", "(", "act_space", ",", "spaces", ".", "Discrete", ")", "for", "act_space", "in", "total_action_space", "]", ")", ":", "\n", "                    ", "act_space", "=", "MultiDiscrete", "(", "[", "[", "0", ",", "act_space", ".", "n", "-", "1", "]", "for", "act_space", "in", "total_action_space", "]", ")", "\n", "", "else", ":", "\n", "                    ", "act_space", "=", "spaces", ".", "Tuple", "(", "total_action_space", ")", "\n", "", "self", ".", "action_space", ".", "append", "(", "act_space", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "action_space", ".", "append", "(", "total_action_space", "[", "0", "]", ")", "\n", "# observation space", "\n", "", "obs_dim", "=", "len", "(", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", ")", "\n", "self", ".", "observation_space", ".", "append", "(", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "inf", ",", "high", "=", "+", "np", ".", "inf", ",", "shape", "=", "(", "obs_dim", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "\n", "# rendering", "\n", "", "self", ".", "cam_range", "=", "cam_range", "\n", "self", ".", "shared_viewer", "=", "shared_viewer", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "*", "self", ".", "n", "\n", "", "self", ".", "_reset_render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.episode_limit": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "episode_limit", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "world", ".", "max_steps_episode", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.seed": [[88, 90], ["numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.step": [[91, 113], ["enumerate", "environment.MultiAgentEnv.world.step", "numpy.sum", "environment.MultiAgentEnv._set_action", "obs_n.append", "reward_n.append", "done_n.append", "info_n[].append", "environment.MultiAgentEnv._get_obs", "environment.MultiAgentEnv._get_reward", "environment.MultiAgentEnv._get_done", "environment.MultiAgentEnv._get_info"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._set_action", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_reward", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_done", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_info"], ["", "def", "step", "(", "self", ",", "action_n", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "{", "'n'", ":", "[", "]", "}", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set action for each agent", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "self", ".", "_set_action", "(", "action_n", "[", "i", "]", ",", "agent", ",", "self", ".", "action_space", "[", "i", "]", ")", "\n", "# advance world state", "\n", "", "self", ".", "world", ".", "step", "(", ")", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "reward_n", ".", "append", "(", "self", ".", "_get_reward", "(", "agent", ")", ")", "\n", "done_n", ".", "append", "(", "self", ".", "_get_done", "(", "agent", ")", ")", "\n", "info_n", "[", "'n'", "]", ".", "append", "(", "self", ".", "_get_info", "(", "agent", ")", ")", "\n", "\n", "# all agents get total reward in cooperative case", "\n", "", "reward", "=", "np", ".", "sum", "(", "reward_n", ")", "\n", "if", "self", ".", "shared_reward", ":", "\n", "            ", "reward_n", "=", "[", "reward", "]", "*", "self", ".", "n", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.reset": [[114, 125], ["environment.MultiAgentEnv.reset_callback", "environment.MultiAgentEnv._reset_render", "obs_n.append", "environment.MultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._reset_render", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# reset world", "\n", "        ", "self", ".", "reset_callback", "(", "self", ".", "world", ")", "\n", "# reset renderer", "\n", "self", ".", "_reset_render", "(", ")", "\n", "# record observations for each agent", "\n", "obs_n", "=", "[", "]", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_info": [[127, 131], ["environment.MultiAgentEnv.info_callback"], "methods", ["None"], ["", "def", "_get_info", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "info_callback", "is", "None", ":", "\n", "            ", "return", "{", "}", "\n", "", "return", "self", ".", "info_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_obs": [[133, 137], ["environment.MultiAgentEnv.observation_callback", "numpy.zeros"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "observation_callback", "is", "None", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "0", ")", "\n", "", "return", "self", ".", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_done": [[140, 144], ["environment.MultiAgentEnv.done_callback"], "methods", ["None"], ["", "def", "_get_done", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "done_callback", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "done_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_reward": [[146, 150], ["environment.MultiAgentEnv.reward_callback"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "reward_callback", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "reward_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._set_action": [[152, 201], ["numpy.zeros", "numpy.zeros", "isinstance", "len", "act.append", "numpy.zeros", "numpy.zeros", "numpy.argmax"], "methods", ["None"], ["", "def", "_set_action", "(", "self", ",", "action", ",", "agent", ",", "action_space", ",", "time", "=", "None", ")", ":", "\n", "        ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "# process action", "\n", "if", "isinstance", "(", "action_space", ",", "MultiDiscrete", ")", ":", "\n", "            ", "act", "=", "[", "]", "\n", "size", "=", "action_space", ".", "high", "-", "action_space", ".", "low", "+", "1", "\n", "index", "=", "0", "\n", "for", "s", "in", "size", ":", "\n", "                ", "act", ".", "append", "(", "action", "[", "index", ":", "(", "index", "+", "s", ")", "]", ")", "\n", "index", "+=", "s", "\n", "", "action", "=", "act", "\n", "", "else", ":", "\n", "            ", "action", "=", "[", "action", "]", "\n", "\n", "", "if", "agent", ".", "movable", ":", "\n", "# physical action", "\n", "            ", "if", "self", ".", "discrete_action_input", ":", "\n", "                ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "# process discrete action", "\n", "if", "action", "[", "0", "]", "==", "1", ":", "agent", ".", "action", ".", "u", "[", "0", "]", "=", "-", "1.0", "\n", "if", "action", "[", "0", "]", "==", "2", ":", "agent", ".", "action", ".", "u", "[", "0", "]", "=", "+", "1.0", "\n", "if", "action", "[", "0", "]", "==", "3", ":", "agent", ".", "action", ".", "u", "[", "1", "]", "=", "-", "1.0", "\n", "if", "action", "[", "0", "]", "==", "4", ":", "agent", ".", "action", ".", "u", "[", "1", "]", "=", "+", "1.0", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "force_discrete_action", ":", "\n", "                    ", "d", "=", "np", ".", "argmax", "(", "action", "[", "0", "]", ")", "\n", "action", "[", "0", "]", "[", ":", "]", "=", "0.0", "\n", "action", "[", "0", "]", "[", "d", "]", "=", "1.0", "\n", "", "if", "self", ".", "discrete_action_space", ":", "\n", "                    ", "agent", ".", "action", ".", "u", "[", "0", "]", "+=", "action", "[", "0", "]", "[", "1", "]", "-", "action", "[", "0", "]", "[", "2", "]", "\n", "agent", ".", "action", ".", "u", "[", "1", "]", "+=", "action", "[", "0", "]", "[", "3", "]", "-", "action", "[", "0", "]", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "agent", ".", "action", ".", "u", "=", "action", "[", "0", "]", "\n", "", "", "sensitivity", "=", "5.0", "\n", "if", "agent", ".", "accel", "is", "not", "None", ":", "\n", "                ", "sensitivity", "=", "agent", ".", "accel", "\n", "", "agent", ".", "action", ".", "u", "*=", "sensitivity", "\n", "action", "=", "action", "[", "1", ":", "]", "\n", "", "if", "not", "agent", ".", "silent", ":", "\n", "# communication action", "\n", "            ", "if", "self", ".", "discrete_action_input", ":", "\n", "                ", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "agent", ".", "action", ".", "c", "[", "action", "[", "0", "]", "]", "=", "1.0", "\n", "", "else", ":", "\n", "                ", "agent", ".", "action", ".", "c", "=", "action", "[", "0", "]", "\n", "", "action", "=", "action", "[", "1", ":", "]", "\n", "# make sure we used all elements of action", "\n", "", "assert", "len", "(", "action", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._reset_render": [[203, 206], ["None"], "methods", ["None"], ["", "def", "_reset_render", "(", "self", ")", ":", "\n", "        ", "self", ".", "render_geoms", "=", "None", "\n", "self", ".", "render_geoms_xform", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.render": [[208, 293], ["range", "range", "len", "len", "environment.MultiAgentEnv._add_lines", "len", "environment.MultiAgentEnv.viewers[].set_bounds", "enumerate", "results.append", "rendering.Viewer", "rendering.make_circle", "rendering.Transform", "rendering.Line.add_attr", "environment.MultiAgentEnv.render_geoms.append", "environment.MultiAgentEnv.render_geoms_xform.append", "range", "numpy.zeros", "environment.MultiAgentEnv.render_geoms_xform[].set_translation", "environment.MultiAgentEnv.viewers[].render", "rendering.Line.set_color", "rendering.Line.set_color", "range", "viewer.add_geom", "rendering.Line", "rendering.Line.set_color", "rendering.Transform", "environment.MultiAgentEnv.render_geoms.append", "environment.MultiAgentEnv.render_geoms_xform.append"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._add_lines", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.set_bounds", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.add_attr", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Viewer.add_geom", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "attn", "=", "None", ")", ":", "\n", "# attn: matrix of size (num_agents, num_agents) ", "\n", "\n", "# if mode == 'human':", "\n", "#     alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'", "\n", "#     message = ''", "\n", "#     for agent in self.world.agents:", "\n", "#         for other in self.world.agents:", "\n", "#             if other is agent:", "\n", "#                 continue", "\n", "#             if np.all(other.state.c == 0):", "\n", "#                 word = '_'", "\n", "#             else:", "\n", "#                 word = alphabet[np.argmax(other.state.c)]", "\n", "#             message += (other.name + ' to ' + agent.name + ': ' + word + '   ')", "\n", "#     print(message)", "\n", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "# create viewers (if necessary)", "\n", "            ", "if", "self", ".", "viewers", "[", "i", "]", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "# from gym.envs.classic_control import rendering", "\n", "                ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "viewers", "[", "i", "]", "=", "rendering", ".", "Viewer", "(", "700", ",", "700", ")", "\n", "\n", "# create rendering geometry", "\n", "", "", "if", "self", ".", "render_geoms", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "# from gym.envs.classic_control import rendering", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "render_geoms", "=", "[", "]", "\n", "self", ".", "render_geoms_xform", "=", "[", "]", "\n", "for", "entity", "in", "self", ".", "world", ".", "entities", ":", "\n", "                ", "geom", "=", "rendering", ".", "make_circle", "(", "entity", ".", "size", ")", "\n", "xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "if", "'agent'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.5", ")", "\n", "", "else", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ")", "\n", "", "geom", ".", "add_attr", "(", "xform", ")", "\n", "self", ".", "render_geoms", ".", "append", "(", "geom", ")", "\n", "self", ".", "render_geoms_xform", ".", "append", "(", "xform", ")", "\n", "\n", "", "self", ".", "render_count", "=", "len", "(", "self", ".", "render_geoms", ")", "\n", "# render attn graph", "\n", "if", "attn", "is", "not", "None", ":", "\n", "# initialize render geoms for line", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "self", ".", "n", ")", ":", "\n", "                        ", "geom", "=", "rendering", ".", "Line", "(", "start", "=", "self", ".", "world", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", ",", "\n", "end", "=", "self", ".", "world", ".", "agents", "[", "j", "]", ".", "state", ".", "p_pos", ",", "\n", "linewidth", "=", "2", ")", "\n", "color", "=", "(", "1.0", ",", "0.0", ",", "0.0", ")", "\n", "alpha", "=", "0", "\n", "geom", ".", "set_color", "(", "*", "color", ",", "alpha", ")", "\n", "xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "self", ".", "render_geoms", ".", "append", "(", "geom", ")", "\n", "self", ".", "render_geoms_xform", ".", "append", "(", "xform", ")", "\n", "\n", "# add geoms to viewer", "\n", "", "", "", "for", "viewer", "in", "self", ".", "viewers", ":", "\n", "                ", "viewer", ".", "geoms", "=", "[", "]", "\n", "for", "geom", "in", "self", ".", "render_geoms", ":", "\n", "                    ", "viewer", ".", "add_geom", "(", "geom", ")", "\n", "\n", "", "", "", "if", "attn", "is", "not", "None", ":", "\n", "            ", "self", ".", "_add_lines", "(", "attn", ")", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "# update bounds to center around agent", "\n", "cam_range", "=", "self", ".", "cam_range", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "                ", "pos", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "", "else", ":", "\n", "                ", "pos", "=", "self", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", "\n", "", "self", ".", "viewers", "[", "i", "]", ".", "set_bounds", "(", "pos", "[", "0", "]", "-", "cam_range", ",", "pos", "[", "0", "]", "+", "cam_range", ",", "pos", "[", "1", "]", "-", "cam_range", ",", "pos", "[", "1", "]", "+", "cam_range", ")", "\n", "# update geometry positions", "\n", "for", "e", ",", "entity", "in", "enumerate", "(", "self", ".", "world", ".", "entities", ")", ":", "\n", "                ", "self", ".", "render_geoms_xform", "[", "e", "]", ".", "set_translation", "(", "*", "entity", ".", "state", ".", "p_pos", ")", "\n", "# render to display or array", "\n", "", "results", ".", "append", "(", "self", ".", "viewers", "[", "i", "]", ".", "render", "(", "return_rgb_array", "=", "mode", "==", "'rgb_array'", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._add_lines": [[294, 307], ["range", "range", "geom.set_color"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.rendering.Geom.set_color"], ["", "def", "_add_lines", "(", "self", ",", "attn", ")", ":", "\n", "        ", "k", "=", "self", ".", "render_count", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "self", ".", "n", ")", ":", "\n", "                ", "val", "=", "attn", "[", "i", "]", "[", "j", "]", "+", "attn", "[", "j", "]", "[", "i", "]", "\n", "geom", "=", "self", ".", "render_geoms", "[", "k", "]", "\n", "color", "=", "(", "1.0", ",", "0.0", ",", "0.0", ")", "\n", "# alpha proportional to mean attention", "\n", "# alpha = .5*val", "\n", "# binary masking", "\n", "alpha", "=", "val", ">", "0", "\n", "geom", ".", "set_color", "(", "*", "color", ",", "alpha", ")", "\n", "k", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._make_receptor_locations": [[309, 327], ["numpy.linspace", "dx.append", "numpy.linspace", "numpy.linspace", "numpy.array", "numpy.linspace", "dx.append", "dx.append", "numpy.array", "numpy.array", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "", "", "def", "_make_receptor_locations", "(", "self", ",", "agent", ")", ":", "\n", "        ", "receptor_type", "=", "'polar'", "\n", "range_min", "=", "0.05", "*", "2.0", "\n", "range_max", "=", "1.00", "\n", "dx", "=", "[", "]", "\n", "# circular receptive field", "\n", "if", "receptor_type", "==", "'polar'", ":", "\n", "            ", "for", "angle", "in", "np", ".", "linspace", "(", "-", "np", ".", "pi", ",", "+", "np", ".", "pi", ",", "8", ",", "endpoint", "=", "False", ")", ":", "\n", "                ", "for", "distance", "in", "np", ".", "linspace", "(", "range_min", ",", "range_max", ",", "3", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "distance", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "angle", ")", ",", "np", ".", "sin", "(", "angle", ")", "]", ")", ")", "\n", "# add origin", "\n", "", "", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "0.0", ",", "0.0", "]", ")", ")", "\n", "# grid receptive field", "\n", "", "if", "receptor_type", "==", "'grid'", ":", "\n", "            ", "for", "x", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                ", "for", "y", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", ")", "\n", "", "", "", "return", "dx", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.get_env_info": [[328, 336], ["environment.MultiAgentEnv.get_state"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.get_state"], ["", "def", "get_env_info", "(", "self", ")", ":", "\n", "        ", "env_info", "=", "{", "\"state_shape\"", ":", "self", ".", "get_state", "(", ")", ".", "shape", "[", "0", "]", ",", "\n", "# \"state_shape\": self.observation_space[0].shape[0],", "\n", "\"obs_shape\"", ":", "self", ".", "observation_space", "[", "0", "]", ".", "shape", "[", "0", "]", ",", "\n", "\"n_actions\"", ":", "self", ".", "action_space", "[", "0", "]", ".", "n", ",", "\n", "\"n_agents\"", ":", "self", ".", "n", ",", "\n", "\"episode_limit\"", ":", "50", "}", "\n", "return", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.get_state": [[337, 339], ["numpy.concatenate", "environment.MultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "get_state", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "[", "self", ".", "_get_obs", "(", "agent", ")", "for", "agent", "in", "self", ".", "agents", "]", ")", "\n", "# entity_pos = [entity.state.p_pos for entity in self.world.landmarks]", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.get_avail_actions": [[344, 346], ["numpy.ones"], "methods", ["None"], ["", "def", "get_avail_actions", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "ones", "(", "(", "self", ".", "n", ",", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv.get_obs": [[347, 349], ["environment.MultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "get_obs", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "_get_obs", "(", "agent", ")", "for", "agent", "in", "self", ".", "agents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.__init__": [[358, 360], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_batch", ")", ":", "\n", "        ", "self", ".", "env_batch", "=", "env_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.n": [[361, 364], ["numpy.sum"], "methods", ["None"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "env", ".", "n", "for", "env", "in", "self", ".", "env_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.action_space": [[365, 368], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.observation_space": [[369, 372], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step": [[373, 387], ["env.step"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step"], ["", "def", "step", "(", "self", ",", "action_n", ",", "time", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "{", "'n'", ":", "[", "]", "}", "\n", "i", "=", "0", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action_n", "[", "i", ":", "(", "i", "+", "env", ".", "n", ")", "]", ",", "time", ")", "\n", "i", "+=", "env", ".", "n", "\n", "obs_n", "+=", "obs", "\n", "# reward = [r / len(self.env_batch) for r in reward]", "\n", "reward_n", "+=", "reward", "\n", "done_n", "+=", "done", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.reset": [[388, 393], ["env.reset"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs_n", "+=", "env", ".", "reset", "(", ")", "\n", "", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render": [[395, 400], ["env.render"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "True", ")", ":", "\n", "        ", "results_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "results_n", "+=", "env", ".", "render", "(", "mode", ",", "close", ")", "\n", "", "return", "results_n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.__init__": [[25, 33], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_agents", "=", "4", ",", "dist_threshold", "=", "0.1", ",", "arena_size", "=", "1", ",", "identity_size", "=", "0", ")", ":", "\n", "        ", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "target_radius", "=", "0.5", "# fixing the target radius for now  ", "\n", "self", ".", "ideal_theta_separation", "=", "(", "2", "*", "np", ".", "pi", ")", "/", "self", ".", "num_agents", "# ideal theta difference between two agents ", "\n", "self", ".", "arena_size", "=", "arena_size", "\n", "self", ".", "dist_thres", "=", "0.05", "\n", "self", ".", "theta_thres", "=", "0.1", "\n", "self", ".", "identity_size", "=", "identity_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.make_world": [[34, 63], ["multiagent.core.World", "enumerate", "enumerate", "simple_formation.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "num_landmarks", "=", "1", "\n", "world", ".", "collaborative", "=", "False", "\n", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", "iden", "=", "i", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.05", "\n", "agent", ".", "adversary", "=", "False", "\n", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "world", ".", "dists", "=", "[", "]", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.reset_world": [[64, 87], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "# colors = [np.array([0,0,0.1]), np.array([0,1,0]), np.array([0,0,1]), np.array([1,1,0]), np.array([1,0,0])]", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "# agent.color = colors[i]", "\n", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "arena_size", ",", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "# bound on the landmark position less than that of the environment for visualization purposes", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", ".5", "*", "self", ".", "arena_size", ",", ".5", "*", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "world", ".", "steps", "=", "0", "\n", "world", ".", "dists", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.reward": [[88, 109], ["simple_formation.get_thetas", "min", "numpy.array", "simple_formation.Scenario._bipartite_min_dists", "numpy.mean", "numpy.clip", "range", "numpy.array", "numpy.linalg.norm", "numpy.cos", "numpy.sin"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.get_thetas", "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario._bipartite_min_dists"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", ".", "iden", "==", "0", ":", "\n", "            ", "landmark_pose", "=", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", "\n", "relative_poses", "=", "[", "agent", ".", "state", ".", "p_pos", "-", "landmark_pose", "for", "agent", "in", "world", ".", "agents", "]", "\n", "thetas", "=", "get_thetas", "(", "relative_poses", ")", "\n", "# anchor at the agent with min theta (closest to the horizontal line)", "\n", "theta_min", "=", "min", "(", "thetas", ")", "\n", "expected_poses", "=", "[", "landmark_pose", "+", "self", ".", "target_radius", "*", "np", ".", "array", "(", "\n", "[", "np", ".", "cos", "(", "theta_min", "+", "i", "*", "self", ".", "ideal_theta_separation", ")", ",", "\n", "np", ".", "sin", "(", "theta_min", "+", "i", "*", "self", ".", "ideal_theta_separation", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "\n", "dists", "=", "np", ".", "array", "(", "[", "[", "np", ".", "linalg", ".", "norm", "(", "a", ".", "state", ".", "p_pos", "-", "pos", ")", "for", "pos", "in", "expected_poses", "]", "for", "a", "in", "world", ".", "agents", "]", ")", "\n", "# optimal 1:1 agent-landmark pairing (bipartite matching algorithm)", "\n", "self", ".", "delta_dists", "=", "self", ".", "_bipartite_min_dists", "(", "dists", ")", "\n", "world", ".", "dists", "=", "self", ".", "delta_dists", "\n", "\n", "total_penalty", "=", "np", ".", "mean", "(", "np", ".", "clip", "(", "self", ".", "delta_dists", ",", "0", ",", "2", ")", ")", "\n", "self", ".", "joint_reward", "=", "-", "total_penalty", "\n", "\n", "", "return", "self", ".", "joint_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario._bipartite_min_dists": [[110, 114], ["scipy.optimize.linear_sum_assignment"], "methods", ["None"], ["", "def", "_bipartite_min_dists", "(", "self", ",", "dists", ")", ":", "\n", "        ", "ri", ",", "ci", "=", "linear_sum_assignment", "(", "dists", ")", "\n", "min_dists", "=", "dists", "[", "ri", ",", "ci", "]", "\n", "return", "min_dists", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.observation": [[115, 123], ["numpy.concatenate", "numpy.append", "numpy.eye"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "for", "entity", "in", "world", ".", "landmarks", "]", "\n", "default_obs", "=", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", ")", "\n", "if", "self", ".", "identity_size", "!=", "0", ":", "\n", "            ", "identified_obs", "=", "np", ".", "append", "(", "np", ".", "eye", "(", "self", ".", "identity_size", ")", "[", "agent", ".", "iden", "]", ",", "default_obs", ")", "\n", "return", "identified_obs", "\n", "", "return", "default_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.done": [[124, 128], ["numpy.all"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "condition1", "=", "world", ".", "steps", ">=", "world", ".", "max_steps_episode", "\n", "self", ".", "is_success", "=", "np", ".", "all", "(", "self", ".", "delta_dists", "<", "self", ".", "dist_thres", ")", "\n", "return", "condition1", "or", "self", ".", "is_success", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.Scenario.info": [[129, 132], ["simple_formation.Scenario.delta_dists.mean"], "methods", ["None"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "{", "'is_success'", ":", "self", ".", "is_success", ",", "'world_steps'", ":", "world", ".", "steps", ",", "\n", "'reward'", ":", "self", ".", "joint_reward", ",", "'dists'", ":", "self", ".", "delta_dists", ".", "mean", "(", ")", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.get_thetas": [[7, 14], ["range", "len", "len", "simple_formation.find_angle"], "function", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.find_angle"], ["def", "get_thetas", "(", "poses", ")", ":", "\n", "# compute angle (0,2pi) from horizontal", "\n", "    ", "thetas", "=", "[", "None", "]", "*", "len", "(", "poses", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "poses", ")", ")", ":", "\n", "# (y,x)", "\n", "        ", "thetas", "[", "i", "]", "=", "find_angle", "(", "poses", "[", "i", "]", ")", "\n", "", "return", "thetas", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_formation.find_angle": [[16, 22], ["numpy.arctan2"], "function", ["None"], ["", "def", "find_angle", "(", "pose", ")", ":", "\n", "# compute angle from horizontal", "\n", "    ", "angle", "=", "np", ".", "arctan2", "(", "pose", "[", "1", "]", ",", "pose", "[", "0", "]", ")", "\n", "if", "angle", "<", "0", ":", "\n", "        ", "angle", "+=", "2", "*", "np", ".", "pi", "\n", "", "return", "angle", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.__init__": [[8, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_agents", "=", "4", ",", "dist_threshold", "=", "0.1", ",", "arena_size", "=", "1", ",", "identity_size", "=", "0", ")", ":", "\n", "        ", "self", ".", "arena_size", "=", "arena_size", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "total_sep", "=", "1.25", "*", "self", ".", "arena_size", "\n", "self", ".", "ideal_sep", "=", "self", ".", "total_sep", "/", "(", "num_agents", "-", "1", ")", "\n", "self", ".", "dist_thres", "=", "0.05", "\n", "self", ".", "identity_size", "=", "identity_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.make_world": [[16, 45], ["multiagent.core.World", "enumerate", "enumerate", "simple_line.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "num_landmarks", "=", "2", "\n", "world", ".", "collaborative", "=", "False", "\n", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", "iden", "=", "i", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.03", "\n", "agent", ".", "adversary", "=", "False", "\n", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.02", "\n", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "world", ".", "dists", "=", "[", "]", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.reset_world": [[46, 81], ["enumerate", "enumerate", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.radians", "numpy.array", "range", "abs", "abs", "numpy.array", "numpy.array", "len", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "# colors = [np.array([0,0,0.1]), np.array([0,1,0]), np.array([0,0,1]), np.array([1,1,0]), np.array([1,0,0])]", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "# agent.color = colors[i]", "\n", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "arena_size", ",", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", ".25", "*", "self", ".", "arena_size", ",", ".25", "*", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "theta", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "2", "*", "np", ".", "pi", ")", "\n", "loc", "=", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", "+", "self", ".", "total_sep", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "theta", ")", ",", "np", ".", "sin", "(", "theta", ")", "]", ")", "\n", "# find a suitable theta such that landmark 1 is within the bounds", "\n", "while", "not", "(", "abs", "(", "loc", "[", "0", "]", ")", "<", "self", ".", "arena_size", "and", "abs", "(", "loc", "[", "1", "]", ")", "<", "self", ".", "arena_size", ")", ":", "\n", "            ", "theta", "+=", "np", ".", "radians", "(", "5", ")", "\n", "loc", "=", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", "+", "self", ".", "total_sep", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "theta", ")", ",", "np", ".", "sin", "(", "theta", ")", "]", ")", "\n", "\n", "", "world", ".", "landmarks", "[", "1", "]", ".", "state", ".", "p_pos", "=", "loc", "\n", "world", ".", "landmarks", "[", "1", "]", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "self", ".", "expected_positions", "=", "[", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", "+", "i", "*", "self", ".", "ideal_sep", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "theta", ")", ",", "np", ".", "sin", "(", "theta", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "world", ".", "agents", ")", ")", "]", "\n", "\n", "world", ".", "steps", "=", "0", "\n", "world", ".", "dists", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.reward": [[82, 93], ["numpy.array", "simple_line.Scenario._bipartite_min_dists", "numpy.mean", "numpy.clip", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario._bipartite_min_dists"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", ".", "iden", "==", "0", ":", "\n", "            ", "dists", "=", "np", ".", "array", "(", "[", "[", "np", ".", "linalg", ".", "norm", "(", "a", ".", "state", ".", "p_pos", "-", "pos", ")", "for", "pos", "in", "self", ".", "expected_positions", "]", "for", "a", "in", "world", ".", "agents", "]", ")", "\n", "# optimal 1:1 agent-landmark pairing (bipartite matching algorithm)", "\n", "self", ".", "delta_dists", "=", "self", ".", "_bipartite_min_dists", "(", "dists", ")", "\n", "world", ".", "dists", "=", "self", ".", "delta_dists", "\n", "\n", "total_penalty", "=", "np", ".", "mean", "(", "np", ".", "clip", "(", "self", ".", "delta_dists", ",", "0", ",", "2", ")", ")", "\n", "self", ".", "joint_reward", "=", "-", "total_penalty", "\n", "\n", "", "return", "self", ".", "joint_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario._bipartite_min_dists": [[94, 98], ["scipy.optimize.linear_sum_assignment"], "methods", ["None"], ["", "def", "_bipartite_min_dists", "(", "self", ",", "dists", ")", ":", "\n", "        ", "ri", ",", "ci", "=", "linear_sum_assignment", "(", "dists", ")", "\n", "min_dists", "=", "dists", "[", "ri", ",", "ci", "]", "\n", "return", "min_dists", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.observation": [[99, 107], ["numpy.concatenate", "numpy.append", "numpy.eye"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "for", "entity", "in", "world", ".", "landmarks", "]", "\n", "default_obs", "=", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", ")", "\n", "if", "self", ".", "identity_size", "!=", "0", ":", "\n", "            ", "identified_obs", "=", "np", ".", "append", "(", "np", ".", "eye", "(", "self", ".", "identity_size", ")", "[", "agent", ".", "iden", "]", ",", "default_obs", ")", "\n", "return", "identified_obs", "\n", "", "return", "default_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.done": [[108, 112], ["numpy.all"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "condition1", "=", "world", ".", "steps", ">=", "world", ".", "max_steps_episode", "\n", "self", ".", "is_success", "=", "np", ".", "all", "(", "self", ".", "delta_dists", "<", "self", ".", "dist_thres", ")", "\n", "return", "condition1", "or", "self", ".", "is_success", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_line.Scenario.info": [[113, 116], ["simple_line.Scenario.delta_dists.mean"], "methods", ["None"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "{", "'is_success'", ":", "self", ".", "is_success", ",", "'world_steps'", ":", "world", ".", "steps", ",", "\n", "'reward'", ":", "self", ".", "joint_reward", ",", "'dists'", ":", "self", ".", "delta_dists", ".", "mean", "(", ")", "}", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.__init__": [[8, 15], ["numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_agents", "=", "3", ",", "dist_threshold", "=", "0.1", ",", "arena_size", "=", "1", ",", "identity_size", "=", "0", ")", ":", "\n", "        ", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "self", ".", "num_agents", ")", "\n", "self", ".", "temp_done", "=", "False", "\n", "self", ".", "dist_threshold", "=", "dist_threshold", "\n", "self", ".", "arena_size", "=", "arena_size", "\n", "self", ".", "identity_size", "=", "identity_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.make_world": [[16, 43], ["multiagent.core.World", "enumerate", "enumerate", "simple_spread.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "0", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "num_landmarks", "=", "num_agents", "\n", "world", ".", "collaborative", "=", "False", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", "iden", "=", "i", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.05", "\n", "agent", ".", "adversary", "=", "False", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "world", ".", "dists", "=", "[", "]", "\n", "world", ".", "dist_thres", "=", "self", ".", "dist_threshold", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.reset_world": [[44, 65], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "arena_size", ",", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "arena_size", ",", "self", ".", "arena_size", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "world", ".", "steps", "=", "0", "\n", "world", ".", "dists", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.is_collision": [[66, 71], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["None"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.reward": [[72, 84], ["simple_spread.Scenario.rewards.mean", "numpy.array", "simple_spread.Scenario._bipartite_min_dists", "numpy.clip", "numpy.full", "numpy.mean", "numpy.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario._bipartite_min_dists"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", ".", "iden", "==", "0", ":", "# compute this only once when called with the first agent", "\n", "# each column represents distance of all agents from the respective landmark", "\n", "            ", "world", ".", "dists", "=", "np", ".", "array", "(", "[", "[", "np", ".", "linalg", ".", "norm", "(", "a", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", "for", "l", "in", "world", ".", "landmarks", "]", "\n", "for", "a", "in", "world", ".", "agents", "]", ")", "\n", "# optimal 1:1 agent-landmark pairing (bipartite matching algorithm)", "\n", "self", ".", "min_dists", "=", "self", ".", "_bipartite_min_dists", "(", "world", ".", "dists", ")", "\n", "# the reward is normalized by the number of agents", "\n", "joint_reward", "=", "np", ".", "clip", "(", "-", "np", ".", "mean", "(", "self", ".", "min_dists", ")", ",", "-", "15", ",", "15", ")", "\n", "self", ".", "rewards", "=", "np", ".", "full", "(", "self", ".", "num_agents", ",", "joint_reward", ")", "\n", "world", ".", "min_dists", "=", "self", ".", "min_dists", "\n", "", "return", "self", ".", "rewards", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario._bipartite_min_dists": [[85, 89], ["scipy.optimize.linear_sum_assignment"], "methods", ["None"], ["", "def", "_bipartite_min_dists", "(", "self", ",", "dists", ")", ":", "\n", "        ", "ri", ",", "ci", "=", "linear_sum_assignment", "(", "dists", ")", "\n", "min_dists", "=", "dists", "[", "ri", ",", "ci", "]", "\n", "return", "min_dists", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.observation": [[90, 98], ["numpy.concatenate", "numpy.append", "numpy.eye"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# positions of all entities in this agent's reference frame, because no other way to bring the landmark information", "\n", "        ", "entity_pos", "=", "[", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "for", "entity", "in", "world", ".", "landmarks", "]", "\n", "default_obs", "=", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", ")", "\n", "if", "self", ".", "identity_size", "!=", "0", ":", "\n", "            ", "identified_obs", "=", "np", ".", "append", "(", "np", ".", "eye", "(", "self", ".", "identity_size", ")", "[", "agent", ".", "iden", "]", ",", "default_obs", ")", "\n", "return", "identified_obs", "\n", "", "return", "default_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.done": [[99, 103], ["numpy.all"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "condition1", "=", "world", ".", "steps", ">=", "world", ".", "max_steps_episode", "\n", "self", ".", "is_success", "=", "np", ".", "all", "(", "self", ".", "min_dists", "<", "world", ".", "dist_thres", ")", "\n", "return", "condition1", "or", "self", ".", "is_success", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.simple_spread.Scenario.info": [[104, 108], ["simple_spread.Scenario.rewards.mean", "simple_spread.Scenario.min_dists.mean"], "methods", ["None"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "info", "=", "{", "'is_success'", ":", "self", ".", "is_success", ",", "'world_steps'", ":", "world", ".", "steps", ",", "\n", "'reward'", ":", "self", ".", "rewards", ".", "mean", "(", ")", ",", "'dists'", ":", "self", ".", "min_dists", ".", "mean", "(", ")", "}", "\n", "return", "info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.scenarios.__init__.load": [[5, 8], ["os.join", "imp.load_source", "os.dirname"], "function", ["None"], []], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.distributions.Categorical.__init__": [[20, 29], ["torch.Module.__init__", "init_", "utils.init", "torch.Linear", "torch.Linear", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__", "home.repos.pwc.inspect_result.sumitsk_matrl.None.utils.init"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_outputs", ")", ":", "\n", "        ", "super", "(", "Categorical", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "init_", "=", "lambda", "m", ":", "init", "(", "m", ",", "\n", "nn", ".", "init", ".", "orthogonal_", ",", "\n", "lambda", "x", ":", "nn", ".", "init", ".", "constant_", "(", "x", ",", "0", ")", ",", "\n", "gain", "=", "0.01", ")", "\n", "\n", "self", ".", "linear", "=", "init_", "(", "nn", ".", "Linear", "(", "num_inputs", ",", "num_outputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.distributions.Categorical.forward": [[30, 33], ["distributions.Categorical.linear", "FixedCategorical"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "return", "FixedCategorical", "(", "logits", "=", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.__init__": [[10, 22], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "storage.RolloutStorage.actions.long", "torch.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_steps", ",", "num_processes", ",", "obs_shape", ",", "action_space", ",", "recurrent_hidden_state_size", ")", ":", "\n", "        ", "self", ".", "obs", "=", "torch", ".", "zeros", "(", "num_steps", "+", "1", ",", "num_processes", ",", "*", "obs_shape", ")", "\n", "self", ".", "recurrent_hidden_states", "=", "torch", ".", "zeros", "(", "num_steps", "+", "1", ",", "num_processes", ",", "recurrent_hidden_state_size", ")", "\n", "self", ".", "rewards", "=", "torch", ".", "zeros", "(", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "value_preds", "=", "torch", ".", "zeros", "(", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "returns", "=", "torch", ".", "zeros", "(", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "action_log_probs", "=", "torch", ".", "zeros", "(", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "actions", "=", "torch", ".", "zeros", "(", "num_steps", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "actions", "=", "self", ".", "actions", ".", "long", "(", ")", "\n", "self", ".", "masks", "=", "torch", ".", "ones", "(", "num_steps", "+", "1", ",", "num_processes", ",", "1", ")", "\n", "self", ".", "num_steps", "=", "num_steps", "\n", "self", ".", "step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to": [[23, 32], ["storage.RolloutStorage.obs.to", "storage.RolloutStorage.recurrent_hidden_states.to", "storage.RolloutStorage.rewards.to", "storage.RolloutStorage.value_preds.to", "storage.RolloutStorage.returns.to", "storage.RolloutStorage.action_log_probs.to", "storage.RolloutStorage.actions.to", "storage.RolloutStorage.masks.to"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "obs", "=", "self", ".", "obs", ".", "to", "(", "device", ")", "\n", "self", ".", "recurrent_hidden_states", "=", "self", ".", "recurrent_hidden_states", ".", "to", "(", "device", ")", "\n", "self", ".", "rewards", "=", "self", ".", "rewards", ".", "to", "(", "device", ")", "\n", "self", ".", "value_preds", "=", "self", ".", "value_preds", ".", "to", "(", "device", ")", "\n", "self", ".", "returns", "=", "self", ".", "returns", ".", "to", "(", "device", ")", "\n", "self", ".", "action_log_probs", "=", "self", ".", "action_log_probs", ".", "to", "(", "device", ")", "\n", "self", ".", "actions", "=", "self", ".", "actions", ".", "to", "(", "device", ")", "\n", "self", ".", "masks", "=", "self", ".", "masks", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.insert": [[33, 43], ["storage.RolloutStorage.obs[].copy_", "storage.RolloutStorage.recurrent_hidden_states[].copy_", "storage.RolloutStorage.actions[].copy_", "storage.RolloutStorage.action_log_probs[].copy_", "storage.RolloutStorage.value_preds[].copy_", "storage.RolloutStorage.rewards[].copy_", "storage.RolloutStorage.masks[].copy_"], "methods", ["None"], ["", "def", "insert", "(", "self", ",", "obs", ",", "recurrent_hidden_states", ",", "actions", ",", "action_log_probs", ",", "value_preds", ",", "rewards", ",", "masks", ")", ":", "\n", "        ", "self", ".", "obs", "[", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "obs", ")", "\n", "self", ".", "recurrent_hidden_states", "[", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "recurrent_hidden_states", ")", "\n", "self", ".", "actions", "[", "self", ".", "step", "]", ".", "copy_", "(", "actions", ")", "\n", "self", ".", "action_log_probs", "[", "self", ".", "step", "]", ".", "copy_", "(", "action_log_probs", ")", "\n", "self", ".", "value_preds", "[", "self", ".", "step", "]", ".", "copy_", "(", "value_preds", ")", "\n", "self", ".", "rewards", "[", "self", ".", "step", "]", ".", "copy_", "(", "rewards", ")", "\n", "self", ".", "masks", "[", "self", ".", "step", "+", "1", "]", ".", "copy_", "(", "masks", ")", "\n", "\n", "self", ".", "step", "=", "(", "self", ".", "step", "+", "1", ")", "%", "self", ".", "num_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.after_update": [[44, 48], ["storage.RolloutStorage.obs[].copy_", "storage.RolloutStorage.recurrent_hidden_states[].copy_", "storage.RolloutStorage.masks[].copy_"], "methods", ["None"], ["", "def", "after_update", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs", "[", "0", "]", ".", "copy_", "(", "self", ".", "obs", "[", "-", "1", "]", ")", "\n", "self", ".", "recurrent_hidden_states", "[", "0", "]", ".", "copy_", "(", "self", ".", "recurrent_hidden_states", "[", "-", "1", "]", ")", "\n", "self", ".", "masks", "[", "0", "]", ".", "copy_", "(", "self", ".", "masks", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.compute_returns": [[49, 61], ["reversed", "reversed", "range", "range", "storage.RolloutStorage.rewards.size", "storage.RolloutStorage.rewards.size"], "methods", ["None"], ["", "def", "compute_returns", "(", "self", ",", "next_value", ",", "use_gae", ",", "gamma", ",", "tau", ")", ":", "\n", "        ", "if", "use_gae", ":", "\n", "            ", "self", ".", "value_preds", "[", "-", "1", "]", "=", "next_value", "\n", "gae", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "rewards", ".", "size", "(", "0", ")", ")", ")", ":", "\n", "                ", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "gamma", "*", "self", ".", "value_preds", "[", "step", "+", "1", "]", "*", "self", ".", "masks", "[", "step", "+", "1", "]", "-", "self", ".", "value_preds", "[", "step", "]", "\n", "gae", "=", "delta", "+", "gamma", "*", "tau", "*", "self", ".", "masks", "[", "step", "+", "1", "]", "*", "gae", "\n", "self", ".", "returns", "[", "step", "]", "=", "gae", "+", "self", ".", "value_preds", "[", "step", "]", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "returns", "[", "-", "1", "]", "=", "next_value", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "rewards", ".", "size", "(", "0", ")", ")", ")", ":", "\n", "                ", "self", ".", "returns", "[", "step", "]", "=", "self", ".", "returns", "[", "step", "+", "1", "]", "*", "gamma", "*", "self", ".", "masks", "[", "step", "+", "1", "]", "+", "self", ".", "rewards", "[", "step", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.feed_forward_generator": [[63, 87], ["storage.RolloutStorage.rewards.size", "torch.utils.data.sampler.BatchSampler", "torch.utils.data.sampler.SubsetRandomSampler", "storage.RolloutStorage.obs[].view", "storage.RolloutStorage.recurrent_hidden_states[].view", "storage.RolloutStorage.actions.view", "storage.RolloutStorage.value_preds[].view", "storage.RolloutStorage.returns[].view", "storage.RolloutStorage.masks[].view", "storage.RolloutStorage.action_log_probs.view", "advantages.view", "range", "storage.RolloutStorage.recurrent_hidden_states.size", "storage.RolloutStorage.actions.size", "storage.RolloutStorage.obs.size"], "methods", ["None"], ["", "", "", "def", "feed_forward_generator", "(", "self", ",", "advantages", ",", "num_mini_batch", ",", "sampler", "=", "None", ")", ":", "\n", "        ", "num_steps", ",", "num_processes", "=", "self", ".", "rewards", ".", "size", "(", ")", "[", "0", ":", "2", "]", "\n", "batch_size", "=", "num_processes", "*", "num_steps", "\n", "assert", "batch_size", ">=", "num_mini_batch", ",", "(", "\n", "\"PPO requires the number of processes ({}) \"", "\n", "\"* number of steps ({}) = {} \"", "\n", "\"to be greater than or equal to the number of PPO mini batches ({}).\"", "\n", "\"\"", ".", "format", "(", "num_processes", ",", "num_steps", ",", "num_processes", "*", "num_steps", ",", "num_mini_batch", ")", ")", "\n", "mini_batch_size", "=", "batch_size", "//", "num_mini_batch", "\n", "if", "sampler", "is", "None", ":", "\n", "            ", "sampler", "=", "BatchSampler", "(", "SubsetRandomSampler", "(", "range", "(", "batch_size", ")", ")", ",", "mini_batch_size", ",", "drop_last", "=", "False", ")", "\n", "", "for", "indices", "in", "sampler", ":", "\n", "            ", "obs_batch", "=", "self", ".", "obs", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "*", "self", ".", "obs", ".", "size", "(", ")", "[", "2", ":", "]", ")", "[", "indices", "]", "\n", "recurrent_hidden_states_batch", "=", "self", ".", "recurrent_hidden_states", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "\n", "self", ".", "recurrent_hidden_states", ".", "size", "(", "-", "1", ")", ")", "[", "indices", "]", "\n", "actions_batch", "=", "self", ".", "actions", ".", "view", "(", "-", "1", ",", "self", ".", "actions", ".", "size", "(", "-", "1", ")", ")", "[", "indices", "]", "\n", "value_preds_batch", "=", "self", ".", "value_preds", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "\n", "return_batch", "=", "self", ".", "returns", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "\n", "masks_batch", "=", "self", ".", "masks", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "\n", "old_action_log_probs_batch", "=", "self", ".", "action_log_probs", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "\n", "adv_targ", "=", "advantages", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "\n", "\n", "yield", "obs_batch", ",", "recurrent_hidden_states_batch", ",", "actions_batch", ",", "value_preds_batch", ",", "return_batch", ",", "masks_batch", ",", "old_action_log_probs_batch", ",", "adv_targ", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.recurrent_generator": [[88, 141], ["storage.RolloutStorage.rewards.size", "torch.randperm", "range", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().view", "storage._flatten_helper", "storage._flatten_helper", "storage._flatten_helper", "storage._flatten_helper", "storage._flatten_helper", "storage._flatten_helper", "storage._flatten_helper", "_flatten_helper.append", "torch.stack().view.append", "_flatten_helper.append", "_flatten_helper.append", "_flatten_helper.append", "_flatten_helper.append", "_flatten_helper.append", "_flatten_helper.append", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper"], ["", "", "def", "recurrent_generator", "(", "self", ",", "advantages", ",", "num_mini_batch", ")", ":", "\n", "        ", "num_processes", "=", "self", ".", "rewards", ".", "size", "(", "1", ")", "\n", "assert", "num_processes", ">=", "num_mini_batch", ",", "(", "\n", "\"PPO requires the number of processes ({}) \"", "\n", "\"to be greater than or equal to the number of \"", "\n", "\"PPO mini batches ({}).\"", ".", "format", "(", "num_processes", ",", "num_mini_batch", ")", ")", "\n", "num_envs_per_batch", "=", "num_processes", "//", "num_mini_batch", "\n", "perm", "=", "torch", ".", "randperm", "(", "num_processes", ")", "\n", "for", "start_ind", "in", "range", "(", "0", ",", "num_processes", ",", "num_envs_per_batch", ")", ":", "\n", "            ", "obs_batch", "=", "[", "]", "\n", "recurrent_hidden_states_batch", "=", "[", "]", "\n", "actions_batch", "=", "[", "]", "\n", "value_preds_batch", "=", "[", "]", "\n", "return_batch", "=", "[", "]", "\n", "masks_batch", "=", "[", "]", "\n", "old_action_log_probs_batch", "=", "[", "]", "\n", "adv_targ", "=", "[", "]", "\n", "\n", "for", "offset", "in", "range", "(", "num_envs_per_batch", ")", ":", "\n", "                ", "ind", "=", "perm", "[", "start_ind", "+", "offset", "]", "\n", "obs_batch", ".", "append", "(", "self", ".", "obs", "[", ":", "-", "1", ",", "ind", "]", ")", "\n", "recurrent_hidden_states_batch", ".", "append", "(", "self", ".", "recurrent_hidden_states", "[", "0", ":", "1", ",", "ind", "]", ")", "\n", "actions_batch", ".", "append", "(", "self", ".", "actions", "[", ":", ",", "ind", "]", ")", "\n", "value_preds_batch", ".", "append", "(", "self", ".", "value_preds", "[", ":", "-", "1", ",", "ind", "]", ")", "\n", "return_batch", ".", "append", "(", "self", ".", "returns", "[", ":", "-", "1", ",", "ind", "]", ")", "\n", "masks_batch", ".", "append", "(", "self", ".", "masks", "[", ":", "-", "1", ",", "ind", "]", ")", "\n", "old_action_log_probs_batch", ".", "append", "(", "self", ".", "action_log_probs", "[", ":", ",", "ind", "]", ")", "\n", "adv_targ", ".", "append", "(", "advantages", "[", ":", ",", "ind", "]", ")", "\n", "\n", "", "T", ",", "N", "=", "self", ".", "num_steps", ",", "num_envs_per_batch", "\n", "# These are all tensors of size (T, N, -1)", "\n", "obs_batch", "=", "torch", ".", "stack", "(", "obs_batch", ",", "1", ")", "\n", "actions_batch", "=", "torch", ".", "stack", "(", "actions_batch", ",", "1", ")", "\n", "value_preds_batch", "=", "torch", ".", "stack", "(", "value_preds_batch", ",", "1", ")", "\n", "return_batch", "=", "torch", ".", "stack", "(", "return_batch", ",", "1", ")", "\n", "masks_batch", "=", "torch", ".", "stack", "(", "masks_batch", ",", "1", ")", "\n", "old_action_log_probs_batch", "=", "torch", ".", "stack", "(", "old_action_log_probs_batch", ",", "1", ")", "\n", "adv_targ", "=", "torch", ".", "stack", "(", "adv_targ", ",", "1", ")", "\n", "\n", "# States is just a (N, -1) tensor", "\n", "recurrent_hidden_states_batch", "=", "torch", ".", "stack", "(", "recurrent_hidden_states_batch", ",", "1", ")", ".", "view", "(", "N", ",", "-", "1", ")", "\n", "\n", "# Flatten the (T, N, ...) tensors to (T * N, ...)", "\n", "obs_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "obs_batch", ")", "\n", "actions_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "actions_batch", ")", "\n", "value_preds_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "value_preds_batch", ")", "\n", "return_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "return_batch", ")", "\n", "masks_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "masks_batch", ")", "\n", "old_action_log_probs_batch", "=", "_flatten_helper", "(", "T", ",", "N", ",", "old_action_log_probs_batch", ")", "\n", "adv_targ", "=", "_flatten_helper", "(", "T", ",", "N", ",", "adv_targ", ")", "\n", "\n", "yield", "obs_batch", ",", "recurrent_hidden_states_batch", ",", "actions_batch", ",", "value_preds_batch", ",", "return_batch", ",", "masks_batch", ",", "old_action_log_probs_batch", ",", "adv_targ", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage._flatten_helper": [[5, 7], ["_tensor.view", "_tensor.size"], "function", ["None"], ["def", "_flatten_helper", "(", "T", ",", "N", ",", "_tensor", ")", ":", "\n", "    ", "return", "_tensor", ".", "view", "(", "T", "*", "N", ",", "*", "_tensor", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.PPO.__init__": [[9, 34], ["torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "actor_critic.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "actor_critic", ",", "\n", "clip_param", ",", "\n", "ppo_epoch", ",", "\n", "num_mini_batch", ",", "\n", "value_loss_coef", ",", "\n", "entropy_coef", ",", "\n", "lr", "=", "None", ",", "\n", "eps", "=", "None", ",", "\n", "max_grad_norm", "=", "None", ",", "\n", "use_clipped_value_loss", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "actor_critic", "=", "actor_critic", "\n", "\n", "self", ".", "clip_param", "=", "clip_param", "\n", "self", ".", "ppo_epoch", "=", "ppo_epoch", "\n", "self", ".", "num_mini_batch", "=", "num_mini_batch", "\n", "\n", "self", ".", "value_loss_coef", "=", "value_loss_coef", "\n", "self", ".", "entropy_coef", "=", "entropy_coef", "\n", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "use_clipped_value_loss", "=", "use_clipped_value_loss", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "actor_critic", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.PPO.update": [[35, 86], ["range", "advantages.mean", "advantages.std", "rollouts.recurrent_generator", "rollouts.feed_forward_generator", "ppo.PPO.actor_critic.evaluate_actions", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "ppo.PPO.optimizer.zero_grad", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "ppo.PPO.optimizer.step", "value_loss.item", "action_loss.item", "dist_entropy.item", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "ppo.PPO.actor_critic.parameters", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.recurrent_generator", "home.repos.pwc.inspect_result.sumitsk_matrl.rlcore.storage.RolloutStorage.feed_forward_generator", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.evaluate_actions", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step"], ["", "def", "update", "(", "self", ",", "rollouts", ")", ":", "\n", "        ", "advantages", "=", "rollouts", ".", "returns", "[", ":", "-", "1", "]", "-", "rollouts", ".", "value_preds", "[", ":", "-", "1", "]", "\n", "advantages", "=", "(", "advantages", "-", "advantages", ".", "mean", "(", ")", ")", "/", "(", "advantages", ".", "std", "(", ")", "+", "1e-5", ")", "\n", "\n", "value_loss_epoch", "=", "0", "\n", "action_loss_epoch", "=", "0", "\n", "dist_entropy_epoch", "=", "0", "\n", "\n", "for", "e", "in", "range", "(", "self", ".", "ppo_epoch", ")", ":", "\n", "            ", "if", "self", ".", "actor_critic", ".", "is_recurrent", ":", "\n", "                ", "data_generator", "=", "rollouts", ".", "recurrent_generator", "(", "advantages", ",", "self", ".", "num_mini_batch", ")", "\n", "", "else", ":", "\n", "                ", "data_generator", "=", "rollouts", ".", "feed_forward_generator", "(", "advantages", ",", "self", ".", "num_mini_batch", ")", "\n", "\n", "", "for", "sample", "in", "data_generator", ":", "\n", "                ", "obs_batch", ",", "recurrent_hidden_states_batch", ",", "actions_batch", ",", "value_preds_batch", ",", "return_batch", ",", "masks_batch", ",", "old_action_log_probs_batch", ",", "adv_targ", "=", "sample", "\n", "\n", "# Reshape to do in a single forward pass for all steps", "\n", "values", ",", "action_log_probs", ",", "dist_entropy", ",", "_", "=", "self", ".", "actor_critic", ".", "evaluate_actions", "(", "obs_batch", ",", "\n", "recurrent_hidden_states_batch", ",", "masks_batch", ",", "actions_batch", ")", "\n", "\n", "ratio", "=", "torch", ".", "exp", "(", "action_log_probs", "-", "old_action_log_probs_batch", ")", "\n", "surr1", "=", "ratio", "*", "adv_targ", "\n", "surr2", "=", "torch", ".", "clamp", "(", "ratio", ",", "1.0", "-", "self", ".", "clip_param", ",", "1.0", "+", "self", ".", "clip_param", ")", "*", "adv_targ", "\n", "action_loss", "=", "-", "torch", ".", "min", "(", "surr1", ",", "surr2", ")", ".", "mean", "(", ")", "\n", "\n", "if", "self", ".", "use_clipped_value_loss", ":", "\n", "                    ", "value_pred_clipped", "=", "value_preds_batch", "+", "(", "values", "-", "value_preds_batch", ")", ".", "clamp", "(", "-", "self", ".", "clip_param", ",", "self", ".", "clip_param", ")", "\n", "value_losses", "=", "(", "values", "-", "return_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_losses_clipped", "=", "(", "value_pred_clipped", "-", "return_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_loss", "=", ".5", "*", "torch", ".", "max", "(", "value_losses", ",", "value_losses_clipped", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                    ", "value_loss", "=", "0.5", "*", "F", ".", "mse_loss", "(", "return_batch", ",", "values", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "(", "value_loss", "*", "self", ".", "value_loss_coef", "+", "action_loss", "-", "dist_entropy", "*", "self", ".", "entropy_coef", ")", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "actor_critic", ".", "parameters", "(", ")", ",", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "value_loss_epoch", "+=", "value_loss", ".", "item", "(", ")", "\n", "action_loss_epoch", "+=", "action_loss", ".", "item", "(", ")", "\n", "dist_entropy_epoch", "+=", "dist_entropy", ".", "item", "(", ")", "\n", "\n", "", "", "num_updates", "=", "self", ".", "ppo_epoch", "*", "self", ".", "num_mini_batch", "\n", "\n", "value_loss_epoch", "/=", "num_updates", "\n", "action_loss_epoch", "/=", "num_updates", "\n", "dist_entropy_epoch", "/=", "num_updates", "\n", "\n", "return", "value_loss_epoch", ",", "action_loss_epoch", ",", "dist_entropy_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.__init__": [[89, 114], ["torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "actor_critic.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "actor_critic", ",", "\n", "clip_param", ",", "\n", "ppo_epoch", ",", "\n", "num_mini_batch", ",", "\n", "value_loss_coef", ",", "\n", "entropy_coef", ",", "\n", "lr", "=", "None", ",", "\n", "eps", "=", "None", ",", "\n", "max_grad_norm", "=", "None", ",", "\n", "use_clipped_value_loss", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "actor_critic", "=", "actor_critic", "\n", "\n", "self", ".", "clip_param", "=", "clip_param", "\n", "self", ".", "ppo_epoch", "=", "ppo_epoch", "\n", "self", ".", "num_mini_batch", "=", "num_mini_batch", "\n", "\n", "self", ".", "value_loss_coef", "=", "value_loss_coef", "\n", "self", ".", "entropy_coef", "=", "entropy_coef", "\n", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "use_clipped_value_loss", "=", "use_clipped_value_loss", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "actor_critic", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.JointPPO.update": [[115, 171], ["range", "advantages_list.append", "NotImplementedError", "ppo.magent_feed_forward_generator", "ppo.JointPPO.actor_critic.evaluate_actions", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "ppo.JointPPO.optimizer.zero_grad", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "ppo.JointPPO.optimizer.step", "value_loss.item", "action_loss.item", "dist_entropy.item", "advantages.mean", "advantages.std", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "torch.min().mean", "ppo.JointPPO.actor_critic.parameters", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.max().mean", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.magent_feed_forward_generator", "home.repos.pwc.inspect_result.sumitsk_matrl.None.mpnn.MPNN.evaluate_actions", "home.repos.pwc.inspect_result.sumitsk_matrl.multiagent.environment.BatchMultiAgentEnv.step"], ["", "def", "update", "(", "self", ",", "rollouts_list", ")", ":", "\n", "# rollouts_list - list of rollouts of agents which share self.actor_critic policy", "\n", "        ", "advantages_list", "=", "[", "]", "\n", "for", "rollout", "in", "rollouts_list", ":", "\n", "            ", "advantages", "=", "rollout", ".", "returns", "[", ":", "-", "1", "]", "-", "rollout", ".", "value_preds", "[", ":", "-", "1", "]", "\n", "advantages", "=", "(", "advantages", "-", "advantages", ".", "mean", "(", ")", ")", "/", "(", "advantages", ".", "std", "(", ")", "+", "1e-5", ")", "\n", "advantages_list", ".", "append", "(", "advantages", ")", "\n", "\n", "", "value_loss_epoch", "=", "0", "\n", "action_loss_epoch", "=", "0", "\n", "dist_entropy_epoch", "=", "0", "\n", "\n", "for", "e", "in", "range", "(", "self", ".", "ppo_epoch", ")", ":", "\n", "            ", "if", "self", ".", "actor_critic", ".", "is_recurrent", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'sampler not implemented for recurrent policies'", ")", "\n", "", "else", ":", "\n", "                ", "data_generator", "=", "magent_feed_forward_generator", "(", "rollouts_list", ",", "advantages_list", ",", "self", ".", "num_mini_batch", ")", "\n", "\n", "# all_samples = [sample for sample in data_generator]", "\n", "\n", "", "for", "sample", "in", "data_generator", ":", "\n", "                ", "obs_batch", ",", "recurrent_hidden_states_batch", ",", "actions_batch", ",", "value_preds_batch", ",", "return_batch", ",", "masks_batch", ",", "old_action_log_probs_batch", ",", "adv_targ", "=", "sample", "\n", "# Reshape to do in a single forward pass for all steps", "\n", "values", ",", "action_log_probs", ",", "dist_entropy", ",", "_", "=", "self", ".", "actor_critic", ".", "evaluate_actions", "(", "obs_batch", ",", "\n", "recurrent_hidden_states_batch", ",", "masks_batch", ",", "actions_batch", ")", "\n", "\n", "ratio", "=", "torch", ".", "exp", "(", "action_log_probs", "-", "old_action_log_probs_batch", ")", "\n", "surr1", "=", "ratio", "*", "adv_targ", "\n", "surr2", "=", "torch", ".", "clamp", "(", "ratio", ",", "1.0", "-", "self", ".", "clip_param", ",", "1.0", "+", "self", ".", "clip_param", ")", "*", "adv_targ", "\n", "action_loss", "=", "-", "torch", ".", "min", "(", "surr1", ",", "surr2", ")", ".", "mean", "(", ")", "\n", "\n", "if", "self", ".", "use_clipped_value_loss", ":", "\n", "                    ", "value_pred_clipped", "=", "value_preds_batch", "+", "(", "values", "-", "value_preds_batch", ")", ".", "clamp", "(", "-", "self", ".", "clip_param", ",", "self", ".", "clip_param", ")", "\n", "value_losses", "=", "(", "values", "-", "return_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_losses_clipped", "=", "(", "value_pred_clipped", "-", "return_batch", ")", ".", "pow", "(", "2", ")", "\n", "value_loss", "=", ".5", "*", "torch", ".", "max", "(", "value_losses", ",", "value_losses_clipped", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                    ", "value_loss", "=", "0.5", "*", "F", ".", "mse_loss", "(", "return_batch", ",", "values", ")", "\n", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "(", "value_loss", "*", "self", ".", "value_loss_coef", "+", "action_loss", "-", "dist_entropy", "*", "self", ".", "entropy_coef", ")", ".", "backward", "(", ")", "\n", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "actor_critic", ".", "parameters", "(", ")", ",", "self", ".", "max_grad_norm", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "value_loss_epoch", "+=", "value_loss", ".", "item", "(", ")", "\n", "action_loss_epoch", "+=", "action_loss", ".", "item", "(", ")", "\n", "dist_entropy_epoch", "+=", "dist_entropy", ".", "item", "(", ")", "\n", "\n", "", "", "num_updates", "=", "self", ".", "ppo_epoch", "*", "self", ".", "num_mini_batch", "\n", "\n", "value_loss_epoch", "/=", "num_updates", "\n", "action_loss_epoch", "/=", "num_updates", "\n", "dist_entropy_epoch", "/=", "num_updates", "\n", "\n", "return", "value_loss_epoch", ",", "action_loss_epoch", ",", "dist_entropy_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.sumitsk_matrl.algo.ppo.magent_feed_forward_generator": [[173, 192], ["int", "torch.utils.data.sampler.BatchSampler", "rollouts_list[].rewards.size", "torch.utils.data.sampler.SubsetRandomSampler", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "rollout.obs[].view", "rollout.recurrent_hidden_states[].view", "rollout.actions.view", "rollout.value_preds[].view", "rollout.returns[].view", "rollout.masks[].view", "rollout.action_log_probs.view", "advantages.view", "rollout.recurrent_hidden_states.size", "rollout.actions.size", "rollout.obs.size"], "function", ["None"], ["", "", "def", "magent_feed_forward_generator", "(", "rollouts_list", ",", "advantages_list", ",", "num_mini_batch", ")", ":", "\n", "    ", "num_steps", ",", "num_processes", "=", "rollouts_list", "[", "0", "]", ".", "rewards", ".", "size", "(", ")", "[", "0", ":", "2", "]", "\n", "batch_size", "=", "num_processes", "*", "num_steps", "\n", "mini_batch_size", "=", "int", "(", "(", "batch_size", "/", "num_mini_batch", ")", ")", "# size of minibatch for each agent", "\n", "sampler", "=", "BatchSampler", "(", "SubsetRandomSampler", "(", "range", "(", "batch_size", ")", ")", ",", "mini_batch_size", ",", "drop_last", "=", "False", ")", "\n", "for", "indices", "in", "sampler", ":", "\n", "        ", "obs_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "obs", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "*", "rollout", ".", "obs", ".", "size", "(", ")", "[", "2", ":", "]", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "recurrent_hidden_states_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "recurrent_hidden_states", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "\n", "rollout", ".", "recurrent_hidden_states", ".", "size", "(", "-", "1", ")", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "actions_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "actions", ".", "view", "(", "-", "1", ",", "\n", "rollout", ".", "actions", ".", "size", "(", "-", "1", ")", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "value_preds_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "value_preds", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "return_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "returns", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "masks_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "masks", "[", ":", "-", "1", "]", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "old_action_log_probs_batch", "=", "torch", ".", "cat", "(", "[", "rollout", ".", "action_log_probs", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "for", "rollout", "in", "rollouts_list", "]", ",", "0", ")", "\n", "adv_targ", "=", "torch", ".", "cat", "(", "[", "advantages", ".", "view", "(", "-", "1", ",", "1", ")", "[", "indices", "]", "for", "advantages", "in", "advantages_list", "]", ",", "0", ")", "\n", "\n", "yield", "obs_batch", ",", "recurrent_hidden_states_batch", ",", "actions_batch", ",", "value_preds_batch", ",", "return_batch", ",", "masks_batch", ",", "old_action_log_probs_batch", ",", "adv_targ", "\n", "\n"]]}