{"home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.get_plot_colors": [[17, 25], ["len", "colorlover.to_rgb", "colorlover.interp", "colorlover.to_numeric"], "function", ["None"], ["def", "get_plot_colors", "(", "max_colors", ",", "color_format", "=", "\"pyplot\"", ")", ":", "\n", "    ", "\"\"\"Generate colors for plotting.\"\"\"", "\n", "colors", "=", "cl", ".", "scales", "[", "\"11\"", "]", "[", "\"qual\"", "]", "[", "\"Paired\"", "]", "\n", "if", "max_colors", ">", "len", "(", "colors", ")", ":", "\n", "        ", "colors", "=", "cl", ".", "to_rgb", "(", "cl", ".", "interp", "(", "colors", ",", "max_colors", ")", ")", "\n", "", "if", "color_format", "==", "\"pyplot\"", ":", "\n", "        ", "return", "[", "[", "j", "/", "255.0", "for", "j", "in", "c", "]", "for", "c", "in", "cl", ".", "to_numeric", "(", "colors", ")", "]", "\n", "", "return", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.prepare_plot_data": [[27, 40], ["zip", "plot_data.append", "len", "pycls.sort_log_data", "pycls.load_log_data", "min"], "function", ["None"], ["", "def", "prepare_plot_data", "(", "log_files", ",", "names", ",", "metric", "=", "\"top1_err\"", ")", ":", "\n", "    ", "\"\"\"Load logs and extract data for plotting error curves.\"\"\"", "\n", "plot_data", "=", "[", "]", "\n", "for", "file", ",", "name", "in", "zip", "(", "log_files", ",", "names", ")", ":", "\n", "        ", "d", ",", "data", "=", "{", "}", ",", "logging", ".", "sort_log_data", "(", "logging", ".", "load_log_data", "(", "file", ")", ")", "\n", "for", "phase", "in", "[", "\"train\"", ",", "\"test\"", "]", ":", "\n", "            ", "x", "=", "data", "[", "phase", "+", "\"_epoch\"", "]", "[", "\"epoch_ind\"", "]", "\n", "y", "=", "data", "[", "phase", "+", "\"_epoch\"", "]", "[", "metric", "]", "\n", "d", "[", "\"x_\"", "+", "phase", "]", ",", "d", "[", "\"y_\"", "+", "phase", "]", "=", "x", ",", "y", "\n", "d", "[", "phase", "+", "\"_label\"", "]", "=", "\"[{:5.2f}] \"", ".", "format", "(", "min", "(", "y", ")", "if", "y", "else", "0", ")", "+", "name", "\n", "", "plot_data", ".", "append", "(", "d", ")", "\n", "", "assert", "len", "(", "plot_data", ")", ">", "0", ",", "\"No data to plot\"", "\n", "return", "plot_data", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.plot_error_curves_plotly": [[42, 113], ["plotting.prepare_plot_data", "plotting.get_plot_colors", "enumerate", "zip", "plotly.Layout", "plotly.plot", "len", "str", "data.append", "data.append", "data.append", "plotly.Scatter", "plotly.Scatter", "plotly.Scatter"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.prepare_plot_data", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.get_plot_colors"], ["", "def", "plot_error_curves_plotly", "(", "log_files", ",", "names", ",", "filename", ",", "metric", "=", "\"top1_err\"", ")", ":", "\n", "    ", "\"\"\"Plot error curves using plotly and save to file.\"\"\"", "\n", "plot_data", "=", "prepare_plot_data", "(", "log_files", ",", "names", ",", "metric", ")", "\n", "colors", "=", "get_plot_colors", "(", "len", "(", "plot_data", ")", ",", "\"plotly\"", ")", "\n", "# Prepare data for plots (3 sets, train duplicated w and w/o legend)", "\n", "data", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "plot_data", ")", ":", "\n", "        ", "s", "=", "str", "(", "i", ")", "\n", "line_train", "=", "{", "\"color\"", ":", "colors", "[", "i", "]", ",", "\"dash\"", ":", "\"dashdot\"", ",", "\"width\"", ":", "1.5", "}", "\n", "line_test", "=", "{", "\"color\"", ":", "colors", "[", "i", "]", ",", "\"dash\"", ":", "\"solid\"", ",", "\"width\"", ":", "1.5", "}", "\n", "data", ".", "append", "(", "\n", "go", ".", "Scatter", "(", "\n", "x", "=", "d", "[", "\"x_train\"", "]", ",", "\n", "y", "=", "d", "[", "\"y_train\"", "]", ",", "\n", "mode", "=", "\"lines\"", ",", "\n", "name", "=", "d", "[", "\"train_label\"", "]", ",", "\n", "line", "=", "line_train", ",", "\n", "legendgroup", "=", "s", ",", "\n", "visible", "=", "True", ",", "\n", "showlegend", "=", "False", ",", "\n", ")", "\n", ")", "\n", "data", ".", "append", "(", "\n", "go", ".", "Scatter", "(", "\n", "x", "=", "d", "[", "\"x_test\"", "]", ",", "\n", "y", "=", "d", "[", "\"y_test\"", "]", ",", "\n", "mode", "=", "\"lines\"", ",", "\n", "name", "=", "d", "[", "\"test_label\"", "]", ",", "\n", "line", "=", "line_test", ",", "\n", "legendgroup", "=", "s", ",", "\n", "visible", "=", "True", ",", "\n", "showlegend", "=", "True", ",", "\n", ")", "\n", ")", "\n", "data", ".", "append", "(", "\n", "go", ".", "Scatter", "(", "\n", "x", "=", "d", "[", "\"x_train\"", "]", ",", "\n", "y", "=", "d", "[", "\"y_train\"", "]", ",", "\n", "mode", "=", "\"lines\"", ",", "\n", "name", "=", "d", "[", "\"train_label\"", "]", ",", "\n", "line", "=", "line_train", ",", "\n", "legendgroup", "=", "s", ",", "\n", "visible", "=", "False", ",", "\n", "showlegend", "=", "True", ",", "\n", ")", "\n", ")", "\n", "# Prepare layout w ability to toggle 'all', 'train', 'test'", "\n", "", "titlefont", "=", "{", "\"size\"", ":", "18", ",", "\"color\"", ":", "\"#7f7f7f\"", "}", "\n", "vis", "=", "[", "[", "True", ",", "True", ",", "False", "]", ",", "[", "False", ",", "False", ",", "True", "]", ",", "[", "False", ",", "True", ",", "False", "]", "]", "\n", "buttons", "=", "zip", "(", "[", "\"all\"", ",", "\"train\"", ",", "\"test\"", "]", ",", "[", "[", "{", "\"visible\"", ":", "v", "}", "]", "for", "v", "in", "vis", "]", ")", "\n", "buttons", "=", "[", "{", "\"label\"", ":", "b", ",", "\"args\"", ":", "v", ",", "\"method\"", ":", "\"update\"", "}", "for", "b", ",", "v", "in", "buttons", "]", "\n", "layout", "=", "go", ".", "Layout", "(", "\n", "title", "=", "metric", "+", "\" vs. epoch<br>[dash=train, solid=test]\"", ",", "\n", "xaxis", "=", "{", "\"title\"", ":", "\"epoch\"", ",", "\"titlefont\"", ":", "titlefont", "}", ",", "\n", "yaxis", "=", "{", "\"title\"", ":", "metric", ",", "\"titlefont\"", ":", "titlefont", "}", ",", "\n", "showlegend", "=", "True", ",", "\n", "hoverlabel", "=", "{", "\"namelength\"", ":", "-", "1", "}", ",", "\n", "updatemenus", "=", "[", "\n", "{", "\n", "\"buttons\"", ":", "buttons", ",", "\n", "\"direction\"", ":", "\"down\"", ",", "\n", "\"showactive\"", ":", "True", ",", "\n", "\"x\"", ":", "1.02", ",", "\n", "\"xanchor\"", ":", "\"left\"", ",", "\n", "\"y\"", ":", "1.08", ",", "\n", "\"yanchor\"", ":", "\"top\"", ",", "\n", "}", "\n", "]", ",", "\n", ")", "\n", "# Create plotly plot", "\n", "offline", ".", "plot", "(", "{", "\"data\"", ":", "data", ",", "\"layout\"", ":", "layout", "}", ",", "filename", "=", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.plot_error_curves_pyplot": [[115, 133], ["plotting.prepare_plot_data", "plotting.get_plot_colors", "enumerate", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.legend", "len", "matplotlib.plot", "matplotlib.plot", "matplotlib.savefig", "matplotlib.clf", "matplotlib.show"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.prepare_plot_data", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.plotting.get_plot_colors"], ["", "def", "plot_error_curves_pyplot", "(", "log_files", ",", "names", ",", "filename", "=", "None", ",", "metric", "=", "\"top1_err\"", ")", ":", "\n", "    ", "\"\"\"Plot error curves using matplotlib.pyplot and save to file.\"\"\"", "\n", "plot_data", "=", "prepare_plot_data", "(", "log_files", ",", "names", ",", "metric", ")", "\n", "colors", "=", "get_plot_colors", "(", "len", "(", "names", ")", ")", "\n", "for", "ind", ",", "d", "in", "enumerate", "(", "plot_data", ")", ":", "\n", "        ", "c", ",", "lbl", "=", "colors", "[", "ind", "]", ",", "d", "[", "\"test_label\"", "]", "\n", "plt", ".", "plot", "(", "d", "[", "\"x_train\"", "]", ",", "d", "[", "\"y_train\"", "]", ",", "\"--\"", ",", "c", "=", "c", ",", "alpha", "=", "0.8", ")", "\n", "plt", ".", "plot", "(", "d", "[", "\"x_test\"", "]", ",", "d", "[", "\"y_test\"", "]", ",", "\"-\"", ",", "c", "=", "c", ",", "alpha", "=", "0.8", ",", "label", "=", "lbl", ")", "\n", "", "plt", ".", "title", "(", "metric", "+", "\" vs. epoch\\n[dash=train, solid=test]\"", ",", "fontsize", "=", "14", ")", "\n", "plt", ".", "xlabel", "(", "\"epoch\"", ",", "fontsize", "=", "14", ")", "\n", "plt", ".", "ylabel", "(", "metric", ",", "fontsize", "=", "14", ")", "\n", "plt", ".", "grid", "(", "alpha", "=", "0.4", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "if", "filename", ":", "\n", "        ", "plt", ".", "savefig", "(", "filename", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging._suppress_print": [[29, 34], ["None"], "function", ["None"], ["def", "_suppress_print", "(", ")", ":", "\n", "    ", "\"\"\"Suppresses printing from the current process.\"\"\"", "\n", "def", "ignore", "(", "*", "_objects", ",", "_sep", "=", "' '", ",", "_end", "=", "'\\n'", ",", "_file", "=", "sys", ".", "stdout", ",", "_flush", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "", "builtins", ".", "print", "=", "ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging": [[36, 59], ["logging.basicConfig", "logging._suppress_print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging._suppress_print"], ["", "def", "setup_logging", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Sets up the logging.\"\"\"", "\n", "# Enable logging only for the master process", "\n", "# if du.is_master_proc():", "\n", "if", "True", ":", "\n", "# Clear the root logger to prevent any existing logging config", "\n", "# (e.g. set by another module) from messing with our setup", "\n", "        ", "logging", ".", "root", ".", "handlers", "=", "[", "]", "\n", "# Construct logging configuration", "\n", "logging_config", "=", "{", "\n", "'level'", ":", "logging", ".", "INFO", ",", "\n", "'format'", ":", "_FORMAT", ",", "\n", "'datefmt'", ":", "'%Y-%m-%d %H:%M:%S'", "\n", "}", "\n", "# Log either to stdout or to a file", "\n", "if", "cfg", ".", "LOG_DEST", "==", "'stdout'", ":", "\n", "            ", "logging_config", "[", "'stream'", "]", "=", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "            ", "logging_config", "[", "'filename'", "]", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EXP_DIR", ",", "_LOG_FILE", ")", "\n", "# Configure logging", "\n", "", "logging", ".", "basicConfig", "(", "**", "logging_config", ")", "\n", "", "else", ":", "\n", "        ", "_suppress_print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.get_logger": [[61, 64], ["logging.getLogger"], "function", ["None"], ["", "", "def", "get_logger", "(", "name", ")", ":", "\n", "    ", "\"\"\"Retrieves the logger.\"\"\"", "\n", "return", "logging", ".", "getLogger", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats": [[66, 76], ["simplejson.dumps", "logging.get_logger", "get_logger.info", "isinstance", "decimal.Decimal", "stats.items"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.get_logger"], ["", "def", "log_json_stats", "(", "stats", ")", ":", "\n", "    ", "\"\"\"Logs json stats.\"\"\"", "\n", "# Decimal + string workaround for having fixed len float vals in logs", "\n", "stats", "=", "{", "\n", "k", ":", "decimal", ".", "Decimal", "(", "'{:.12f}'", ".", "format", "(", "v", ")", ")", "if", "isinstance", "(", "v", ",", "float", ")", "else", "v", "\n", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", "\n", "}", "\n", "json_stats", "=", "simplejson", ".", "dumps", "(", "stats", ",", "sort_keys", "=", "True", ",", "use_decimal", "=", "True", ")", "\n", "logger", "=", "get_logger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "'{:s}{:s}'", ".", "format", "(", "_TAG", ",", "json_stats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.load_json_stats": [[78, 85], ["open", "f.readlines", "simplejson.loads", "l.find", "len"], "function", ["None"], ["", "def", "load_json_stats", "(", "log_file", ")", ":", "\n", "    ", "\"\"\"Loads json_stats from a single log file.\"\"\"", "\n", "with", "open", "(", "log_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "json_lines", "=", "[", "l", "[", "l", ".", "find", "(", "_TAG", ")", "+", "len", "(", "_TAG", ")", ":", "]", "for", "l", "in", "lines", "if", "_TAG", "in", "l", "]", "\n", "json_stats", "=", "[", "simplejson", ".", "loads", "(", "l", ")", "for", "l", "in", "json_lines", "]", "\n", "return", "json_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.parse_json_stats": [[87, 93], ["int", "val.split"], "function", ["None"], ["", "def", "parse_json_stats", "(", "log", ",", "row_type", ",", "key", ")", ":", "\n", "    ", "\"\"\"Extract values corresponding to row_type/key out of log.\"\"\"", "\n", "vals", "=", "[", "row", "[", "key", "]", "for", "row", "in", "log", "if", "row", "[", "'_type'", "]", "==", "row_type", "and", "key", "in", "row", "]", "\n", "if", "key", "==", "'iter'", "or", "key", "==", "'epoch'", ":", "\n", "        ", "vals", "=", "[", "int", "(", "val", ".", "split", "(", "'/'", ")", "[", "0", "]", ")", "for", "val", "in", "vals", "]", "\n", "", "return", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.get_log_files": [[95, 102], ["zip", "os.path.join", "sorted", "zip", "os.path.exists", "os.listdir"], "function", ["None"], ["", "def", "get_log_files", "(", "log_dir", ",", "name_filter", "=", "''", ")", ":", "\n", "    ", "\"\"\"Get all log files in directory containing subdirs of trained models.\"\"\"", "\n", "names", "=", "[", "n", "for", "n", "in", "sorted", "(", "os", ".", "listdir", "(", "log_dir", ")", ")", "if", "name_filter", "in", "n", "]", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "log_dir", ",", "n", ",", "_LOG_FILE", ")", "for", "n", "in", "names", "]", "\n", "f_n_ps", "=", "[", "(", "f", ",", "n", ")", "for", "(", "f", ",", "n", ")", "in", "zip", "(", "files", ",", "names", ")", "if", "os", ".", "path", ".", "exists", "(", "f", ")", "]", "\n", "files", ",", "names", "=", "zip", "(", "*", "f_n_ps", ")", "\n", "return", "files", ",", "names", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ChildException.__init__": [[80, 82], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "child_trace", ")", ":", "\n", "        ", "super", "(", "ChildException", ",", "self", ")", ".", "__init__", "(", "child_trace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ErrorHandler.__init__": [[90, 100], ["threading.Thread", "distributed.ErrorHandler.error_listener.start", "signal.signal"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "# Shared error queue", "\n", "        ", "self", ".", "error_queue", "=", "error_queue", "\n", "# Children processes sharing the error queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "# Start a thread listening to errors", "\n", "self", ".", "error_listener", "=", "threading", ".", "Thread", "(", "target", "=", "self", ".", "listen", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_listener", ".", "start", "(", ")", "\n", "# Register the signal handler", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ErrorHandler.add_child": [[101, 104], ["distributed.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\"Registers a child process.\"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ErrorHandler.listen": [[105, 113], ["distributed.ErrorHandler.error_queue.get", "distributed.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "listen", "(", "self", ")", ":", "\n", "        ", "\"\"\"Listens for errors in the error queue.\"\"\"", "\n", "# Wait until there is an error in the queue", "\n", "child_trace", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "# Put the error back for the signal handler", "\n", "self", ".", "error_queue", ".", "put", "(", "child_trace", ")", "\n", "# Invoke the signal handler", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ErrorHandler.signal_handler": [[114, 121], ["distributed.ChildException", "os.kill", "distributed.ErrorHandler.error_queue.get"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "_sig_num", ",", "_stack_frame", ")", ":", "\n", "        ", "\"\"\"Signal handler.\"\"\"", "\n", "# Kill children processes", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "\n", "# Propagate the error from the child process", "\n", "", "raise", "ChildException", "(", "self", ".", "error_queue", ".", "get", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.is_master_proc": [[25, 33], ["torch.distributed.get_rank"], "function", ["None"], ["def", "is_master_proc", "(", ")", ":", "\n", "    ", "\"\"\"Determines if the current process is the master process.\n\n    Master process is responsible for logging, writing and loading checkpoints. In\n    the multi GPU setting, we assign the master role to the rank 0 process. When\n    training using a single GPU, there is a single process which is considered master.\n    \"\"\"", "\n", "return", "cfg", ".", "NUM_GPUS", "==", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.init_process_group": [[35, 45], ["torch.cuda.set_device", "torch.distributed.init_process_group"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.init_process_group"], ["", "def", "init_process_group", "(", "proc_rank", ",", "world_size", ",", "port", ")", ":", "\n", "    ", "\"\"\"Initializes the default process group.\"\"\"", "\n", "# Set the GPU to use", "\n", "torch", ".", "cuda", ".", "set_device", "(", "proc_rank", ")", "\n", "# Initialize the process group", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "cfg", ".", "DIST_BACKEND", ",", "\n", "init_method", "=", "\"tcp://{}:{}\"", ".", "format", "(", "cfg", ".", "HOST", ",", "port", ")", ",", "\n", "world_size", "=", "world_size", ",", "\n", "rank", "=", "proc_rank", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.destroy_process_group": [[48, 51], ["torch.distributed.destroy_process_group"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.destroy_process_group"], ["", "def", "destroy_process_group", "(", ")", ":", "\n", "    ", "\"\"\"Destroys the default process group.\"\"\"", "\n", "torch", ".", "distributed", ".", "destroy_process_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.scaled_all_reduce": [[53, 75], ["torch.distributed.all_reduce", "reductions.append", "torch.distributed.all_reduce.wait", "tensor.mul_"], "function", ["None"], ["", "def", "scaled_all_reduce", "(", "tensors", ")", ":", "\n", "    ", "\"\"\"Performs the scaled all_reduce operation on the provided tensors.\n\n    The input tensors are modified in-place. Currently supports only the sum\n    reduction operator. The reduced values are scaled by the inverse size of the\n    process group (equivalent to cfg.NUM_GPUS).\n    \"\"\"", "\n", "# There is no need for reduction in the single-proc case", "\n", "if", "cfg", ".", "NUM_GPUS", "==", "1", ":", "\n", "        ", "return", "tensors", "\n", "# Queue the reductions", "\n", "", "reductions", "=", "[", "]", "\n", "for", "tensor", "in", "tensors", ":", "\n", "        ", "reduction", "=", "torch", ".", "distributed", ".", "all_reduce", "(", "tensor", ",", "async_op", "=", "True", ")", "\n", "reductions", ".", "append", "(", "reduction", ")", "\n", "# Wait for reductions to finish", "\n", "", "for", "reduction", "in", "reductions", ":", "\n", "        ", "reduction", ".", "wait", "(", ")", "\n", "# Scale the results", "\n", "", "for", "tensor", "in", "tensors", ":", "\n", "        ", "tensor", ".", "mul_", "(", "1.0", "/", "cfg", ".", "NUM_GPUS", ")", "\n", "", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.run": [[123, 139], ["distributed.init_process_group", "fun", "distributed.destroy_process_group", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.init_process_group", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.destroy_process_group"], ["", "", "def", "run", "(", "proc_rank", ",", "world_size", ",", "port", ",", "error_queue", ",", "fun", ",", "fun_args", ",", "fun_kwargs", ")", ":", "\n", "    ", "\"\"\"Runs a function from a child process.\"\"\"", "\n", "try", ":", "\n", "# Initialize the process group", "\n", "        ", "init_process_group", "(", "proc_rank", ",", "world_size", ",", "port", ")", "\n", "# Run the function", "\n", "fun", "(", "*", "fun_args", ",", "**", "fun_kwargs", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "# Killed by the parent process", "\n", "        ", "pass", "\n", "", "except", "Exception", ":", "\n", "# Propagate exception to the parent process", "\n", "        ", "error_queue", ".", "put", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "", "finally", ":", "\n", "# Destroy the process group", "\n", "        ", "destroy_process_group", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.multi_proc_run": [[141, 165], ["multiprocessing.SimpleQueue", "distributed.ErrorHandler", "random.Random().randint", "range", "fun", "multiprocessing.Process", "ps.append", "multiprocessing.Process.start", "distributed.ErrorHandler.add_child", "p.join", "random.Random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.distributed.ErrorHandler.add_child"], ["", "", "def", "multi_proc_run", "(", "num_proc", ",", "fun", ",", "fun_args", "=", "(", ")", ",", "fun_kwargs", "=", "None", ")", ":", "\n", "    ", "\"\"\"Runs a function in a multi-proc setting (unless num_proc == 1).\"\"\"", "\n", "# There is no need for multi-proc in the single-proc case", "\n", "fun_kwargs", "=", "fun_kwargs", "if", "fun_kwargs", "else", "{", "}", "\n", "if", "num_proc", "==", "1", ":", "\n", "        ", "fun", "(", "*", "fun_args", ",", "**", "fun_kwargs", ")", "\n", "return", "\n", "# Handle errors from training subprocesses", "\n", "", "error_queue", "=", "multiprocessing", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "# Get a random port to use (without using global random number generator)", "\n", "port", "=", "random", ".", "Random", "(", ")", ".", "randint", "(", "cfg", ".", "PORT_RANGE", "[", "0", "]", ",", "cfg", ".", "PORT_RANGE", "[", "1", "]", ")", "\n", "# Run each training subprocess", "\n", "ps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_proc", ")", ":", "\n", "        ", "p_i", "=", "multiprocessing", ".", "Process", "(", "\n", "target", "=", "run", ",", "args", "=", "(", "i", ",", "num_proc", ",", "port", ",", "error_queue", ",", "fun", ",", "fun_args", ",", "fun_kwargs", ")", "\n", ")", "\n", "ps", ".", "append", "(", "p_i", ")", "\n", "p_i", ".", "start", "(", ")", "\n", "error_handler", ".", "add_child", "(", "p_i", ".", "pid", ")", "\n", "# Wait for each subprocess to finish", "\n", "", "for", "p", "in", "ps", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.io.cache_url": [[22, 40], ["url.startswith", "url.replace", "os.path.exists", "os.path.dirname", "logger.info", "io.download_url", "re.match", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.io.download_url"], ["def", "cache_url", "(", "url_or_file", ",", "cache_dir", ",", "base_url", "=", "_PYCLS_BASE_URL", ")", ":", "\n", "    ", "\"\"\"Download the file specified by the URL to the cache_dir and return the path to\n    the cached file. If the argument is not a URL, simply return it as is.\n    \"\"\"", "\n", "is_url", "=", "re", ".", "match", "(", "r\"^(?:http)s?://\"", ",", "url_or_file", ",", "re", ".", "IGNORECASE", ")", "is", "not", "None", "\n", "if", "not", "is_url", ":", "\n", "        ", "return", "url_or_file", "\n", "", "url", "=", "url_or_file", "\n", "assert", "url", ".", "startswith", "(", "base_url", ")", ",", "\"url must start with: {}\"", ".", "format", "(", "base_url", ")", "\n", "cache_file_path", "=", "url", ".", "replace", "(", "base_url", ",", "cache_dir", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file_path", ")", ":", "\n", "        ", "return", "cache_file_path", "\n", "", "cache_file_dir", "=", "os", ".", "path", ".", "dirname", "(", "cache_file_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_file_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_file_dir", ")", "\n", "", "logger", ".", "info", "(", "\"Downloading remote file {} to {}\"", ".", "format", "(", "url", ",", "cache_file_path", ")", ")", "\n", "download_url", "(", "url", ",", "cache_file_path", ")", "\n", "return", "cache_file_path", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.io._progress_bar": [[42, 56], ["int", "round", "sys.stdout.write", "sys.stdout.flush", "round", "sys.stdout.write", "float", "float"], "function", ["None"], ["", "def", "_progress_bar", "(", "count", ",", "total", ")", ":", "\n", "    ", "\"\"\"Report download progress. Credit:\n    https://stackoverflow.com/questions/3173320/text-progress-bar-in-the-console/27871113\n    \"\"\"", "\n", "bar_len", "=", "60", "\n", "filled_len", "=", "int", "(", "round", "(", "bar_len", "*", "count", "/", "float", "(", "total", ")", ")", ")", "\n", "percents", "=", "round", "(", "100.0", "*", "count", "/", "float", "(", "total", ")", ",", "1", ")", "\n", "bar", "=", "\"=\"", "*", "filled_len", "+", "\"-\"", "*", "(", "bar_len", "-", "filled_len", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "\n", "\"  [{}] {}% of {:.1f}MB file  \\r\"", ".", "format", "(", "bar", ",", "percents", ",", "total", "/", "1024", "/", "1024", ")", "\n", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "count", ">=", "total", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.io.download_url": [[58, 77], ["urllib.request.Request", "urllib.request.urlopen", "urlrequest.urlopen.info().get().strip", "int", "open", "urlrequest.urlopen.info().get", "urlrequest.urlopen.read", "len", "f.write", "progress_hook", "urlrequest.urlopen.info"], "function", ["None"], ["", "", "def", "download_url", "(", "url", ",", "dst_file_path", ",", "chunk_size", "=", "8192", ",", "progress_hook", "=", "_progress_bar", ")", ":", "\n", "    ", "\"\"\"Download url and write it to dst_file_path. Credit:\n    https://stackoverflow.com/questions/2028517/python-urllib2-progress-hook\n    \"\"\"", "\n", "req", "=", "urlrequest", ".", "Request", "(", "url", ")", "\n", "response", "=", "urlrequest", ".", "urlopen", "(", "req", ")", "\n", "total_size", "=", "response", ".", "info", "(", ")", ".", "get", "(", "\"Content-Length\"", ")", ".", "strip", "(", ")", "\n", "total_size", "=", "int", "(", "total_size", ")", "\n", "bytes_so_far", "=", "0", "\n", "with", "open", "(", "dst_file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "while", "1", ":", "\n", "            ", "chunk", "=", "response", ".", "read", "(", "chunk_size", ")", "\n", "bytes_so_far", "+=", "len", "(", "chunk", ")", "\n", "if", "not", "chunk", ":", "\n", "                ", "break", "\n", "", "if", "progress_hook", ":", "\n", "                ", "progress_hook", "(", "bytes_so_far", ",", "total_size", ")", "\n", "", "f", ".", "write", "(", "chunk", ")", "\n", "", "", "return", "bytes_so_far", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topks_correct": [[20, 39], ["torch.topk", "torch.topk", "top_max_k_inds.t.t", "labels.view().expand_as", "top_max_k_inds.t.eq", "preds.size", "labels.size", "max", "top_max_k_correct[].reshape().float().sum", "labels.view", "top_max_k_correct[].reshape().float", "top_max_k_correct[].reshape"], "function", ["None"], ["def", "topks_correct", "(", "preds", ",", "labels", ",", "ks", ")", ":", "\n", "    ", "\"\"\"Computes the number of top-k correct predictions for each k.\"\"\"", "\n", "assert", "preds", ".", "size", "(", "0", ")", "==", "labels", ".", "size", "(", "0", ")", ",", "'Batch dim of predictions and labels must match'", "\n", "# Find the top max_k predictions for each sample", "\n", "_top_max_k_vals", ",", "top_max_k_inds", "=", "torch", ".", "topk", "(", "\n", "preds", ",", "max", "(", "ks", ")", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", "\n", ")", "\n", "# (batch_size, max_k) -> (max_k, batch_size)", "\n", "top_max_k_inds", "=", "top_max_k_inds", ".", "t", "(", ")", "\n", "# (batch_size, ) -> (max_k, batch_size)", "\n", "rep_max_k_labels", "=", "labels", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "top_max_k_inds", ")", "\n", "# (i, j) = 1 if top i-th prediction for the j-th sample is correct", "\n", "top_max_k_correct", "=", "top_max_k_inds", ".", "eq", "(", "rep_max_k_labels", ")", "\n", "# Compute the number of topk correct predictions for each k", "\n", "topks_correct", "=", "[", "\n", "top_max_k_correct", "[", ":", "k", ",", ":", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "for", "k", "in", "ks", "\n", "]", "\n", "return", "topks_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors": [[41, 45], ["metrics.topks_correct", "preds.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topks_correct"], ["", "def", "topk_errors", "(", "preds", ",", "labels", ",", "ks", ")", ":", "\n", "    ", "\"\"\"Computes the top-k error for each k.\"\"\"", "\n", "num_topks_correct", "=", "topks_correct", "(", "preds", ",", "labels", ",", "ks", ")", "\n", "return", "[", "(", "1.0", "-", "x", "/", "preds", ".", "size", "(", "0", ")", ")", "*", "100.0", "for", "x", "in", "num_topks_correct", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_accuracies": [[47, 51], ["metrics.topks_correct", "preds.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topks_correct"], ["", "def", "topk_accuracies", "(", "preds", ",", "labels", ",", "ks", ")", ":", "\n", "    ", "\"\"\"Computes the top-k accuracy for each k.\"\"\"", "\n", "num_topks_correct", "=", "topks_correct", "(", "preds", ",", "labels", ",", "ks", ")", "\n", "return", "[", "(", "x", "/", "preds", ".", "size", "(", "0", ")", ")", "*", "100.0", "for", "x", "in", "num_topks_correct", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.params_count": [[53, 56], ["numpy.sum().item", "numpy.sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "params_count", "(", "model", ")", ":", "\n", "    ", "\"\"\"Computes the number of parameters.\"\"\"", "\n", "return", "np", ".", "sum", "(", "[", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.flops_count": [[58, 81], ["model.named_modules", "count.item", "isinstance", "numpy.prod", "isinstance", "isinstance", "m.bias.numel", "m.weight.numel"], "function", ["None"], ["", "def", "flops_count", "(", "model", ")", ":", "\n", "    ", "\"\"\"Computes the number of flops statically.\"\"\"", "\n", "h", ",", "w", "=", "cfg", ".", "TRAIN", ".", "IM_SIZE", ",", "cfg", ".", "TRAIN", ".", "IM_SIZE", "\n", "count", "=", "0", "\n", "for", "n", ",", "m", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "if", "'se.'", "in", "n", ":", "\n", "                ", "count", "+=", "m", ".", "in_channels", "*", "m", ".", "out_channels", "+", "m", ".", "bias", ".", "numel", "(", ")", "\n", "continue", "\n", "", "h_out", "=", "(", "h", "+", "2", "*", "m", ".", "padding", "[", "0", "]", "-", "m", ".", "kernel_size", "[", "0", "]", ")", "//", "m", ".", "stride", "[", "0", "]", "+", "1", "\n", "w_out", "=", "(", "w", "+", "2", "*", "m", ".", "padding", "[", "1", "]", "-", "m", ".", "kernel_size", "[", "1", "]", ")", "//", "m", ".", "stride", "[", "1", "]", "+", "1", "\n", "count", "+=", "np", ".", "prod", "(", "[", "\n", "m", ".", "weight", ".", "numel", "(", ")", ",", "\n", "h_out", ",", "w_out", "\n", "]", ")", "\n", "if", "'.proj'", "not", "in", "n", ":", "\n", "                ", "h", ",", "w", "=", "h_out", ",", "w_out", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "MaxPool2d", ")", ":", "\n", "            ", "h", "=", "(", "h", "+", "2", "*", "m", ".", "padding", "-", "m", ".", "kernel_size", ")", "//", "m", ".", "stride", "+", "1", "\n", "w", "=", "(", "w", "+", "2", "*", "m", ".", "padding", "-", "m", ".", "kernel_size", ")", "//", "m", ".", "stride", "+", "1", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "count", "+=", "m", ".", "in_features", "*", "m", ".", "out_features", "\n", "", "", "return", "count", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage": [[83, 87], ["torch.cuda.max_memory_allocated", "torch.cuda.max_memory_allocated"], "function", ["None"], ["", "def", "gpu_mem_usage", "(", ")", ":", "\n", "    ", "\"\"\"Computes the GPU memory usage for the current device (MB).\"\"\"", "\n", "mem_usage_bytes", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "\n", "return", "mem_usage_bytes", "/", "_B_IN_MB", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.__init__": [[16, 23], ["timer.Timer.reset"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "total_time", "=", "None", "\n", "self", ".", "calls", "=", "None", "\n", "self", ".", "start_time", "=", "None", "\n", "self", ".", "diff", "=", "None", "\n", "self", ".", "average_time", "=", "None", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic": [[24, 27], ["time.time"], "methods", ["None"], ["", "def", "tic", "(", "self", ")", ":", "\n", "# using time.time as time.clock does not normalize for multithreading", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc": [[28, 33], ["time.time"], "methods", ["None"], ["", "def", "toc", "(", "self", ")", ":", "\n", "        ", "self", ".", "diff", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "total_time", "+=", "self", ".", "diff", "\n", "self", ".", "calls", "+=", "1", "\n", "self", ".", "average_time", "=", "self", ".", "total_time", "/", "self", ".", "calls", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.reset": [[34, 40], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "total_time", "=", "0.0", "\n", "self", ".", "calls", "=", "0", "\n", "self", ".", "start_time", "=", "0.0", "\n", "self", ".", "diff", "=", "0.0", "\n", "self", ".", "average_time", "=", "0.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.init_weights": [[18, 34], ["isinstance", "m.weight.data.normal_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "math.sqrt", "hasattr", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["None"], ["def", "init_weights", "(", "m", ")", ":", "\n", "    ", "\"\"\"Performs ResNet-style weight initialization.\"\"\"", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "# Note that there is no bias due to BN", "\n", "        ", "fan_out", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "math", ".", "sqrt", "(", "2.0", "/", "fan_out", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "zero_init_gamma", "=", "(", "\n", "hasattr", "(", "m", ",", "'final_bn'", ")", "and", "m", ".", "final_bn", "and", "\n", "cfg", ".", "BN", ".", "ZERO_INIT_FINAL_GAMMA", "\n", ")", "\n", "m", ".", "weight", ".", "data", ".", "fill_", "(", "0.0", "if", "zero_init_gamma", "else", "1.0", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.compute_precise_bn_stats": [[36, 64], ["torch.no_grad", "torch.no_grad", "min", "itertools.islice", "enumerate", "len", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "model", "enumerate", "model.modules", "isinstance", "inputs.cuda"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_precise_bn_stats", "(", "model", ",", "loader", ")", ":", "\n", "    ", "\"\"\"Computes precise BN stats on training data.\"\"\"", "\n", "# Compute the number of minibatches to use", "\n", "num_iter", "=", "min", "(", "cfg", ".", "BN", ".", "NUM_SAMPLES_PRECISE", "//", "loader", ".", "batch_size", ",", "len", "(", "loader", ")", ")", "\n", "# Retrieve the BN layers", "\n", "bns", "=", "[", "m", "for", "m", "in", "model", ".", "modules", "(", ")", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", "]", "\n", "# Initialize stats storage", "\n", "mus", "=", "[", "torch", ".", "zeros_like", "(", "bn", ".", "running_mean", ")", "for", "bn", "in", "bns", "]", "\n", "sqs", "=", "[", "torch", ".", "zeros_like", "(", "bn", ".", "running_var", ")", "for", "bn", "in", "bns", "]", "\n", "# Remember momentum values", "\n", "moms", "=", "[", "bn", ".", "momentum", "for", "bn", "in", "bns", "]", "\n", "# Disable momentum", "\n", "for", "bn", "in", "bns", ":", "\n", "        ", "bn", ".", "momentum", "=", "1.0", "\n", "# Accumulate the stats across the data samples", "\n", "", "for", "inputs", ",", "_labels", "in", "itertools", ".", "islice", "(", "loader", ",", "num_iter", ")", ":", "\n", "        ", "model", "(", "inputs", ".", "cuda", "(", ")", ")", "\n", "# Accumulate the stats for each BN layer", "\n", "for", "i", ",", "bn", "in", "enumerate", "(", "bns", ")", ":", "\n", "            ", "m", ",", "v", "=", "bn", ".", "running_mean", ",", "bn", ".", "running_var", "\n", "sqs", "[", "i", "]", "+=", "(", "v", "+", "m", "*", "m", ")", "/", "num_iter", "\n", "mus", "[", "i", "]", "+=", "m", "/", "num_iter", "\n", "# Set the stats and restore momentum values", "\n", "", "", "for", "i", ",", "bn", "in", "enumerate", "(", "bns", ")", ":", "\n", "        ", "bn", ".", "running_var", "=", "sqs", "[", "i", "]", "-", "mus", "[", "i", "]", "*", "mus", "[", "i", "]", "\n", "bn", ".", "running_mean", "=", "mus", "[", "i", "]", "\n", "bn", ".", "momentum", "=", "moms", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.reset_bn_stats": [[66, 71], ["model.modules", "isinstance", "m.reset_running_stats"], "function", ["None"], ["", "", "def", "reset_bn_stats", "(", "model", ")", ":", "\n", "    ", "\"\"\"Resets running BN stats.\"\"\"", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "m", ".", "reset_running_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.drop_connect": [[73, 81], ["torch.empty", "torch.empty", "torch.empty.bernoulli_", "x.div_", "x.mul_"], "function", ["None"], ["", "", "", "def", "drop_connect", "(", "x", ",", "drop_ratio", ")", ":", "\n", "    ", "\"\"\"Drop connect (adapted from DARTS).\"\"\"", "\n", "keep_ratio", "=", "1.0", "-", "drop_ratio", "\n", "mask", "=", "torch", ".", "empty", "(", "[", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "mask", ".", "bernoulli_", "(", "keep_ratio", ")", "\n", "x", ".", "div_", "(", "keep_ratio", ")", "\n", "x", ".", "mul_", "(", "mask", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.get_flat_weights": [[83, 86], ["torch.cat", "torch.cat", "p.data.view", "model.parameters"], "function", ["None"], ["", "def", "get_flat_weights", "(", "model", ")", ":", "\n", "    ", "\"\"\"Gets all model weights as a single flat vector.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "p", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.set_flat_weights": [[88, 96], ["model.parameters", "p.data.numel", "p.data.copy_", "flat_weights.numel", "flat_weights[].view_as"], "function", ["None"], ["", "def", "set_flat_weights", "(", "model", ",", "flat_weights", ")", ":", "\n", "    ", "\"\"\"Sets all model weights from a single flat vector.\"\"\"", "\n", "k", "=", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "n", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "p", ".", "data", ".", "copy_", "(", "flat_weights", "[", "k", ":", "(", "k", "+", "n", ")", "]", ".", "view_as", "(", "p", ".", "data", ")", ")", "\n", "k", "+=", "n", "\n", "", "assert", "k", "==", "flat_weights", ".", "numel", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_eval": [[22, 43], ["torch.no_grad", "torch.no_grad", "model.eval", "torch.zeros().cuda", "torch.zeros().cuda", "pycls.core.timer.Timer", "range", "int", "pycls.core.timer.Timer.tic", "model", "torch.cuda.synchronize", "torch.cuda.synchronize", "pycls.core.timer.Timer.toc", "torch.zeros", "torch.zeros", "pycls.core.timer.Timer.reset"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "compute_time_eval", "(", "model", ")", ":", "\n", "    ", "\"\"\"Computes precise model forward test time using dummy data.\"\"\"", "\n", "# Use eval mode", "\n", "model", ".", "eval", "(", ")", "\n", "# Generate a dummy mini-batch and copy data to GPU", "\n", "im_size", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "IM_SIZE", ",", "int", "(", "cfg", ".", "TEST", ".", "BATCH_SIZE", "/", "cfg", ".", "NUM_GPUS", ")", "\n", "inputs", "=", "torch", ".", "zeros", "(", "batch_size", ",", "3", ",", "im_size", ",", "im_size", ")", ".", "cuda", "(", "non_blocking", "=", "False", ")", "\n", "# Compute precise forward pass time", "\n", "timer", "=", "Timer", "(", ")", "\n", "total_iter", "=", "cfg", ".", "PREC_TIME", ".", "NUM_ITER", "+", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", "\n", "for", "cur_iter", "in", "range", "(", "total_iter", ")", ":", "\n", "# Reset the timers after the warmup phase", "\n", "        ", "if", "cur_iter", "==", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", ":", "\n", "            ", "timer", ".", "reset", "(", ")", "\n", "# Forward", "\n", "", "timer", ".", "tic", "(", ")", "\n", "model", "(", "inputs", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "timer", ".", "toc", "(", ")", "\n", "", "return", "timer", ".", "average_time", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_train": [[45, 83], ["model.train", "torch.rand().cuda", "torch.rand().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "pycls.smooth_one_hot_labels", "torch.GradScaler", "range", "zip", "int", "pycls.core.timer.Timer", "pycls.core.timer.Timer", "fw_timer.tic", "torch.cuda.synchronize", "torch.cuda.synchronize", "fw_timer.toc", "bw_timer.tic", "amp.GradScaler.scale().backward", "torch.cuda.synchronize", "torch.cuda.synchronize", "bw_timer.toc", "torch.rand", "torch.rand", "torch.zeros", "torch.zeros", "model.modules", "isinstance", "bn.running_mean.clone", "bn.running_var.clone", "fw_timer.reset", "bw_timer.reset", "torch.autocast", "model", "loss_fun", "amp.GradScaler.scale"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.smooth_one_hot_labels", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["", "def", "compute_time_train", "(", "model", ",", "loss_fun", ")", ":", "\n", "    ", "\"\"\"Computes precise model forward + backward time using dummy data.\"\"\"", "\n", "# Use train mode", "\n", "model", ".", "train", "(", ")", "\n", "# Generate a dummy mini-batch and copy data to GPU", "\n", "im_size", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "IM_SIZE", ",", "int", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "cfg", ".", "NUM_GPUS", ")", "\n", "inputs", "=", "torch", ".", "rand", "(", "batch_size", ",", "3", ",", "im_size", ",", "im_size", ")", ".", "cuda", "(", "non_blocking", "=", "False", ")", "\n", "labels", "=", "torch", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "cuda", "(", "non_blocking", "=", "False", ")", "\n", "labels_one_hot", "=", "net", ".", "smooth_one_hot_labels", "(", "labels", ")", "\n", "# Cache BatchNorm2D running stats", "\n", "bns", "=", "[", "m", "for", "m", "in", "model", ".", "modules", "(", ")", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", "]", "\n", "bn_stats", "=", "[", "[", "bn", ".", "running_mean", ".", "clone", "(", ")", ",", "bn", ".", "running_var", ".", "clone", "(", ")", "]", "for", "bn", "in", "bns", "]", "\n", "# Create a GradScaler for mixed precision training", "\n", "scaler", "=", "amp", ".", "GradScaler", "(", "enabled", "=", "cfg", ".", "TRAIN", ".", "MIXED_PRECISION", ")", "\n", "# Compute precise forward backward pass time", "\n", "fw_timer", ",", "bw_timer", "=", "Timer", "(", ")", ",", "Timer", "(", ")", "\n", "total_iter", "=", "cfg", ".", "PREC_TIME", ".", "NUM_ITER", "+", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", "\n", "for", "cur_iter", "in", "range", "(", "total_iter", ")", ":", "\n", "# Reset the timers after the warmup phase", "\n", "        ", "if", "cur_iter", "==", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", ":", "\n", "            ", "fw_timer", ".", "reset", "(", ")", "\n", "bw_timer", ".", "reset", "(", ")", "\n", "# Forward", "\n", "", "fw_timer", ".", "tic", "(", ")", "\n", "with", "amp", ".", "autocast", "(", "enabled", "=", "cfg", ".", "TRAIN", ".", "MIXED_PRECISION", ")", ":", "\n", "            ", "preds", "=", "model", "(", "inputs", ")", "\n", "loss", "=", "loss_fun", "(", "preds", ",", "labels_one_hot", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "fw_timer", ".", "toc", "(", ")", "\n", "# Backward", "\n", "bw_timer", ".", "tic", "(", ")", "\n", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "bw_timer", ".", "toc", "(", ")", "\n", "# Restore BatchNorm2D running stats", "\n", "", "for", "bn", ",", "(", "mean", ",", "var", ")", "in", "zip", "(", "bns", ",", "bn_stats", ")", ":", "\n", "        ", "bn", ".", "running_mean", ",", "bn", ".", "running_var", "=", "mean", ",", "var", "\n", "", "return", "fw_timer", ".", "average_time", ",", "bw_timer", ".", "average_time", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_loader": [[85, 99], ["pycls.core.timer.Timer", "pycls.shuffle", "iter", "min", "range", "len", "pycls.core.timer.Timer.tic", "next", "pycls.core.timer.Timer.toc", "pycls.core.timer.Timer.reset"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["", "def", "compute_time_loader", "(", "data_loader", ")", ":", "\n", "    ", "\"\"\"Computes loader time.\"\"\"", "\n", "timer", "=", "Timer", "(", ")", "\n", "loader", ".", "shuffle", "(", "data_loader", ",", "0", ")", "\n", "data_loader_iterator", "=", "iter", "(", "data_loader", ")", "\n", "total_iter", "=", "cfg", ".", "PREC_TIME", ".", "NUM_ITER", "+", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", "\n", "total_iter", "=", "min", "(", "total_iter", ",", "len", "(", "data_loader", ")", ")", "\n", "for", "cur_iter", "in", "range", "(", "total_iter", ")", ":", "\n", "        ", "if", "cur_iter", "==", "cfg", ".", "PREC_TIME", ".", "WARMUP_ITER", ":", "\n", "            ", "timer", ".", "reset", "(", ")", "\n", "", "timer", ".", "tic", "(", ")", "\n", "next", "(", "data_loader_iterator", ")", "\n", "timer", ".", "toc", "(", ")", "\n", "", "return", "timer", ".", "average_time", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_model": [[101, 116], ["logger.info", "benchmark.compute_time_eval", "benchmark.compute_time_train", "logger.info", "pycls.dump_log_data"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_eval", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_train"], ["", "def", "compute_time_model", "(", "model", ",", "loss_fun", ")", ":", "\n", "    ", "\"\"\"Times model.\"\"\"", "\n", "logger", ".", "info", "(", "\"Computing model timings only...\"", ")", "\n", "# Compute timings", "\n", "test_fw_time", "=", "compute_time_eval", "(", "model", ")", "\n", "train_fw_time", ",", "train_bw_time", "=", "compute_time_train", "(", "model", ",", "loss_fun", ")", "\n", "train_fw_bw_time", "=", "train_fw_time", "+", "train_bw_time", "\n", "# Output iter timing", "\n", "iter_times", "=", "{", "\n", "\"test_fw_time\"", ":", "test_fw_time", ",", "\n", "\"train_fw_time\"", ":", "train_fw_time", ",", "\n", "\"train_bw_time\"", ":", "train_bw_time", ",", "\n", "\"train_fw_bw_time\"", ":", "train_fw_bw_time", ",", "\n", "}", "\n", "logger", ".", "info", "(", "logging", ".", "dump_log_data", "(", "iter_times", ",", "\"iter_times\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_full": [[118, 147], ["logger.info", "benchmark.compute_time_eval", "benchmark.compute_time_train", "benchmark.compute_time_loader", "logger.info", "logger.info", "logger.info", "pycls.dump_log_data", "pycls.dump_log_data", "max", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_eval", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_train", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.benchmark.compute_time_loader"], ["", "def", "compute_time_full", "(", "model", ",", "loss_fun", ",", "train_loader", ",", "test_loader", ")", ":", "\n", "    ", "\"\"\"Times model and data loader.\"\"\"", "\n", "logger", ".", "info", "(", "\"Computing model and loader timings...\"", ")", "\n", "# Compute timings", "\n", "test_fw_time", "=", "compute_time_eval", "(", "model", ")", "\n", "train_fw_time", ",", "train_bw_time", "=", "compute_time_train", "(", "model", ",", "loss_fun", ")", "\n", "train_fw_bw_time", "=", "train_fw_time", "+", "train_bw_time", "\n", "train_loader_time", "=", "compute_time_loader", "(", "train_loader", ")", "\n", "# Output iter timing", "\n", "iter_times", "=", "{", "\n", "\"test_fw_time\"", ":", "test_fw_time", ",", "\n", "\"train_fw_time\"", ":", "train_fw_time", ",", "\n", "\"train_bw_time\"", ":", "train_bw_time", ",", "\n", "\"train_fw_bw_time\"", ":", "train_fw_bw_time", ",", "\n", "\"train_loader_time\"", ":", "train_loader_time", ",", "\n", "}", "\n", "logger", ".", "info", "(", "logging", ".", "dump_log_data", "(", "iter_times", ",", "\"iter_times\"", ")", ")", "\n", "# Output epoch timing", "\n", "epoch_times", "=", "{", "\n", "\"test_fw_time\"", ":", "test_fw_time", "*", "len", "(", "test_loader", ")", ",", "\n", "\"train_fw_time\"", ":", "train_fw_time", "*", "len", "(", "train_loader", ")", ",", "\n", "\"train_bw_time\"", ":", "train_bw_time", "*", "len", "(", "train_loader", ")", ",", "\n", "\"train_fw_bw_time\"", ":", "train_fw_bw_time", "*", "len", "(", "train_loader", ")", ",", "\n", "\"train_loader_time\"", ":", "train_loader_time", "*", "len", "(", "train_loader", ")", ",", "\n", "}", "\n", "logger", ".", "info", "(", "logging", ".", "dump_log_data", "(", "epoch_times", ",", "\"epoch_times\"", ")", ")", "\n", "# Compute data loader overhead (assuming DATA_LOADER.NUM_WORKERS>1)", "\n", "overhead", "=", "max", "(", "0", ",", "train_loader_time", "-", "train_fw_bw_time", ")", "/", "train_fw_bw_time", "\n", "logger", ".", "info", "(", "\"Overhead of data loader is {:.2f}%\"", ".", "format", "(", "overhead", "*", "100", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.__init__": [[27, 31], ["collections.deque"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "window_size", ")", ":", "\n", "        ", "self", ".", "deque", "=", "deque", "(", "maxlen", "=", "window_size", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.reset": [[32, 36], ["meters.ScalarMeter.deque.clear"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "deque", ".", "clear", "(", ")", "\n", "self", ".", "total", "=", "0.0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.add_value": [[37, 41], ["meters.ScalarMeter.deque.append"], "methods", ["None"], ["", "def", "add_value", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "deque", ".", "append", "(", "value", ")", "\n", "self", ".", "count", "+=", "1", "\n", "self", ".", "total", "+=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_median": [[42, 44], ["numpy.median"], "methods", ["None"], ["", "def", "get_win_median", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "median", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_avg": [[45, 47], ["numpy.mean"], "methods", ["None"], ["", "def", "get_win_avg", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "deque", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_global_avg": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_global_avg", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.__init__": [[55, 67], ["pycls.utils.timer.Timer", "pycls.utils.timer.Timer", "meters.ScalarMeter", "meters.ScalarMeter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "epoch_iters", ")", ":", "\n", "        ", "self", ".", "epoch_iters", "=", "epoch_iters", "\n", "self", ".", "max_iter", "=", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "*", "epoch_iters", "\n", "self", ".", "iter_timer", "=", "Timer", "(", ")", "\n", "self", ".", "loss", "=", "ScalarMeter", "(", "cfg", ".", "LOG_PERIOD", ")", "\n", "self", ".", "loss_total", "=", "0.0", "\n", "self", ".", "lr", "=", "None", "\n", "# Current minibatch errors (smoothed over a window)", "\n", "self", ".", "mb_top1_err", "=", "ScalarMeter", "(", "cfg", ".", "LOG_PERIOD", ")", "\n", "# Number of misclassified examples", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.reset": [[68, 77], ["meters.TrainMeter.loss.reset", "meters.TrainMeter.mb_top1_err.reset", "meters.TrainMeter.iter_timer.reset"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["", "def", "reset", "(", "self", ",", "timer", "=", "False", ")", ":", "\n", "        ", "if", "timer", ":", "\n", "            ", "self", ".", "iter_timer", ".", "reset", "(", ")", "\n", "", "self", ".", "loss", ".", "reset", "(", ")", "\n", "self", ".", "loss_total", "=", "0.0", "\n", "self", ".", "lr", "=", "None", "\n", "self", ".", "mb_top1_err", ".", "reset", "(", ")", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.iter_tic": [[78, 80], ["meters.TrainMeter.iter_timer.tic"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic"], ["", "def", "iter_tic", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "tic", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.iter_toc": [[81, 83], ["meters.TrainMeter.iter_timer.toc"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc"], ["", "def", "iter_toc", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "toc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.update_stats": [[84, 93], ["meters.TrainMeter.mb_top1_err.add_value", "meters.TrainMeter.loss.add_value"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.add_value", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.add_value"], ["", "def", "update_stats", "(", "self", ",", "top1_err", ",", "loss", ",", "lr", ",", "mb_size", ")", ":", "\n", "# Current minibatch stats", "\n", "        ", "self", ".", "mb_top1_err", ".", "add_value", "(", "top1_err", ")", "\n", "self", ".", "loss", ".", "add_value", "(", "loss", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "# Aggregate stats", "\n", "self", ".", "num_top1_mis", "+=", "top1_err", "*", "mb_size", "\n", "self", ".", "loss_total", "+=", "loss", "*", "mb_size", "\n", "self", ".", "num_samples", "+=", "mb_size", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.get_iter_stats": [[95, 110], ["datetime.timedelta", "pycls.gpu_mem_usage", "pycls.gpu_mem_usage", "meters.TrainMeter.mb_top1_err.get_win_median", "meters.TrainMeter.loss.get_win_median", "int"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_median", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_median"], ["", "def", "get_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "eta_sec", "=", "self", ".", "iter_timer", ".", "average_time", "*", "(", "\n", "self", ".", "max_iter", "-", "(", "cur_epoch", "*", "self", ".", "epoch_iters", "+", "cur_iter", "+", "1", ")", "\n", ")", "\n", "eta_td", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_sec", ")", ")", "\n", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "stats", "=", "{", "\n", "'_type'", ":", "'train_iter'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'iter'", ":", "'{}/{}'", ".", "format", "(", "cur_iter", "+", "1", ",", "self", ".", "epoch_iters", ")", ",", "\n", "'top1_err'", ":", "self", ".", "mb_top1_err", ".", "get_win_median", "(", ")", ",", "\n", "'loss'", ":", "self", ".", "loss", ".", "get_win_median", "(", ")", ",", "\n", "'lr'", ":", "self", ".", "lr", ",", "\n", "}", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.log_iter_stats": [[111, 116], ["meters.TrainMeter.get_iter_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "if", "(", "cur_iter", "+", "1", ")", "%", "cfg", ".", "LOG_PERIOD", "!=", "0", ":", "\n", "            ", "return", "\n", "", "stats", "=", "self", ".", "get_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.get_epoch_stats": [[117, 133], ["datetime.timedelta", "pycls.gpu_mem_usage", "pycls.gpu_mem_usage", "int"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage"], ["", "def", "get_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "eta_sec", "=", "self", ".", "iter_timer", ".", "average_time", "*", "(", "\n", "self", ".", "max_iter", "-", "(", "cur_epoch", "+", "1", ")", "*", "self", ".", "epoch_iters", "\n", ")", "\n", "eta_td", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_sec", ")", ")", "\n", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "top1_err", "=", "self", ".", "num_top1_mis", "/", "self", ".", "num_samples", "\n", "avg_loss", "=", "self", ".", "loss_total", "/", "self", ".", "num_samples", "\n", "stats", "=", "{", "\n", "'_type'", ":", "'train_epoch'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'top1_err'", ":", "top1_err", ",", "\n", "'loss'", ":", "avg_loss", ",", "\n", "'lr'", ":", "self", ".", "lr", ",", "\n", "}", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TrainMeter.log_epoch_stats": [[134, 137], ["meters.TrainMeter.get_epoch_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "stats", "=", "self", ".", "get_epoch_stats", "(", "cur_epoch", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.__init__": [[142, 152], ["pycls.utils.timer.Timer", "pycls.utils.timer.Timer", "meters.ScalarMeter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ")", ":", "\n", "        ", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "iter_timer", "=", "Timer", "(", ")", "\n", "# Current minibatch errors (smoothed over a window)", "\n", "self", ".", "mb_top1_err", "=", "ScalarMeter", "(", "cfg", ".", "LOG_PERIOD", ")", "\n", "# Min errors (over the full test set)", "\n", "self", ".", "min_top1_err", "=", "100.0", "\n", "# Number of misclassified examples", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.reset": [[153, 160], ["meters.TestMeter.iter_timer.reset", "meters.TestMeter.mb_top1_err.reset"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["", "def", "reset", "(", "self", ",", "min_errs", "=", "False", ")", ":", "\n", "        ", "if", "min_errs", ":", "\n", "            ", "self", ".", "min_top1_err", "=", "100.0", "\n", "", "self", ".", "iter_timer", ".", "reset", "(", ")", "\n", "self", ".", "mb_top1_err", ".", "reset", "(", ")", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.iter_tic": [[161, 163], ["meters.TestMeter.iter_timer.tic"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic"], ["", "def", "iter_tic", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "tic", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.iter_toc": [[164, 166], ["meters.TestMeter.iter_timer.toc"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc"], ["", "def", "iter_toc", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "toc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.update_stats": [[167, 171], ["meters.TestMeter.mb_top1_err.add_value"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.add_value"], ["", "def", "update_stats", "(", "self", ",", "top1_err", ",", "mb_size", ")", ":", "\n", "        ", "self", ".", "mb_top1_err", ".", "add_value", "(", "top1_err", ")", "\n", "self", ".", "num_top1_mis", "+=", "top1_err", "*", "mb_size", "\n", "self", ".", "num_samples", "+=", "mb_size", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.get_iter_stats": [[172, 181], ["pycls.gpu_mem_usage", "pycls.gpu_mem_usage", "meters.TestMeter.mb_top1_err.get_win_median"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_median"], ["", "def", "get_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "iter_stats", "=", "{", "\n", "'_type'", ":", "'test_iter'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'iter'", ":", "'{}/{}'", ".", "format", "(", "cur_iter", "+", "1", ",", "self", ".", "max_iter", ")", ",", "\n", "'top1_err'", ":", "self", ".", "mb_top1_err", ".", "get_win_median", "(", ")", ",", "\n", "}", "\n", "return", "iter_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.log_iter_stats": [[182, 187], ["meters.TestMeter.get_iter_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "if", "(", "cur_iter", "+", "1", ")", "%", "cfg", ".", "LOG_PERIOD", "!=", "0", ":", "\n", "            ", "return", "\n", "", "stats", "=", "self", ".", "get_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.get_epoch_stats": [[188, 199], ["min", "pycls.gpu_mem_usage", "pycls.gpu_mem_usage"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage"], ["", "def", "get_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "top1_err", "=", "self", ".", "num_top1_mis", "/", "self", ".", "num_samples", "\n", "self", ".", "min_top1_err", "=", "min", "(", "self", ".", "min_top1_err", ",", "top1_err", ")", "\n", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "stats", "=", "{", "\n", "'_type'", ":", "'test_epoch'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'top1_err'", ":", "top1_err", ",", "\n", "'min_top1_err'", ":", "self", ".", "min_top1_err", "\n", "}", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.TestMeter.log_epoch_stats": [[200, 203], ["meters.TestMeter.get_epoch_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "stats", "=", "self", ".", "get_epoch_stats", "(", "cur_epoch", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.__init__": [[207, 217], ["pycls.utils.timer.Timer", "pycls.utils.timer.Timer", "meters.ScalarMeter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ")", ":", "\n", "        ", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "iter_timer", "=", "Timer", "(", ")", "\n", "# Current minibatch errors (smoothed over a window)", "\n", "self", ".", "mb_top1_err", "=", "ScalarMeter", "(", "cfg", ".", "LOG_PERIOD", ")", "\n", "# Min errors (over the full Val set)", "\n", "self", ".", "min_top1_err", "=", "100.0", "\n", "# Number of misclassified examples", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.reset": [[218, 225], ["meters.ValMeter.iter_timer.reset", "meters.ValMeter.mb_top1_err.reset"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["", "def", "reset", "(", "self", ",", "min_errs", "=", "False", ")", ":", "\n", "        ", "if", "min_errs", ":", "\n", "            ", "self", ".", "min_top1_err", "=", "100.0", "\n", "", "self", ".", "iter_timer", ".", "reset", "(", ")", "\n", "self", ".", "mb_top1_err", ".", "reset", "(", ")", "\n", "self", ".", "num_top1_mis", "=", "0", "\n", "self", ".", "num_samples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic": [[226, 228], ["meters.ValMeter.iter_timer.tic"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.tic"], ["", "def", "iter_tic", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "tic", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc": [[229, 231], ["meters.ValMeter.iter_timer.toc"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.timer.Timer.toc"], ["", "def", "iter_toc", "(", "self", ")", ":", "\n", "        ", "self", ".", "iter_timer", ".", "toc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats": [[232, 236], ["meters.ValMeter.mb_top1_err.add_value"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.add_value"], ["", "def", "update_stats", "(", "self", ",", "top1_err", ",", "mb_size", ")", ":", "\n", "        ", "self", ".", "mb_top1_err", ".", "add_value", "(", "top1_err", ")", "\n", "self", ".", "num_top1_mis", "+=", "top1_err", "*", "mb_size", "\n", "self", ".", "num_samples", "+=", "mb_size", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_iter_stats": [[237, 246], ["pycls.gpu_mem_usage", "pycls.gpu_mem_usage", "meters.ValMeter.mb_top1_err.get_win_median"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ScalarMeter.get_win_median"], ["", "def", "get_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "iter_stats", "=", "{", "\n", "'_type'", ":", "'Val_iter'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'iter'", ":", "'{}/{}'", ".", "format", "(", "cur_iter", "+", "1", ",", "self", ".", "max_iter", ")", ",", "\n", "'top1_err'", ":", "self", ".", "mb_top1_err", ".", "get_win_median", "(", ")", ",", "\n", "}", "\n", "return", "iter_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats": [[247, 252], ["meters.ValMeter.get_iter_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_iter_stats", "(", "self", ",", "cur_epoch", ",", "cur_iter", ")", ":", "\n", "        ", "if", "(", "cur_iter", "+", "1", ")", "%", "cfg", ".", "LOG_PERIOD", "!=", "0", ":", "\n", "            ", "return", "\n", "", "stats", "=", "self", ".", "get_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_epoch_stats": [[253, 264], ["min", "pycls.gpu_mem_usage", "pycls.gpu_mem_usage"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.gpu_mem_usage"], ["", "def", "get_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "top1_err", "=", "self", ".", "num_top1_mis", "/", "self", ".", "num_samples", "\n", "self", ".", "min_top1_err", "=", "min", "(", "self", ".", "min_top1_err", ",", "top1_err", ")", "\n", "mem_usage", "=", "metrics", ".", "gpu_mem_usage", "(", ")", "\n", "stats", "=", "{", "\n", "'_type'", ":", "'Val_epoch'", ",", "\n", "'epoch'", ":", "'{}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ",", "\n", "'top1_err'", ":", "top1_err", ",", "\n", "'min_top1_err'", ":", "self", ".", "min_top1_err", "\n", "}", "\n", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats": [[265, 268], ["meters.ValMeter.get_epoch_stats", "pycls.log_json_stats", "pycls.log_json_stats"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.get_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.log_json_stats"], ["", "def", "log_epoch_stats", "(", "self", ",", "cur_epoch", ")", ":", "\n", "        ", "stats", "=", "self", ".", "get_epoch_stats", "(", "cur_epoch", ")", "\n", "lu", ".", "log_json_stats", "(", "stats", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.eta_str": [[16, 22], ["divmod", "divmod"], "function", ["None"], ["def", "eta_str", "(", "eta_td", ")", ":", "\n", "    ", "\"\"\"Converts an eta timedelta to a fixed-width string format.\"\"\"", "\n", "days", "=", "eta_td", ".", "days", "\n", "hrs", ",", "rem", "=", "divmod", "(", "eta_td", ".", "seconds", ",", "3600", ")", "\n", "mins", ",", "secs", "=", "divmod", "(", "rem", ",", "60", ")", "\n", "return", "'{0:02},{1:02}:{2:02}:{3:02}'", ".", "format", "(", "days", ",", "hrs", ",", "mins", ",", "secs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint_dir": [[24, 27], ["os.path.join"], "function", ["None"], ["def", "get_checkpoint_dir", "(", "episode_dir", ")", ":", "\n", "    ", "\"\"\"Retrieves the location for storing checkpoints.\"\"\"", "\n", "return", "os", ".", "path", ".", "join", "(", "episode_dir", ",", "_DIR_NAME", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint": [[29, 34], ["os.path.join"], "function", ["None"], ["", "def", "get_checkpoint", "(", "epoch", ",", "episode_dir", ")", ":", "\n", "    ", "\"\"\"Retrieves the path to a checkpoint file.\"\"\"", "\n", "name", "=", "\"{}{:04d}.pyth\"", ".", "format", "(", "_NAME_PREFIX", ",", "epoch", ")", "\n", "# return os.path.join(get_checkpoint_dir(), name)", "\n", "return", "os", ".", "path", ".", "join", "(", "episode_dir", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint_best": [[36, 39], ["os.path.join"], "function", ["None"], ["", "def", "get_checkpoint_best", "(", "episode_dir", ")", ":", "\n", "    ", "\"\"\"Retrieves the path to the best checkpoint file.\"\"\"", "\n", "return", "os", ".", "path", ".", "join", "(", "episode_dir", ",", "\"model.pyth\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_last_checkpoint": [[41, 47], ["checkpoint.get_checkpoint_dir", "os.path.join", "sorted", "os.listdir"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint_dir"], ["", "def", "get_last_checkpoint", "(", "episode_dir", ")", ":", "\n", "    ", "\"\"\"Retrieves the most recent checkpoint (highest epoch number).\"\"\"", "\n", "checkpoint_dir", "=", "get_checkpoint_dir", "(", "episode_dir", ")", "\n", "checkpoints", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "checkpoint_dir", ")", "if", "_NAME_PREFIX", "in", "f", "]", "\n", "last_checkpoint_name", "=", "sorted", "(", "checkpoints", ")", "[", "-", "1", "]", "\n", "return", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "last_checkpoint_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.has_checkpoint": [[49, 55], ["checkpoint.get_checkpoint_dir", "any", "os.path.exists", "os.listdir"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint_dir"], ["", "def", "has_checkpoint", "(", "episode_dir", ")", ":", "\n", "    ", "\"\"\"Determines if there are checkpoints available.\"\"\"", "\n", "checkpoint_dir", "=", "get_checkpoint_dir", "(", "episode_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "        ", "return", "False", "\n", "", "return", "any", "(", "_NAME_PREFIX", "in", "f", "for", "f", "in", "os", ".", "listdir", "(", "checkpoint_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.save_checkpoint": [[57, 83], ["os.makedirs", "checkpoint.get_checkpoint", "torch.save", "cfg.dump"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint"], ["", "def", "save_checkpoint", "(", "info", ",", "model_state", ",", "optimizer_state", ",", "epoch", ",", "cfg", ")", ":", "\n", "\n", "    ", "\"\"\"Saves a checkpoint.\"\"\"", "\n", "# Save checkpoints only from the master process", "\n", "# if not dist.is_master_proc():", "\n", "#     return", "\n", "# Ensure that the checkpoint dir exists", "\n", "os", ".", "makedirs", "(", "cfg", ".", "EPISODE_DIR", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Record the state", "\n", "checkpoint", "=", "{", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"model_state\"", ":", "model_state", ",", "\n", "\"optimizer_state\"", ":", "optimizer_state", ",", "\n", "\"cfg\"", ":", "cfg", ".", "dump", "(", ")", ",", "\n", "}", "\n", "global", "_NAME_PREFIX", "\n", "_NAME_PREFIX", "=", "info", "+", "'_'", "+", "_NAME_PREFIX", "\n", "\n", "# Write the checkpoint", "\n", "checkpoint_file", "=", "get_checkpoint", "(", "epoch", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_file", ")", "\n", "# print(\"Model checkpoint saved at path: {}\".format(checkpoint_file))", "\n", "\n", "_NAME_PREFIX", "=", "'model_epoch_'", "\n", "return", "checkpoint_file", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint": [[85, 93], ["os.path.exists", "err_str.format", "torch.load", "pycls.core.net.unwrap_model().load_state_dict", "optimizer.load_state_dict", "pycls.core.net.unwrap_model"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.net.unwrap_model"], ["", "def", "load_checkpoint", "(", "checkpoint_file", ",", "model", ",", "optimizer", "=", "None", ")", ":", "\n", "    ", "\"\"\"Loads the checkpoint from the given file.\"\"\"", "\n", "err_str", "=", "\"Checkpoint '{}' not found\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "checkpoint_file", ")", ",", "err_str", ".", "format", "(", "checkpoint_file", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "unwrap_model", "(", "model", ")", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state\"", "]", ")", "if", "optimizer", "else", "(", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.delete_checkpoints": [[95, 105], ["len", "checkpoint.get_checkpoint_dir", "os.remove", "os.path.exists", "os.listdir", "sorted", "os.path.join"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.get_checkpoint_dir"], ["", "def", "delete_checkpoints", "(", "checkpoint_dir", "=", "None", ",", "keep", "=", "\"all\"", ")", ":", "\n", "    ", "\"\"\"Deletes unneeded checkpoints, keep can be \"all\", \"last\", or \"none\".\"\"\"", "\n", "assert", "keep", "in", "[", "\"all\"", ",", "\"last\"", ",", "\"none\"", "]", ",", "\"Invalid keep setting: {}\"", ".", "format", "(", "keep", ")", "\n", "checkpoint_dir", "=", "checkpoint_dir", "if", "checkpoint_dir", "else", "get_checkpoint_dir", "(", ")", "\n", "if", "keep", "==", "\"all\"", "or", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "        ", "return", "0", "\n", "", "checkpoints", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "checkpoint_dir", ")", "if", "_NAME_PREFIX", "in", "f", "]", "\n", "checkpoints", "=", "sorted", "(", "checkpoints", ")", "[", ":", "-", "1", "]", "if", "keep", "==", "\"last\"", "else", "checkpoints", "\n", "[", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "checkpoint", ")", ")", "for", "checkpoint", "in", "checkpoints", "]", "\n", "return", "len", "(", "checkpoints", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.helpers.load_imageset": [[3, 13], ["csv.reader", "open", "os.path.join"], "function", ["None"], ["def", "load_imageset", "(", "path", ",", "set_name", ")", ":", "\n", "    ", "\"\"\"\n    Returns the image set `set_name` present at `path` as a list.\n    Keyword arguments:\n        path -- path to data folder\n        set_name -- image set name - labeled or unlabeled.\n    \"\"\"", "\n", "reader", "=", "csv", ".", "reader", "(", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "set_name", "+", "'.csv'", ")", ",", "'rt'", ")", ")", "\n", "reader", "=", "[", "r", "[", "0", "]", "for", "r", "in", "reader", "]", "\n", "return", "reader", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.gaussian_blur.GaussianBlur.__init__": [[12, 30], ["torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage", "torch.ReflectionPad2d", "torch.ReflectionPad2d"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "kernel_size", ")", ":", "\n", "        ", "radias", "=", "kernel_size", "//", "2", "\n", "kernel_size", "=", "radias", "*", "2", "+", "1", "\n", "self", ".", "blur_h", "=", "nn", ".", "Conv2d", "(", "3", ",", "3", ",", "kernel_size", "=", "(", "kernel_size", ",", "1", ")", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ",", "groups", "=", "3", ")", "\n", "self", ".", "blur_v", "=", "nn", ".", "Conv2d", "(", "3", ",", "3", ",", "kernel_size", "=", "(", "1", ",", "kernel_size", ")", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ",", "groups", "=", "3", ")", "\n", "self", ".", "k", "=", "kernel_size", "\n", "self", ".", "r", "=", "radias", "\n", "\n", "self", ".", "blur", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReflectionPad2d", "(", "radias", ")", ",", "\n", "self", ".", "blur_h", ",", "\n", "self", ".", "blur_v", "\n", ")", "\n", "\n", "self", ".", "pil_to_tensor", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "self", ".", "tensor_to_pil", "=", "transforms", ".", "ToPILImage", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.gaussian_blur.GaussianBlur.__call__": [[31, 50], ["gaussian_blur.GaussianBlur.pil_to_tensor().unsqueeze", "numpy.random.uniform", "numpy.arange", "numpy.exp", "torch.from_numpy().view().repeat", "torch.from_numpy().view().repeat", "torch.from_numpy().view().repeat", "torch.from_numpy().view().repeat", "gaussian_blur.GaussianBlur.blur_h.weight.data.copy_", "gaussian_blur.GaussianBlur.blur_v.weight.data.copy_", "gaussian_blur.GaussianBlur.tensor_to_pil", "torch.from_numpy().view().repeat.sum", "torch.from_numpy().view().repeat.sum", "torch.from_numpy().view().repeat.view", "torch.from_numpy().view().repeat.view", "torch.from_numpy().view().repeat.view", "torch.from_numpy().view().repeat.view", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gaussian_blur.GaussianBlur.blur", "img.squeeze.squeeze.squeeze", "gaussian_blur.GaussianBlur.pil_to_tensor", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "torch.from_numpy().view", "numpy.power", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "img", "=", "self", ".", "pil_to_tensor", "(", "img", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "sigma", "=", "np", ".", "random", ".", "uniform", "(", "0.1", ",", "2.0", ")", "\n", "x", "=", "np", ".", "arange", "(", "-", "self", ".", "r", ",", "self", ".", "r", "+", "1", ")", "\n", "x", "=", "np", ".", "exp", "(", "-", "np", ".", "power", "(", "x", ",", "2", ")", "/", "(", "2", "*", "sigma", "*", "sigma", ")", ")", "\n", "x", "=", "x", "/", "x", ".", "sum", "(", ")", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "3", ",", "1", ")", "\n", "\n", "self", ".", "blur_h", ".", "weight", ".", "data", ".", "copy_", "(", "x", ".", "view", "(", "3", ",", "1", ",", "self", ".", "k", ",", "1", ")", ")", "\n", "self", ".", "blur_v", ".", "weight", ".", "data", ".", "copy_", "(", "x", ".", "view", "(", "3", ",", "1", ",", "1", ",", "self", ".", "k", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "img", "=", "self", ".", "blur", "(", "img", ")", "\n", "img", "=", "img", ".", "squeeze", "(", ")", "\n", "\n", "", "img", "=", "self", ".", "tensor_to_pil", "(", "img", ")", "\n", "\n", "return", "img", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.collate.collate_custom": [[12, 40], ["isinstance", "isinstance", "TypeError", "numpy.stack", "torch.stack", "isinstance", "numpy.stack", "isinstance", "type", "torch.LongTensor", "isinstance", "torch.FloatTensor", "isinstance", "isinstance", "isinstance", "collate.collate_custom", "zip", "collate.collate_custom", "key.find"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.collate.collate_custom", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.collate.collate_custom"], ["def", "collate_custom", "(", "batch", ")", ":", "\n", "    ", "if", "isinstance", "(", "batch", "[", "0", "]", ",", "np", ".", "int64", ")", ":", "\n", "        ", "return", "np", ".", "stack", "(", "batch", ",", "0", ")", "\n", "\n", "", "if", "isinstance", "(", "batch", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "stack", "(", "batch", ",", "0", ")", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "np", ".", "stack", "(", "batch", ",", "0", ")", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "int", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "batch", ")", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "batch", ")", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Mapping", ")", ":", "\n", "        ", "batch_modified", "=", "{", "key", ":", "collate_custom", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "batch", "[", "0", "]", "if", "key", ".", "find", "(", "'idx'", ")", "<", "0", "}", "\n", "return", "batch_modified", "\n", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Sequence", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "collate_custom", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "\n", "", "raise", "TypeError", "(", "(", "'Type is {}'", ".", "format", "(", "type", "(", "batch", "[", "0", "]", ")", ")", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config": [[10, 58], ["easydict.EasyDict", "yaml.safe_load.items", "os.path.join", "os.path.join", "utils.utils.mkdir_if_missing", "utils.utils.mkdir_if_missing", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "open", "yaml.safe_load", "os.path.join", "os.path.join", "os.path.join", "utils.utils.mkdir_if_missing", "utils.utils.mkdir_if_missing", "utils.utils.mkdir_if_missing", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "yaml.safe_load"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing"], ["from", "yacs", ".", "config", "import", "CfgNode", "as", "CN", "\n", "\n", "\n", "# Global config object", "\n", "_C", "=", "CN", "(", ")", "\n", "\n", "# Example usage:", "\n", "#   from core.config import cfg", "\n", "cfg", "=", "_C", "\n", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Misc options", "\n", "# ---------------------------------------------------------------------------- #", "\n", "# Number of GPUs to use (applies to both training and testing)", "\n", "_C", ".", "NUM_GPUS", "=", "1", "\n", "# Output directory (will be created at the projec root)", "\n", "_C", ".", "OUT_DIR", "=", "'output'", "\n", "# Experiment directory", "\n", "_C", ".", "EXP_DIR", "=", "''", "\n", "# Episode directory", "\n", "_C", ".", "EPISODE_DIR", "=", "''", "\n", "# Config destination (in OUT_DIR)", "\n", "_C", ".", "CFG_DEST", "=", "'config.yaml'", "\n", "# Note that non-determinism may still be present due to non-deterministic", "\n", "# operator implementations in GPU operator libraries", "\n", "_C", ".", "RNG_SEED", "=", "None", "\n", "# Folder name where best model logs etc are saved. \"auto\" creates a timestamp based folder ", "\n", "_C", ".", "EXP_NAME", "=", "'auto'", "\n", "# Which GPU to run on", "\n", "_C", ".", "GPU_ID", "=", "0", "\n", "# Log destination ('stdout' or 'file')", "\n", "_C", ".", "LOG_DEST", "=", "'file'", "\n", "# Log period in iters", "\n", "_C", ".", "LOG_PERIOD", "=", "10", "\n", "\n", "\n", "#------------------------------------------------------------------------------#", "\n", "# VAAL Options (Taken from https://arxiv.org/abs/1904.00370)", "\n", "#------------------------------------------------------------------------------#", "\n", "_C", ".", "VAAL", "=", "CN", "(", ")", "\n", "_C", ".", "VAAL", ".", "TRAIN_VAAL", "=", "False", "\n", "_C", ".", "VAAL", ".", "Z_DIM", "=", "32", "\n", "_C", ".", "VAAL", ".", "VAE_BS", "=", "64", "\n", "_C", ".", "VAAL", ".", "VAE_EPOCHS", "=", "100", "\n", "_C", ".", "VAAL", ".", "VAE_LR", "=", "5e-4", "\n", "_C", ".", "VAAL", ".", "DISC_LR", "=", "5e-4", "\n", "_C", ".", "VAAL", ".", "BETA", "=", "1.0", "\n", "_C", ".", "VAAL", ".", "ADVERSARY_PARAM", "=", "1.0", "\n", "_C", ".", "VAAL", ".", "IM_SIZE", "=", "32", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir": [[9, 28], ["None"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "db_root_dir", "(", "database", "=", "''", ")", ":", "\n", "        ", "db_names", "=", "{", "'cifar-10'", ",", "'stl-10'", ",", "'cifar-100'", ",", "'imagenet'", ",", "'imagenet_50'", ",", "'imagenet_100'", ",", "'imagenet_200'", "}", "\n", "assert", "(", "database", "in", "db_names", ")", "\n", "\n", "if", "database", "==", "'cifar-10'", ":", "\n", "            ", "return", "'./datasets/cifar-10/'", "\n", "\n", "", "elif", "database", "==", "'cifar-100'", ":", "\n", "            ", "return", "'./datasets/cifar-100/'", "\n", "\n", "", "elif", "database", "==", "'stl-10'", ":", "\n", "            ", "return", "'./datasets/stl-10/'", "\n", "\n", "", "elif", "database", "in", "[", "'imagenet'", ",", "'imagenet_50'", ",", "'imagenet_100'", ",", "'imagenet_200'", "]", ":", "\n", "            ", "return", "'./datasets/imagenet/'", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_criterion": [[14, 31], ["SimCLRLoss", "SCANLoss", "ConfidenceBasedCE", "ValueError"], "function", ["None"], ["def", "get_criterion", "(", "p", ")", ":", "\n", "    ", "if", "p", "[", "'criterion'", "]", "==", "'simclr'", ":", "\n", "        ", "from", "losses", ".", "losses", "import", "SimCLRLoss", "\n", "criterion", "=", "SimCLRLoss", "(", "**", "p", "[", "'criterion_kwargs'", "]", ")", "\n", "\n", "", "elif", "p", "[", "'criterion'", "]", "==", "'scan'", ":", "\n", "        ", "from", "losses", ".", "losses", "import", "SCANLoss", "\n", "criterion", "=", "SCANLoss", "(", "**", "p", "[", "'criterion_kwargs'", "]", ")", "\n", "\n", "", "elif", "p", "[", "'criterion'", "]", "==", "'confidence-cross-entropy'", ":", "\n", "        ", "from", "losses", ".", "losses", "import", "ConfidenceBasedCE", "\n", "criterion", "=", "ConfidenceBasedCE", "(", "p", "[", "'confidence_threshold'", "]", ",", "p", "[", "'criterion_kwargs'", "]", "[", "'apply_class_balancing'", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid criterion {}'", ".", "format", "(", "p", "[", "'criterion'", "]", ")", ")", "\n", "\n", "", "return", "criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_feature_dimensions_backbone": [[33, 42], ["None"], "function", ["None"], ["", "def", "get_feature_dimensions_backbone", "(", "p", ")", ":", "\n", "    ", "if", "p", "[", "'backbone'", "]", "==", "'resnet18'", ":", "\n", "        ", "return", "512", "\n", "\n", "", "elif", "p", "[", "'backbone'", "]", "==", "'resnet50'", ":", "\n", "        ", "return", "2048", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_model": [[44, 121], ["ContrastiveModel", "os.path.exists", "torch.load", "resnet18", "ValueError", "ClusteringModel", "ValueError", "ClusteringModel.load_state_dict", "ValueError", "resnet18", "resnet50", "ClusteringModel.load_state_dict", "os.path.exists", "resnet18", "set", "set", "model_state.pop", "model_state.keys"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.resnet18", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.resnet18", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet50", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.resnet18"], ["", "", "def", "get_model", "(", "p", ",", "pretrain_path", "=", "None", ")", ":", "\n", "# Get backbone", "\n", "    ", "if", "p", "[", "'backbone'", "]", "==", "'resnet18'", ":", "\n", "        ", "if", "p", "[", "'train_db_name'", "]", "in", "[", "'cifar-10'", ",", "'cifar-100'", "]", ":", "\n", "            ", "from", "models", ".", "resnet_cifar", "import", "resnet18", "\n", "backbone", "=", "resnet18", "(", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'stl-10'", ":", "\n", "            ", "from", "models", ".", "resnet_stl", "import", "resnet18", "\n", "backbone", "=", "resnet18", "(", ")", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'tiny-imagenet'", ":", "\n", "            ", "from", "models", ".", "resnet_tinyimagenet", "import", "resnet18", "\n", "backbone", "=", "resnet18", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "elif", "p", "[", "'backbone'", "]", "==", "'resnet50'", ":", "\n", "        ", "if", "'imagenet'", "in", "p", "[", "'train_db_name'", "]", ":", "\n", "            ", "from", "models", ".", "resnet", "import", "resnet50", "\n", "backbone", "=", "resnet50", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid backbone {}'", ".", "format", "(", "p", "[", "'backbone'", "]", ")", ")", "\n", "\n", "# Setup", "\n", "", "if", "p", "[", "'setup'", "]", "in", "[", "'simclr'", ",", "'moco'", "]", ":", "\n", "        ", "from", "models", ".", "models", "import", "ContrastiveModel", "\n", "model", "=", "ContrastiveModel", "(", "backbone", ",", "**", "p", "[", "'model_kwargs'", "]", ")", "\n", "\n", "", "elif", "p", "[", "'setup'", "]", "in", "[", "'scan'", ",", "'selflabel'", "]", ":", "\n", "        ", "from", "models", ".", "models", "import", "ClusteringModel", "\n", "if", "p", "[", "'setup'", "]", "==", "'selflabel'", ":", "\n", "            ", "assert", "(", "p", "[", "'num_heads'", "]", "==", "1", ")", "\n", "", "model", "=", "ClusteringModel", "(", "backbone", ",", "p", "[", "'num_classes'", "]", ",", "p", "[", "'num_heads'", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid setup {}'", ".", "format", "(", "p", "[", "'setup'", "]", ")", ")", "\n", "\n", "# Load pretrained weights", "\n", "", "if", "pretrain_path", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "pretrain_path", ")", ":", "\n", "        ", "state", "=", "torch", ".", "load", "(", "pretrain_path", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "p", "[", "'setup'", "]", "==", "'scan'", ":", "# Weights are supposed to be transfered from contrastive training", "\n", "            ", "missing", "=", "model", ".", "load_state_dict", "(", "state", ",", "strict", "=", "False", ")", "\n", "assert", "(", "set", "(", "missing", "[", "1", "]", ")", "==", "{", "\n", "'contrastive_head.0.weight'", ",", "'contrastive_head.0.bias'", ",", "\n", "'contrastive_head.2.weight'", ",", "'contrastive_head.2.bias'", "}", "\n", "or", "set", "(", "missing", "[", "1", "]", ")", "==", "{", "\n", "'contrastive_head.weight'", ",", "'contrastive_head.bias'", "}", ")", "\n", "\n", "", "elif", "p", "[", "'setup'", "]", "==", "'selflabel'", ":", "# Weights are supposed to be transfered from scan ", "\n", "# We only continue with the best head (pop all heads first, then copy back the best head)", "\n", "            ", "model_state", "=", "state", "[", "'model'", "]", "\n", "all_heads", "=", "[", "k", "for", "k", "in", "model_state", ".", "keys", "(", ")", "if", "'cluster_head'", "in", "k", "]", "\n", "best_head_weight", "=", "model_state", "[", "'cluster_head.%d.weight'", "%", "(", "state", "[", "'head'", "]", ")", "]", "\n", "best_head_bias", "=", "model_state", "[", "'cluster_head.%d.bias'", "%", "(", "state", "[", "'head'", "]", ")", "]", "\n", "for", "k", "in", "all_heads", ":", "\n", "                ", "model_state", ".", "pop", "(", "k", ")", "\n", "\n", "", "model_state", "[", "'cluster_head.0.weight'", "]", "=", "best_head_weight", "\n", "model_state", "[", "'cluster_head.0.bias'", "]", "=", "best_head_bias", "\n", "missing", "=", "model", ".", "load_state_dict", "(", "model_state", ",", "strict", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "elif", "pretrain_path", "is", "not", "None", "and", "not", "os", ".", "path", ".", "exists", "(", "pretrain_path", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Path with pre-trained weights does not exist {}'", ".", "format", "(", "pretrain_path", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset": [[123, 165], ["CIFAR10", "AugmentedDataset", "numpy.load", "NeighborsDataset", "CIFAR100", "STL10", "TinyImageNet", "ImageNet", "ImageNetSubset", "ValueError"], "function", ["None"], ["", "def", "get_train_dataset", "(", "p", ",", "transform", ",", "to_augmented_dataset", "=", "False", ",", "\n", "to_neighbors_dataset", "=", "False", ",", "split", "=", "None", ")", ":", "\n", "# Base dataset", "\n", "    ", "if", "p", "[", "'train_db_name'", "]", "==", "'cifar-10'", ":", "\n", "        ", "from", "data", ".", "cifar", "import", "CIFAR10", "\n", "dataset", "=", "CIFAR10", "(", "train", "=", "True", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'cifar-100'", ":", "\n", "        ", "from", "data", ".", "cifar", "import", "CIFAR100", "\n", "dataset", "=", "CIFAR100", "(", "train", "=", "True", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'stl-10'", ":", "\n", "        ", "from", "data", ".", "stl", "import", "STL10", "\n", "dataset", "=", "STL10", "(", "split", "=", "split", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'tiny-imagenet'", ":", "\n", "        ", "from", "data", ".", "tinyimagenet", "import", "TinyImageNet", "\n", "dataset", "=", "TinyImageNet", "(", "root", "=", "''", ",", "split", "=", "'train'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'imagenet'", ":", "\n", "        ", "from", "data", ".", "imagenet", "import", "ImageNet", "\n", "dataset", "=", "ImageNet", "(", "split", "=", "'train'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "in", "[", "'imagenet_50'", ",", "'imagenet_100'", ",", "'imagenet_200'", "]", ":", "\n", "        ", "from", "data", ".", "imagenet", "import", "ImageNetSubset", "\n", "subset_file", "=", "'./data/imagenet_subsets/%s.txt'", "%", "(", "p", "[", "'train_db_name'", "]", ")", "\n", "dataset", "=", "ImageNetSubset", "(", "subset_file", "=", "subset_file", ",", "split", "=", "'train'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid train dataset {}'", ".", "format", "(", "p", "[", "'train_db_name'", "]", ")", ")", "\n", "\n", "# Wrap into other dataset (__getitem__ changes)", "\n", "", "if", "to_augmented_dataset", ":", "# Dataset returns an image and an augmentation of that image.", "\n", "        ", "from", "data", ".", "custom_dataset", "import", "AugmentedDataset", "\n", "dataset", "=", "AugmentedDataset", "(", "dataset", ")", "\n", "\n", "", "if", "to_neighbors_dataset", ":", "# Dataset returns an image and one of its nearest neighbors.", "\n", "        ", "from", "data", ".", "custom_dataset", "import", "NeighborsDataset", "\n", "indices", "=", "np", ".", "load", "(", "p", "[", "'topk_neighbors_train_path'", "]", ")", "\n", "dataset", "=", "NeighborsDataset", "(", "dataset", ",", "indices", ",", "p", "[", "'num_neighbors'", "]", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset": [[167, 204], ["CIFAR10", "numpy.load", "NeighborsDataset", "CIFAR100", "STL10", "TinyImageNet", "ImageNet", "ImageNetSubset", "ValueError"], "function", ["None"], ["", "def", "get_val_dataset", "(", "p", ",", "transform", "=", "None", ",", "to_neighbors_dataset", "=", "False", ")", ":", "\n", "# Base dataset", "\n", "    ", "if", "p", "[", "'val_db_name'", "]", "==", "'cifar-10'", ":", "\n", "        ", "from", "data", ".", "cifar", "import", "CIFAR10", "\n", "dataset", "=", "CIFAR10", "(", "train", "=", "False", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'val_db_name'", "]", "==", "'cifar-100'", ":", "\n", "        ", "from", "data", ".", "cifar", "import", "CIFAR100", "\n", "dataset", "=", "CIFAR100", "(", "train", "=", "False", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'val_db_name'", "]", "==", "'stl-10'", ":", "\n", "        ", "from", "data", ".", "stl", "import", "STL10", "\n", "dataset", "=", "STL10", "(", "split", "=", "'test'", ",", "transform", "=", "transform", ",", "download", "=", "True", ")", "\n", "\n", "", "elif", "p", "[", "'train_db_name'", "]", "==", "'tiny-imagenet'", ":", "\n", "        ", "from", "data", ".", "tinyimagenet", "import", "TinyImageNet", "\n", "dataset", "=", "TinyImageNet", "(", "root", "=", "''", ",", "split", "=", "'val'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "elif", "p", "[", "'val_db_name'", "]", "==", "'imagenet'", ":", "\n", "        ", "from", "data", ".", "imagenet", "import", "ImageNet", "\n", "dataset", "=", "ImageNet", "(", "split", "=", "'val'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "elif", "p", "[", "'val_db_name'", "]", "in", "[", "'imagenet_50'", ",", "'imagenet_100'", ",", "'imagenet_200'", "]", ":", "\n", "        ", "from", "data", ".", "imagenet", "import", "ImageNetSubset", "\n", "subset_file", "=", "'./data/imagenet_subsets/%s.txt'", "%", "(", "p", "[", "'val_db_name'", "]", ")", "\n", "dataset", "=", "ImageNetSubset", "(", "subset_file", "=", "subset_file", ",", "split", "=", "'val'", ",", "transform", "=", "transform", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid validation dataset {}'", ".", "format", "(", "p", "[", "'val_db_name'", "]", ")", ")", "\n", "\n", "# Wrap into other dataset (__getitem__ changes) ", "\n", "", "if", "to_neighbors_dataset", ":", "# Dataset returns an image and one of its nearest neighbors.", "\n", "        ", "from", "data", ".", "custom_dataset", "import", "NeighborsDataset", "\n", "indices", "=", "np", ".", "load", "(", "p", "[", "'topk_neighbors_val_path'", "]", ")", "\n", "dataset", "=", "NeighborsDataset", "(", "dataset", ",", "indices", ",", "5", ")", "# Only use 5", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataloader": [[206, 210], ["torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_train_dataloader", "(", "p", ",", "dataset", ")", ":", "\n", "    ", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "num_workers", "=", "p", "[", "'num_workers'", "]", ",", "\n", "batch_size", "=", "p", "[", "'batch_size'", "]", ",", "pin_memory", "=", "True", ",", "collate_fn", "=", "collate_custom", ",", "\n", "drop_last", "=", "True", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader": [[212, 216], ["torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_val_dataloader", "(", "p", ",", "dataset", ")", ":", "\n", "    ", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "num_workers", "=", "p", "[", "'num_workers'", "]", ",", "\n", "batch_size", "=", "p", "[", "'batch_size'", "]", ",", "pin_memory", "=", "True", ",", "collate_fn", "=", "collate_custom", ",", "\n", "drop_last", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_transformations": [[218, 256], ["torchvision.Compose", "torchvision.Compose", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.Compose", "ValueError", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.RandomHorizontalFlip", "torchvision.RandomCrop", "data.augment.Augment", "torchvision.ToTensor", "torchvision.Normalize", "data.augment.Cutout", "torchvision.ColorJitter"], "function", ["None"], ["", "def", "get_train_transformations", "(", "p", ")", ":", "\n", "    ", "if", "p", "[", "'augmentation_strategy'", "]", "==", "'standard'", ":", "\n", "# Standard augmentation strategy", "\n", "        ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'random_resized_crop'", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'normalize'", "]", ")", "\n", "]", ")", "\n", "\n", "", "elif", "p", "[", "'augmentation_strategy'", "]", "==", "'simclr'", ":", "\n", "# Augmentation strategy from the SimCLR paper", "\n", "        ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'random_resized_crop'", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "\n", "transforms", ".", "ColorJitter", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'color_jitter'", "]", ")", "\n", "]", ",", "p", "=", "p", "[", "'augmentation_kwargs'", "]", "[", "'color_jitter_random_apply'", "]", "[", "'p'", "]", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'random_grayscale'", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'normalize'", "]", ")", "\n", "]", ")", "\n", "\n", "", "elif", "p", "[", "'augmentation_strategy'", "]", "==", "'ours'", ":", "\n", "# Augmentation strategy from our paper ", "\n", "        ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "p", "[", "'augmentation_kwargs'", "]", "[", "'crop_size'", "]", ")", ",", "\n", "Augment", "(", "p", "[", "'augmentation_kwargs'", "]", "[", "'num_strong_augs'", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "**", "p", "[", "'augmentation_kwargs'", "]", "[", "'normalize'", "]", ")", ",", "\n", "Cutout", "(", "\n", "n_holes", "=", "p", "[", "'augmentation_kwargs'", "]", "[", "'cutout_kwargs'", "]", "[", "'n_holes'", "]", ",", "\n", "length", "=", "p", "[", "'augmentation_kwargs'", "]", "[", "'cutout_kwargs'", "]", "[", "'length'", "]", ",", "\n", "random", "=", "p", "[", "'augmentation_kwargs'", "]", "[", "'cutout_kwargs'", "]", "[", "'random'", "]", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid augmentation strategy {}'", ".", "format", "(", "p", "[", "'augmentation_strategy'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations": [[258, 263], ["torchvision.Compose", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.Normalize"], "function", ["None"], ["", "", "def", "get_val_transformations", "(", "p", ")", ":", "\n", "    ", "return", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "CenterCrop", "(", "p", "[", "'transformation_kwargs'", "]", "[", "'crop_size'", "]", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "**", "p", "[", "'transformation_kwargs'", "]", "[", "'normalize'", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_optimizer": [[265, 289], ["model.named_parameters", "list", "model.parameters", "torch.optim.SGD", "filter", "len", "torch.optim.Adam", "ValueError", "model.parameters"], "function", ["None"], ["", "def", "get_optimizer", "(", "p", ",", "model", ",", "cluster_head_only", "=", "False", ")", ":", "\n", "    ", "if", "cluster_head_only", ":", "# Only weights in the cluster head will be updated ", "\n", "        ", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'cluster_head'", "in", "name", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "True", "\n", "", "else", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "assert", "(", "len", "(", "params", ")", "==", "2", "*", "p", "[", "'num_heads'", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "params", "=", "model", ".", "parameters", "(", ")", "\n", "\n", "\n", "", "if", "p", "[", "'optimizer'", "]", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "params", ",", "**", "p", "[", "'optimizer_kwargs'", "]", ")", "\n", "\n", "", "elif", "p", "[", "'optimizer'", "]", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "**", "p", "[", "'optimizer_kwargs'", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid optimizer {}'", ".", "format", "(", "p", "[", "'optimizer'", "]", ")", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.adjust_learning_rate": [[291, 313], ["numpy.sum", "ValueError", "numpy.array", "math.cos"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "p", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "p", "[", "'optimizer_kwargs'", "]", "[", "'lr'", "]", "\n", "\n", "if", "p", "[", "'scheduler'", "]", "==", "'cosine'", ":", "\n", "        ", "eta_min", "=", "lr", "*", "(", "p", "[", "'scheduler_kwargs'", "]", "[", "'lr_decay_rate'", "]", "**", "3", ")", "\n", "lr", "=", "eta_min", "+", "(", "lr", "-", "eta_min", ")", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "epoch", "/", "p", "[", "'epochs'", "]", ")", ")", "/", "2", "\n", "\n", "", "elif", "p", "[", "'scheduler'", "]", "==", "'step'", ":", "\n", "        ", "steps", "=", "np", ".", "sum", "(", "epoch", ">", "np", ".", "array", "(", "p", "[", "'scheduler_kwargs'", "]", "[", "'lr_decay_epochs'", "]", ")", ")", "\n", "if", "steps", ">", "0", ":", "\n", "            ", "lr", "=", "lr", "*", "(", "p", "[", "'scheduler_kwargs'", "]", "[", "'lr_decay_rate'", "]", "**", "steps", ")", "\n", "\n", "", "", "elif", "p", "[", "'scheduler'", "]", "==", "'constant'", ":", "\n", "        ", "lr", "=", "lr", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid learning rate schedule {}'", ".", "format", "(", "p", "[", "'scheduler'", "]", ")", ")", "\n", "\n", "", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n", "", "return", "lr", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.ema.EMA.__init__": [[7, 11], ["v.clone().detach", "model.state_dict().items", "model.named_parameters", "v.clone", "model.state_dict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "alpha", "=", "0.999", ")", ":", "\n", "        ", "self", ".", "shadow", "=", "{", "k", ":", "v", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "k", ",", "v", "in", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "}", "\n", "self", ".", "param_keys", "=", "[", "k", "for", "k", ",", "_", "in", "model", ".", "named_parameters", "(", ")", "]", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.ema.EMA.update_params": [[12, 16], ["model.state_dict", "ema.EMA.shadow[].copy_"], "methods", ["None"], ["", "def", "update_params", "(", "self", ",", "model", ")", ":", "\n", "        ", "state", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "name", "in", "self", ".", "param_keys", ":", "\n", "            ", "self", ".", "shadow", "[", "name", "]", ".", "copy_", "(", "self", ".", "alpha", "*", "self", ".", "shadow", "[", "name", "]", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "state", "[", "name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.ema.EMA.apply_shadow": [[17, 19], ["model.load_state_dict"], "methods", ["None"], ["", "", "def", "apply_shadow", "(", "self", ",", "model", ")", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "self", ".", "shadow", ",", "strict", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.contrastive_evaluate": [[16, 32], ["torch.no_grad", "torch.no_grad", "utils.utils.AverageMeter", "model.eval", "batch[].cuda", "batch[].cuda", "model", "memory_bank.weighted_knn", "utils.utils.AverageMeter.update", "torch.mean", "torch.mean", "acc1.item", "batch[].cuda.size", "torch.eq().float", "torch.eq().float", "torch.eq", "torch.eq"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.weighted_knn", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "contrastive_evaluate", "(", "val_loader", ",", "model", ",", "memory_bank", ")", ":", "\n", "    ", "top1", "=", "AverageMeter", "(", "'Acc@1'", ",", "':6.2f'", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "val_loader", ":", "\n", "        ", "images", "=", "batch", "[", "'image'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "target", "=", "batch", "[", "'target'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "output", "=", "model", "(", "images", ")", "\n", "output", "=", "memory_bank", ".", "weighted_knn", "(", "output", ")", "\n", "\n", "acc1", "=", "100", "*", "torch", ".", "mean", "(", "torch", ".", "eq", "(", "output", ",", "target", ")", ".", "float", "(", ")", ")", "\n", "top1", ".", "update", "(", "acc1", ".", "item", "(", ")", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "", "return", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.get_predictions": [[34, 85], ["torch.no_grad", "torch.no_grad", "model.eval", "isinstance", "torch.cat", "torch.cat", "utils.common_config.get_feature_dimensions_backbone", "torch.zeros().cuda", "torch.zeros().cuda", "batch[].cuda", "model", "enumerate", "torch.cat.append", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat", "torch.cat", "range", "range", "predictions[].append", "probs[].append", "torch.cat.append", "torch.zeros().cuda.cpu", "torch.zeros", "torch.zeros", "torch.argmax", "torch.argmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zip", "zip", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_feature_dimensions_backbone", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_predictions", "(", "p", ",", "dataloader", ",", "model", ",", "return_features", "=", "False", ")", ":", "\n", "# Make predictions on a dataset with neighbors", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "predictions", "=", "[", "[", "]", "for", "_", "in", "range", "(", "p", "[", "'num_heads'", "]", ")", "]", "\n", "probs", "=", "[", "[", "]", "for", "_", "in", "range", "(", "p", "[", "'num_heads'", "]", ")", "]", "\n", "targets", "=", "[", "]", "\n", "if", "return_features", ":", "\n", "        ", "ft_dim", "=", "get_feature_dimensions_backbone", "(", "p", ")", "\n", "features", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataloader", ".", "sampler", ")", ",", "ft_dim", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "", "if", "isinstance", "(", "dataloader", ".", "dataset", ",", "NeighborsDataset", ")", ":", "# Also return the neighbors", "\n", "        ", "key_", "=", "'anchor'", "\n", "include_neighbors", "=", "True", "\n", "neighbors", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "        ", "key_", "=", "'image'", "\n", "include_neighbors", "=", "False", "\n", "\n", "", "ptr", "=", "0", "\n", "for", "batch", "in", "dataloader", ":", "\n", "        ", "images", "=", "batch", "[", "key_", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "bs", "=", "images", ".", "shape", "[", "0", "]", "\n", "res", "=", "model", "(", "images", ",", "forward_pass", "=", "'return_all'", ")", "\n", "output", "=", "res", "[", "'output'", "]", "\n", "if", "return_features", ":", "\n", "            ", "features", "[", "ptr", ":", "ptr", "+", "bs", "]", "=", "res", "[", "'features'", "]", "\n", "ptr", "+=", "bs", "\n", "", "for", "i", ",", "output_i", "in", "enumerate", "(", "output", ")", ":", "\n", "            ", "predictions", "[", "i", "]", ".", "append", "(", "torch", ".", "argmax", "(", "output_i", ",", "dim", "=", "1", ")", ")", "\n", "probs", "[", "i", "]", ".", "append", "(", "F", ".", "softmax", "(", "output_i", ",", "dim", "=", "1", ")", ")", "\n", "", "targets", ".", "append", "(", "batch", "[", "'target'", "]", ")", "\n", "if", "include_neighbors", ":", "\n", "            ", "neighbors", ".", "append", "(", "batch", "[", "'possible_neighbors'", "]", ")", "\n", "\n", "", "", "predictions", "=", "[", "torch", ".", "cat", "(", "pred_", ",", "dim", "=", "0", ")", ".", "cpu", "(", ")", "for", "pred_", "in", "predictions", "]", "\n", "probs", "=", "[", "torch", ".", "cat", "(", "prob_", ",", "dim", "=", "0", ")", ".", "cpu", "(", ")", "for", "prob_", "in", "probs", "]", "\n", "targets", "=", "torch", ".", "cat", "(", "targets", ",", "dim", "=", "0", ")", "\n", "\n", "if", "include_neighbors", ":", "\n", "        ", "neighbors", "=", "torch", ".", "cat", "(", "neighbors", ",", "dim", "=", "0", ")", "\n", "out", "=", "[", "{", "'predictions'", ":", "pred_", ",", "'probabilities'", ":", "prob_", ",", "'targets'", ":", "targets", ",", "'neighbors'", ":", "neighbors", "}", "for", "pred_", ",", "prob_", "in", "zip", "(", "predictions", ",", "probs", ")", "]", "\n", "\n", "", "else", ":", "\n", "        ", "out", "=", "[", "{", "'predictions'", ":", "pred_", ",", "'probabilities'", ":", "prob_", ",", "'targets'", ":", "targets", "}", "for", "pred_", ",", "prob_", "in", "zip", "(", "predictions", ",", "probs", ")", "]", "\n", "\n", "", "if", "return_features", ":", "\n", "        ", "return", "out", ",", "features", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.scan_evaluate": [[87, 120], ["torch.no_grad", "torch.no_grad", "len", "numpy.argmin", "numpy.min", "torch.arange().view().expand_as", "torch.arange().view().expand_as", "losses.losses.entropy().item", "torch.matmul", "torch.matmul", "neighbors.contiguous().view.contiguous().view", "anchors.contiguous().view.contiguous().view", "torch.ones_like", "torch.ones_like", "torch.binary_cross_entropy().item", "output.append", "probs.t", "torch.arange().view", "torch.arange().view", "losses.losses.entropy", "neighbors.contiguous().view.contiguous", "anchors.contiguous().view.contiguous", "torch.binary_cross_entropy", "torch.mean", "torch.mean", "torch.arange", "torch.arange", "neighbors.contiguous().view.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.entropy"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "scan_evaluate", "(", "predictions", ")", ":", "\n", "# Evaluate model based on SCAN loss.", "\n", "    ", "num_heads", "=", "len", "(", "predictions", ")", "\n", "output", "=", "[", "]", "\n", "\n", "for", "head", "in", "predictions", ":", "\n", "# Neighbors and anchors", "\n", "        ", "probs", "=", "head", "[", "'probabilities'", "]", "\n", "neighbors", "=", "head", "[", "'neighbors'", "]", "\n", "anchors", "=", "torch", ".", "arange", "(", "neighbors", ".", "size", "(", "0", ")", ")", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "neighbors", ")", "\n", "\n", "# Entropy loss", "\n", "entropy_loss", "=", "entropy", "(", "torch", ".", "mean", "(", "probs", ",", "dim", "=", "0", ")", ",", "input_as_probabilities", "=", "True", ")", ".", "item", "(", ")", "\n", "\n", "# Consistency loss       ", "\n", "similarity", "=", "torch", ".", "matmul", "(", "probs", ",", "probs", ".", "t", "(", ")", ")", "\n", "neighbors", "=", "neighbors", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "anchors", "=", "anchors", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "similarity", "=", "similarity", "[", "anchors", ",", "neighbors", "]", "\n", "ones", "=", "torch", ".", "ones_like", "(", "similarity", ")", "\n", "consistency_loss", "=", "F", ".", "binary_cross_entropy", "(", "similarity", ",", "ones", ")", ".", "item", "(", ")", "\n", "\n", "# Total loss", "\n", "total_loss", "=", "-", "entropy_loss", "+", "consistency_loss", "\n", "\n", "output", ".", "append", "(", "{", "'entropy'", ":", "entropy_loss", ",", "'consistency'", ":", "consistency_loss", ",", "'total_loss'", ":", "total_loss", "}", ")", "\n", "\n", "", "total_losses", "=", "[", "output_", "[", "'total_loss'", "]", "for", "output_", "in", "output", "]", "\n", "lowest_loss_head", "=", "np", ".", "argmin", "(", "total_losses", ")", "\n", "lowest_loss", "=", "np", ".", "min", "(", "total_losses", ")", "\n", "\n", "return", "{", "'scan'", ":", "output", ",", "'lowest_loss_head'", ":", "lowest_loss_head", ",", "'lowest_loss'", ":", "lowest_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate": [[122, 160], ["torch.no_grad", "torch.no_grad", "head[].cuda", "head[].cuda", "head[].cuda", "torch.unique().numel", "torch.unique().numel", "head[].cuda.size", "evaluate_utils._hungarian_match", "torch.zeros().cuda", "torch.zeros().cuda", "sklearn.metrics.normalized_mutual_info_score", "sklearn.metrics.adjusted_rand_score", "head[].cuda.topk", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.eq", "int", "int", "float", "head[].cuda.cpu().numpy", "head[].cuda.cpu().numpy", "head[].cuda.cpu().numpy", "head[].cuda.cpu().numpy", "int", "head[].cuda.view().expand_as", "float", "float", "utils.utils.confusion_matrix", "torch.unique", "torch.unique", "torch.zeros", "torch.zeros", "reordered_preds_top5.eq.sum", "torch.zeros().cuda.cpu().numpy", "head[].cuda.cpu().numpy", "head[].cuda.cpu", "head[].cuda.cpu", "head[].cuda.cpu", "head[].cuda.cpu", "head[].cuda.view", "int", "int", "torch.zeros().cuda.cpu", "head[].cuda.cpu"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils._hungarian_match", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.confusion_matrix", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "hungarian_evaluate", "(", "subhead_index", ",", "all_predictions", ",", "class_names", "=", "None", ",", "\n", "compute_purity", "=", "True", ",", "compute_confusion_matrix", "=", "True", ",", "\n", "confusion_matrix_file", "=", "None", ")", ":", "\n", "# Evaluate model based on hungarian matching between predicted cluster assignment and gt classes.", "\n", "# This is computed only for the passed subhead index.", "\n", "\n", "# Hungarian matching", "\n", "    ", "head", "=", "all_predictions", "[", "subhead_index", "]", "\n", "targets", "=", "head", "[", "'targets'", "]", ".", "cuda", "(", ")", "\n", "predictions", "=", "head", "[", "'predictions'", "]", ".", "cuda", "(", ")", "\n", "probs", "=", "head", "[", "'probabilities'", "]", ".", "cuda", "(", ")", "\n", "num_classes", "=", "torch", ".", "unique", "(", "targets", ")", ".", "numel", "(", ")", "\n", "num_elems", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "match", "=", "_hungarian_match", "(", "predictions", ",", "targets", ",", "preds_k", "=", "num_classes", ",", "targets_k", "=", "num_classes", ")", "\n", "reordered_preds", "=", "torch", ".", "zeros", "(", "num_elems", ",", "dtype", "=", "predictions", ".", "dtype", ")", ".", "cuda", "(", ")", "\n", "for", "pred_i", ",", "target_i", "in", "match", ":", "\n", "        ", "reordered_preds", "[", "predictions", "==", "int", "(", "pred_i", ")", "]", "=", "int", "(", "target_i", ")", "\n", "\n", "# Gather performance metrics", "\n", "", "acc", "=", "int", "(", "(", "reordered_preds", "==", "targets", ")", ".", "sum", "(", ")", ")", "/", "float", "(", "num_elems", ")", "\n", "nmi", "=", "metrics", ".", "normalized_mutual_info_score", "(", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "predictions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ari", "=", "metrics", ".", "adjusted_rand_score", "(", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "predictions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "_", ",", "preds_top5", "=", "probs", ".", "topk", "(", "5", ",", "1", ",", "largest", "=", "True", ")", "\n", "reordered_preds_top5", "=", "torch", ".", "zeros_like", "(", "preds_top5", ")", "\n", "for", "pred_i", ",", "target_i", "in", "match", ":", "\n", "        ", "reordered_preds_top5", "[", "preds_top5", "==", "int", "(", "pred_i", ")", "]", "=", "int", "(", "target_i", ")", "\n", "", "correct_top5_binary", "=", "reordered_preds_top5", ".", "eq", "(", "targets", ".", "view", "(", "-", "1", ",", "1", ")", ".", "expand_as", "(", "reordered_preds_top5", ")", ")", "\n", "top5", "=", "float", "(", "correct_top5_binary", ".", "sum", "(", ")", ")", "/", "float", "(", "num_elems", ")", "\n", "\n", "# Compute confusion matrix", "\n", "if", "compute_confusion_matrix", ":", "\n", "        ", "confusion_matrix", "(", "reordered_preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "class_names", ",", "confusion_matrix_file", ")", "\n", "\n", "", "return", "{", "'ACC'", ":", "acc", ",", "'ARI'", ":", "ari", ",", "'NMI'", ":", "nmi", ",", "'ACC Top-5'", ":", "top5", ",", "'hungarian_match'", ":", "match", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils._hungarian_match": [[162, 187], ["torch.no_grad", "torch.no_grad", "numpy.zeros", "range", "scipy.optimize.linear_sum_assignment", "numpy.array", "range", "list", "res.append", "int", "zip"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_hungarian_match", "(", "flat_preds", ",", "flat_targets", ",", "preds_k", ",", "targets_k", ")", ":", "\n", "# Based on implementation from IIC", "\n", "    ", "num_samples", "=", "flat_targets", ".", "shape", "[", "0", "]", "\n", "\n", "assert", "(", "preds_k", "==", "targets_k", ")", "# one to one", "\n", "num_k", "=", "preds_k", "\n", "num_correct", "=", "np", ".", "zeros", "(", "(", "num_k", ",", "num_k", ")", ")", "\n", "\n", "for", "c1", "in", "range", "(", "num_k", ")", ":", "\n", "        ", "for", "c2", "in", "range", "(", "num_k", ")", ":", "\n", "# elementwise, so each sample contributes once", "\n", "            ", "votes", "=", "int", "(", "(", "(", "flat_preds", "==", "c1", ")", "*", "(", "flat_targets", "==", "c2", ")", ")", ".", "sum", "(", ")", ")", "\n", "num_correct", "[", "c1", ",", "c2", "]", "=", "votes", "\n", "\n", "# num_correct is small", "\n", "", "", "match", "=", "linear_sum_assignment", "(", "num_samples", "-", "num_correct", ")", "\n", "match", "=", "np", ".", "array", "(", "list", "(", "zip", "(", "*", "match", ")", ")", ")", "\n", "\n", "# return as list of tuples, out_c to gt_c", "\n", "res", "=", "[", "]", "\n", "for", "out_c", ",", "gt_c", "in", "match", ":", "\n", "        ", "res", ".", "append", "(", "(", "out_c", ",", "gt_c", ")", ")", "\n", "\n", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.train_utils.simclr_train": [[10, 41], ["utils.utils.AverageMeter", "utils.utils.ProgressMeter", "model.train", "enumerate", "len", "images.size", "torch.cat", "input_.cuda.view", "input_.cuda.cuda", "batch[].cuda", "model().view", "criterion", "utils.utils.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "criterion.item", "utils.utils.ProgressMeter.display", "images.unsqueeze", "images_augmented.unsqueeze", "model"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter.display"], ["def", "simclr_train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\" \n    Train according to the scheme from SimCLR\n    https://arxiv.org/abs/2002.05709\n    \"\"\"", "\n", "losses", "=", "AverageMeter", "(", "'Loss'", ",", "':.4e'", ")", "\n", "progress", "=", "ProgressMeter", "(", "len", "(", "train_loader", ")", ",", "\n", "[", "losses", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "images", "=", "batch", "[", "'image'", "]", "\n", "images_augmented", "=", "batch", "[", "'image_augmented'", "]", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "images", ".", "size", "(", ")", "\n", "input_", "=", "torch", ".", "cat", "(", "[", "images", ".", "unsqueeze", "(", "1", ")", ",", "images_augmented", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "input_", "=", "input_", ".", "view", "(", "-", "1", ",", "c", ",", "h", ",", "w", ")", "\n", "input_", "=", "input_", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "targets", "=", "batch", "[", "'target'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "output", "=", "model", "(", "input_", ")", ".", "view", "(", "b", ",", "2", ",", "-", "1", ")", "\n", "loss", "=", "criterion", "(", "output", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "25", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.train_utils.scan_train": [[43, 97], ["utils.utils.AverageMeter", "utils.utils.AverageMeter", "utils.utils.AverageMeter", "utils.utils.ProgressMeter", "enumerate", "len", "model.eval", "model.train", "batch[].cuda", "batch[].cuda", "zip", "utils.utils.AverageMeter.update", "utils.utils.AverageMeter.update", "utils.utils.AverageMeter.update", "torch.sum", "optimizer.zero_grad", "torch.sum.backward", "optimizer.step", "model", "model", "model", "model", "criterion", "torch.sum.append", "consistency_loss.append", "entropy_loss.append", "numpy.mean", "numpy.mean", "numpy.mean", "torch.stack", "utils.utils.ProgressMeter.display", "torch.no_grad", "model", "model", "v.item", "v.item", "v.item"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter.display"], ["", "", "", "def", "scan_train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "update_cluster_head_only", "=", "False", ")", ":", "\n", "    ", "\"\"\" \n    Train w/ SCAN-Loss\n    \"\"\"", "\n", "total_losses", "=", "AverageMeter", "(", "'Total Loss'", ",", "':.4e'", ")", "\n", "consistency_losses", "=", "AverageMeter", "(", "'Consistency Loss'", ",", "':.4e'", ")", "\n", "entropy_losses", "=", "AverageMeter", "(", "'Entropy'", ",", "':.4e'", ")", "\n", "progress", "=", "ProgressMeter", "(", "len", "(", "train_loader", ")", ",", "\n", "[", "total_losses", ",", "consistency_losses", ",", "entropy_losses", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "if", "update_cluster_head_only", ":", "\n", "        ", "model", ".", "eval", "(", ")", "# No need to update BN", "\n", "", "else", ":", "\n", "        ", "model", ".", "train", "(", ")", "# Update BN", "\n", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# Forward pass", "\n", "        ", "anchors", "=", "batch", "[", "'anchor'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "neighbors", "=", "batch", "[", "'neighbor'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "if", "update_cluster_head_only", ":", "# Only calculate gradient for backprop of linear layer", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "anchors_features", "=", "model", "(", "anchors", ",", "forward_pass", "=", "'backbone'", ")", "\n", "neighbors_features", "=", "model", "(", "neighbors", ",", "forward_pass", "=", "'backbone'", ")", "\n", "", "anchors_output", "=", "model", "(", "anchors_features", ",", "forward_pass", "=", "'head'", ")", "\n", "neighbors_output", "=", "model", "(", "neighbors_features", ",", "forward_pass", "=", "'head'", ")", "\n", "\n", "", "else", ":", "# Calculate gradient for backprop of complete network", "\n", "            ", "anchors_output", "=", "model", "(", "anchors", ")", "\n", "neighbors_output", "=", "model", "(", "neighbors", ")", "\n", "\n", "# Loss for every head", "\n", "", "total_loss", ",", "consistency_loss", ",", "entropy_loss", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "anchors_output_subhead", ",", "neighbors_output_subhead", "in", "zip", "(", "anchors_output", ",", "neighbors_output", ")", ":", "\n", "            ", "total_loss_", ",", "consistency_loss_", ",", "entropy_loss_", "=", "criterion", "(", "anchors_output_subhead", ",", "\n", "neighbors_output_subhead", ")", "\n", "total_loss", ".", "append", "(", "total_loss_", ")", "\n", "consistency_loss", ".", "append", "(", "consistency_loss_", ")", "\n", "entropy_loss", ".", "append", "(", "entropy_loss_", ")", "\n", "\n", "# Register the mean loss and backprop the total loss to cover all subheads", "\n", "", "total_losses", ".", "update", "(", "np", ".", "mean", "(", "[", "v", ".", "item", "(", ")", "for", "v", "in", "total_loss", "]", ")", ")", "\n", "consistency_losses", ".", "update", "(", "np", ".", "mean", "(", "[", "v", ".", "item", "(", ")", "for", "v", "in", "consistency_loss", "]", ")", ")", "\n", "entropy_losses", ".", "update", "(", "np", ".", "mean", "(", "[", "v", ".", "item", "(", ")", "for", "v", "in", "entropy_loss", "]", ")", ")", "\n", "\n", "total_loss", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "total_loss", ",", "dim", "=", "0", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "25", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.train_utils.selflabel_train": [[99, 129], ["utils.utils.AverageMeter", "utils.utils.ProgressMeter", "model.train", "enumerate", "len", "batch[].cuda", "batch[].cuda", "criterion", "utils.utils.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "torch.no_grad", "model", "criterion.item", "ema.update_params", "ema.apply_shadow", "utils.utils.ProgressMeter.display", "model"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.ema.EMA.update_params", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.ema.EMA.apply_shadow", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter.display"], ["", "", "", "def", "selflabel_train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "ema", "=", "None", ")", ":", "\n", "    ", "\"\"\" \n    Self-labeling based on confident samples\n    \"\"\"", "\n", "losses", "=", "AverageMeter", "(", "'Loss'", ",", "':.4e'", ")", "\n", "progress", "=", "ProgressMeter", "(", "len", "(", "train_loader", ")", ",", "[", "losses", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "images", "=", "batch", "[", "'image'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "images_augmented", "=", "batch", "[", "'image_augmented'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "images", ")", "[", "0", "]", "\n", "", "output_augmented", "=", "model", "(", "images_augmented", ")", "[", "0", "]", "\n", "\n", "loss", "=", "criterion", "(", "output", ",", "output_augmented", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "ema", "is", "not", "None", ":", "# Apply EMA to update the weights of the network", "\n", "            ", "ema", ".", "update_params", "(", "model", ")", "\n", "ema", ".", "apply_shadow", "(", "model", ")", "\n", "\n", "", "if", "i", "%", "25", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.AverageMeter.__init__": [[20, 24], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "fmt", "=", "':f'", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "fmt", "=", "fmt", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.AverageMeter.reset": [[25, 30], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.AverageMeter.update": [[31, 36], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.AverageMeter.__str__": [[37, 40], ["fmtstr.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmtstr", "=", "'{name} {val'", "+", "self", ".", "fmt", "+", "'} ({avg'", "+", "self", ".", "fmt", "+", "'})'", "\n", "return", "fmtstr", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter.__init__": [[43, 47], ["utils.ProgressMeter._get_batch_fmtstr"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter._get_batch_fmtstr"], ["    ", "def", "__init__", "(", "self", ",", "num_batches", ",", "meters", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "batch_fmtstr", "=", "self", ".", "_get_batch_fmtstr", "(", "num_batches", ")", "\n", "self", ".", "meters", "=", "meters", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter.display": [[48, 52], ["print", "str", "utils.ProgressMeter.batch_fmtstr.format"], "methods", ["None"], ["", "def", "display", "(", "self", ",", "batch", ")", ":", "\n", "        ", "entries", "=", "[", "self", ".", "prefix", "+", "self", ".", "batch_fmtstr", ".", "format", "(", "batch", ")", "]", "\n", "entries", "+=", "[", "str", "(", "meter", ")", "for", "meter", "in", "self", ".", "meters", "]", "\n", "print", "(", "'\\t'", ".", "join", "(", "entries", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.ProgressMeter._get_batch_fmtstr": [[53, 57], ["len", "str", "str", "fmt.format"], "methods", ["None"], ["", "def", "_get_batch_fmtstr", "(", "self", ",", "num_batches", ")", ":", "\n", "        ", "num_digits", "=", "len", "(", "str", "(", "num_batches", "//", "1", ")", ")", "\n", "fmt", "=", "'{:'", "+", "str", "(", "num_digits", ")", "+", "'d}'", "\n", "return", "'['", "+", "fmt", "+", "'/'", "+", "fmt", ".", "format", "(", "num_batches", ")", "+", "']'", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.mkdir_if_missing": [[10, 17], ["os.path.exists", "os.makedirs"], "function", ["None"], ["def", "mkdir_if_missing", "(", "directory", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ")", "\n", "", "except", "OSError", "as", "e", ":", "\n", "            ", "if", "e", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "                ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank": [[59, 71], ["torch.no_grad", "model.eval", "memory_bank.reset", "enumerate", "batch[].cuda", "batch[].cuda", "model", "memory_bank.update", "print", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fill_memory_bank", "(", "loader", ",", "model", ",", "memory_bank", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "memory_bank", ".", "reset", "(", ")", "\n", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ")", ":", "\n", "        ", "images", "=", "batch", "[", "'image'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "targets", "=", "batch", "[", "'target'", "]", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "output", ",", "pre_last", "=", "model", "(", "images", ",", "return_pre_last", "=", "True", ")", "\n", "memory_bank", ".", "update", "(", "output", ",", "pre_last", ",", "targets", ")", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "'Fill Memory Bank [%d/%d]'", "%", "(", "i", ",", "len", "(", "loader", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.confusion_matrix": [[73, 99], ["sklearn.metrics.confusion_matrix", "plt.subplots", "plt.imshow", "axes.set_xticks", "axes.set_yticks", "axes.set_xticklabels", "axes.set_yticklabels", "numpy.ndenumerate", "plt.tight_layout", "plt.close", "numpy.sum", "plt.show", "plt.savefig", "axes.text", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.confusion_matrix"], ["", "", "", "def", "confusion_matrix", "(", "predictions", ",", "gt", ",", "class_names", ",", "output_file", "=", "None", ")", ":", "\n", "# Plot confusion_matrix and store result to output_file", "\n", "    ", "import", "sklearn", ".", "metrics", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "confusion_matrix", "=", "sklearn", ".", "metrics", ".", "confusion_matrix", "(", "gt", ",", "predictions", ")", "\n", "confusion_matrix", "=", "confusion_matrix", "/", "np", ".", "sum", "(", "confusion_matrix", ",", "1", ")", "\n", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "1", ")", "\n", "plt", ".", "imshow", "(", "confusion_matrix", ",", "cmap", "=", "'Blues'", ")", "\n", "axes", ".", "set_xticks", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", ")", "\n", "axes", ".", "set_yticks", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", ")", "\n", "axes", ".", "set_xticklabels", "(", "class_names", ",", "ha", "=", "'right'", ",", "fontsize", "=", "8", ",", "rotation", "=", "40", ")", "\n", "axes", ".", "set_yticklabels", "(", "class_names", ",", "ha", "=", "'right'", ",", "fontsize", "=", "8", ")", "\n", "\n", "for", "(", "i", ",", "j", ")", ",", "z", "in", "np", ".", "ndenumerate", "(", "confusion_matrix", ")", ":", "\n", "        ", "if", "i", "==", "j", ":", "\n", "            ", "axes", ".", "text", "(", "j", ",", "i", ",", "'%d'", "%", "(", "100", "*", "z", ")", ",", "ha", "=", "'center'", ",", "va", "=", "'center'", ",", "color", "=", "'white'", ",", "fontsize", "=", "6", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "", "plt", ".", "tight_layout", "(", ")", "\n", "if", "output_file", "is", "None", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "savefig", "(", "output_file", ",", "dpi", "=", "300", ",", "bbox_inches", "=", "'tight'", ")", "\n", "", "plt", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.__init__": [[10, 21], ["torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "dim", ",", "num_classes", ",", "temperature", ",", "feature_dim", "=", "512", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "features", "=", "torch", ".", "FloatTensor", "(", "self", ".", "n", ",", "self", ".", "dim", ")", "\n", "self", ".", "pre_lasts", "=", "torch", ".", "FloatTensor", "(", "self", ".", "n", ",", "feature_dim", ")", "\n", "self", ".", "targets", "=", "torch", ".", "LongTensor", "(", "self", ".", "n", ")", "\n", "self", ".", "ptr", "=", "0", "\n", "self", ".", "device", "=", "'cpu'", "\n", "self", ".", "K", "=", "100", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "C", "=", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.weighted_knn": [[22, 39], ["torch.zeros().to", "torch.matmul", "torch.matmul.topk", "memory.MemoryBank.targets.view().expand", "torch.gather", "torch.zeros().to.resize_().zero_", "torch.zeros().to.scatter_", "yd.clone().div_().exp_", "torch.sum", "torch.sum.sort", "memory.MemoryBank.features.t", "torch.gather.view", "torch.mul", "torch.zeros", "memory.MemoryBank.targets.view", "torch.zeros().to.resize_", "yd.clone().div_", "torch.zeros().to.view", "yd.clone().div_().exp_.view", "yd.clone"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to"], ["", "def", "weighted_knn", "(", "self", ",", "predictions", ")", ":", "\n", "# perform weighted knn", "\n", "        ", "retrieval_one_hot", "=", "torch", ".", "zeros", "(", "self", ".", "K", ",", "self", ".", "C", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "batchSize", "=", "predictions", ".", "shape", "[", "0", "]", "\n", "correlation", "=", "torch", ".", "matmul", "(", "predictions", ",", "self", ".", "features", ".", "t", "(", ")", ")", "\n", "yd", ",", "yi", "=", "correlation", ".", "topk", "(", "self", ".", "K", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "candidates", "=", "self", ".", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "batchSize", ",", "-", "1", ")", "\n", "retrieval", "=", "torch", ".", "gather", "(", "candidates", ",", "1", ",", "yi", ")", "\n", "retrieval_one_hot", ".", "resize_", "(", "batchSize", "*", "self", ".", "K", ",", "self", ".", "C", ")", ".", "zero_", "(", ")", "\n", "retrieval_one_hot", ".", "scatter_", "(", "1", ",", "retrieval", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1", ")", "\n", "yd_transform", "=", "yd", ".", "clone", "(", ")", ".", "div_", "(", "self", ".", "temperature", ")", ".", "exp_", "(", ")", "\n", "probs", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "retrieval_one_hot", ".", "view", "(", "batchSize", ",", "-", "1", ",", "self", ".", "C", ")", ",", "\n", "yd_transform", ".", "view", "(", "batchSize", ",", "-", "1", ",", "1", ")", ")", ",", "1", ")", "\n", "_", ",", "class_preds", "=", "probs", ".", "sort", "(", "1", ",", "True", ")", "\n", "class_pred", "=", "class_preds", "[", ":", ",", "0", "]", "\n", "\n", "return", "class_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.knn": [[40, 46], ["torch.matmul", "torch.argmax", "torch.index_select", "memory.MemoryBank.features.t"], "methods", ["None"], ["", "def", "knn", "(", "self", ",", "predictions", ")", ":", "\n", "# perform knn", "\n", "        ", "correlation", "=", "torch", ".", "matmul", "(", "predictions", ",", "self", ".", "features", ".", "t", "(", ")", ")", "\n", "sample_pred", "=", "torch", ".", "argmax", "(", "correlation", ",", "dim", "=", "1", ")", "\n", "class_pred", "=", "torch", ".", "index_select", "(", "self", ".", "targets", ",", "0", ",", "sample_pred", ")", "\n", "return", "class_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors": [[47, 67], ["memory.MemoryBank.features.cpu().numpy", "faiss.IndexFlatIP", "faiss.index_cpu_to_all_gpus", "faiss.index_cpu_to_all_gpus.add", "faiss.index_cpu_to_all_gpus.search", "memory.MemoryBank.targets.cpu().numpy", "numpy.take", "numpy.repeat", "numpy.mean", "memory.MemoryBank.features.cpu", "memory.MemoryBank.reshape", "memory.MemoryBank.targets.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "mine_nearest_neighbors", "(", "self", ",", "topk", ",", "calculate_accuracy", "=", "True", ")", ":", "\n", "# mine the topk nearest neighbors for every sample", "\n", "        ", "import", "faiss", "\n", "features", "=", "self", ".", "features", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "n", ",", "dim", "=", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", "\n", "index", "=", "faiss", ".", "IndexFlatIP", "(", "dim", ")", "\n", "index", "=", "faiss", ".", "index_cpu_to_all_gpus", "(", "index", ")", "\n", "index", ".", "add", "(", "features", ")", "\n", "distances", ",", "indices", "=", "index", ".", "search", "(", "features", ",", "topk", "+", "1", ")", "# Sample itself is included", "\n", "\n", "# evaluate ", "\n", "if", "calculate_accuracy", ":", "\n", "            ", "targets", "=", "self", ".", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "neighbor_targets", "=", "np", ".", "take", "(", "targets", ",", "indices", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "0", ")", "# Exclude sample itself for eval", "\n", "anchor_targets", "=", "np", ".", "repeat", "(", "targets", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "topk", ",", "axis", "=", "1", ")", "\n", "accuracy", "=", "np", ".", "mean", "(", "neighbor_targets", "==", "anchor_targets", ")", "\n", "return", "indices", ",", "accuracy", "\n", "\n", "", "else", ":", "\n", "            ", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset": [[68, 70], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ptr", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.update": [[71, 80], ["features.size", "memory.MemoryBank.features[].copy_", "memory.MemoryBank.pre_lasts[].copy_", "memory.MemoryBank.targets[].copy_", "features.detach", "pre_last.detach", "targets.detach"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "features", ",", "pre_last", ",", "targets", ")", ":", "\n", "        ", "b", "=", "features", ".", "size", "(", "0", ")", "\n", "\n", "assert", "(", "b", "+", "self", ".", "ptr", "<=", "self", ".", "n", ")", "\n", "\n", "self", ".", "features", "[", "self", ".", "ptr", ":", "self", ".", "ptr", "+", "b", "]", ".", "copy_", "(", "features", ".", "detach", "(", ")", ")", "\n", "self", ".", "pre_lasts", "[", "self", ".", "ptr", ":", "self", ".", "ptr", "+", "b", "]", ".", "copy_", "(", "pre_last", ".", "detach", "(", ")", ")", "\n", "self", ".", "targets", "[", "self", ".", "ptr", ":", "self", ".", "ptr", "+", "b", "]", ".", "copy_", "(", "targets", ".", "detach", "(", ")", ")", "\n", "self", ".", "ptr", "+=", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to": [[81, 86], ["memory.MemoryBank.features.to", "memory.MemoryBank.pre_lasts.to", "memory.MemoryBank.targets.to"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "features", "=", "self", ".", "features", ".", "to", "(", "device", ")", "\n", "self", ".", "pre_lasts", "=", "self", ".", "pre_lasts", ".", "to", "(", "device", ")", "\n", "self", ".", "targets", "=", "self", ".", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu": [[87, 89], ["memory.MemoryBank.to"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "        ", "self", ".", "to", "(", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda": [[90, 92], ["memory.MemoryBank.to"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.to"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "to", "(", "'cuda:0'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.__init__": [[31, 59], ["tiny_imagenet.TinyImageNet.check_root", "torchvision.utils.verify_str_arg", "tiny_imagenet.TinyImageNet.load_wnid_to_classes", "torchvision.ImageFolder.__init__", "numpy.load", "enumerate", "numpy.load", "tiny_imagenet.TinyImageNet.load_val_data", "os.path.join", "range", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.check_root", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.load_wnid_to_classes", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.load_val_data"], ["def", "__init__", "(", "self", ",", "root", ":", "str", ",", "split", ":", "str", "=", "'train'", ",", "transform", "=", "None", ",", "test_transform", "=", "None", ",", "only_features", "=", "False", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "\n", "assert", "self", ".", "check_root", "(", ")", ",", "\"Something is wrong with the Tiny ImageNet dataset path. Download the official dataset zip from http://cs231n.stanford.edu/tiny-imagenet-200.zip and unzip it inside {}.\"", ".", "format", "(", "self", ".", "root", ")", "\n", "self", ".", "split", "=", "datasets", ".", "utils", ".", "verify_str_arg", "(", "split", ",", "\"split\"", ",", "(", "\"train\"", ",", "\"val\"", ")", ")", "\n", "wnid_to_classes", "=", "self", ".", "load_wnid_to_classes", "(", ")", "\n", "\n", "super", "(", "TinyImageNet", ",", "self", ")", ".", "__init__", "(", "self", ".", "split_folder", ",", "**", "kwargs", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "wnids", "=", "self", ".", "classes", "\n", "self", ".", "wnid_to_idx", "=", "self", ".", "class_to_idx", "\n", "self", ".", "classes", "=", "[", "wnid_to_classes", "[", "wnid", "]", "for", "wnid", "in", "self", ".", "wnids", "]", "\n", "self", ".", "class_to_idx", "=", "{", "cls", ":", "idx", "\n", "for", "idx", ",", "clss", "in", "enumerate", "(", "self", ".", "classes", ")", "\n", "for", "cls", "in", "clss", "}", "\n", "# Tiny ImageNet val directory structure is not similar to that of train's", "\n", "# So a custom loading function is necessary", "\n", "self", ".", "only_features", "=", "only_features", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "features", "=", "np", ".", "load", "(", "'../../scan/results/tiny-imagenet/pretext/features_seed1.npy'", ")", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "features", "=", "np", ".", "load", "(", "'../../scan/results/tiny-imagenet/pretext/test_features_seed1.npy'", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "imgs", ",", "self", ".", "targets", "=", "self", ".", "load_val_data", "(", ")", "\n", "self", ".", "samples", "=", "[", "(", "self", ".", "imgs", "[", "idx", "]", ",", "self", ".", "targets", "[", "idx", "]", ")", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "imgs", ")", ")", "]", "\n", "self", ".", "root", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'val'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.split_folder": [[64, 67], ["os.path.join"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "split_folder", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.load_val_data": [[69, 79], ["numpy.array", "open", "os.path.join", "imgs.append", "numpy.array.append", "line.split", "line.split", "os.path.join"], "methods", ["None"], ["", "def", "load_val_data", "(", "self", ")", ":", "\n", "        ", "imgs", ",", "targets", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "'val_annotations.txt'", ")", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "for", "line", "in", "file", ":", "\n", "                ", "if", "line", ".", "split", "(", ")", "[", "1", "]", "in", "self", ".", "wnids", ":", "\n", "                    ", "img_file", ",", "wnid", "=", "line", ".", "split", "(", "'\\t'", ")", "[", ":", "2", "]", "\n", "imgs", ".", "append", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "'images'", ",", "img_file", ")", ")", "\n", "targets", ".", "append", "(", "wnid", ")", "\n", "", "", "", "targets", "=", "np", ".", "array", "(", "[", "self", ".", "wnid_to_idx", "[", "wnid", "]", "for", "wnid", "in", "targets", "]", ")", "\n", "return", "imgs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.load_wnid_to_classes": [[81, 88], ["open", "file.readlines", "os.path.join", "x.split", "x[].strip"], "methods", ["None"], ["", "def", "load_wnid_to_classes", "(", "self", ")", ":", "\n", "        ", "wnid_to_classes", "=", "{", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'words.txt'", ")", ",", "'r'", ")", "as", "file", ":", "\n", "            ", "lines", "=", "file", ".", "readlines", "(", ")", "\n", "lines", "=", "[", "x", ".", "split", "(", "'\\t'", ")", "for", "x", "in", "lines", "]", "\n", "wnid_to_classes", "=", "{", "x", "[", "0", "]", ":", "x", "[", "1", "]", ".", "strip", "(", ")", "for", "x", "in", "lines", "}", "\n", "", "return", "wnid_to_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.check_root": [[89, 95], ["os.scandir"], "methods", ["None"], ["", "def", "check_root", "(", "self", ")", ":", "\n", "        ", "tinyim_set", "=", "[", "'words.txt'", ",", "'wnids.txt'", ",", "'train'", ",", "'val'", ",", "'test'", "]", "\n", "for", "x", "in", "os", ".", "scandir", "(", "self", ".", "root", ")", ":", "\n", "            ", "if", "x", ".", "name", "not", "in", "tinyim_set", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.tiny_imagenet.TinyImageNet.__getitem__": [[96, 118], ["tiny_imagenet.TinyImageNet.loader", "tiny_imagenet.TinyImageNet.test_transform", "tiny_imagenet.TinyImageNet.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", ",", "target", "=", "self", ".", "samples", "[", "index", "]", "\n", "sample", "=", "self", ".", "loader", "(", "path", ")", "\n", "\n", "if", "self", ".", "only_features", ":", "\n", "            ", "sample", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "no_aug", ":", "\n", "                ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                    ", "sample", "=", "self", ".", "test_transform", "(", "sample", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                    ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "\n", "", "", "", "return", "sample", ",", "target", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.affine_warp": [[65, 68], ["im.transform"], "function", ["None"], ["def", "affine_warp", "(", "im", ",", "data", ")", ":", "\n", "    ", "\"\"\"Applies affine transform to image.\"\"\"", "\n", "return", "im", ".", "transform", "(", "im", ".", "size", ",", "Image", ".", "AFFINE", ",", "data", ",", "**", "WARP_PARAMS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.apply_op": [[172, 183], ["random.random", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], ["def", "apply_op", "(", "im", ",", "op", ",", "prob", ",", "magnitude", ")", ":", "\n", "    ", "\"\"\"Apply the selected op to image with given probability and magnitude.\"\"\"", "\n", "# The magnitude is converted to an absolute value v for an op (some ops use -v or v)", "\n", "assert", "0", "<=", "magnitude", "<=", "1", "\n", "assert", "op", "in", "OP_RANGES", "and", "op", "in", "OP_FUNCTIONS", ",", "\"unknown op \"", "+", "op", "\n", "if", "prob", "<", "1", "and", "random", ".", "random", "(", ")", ">", "prob", ":", "\n", "        ", "return", "im", "\n", "", "min_v", ",", "max_v", ",", "negate", "=", "OP_RANGES", "[", "op", "]", "\n", "v", "=", "magnitude", "*", "(", "max_v", "-", "min_v", ")", "+", "min_v", "\n", "v", "=", "-", "v", "if", "negate", "and", "random", ".", "random", "(", ")", ">", "0.5", "else", "v", "\n", "return", "OP_FUNCTIONS", "[", "op", "]", "(", "im", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.rand_augment": [[185, 191], ["numpy.random.choice", "int", "augment.apply_op"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.apply_op"], ["", "def", "rand_augment", "(", "im", ",", "magnitude", ",", "ops", "=", "None", ",", "n_ops", "=", "2", ",", "prob", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Applies random augmentation to an image.\"\"\"", "\n", "ops", "=", "ops", "if", "ops", "else", "RANDAUG_OPS", "\n", "for", "op", "in", "np", ".", "random", ".", "choice", "(", "ops", ",", "int", "(", "n_ops", ")", ")", ":", "\n", "        ", "im", "=", "apply_op", "(", "im", ",", "op", ",", "prob", ",", "magnitude", ")", "\n", "", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.auto_augment": [[193, 199], ["random.choice", "augment.apply_op"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.apply_op"], ["", "def", "auto_augment", "(", "im", ",", "policy", "=", "None", ")", ":", "\n", "    ", "\"\"\"Apply auto augmentation to an image.\"\"\"", "\n", "policy", "=", "policy", "if", "policy", "else", "AUTOAUG_POLICY", "\n", "for", "op", ",", "prob", ",", "magnitude", "in", "random", ".", "choice", "(", "policy", ")", ":", "\n", "        ", "im", "=", "apply_op", "(", "im", ",", "op", ",", "prob", ",", "magnitude", ")", "\n", "", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.make_augment": [[201, 213], ["augment_str.split", "all", "float", "augment", "dict", "zip"], "function", ["None"], ["", "def", "make_augment", "(", "augment_str", ")", ":", "\n", "    ", "\"\"\"Generate augmentation function from separated parameter string.\n    The parameter string augment_str may be either \"AutoAugment\" or \"RandAugment\".\n    Undocumented use allows for specifying extra params, e.g. \"RandAugment_N2_M0.5\".\"\"\"", "\n", "params", "=", "augment_str", ".", "split", "(", "\"_\"", ")", "\n", "names", "=", "{", "\"N\"", ":", "\"n_ops\"", ",", "\"M\"", ":", "\"magnitude\"", ",", "\"P\"", ":", "\"prob\"", "}", "\n", "assert", "params", "[", "0", "]", "in", "[", "\"RandAugment\"", ",", "\"AutoAugment\"", "]", "\n", "assert", "all", "(", "p", "[", "0", "]", "in", "names", "for", "p", "in", "params", "[", "1", ":", "]", ")", "\n", "keys", "=", "[", "names", "[", "p", "[", "0", "]", "]", "for", "p", "in", "params", "[", "1", ":", "]", "]", "\n", "vals", "=", "[", "float", "(", "p", "[", "1", ":", "]", ")", "for", "p", "in", "params", "[", "1", ":", "]", "]", "\n", "augment", "=", "rand_augment", "if", "params", "[", "0", "]", "==", "\"RandAugment\"", "else", "auto_augment", "\n", "return", "lambda", "im", ":", "augment", "(", "im", ",", "**", "dict", "(", "zip", "(", "keys", ",", "vals", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.visualize_ops": [[215, 225], ["PIL.Image.new", "enumerate", "numpy.linspace", "enumerate", "augment.apply_op", "Image.new.paste", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.apply_op"], ["", "def", "visualize_ops", "(", "im", ",", "ops", "=", "None", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "\"\"\"Visualize ops by applying each op by varying amounts.\"\"\"", "\n", "ops", "=", "ops", "if", "ops", "else", "RANDAUG_OPS", "\n", "w", ",", "h", ",", "magnitudes", "=", "im", ".", "size", "[", "0", "]", ",", "im", ".", "size", "[", "1", "]", ",", "np", ".", "linspace", "(", "0", ",", "1", ",", "num_steps", ")", "\n", "output", "=", "Image", ".", "new", "(", "\"RGB\"", ",", "(", "w", "*", "num_steps", ",", "h", "*", "len", "(", "ops", ")", ")", ")", "\n", "for", "i", ",", "op", "in", "enumerate", "(", "ops", ")", ":", "\n", "        ", "for", "j", ",", "m", "in", "enumerate", "(", "magnitudes", ")", ":", "\n", "            ", "out", "=", "apply_op", "(", "im", ",", "op", ",", "prob", "=", "1.0", ",", "magnitude", "=", "m", ")", "\n", "output", ".", "paste", "(", "out", ",", "(", "j", "*", "w", ",", "i", "*", "h", ")", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.augment.visualize_aug": [[227, 235], ["PIL.Image.new", "range", "range", "Image.new.paste", "augment"], "function", ["None"], ["", "def", "visualize_aug", "(", "im", ",", "augment", "=", "rand_augment", ",", "num_trials", "=", "10", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Visualize augmentation by applying random augmentations.\"\"\"", "\n", "w", ",", "h", "=", "im", ".", "size", "[", "0", "]", ",", "im", ".", "size", "[", "1", "]", "\n", "output", "=", "Image", ".", "new", "(", "\"RGB\"", ",", "(", "w", "*", "num_trials", ",", "h", "*", "num_trials", ")", ")", "\n", "for", "i", "in", "range", "(", "num_trials", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num_trials", ")", ":", "\n", "            ", "output", ".", "paste", "(", "augment", "(", "im", ",", "**", "kwargs", ")", ",", "(", "j", "*", "w", ",", "i", "*", "h", ")", ")", "\n", "", "", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.__init__": [[12, 25], ["pycls.datasets.custom_datasets.CIFAR10.__init__", "print", "imbalanced_cifar.IMBALANCECIFAR10.get_img_num_per_cls", "imbalanced_cifar.IMBALANCECIFAR10.gen_imbalanced_data", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_img_num_per_cls", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.gen_imbalanced_data"], ["def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", "=", "None", ",", "test_transform", "=", "None", ",", "imbalance_ratio", "=", "0.02", ",", "imb_type", "=", "'exp'", ")", ":", "\n", "        ", "super", "(", "IMBALANCECIFAR10", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "test_transform", "=", "test_transform", ",", "download", "=", "True", ")", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "transform", "=", "transform", "\n", "if", "self", ".", "train", ":", "\n", "            ", "img_num_list", "=", "self", ".", "get_img_num_per_cls", "(", "self", ".", "cls_num", ",", "imb_type", ",", "imbalance_ratio", ")", "\n", "self", ".", "gen_imbalanced_data", "(", "img_num_list", ")", "\n", "phase", "=", "'Train'", "\n", "", "else", ":", "\n", "            ", "phase", "=", "'Test'", "\n", "", "self", ".", "labels", "=", "self", ".", "targets", "\n", "\n", "print", "(", "\"{} Mode: Contain {} images\"", ".", "format", "(", "phase", ",", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10._get_class_dict": [[26, 34], ["dict", "enumerate", "imbalanced_cifar.IMBALANCECIFAR10.get_annotations", "class_dict[].append"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_annotations"], ["", "def", "_get_class_dict", "(", "self", ")", ":", "\n", "        ", "class_dict", "=", "dict", "(", ")", "\n", "for", "i", ",", "anno", "in", "enumerate", "(", "self", ".", "get_annotations", "(", ")", ")", ":", "\n", "            ", "cat_id", "=", "anno", "[", "\"category_id\"", "]", "\n", "if", "not", "cat_id", "in", "class_dict", ":", "\n", "                ", "class_dict", "[", "cat_id", "]", "=", "[", "]", "\n", "", "class_dict", "[", "cat_id", "]", ".", "append", "(", "i", ")", "\n", "", "return", "class_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_img_num_per_cls": [[36, 51], ["len", "range", "img_num_per_cls.append", "range", "range", "img_num_per_cls.extend", "int", "img_num_per_cls.append", "img_num_per_cls.append", "int", "int", "int"], "methods", ["None"], ["", "def", "get_img_num_per_cls", "(", "self", ",", "cls_num", ",", "imb_type", ",", "imb_factor", ")", ":", "\n", "        ", "img_max", "=", "len", "(", "self", ".", "data", ")", "/", "cls_num", "\n", "img_num_per_cls", "=", "[", "]", "\n", "if", "imb_type", "==", "'exp'", ":", "\n", "            ", "for", "cls_idx", "in", "range", "(", "cls_num", ")", ":", "\n", "                ", "num", "=", "img_max", "*", "(", "imb_factor", "**", "(", "cls_idx", "/", "(", "cls_num", "-", "1.0", ")", ")", ")", "\n", "img_num_per_cls", ".", "append", "(", "int", "(", "num", ")", ")", "\n", "", "", "elif", "imb_type", "==", "'step'", ":", "\n", "            ", "for", "cls_idx", "in", "range", "(", "cls_num", "//", "2", ")", ":", "\n", "                ", "img_num_per_cls", ".", "append", "(", "int", "(", "img_max", ")", ")", "\n", "", "for", "cls_idx", "in", "range", "(", "cls_num", "//", "2", ")", ":", "\n", "                ", "img_num_per_cls", ".", "append", "(", "int", "(", "img_max", "*", "imb_factor", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "img_num_per_cls", ".", "extend", "(", "[", "int", "(", "img_max", ")", "]", "*", "cls_num", ")", "\n", "", "return", "img_num_per_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.gen_imbalanced_data": [[52, 70], ["numpy.array", "numpy.unique", "dict", "zip", "numpy.vstack", "numpy.random.shuffle", "numpy.vstack.append", "new_targets.extend", "numpy.where"], "methods", ["None"], ["", "def", "gen_imbalanced_data", "(", "self", ",", "img_num_per_cls", ")", ":", "\n", "\n", "        ", "new_data", "=", "[", "]", "\n", "new_targets", "=", "[", "]", "\n", "targets_np", "=", "np", ".", "array", "(", "self", ".", "targets", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "classes", "=", "np", ".", "unique", "(", "targets_np", ")", "\n", "\n", "self", ".", "num_per_cls_dict", "=", "dict", "(", ")", "\n", "for", "the_class", ",", "the_img_num", "in", "zip", "(", "classes", ",", "img_num_per_cls", ")", ":", "\n", "            ", "self", ".", "num_per_cls_dict", "[", "the_class", "]", "=", "the_img_num", "\n", "idx", "=", "np", ".", "where", "(", "targets_np", "==", "the_class", ")", "[", "0", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "selec_idx", "=", "idx", "[", ":", "the_img_num", "]", "\n", "new_data", ".", "append", "(", "self", ".", "data", "[", "selec_idx", ",", "...", "]", ")", "\n", "new_targets", ".", "extend", "(", "[", "the_class", ",", "]", "*", "the_img_num", ")", "\n", "", "new_data", "=", "np", ".", "vstack", "(", "new_data", ")", "\n", "self", ".", "data", "=", "new_data", "\n", "self", ".", "targets", "=", "new_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.__len__": [[71, 73], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_num_classes": [[74, 76], ["None"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls_num", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_annotations": [[77, 82], ["annos.append", "int"], "methods", ["None"], ["", "def", "get_annotations", "(", "self", ")", ":", "\n", "        ", "annos", "=", "[", "]", "\n", "for", "label", "in", "self", ".", "labels", ":", "\n", "            ", "annos", ".", "append", "(", "{", "'category_id'", ":", "int", "(", "label", ")", "}", ")", "\n", "", "return", "annos", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.imbalanced_cifar.IMBALANCECIFAR10.get_cls_num_list": [[83, 88], ["range", "cls_num_list.append"], "methods", ["None"], ["", "def", "get_cls_num_list", "(", "self", ")", ":", "\n", "        ", "cls_num_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "cls_num", ")", ":", "\n", "            ", "cls_num_list", ".", "append", "(", "self", ".", "num_per_cls_dict", "[", "i", "]", ")", "\n", "", "return", "cls_num_list", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.CIFAR10.__init__": [[8, 18], ["super().__init__", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", ",", "test_transform", ",", "download", "=", "True", ",", "only_features", "=", "False", ")", ":", "\n", "        ", "super", "(", "CIFAR10", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "download", "=", "download", ")", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "self", ".", "only_features", "=", "only_features", "\n", "if", "train", ":", "\n", "            ", "fname", "=", "'../../scan/results/cifar-10/pretext/features_seed1.npy'", "\n", "", "else", ":", "\n", "            ", "fname", "=", "'../../scan/results/cifar-10/pretext/test_features_seed1.npy'", "\n", "", "self", ".", "features", "=", "np", ".", "load", "(", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.CIFAR10.__getitem__": [[20, 45], ["PIL.Image.fromarray", "custom_datasets.CIFAR10.test_transform", "custom_datasets.CIFAR10.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "if", "self", ".", "only_features", ":", "\n", "            ", "img", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "no_aug", ":", "\n", "                ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "test_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.CIFAR100.__init__": [[48, 58], ["super().__init__", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", ",", "test_transform", ",", "download", "=", "True", ",", "only_features", "=", "False", ")", ":", "\n", "        ", "super", "(", "CIFAR100", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "download", "=", "download", ")", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "self", ".", "only_features", "=", "only_features", "\n", "if", "train", ":", "\n", "            ", "fname", "=", "'../../scan/results/cifar-100/pretext/features_seed1.npy'", "\n", "", "else", ":", "\n", "            ", "fname", "=", "'../../scan/results/cifar-100/pretext/test_features_seed1.npy'", "\n", "", "self", ".", "features", "=", "np", ".", "load", "(", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.CIFAR100.__getitem__": [[59, 83], ["PIL.Image.fromarray", "custom_datasets.CIFAR100.test_transform", "custom_datasets.CIFAR100.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "if", "self", ".", "only_features", ":", "\n", "            ", "img", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "no_aug", ":", "\n", "                ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "test_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                    ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.STL10.__init__": [[86, 91], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", ",", "test_transform", ",", "download", "=", "True", ")", ":", "\n", "        ", "super", "(", "STL10", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "download", "=", "download", ")", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "self", ".", "targets", "=", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.STL10.__getitem__": [[92, 114], ["PIL.Image.fromarray", "int", "custom_datasets.STL10.transpose", "custom_datasets.STL10.test_transform", "custom_datasets.STL10.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "\n", "if", "self", ".", "no_aug", ":", "\n", "            ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "test_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.MNIST.__init__": [[117, 121], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", ",", "test_transform", ",", "download", "=", "True", ")", ":", "\n", "        ", "super", "(", "MNIST", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "download", "=", "download", ")", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.MNIST.__getitem__": [[122, 145], ["PIL.Image.fromarray", "int", "custom_datasets.MNIST.numpy", "custom_datasets.MNIST.test_transform", "custom_datasets.MNIST.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", "\n", "\n", "if", "self", ".", "no_aug", ":", "\n", "            ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "test_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.SVHN.__init__": [[148, 152], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "train", ",", "transform", ",", "test_transform", ",", "download", "=", "True", ")", ":", "\n", "        ", "super", "(", "SVHN", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", ",", "transform", "=", "transform", ",", "download", "=", "download", ")", "\n", "self", ".", "test_transform", "=", "test_transform", "\n", "self", ".", "no_aug", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.custom_datasets.SVHN.__getitem__": [[153, 176], ["PIL.Image.fromarray", "custom_datasets.SVHN.test_transform", "custom_datasets.SVHN.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "\n", "if", "self", ".", "no_aug", ":", "\n", "            ", "if", "self", ".", "test_transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "test_transform", "(", "img", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "                ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "\n", "", "", "return", "img", ",", "target", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.randaugment.RandAugmentPolicy.__init__": [[26, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fillcolor", "=", "(", "0", ",", "0", ",", "0", ")", ",", "N", "=", "1", ",", "M", "=", "5", ")", ":", "\n", "        ", "self", ".", "policies", "=", "[", "\"invert\"", ",", "\"autocontrast\"", ",", "\"equalize\"", ",", "\"rotate\"", ",", "\"solarize\"", ",", "\"color\"", ",", "\"posterize\"", ",", "\"contrast\"", ",", "\"brightness\"", ",", "\"sharpness\"", ",", "\"shearX\"", ",", "\"shearY\"", ",", "\"translateX\"", ",", "\"translateY\"", ",", "\"cutout\"", "]", "\n", "self", ".", "N", "=", "N", "\n", "self", ".", "M", "=", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.randaugment.RandAugmentPolicy.__call__": [[33, 40], ["numpy.random.choice", "randaugment.SubPolicy", "SubPolicy."], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "choosen_policies", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "policies", ",", "self", ".", "N", ")", "\n", "for", "policy", "in", "choosen_policies", ":", "\n", "            ", "subpolicy_obj", "=", "SubPolicy", "(", "operation", "=", "policy", ",", "magnitude", "=", "self", ".", "M", ")", "\n", "img", "=", "subpolicy_obj", "(", "img", ")", "\n", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.randaugment.RandAugmentPolicy.__repr__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"RandAugment CIFAR10 Policy with Cutout\"", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.randaugment.SubPolicy.__init__": [[45, 132], ["numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.round().astype", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "img.copy.copy.convert().rotate", "PIL.Image.composite().convert", "randaugment.SubPolicy.__init__.CutoutAbs"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "operation", ",", "magnitude", ",", "fillcolor", "=", "(", "128", ",", "128", ",", "128", ")", ",", "MAX_PARAM", "=", "10", ")", ":", "\n", "        ", "ranges", "=", "{", "\n", "\"shearX\"", ":", "np", ".", "linspace", "(", "0", ",", "0.3", ",", "MAX_PARAM", ")", ",", "\n", "\"shearY\"", ":", "np", ".", "linspace", "(", "0", ",", "0.3", ",", "MAX_PARAM", ")", ",", "\n", "\"translateX\"", ":", "np", ".", "linspace", "(", "0", ",", "150", "/", "331", ",", "MAX_PARAM", ")", ",", "\n", "\"translateY\"", ":", "np", ".", "linspace", "(", "0", ",", "150", "/", "331", ",", "MAX_PARAM", ")", ",", "\n", "\"rotate\"", ":", "np", ".", "linspace", "(", "0", ",", "30", ",", "MAX_PARAM", ")", ",", "\n", "\"color\"", ":", "np", ".", "linspace", "(", "0.0", ",", "0.9", ",", "MAX_PARAM", ")", ",", "\n", "\"posterize\"", ":", "np", ".", "round", "(", "np", ".", "linspace", "(", "8", ",", "4", ",", "MAX_PARAM", ")", ",", "0", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "\n", "\"solarize\"", ":", "np", ".", "linspace", "(", "256", ",", "0", ",", "MAX_PARAM", ")", ",", "\n", "\"contrast\"", ":", "np", ".", "linspace", "(", "0.0", ",", "0.9", ",", "MAX_PARAM", ")", ",", "\n", "\"sharpness\"", ":", "np", ".", "linspace", "(", "0.0", ",", "0.9", ",", "MAX_PARAM", ")", ",", "\n", "\"brightness\"", ":", "np", ".", "linspace", "(", "0.0", ",", "0.9", ",", "MAX_PARAM", ")", ",", "\n", "\"autocontrast\"", ":", "[", "0", "]", "*", "MAX_PARAM", ",", "\n", "\"equalize\"", ":", "[", "0", "]", "*", "MAX_PARAM", ",", "\n", "\"invert\"", ":", "[", "0", "]", "*", "MAX_PARAM", ",", "\n", "\"cutout\"", ":", "np", ".", "linspace", "(", "0.0", ",", "0.8", ",", "MAX_PARAM", ")", ",", "\n", "}", "\n", "\n", "# from https://stackoverflow.com/questions/5252170/specify-image-filling-color-when-rotating-in-python-with-pil-and-setting-expand", "\n", "def", "rotate_with_fill", "(", "img", ",", "magnitude", ")", ":", "\n", "            ", "rot", "=", "img", ".", "convert", "(", "\"RGBA\"", ")", ".", "rotate", "(", "magnitude", ")", "\n", "#return Image.composite(rot, Image.new(\"RGBA\", rot.size, (128,) * 4), rot).convert(img.mode)", "\n", "return", "Image", ".", "composite", "(", "rot", ",", "Image", ".", "new", "(", "\"RGBA\"", ",", "rot", ".", "size", ",", "(", "0", ",", ")", "*", "4", ")", ",", "rot", ")", ".", "convert", "(", "img", ".", "mode", ")", "\n", "\n", "", "def", "Cutout", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "            ", "assert", "0.0", "<=", "v", "<=", "0.8", "\n", "if", "v", "<=", "0.", ":", "\n", "                ", "return", "img", "\n", "\n", "", "v", "=", "v", "*", "img", ".", "size", "[", "0", "]", "\n", "\n", "return", "CutoutAbs", "(", "img", ",", "v", ")", "\n", "\n", "\n", "", "def", "CutoutAbs", "(", "img", ",", "v", ")", ":", "# [0, 60] => percentage: [0, 0.2]", "\n", "# assert 0 <= v <= 20", "\n", "            ", "if", "v", "<", "0", ":", "\n", "                ", "return", "img", "\n", "", "w", ",", "h", "=", "img", ".", "size", "\n", "x0", "=", "np", ".", "random", ".", "uniform", "(", "w", ")", "\n", "y0", "=", "np", ".", "random", ".", "uniform", "(", "h", ")", "\n", "\n", "x0", "=", "int", "(", "max", "(", "0", ",", "x0", "-", "v", "/", "2.", ")", ")", "\n", "y0", "=", "int", "(", "max", "(", "0", ",", "y0", "-", "v", "/", "2.", ")", ")", "\n", "x1", "=", "min", "(", "w", ",", "x0", "+", "v", ")", "\n", "y1", "=", "min", "(", "h", ",", "y0", "+", "v", ")", "\n", "\n", "xy", "=", "(", "x0", ",", "y0", ",", "x1", ",", "y1", ")", "\n", "#color = (125, 123, 114)", "\n", "color", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "img", "=", "img", ".", "copy", "(", ")", "\n", "ImageDraw", ".", "Draw", "(", "img", ")", ".", "rectangle", "(", "xy", ",", "color", ")", "\n", "return", "img", "\n", "\n", "", "func", "=", "{", "\n", "\"shearX\"", ":", "lambda", "img", ",", "magnitude", ":", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ",", "0", ",", "0", ",", "1", ",", "0", ")", ",", "\n", "Image", ".", "BICUBIC", ",", "fillcolor", "=", "fillcolor", ")", ",", "\n", "\"shearY\"", ":", "lambda", "img", ",", "magnitude", ":", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ",", "1", ",", "0", ")", ",", "\n", "Image", ".", "BICUBIC", ",", "fillcolor", "=", "fillcolor", ")", ",", "\n", "\"translateX\"", ":", "lambda", "img", ",", "magnitude", ":", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "magnitude", "*", "img", ".", "size", "[", "0", "]", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ",", "0", ",", "1", ",", "0", ")", ",", "\n", "fillcolor", "=", "fillcolor", ")", ",", "\n", "\"translateY\"", ":", "lambda", "img", ",", "magnitude", ":", "img", ".", "transform", "(", "\n", "img", ".", "size", ",", "Image", ".", "AFFINE", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "magnitude", "*", "img", ".", "size", "[", "1", "]", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "fillcolor", "=", "fillcolor", ")", ",", "\n", "\"rotate\"", ":", "lambda", "img", ",", "magnitude", ":", "rotate_with_fill", "(", "img", ",", "magnitude", ")", ",", "\n", "# \"rotate\": lambda img, magnitude: img.rotate(magnitude * random.choice([-1, 1])),", "\n", "\"color\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageEnhance", ".", "Color", "(", "img", ")", ".", "enhance", "(", "1", "+", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "\"posterize\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageOps", ".", "posterize", "(", "img", ",", "magnitude", ")", ",", "\n", "\"solarize\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageOps", ".", "solarize", "(", "img", ",", "magnitude", ")", ",", "\n", "\"contrast\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageEnhance", ".", "Contrast", "(", "img", ")", ".", "enhance", "(", "\n", "1", "+", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "\"sharpness\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageEnhance", ".", "Sharpness", "(", "img", ")", ".", "enhance", "(", "\n", "1", "+", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "\"brightness\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageEnhance", ".", "Brightness", "(", "img", ")", ".", "enhance", "(", "\n", "1", "+", "magnitude", "*", "random", ".", "choice", "(", "[", "-", "1", ",", "1", "]", ")", ")", ",", "\n", "\"autocontrast\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageOps", ".", "autocontrast", "(", "img", ")", ",", "\n", "\"equalize\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageOps", ".", "equalize", "(", "img", ")", ",", "\n", "\"invert\"", ":", "lambda", "img", ",", "magnitude", ":", "ImageOps", ".", "invert", "(", "img", ")", ",", "\n", "\"cutout\"", ":", "lambda", "img", ",", "magnitude", ":", "Cutout", "(", "img", ",", "magnitude", ")", "\n", "}", "\n", "\n", "self", ".", "operation", "=", "func", "[", "operation", "]", "\n", "self", ".", "magnitude", "=", "ranges", "[", "operation", "]", "[", "magnitude", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.randaugment.SubPolicy.__call__": [[134, 137], ["randaugment.SubPolicy.operation"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "img", "=", "self", ".", "operation", "(", "img", ",", "self", ".", "magnitude", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data._RepeatSampler.__init__": [[27, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ")", ":", "\n", "        ", "self", ".", "sampler", "=", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data._RepeatSampler.__iter__": [[30, 33], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "from", "iter", "(", "self", ".", "sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.MultiEpochsDataLoader.__init__": [[37, 43], ["super().__init__", "data._RepeatSampler", "super().__iter__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.sampler.IndexedSequentialSampler.__iter__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_DataLoader__initialized", "=", "False", "\n", "self", ".", "batch_sampler", "=", "_RepeatSampler", "(", "self", ".", "batch_sampler", ")", "\n", "self", ".", "_DataLoader__initialized", "=", "True", "\n", "self", ".", "iterator", "=", "super", "(", ")", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.MultiEpochsDataLoader.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "batch_sampler", ".", "sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.MultiEpochsDataLoader.__iter__": [[47, 50], ["range", "len", "next"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "yield", "next", "(", "self", ".", "iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.__init__": [[62, 78], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Initializes dataset attribute of (Data class) object with specified \"dataset\" argument.\n        INPUT:\n        cfg: yacs.config, config object\n        \"\"\"", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "num_workers", "=", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", "\n", "self", ".", "dataset", "=", "cfg", ".", "DATASET", ".", "NAME", "\n", "self", ".", "data_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", "\n", "self", ".", "datasets_accepted", "=", "cfg", ".", "DATASET", ".", "ACCEPTED", "\n", "# self.target_dir = {\"test\": cfg.DATASET.TEST_DIR, \"train\": cfg.DATASET.TRAIN_DIR, \"val\": cfg.DATASET.VAL_DIR}", "\n", "self", ".", "eval_mode", "=", "False", "\n", "self", ".", "aug_method", "=", "cfg", ".", "DATASET", ".", "AUG_METHOD", "\n", "self", ".", "rand_augment_N", "=", "1", "if", "cfg", "is", "None", "else", "cfg", ".", "RANDAUG", ".", "N", "\n", "self", ".", "rand_augment_M", "=", "5", "if", "cfg", "is", "None", "else", "cfg", ".", "RANDAUG", ".", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.about": [[79, 84], ["print"], "methods", ["None"], ["", "def", "about", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Show all properties of this class.\n        \"\"\"", "\n", "print", "(", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.make_data_lists": [[86, 107], ["os.path.join", "os.path.join", "glob.glob", "glob.glob", "os.path.exists", "os.path.exists", "os.path.join", "os.path.join", "open", "filehandle.writelines", "open", "filehandle.writelines"], "methods", ["None"], ["", "def", "make_data_lists", "(", "self", ",", "exp_dir", ")", ":", "\n", "        ", "\"\"\"\n        Creates train.txt, test.txt and valid.txt. Text format is chosen to allow readability. \n        Keyword arguments:\n            exp_dir -- Full path to the experiment directory where index lists will be saved\n        \"\"\"", "\n", "train", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "'train.txt'", ")", "\n", "test", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "'test.txt'", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "train", ")", "or", "os", ".", "path", ".", "exists", "(", "test", ")", ":", "\n", "            ", "out", "=", "f'train.txt or test.text already exist at {exp_dir}'", "\n", "return", "None", "\n", "\n", "", "train_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train/**/*.png'", ")", ",", "recursive", "=", "True", ")", "\n", "test_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test/**/*.png'", ")", ",", "recursive", "=", "True", ")", "\n", "\n", "with", "open", "(", "train", ",", "'w'", ")", "as", "filehandle", ":", "\n", "            ", "filehandle", ".", "writelines", "(", "\"%s\\n\"", "%", "index", "for", "index", "in", "train_list", ")", "\n", "\n", "", "with", "open", "(", "test", ",", "'w'", ")", "as", "filehandle", ":", "\n", "            ", "filehandle", ".", "writelines", "(", "\"%s\\n\"", "%", "index", "for", "index", "in", "test_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getPreprocessOps": [[109, 175], ["ops.append", "ops.append", "print", "logger.info", "ops.insert", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "print", "torchvision.transforms.RandomCrop", "simclr_augment.get_simclr_ops", "ops.append", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "randaugment.RandAugmentPolicy", "ops.append", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomCrop"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.simclr_augment.get_simclr_ops"], ["", "", "def", "getPreprocessOps", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function specifies the steps to be accounted for preprocessing.\n        \n        INPUT:\n        None\n        \n        OUTPUT:\n        Returns a list of preprocessing steps. Note the order of operations matters in the list.\n        \"\"\"", "\n", "if", "self", ".", "dataset", "in", "self", ".", "datasets_accepted", ":", "\n", "            ", "ops", "=", "[", "]", "\n", "norm_mean", "=", "[", "]", "\n", "norm_std", "=", "[", "]", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "\"CIFAR10\"", ",", "\"CIFAR100\"", ",", "'IMBALANCED_CIFAR10'", ",", "'IMBALANCED_CIFAR100'", "]", ":", "\n", "                ", "ops", "=", "[", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", "]", "\n", "norm_mean", "=", "[", "0.4914", ",", "0.4822", ",", "0.4465", "]", "\n", "norm_std", "=", "[", "0.247", ",", "0.2435", ",", "0.2616", "]", "\n", "", "elif", "self", ".", "dataset", "==", "\"MNIST\"", ":", "\n", "                ", "ops", "=", "[", "transforms", ".", "Resize", "(", "32", ")", "]", "\n", "norm_mean", "=", "[", "0.1307", ",", "]", "\n", "norm_std", "=", "[", "0.3081", ",", "]", "\n", "", "elif", "self", ".", "dataset", "==", "\"TINYIMAGENET\"", ":", "\n", "# ops = [transforms.RandomResizedCrop(64)]", "\n", "                ", "ops", "=", "[", "transforms", ".", "RandomResizedCrop", "(", "64", ",", "scale", "=", "(", "0.5", ",", "1.", ")", ")", "]", "\n", "\n", "# Using ImageNet values ", "\n", "norm_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "norm_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "", "elif", "self", ".", "dataset", "in", "[", "\"IMAGENET\"", ",", "'IMAGENET50'", ",", "'IMAGENET100'", ",", "'IMAGENET200'", "]", ":", "\n", "                ", "ops", "=", "[", "transforms", ".", "RandomResizedCrop", "(", "224", ",", "scale", "=", "(", "0.5", ",", "1.", ")", ")", "]", "\n", "# Using ImageNet values", "\n", "norm_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "norm_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "", "elif", "self", ".", "dataset", "in", "[", "\"SVHN\"", "]", ":", "\n", "                ", "ops", "=", "[", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", "]", "\n", "norm_mean", "=", "[", "0.4376", ",", "0.4437", ",", "0.4728", "]", "\n", "norm_std", "=", "[", "0.1980", ",", "0.2010", ",", "0.1970", "]", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "if", "not", "self", ".", "eval_mode", "and", "(", "self", ".", "aug_method", "==", "'simclr'", ")", ":", "\n", "                ", "ops", ".", "insert", "(", "1", ",", "get_simclr_ops", "(", "input_shape", "=", "cfg", ".", "TRAIN", ".", "IM_SIZE", ")", ")", "\n", "\n", "", "elif", "not", "self", ".", "eval_mode", "and", "(", "self", ".", "aug_method", "==", "'randaug'", ")", ":", "\n", "#N and M values are taken from Experiment Section of RandAugment Paper", "\n", "#Though RandAugment paper works with WideResNet model", "\n", "                ", "ops", ".", "append", "(", "RandAugmentPolicy", "(", "N", "=", "self", ".", "rand_augment_N", ",", "M", "=", "self", ".", "rand_augment_M", ")", ")", "\n", "\n", "", "elif", "not", "self", ".", "eval_mode", "and", "(", "self", ".", "aug_method", "==", "'hflip'", ")", ":", "\n", "                ", "ops", ".", "append", "(", "transforms", ".", "RandomHorizontalFlip", "(", ")", ")", "\n", "\n", "", "ops", ".", "append", "(", "transforms", ".", "ToTensor", "(", ")", ")", "\n", "ops", ".", "append", "(", "transforms", ".", "Normalize", "(", "norm_mean", ",", "norm_std", ")", ")", "\n", "\n", "if", "self", ".", "eval_mode", ":", "\n", "                ", "ops", "=", "[", "ops", "[", "0", "]", ",", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "norm_mean", ",", "norm_std", ")", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"Preprocess Operations Selected ==> \"", ",", "ops", ")", "\n", "# logger.info(\"Preprocess Operations Selected ==> \", ops)", "\n", "", "return", "ops", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Either the specified {} dataset is not added or there is no if condition in getDataset function of Data class\"", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Either the specified {} dataset is not added or there is no if condition in getDataset function of Data class\"", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset": [[177, 257], ["data.Data.getPreprocessOps", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "data.Data.getPreprocessOps", "pycls.datasets.custom_datasets.MNIST", "len", "pycls.datasets.custom_datasets.CIFAR10", "len", "pycls.datasets.custom_datasets.CIFAR100", "len", "pycls.datasets.custom_datasets.SVHN", "pycls.datasets.custom_datasets.SVHN", "len", "pycls.datasets.tiny_imagenet.TinyImageNet", "pycls.datasets.tiny_imagenet.TinyImageNet", "len", "ImageNet", "ImageNet", "len", "pycls.datasets.imbalanced_cifar.IMBALANCECIFAR10", "len", "pycls.datasets.imbalanced_cifar.IMBALANCECIFAR100", "print", "logger.info", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getPreprocessOps", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getPreprocessOps"], ["", "", "def", "getDataset", "(", "self", ",", "save_dir", ",", "isTrain", "=", "True", ",", "isDownload", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This function returns the dataset instance and number of data points in it.\n        \n        INPUT:\n        save_dir: String, It specifies the path where dataset will be saved if downloaded.\n        \n        preprocess_steps(optional): List, Contains the ordered operations used for preprocessing the data.\n        \n        isTrain (optional): Bool, If true then Train partition is downloaded else Test partition.\n        \n        isDownload (optional): Bool, If true then dataset is saved at path specified by \"save_dir\".\n        \n        OUTPUT:\n        (On Success) Returns the tuple of dataset instance and length of dataset.\n        (On Failure) Returns Message as <dataset> not specified.\n        \"\"\"", "\n", "self", ".", "eval_mode", "=", "True", "\n", "test_preops_list", "=", "self", ".", "getPreprocessOps", "(", ")", "\n", "test_preprocess_steps", "=", "transforms", ".", "Compose", "(", "test_preops_list", ")", "\n", "self", ".", "eval_mode", "=", "False", "\n", "\n", "if", "isTrain", ":", "\n", "            ", "preprocess_steps", "=", "self", ".", "getPreprocessOps", "(", ")", "\n", "", "else", ":", "\n", "            ", "preprocess_steps", "=", "test_preops_list", "\n", "", "preprocess_steps", "=", "transforms", ".", "Compose", "(", "preprocess_steps", ")", "\n", "\n", "only_features", "=", "self", ".", "cfg", ".", "MODEL", ".", "LINEAR_FROM_FEATURES", "\n", "\n", "if", "self", ".", "dataset", "==", "\"MNIST\"", ":", "\n", "            ", "mnist", "=", "MNIST", "(", "save_dir", ",", "train", "=", "isTrain", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "download", "=", "isDownload", ")", "\n", "return", "mnist", ",", "len", "(", "mnist", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "\"CIFAR10\"", ":", "\n", "            ", "cifar10", "=", "CIFAR10", "(", "save_dir", ",", "train", "=", "isTrain", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "download", "=", "isDownload", ",", "only_features", "=", "only_features", ")", "\n", "return", "cifar10", ",", "len", "(", "cifar10", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "\"CIFAR100\"", ":", "\n", "            ", "cifar100", "=", "CIFAR100", "(", "save_dir", ",", "train", "=", "isTrain", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "download", "=", "isDownload", ",", "only_features", "=", "only_features", ")", "\n", "return", "cifar100", ",", "len", "(", "cifar100", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "\"SVHN\"", ":", "\n", "            ", "if", "isTrain", ":", "\n", "                ", "svhn", "=", "SVHN", "(", "save_dir", ",", "split", "=", "'train'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "download", "=", "isDownload", ")", "\n", "", "else", ":", "\n", "                ", "svhn", "=", "SVHN", "(", "save_dir", ",", "split", "=", "'test'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "download", "=", "isDownload", ")", "\n", "", "return", "svhn", ",", "len", "(", "svhn", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "\"TINYIMAGENET\"", ":", "\n", "            ", "if", "isTrain", ":", "\n", "# tiny = datasets.ImageFolder(save_dir+'/train', transform=preprocess_steps)", "\n", "                ", "tiny", "=", "TinyImageNet", "(", "save_dir", ",", "split", "=", "'train'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "only_features", "=", "only_features", ")", "\n", "", "else", ":", "\n", "# tiny = datasets.ImageFolder(save_dir+'/val', transform=preprocess_steps)", "\n", "                ", "tiny", "=", "TinyImageNet", "(", "save_dir", ",", "split", "=", "'val'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ")", "\n", "", "return", "tiny", ",", "len", "(", "tiny", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "'IMAGENET50'", ",", "'IMAGENET100'", ",", "'IMAGENET200'", "]", ":", "\n", "            ", "if", "isTrain", ":", "\n", "# tiny = datasets.ImageFolder(save_dir+'/train', transform=preprocess_steps)", "\n", "                ", "imagenet", "=", "ImageNet", "(", "save_dir", ",", "split", "=", "'train'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ",", "only_features", "=", "only_features", ")", "\n", "", "else", ":", "\n", "# tiny = datasets.ImageFolder(save_dir+'/val', transform=preprocess_steps)", "\n", "                ", "imagenet", "=", "ImageNet", "(", "save_dir", ",", "split", "=", "'val'", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ",", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ",", "only_features", "=", "only_features", ")", "\n", "", "return", "imagenet", ",", "len", "(", "imagenet", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "'IMBALANCED_CIFAR10'", ":", "\n", "            ", "im_cifar10", "=", "IMBALANCECIFAR10", "(", "save_dir", ",", "train", "=", "isTrain", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ")", "\n", "return", "im_cifar10", ",", "len", "(", "im_cifar10", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "'IMBALANCED_CIFAR100'", ":", "\n", "            ", "im_cifar100", "=", "IMBALANCECIFAR100", "(", "save_dir", ",", "train", "=", "isTrain", ",", "transform", "=", "preprocess_steps", ",", "test_transform", "=", "test_preprocess_steps", ")", "\n", "return", "im_cifar100", ",", "len", "(", "im_cifar100", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Either the specified {} dataset is not added or there is no if condition in getDataset function of Data class\"", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Either the specified {} dataset is not added or there is no if condition in getDataset function of Data class\"", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeLUVSets": [[259, 323], ["torch.manual_seed", "numpy.random.seed", "isinstance", "isinstance", "len", "numpy.random.shuffle", "int", "int", "numpy.array", "numpy.array", "numpy.array", "numpy.save", "numpy.save", "numpy.save", "type", "type", "range"], "methods", ["None"], ["", "", "def", "makeLUVSets", "(", "self", ",", "train_split_ratio", ",", "val_split_ratio", ",", "data", ",", "seed_id", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the labelled and unlabelled set by splitting the data into train\n        and validation according to split_ratios arguments.\n\n        Visually it does the following:\n\n        |<------------- Train -------------><--- Validation --->\n\n        |<--- Labelled --><---Unlabelled --><--- Validation --->\n\n        INPUT:\n        train_split_ratio: Float, Specifies the proportion of data in train set.\n        For example: 0.8 means beginning 80% of data is training data.\n\n        val_split_ratio: Float, Specifies the proportion of data in validation set.\n        For example: 0.1 means ending 10% of data is validation data.\n\n        data: reference to dataset instance. This can be obtained by calling getDataset function of Data class.\n        \n        OUTPUT:\n        (On Success) Sets the labelled, unlabelled set along with validation set\n        (On Failure) Returns Message as <dataset> not specified.\n        \"\"\"", "\n", "# Reproducibility stuff", "\n", "torch", ".", "manual_seed", "(", "seed_id", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_id", ")", "\n", "\n", "assert", "isinstance", "(", "train_split_ratio", ",", "float", ")", ",", "\"Train split ratio is of {} datatype instead of float\"", ".", "format", "(", "type", "(", "train_split_ratio", ")", ")", "\n", "assert", "isinstance", "(", "val_split_ratio", ",", "float", ")", ",", "\"Val split ratio is of {} datatype instead of float\"", ".", "format", "(", "type", "(", "val_split_ratio", ")", ")", "\n", "assert", "self", ".", "dataset", "in", "self", ".", "datasets_accepted", ",", "\"Sorry the dataset {} is not supported. Currently we support {}\"", ".", "format", "(", "self", ".", "dataset", ",", "self", ".", "datasets_accepted", ")", "\n", "\n", "lSet", "=", "[", "]", "\n", "uSet", "=", "[", "]", "\n", "valSet", "=", "[", "]", "\n", "\n", "n_dataPoints", "=", "len", "(", "data", ")", "\n", "all_idx", "=", "[", "i", "for", "i", "in", "range", "(", "n_dataPoints", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "all_idx", ")", "\n", "train_splitIdx", "=", "int", "(", "train_split_ratio", "*", "n_dataPoints", ")", "\n", "#To get the validation index from end we multiply n_datapoints with 1-val_ratio ", "\n", "val_splitIdx", "=", "int", "(", "(", "1", "-", "val_split_ratio", ")", "*", "n_dataPoints", ")", "\n", "#Check there should be no overlap with train and val data", "\n", "assert", "train_split_ratio", "+", "val_split_ratio", "<", "1.0", ",", "\"Validation data over laps with train data as last train index is {} and last val index is {}. \\\n            The program expects val index > train index. Please satisfy the constraint: train_split_ratio + val_split_ratio < 1.0; currently it is {} + {} is not < 1.0 => {} is not < 1.0\"", ".", "format", "(", "train_splitIdx", ",", "val_splitIdx", ",", "train_split_ratio", ",", "val_split_ratio", ",", "train_split_ratio", "+", "val_split_ratio", ")", "\n", "\n", "lSet", "=", "all_idx", "[", ":", "train_splitIdx", "]", "\n", "uSet", "=", "all_idx", "[", "train_splitIdx", ":", "val_splitIdx", "]", "\n", "valSet", "=", "all_idx", "[", "val_splitIdx", ":", "]", "\n", "\n", "# print(\"=============================\")", "\n", "# print(\"lSet len: {}, uSet len: {} and valSet len: {}\".format(len(lSet),len(uSet),len(valSet)))", "\n", "# print(\"=============================\")", "\n", "\n", "lSet", "=", "np", ".", "array", "(", "lSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "uSet", "=", "np", ".", "array", "(", "uSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "valSet", "=", "np", ".", "array", "(", "valSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "\n", "np", ".", "save", "(", "f'{save_dir}/lSet.npy'", ",", "lSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/uSet.npy'", ",", "uSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/valSet.npy'", ",", "valSet", ")", "\n", "\n", "return", "f'{save_dir}/lSet.npy'", ",", "f'{save_dir}/uSet.npy'", ",", "f'{save_dir}/valSet.npy'", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeTVSets": [[324, 373], ["torch.manual_seed", "numpy.random.seed", "isinstance", "len", "numpy.random.shuffle", "int", "numpy.array", "numpy.array", "numpy.save", "numpy.save", "type", "range"], "methods", ["None"], ["", "def", "makeTVSets", "(", "self", ",", "val_split_ratio", ",", "data", ",", "seed_id", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the train and validation sets by splitting the train data according to split_ratios arguments.\n\n        Visually it does the following:\n\n        |<------------- Train -------------><--- Validation --->\n\n        INPUT:\n        val_split_ratio: Float, Specifies the proportion of data in validation set.\n        For example: 0.1 means ending 10% of data is validation data.\n\n        data: reference to dataset instance. This can be obtained by calling getDataset function of Data class.\n        \n        OUTPUT:\n        (On Success) Sets the train set and the validation set\n        (On Failure) Returns Message as <dataset> not specified.\n        \"\"\"", "\n", "# Reproducibility stuff", "\n", "torch", ".", "manual_seed", "(", "seed_id", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_id", ")", "\n", "\n", "assert", "isinstance", "(", "val_split_ratio", ",", "float", ")", ",", "\"Val split ratio is of {} datatype instead of float\"", ".", "format", "(", "type", "(", "val_split_ratio", ")", ")", "\n", "assert", "self", ".", "dataset", "in", "self", ".", "datasets_accepted", ",", "\"Sorry the dataset {} is not supported. Currently we support {}\"", ".", "format", "(", "self", ".", "dataset", ",", "self", ".", "datasets_accepted", ")", "\n", "\n", "trainSet", "=", "[", "]", "\n", "valSet", "=", "[", "]", "\n", "\n", "n_dataPoints", "=", "len", "(", "data", ")", "\n", "all_idx", "=", "[", "i", "for", "i", "in", "range", "(", "n_dataPoints", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "all_idx", ")", "\n", "\n", "# To get the validation index from end we multiply n_datapoints with 1-val_ratio ", "\n", "val_splitIdx", "=", "int", "(", "(", "1", "-", "val_split_ratio", ")", "*", "n_dataPoints", ")", "\n", "\n", "trainSet", "=", "all_idx", "[", ":", "val_splitIdx", "]", "\n", "valSet", "=", "all_idx", "[", "val_splitIdx", ":", "]", "\n", "\n", "# print(\"=============================\")", "\n", "# print(\"lSet len: {}, uSet len: {} and valSet len: {}\".format(len(lSet),len(uSet),len(valSet)))", "\n", "# print(\"=============================\")", "\n", "\n", "trainSet", "=", "np", ".", "array", "(", "trainSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "valSet", "=", "np", ".", "array", "(", "valSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "\n", "np", ".", "save", "(", "f'{save_dir}/trainSet.npy'", ",", "trainSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/valSet.npy'", ",", "valSet", ")", "\n", "\n", "return", "f'{save_dir}/trainSet.npy'", ",", "f'{save_dir}/valSet.npy'", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeUVSets": [[374, 422], ["torch.manual_seed", "numpy.random.seed", "isinstance", "len", "numpy.random.shuffle", "int", "numpy.array", "numpy.array", "numpy.save", "numpy.save", "type"], "methods", ["None"], ["", "def", "makeUVSets", "(", "self", ",", "val_split_ratio", ",", "data", ",", "seed_id", ",", "save_dir", ")", ":", "\n", "        ", "\"\"\"\n        Initial labeled pool should already be sampled. We use this function to initialize the train and validation sets by splitting the train data according to split_ratios arguments.\n\n        Visually it does the following:\n\n        |<------------- Unlabeled -------------><--- Validation --->\n\n        INPUT:\n        val_split_ratio: Float, Specifies the proportion of data in validation set.\n        For example: 0.1 means ending 10% of data is validation data.\n\n        data: reference to uSet instance post initial pool sampling. This can be obtained by calling getDataset function of Data class.\n        \n        OUTPUT:\n        (On Success) Sets the unlabeled set and the validation set\n        (On Failure) Returns Message as <dataset> not specified.\n        \"\"\"", "\n", "# Reproducibility stuff", "\n", "torch", ".", "manual_seed", "(", "seed_id", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_id", ")", "\n", "\n", "assert", "isinstance", "(", "val_split_ratio", ",", "float", ")", ",", "\"Val split ratio is of {} datatype instead of float\"", ".", "format", "(", "type", "(", "val_split_ratio", ")", ")", "\n", "assert", "self", ".", "dataset", "in", "self", ".", "datasets_accepted", ",", "\"Sorry the dataset {} is not supported. Currently we support {}\"", ".", "format", "(", "self", ".", "dataset", ",", "self", ".", "datasets_accepted", ")", "\n", "uSet", "=", "[", "]", "\n", "valSet", "=", "[", "]", "\n", "\n", "n_dataPoints", "=", "len", "(", "data", ")", "\n", "# all_idx = [i for i in range(n_dataPoints)]", "\n", "np", ".", "random", ".", "shuffle", "(", "data", ")", "\n", "\n", "# To get the validation index from end we multiply n_datapoints with 1-val_ratio ", "\n", "val_splitIdx", "=", "int", "(", "(", "1", "-", "val_split_ratio", ")", "*", "n_dataPoints", ")", "\n", "\n", "uSet", "=", "data", "[", ":", "val_splitIdx", "]", "\n", "valSet", "=", "data", "[", "val_splitIdx", ":", "]", "\n", "\n", "# print(\"=============================\")", "\n", "# print(\"lSet len: {}, uSet len: {} and valSet len: {}\".format(len(lSet),len(uSet),len(valSet)))", "\n", "# print(\"=============================\")", "\n", "\n", "uSet", "=", "np", ".", "array", "(", "uSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "valSet", "=", "np", ".", "array", "(", "valSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "\n", "np", ".", "save", "(", "f'{save_dir}/uSet.npy'", ",", "uSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/valSet.npy'", ",", "valSet", ")", "\n", "\n", "return", "f'{save_dir}/uSet.npy'", ",", "f'{save_dir}/valSet.npy'", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader": [[423, 459], ["isinstance", "isinstance", "torch.utils.data.sampler.SubsetRandomSampler", "min", "data.MultiEpochsDataLoader", "type", "type", "len", "numpy.concatenate", "len"], "methods", ["None"], ["", "def", "getIndexesDataLoader", "(", "self", ",", "indexes", ",", "batch_size", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Gets reference to the data loader which provides batches of <batch_size> by randomly sampling\n        from indexes set. We use SubsetRandomSampler as sampler in returned DataLoader.\n\n        ARGS\n        -----\n\n        indexes: np.ndarray, dtype: int, Array of indexes which will be used for random sampling.\n\n        batch_size: int, Specifies the batchsize used by data loader.\n\n        data: reference to dataset instance. This can be obtained by calling getDataset function of Data class.\n\n        OUTPUT\n        ------\n\n        Returns a reference to dataloader\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "indexes", ",", "np", ".", "ndarray", ")", ",", "\"Indexes has dtype: {} whereas expected is nd.array.\"", ".", "format", "(", "type", "(", "indexes", ")", ")", "\n", "assert", "isinstance", "(", "batch_size", ",", "int", ")", ",", "\"Batchsize is expected to be of int type whereas currently it has dtype: {}\"", ".", "format", "(", "type", "(", "batch_size", ")", ")", "\n", "while", "len", "(", "indexes", ")", "<", "batch_size", ":", "\n", "            ", "orig_indexes", "=", "indexes", "\n", "indexes", "=", "np", ".", "concatenate", "(", "(", "indexes", ",", "orig_indexes", ")", ")", "\n", "\n", "", "subsetSampler", "=", "SubsetRandomSampler", "(", "indexes", ")", "\n", "# # print(data)", "\n", "# if self.dataset == \"IMAGENET\":", "\n", "#     loader = DataLoader(dataset=data, batch_size=batch_size,sampler=subsetSampler, pin_memory=True)", "\n", "# else:", "\n", "batch_size", "=", "min", "(", "batch_size", ",", "len", "(", "indexes", ")", ")", "\n", "\n", "loader", "=", "MultiEpochsDataLoader", "(", "dataset", "=", "data", ",", "num_workers", "=", "8", ",", "batch_size", "=", "batch_size", ",", "\n", "sampler", "=", "subsetSampler", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "True", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader": [[461, 491], ["isinstance", "isinstance", "pycls.datasets.sampler.IndexedSequentialSampler", "data.MultiEpochsDataLoader", "type", "type"], "methods", ["None"], ["", "def", "getSequentialDataLoader", "(", "self", ",", "indexes", ",", "batch_size", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Gets reference to the data loader which provides batches of <batch_size> sequentially \n        from indexes set. We use IndexedSequentialSampler as sampler in returned DataLoader.\n\n        ARGS\n        -----\n\n        indexes: np.ndarray, dtype: int, Array of indexes which will be used for random sampling.\n\n        batch_size: int, Specifies the batchsize used by data loader.\n\n        data: reference to dataset instance. This can be obtained by calling getDataset function of Data class.\n\n        OUTPUT\n        ------\n\n        Returns a reference to dataloader\n        \"\"\"", "\n", "\n", "assert", "isinstance", "(", "indexes", ",", "np", ".", "ndarray", ")", ",", "\"Indexes has dtype: {} whereas expected is nd.array.\"", ".", "format", "(", "type", "(", "indexes", ")", ")", "\n", "assert", "isinstance", "(", "batch_size", ",", "int", ")", ",", "\"Batchsize is expected to be of int type whereas currently it has dtype: {}\"", ".", "format", "(", "type", "(", "batch_size", ")", ")", "\n", "\n", "subsetSampler", "=", "IndexedSequentialSampler", "(", "indexes", ")", "\n", "# if self.dataset == \"IMAGENET\":", "\n", "#     loader = DataLoader(dataset=data, batch_size=batch_size,sampler=subsetSampler,pin_memory=True)", "\n", "# else:", "\n", "\n", "loader", "=", "MultiEpochsDataLoader", "(", "dataset", "=", "data", ",", "num_workers", "=", "self", ".", "num_workers", ",", "batch_size", "=", "batch_size", ",", "sampler", "=", "subsetSampler", ",", "shuffle", "=", "False", ",", "pin_memory", "=", "True", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader": [[493, 523], ["torch.manual_seed", "numpy.random.seed", "len", "torch.utils.data.sampler.SubsetRandomSampler", "data.MultiEpochsDataLoader", "range"], "methods", ["None"], ["", "def", "getTestLoader", "(", "self", ",", "data", ",", "test_batch_size", ",", "seed_id", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Implements a random subset sampler for sampling the data from test set.\n        \n        INPUT:\n        data: reference to dataset instance. This can be obtained by calling getDataset function of Data class.\n        \n        test_batch_size: int, Denotes the size of test batch\n\n        seed_id: int, Helps in reporoducing results of random operations\n        \n        OUTPUT:\n        (On Success) Returns the testLoader\n        (On Failure) Returns Message as <dataset> not specified.\n        \"\"\"", "\n", "# Reproducibility stuff", "\n", "torch", ".", "manual_seed", "(", "seed_id", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed_id", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "self", ".", "datasets_accepted", ":", "\n", "            ", "n_datapts", "=", "len", "(", "data", ")", "\n", "idx", "=", "[", "i", "for", "i", "in", "range", "(", "n_datapts", ")", "]", "\n", "#np.random.shuffle(idx)", "\n", "\n", "test_sampler", "=", "SubsetRandomSampler", "(", "idx", ")", "\n", "testLoader", "=", "MultiEpochsDataLoader", "(", "data", ",", "num_workers", "=", "self", ".", "num_workers", ",", "batch_size", "=", "test_batch_size", ",", "sampler", "=", "test_sampler", ",", "pin_memory", "=", "True", ")", "\n", "return", "testLoader", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadPartitions": [[525, 541], ["isinstance", "isinstance", "isinstance", "numpy.load", "numpy.load", "numpy.load", "len", "len", "len", "set", "set", "set", "set", "set", "set"], "methods", ["None"], ["", "", "def", "loadPartitions", "(", "self", ",", "lSetPath", ",", "uSetPath", ",", "valSetPath", ")", ":", "\n", "\n", "        ", "assert", "isinstance", "(", "lSetPath", ",", "str", ")", ",", "\"Expected lSetPath to be a string.\"", "\n", "assert", "isinstance", "(", "uSetPath", ",", "str", ")", ",", "\"Expected uSetPath to be a string.\"", "\n", "assert", "isinstance", "(", "valSetPath", ",", "str", ")", ",", "\"Expected valSetPath to be a string.\"", "\n", "\n", "lSet", "=", "np", ".", "load", "(", "lSetPath", ",", "allow_pickle", "=", "True", ")", "\n", "uSet", "=", "np", ".", "load", "(", "uSetPath", ",", "allow_pickle", "=", "True", ")", "\n", "valSet", "=", "np", ".", "load", "(", "valSetPath", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "#Checking no overlap", "\n", "assert", "len", "(", "set", "(", "valSet", ")", "&", "set", "(", "uSet", ")", ")", "==", "0", ",", "\"Intersection is not allowed between validationset and uset\"", "\n", "assert", "len", "(", "set", "(", "valSet", ")", "&", "set", "(", "lSet", ")", ")", "==", "0", ",", "\"Intersection is not allowed between validationset and lSet\"", "\n", "assert", "len", "(", "set", "(", "uSet", ")", "&", "set", "(", "lSet", ")", ")", "==", "0", ",", "\"Intersection is not allowed between uSet and lSet\"", "\n", "\n", "return", "lSet", ",", "uSet", ",", "valSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadTVPartitions": [[542, 554], ["isinstance", "isinstance", "numpy.load", "numpy.load", "len", "set", "set"], "methods", ["None"], ["", "def", "loadTVPartitions", "(", "self", ",", "trainSetPath", ",", "valSetPath", ")", ":", "\n", "\n", "        ", "assert", "isinstance", "(", "trainSetPath", ",", "str", ")", ",", "\"Expected trainSetPath to be a string.\"", "\n", "assert", "isinstance", "(", "valSetPath", ",", "str", ")", ",", "\"Expected valSetPath to be a string.\"", "\n", "\n", "trainSet", "=", "np", ".", "load", "(", "trainSetPath", ",", "allow_pickle", "=", "True", ")", "\n", "valSet", "=", "np", ".", "load", "(", "valSetPath", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "#Checking no overlap", "\n", "assert", "len", "(", "set", "(", "valSet", ")", "&", "set", "(", "trainSet", ")", ")", "==", "0", ",", "\"Intersection is not allowed between validationset and trainSet\"", "\n", "\n", "return", "trainSet", ",", "valSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadPartition": [[556, 562], ["isinstance", "numpy.load"], "methods", ["None"], ["", "def", "loadPartition", "(", "self", ",", "setPath", ")", ":", "\n", "\n", "        ", "assert", "isinstance", "(", "setPath", ",", "str", ")", ",", "\"Expected setPath to be a string.\"", "\n", "\n", "setArray", "=", "np", ".", "load", "(", "setPath", ",", "allow_pickle", "=", "True", ")", "\n", "return", "setArray", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSets": [[564, 573], ["numpy.array", "numpy.array", "numpy.array", "numpy.save", "numpy.save", "numpy.save"], "methods", ["None"], ["", "def", "saveSets", "(", "self", ",", "lSet", ",", "uSet", ",", "activeSet", ",", "save_dir", ")", ":", "\n", "\n", "        ", "lSet", "=", "np", ".", "array", "(", "lSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "uSet", "=", "np", ".", "array", "(", "uSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "valSet", "=", "np", ".", "array", "(", "activeSet", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "\n", "np", ".", "save", "(", "f'{save_dir}/lSet.npy'", ",", "lSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/uSet.npy'", ",", "uSet", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/activeSet.npy'", ",", "activeSet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSet": [[577, 582], ["numpy.array", "numpy.save"], "methods", ["None"], ["", "def", "saveSet", "(", "self", ",", "setArray", ",", "setName", ",", "save_dir", ")", ":", "\n", "\n", "        ", "setArray", "=", "np", ".", "array", "(", "setArray", ",", "dtype", "=", "np", ".", "ndarray", ")", "\n", "np", ".", "save", "(", "f'{save_dir}/{setName}.npy'", ",", "setArray", ")", "\n", "return", "f'{save_dir}/{setName}.npy'", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getClassWeightsFromDataset": [[584, 587], ["data.Data.getIndexesDataLoader", "data.Data.getClassWeights"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getClassWeights"], ["", "def", "getClassWeightsFromDataset", "(", "self", ",", "dataset", ",", "index_set", ",", "bs", ")", ":", "\n", "        ", "temp_loader", "=", "self", ".", "getIndexesDataLoader", "(", "indexes", "=", "index_set", ",", "batch_size", "=", "bs", ",", "data", "=", "dataset", ")", "\n", "return", "self", ".", "getClassWeights", "(", "temp_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getClassWeights": [[589, 621], ["print", "numpy.concatenate", "print", "numpy.unique", "print", "len", "numpy.zeros", "print", "torch.Tensor", "numpy.concatenate.append", "numpy.sum", "numpy.sum"], "methods", ["None"], ["", "def", "getClassWeights", "(", "self", ",", "dataloader", ")", ":", "\n", "\n", "        ", "\"\"\"\n        INPUT\n        dataloader: dataLoader\n        \n        OUTPUT\n        Returns a tensor of size C where each element at index i represents the weight for class i. \n        \"\"\"", "\n", "\n", "all_labels", "=", "[", "]", "\n", "for", "_", ",", "y", "in", "dataloader", ":", "\n", "            ", "all_labels", ".", "append", "(", "y", ")", "\n", "", "print", "(", "\"===Computing Imbalanced Weights===\"", ")", "\n", "\n", "\n", "all_labels", "=", "np", ".", "concatenate", "(", "all_labels", ",", "axis", "=", "0", ")", "\n", "print", "(", "f\"all_labels.shape: {all_labels.shape}\"", ")", "\n", "classes", "=", "np", ".", "unique", "(", "all_labels", ")", "\n", "print", "(", "f\"classes: {classes.shape}\"", ")", "\n", "num_classes", "=", "len", "(", "classes", ")", "\n", "freq_count", "=", "np", ".", "zeros", "(", "num_classes", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "classes", ":", "\n", "            ", "freq_count", "[", "i", "]", "=", "(", "all_labels", "==", "i", ")", ".", "sum", "(", ")", "\n", "\n", "#Normalize", "\n", "", "freq_count", "=", "(", "1.0", "*", "freq_count", ")", "/", "np", ".", "sum", "(", "freq_count", ")", "\n", "print", "(", "f\"=== Sum(freq_count): {np.sum(freq_count)} ===\"", ")", "\n", "class_weights", "=", "1.", "/", "freq_count", "\n", "\n", "class_weights", "=", "torch", ".", "Tensor", "(", "class_weights", ")", "\n", "return", "class_weights", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.sampler.IndexedSequentialSampler.__init__": [[15, 18], ["print"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_idxes", ",", "isDebug", "=", "False", ")", ":", "\n", "        ", "if", "isDebug", ":", "print", "(", "\"========= my custom squential sampler =========\"", ")", "\n", "self", ".", "data_idxes", "=", "data_idxes", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.sampler.IndexedSequentialSampler.__iter__": [[19, 21], ["range", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "data_idxes", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "data_idxes", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.sampler.IndexedSequentialSampler.__len__": [[22, 24], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.simclr_augment.get_simclr_ops": [[7, 15], ["torchvision.transforms.ColorJitter", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomApply", "torchvision.transforms.RandomGrayscale", "utils.gaussian_blur.GaussianBlur", "int"], "function", ["None"], ["def", "get_simclr_ops", "(", "input_shape", ",", "s", "=", "1", ")", ":", "\n", "# get a set of data augmentation transformations as described in the SimCLR paper.", "\n", "    ", "color_jitter", "=", "transforms", ".", "ColorJitter", "(", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.2", "*", "s", ")", "\n", "ops", "=", "[", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "color_jitter", "]", ",", "p", "=", "0.8", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "GaussianBlur", "(", "kernel_size", "=", "int", "(", "0.1", "*", "input_shape", ")", ")", ",", "]", "\n", "return", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.VGG.__init__": [[37, 72], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "logger.warning", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "vgg.VGG._initialize_weights"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.VGG._initialize_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "features", ":", "nn", ".", "Module", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "init_weights", ":", "bool", "=", "True", ",", "\n", "use_dropout", "=", "False", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "VGG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "penultimate_active", "=", "False", "\n", "if", "self", ".", "num_classes", "==", "1000", ":", "\n", "            ", "logger", ".", "warning", "(", "\"This open source implementation is only suitable for small datasets like CIFAR. \\\n                For Imagenet we recommend to use Resnet based models\"", ")", "\n", "self", ".", "penultimate_dim", "=", "4096", "\n", "", "else", ":", "\n", "            ", "self", ".", "penultimate_dim", "=", "512", "\n", "", "self", ".", "features", "=", "features", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "penultimate_act", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "self", ".", "penultimate_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "#nn.Dropout(),", "\n", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "penultimate_dim", ",", "num_classes", ")", "\n", ")", "\n", "\n", "# Describe model with source code link", "\n", "self", ".", "description", "=", "\"VGG16 model loaded from VAAL source code with penultimate dim as {}\"", ".", "format", "(", "self", ".", "penultimate_dim", ")", "\n", "self", ".", "source_link", "=", "\"https://github.com/sinhasam/vaal/blob/master/vgg.py\"", "\n", "\n", "if", "init_weights", ":", "\n", "            ", "self", ".", "_initialize_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.VGG.forward": [[73, 82], ["vgg.VGG.features", "vgg.VGG.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "vgg.VGG.penultimate_act", "vgg.VGG.classifier"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "z", "=", "self", ".", "penultimate_act", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "z", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "z", ",", "x", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.VGG._initialize_weights": [[83, 95], ["vgg.VGG.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.normal_", "torch.init.normal_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "_initialize_weights", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0", ",", "0.01", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.make_layers": [[97, 112], ["torch.Sequential", "typing.cast", "torch.Conv2d", "torch.MaxPool2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "function", ["None"], ["", "", "", "", "def", "make_layers", "(", "cfg", ":", "List", "[", "Union", "[", "str", ",", "int", "]", "]", ",", "batch_norm", ":", "bool", "=", "False", ")", "->", "nn", ".", "Sequential", ":", "\n", "    ", "layers", ":", "List", "[", "nn", ".", "Module", "]", "=", "[", "]", "\n", "in_channels", "=", "3", "\n", "for", "v", "in", "cfg", ":", "\n", "        ", "if", "v", "==", "'M'", ":", "\n", "            ", "layers", "+=", "[", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "]", "\n", "", "else", ":", "\n", "            ", "v", "=", "cast", "(", "int", ",", "v", ")", "\n", "conv2d", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "v", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "if", "batch_norm", ":", "\n", "                ", "layers", "+=", "[", "conv2d", ",", "nn", ".", "BatchNorm2d", "(", "v", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "layers", "+=", "[", "conv2d", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "", "in_channels", "=", "v", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg": [[122, 131], ["vgg.VGG", "vgg.make_layers", "torch.utils.model_zoo.load_url", "VGG.load_state_dict"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.make_layers"], ["def", "_vgg", "(", "arch", ":", "str", ",", "cfg", ":", "str", ",", "batch_norm", ":", "bool", ",", "pretrained", ":", "bool", ",", "progress", ":", "bool", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "if", "pretrained", ":", "\n", "        ", "kwargs", "[", "'init_weights'", "]", "=", "False", "\n", "", "model", "=", "VGG", "(", "make_layers", "(", "cfgs", "[", "cfg", "]", ",", "batch_norm", "=", "batch_norm", ")", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg11": [[133, 141], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg11", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 11-layer model (configuration \"A\") from\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg11'", ",", "'A'", ",", "False", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg11_bn": [[143, 151], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg11_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg11_bn'", ",", "'A'", ",", "True", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg13": [[153, 161], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg13", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 13-layer model (configuration \"B\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg13'", ",", "'B'", ",", "False", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg13_bn": [[163, 171], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg13_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg13_bn'", ",", "'B'", ",", "True", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg16": [[173, 181], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg16", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 16-layer model (configuration \"D\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg16'", ",", "'D'", ",", "False", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg16_bn": [[183, 191], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg16_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg16_bn'", ",", "'D'", ",", "True", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg19": [[193, 201], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg19", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 19-layer model (configuration \"E\")\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg19'", ",", "'E'", ",", "False", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg.vgg19_bn": [[203, 211], ["vgg._vgg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vgg._vgg"], ["", "def", "vgg19_bn", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "VGG", ":", "\n", "    ", "r\"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`._\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_vgg", "(", "'vgg19_bn'", ",", "'E'", ",", "True", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.View.__init__": [[14, 17], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "super", "(", "View", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.View.forward": [[18, 20], ["tensor.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "return", "tensor", ".", "view", "(", "self", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE.__init__": [[24, 75], ["torch.Module.__init__", "print", "logger.info", "print", "logger.info", "print", "logger.info", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vaal_model.VAE.weight_init", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "vaal_model.View", "torch.Linear", "torch.Linear", "torch.Linear", "vaal_model.View", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.weight_init"], ["def", "__init__", "(", "self", ",", "device_id", ",", "z_dim", "=", "32", ",", "nc", "=", "3", ")", ":", "\n", "        ", "super", "(", "VAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "print", "(", "\"============================\"", ")", "\n", "logger", ".", "info", "(", "\"============================\"", ")", "\n", "print", "(", "f\"Constructing VAE MODEL with z_dim: {z_dim}\"", ")", "\n", "logger", ".", "info", "(", "f\"Constructing VAE MODEL with z_dim: {z_dim}\"", ")", "\n", "print", "(", "\"============================\"", ")", "\n", "logger", ".", "info", "(", "\"============================\"", ")", "\n", "self", ".", "encode_shape", "=", "int", "(", "z_dim", "/", "16", ")", "\n", "if", "z_dim", "==", "32", ":", "\n", "            ", "self", ".", "decode_shape", "=", "4", "\n", "", "elif", "z_dim", "==", "64", ":", "\n", "            ", "self", ".", "decode_shape", "=", "8", "\n", "", "else", ":", "\n", "            ", "self", ".", "decode_shape", "=", "4", "\n", "", "self", ".", "device_id", "=", "device_id", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "nc", "=", "nc", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "nc", ",", "128", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  128, 32, 32 or B, 128, 64, 64", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  256, 16, 16 or B, 256, 32, 32", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  512,  8,  8 or B, 512, 16, 16", "\n", "nn", ".", "BatchNorm2d", "(", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "1024", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B, 1024,  4,  4 or B, 1024, 8, 8", "\n", "nn", ".", "BatchNorm2d", "(", "1024", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "View", "(", "(", "-", "1", ",", "1024", "*", "self", ".", "encode_shape", "*", "self", ".", "encode_shape", ")", ")", ",", "# B, 1024*4*4 or B, 1024, 4, 4", "\n", ")", "\n", "\n", "self", ".", "fc_mu", "=", "nn", ".", "Linear", "(", "1024", "*", "self", ".", "encode_shape", "*", "self", ".", "encode_shape", ",", "z_dim", ")", "# B, z_dim", "\n", "self", ".", "fc_logvar", "=", "nn", ".", "Linear", "(", "1024", "*", "self", ".", "encode_shape", "*", "self", ".", "encode_shape", ",", "z_dim", ")", "# B, z_dim", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "1024", "*", "self", ".", "decode_shape", "*", "self", ".", "decode_shape", ")", ",", "# B, 1024*8*8", "\n", "View", "(", "(", "-", "1", ",", "1024", ",", "self", ".", "decode_shape", ",", "self", ".", "decode_shape", ")", ")", ",", "# B, 1024,  8,  8", "\n", "nn", ".", "ConvTranspose2d", "(", "1024", ",", "512", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  512, 16, 16", "\n", "nn", ".", "BatchNorm2d", "(", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "512", ",", "256", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  256, 32, 32", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "256", ",", "128", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "# B,  128, 64, 64", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "nc", ",", "1", ")", ",", "# B,   nc, 64, 64", "\n", ")", "\n", "self", ".", "weight_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE.weight_init": [[76, 83], ["vaal_model.kaiming_init", "vaal_model.kaiming_init"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init"], ["", "def", "weight_init", "(", "self", ")", ":", "\n", "        ", "for", "block", "in", "self", ".", "_modules", ":", "\n", "            ", "try", ":", "\n", "                ", "for", "m", "in", "self", ".", "_modules", "[", "block", "]", ":", "\n", "                    ", "kaiming_init", "(", "m", ")", "\n", "", "", "except", ":", "\n", "                ", "kaiming_init", "(", "block", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE.forward": [[84, 91], ["vaal_model.VAE._encode", "vaal_model.VAE.reparameterize", "vaal_model.VAE._decode", "vaal_model.VAE.fc_mu", "vaal_model.VAE.fc_logvar"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE._encode", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE.reparameterize", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE._decode"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "z", "=", "self", ".", "_encode", "(", "x", ")", "\n", "mu", ",", "logvar", "=", "self", ".", "fc_mu", "(", "z", ")", ",", "self", ".", "fc_logvar", "(", "z", ")", "\n", "z", "=", "self", ".", "reparameterize", "(", "mu", ",", "logvar", ")", "\n", "x_recon", "=", "self", ".", "_decode", "(", "z", ")", "\n", "\n", "return", "x_recon", ",", "z", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE.reparameterize": [[92, 100], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "mu.cuda.cuda.cuda", "stds.cuda", "torch.randn.cuda", "torch.randn.cuda", "torch.randn.cuda", "mu.cuda.cuda.size"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "def", "reparameterize", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "stds", "=", "(", "0.5", "*", "logvar", ")", ".", "exp", "(", ")", "\n", "epsilon", "=", "torch", ".", "randn", "(", "*", "mu", ".", "size", "(", ")", ")", "\n", "#if mu.is_cuda:", "\n", "stds", ",", "epsilon", "=", "stds", ".", "cuda", "(", ")", ",", "epsilon", ".", "cuda", "(", ")", "\n", "mu", "=", "mu", ".", "cuda", "(", ")", "\n", "latents", "=", "epsilon", "*", "stds", "+", "mu", "\n", "return", "latents", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE._encode": [[101, 103], ["vaal_model.VAE.encoder"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.VAE._decode": [[104, 106], ["vaal_model.VAE.decoder"], "methods", ["None"], ["", "def", "_decode", "(", "self", ",", "z", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.clf_Discriminator.__init__": [[112, 138], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vaal_model.clf_Discriminator.weight_init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.weight_init"], ["def", "__init__", "(", "self", ",", "z_dim", "=", "10", ",", "n_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "clf_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "\n", "self", ".", "disc_out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "self", ".", "clf_out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n", "\n", "self", ".", "weight_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.clf_Discriminator.weight_init": [[139, 143], ["vaal_model.kaiming_init"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init"], ["", "def", "weight_init", "(", "self", ")", ":", "\n", "        ", "for", "block", "in", "self", ".", "_modules", ":", "\n", "            ", "for", "m", "in", "self", ".", "_modules", "[", "block", "]", ":", "\n", "                ", "kaiming_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.clf_Discriminator.forward": [[144, 149], ["vaal_model.clf_Discriminator.net", "vaal_model.clf_Discriminator.disc_out", "vaal_model.clf_Discriminator.clf_out"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "disc_out", "=", "self", ".", "disc_out", "(", "z", ")", "\n", "clf_out", "=", "self", ".", "clf_out", "(", "z", ")", "\n", "return", "disc_out", ",", "clf_out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.Discriminator.__init__": [[153, 174], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vaal_model.Discriminator.weight_init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.weight_init"], ["def", "__init__", "(", "self", ",", "z_dim", "=", "10", ")", ":", "\n", "        ", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "penultimate_active", "=", "False", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "\n", "self", ".", "out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", ",", "1", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "self", ".", "weight_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.Discriminator.weight_init": [[175, 179], ["vaal_model.kaiming_init"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init"], ["", "def", "weight_init", "(", "self", ")", ":", "\n", "        ", "for", "block", "in", "self", ".", "_modules", ":", "\n", "            ", "for", "m", "in", "self", ".", "_modules", "[", "block", "]", ":", "\n", "                ", "kaiming_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.Discriminator.forward": [[180, 185], ["vaal_model.Discriminator.net", "vaal_model.Discriminator.out", "vaal_model.Discriminator.out"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "z", ",", "self", ".", "out", "(", "z", ")", "\n", "", "return", "self", ".", "out", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.__init__": [[188, 209], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "vaal_model.WGAN_Discriminator.weight_init", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.weight_init"], ["def", "__init__", "(", "self", ",", "z_dim", "=", "10", ")", ":", "\n", "        ", "super", "(", "WGAN_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "penultimate_active", "=", "False", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", "\n", ")", "\n", "\n", "self", ".", "out", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", ",", "1", ")", ",", "\n", "#nn.Sigmoid()", "\n", ")", "\n", "\n", "self", ".", "weight_init", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.weight_init": [[210, 214], ["vaal_model.kaiming_init"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init"], ["", "def", "weight_init", "(", "self", ")", ":", "\n", "        ", "for", "block", "in", "self", ".", "_modules", ":", "\n", "            ", "for", "m", "in", "self", ".", "_modules", "[", "block", "]", ":", "\n", "                ", "kaiming_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.WGAN_Discriminator.forward": [[215, 220], ["vaal_model.WGAN_Discriminator.net", "vaal_model.WGAN_Discriminator.out", "vaal_model.WGAN_Discriminator.out"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "z", ")", ":", "\n", "        ", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "z", ",", "self", ".", "out", "(", "z", ")", "\n", "", "return", "self", ".", "out", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.kaiming_init": [[222, 231], ["isinstance", "torch.kaiming_normal_", "isinstance", "m.bias.data.fill_", "m.weight.data.fill_", "m.bias.data.fill_"], "function", ["None"], ["", "", "def", "kaiming_init", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm1d", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.vaal_model.normal_init": [[233, 242], ["isinstance", "m.weight.data.normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "function", ["None"], ["", "", "", "def", "normal_init", "(", "m", ",", "mean", ",", "std", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", ",", "std", ")", "\n", "if", "m", ".", "bias", ".", "data", "is", "not", "None", ":", "\n", "            ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "BatchNorm1d", ")", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "if", "m", ".", "bias", ".", "data", "is", "not", "None", ":", "\n", "            ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.BasicBlock.__init__": [[42, 68], ["torch.Module.__init__", "resnet.conv3x3", "norm_layer", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "norm_layer", "ValueError", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv3x3", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv3x3"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inplanes", ":", "int", ",", "\n", "planes", ":", "int", ",", "\n", "stride", ":", "int", "=", "1", ",", "\n", "downsample", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "groups", ":", "int", "=", "1", ",", "\n", "base_width", ":", "int", "=", "64", ",", "\n", "dilation", ":", "int", "=", "1", ",", "\n", "norm_layer", ":", "Optional", "[", "Callable", "[", "...", ",", "nn", ".", "Module", "]", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", "or", "base_width", "!=", "64", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1 and base_width=64'", ")", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dilation > 1 not supported in BasicBlock\"", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.BasicBlock.forward": [[69, 86], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.Bottleneck.__init__": [[97, 122], ["torch.Module.__init__", "resnet.conv1x1", "norm_layer", "resnet.conv3x3", "norm_layer", "resnet.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv1x1", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv3x3", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv1x1"], ["def", "__init__", "(", "\n", "self", ",", "\n", "inplanes", ":", "int", ",", "\n", "planes", ":", "int", ",", "\n", "stride", ":", "int", "=", "1", ",", "\n", "downsample", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "groups", ":", "int", "=", "1", ",", "\n", "base_width", ":", "int", "=", "64", ",", "\n", "dilation", ":", "int", "=", "1", ",", "\n", "norm_layer", ":", "Optional", "[", "Callable", "[", "...", ",", "nn", ".", "Module", "]", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "groups", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.Bottleneck.forward": [[123, 144], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.ResNet.__init__": [[148, 212], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "resnet.ResNet.modules", "len", "ValueError", "isinstance", "resnet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "block", ":", "Type", "[", "Union", "[", "BasicBlock", ",", "Bottleneck", "]", "]", ",", "\n", "layers", ":", "List", "[", "int", "]", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "zero_init_residual", ":", "bool", "=", "False", ",", "\n", "groups", ":", "int", "=", "1", ",", "\n", "width_per_group", ":", "int", "=", "64", ",", "\n", "replace_stride_with_dilation", ":", "Optional", "[", "List", "[", "bool", "]", "]", "=", "None", ",", "\n", "norm_layer", ":", "Optional", "[", "Callable", "[", "...", ",", "nn", ".", "Module", "]", "]", "=", "None", ",", "\n", "penultimate_active", ":", "bool", "=", "False", ",", "\n", "use_dropout", ":", "bool", "=", "False", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "self", ".", "use_dropout", "=", "use_dropout", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "self", ".", "penultimate_active", "=", "penultimate_active", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "# type: ignore[arg-type]", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "# type: ignore[arg-type]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.ResNet._make_layer": [[213, 237], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet.conv1x1", "norm_layer", "block"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv1x1"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ":", "Type", "[", "Union", "[", "BasicBlock", ",", "Bottleneck", "]", "]", ",", "planes", ":", "int", ",", "blocks", ":", "int", ",", "\n", "stride", ":", "int", "=", "1", ",", "dilate", ":", "bool", "=", "False", ")", "->", "nn", ".", "Sequential", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.ResNet._forward_impl": [[238, 258], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "resnet.ResNet.fc", "resnet.ResNet.drop"], "methods", ["None"], ["", "def", "_forward_impl", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "# See note [TorchScript super()]", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "z", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "z", "=", "self", ".", "drop", "(", "z", ")", "\n", "", "x", "=", "self", ".", "fc", "(", "z", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "z", ",", "x", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.ResNet.forward": [[259, 261], ["resnet.ResNet._forward_impl"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.ResNet._forward_impl"], ["", "def", "forward", "(", "self", ",", "x", ":", "Tensor", ")", "->", "Tensor", ":", "\n", "        ", "return", "self", ".", "_forward_impl", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv3x3": [[28, 32], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ":", "int", ",", "out_planes", ":", "int", ",", "stride", ":", "int", "=", "1", ",", "groups", ":", "int", "=", "1", ",", "dilation", ":", "int", "=", "1", ")", "->", "nn", ".", "Conv2d", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.conv1x1": [[34, 37], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ":", "int", ",", "out_planes", ":", "int", ",", "stride", ":", "int", "=", "1", ")", "->", "nn", ".", "Conv2d", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet": [[263, 277], ["resnet.ResNet", "torch.utils.model_zoo.load_url", "ResNet.load_state_dict"], "function", ["None"], ["", "", "def", "_resnet", "(", "\n", "arch", ":", "str", ",", "\n", "block", ":", "Type", "[", "Union", "[", "BasicBlock", ",", "Bottleneck", "]", "]", ",", "\n", "layers", ":", "List", "[", "int", "]", ",", "\n", "pretrained", ":", "bool", ",", "\n", "progress", ":", "bool", ",", "\n", "**", "kwargs", ":", "Any", "\n", ")", "->", "ResNet", ":", "\n", "    ", "model", "=", "ResNet", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet18": [[279, 289], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnet18", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNet-18 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet18'", ",", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet34": [[291, 301], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnet34", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNet-34 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet34'", ",", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet50": [[9, 13], ["torch.Identity"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Identity"], ["\n", "__all__", "=", "[", "'ResNet'", ",", "'resnet18'", ",", "'resnet34'", ",", "'resnet50'", ",", "'resnet101'", ",", "\n", "'resnet152'", ",", "'resnext50_32x4d'", ",", "'resnext101_32x8d'", ",", "\n", "'wide_resnet50_2'", ",", "'wide_resnet101_2'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet101": [[315, 325], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnet101", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNet-101 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet101'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnet152": [[327, 337], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnet152", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnext50_32x4d": [[339, 351], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnext50_32x4d", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNeXt-50 32x4d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "4", "\n", "return", "_resnet", "(", "'resnext50_32x4d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.resnext101_32x8d": [[353, 365], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "resnext101_32x8d", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"ResNeXt-101 32x8d model from\n    `\"Aggregated Residual Transformation for Deep Neural Networks\" <https://arxiv.org/pdf/1611.05431.pdf>`_.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnet", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.wide_resnet50_2": [[367, 383], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "wide_resnet50_2", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"Wide ResNet-50-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet50_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet.wide_resnet101_2": [[385, 401], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet._resnet"], ["", "def", "wide_resnet101_2", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "ResNet", ":", "\n", "    ", "r\"\"\"Wide ResNet-101-2 model from\n    `\"Wide Residual Networks\" <https://arxiv.org/pdf/1605.07146.pdf>`_.\n\n    The model is the same as ResNet except for the bottleneck number of channels\n    which is twice larger in every block. The number of channels in outer 1x1\n    convolutions is the same, e.g. last block in ResNet-50 has 2048-512-2048\n    channels, and in Wide ResNet-50-2 has 2048-1024-2048.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "64", "*", "2", "\n", "return", "_resnet", "(", "'wide_resnet101_2'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "pretrained", ",", "progress", ",", "**", "kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.alexnet.AlexNet.__init__": [[19, 51], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", ":", "int", "=", "1000", ",", "use_dropout", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", "AlexNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_dropout", "=", "use_dropout", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "192", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "192", ",", "384", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "384", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ")", ",", "\n", ")", "\n", "# self.avgpool = nn.AdaptiveAvgPool2d((6, 6))", "\n", "self", ".", "fc_block", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "256", "*", "2", "*", "2", ",", "4096", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "4096", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "4096", ",", "num_classes", ")", ",", "\n", ")", "\n", "self", ".", "penultimate_active", "=", "False", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.alexnet.AlexNet.forward": [[52, 63], ["alexnet.AlexNet.features", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "alexnet.AlexNet.fc_block", "alexnet.AlexNet.classifier", "alexnet.AlexNet.drop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "# x = self.avgpool(x)", "\n", "z", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "if", "self", ".", "use_dropout", ":", "\n", "            ", "x", "=", "self", ".", "drop", "(", "x", ")", "\n", "", "z", "=", "self", ".", "fc_block", "(", "z", ")", "\n", "x", "=", "self", ".", "classifier", "(", "z", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "z", ",", "x", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.alexnet.alexnet": [[65, 78], ["alexnet.AlexNet", "torch.utils.model_zoo.load_url", "AlexNet.load_state_dict"], "function", ["None"], ["", "", "def", "alexnet", "(", "pretrained", ":", "bool", "=", "False", ",", "progress", ":", "bool", "=", "True", ",", "**", "kwargs", ":", "Any", ")", "->", "AlexNet", ":", "\n", "    ", "r\"\"\"AlexNet model architecture from the\n    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "model", "=", "AlexNet", "(", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "'alexnet'", "]", ",", "\n", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.models.ContrastiveModel.__init__": [[11, 27], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "ValueError", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "backbone", ",", "head", "=", "'mlp'", ",", "features_dim", "=", "128", ")", ":", "\n", "        ", "super", "(", "ContrastiveModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "[", "'backbone'", "]", "\n", "self", ".", "backbone_dim", "=", "backbone", "[", "'dim'", "]", "\n", "self", ".", "head", "=", "head", "\n", "\n", "if", "head", "==", "'linear'", ":", "\n", "            ", "self", ".", "contrastive_head", "=", "nn", ".", "Linear", "(", "self", ".", "backbone_dim", ",", "features_dim", ")", "\n", "\n", "", "elif", "head", "==", "'mlp'", ":", "\n", "            ", "self", ".", "contrastive_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "backbone_dim", ",", "self", ".", "backbone_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "self", ".", "backbone_dim", ",", "features_dim", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid head {}'", ".", "format", "(", "head", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.models.ContrastiveModel.forward": [[28, 35], ["models.ContrastiveModel.backbone", "models.ContrastiveModel.contrastive_head", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "return_pre_last", "=", "False", ")", ":", "\n", "        ", "pre_last", "=", "self", ".", "backbone", "(", "x", ")", "\n", "features", "=", "self", ".", "contrastive_head", "(", "pre_last", ")", "\n", "features", "=", "F", ".", "normalize", "(", "features", ",", "dim", "=", "1", ")", "\n", "if", "return_pre_last", ":", "\n", "            ", "return", "features", ",", "pre_last", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.models.ClusteringModel.__init__": [[38, 46], ["torch.Module.__init__", "isinstance", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "backbone", ",", "nclusters", ",", "nheads", "=", "1", ")", ":", "\n", "        ", "super", "(", "ClusteringModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "backbone", "=", "backbone", "[", "'backbone'", "]", "\n", "self", ".", "backbone_dim", "=", "backbone", "[", "'dim'", "]", "\n", "self", ".", "nheads", "=", "nheads", "\n", "assert", "(", "isinstance", "(", "self", ".", "nheads", ",", "int", ")", ")", "\n", "assert", "(", "self", ".", "nheads", ">", "0", ")", "\n", "self", ".", "cluster_head", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "backbone_dim", ",", "nclusters", ")", "for", "_", "in", "range", "(", "self", ".", "nheads", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.models.ClusteringModel.forward": [[47, 66], ["models.ClusteringModel.backbone", "cluster_head", "models.ClusteringModel.backbone", "cluster_head", "models.ClusteringModel.backbone", "ValueError", "cluster_head"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "forward_pass", "=", "'default'", ")", ":", "\n", "        ", "if", "forward_pass", "==", "'default'", ":", "\n", "            ", "features", "=", "self", ".", "backbone", "(", "x", ")", "\n", "out", "=", "[", "cluster_head", "(", "features", ")", "for", "cluster_head", "in", "self", ".", "cluster_head", "]", "\n", "\n", "", "elif", "forward_pass", "==", "'backbone'", ":", "\n", "            ", "out", "=", "self", ".", "backbone", "(", "x", ")", "\n", "\n", "", "elif", "forward_pass", "==", "'head'", ":", "\n", "            ", "out", "=", "[", "cluster_head", "(", "x", ")", "for", "cluster_head", "in", "self", ".", "cluster_head", "]", "\n", "\n", "", "elif", "forward_pass", "==", "'return_all'", ":", "\n", "            ", "features", "=", "self", ".", "backbone", "(", "x", ")", "\n", "out", "=", "{", "'features'", ":", "features", ",", "'output'", ":", "[", "cluster_head", "(", "features", ")", "for", "cluster_head", "in", "self", ".", "cluster_head", "]", "}", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid forward pass {}'", ".", "format", "(", "forward_pass", ")", ")", "\n", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.BasicBlock.__init__": [[12, 25], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.BasicBlock.forward": [[27, 37], ["torch.relu", "torch.relu", "torch.relu", "resnet_tinyimagenet.BasicBlock.bn2", "resnet_tinyimagenet.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_tinyimagenet.BasicBlock.bn1", "resnet_tinyimagenet.BasicBlock.conv2", "resnet_tinyimagenet.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.Bottleneck.__init__": [[42, 57], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.Bottleneck.forward": [[59, 70], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet_tinyimagenet.Bottleneck.bn3", "resnet_tinyimagenet.Bottleneck.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_tinyimagenet.Bottleneck.bn1", "resnet_tinyimagenet.Bottleneck.bn2", "resnet_tinyimagenet.Bottleneck.conv3", "resnet_tinyimagenet.Bottleneck.conv1", "resnet_tinyimagenet.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.ResNet.__init__": [[73, 103], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet_tinyimagenet.ResNet._make_layer", "resnet_tinyimagenet.ResNet._make_layer", "resnet_tinyimagenet.ResNet._make_layer", "resnet_tinyimagenet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "resnet_tinyimagenet.ResNet.modules", "isinstance", "resnet_tinyimagenet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "in_channel", "=", "3", ",", "zero_init_residual", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "64", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves", "\n", "# like an identity. This improves the model by 0.2~0.3% according to:", "\n", "# https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.ResNet._make_layer": [[104, 112], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "stride", "=", "strides", "[", "i", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.ResNet.forward": [[113, 122], ["torch.relu", "torch.relu", "torch.relu", "resnet_tinyimagenet.ResNet.layer1", "resnet_tinyimagenet.ResNet.layer2", "resnet_tinyimagenet.ResNet.layer3", "resnet_tinyimagenet.ResNet.layer4", "resnet_tinyimagenet.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "resnet_tinyimagenet.ResNet.bn1", "resnet_tinyimagenet.ResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "self", ".", "avgpool", "(", "out", ")", "\n", "out", "=", "torch", ".", "flatten", "(", "out", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_tinyimagenet.resnet18": [[124, 126], ["resnet_tinyimagenet.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "'backbone'", ":", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", ",", "'dim'", ":", "512", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.BasicBlock.__init__": [[12, 25], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.BasicBlock.forward": [[27, 37], ["torch.relu", "torch.relu", "torch.relu", "resnet_cifar.BasicBlock.bn2", "resnet_cifar.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_cifar.BasicBlock.bn1", "resnet_cifar.BasicBlock.conv2", "resnet_cifar.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.Bottleneck.__init__": [[42, 57], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.Bottleneck.forward": [[59, 70], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet_cifar.Bottleneck.bn3", "resnet_cifar.Bottleneck.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_cifar.Bottleneck.bn1", "resnet_cifar.Bottleneck.bn2", "resnet_cifar.Bottleneck.conv3", "resnet_cifar.Bottleneck.conv1", "resnet_cifar.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.ResNet.__init__": [[73, 103], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet_cifar.ResNet._make_layer", "resnet_cifar.ResNet._make_layer", "resnet_cifar.ResNet._make_layer", "resnet_cifar.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "resnet_cifar.ResNet.modules", "isinstance", "resnet_cifar.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "in_channel", "=", "3", ",", "zero_init_residual", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "64", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves", "\n", "# like an identity. This improves the model by 0.2~0.3% according to:", "\n", "# https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.ResNet._make_layer": [[104, 112], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "stride", "=", "strides", "[", "i", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.ResNet.forward": [[113, 122], ["torch.relu", "torch.relu", "torch.relu", "resnet_cifar.ResNet.layer1", "resnet_cifar.ResNet.layer2", "resnet_cifar.ResNet.layer3", "resnet_cifar.ResNet.layer4", "resnet_cifar.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "resnet_cifar.ResNet.bn1", "resnet_cifar.ResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "self", ".", "avgpool", "(", "out", ")", "\n", "out", "=", "torch", ".", "flatten", "(", "out", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_cifar.resnet18": [[124, 126], ["resnet_cifar.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "'backbone'", ":", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", ",", "'dim'", ":", "512", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.BasicBlock.__init__": [[12, 25], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.BasicBlock.forward": [[27, 37], ["torch.relu", "torch.relu", "torch.relu", "resnet_stl.BasicBlock.bn2", "resnet_stl.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_stl.BasicBlock.bn1", "resnet_stl.BasicBlock.conv2", "resnet_stl.BasicBlock.conv1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.Bottleneck.__init__": [[42, 57], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "is_last", "=", "False", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_last", "=", "is_last", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "self", ".", "expansion", "*", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.Bottleneck.forward": [[59, 70], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet_stl.Bottleneck.bn3", "resnet_stl.Bottleneck.shortcut", "torch.relu", "torch.relu", "torch.relu", "resnet_stl.Bottleneck.bn1", "resnet_stl.Bottleneck.bn2", "resnet_stl.Bottleneck.conv3", "resnet_stl.Bottleneck.conv1", "resnet_stl.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "preact", "=", "out", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "if", "self", ".", "is_last", ":", "\n", "            ", "return", "out", ",", "preact", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet.__init__": [[73, 104], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "resnet_stl.ResNet._make_layer", "resnet_stl.ResNet._make_layer", "resnet_stl.ResNet._make_layer", "resnet_stl.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "resnet_stl.ResNet.modules", "isinstance", "resnet_stl.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer", "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "in_channel", "=", "3", ",", "zero_init_residual", "=", "False", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "64", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channel", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "num_blocks", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves", "\n", "# like an identity. This improves the model by 0.2~0.3% according to:", "\n", "# https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet._make_layer": [[105, 113], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "stride", "=", "strides", "[", "i", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.ResNet.forward": [[114, 123], ["resnet_stl.ResNet.maxpool", "resnet_stl.ResNet.layer1", "resnet_stl.ResNet.layer2", "resnet_stl.ResNet.layer3", "resnet_stl.ResNet.layer4", "resnet_stl.ResNet.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.relu", "torch.relu", "torch.relu", "resnet_stl.ResNet.bn1", "resnet_stl.ResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "maxpool", "(", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "self", ".", "avgpool", "(", "out", ")", "\n", "out", "=", "torch", ".", "flatten", "(", "out", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.models.resnet_stl.resnet18": [[125, 127], ["resnet_stl.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "return", "{", "'backbone'", ":", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", ",", "'dim'", ":", "512", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.config.assert_cfg": [[231, 249], ["None"], "function", ["None"], ["def", "assert_cfg", "(", ")", ":", "\n", "    ", "\"\"\"Checks config values invariants.\"\"\"", "\n", "assert", "not", "_C", ".", "OPTIM", ".", "STEPS", "or", "_C", ".", "OPTIM", ".", "STEPS", "[", "0", "]", "==", "0", ",", "'The first lr step must start at 0'", "\n", "assert", "_C", ".", "TRAIN", ".", "SPLIT", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ",", "'Train split \\'{}\\' not supported'", ".", "format", "(", "_C", ".", "TRAIN", ".", "SPLIT", ")", "\n", "assert", "_C", ".", "TRAIN", ".", "BATCH_SIZE", "%", "_C", ".", "NUM_GPUS", "==", "0", ",", "'Train mini-batch size should be a multiple of NUM_GPUS.'", "\n", "assert", "_C", ".", "TEST", ".", "SPLIT", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ",", "'Test split \\'{}\\' not supported'", ".", "format", "(", "_C", ".", "TEST", ".", "SPLIT", ")", "\n", "assert", "_C", ".", "TEST", ".", "BATCH_SIZE", "%", "_C", ".", "NUM_GPUS", "==", "0", ",", "'Test mini-batch size should be a multiple of NUM_GPUS.'", "\n", "\n", "#our assertions", "\n", "if", "_C", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"uncertainty_uniform_discretize\"", ":", "\n", "        ", "assert", "_C", ".", "ACTIVE_LEARNING", ".", "N_BINS", "!=", "0", ",", "\"The number of bins used cannot be 0. Please provide a number >0 for {} sampling function\"", ".", "format", "(", "_C", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.config.custom_dump_cfg": [[250, 255], ["os.path.join", "open", "_C.dump"], "function", ["None"], ["", "", "def", "custom_dump_cfg", "(", "temp_cfg", ")", ":", "\n", "    ", "\"\"\"Dumps the config to the output directory.\"\"\"", "\n", "cfg_file", "=", "os", ".", "path", ".", "join", "(", "temp_cfg", ".", "EXP_DIR", ",", "temp_cfg", ".", "CFG_DEST", ")", "\n", "with", "open", "(", "cfg_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "_C", ".", "dump", "(", "stream", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg": [[257, 262], ["os.path.join", "open", "cfg.dump"], "function", ["None"], ["", "", "def", "dump_cfg", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Dumps the config to the output directory.\"\"\"", "\n", "cfg_file", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EXP_DIR", ",", "cfg", ".", "CFG_DEST", ")", "\n", "with", "open", "(", "cfg_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cfg", ".", "dump", "(", "stream", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.config.load_cfg": [[264, 268], ["os.path.join", "_C.merge_from_file"], "function", ["None"], ["", "", "def", "load_cfg", "(", "out_dir", ",", "cfg_dest", "=", "'config.yaml'", ")", ":", "\n", "    ", "\"\"\"Loads config from specified output directory.\"\"\"", "\n", "cfg_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "cfg_dest", ")", "\n", "_C", ".", "merge_from_file", "(", "cfg_file", ")", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.SoftCrossEntropyLoss.__init__": [[79, 81], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["x", ".", "mul_", "(", "mask", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.SoftCrossEntropyLoss.forward": [[82, 85], ["torch.nn.functional.log_softmax", "torch.sum"], "methods", ["None"], ["\n", "", "def", "get_flat_weights", "(", "model", ")", ":", "\n", "    ", "\"\"\"Gets all model weights as a single flat vector.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "p", ".", "data", ".", "view", "(", "-", "1", ",", "1", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.unwrap_model": [[16, 20], ["isinstance"], "function", ["None"], ["\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "    ", "\"\"\"Performs ResNet-style weight initialization.\"\"\"", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.complexity": [[54, 60], ["unwrap_model().complexity", "net.unwrap_model"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.net.complexity", "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.unwrap_model"], ["# Accumulate the stats for each BN layer", "\n", "for", "i", ",", "bn", "in", "enumerate", "(", "bns", ")", ":", "\n", "            ", "m", ",", "v", "=", "bn", ".", "running_mean", ",", "bn", ".", "running_var", "\n", "sqs", "[", "i", "]", "+=", "(", "v", "+", "m", "*", "m", ")", "/", "num_iter", "\n", "mus", "[", "i", "]", "+=", "m", "/", "num_iter", "\n", "# Set the stats and restore momentum values", "\n", "", "", "for", "i", ",", "bn", "in", "enumerate", "(", "bns", ")", ":", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.smooth_one_hot_labels": [[62, 73], ["torch.full", "torch.full.scatter_", "labels.long().view", "labels.max", "labels.long"], "function", ["None"], ["bn", ".", "running_mean", "=", "mus", "[", "i", "]", "\n", "bn", ".", "momentum", "=", "moms", "[", "i", "]", "\n", "\n", "\n", "", "", "def", "reset_bn_stats", "(", "model", ")", ":", "\n", "    ", "\"\"\"Resets running BN stats.\"\"\"", "\n", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "m", ".", "reset_running_stats", "(", ")", "\n", "\n", "\n", "", "", "", "def", "drop_connect", "(", "x", ",", "drop_ratio", ")", ":", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.net.mixup": [[87, 97], ["numpy.random.beta", "torch.randperm", "labels.argmax"], "function", ["None"], ["\n", "", "def", "set_flat_weights", "(", "model", ",", "flat_weights", ")", ":", "\n", "    ", "\"\"\"Sets all model weights from a single flat vector.\"\"\"", "\n", "k", "=", "0", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "n", "=", "p", ".", "data", ".", "numel", "(", ")", "\n", "p", ".", "data", ".", "copy_", "(", "flat_weights", "[", "k", ":", "(", "k", "+", "n", ")", "]", ".", "view_as", "(", "p", ".", "data", ")", ")", "\n", "k", "+=", "n", "\n", "", "assert", "k", "==", "flat_weights", ".", "numel", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.FeaturesNet.__init__": [[45, 52], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_layers", ",", "out_layers", ",", "use_mlp", "=", "False", ",", "penultimate_active", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_mlp", "=", "use_mlp", "\n", "self", ".", "penultimate_active", "=", "penultimate_active", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_layers", ",", "in_layers", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "in_layers", ",", "in_layers", ")", "\n", "self", ".", "final", "=", "nn", ".", "Linear", "(", "in_layers", ",", "out_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.FeaturesNet.forward": [[53, 62], ["builders.FeaturesNet.final", "torch.nn.functional.relu", "torch.nn.functional.relu", "builders.FeaturesNet.lin1", "builders.FeaturesNet.lin2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "feats", "=", "x", "\n", "if", "self", ".", "use_mlp", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "lin1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "(", "self", ".", "lin2", "(", "x", ")", ")", ")", "\n", "", "out", "=", "self", ".", "final", "(", "x", ")", "\n", "if", "self", ".", "penultimate_active", ":", "\n", "            ", "return", "feats", ",", "out", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model": [[64, 69], ["err_str.format", "_models.keys"], "function", ["None"], ["", "", "def", "get_model", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Gets the model class specified in the config.\"\"\"", "\n", "err_str", "=", "\"Model type '{}' not supported\"", "\n", "assert", "cfg", ".", "MODEL", ".", "TYPE", "in", "_models", ".", "keys", "(", ")", ",", "err_str", ".", "format", "(", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "return", "_models", "[", "cfg", ".", "MODEL", ".", "TYPE", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_loss_fun": [[71, 76], ["err_str.format", "_loss_funs.keys"], "function", ["None"], ["", "def", "get_loss_fun", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Gets the loss function class specified in the config.\"\"\"", "\n", "err_str", "=", "\"Loss function type '{}' not supported\"", "\n", "assert", "cfg", ".", "MODEL", ".", "LOSS_FUN", "in", "_loss_funs", ".", "keys", "(", ")", ",", "err_str", ".", "format", "(", "cfg", ".", "TRAIN", ".", "LOSS", ")", "\n", "return", "_loss_funs", "[", "cfg", ".", "MODEL", ".", "LOSS_FUN", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model": [[78, 89], ["builders.FeaturesNet", "builders.get_model", "torch.nn.Conv2d"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model"], ["", "def", "build_model", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Builds the model.\"\"\"", "\n", "if", "cfg", ".", "MODEL", ".", "LINEAR_FROM_FEATURES", ":", "\n", "        ", "num_features", "=", "384", "if", "cfg", ".", "DATASET", ".", "NAME", "in", "[", "'IMAGENET50'", ",", "'IMAGENET100'", ",", "'IMAGENET200'", "]", "else", "512", "\n", "return", "FeaturesNet", "(", "num_features", ",", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ")", "\n", "\n", "", "model", "=", "get_model", "(", "cfg", ")", "(", "num_classes", "=", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ",", "use_dropout", "=", "True", ")", "\n", "if", "cfg", ".", "DATASET", ".", "NAME", "==", "'MNIST'", ":", "\n", "        ", "model", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "64", ",", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "3", ",", "3", ")", ",", "bias", "=", "False", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_loss_fun": [[91, 94], ["builders.get_loss_fun"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun"], ["", "def", "build_loss_fun", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Build the loss function.\"\"\"", "\n", "return", "get_loss_fun", "(", "cfg", ")", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.register_model": [[96, 99], ["None"], "function", ["None"], ["", "def", "register_model", "(", "name", ",", "ctor", ")", ":", "\n", "    ", "\"\"\"Registers a model dynamically.\"\"\"", "\n", "_models", "[", "name", "]", "=", "ctor", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.register_loss_fun": [[101, 104], ["None"], "function", ["None"], ["", "def", "register_loss_fun", "(", "name", ",", "ctor", ")", ":", "\n", "    ", "\"\"\"Registers a loss function dynamically.\"\"\"", "\n", "_loss_funs", "[", "name", "]", "=", "ctor", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer": [[15, 66], ["model.parameters", "torch.optim.SGD", "model.parameters", "torch.optim.Adam", "model.named_parameters", "model.named_parameters", "model.parameters"], "function", ["None"], ["def", "construct_optimizer", "(", "cfg", ",", "model", ")", ":", "\n", "    ", "\"\"\"Constructs the optimizer.\n\n    Note that the momentum update in PyTorch differs from the one in Caffe2.\n    In particular,\n\n        Caffe2:\n            V := mu * V + lr * g\n            p := p - V\n\n        PyTorch:\n            V := mu * V + g\n            p := p - lr * V\n\n    where V is the velocity, mu is the momentum factor, lr is the learning rate,\n    g is the gradient and p are the parameters.\n\n    Since V is defined independently of the learning rate in PyTorch,\n    when the learning rate is changed there is no need to perform the\n    momentum correction by scaling V (unlike in the Caffe2 case).\n    \"\"\"", "\n", "if", "cfg", ".", "BN", ".", "USE_CUSTOM_WEIGHT_DECAY", ":", "\n", "# Apply different weight decay to Batchnorm and non-batchnorm parameters.", "\n", "        ", "p_bn", "=", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "\"bn\"", "in", "n", "]", "\n", "p_non_bn", "=", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "\"bn\"", "not", "in", "n", "]", "\n", "optim_params", "=", "[", "\n", "{", "\"params\"", ":", "p_bn", ",", "\"weight_decay\"", ":", "cfg", ".", "BN", ".", "CUSTOM_WEIGHT_DECAY", "}", ",", "\n", "{", "\"params\"", ":", "p_non_bn", ",", "\"weight_decay\"", ":", "cfg", ".", "OPTIM", ".", "WEIGHT_DECAY", "}", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "optim_params", "=", "model", ".", "parameters", "(", ")", "\n", "\n", "", "if", "cfg", ".", "OPTIM", ".", "TYPE", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "cfg", ".", "OPTIM", ".", "BASE_LR", ",", "\n", "momentum", "=", "cfg", ".", "OPTIM", ".", "MOMENTUM", ",", "\n", "weight_decay", "=", "cfg", ".", "OPTIM", ".", "WEIGHT_DECAY", ",", "\n", "dampening", "=", "cfg", ".", "OPTIM", ".", "DAMPENING", ",", "\n", "nesterov", "=", "cfg", ".", "OPTIM", ".", "NESTEROV", "\n", ")", "\n", "", "elif", "cfg", ".", "OPTIM", ".", "TYPE", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "cfg", ".", "OPTIM", ".", "BASE_LR", ",", "\n", "weight_decay", "=", "cfg", ".", "OPTIM", ".", "WEIGHT_DECAY", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.lr_fun_steps": [[68, 72], ["enumerate"], "function", ["None"], ["", "def", "lr_fun_steps", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Steps schedule (cfg.OPTIM.LR_POLICY = 'steps').\"\"\"", "\n", "ind", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "cfg", ".", "OPTIM", ".", "STEPS", ")", "if", "cur_epoch", ">=", "s", "]", "[", "-", "1", "]", "\n", "return", "cfg", ".", "OPTIM", ".", "LR_MULT", "**", "ind", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.lr_fun_exp": [[74, 77], ["None"], "function", ["None"], ["", "def", "lr_fun_exp", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Exponential schedule (cfg.OPTIM.LR_POLICY = 'exp').\"\"\"", "\n", "return", "cfg", ".", "OPTIM", ".", "MIN_LR", "**", "(", "cur_epoch", "/", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.lr_fun_cos": [[79, 83], ["numpy.cos"], "function", ["None"], ["", "def", "lr_fun_cos", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Cosine schedule (cfg.OPTIM.LR_POLICY = 'cos').\"\"\"", "\n", "lr", "=", "0.5", "*", "(", "1.0", "+", "np", ".", "cos", "(", "np", ".", "pi", "*", "cur_epoch", "/", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ")", "\n", "return", "(", "1.0", "-", "cfg", ".", "OPTIM", ".", "MIN_LR", ")", "*", "lr", "+", "cfg", ".", "OPTIM", ".", "MIN_LR", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.lr_fun_lin": [[85, 89], ["None"], "function", ["None"], ["", "def", "lr_fun_lin", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Linear schedule (cfg.OPTIM.LR_POLICY = 'lin').\"\"\"", "\n", "lr", "=", "1.0", "-", "cur_epoch", "/", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", "return", "(", "1.0", "-", "cfg", ".", "OPTIM", ".", "MIN_LR", ")", "*", "lr", "+", "cfg", ".", "OPTIM", ".", "MIN_LR", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.lr_fun_none": [[91, 94], ["None"], "function", ["None"], ["", "def", "lr_fun_none", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"No schedule (cfg.OPTIM.LR_POLICY = 'none').\"\"\"", "\n", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_lr_fun": [[96, 103], ["globals", "globals"], "function", ["None"], ["", "def", "get_lr_fun", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"Retrieves the specified lr policy function\"\"\"", "\n", "lr_fun", "=", "\"lr_fun_\"", "+", "cfg", ".", "OPTIM", ".", "LR_POLICY", "\n", "assert", "lr_fun", "in", "globals", "(", ")", ",", "\"Unknown LR policy: \"", "+", "cfg", ".", "OPTIM", ".", "LR_POLICY", "\n", "err_str", "=", "\"exp lr policy requires OPTIM.MIN_LR to be greater than 0.\"", "\n", "assert", "cfg", ".", "OPTIM", ".", "LR_POLICY", "!=", "\"exp\"", "or", "cfg", ".", "OPTIM", ".", "MIN_LR", ">", "0", ",", "err_str", "\n", "return", "globals", "(", ")", "[", "lr_fun", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr": [[105, 115], ["optimizer.get_lr_fun"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_lr_fun"], ["", "def", "get_epoch_lr", "(", "cfg", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Retrieves the lr for the given epoch according to the policy.\"\"\"", "\n", "# Get lr and scale by by BASE_LR", "\n", "lr", "=", "get_lr_fun", "(", "cfg", ")", "(", "cfg", ",", "cur_epoch", ")", "*", "cfg", ".", "OPTIM", ".", "BASE_LR", "\n", "# Linear warmup", "\n", "if", "cur_epoch", "<", "cfg", ".", "OPTIM", ".", "WARMUP_EPOCHS", "and", "'none'", "not", "in", "cfg", ".", "OPTIM", ".", "LR_POLICY", ":", "\n", "        ", "alpha", "=", "cur_epoch", "/", "cfg", ".", "OPTIM", ".", "WARMUP_EPOCHS", "\n", "warmup_factor", "=", "cfg", ".", "OPTIM", ".", "WARMUP_FACTOR", "*", "(", "1.0", "-", "alpha", ")", "+", "alpha", "\n", "lr", "*=", "warmup_factor", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.set_lr": [[117, 121], ["None"], "function", ["None"], ["", "def", "set_lr", "(", "optimizer", ",", "new_lr", ")", ":", "\n", "    ", "\"\"\"Sets the optimizer lr to the specified value.\"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "\"lr\"", "]", "=", "new_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.plot_lr_fun": [[123, 133], ["list", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylim", "matplotlib.show", "range", "optimizer.get_epoch_lr"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr"], ["", "", "def", "plot_lr_fun", "(", ")", ":", "\n", "    ", "\"\"\"Visualizes lr function.\"\"\"", "\n", "epochs", "=", "list", "(", "range", "(", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ")", "\n", "lrs", "=", "[", "get_epoch_lr", "(", "epoch", ")", "for", "epoch", "in", "epochs", "]", "\n", "plt", ".", "plot", "(", "epochs", ",", "lrs", ",", "\".-\"", ")", "\n", "plt", ".", "title", "(", "\"lr_policy: {}\"", ".", "format", "(", "cfg", ".", "OPTIM", ".", "LR_POLICY", ")", ")", "\n", "plt", ".", "xlabel", "(", "\"epochs\"", ")", "\n", "plt", ".", "ylabel", "(", "\"learning rate\"", ")", "\n", "plt", ".", "ylim", "(", "bottom", "=", "0", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun": [[12, 17], ["_loss_funs.keys"], "function", ["None"], ["def", "get_loss_fun", "(", ")", ":", "\n", "    ", "\"\"\"Retrieves the loss function.\"\"\"", "\n", "assert", "cfg", ".", "MODEL", ".", "LOSS_FUN", "in", "_loss_funs", ".", "keys", "(", ")", ",", "'Loss function \\'{}\\' not supported'", ".", "format", "(", "cfg", ".", "TRAIN", ".", "LOSS", ")", "\n", "return", "_loss_funs", "[", "cfg", ".", "MODEL", ".", "LOSS_FUN", "]", "(", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.register_loss_fun": [[19, 22], ["None"], "function", ["None"], ["", "def", "register_loss_fun", "(", "name", ",", "ctor", ")", ":", "\n", "    ", "\"\"\"Registers a loss function dynamically.\"\"\"", "\n", "_loss_funs", "[", "name", "]", "=", "ctor", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.ActiveLearning.ActiveLearning.__init__": [[15, 19], ["Sampling.Sampling.Sampling"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataObj", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "dataObj", "=", "dataObj", "\n", "self", ".", "sampler", "=", "Sampling", "(", "dataObj", "=", "dataObj", ",", "cfg", "=", "cfg", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.ActiveLearning.ActiveLearning.sample_from_uSet": [[20, 112], ["len", "len", "ActiveLearning.ActiveLearning.sampler.random", "clf_model.eval", "ActiveLearning.ActiveLearning.sampler.uncertainty", "clf_model.train", "clf_model.eval", "ActiveLearning.ActiveLearning.sampler.entropy", "clf_model.train", "clf_model.eval", "ActiveLearning.ActiveLearning.sampler.margin", "clf_model.train", "clf_model.eval", "Sampling.Sampling.CoreSetMIPSampling", "Sampling.Sampling.CoreSetMIPSampling.query", "clf_model.train", "ActiveLearning.ActiveLearning.cfg.ACTIVE_LEARNING.SAMPLING_FN.startswith", "ActiveLearning.ActiveLearning.cfg.ACTIVE_LEARNING.SAMPLING_FN.endswith", "TypiClust", "ProbCover.select_samples", "ActiveLearning.ActiveLearning.cfg.ACTIVE_LEARNING.SAMPLING_FN.lower", "ProbCover", "ProbCover.select_samples", "ActiveLearning.ActiveLearning.sampler.dbal", "ActiveLearning.ActiveLearning.sampler.bald", "ActiveLearning.ActiveLearning.sampler.ensemble_var_R", "Sampling.Sampling.AdversarySampler", "Sampling.Sampling.AdversarySampler.vaal_perform_training", "Sampling.Sampling.AdversarySampler.sample_for_labeling", "print"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.uncertainty", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.entropy", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.margin", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.query", "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.select_samples", "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.select_samples", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.dbal", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.bald", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.ensemble_var_R", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.vaal_perform_training", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.sample_for_labeling"], ["", "def", "sample_from_uSet", "(", "self", ",", "clf_model", ",", "lSet", ",", "uSet", ",", "trainDataset", ",", "supportingModels", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Sample from uSet using cfg.ACTIVE_LEARNING.SAMPLING_FN.\n\n        INPUT\n        ------\n        clf_model: Reference of task classifier model class [Typically VGG]\n\n        supportingModels: List of models which are used for sampling process.\n\n        OUTPUT\n        -------\n        Returns activeSet, uSet\n        \"\"\"", "\n", "assert", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ">", "0", ",", "\"Expected a positive budgetSize\"", "\n", "assert", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", "<", "len", "(", "uSet", ")", ",", "\"BudgetSet cannot exceed length of unlabelled set. Length of unlabelled set: {} and budgetSize: {}\"", ".", "format", "(", "len", "(", "uSet", ")", ",", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ")", "\n", "\n", "if", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"random\"", ":", "\n", "\n", "            ", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "random", "(", "uSet", "=", "uSet", ",", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"uncertainty\"", ":", "\n", "            ", "oldmode", "=", "clf_model", ".", "training", "\n", "clf_model", ".", "eval", "(", ")", "\n", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "uncertainty", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "lSet", "=", "lSet", ",", "uSet", "=", "uSet", ",", "model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "clf_model", ".", "train", "(", "oldmode", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"entropy\"", ":", "\n", "            ", "oldmode", "=", "clf_model", ".", "training", "\n", "clf_model", ".", "eval", "(", ")", "\n", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "entropy", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "lSet", "=", "lSet", ",", "uSet", "=", "uSet", ",", "model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "clf_model", ".", "train", "(", "oldmode", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"margin\"", ":", "\n", "            ", "oldmode", "=", "clf_model", ".", "training", "\n", "clf_model", ".", "eval", "(", ")", "\n", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "margin", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "lSet", "=", "lSet", ",", "uSet", "=", "uSet", ",", "model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "clf_model", ".", "train", "(", "oldmode", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"coreset\"", ":", "\n", "            ", "waslatent", "=", "clf_model", ".", "penultimate_active", "\n", "wastrain", "=", "clf_model", ".", "training", "\n", "clf_model", ".", "penultimate_active", "=", "True", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     clf_model.cuda(0)", "\n", "clf_model", ".", "eval", "(", ")", "\n", "coreSetSampler", "=", "CoreSetMIPSampling", "(", "cfg", "=", "self", ".", "cfg", ",", "dataObj", "=", "self", ".", "dataObj", ")", "\n", "activeSet", ",", "uSet", "=", "coreSetSampler", ".", "query", "(", "lSet", "=", "lSet", ",", "uSet", "=", "uSet", ",", "clf_model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "\n", "clf_model", ".", "penultimate_active", "=", "waslatent", "\n", "clf_model", ".", "train", "(", "wastrain", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ".", "startswith", "(", "\"typiclust\"", ")", ":", "\n", "            ", "from", ".", "typiclust", "import", "TypiClust", "\n", "is_scan", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ".", "endswith", "(", "'dc'", ")", "\n", "tpc", "=", "TypiClust", "(", "self", ".", "cfg", ",", "lSet", ",", "uSet", ",", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "is_scan", "=", "is_scan", ")", "\n", "activeSet", ",", "uSet", "=", "tpc", ".", "select_samples", "(", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ".", "lower", "(", ")", "in", "[", "\"prob_cover\"", ",", "'probcover'", "]", ":", "\n", "            ", "from", ".", "prob_cover", "import", "ProbCover", "\n", "tpc", "=", "ProbCover", "(", "self", ".", "cfg", ",", "lSet", ",", "uSet", ",", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "\n", "delta", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DELTA", ")", "\n", "activeSet", ",", "uSet", "=", "tpc", ".", "select_samples", "(", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"dbal\"", "or", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"DBAL\"", ":", "\n", "            ", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "dbal", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "uSet", "=", "uSet", ",", "clf_model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"bald\"", "or", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"BALD\"", ":", "\n", "            ", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "bald", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "uSet", "=", "uSet", ",", "clf_model", "=", "clf_model", ",", "dataset", "=", "trainDataset", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"ensemble_var_R\"", ":", "\n", "            ", "activeSet", ",", "uSet", "=", "self", ".", "sampler", ".", "ensemble_var_R", "(", "budgetSize", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ",", "uSet", "=", "uSet", ",", "clf_models", "=", "supportingModels", ",", "dataset", "=", "trainDataset", ")", "\n", "\n", "", "elif", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", "==", "\"vaal\"", ":", "\n", "            ", "adv_sampler", "=", "AdversarySampler", "(", "cfg", "=", "self", ".", "cfg", ",", "dataObj", "=", "self", ".", "dataObj", ")", "\n", "\n", "# Train VAE and discriminator first", "\n", "vae", ",", "disc", ",", "uSet_loader", "=", "adv_sampler", ".", "vaal_perform_training", "(", "lSet", "=", "lSet", ",", "uSet", "=", "uSet", ",", "dataset", "=", "trainDataset", ")", "\n", "\n", "# Do active sampling", "\n", "activeSet", ",", "uSet", "=", "adv_sampler", ".", "sample_for_labeling", "(", "vae", "=", "vae", ",", "discriminator", "=", "disc", ",", "unlabeled_dataloader", "=", "uSet_loader", ",", "uSet", "=", "uSet", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"{self.cfg.ACTIVE_LEARNING.SAMPLING_FN} is either not implemented or there is some spelling mistake.\"", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "", "return", "activeSet", ",", "uSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.TypiClust.__init__": [[48, 58], ["typiclust.TypiClust.init_features_and_clusters"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.TypiClust.init_features_and_clusters"], ["def", "__init__", "(", "self", ",", "cfg", ",", "lSet", ",", "uSet", ",", "budgetSize", ",", "is_scan", "=", "False", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "ds_name", "=", "self", ".", "cfg", "[", "'DATASET'", "]", "[", "'NAME'", "]", "\n", "self", ".", "seed", "=", "self", ".", "cfg", "[", "'RNG_SEED'", "]", "\n", "self", ".", "features", "=", "None", "\n", "self", ".", "clusters", "=", "None", "\n", "self", ".", "lSet", "=", "lSet", "\n", "self", ".", "uSet", "=", "uSet", "\n", "self", ".", "budgetSize", "=", "budgetSize", "\n", "self", ".", "init_features_and_clusters", "(", "is_scan", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.TypiClust.init_features_and_clusters": [[59, 82], ["min", "print", "print", "numpy.load", "numpy.load().argmax", "numpy.load", "typiclust.kmeans", "len", "numpy.load", "fname.replace"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.kmeans"], ["", "def", "init_features_and_clusters", "(", "self", ",", "is_scan", ")", ":", "\n", "        ", "num_clusters", "=", "min", "(", "len", "(", "self", ".", "lSet", ")", "+", "self", ".", "budgetSize", ",", "self", ".", "MAX_NUM_CLUSTERS", ")", "\n", "print", "(", "f'Clustering into {num_clusters} clustering. Scan clustering: {is_scan}'", ")", "\n", "if", "is_scan", ":", "\n", "            ", "fname_dict", "=", "{", "'CIFAR10'", ":", "f'../../scan/results/cifar-10/scan/features_seed{self.seed}_clusters{num_clusters}.npy'", ",", "\n", "'CIFAR100'", ":", "f'../../scan/results/cifar-100/scan/features_seed{self.seed}_clusters{num_clusters}.npy'", ",", "\n", "'TINYIMAGENET'", ":", "f'../../scan/results/tiny-imagenet/scan/features_seed{self.seed}_clusters{num_clusters}.npy'", ",", "\n", "}", "\n", "fname", "=", "fname_dict", "[", "self", ".", "ds_name", "]", "\n", "self", ".", "features", "=", "np", ".", "load", "(", "fname", ")", "\n", "self", ".", "clusters", "=", "np", ".", "load", "(", "fname", ".", "replace", "(", "'features'", ",", "'probs'", ")", ")", ".", "argmax", "(", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "fname_dict", "=", "{", "'CIFAR10'", ":", "f'../../scan/results/cifar-10/pretext/features_seed{self.seed}.npy'", ",", "\n", "'CIFAR100'", ":", "f'../../scan/results/cifar-100/pretext/features_seed{self.seed}.npy'", ",", "\n", "'TINYIMAGENET'", ":", "f'../../scan/results/tiny-imagenet/pretext/features_seed{self.seed}.npy'", ",", "\n", "'IMAGENET50'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "'IMAGENET100'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "'IMAGENET200'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "}", "\n", "fname", "=", "fname_dict", "[", "self", ".", "ds_name", "]", "\n", "self", ".", "features", "=", "np", ".", "load", "(", "fname", ")", "\n", "self", ".", "clusters", "=", "kmeans", "(", "self", ".", "features", ",", "num_clusters", "=", "num_clusters", ")", "\n", "", "print", "(", "f'Finished clustering into {num_clusters} clusters.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.TypiClust.select_samples": [[83, 121], ["numpy.concatenate().astype", "numpy.copy", "numpy.arange", "numpy.unique", "numpy.bincount", "pandas.DataFrame", "clusters_df.sort_values.sort_values.sort_values", "range", "numpy.array", "numpy.array", "print", "print", "len", "typiclust.calculate_typicality", "numpy.array.append", "len", "len", "sorted", "numpy.concatenate", "len", "min", "numpy.intersect1d", "list", "calculate_typicality.argmax", "len", "len", "set", "set", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.calculate_typicality"], ["", "def", "select_samples", "(", "self", ",", ")", ":", "\n", "# using only labeled+unlabeled indices, without validation set.", "\n", "        ", "relevant_indices", "=", "np", ".", "concatenate", "(", "[", "self", ".", "lSet", ",", "self", ".", "uSet", "]", ")", ".", "astype", "(", "int", ")", "\n", "features", "=", "self", ".", "features", "[", "relevant_indices", "]", "\n", "labels", "=", "np", ".", "copy", "(", "self", ".", "clusters", "[", "relevant_indices", "]", ")", "\n", "existing_indices", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "lSet", ")", ")", "\n", "# counting cluster sizes and number of labeled samples per cluster", "\n", "cluster_ids", ",", "cluster_sizes", "=", "np", ".", "unique", "(", "labels", ",", "return_counts", "=", "True", ")", "\n", "cluster_labeled_counts", "=", "np", ".", "bincount", "(", "labels", "[", "existing_indices", "]", ",", "minlength", "=", "len", "(", "cluster_ids", ")", ")", "\n", "clusters_df", "=", "pd", ".", "DataFrame", "(", "{", "'cluster_id'", ":", "cluster_ids", ",", "'cluster_size'", ":", "cluster_sizes", ",", "'existing_count'", ":", "cluster_labeled_counts", ",", "\n", "'neg_cluster_size'", ":", "-", "1", "*", "cluster_sizes", "}", ")", "\n", "# drop too small clusters", "\n", "clusters_df", "=", "clusters_df", "[", "clusters_df", ".", "cluster_size", ">", "self", ".", "MIN_CLUSTER_SIZE", "]", "\n", "# sort clusters by lowest number of existing samples, and then by cluster sizes (large to small)", "\n", "clusters_df", "=", "clusters_df", ".", "sort_values", "(", "[", "'existing_count'", ",", "'neg_cluster_size'", "]", ")", "\n", "labels", "[", "existing_indices", "]", "=", "-", "1", "\n", "\n", "selected", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "budgetSize", ")", ":", "\n", "            ", "cluster", "=", "clusters_df", ".", "iloc", "[", "i", "%", "len", "(", "clusters_df", ")", "]", ".", "cluster_id", "\n", "indices", "=", "(", "labels", "==", "cluster", ")", ".", "nonzero", "(", ")", "[", "0", "]", "\n", "rel_feats", "=", "features", "[", "indices", "]", "\n", "# in case we have too small cluster, calculate density among half of the cluster", "\n", "typicality", "=", "calculate_typicality", "(", "rel_feats", ",", "min", "(", "self", ".", "K_NN", ",", "len", "(", "indices", ")", "//", "2", ")", ")", "\n", "idx", "=", "indices", "[", "typicality", ".", "argmax", "(", ")", "]", "\n", "selected", ".", "append", "(", "idx", ")", "\n", "labels", "[", "idx", "]", "=", "-", "1", "\n", "\n", "", "selected", "=", "np", ".", "array", "(", "selected", ")", "\n", "assert", "len", "(", "selected", ")", "==", "self", ".", "budgetSize", ",", "'added a different number of samples'", "\n", "assert", "len", "(", "np", ".", "intersect1d", "(", "selected", ",", "existing_indices", ")", ")", "==", "0", ",", "'should be new samples'", "\n", "activeSet", "=", "relevant_indices", "[", "selected", "]", "\n", "remainSet", "=", "np", ".", "array", "(", "sorted", "(", "list", "(", "set", "(", "self", ".", "uSet", ")", "-", "set", "(", "activeSet", ")", ")", ")", ")", "\n", "\n", "print", "(", "f'Finished the selection of {len(activeSet)} samples.'", ")", "\n", "print", "(", "f'Active set is {activeSet}'", ")", "\n", "return", "activeSet", ",", "remainSet", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.get_nn": [[6, 16], ["features.astype.astype", "faiss.IndexFlatL2", "faiss.index_cpu_to_all_gpus", "faiss.index_cpu_to_all_gpus.add", "faiss.index_cpu_to_all_gpus.search"], "function", ["None"], ["def", "get_nn", "(", "features", ",", "num_neighbors", ")", ":", "\n", "# calculates nearest neighbors on GPU", "\n", "    ", "d", "=", "features", ".", "shape", "[", "1", "]", "\n", "features", "=", "features", ".", "astype", "(", "np", ".", "float32", ")", "\n", "cpu_index", "=", "faiss", ".", "IndexFlatL2", "(", "d", ")", "\n", "gpu_index", "=", "faiss", ".", "index_cpu_to_all_gpus", "(", "cpu_index", ")", "\n", "gpu_index", ".", "add", "(", "features", ")", "# add vectors to the index", "\n", "distances", ",", "indices", "=", "gpu_index", ".", "search", "(", "features", ",", "num_neighbors", "+", "1", ")", "\n", "# 0 index is the same sample, dropping it", "\n", "return", "distances", "[", ":", ",", "1", ":", "]", ",", "indices", "[", ":", ",", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.get_mean_nn_dist": [[18, 24], ["typiclust.get_nn", "distances.mean"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.get_nn"], ["", "def", "get_mean_nn_dist", "(", "features", ",", "num_neighbors", ",", "return_indices", "=", "False", ")", ":", "\n", "    ", "distances", ",", "indices", "=", "get_nn", "(", "features", ",", "num_neighbors", ")", "\n", "mean_distance", "=", "distances", ".", "mean", "(", "axis", "=", "1", ")", "\n", "if", "return_indices", ":", "\n", "        ", "return", "mean_distance", ",", "indices", "\n", "", "return", "mean_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.calculate_typicality": [[26, 31], ["typiclust.get_mean_nn_dist"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.get_mean_nn_dist"], ["", "def", "calculate_typicality", "(", "features", ",", "num_neighbors", ")", ":", "\n", "    ", "mean_distance", "=", "get_mean_nn_dist", "(", "features", ",", "num_neighbors", ")", "\n", "# low distance to NN is high density", "\n", "typicality", "=", "1", "/", "(", "mean_distance", "+", "1e-5", ")", "\n", "return", "typicality", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.typiclust.kmeans": [[33, 41], ["sklearn.cluster.KMeans", "sklearn.cluster.MiniBatchKMeans.fit_predict", "sklearn.cluster.MiniBatchKMeans", "sklearn.cluster.MiniBatchKMeans.fit_predict"], "function", ["None"], ["", "def", "kmeans", "(", "features", ",", "num_clusters", ")", ":", "\n", "    ", "if", "num_clusters", "<=", "50", ":", "\n", "        ", "km", "=", "KMeans", "(", "n_clusters", "=", "num_clusters", ")", "\n", "km", ".", "fit_predict", "(", "features", ")", "\n", "", "else", ":", "\n", "        ", "km", "=", "MiniBatchKMeans", "(", "n_clusters", "=", "num_clusters", ",", "batch_size", "=", "5000", ")", "\n", "km", ".", "fit_predict", "(", "features", ")", "\n", "", "return", "km", ".", "labels_", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.EntropyLoss.__init__": [[28, 30], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "EntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.EntropyLoss.forward": [[31, 40], ["entropy.sum", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.log2", "torch.log2", "torch.log2", "torch.log2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "applySoftMax", "=", "True", ")", ":", "\n", "#Assuming x : [BatchSize, ]", "\n", "\n", "        ", "if", "applySoftMax", ":", "\n", "            ", "entropy", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "entropy", "=", "x", "*", "torch", ".", "log2", "(", "x", ")", "\n", "", "entropy", "=", "-", "1", "*", "entropy", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.__init__": [[46, 51], ["torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cfg", ",", "dataObj", ",", "isMIP", "=", "False", ")", ":", "\n", "        ", "self", ".", "dataObj", "=", "dataObj", "\n", "self", ".", "cuda_id", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "isMIP", "=", "isMIP", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.get_representation": [[52, 76], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "clf_model.cuda", "Sampling.CoreSetMIPSampling.dataObj.getSequentialDataLoader", "print", "enumerate", "numpy.concatenate", "tqdm.tqdm.tqdm", "int", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x.type.type.cuda", "x.type.type.type", "clf_model", "numpy.concatenate.append", "len", "temp_z.cpu().numpy", "temp_z.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_representation", "(", "self", ",", "clf_model", ",", "idx_set", ",", "dataset", ")", ":", "\n", "\n", "        ", "clf_model", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     print(\"Loading the model in data parallel where num_GPUS: {}\".format(self.cfg.NUM_GPUS))", "\n", "#     clf_model = torch.nn.DataParallel(clf_model, device_ids = [i for i in range(self.cfg.NUM_GPUS)])", "\n", "\n", "#     tempIdxSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=idx_set, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "tempIdxSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "idx_set", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "features", "=", "[", "]", "\n", "\n", "print", "(", "f\"len(dataLoader): {len(tempIdxSetLoader)}\"", ")", "\n", "\n", "for", "i", ",", "(", "x", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "tempIdxSetLoader", ",", "desc", "=", "\"Extracting Representations\"", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x", "=", "x", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "x", "=", "x", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "temp_z", ",", "_", "=", "clf_model", "(", "x", ")", "\n", "features", ".", "append", "(", "temp_z", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "features", "=", "np", ".", "concatenate", "(", "features", ",", "axis", "=", "0", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.gpu_compute_dists": [[77, 93], ["torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["None"], ["", "def", "gpu_compute_dists", "(", "self", ",", "M1", ",", "M2", ")", ":", "\n", "        ", "\"\"\"\n        Computes L2 norm square on gpu\n        Assume \n        M1: M x D matrix\n        M2: N x D matrix\n\n        output: M x N matrix\n        \"\"\"", "\n", "#print(f\"Function call to gpu_compute dists; M1: {M1.shape} and M2: {M2.shape}\")", "\n", "M1_norm", "=", "(", "M1", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "M2_t", "=", "torch", ".", "transpose", "(", "M2", ",", "0", ",", "1", ")", "\n", "M2_norm", "=", "(", "M2", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "dists", "=", "M1_norm", "+", "M2_norm", "-", "2.0", "*", "torch", ".", "mm", "(", "M1", ",", "M2_t", ")", "\n", "return", "dists", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.compute_dists": [[94, 97], ["numpy.sum().reshape", "numpy.sum", "numpy.dot", "numpy.sum"], "methods", ["None"], ["", "def", "compute_dists", "(", "self", ",", "X", ",", "X_train", ")", ":", "\n", "        ", "dists", "=", "-", "2", "*", "np", ".", "dot", "(", "X", ",", "X_train", ".", "T", ")", "+", "np", ".", "sum", "(", "X_train", "**", "2", ",", "axis", "=", "1", ")", "+", "np", ".", "sum", "(", "X", "**", "2", ",", "axis", "=", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "return", "dists", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.optimal_greedy_k_center": [[98, 124], ["numpy.arange", "numpy.vstack", "print", "time.time", "Sampling.CoreSetMIPSampling.compute_dists", "time.time", "print", "range", "numpy.array", "numpy.arange", "numpy.array", "numpy.min", "numpy.argmax", "greedy_indices.append", "set", "list", "print", "numpy.append", "set", "set", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists"], ["", "def", "optimal_greedy_k_center", "(", "self", ",", "labeled", ",", "unlabeled", ")", ":", "\n", "        ", "n_lSet", "=", "labeled", ".", "shape", "[", "0", "]", "\n", "lSetIds", "=", "np", ".", "arange", "(", "n_lSet", ")", "\n", "n_uSet", "=", "unlabeled", ".", "shape", "[", "0", "]", "\n", "uSetIds", "=", "n_lSet", "+", "np", ".", "arange", "(", "n_uSet", ")", "\n", "\n", "#order is important", "\n", "features", "=", "np", ".", "vstack", "(", "(", "labeled", ",", "unlabeled", ")", ")", "\n", "print", "(", "\"Started computing distance matrix of {}x{}\"", ".", "format", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "0", "]", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "distance_mat", "=", "self", ".", "compute_dists", "(", "features", ",", "features", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Distance matrix computed in {} seconds\"", ".", "format", "(", "end", "-", "start", ")", ")", "\n", "greedy_indices", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ")", ":", "\n", "            ", "if", "i", "!=", "0", "and", "i", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "\"Sampled {} samples\"", ".", "format", "(", "i", ")", ")", "\n", "", "lab_temp_indexes", "=", "np", ".", "array", "(", "np", ".", "append", "(", "lSetIds", ",", "greedy_indices", ")", ",", "dtype", "=", "int", ")", "\n", "min_dist", "=", "np", ".", "min", "(", "distance_mat", "[", "lab_temp_indexes", ",", "n_lSet", ":", "]", ",", "axis", "=", "0", ")", "\n", "active_index", "=", "np", ".", "argmax", "(", "min_dist", ")", "\n", "greedy_indices", ".", "append", "(", "n_lSet", "+", "active_index", ")", "\n", "\n", "", "remainSet", "=", "set", "(", "np", ".", "arange", "(", "features", ".", "shape", "[", "0", "]", ")", ")", "-", "set", "(", "greedy_indices", ")", "-", "set", "(", "lSetIds", ")", "\n", "remainSet", "=", "np", ".", "array", "(", "list", "(", "remainSet", ")", ")", "\n", "\n", "return", "greedy_indices", "-", "n_lSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.greedy_k_center": [[125, 177], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "print", "print", "time.time", "torch.min", "torch.min", "torch.min", "torch.min", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "print", "numpy.empty", "tqdm.tqdm.tqdm", "torch.max", "torch.max", "torch.max", "torch.max", "farthest.item", "tqdm.tqdm.tqdm", "numpy.array", "Sampling.CoreSetMIPSampling.gpu_compute_dists", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "range", "Sampling.CoreSetMIPSampling.gpu_compute_dists", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.min", "torch.min", "torch.min", "torch.min", "min_dist.reshape.reshape.reshape", "torch.max", "torch.max", "torch.max", "torch.max", "farthest.item", "set", "set", "list", "range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "labeled[].reshape", "Sampling.CoreSetMIPSampling.gpu_compute_dists", "Sampling.CoreSetMIPSampling.gpu_compute_dists", "torch.min", "torch.min", "torch.min", "torch.min", "unlabeled[].reshape", "numpy.arange", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "[].reshape", "Sampling.CoreSetMIPSampling.reshape", "numpy.max", "time.time", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists"], ["", "def", "greedy_k_center", "(", "self", ",", "labeled", ",", "unlabeled", ")", ":", "\n", "        ", "greedy_indices", "=", "[", "None", "for", "i", "in", "range", "(", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", ")", "]", "\n", "greedy_indices_counter", "=", "0", "\n", "#move cpu to gpu", "\n", "labeled", "=", "torch", ".", "from_numpy", "(", "labeled", ")", ".", "cuda", "(", "0", ")", "\n", "unlabeled", "=", "torch", ".", "from_numpy", "(", "unlabeled", ")", ".", "cuda", "(", "0", ")", "\n", "\n", "print", "(", "f\"[GPU] Labeled.shape: {labeled.shape}\"", ")", "\n", "print", "(", "f\"[GPU] Unlabeled.shape: {unlabeled.shape}\"", ")", "\n", "# get the minimum distances between the labeled and unlabeled examples (iteratively, to avoid memory issues):", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "min_dist", ",", "_", "=", "torch", ".", "min", "(", "self", ".", "gpu_compute_dists", "(", "labeled", "[", "0", ",", ":", "]", ".", "reshape", "(", "(", "1", ",", "labeled", ".", "shape", "[", "1", "]", ")", ")", ",", "unlabeled", ")", ",", "dim", "=", "0", ")", "\n", "min_dist", "=", "torch", ".", "reshape", "(", "min_dist", ",", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "print", "(", "f\"time taken: {time.time() - st} seconds\"", ")", "\n", "\n", "temp_range", "=", "500", "\n", "dist", "=", "np", ".", "empty", "(", "(", "temp_range", ",", "unlabeled", ".", "shape", "[", "0", "]", ")", ")", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "1", ",", "labeled", ".", "shape", "[", "0", "]", ",", "temp_range", ")", ",", "desc", "=", "\"Getting first farthest index\"", ")", ":", "\n", "            ", "if", "j", "+", "temp_range", "<", "labeled", ".", "shape", "[", "0", "]", ":", "\n", "                ", "dist", "=", "self", ".", "gpu_compute_dists", "(", "labeled", "[", "j", ":", "j", "+", "temp_range", ",", ":", "]", ",", "unlabeled", ")", "\n", "", "else", ":", "\n", "                ", "dist", "=", "self", ".", "gpu_compute_dists", "(", "labeled", "[", "j", ":", ",", ":", "]", ",", "unlabeled", ")", "\n", "\n", "", "min_dist", "=", "torch", ".", "cat", "(", "(", "min_dist", ",", "torch", ".", "min", "(", "dist", ",", "dim", "=", "0", ")", "[", "0", "]", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "1", "]", ")", ")", ")", ")", "\n", "\n", "min_dist", "=", "torch", ".", "min", "(", "min_dist", ",", "dim", "=", "0", ")", "[", "0", "]", "\n", "min_dist", "=", "torch", ".", "reshape", "(", "min_dist", ",", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "# iteratively insert the farthest index and recalculate the minimum distances:", "\n", "", "_", ",", "farthest", "=", "torch", ".", "max", "(", "min_dist", ",", "dim", "=", "1", ")", "\n", "greedy_indices", "[", "greedy_indices_counter", "]", "=", "farthest", ".", "item", "(", ")", "\n", "greedy_indices_counter", "+=", "1", "\n", "\n", "amount", "=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", "-", "1", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "amount", ")", ",", "desc", "=", "\"Constructing Active set\"", ")", ":", "\n", "            ", "dist", "=", "self", ".", "gpu_compute_dists", "(", "unlabeled", "[", "greedy_indices", "[", "greedy_indices_counter", "-", "1", "]", ",", ":", "]", ".", "reshape", "(", "(", "1", ",", "unlabeled", ".", "shape", "[", "1", "]", ")", ")", ",", "unlabeled", ")", "\n", "\n", "min_dist", "=", "torch", ".", "cat", "(", "(", "min_dist", ",", "dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "1", "]", ")", ")", ")", ")", "\n", "\n", "min_dist", ",", "_", "=", "torch", ".", "min", "(", "min_dist", ",", "dim", "=", "0", ")", "\n", "min_dist", "=", "min_dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "_", ",", "farthest", "=", "torch", ".", "max", "(", "min_dist", ",", "dim", "=", "1", ")", "\n", "greedy_indices", "[", "greedy_indices_counter", "]", "=", "farthest", ".", "item", "(", ")", "\n", "greedy_indices_counter", "+=", "1", "\n", "\n", "", "remainSet", "=", "set", "(", "np", ".", "arange", "(", "unlabeled", ".", "shape", "[", "0", "]", ")", ")", "-", "set", "(", "greedy_indices", ")", "\n", "remainSet", "=", "np", ".", "array", "(", "list", "(", "remainSet", ")", ")", "\n", "if", "self", ".", "isMIP", ":", "\n", "            ", "return", "greedy_indices", ",", "remainSet", ",", "math", ".", "sqrt", "(", "np", ".", "max", "(", "min_dist", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "greedy_indices", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.query": [[178, 203], ["print", "Sampling.CoreSetMIPSampling.get_representation", "print", "Sampling.CoreSetMIPSampling.get_representation", "print", "print", "print", "time.time", "Sampling.CoreSetMIPSampling.greedy_k_center", "time.time", "print"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.get_representation", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.CoreSetMIPSampling.get_representation", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.greedy_k_center"], ["", "", "def", "query", "(", "self", ",", "lSet", ",", "uSet", ",", "clf_model", ",", "dataset", ")", ":", "\n", "\n", "        ", "assert", "clf_model", ".", "training", "==", "False", ",", "\"Classification model expected in training mode\"", "\n", "assert", "clf_model", ".", "penultimate_active", "==", "True", ",", "\"Classification model is expected in penultimate mode\"", "\n", "\n", "print", "(", "\"Extracting Lset Representations\"", ")", "\n", "lb_repr", "=", "self", ".", "get_representation", "(", "clf_model", "=", "clf_model", ",", "idx_set", "=", "lSet", ",", "dataset", "=", "dataset", ")", "\n", "print", "(", "\"Extracting Uset Representations\"", ")", "\n", "ul_repr", "=", "self", ".", "get_representation", "(", "clf_model", "=", "clf_model", ",", "idx_set", "=", "uSet", ",", "dataset", "=", "dataset", ")", "\n", "\n", "print", "(", "\"lb_repr.shape: \"", ",", "lb_repr", ".", "shape", ")", "\n", "print", "(", "\"ul_repr.shape: \"", ",", "ul_repr", ".", "shape", ")", "\n", "\n", "if", "self", ".", "isMIP", "==", "True", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Solving K Center Greedy Approach\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "greedy_indexes", ",", "remainSet", "=", "self", ".", "greedy_k_center", "(", "labeled", "=", "lb_repr", ",", "unlabeled", "=", "ul_repr", ")", "\n", "# greedy_indexes, remainSet = self.optimal_greedy_k_center(labeled=lb_repr, unlabeled=ul_repr)", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Time taken to solve K center: {} seconds\"", ".", "format", "(", "end", "-", "start", ")", ")", "\n", "activeSet", "=", "uSet", "[", "greedy_indexes", "]", "\n", "remainSet", "=", "uSet", "[", "remainSet", "]", "\n", "", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.__init__": [[211, 215], ["cfg.ACTIVE_LEARNING.SAMPLING_FN.startswith", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataObj", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "cuda_id", "=", "0", "if", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ".", "startswith", "(", "\"ensemble\"", ")", "else", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "self", ".", "dataObj", "=", "dataObj", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.gpu_compute_dists": [[216, 231], ["torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["None"], ["", "def", "gpu_compute_dists", "(", "self", ",", "M1", ",", "M2", ")", ":", "\n", "        ", "\"\"\"\n        Computes L2 norm square on gpu\n        Assume \n        M1: M x D matrix\n        M2: N x D matrix\n\n        output: M x N matrix\n        \"\"\"", "\n", "M1_norm", "=", "(", "M1", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "M2_t", "=", "torch", ".", "transpose", "(", "M2", ",", "0", ",", "1", ")", "\n", "M2_norm", "=", "(", "M2", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "dists", "=", "M1_norm", "+", "M2_norm", "-", "2.0", "*", "torch", ".", "mm", "(", "M1", ",", "M2_t", ")", "\n", "return", "dists", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.get_predictions": [[232, 256], ["clf_model.cuda", "Sampling.Sampling.dataObj.getSequentialDataLoader", "enumerate", "numpy.concatenate", "tqdm.tqdm.tqdm", "int", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x.type.type.cuda", "x.type.type.type", "clf_model", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "numpy.concatenate.append", "torch.nn.functional.softmax.cpu().numpy", "torch.nn.functional.softmax.cpu().numpy", "torch.nn.functional.softmax.cpu", "torch.nn.functional.softmax.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "get_predictions", "(", "self", ",", "clf_model", ",", "idx_set", ",", "dataset", ")", ":", "\n", "\n", "        ", "clf_model", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "#Used by bald acquisition", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     tempIdxSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=idx_set, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "tempIdxSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "idx_set", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "tempIdxSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "preds", "=", "[", "]", "\n", "for", "i", ",", "(", "x", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "tempIdxSetLoader", ",", "desc", "=", "\"Collecting predictions in get_predictions function\"", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x", "=", "x", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "x", "=", "x", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "\n", "temp_pred", "=", "clf_model", "(", "x", ")", "\n", "\n", "#To get probabilities", "\n", "temp_pred", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "temp_pred", ",", "dim", "=", "1", ")", "\n", "preds", ".", "append", "(", "temp_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "preds", "=", "np", ".", "concatenate", "(", "preds", ",", "axis", "=", "0", ")", "\n", "tempIdxSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random": [[258, 290], ["numpy.random.seed", "isinstance", "isinstance", "numpy.random.shuffle", "type", "type", "len", "len", "range", "len"], "methods", ["None"], ["", "def", "random", "(", "self", ",", "uSet", ",", "budgetSize", ")", ":", "\n", "        ", "\"\"\"\n        Chooses <budgetSize> number of data points randomly from uSet.\n        \n        NOTE: The returned uSet is modified such that it does not contain active datapoints.\n\n        INPUT\n        ------\n\n        uSet: np.ndarray, It describes the index set of unlabelled set.\n\n        budgetSize: int, The number of active data points to be chosen for active learning.\n\n        OUTPUT\n        -------\n\n        Returns activeSet, uSet   \n        \"\"\"", "\n", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "assert", "isinstance", "(", "uSet", ",", "np", ".", "ndarray", ")", ",", "\"Expected uSet of type np.ndarray whereas provided is dtype:{}\"", ".", "format", "(", "type", "(", "uSet", ")", ")", "\n", "assert", "isinstance", "(", "budgetSize", ",", "int", ")", ",", "\"Expected budgetSize of type int whereas provided is dtype:{}\"", ".", "format", "(", "type", "(", "budgetSize", ")", ")", "\n", "assert", "budgetSize", ">", "0", ",", "\"Expected a positive budgetSize\"", "\n", "assert", "budgetSize", "<", "len", "(", "uSet", ")", ",", "\"BudgetSet cannot exceed length of unlabelled set. Length of unlabelled set: {} and budgetSize: {}\"", ".", "format", "(", "len", "(", "uSet", ")", ",", "budgetSize", ")", "\n", "\n", "tempIdx", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "uSet", ")", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "tempIdx", ")", "\n", "activeSet", "=", "uSet", "[", "tempIdx", "[", "0", ":", "budgetSize", "]", "]", "\n", "uSet", "=", "uSet", "[", "tempIdx", "[", "budgetSize", ":", "]", "]", "\n", "return", "activeSet", ",", "uSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.bald": [[292, 350], ["clf_model.cuda", "clf_model.train", "clf_model.modules", "Sampling.Sampling.dataObj.getSequentialDataLoader", "len", "numpy.zeros", "numpy.zeros", "tqdm.tqdm.tqdm", "numpy.divide", "numpy.log2", "numpy.sum", "numpy.divide", "print", "clf_model.train", "isinstance", "range", "Sampling.Sampling.get_predictions", "numpy.log2", "numpy.sum", "numpy.multiply", "numpy.argsort", "m.eval", "int", "numpy.multiply"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions"], ["", "def", "bald", "(", "self", ",", "budgetSize", ",", "uSet", ",", "clf_model", ",", "dataset", ")", ":", "\n", "        ", "\"Implements BALD acquisition function where we maximize information gain.\"", "\n", "\n", "clf_model", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "\n", "assert", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", "!=", "0", ",", "\"Expected dropout iterations > 0.\"", "\n", "\n", "#Set Batchnorm in eval mode whereas dropout in train mode", "\n", "clf_model", ".", "train", "(", ")", "\n", "for", "m", "in", "clf_model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "eval", "(", ")", "\n", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "", "", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "n_uPts", "=", "len", "(", "uSet", ")", "\n", "# Source Code was in tensorflow", "\n", "# To provide same readability we use same variable names where ever possible", "\n", "# Original TF-Code: https://github.com/Riashat/Deep-Bayesian-Active-Learning/blob/master/MC_Dropout_Keras/Dropout_Bald_Q10_N1000_Paper.py#L223", "\n", "\n", "# Heuristic: G_X - F_X", "\n", "score_All", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_uPts", ",", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ")", ")", "\n", "all_entropy_dropout", "=", "np", ".", "zeros", "(", "shape", "=", "(", "n_uPts", ")", ")", "\n", "\n", "for", "d", "in", "tqdm", "(", "range", "(", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", ")", ",", "desc", "=", "\"Dropout Iterations\"", ")", ":", "\n", "            ", "dropout_score", "=", "self", ".", "get_predictions", "(", "clf_model", "=", "clf_model", ",", "idx_set", "=", "uSet", ",", "dataset", "=", "dataset", ")", "\n", "\n", "score_All", "+=", "dropout_score", "\n", "\n", "#computing F_x", "\n", "dropout_score_log", "=", "np", ".", "log2", "(", "dropout_score", "+", "1e-6", ")", "#Add 1e-6 to avoid log(0)", "\n", "Entropy_Compute", "=", "-", "np", ".", "multiply", "(", "dropout_score", ",", "dropout_score_log", ")", "\n", "Entropy_per_Dropout", "=", "np", ".", "sum", "(", "Entropy_Compute", ",", "axis", "=", "1", ")", "\n", "\n", "all_entropy_dropout", "+=", "Entropy_per_Dropout", "\n", "\n", "", "Avg_Pi", "=", "np", ".", "divide", "(", "score_All", ",", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", ")", "\n", "Log_Avg_Pi", "=", "np", ".", "log2", "(", "Avg_Pi", "+", "1e-6", ")", "\n", "Entropy_Avg_Pi", "=", "-", "np", ".", "multiply", "(", "Avg_Pi", ",", "Log_Avg_Pi", ")", "\n", "Entropy_Average_Pi", "=", "np", ".", "sum", "(", "Entropy_Avg_Pi", ",", "axis", "=", "1", ")", "\n", "G_X", "=", "Entropy_Average_Pi", "\n", "Average_Entropy", "=", "np", ".", "divide", "(", "all_entropy_dropout", ",", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", ")", "\n", "F_X", "=", "Average_Entropy", "\n", "\n", "U_X", "=", "G_X", "-", "F_X", "\n", "print", "(", "\"U_X.shape: \"", ",", "U_X", ".", "shape", ")", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "U_X", ")", "[", ":", ":", "-", "1", "]", "# argsort helps to return the indices of u_scores such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "# Setting task model in train mode for further learning", "\n", "clf_model", ".", "train", "(", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.dbal": [[352, 416], ["clf_model.cuda", "clf_model.train", "clf_model.modules", "Sampling.Sampling.dataObj.getSequentialDataLoader", "len", "Sampling.EntropyLoss", "print", "enumerate", "numpy.concatenate", "isinstance", "tqdm.tqdm.tqdm", "x_u.cuda.cuda.type", "numpy.zeros", "range", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "EntropyLoss.", "numpy.concatenate.append", "numpy.argsort", "m.eval", "int", "len", "EntropyLoss.cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x_u.cuda.cuda.cuda", "clf_model", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "numpy.add", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.nn.functional.softmax.cpu().numpy", "torch.nn.functional.softmax.cpu().numpy", "EntropyLoss.cpu", "torch.nn.functional.softmax.cpu", "torch.nn.functional.softmax.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "dbal", "(", "self", ",", "budgetSize", ",", "uSet", ",", "clf_model", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        Implements deep bayesian active learning where uncertainty is measured by \n        maximizing entropy of predictions. This uncertainty method is choosen following\n        the recent state of the art approach, VAAL. [SOURCE: Implementation Details in VAAL paper]\n        \n        In bayesian view, predictions are computed with the help of dropouts and \n        Monte Carlo approximation \n        \"\"\"", "\n", "clf_model", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "\n", "# Set Batchnorm in eval mode whereas dropout in train mode", "\n", "clf_model", ".", "train", "(", ")", "\n", "for", "m", "in", "clf_model", ".", "modules", "(", ")", ":", "\n", "#print(\"True\")", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "eval", "(", ")", "\n", "\n", "", "", "assert", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", "!=", "0", ",", "\"Expected dropout iterations > 0.\"", "\n", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "u_scores", "=", "[", "]", "\n", "n_uPts", "=", "len", "(", "uSet", ")", "\n", "ptsProcessed", "=", "0", "\n", "\n", "entropy_loss", "=", "EntropyLoss", "(", ")", "\n", "\n", "print", "(", "\"len usetLoader: {}\"", ".", "format", "(", "len", "(", "uSetLoader", ")", ")", ")", "\n", "temp_i", "=", "0", "\n", "\n", "for", "k", ",", "(", "x_u", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "uSetLoader", ",", "desc", "=", "\"uSet Feed Forward\"", ")", ")", ":", "\n", "            ", "temp_i", "+=", "1", "\n", "x_u", "=", "x_u", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "z_op", "=", "np", ".", "zeros", "(", "(", "x_u", ".", "shape", "[", "0", "]", ",", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", ")", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "x_u", "=", "x_u", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "temp_op", "=", "clf_model", "(", "x_u", ")", "\n", "# Till here z_op represents logits of p(y|x).", "\n", "# So to get probabilities", "\n", "temp_op", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "temp_op", ",", "dim", "=", "1", ")", "\n", "z_op", "=", "np", ".", "add", "(", "z_op", ",", "temp_op", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "z_op", "/=", "self", ".", "cfg", ".", "ACTIVE_LEARNING", ".", "DROPOUT_ITERATIONS", "\n", "\n", "z_op", "=", "torch", ".", "from_numpy", "(", "z_op", ")", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "entropy_z_op", "=", "entropy_loss", "(", "z_op", ",", "applySoftMax", "=", "False", ")", "\n", "\n", "# Now entropy_z_op = Sum over all classes{ -p(y=c|x) log p(y=c|x)}", "\n", "u_scores", ".", "append", "(", "entropy_z_op", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ptsProcessed", "+=", "x_u", ".", "shape", "[", "0", "]", "\n", "\n", "", "u_scores", "=", "np", ".", "concatenate", "(", "u_scores", ",", "axis", "=", "0", ")", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "u_scores", ")", "[", ":", ":", "-", "1", "]", "# argsort helps to return the indices of u_scores such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.ensemble_var_R": [[418, 474], ["len", "Sampling.Sampling.dataObj.getSequentialDataLoader", "print", "numpy.zeros", "enumerate", "numpy.squeeze", "print", "print", "cmodel.cuda", "cmodel.eval", "tqdm.tqdm.tqdm", "x_u.cuda.cuda.type", "numpy.zeros", "range", "stats.mode", "numpy.array", "numpy.argsort", "int", "len", "len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x_u.cuda.cuda.cuda", "torch.max", "torch.max", "torch.max", "torch.max", "temp_pred.cpu().numpy.cpu().numpy.cpu().numpy", "str", "temp_pred.cpu().numpy.cpu().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "ensemble_var_R", "(", "self", ",", "budgetSize", ",", "uSet", ",", "clf_models", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n        Implements ensemble variance_ratio measured as the number of disagreement in committee \n        with respect to the predicted class. \n        If f_m is number of members agreeing to predicted class then \n        variance ratio(var_r) is evaludated as follows:\n        \n            var_r = 1 - (f_m / T); where T is number of commitee members\n\n        For more details refer equation 4 in \n        http://openaccess.thecvf.com/content_cvpr_2018/papers/Beluch_The_Power_of_CVPR_2018_paper.pdf\n        \"\"\"", "\n", "from", "scipy", "import", "stats", "\n", "T", "=", "len", "(", "clf_models", ")", "\n", "\n", "for", "cmodel", "in", "clf_models", ":", "\n", "            ", "cmodel", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "cmodel", ".", "eval", "(", ")", "\n", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "print", "(", "\"len usetLoader: {}\"", ".", "format", "(", "len", "(", "uSetLoader", ")", ")", ")", "\n", "\n", "temp_i", "=", "0", "\n", "var_r_scores", "=", "np", ".", "zeros", "(", "(", "len", "(", "uSet", ")", ",", "1", ")", ",", "dtype", "=", "float", ")", "\n", "\n", "for", "k", ",", "(", "x_u", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "uSetLoader", ",", "desc", "=", "\"uSet Forward Passes through \"", "+", "str", "(", "T", ")", "+", "\" models\"", ")", ")", ":", "\n", "            ", "x_u", "=", "x_u", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "ens_preds", "=", "np", ".", "zeros", "(", "(", "x_u", ".", "shape", "[", "0", "]", ",", "T", ")", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "clf_models", ")", ")", ":", "\n", "               ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "x_u", "=", "x_u", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "temp_op", "=", "clf_models", "[", "i", "]", "(", "x_u", ")", "\n", "_", ",", "temp_pred", "=", "torch", ".", "max", "(", "temp_op", ",", "1", ")", "\n", "temp_pred", "=", "temp_pred", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "ens_preds", "[", ":", ",", "i", "]", "=", "temp_pred", "\n", "", "", "_", ",", "mode_cnt", "=", "stats", ".", "mode", "(", "ens_preds", ",", "1", ")", "\n", "temp_varr", "=", "1.0", "-", "(", "mode_cnt", "/", "T", "*", "1.0", ")", "\n", "var_r_scores", "[", "temp_i", ":", "temp_i", "+", "x_u", ".", "shape", "[", "0", "]", "]", "=", "temp_varr", "\n", "\n", "temp_i", "=", "temp_i", "+", "x_u", ".", "shape", "[", "0", "]", "\n", "\n", "", "var_r_scores", "=", "np", ".", "squeeze", "(", "np", ".", "array", "(", "var_r_scores", ")", ")", "\n", "print", "(", "\"var_r_scores: \"", ")", "\n", "print", "(", "var_r_scores", ".", "shape", ")", "\n", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "var_r_scores", ")", "[", ":", ":", "-", "1", "]", "#argsort helps to return the indices of u_scores such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.uncertainty": [[475, 518], ["model.cuda", "Sampling.Sampling.dataObj.getSequentialDataLoader", "len", "print", "enumerate", "numpy.concatenate", "print", "tqdm.tqdm.tqdm", "numpy.argsort", "int", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x_u.cuda.cuda.cuda", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.max", "torch.max", "torch.max", "torch.max", "numpy.concatenate.append", "model.cuda.", "torch.nn.functional.softmax.detach().cpu().numpy", "torch.nn.functional.softmax.detach().cpu().numpy", "torch.nn.functional.softmax.detach().cpu", "torch.nn.functional.softmax.detach().cpu", "torch.nn.functional.softmax.detach", "torch.nn.functional.softmax.detach"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "uncertainty", "(", "self", ",", "budgetSize", ",", "lSet", ",", "uSet", ",", "model", ",", "dataset", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Implements the uncertainty principle as a acquisition function.\n        \"\"\"", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", "\n", "assert", "model", ".", "training", "==", "False", ",", "\"Model expected in eval mode whereas currently it is in {}\"", ".", "format", "(", "model", ".", "training", ")", "\n", "\n", "clf", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "u_ranks", "=", "[", "]", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     print(\"Loading the model in data parallel where num_GPUS: {}\".format(self.cfg.NUM_GPUS))", "\n", "#     clf = torch.nn.DataParallel(clf, device_ids = [i for i in range(self.cfg.NUM_GPUS)])", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "\n", "n_uLoader", "=", "len", "(", "uSetLoader", ")", "\n", "print", "(", "\"len(uSetLoader): {}\"", ".", "format", "(", "n_uLoader", ")", ")", "\n", "for", "i", ",", "(", "x_u", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "uSetLoader", ",", "desc", "=", "\"uSet Activations\"", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x_u", "=", "x_u", ".", "cuda", "(", "0", ")", "\n", "\n", "temp_u_rank", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "clf", "(", "x_u", ")", ",", "dim", "=", "1", ")", "\n", "temp_u_rank", ",", "_", "=", "torch", ".", "max", "(", "temp_u_rank", ",", "dim", "=", "1", ")", "\n", "temp_u_rank", "=", "1", "-", "temp_u_rank", "\n", "u_ranks", ".", "append", "(", "temp_u_rank", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "u_ranks", "=", "np", ".", "concatenate", "(", "u_ranks", ",", "axis", "=", "0", ")", "\n", "# Now u_ranks has shape: [U_Size x 1]", "\n", "\n", "# index of u_ranks serve as key to refer in u_idx", "\n", "print", "(", "f\"u_ranks.shape: {u_ranks.shape}\"", ")", "\n", "# we add -1 for reversing the sorted array", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "u_ranks", ")", "[", ":", ":", "-", "1", "]", "# argsort helps to return the indices of u_ranks such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.entropy": [[520, 562], ["model.cuda", "Sampling.Sampling.dataObj.getSequentialDataLoader", "len", "print", "enumerate", "numpy.concatenate", "print", "tqdm.tqdm.tqdm", "numpy.argsort", "int", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x_u.cuda.cuda.cuda", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "numpy.concatenate.append", "model.cuda.", "torch.log2", "torch.log2", "torch.log2", "torch.log2", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.nn.functional.softmax.detach().cpu().numpy", "torch.nn.functional.softmax.detach().cpu().numpy", "torch.nn.functional.softmax.detach().cpu", "torch.nn.functional.softmax.detach().cpu", "torch.nn.functional.softmax.detach", "torch.nn.functional.softmax.detach"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "entropy", "(", "self", ",", "budgetSize", ",", "lSet", ",", "uSet", ",", "model", ",", "dataset", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Implements the uncertainty principle as a acquisition function.\n        \"\"\"", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", "\n", "assert", "model", ".", "training", "==", "False", ",", "\"Model expected in eval mode whereas currently it is in {}\"", ".", "format", "(", "model", ".", "training", ")", "\n", "\n", "clf", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "u_ranks", "=", "[", "]", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     print(\"Loading the model in data parallel where num_GPUS: {}\".format(self.cfg.NUM_GPUS))", "\n", "#     clf = torch.nn.DataParallel(clf, device_ids = [i for i in range(self.cfg.NUM_GPUS)])", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "\n", "n_uLoader", "=", "len", "(", "uSetLoader", ")", "\n", "print", "(", "\"len(uSetLoader): {}\"", ".", "format", "(", "n_uLoader", ")", ")", "\n", "for", "i", ",", "(", "x_u", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "uSetLoader", ",", "desc", "=", "\"uSet Activations\"", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x_u", "=", "x_u", ".", "cuda", "(", "0", ")", "\n", "\n", "temp_u_rank", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "clf", "(", "x_u", ")", ",", "dim", "=", "1", ")", "\n", "temp_u_rank", "=", "temp_u_rank", "*", "torch", ".", "log2", "(", "temp_u_rank", ")", "\n", "temp_u_rank", "=", "-", "1", "*", "torch", ".", "sum", "(", "temp_u_rank", ",", "dim", "=", "1", ")", "\n", "u_ranks", ".", "append", "(", "temp_u_rank", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "u_ranks", "=", "np", ".", "concatenate", "(", "u_ranks", ",", "axis", "=", "0", ")", "\n", "# Now u_ranks has shape: [U_Size x 1]", "\n", "\n", "# index of u_ranks serve as key to refer in u_idx", "\n", "print", "(", "f\"u_ranks.shape: {u_ranks.shape}\"", ")", "\n", "# we add -1 for reversing the sorted array", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "u_ranks", ")", "[", ":", ":", "-", "1", "]", "# argsort helps to return the indices of u_ranks such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.margin": [[564, 608], ["model.cuda", "Sampling.Sampling.dataObj.getSequentialDataLoader", "len", "print", "enumerate", "numpy.concatenate", "print", "tqdm.tqdm.tqdm", "numpy.argsort", "int", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "x_u.cuda.cuda.cuda", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "numpy.concatenate.append", "model.cuda.", "difference.detach().cpu().numpy", "difference.detach().cpu", "difference.detach"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "margin", "(", "self", ",", "budgetSize", ",", "lSet", ",", "uSet", ",", "model", ",", "dataset", ")", ":", "\n", "\n", "        ", "\"\"\"\n        Implements the uncertainty principle as a acquisition function.\n        \"\"\"", "\n", "num_classes", "=", "self", ".", "cfg", ".", "MODEL", ".", "NUM_CLASSES", "\n", "assert", "model", ".", "training", "==", "False", ",", "\"Model expected in eval mode whereas currently it is in {}\"", ".", "format", "(", "model", ".", "training", ")", "\n", "\n", "clf", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "u_ranks", "=", "[", "]", "\n", "# if self.cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     print(\"Loading the model in data parallel where num_GPUS: {}\".format(self.cfg.NUM_GPUS))", "\n", "#     clf = torch.nn.DataParallel(clf, device_ids = [i for i in range(self.cfg.NUM_GPUS)])", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg=self.cfg, indices=uSet, isDistributed=False, isShuffle=False, isVaalSampling=False)", "\n", "# else:", "\n", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", ",", "data", "=", "dataset", ")", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "\n", "n_uLoader", "=", "len", "(", "uSetLoader", ")", "\n", "print", "(", "\"len(uSetLoader): {}\"", ".", "format", "(", "n_uLoader", ")", ")", "\n", "for", "i", ",", "(", "x_u", ",", "_", ")", "in", "enumerate", "(", "tqdm", "(", "uSetLoader", ",", "desc", "=", "\"uSet Activations\"", ")", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "x_u", "=", "x_u", ".", "cuda", "(", "0", ")", "\n", "\n", "temp_u_rank", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "clf", "(", "x_u", ")", ",", "dim", "=", "1", ")", "\n", "temp_u_rank", ",", "_", "=", "torch", ".", "sort", "(", "temp_u_rank", ",", "descending", "=", "True", ")", "\n", "difference", "=", "temp_u_rank", "[", ":", ",", "0", "]", "-", "temp_u_rank", "[", ":", ",", "1", "]", "\n", "# for code consistency across uncertainty, entropy methods i.e., picking datapoints with max value  ", "\n", "difference", "=", "-", "1", "*", "difference", "\n", "u_ranks", ".", "append", "(", "difference", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "u_ranks", "=", "np", ".", "concatenate", "(", "u_ranks", ",", "axis", "=", "0", ")", "\n", "# Now u_ranks has shape: [U_Size x 1]", "\n", "\n", "# index of u_ranks serve as key to refer in u_idx", "\n", "print", "(", "f\"u_ranks.shape: {u_ranks.shape}\"", ")", "\n", "# we add -1 for reversing the sorted array", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "u_ranks", ")", "[", ":", ":", "-", "1", "]", "#argsort helps to return the indices of u_ranks such that their corresponding values are sorted.", "\n", "activeSet", "=", "sorted_idx", "[", ":", "budgetSize", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "budgetSize", ":", "]", "]", "\n", "uSetLoader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.__init__": [[613, 624], ["torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataObj", ",", "cfg", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "dataObj", "=", "dataObj", "\n", "self", ".", "budget", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", "\n", "self", ".", "cuda_id", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "if", "cfg", ".", "DATASET", ".", "NAME", "==", "'TINYIMAGENET'", ":", "\n", "            ", "cfg", ".", "VAAL", ".", "Z_DIM", "=", "64", "\n", "cfg", ".", "VAAL", ".", "IM_SIZE", "=", "64", "\n", "", "else", ":", "\n", "            ", "cfg", ".", "VAAL", ".", "Z_DIM", "=", "32", "\n", "cfg", ".", "VAAL", ".", "IM_SIZE", "=", "32", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists": [[626, 629], ["numpy.sum", "numpy.sum", "numpy.dot"], "methods", ["None"], ["", "", "def", "compute_dists", "(", "self", ",", "X", ",", "X_train", ")", ":", "\n", "        ", "dists", "=", "-", "2", "*", "np", ".", "dot", "(", "X", ",", "X_train", ".", "T", ")", "+", "np", ".", "sum", "(", "X_train", "**", "2", ",", "axis", "=", "1", ")", "+", "np", ".", "sum", "(", "X", "**", "2", ",", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "return", "dists", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.vaal_perform_training": [[630, 645], ["vaal_util.train_vae_disc", "Sampling.AdversarySampler.dataObj.getSequentialDataLoader", "vae.eval", "disc.eval", "int"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.train_vae_disc", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader"], ["", "def", "vaal_perform_training", "(", "self", ",", "lSet", ",", "uSet", ",", "dataset", ",", "debug", "=", "False", ")", ":", "\n", "        ", "oldmode", "=", "self", ".", "dataObj", ".", "eval_mode", "\n", "self", ".", "dataObj", ".", "eval_mode", "=", "True", "\n", "self", ".", "dataObj", ".", "eval_mode", "=", "oldmode", "\n", "\n", "# First train vae and disc", "\n", "vae", ",", "disc", "=", "train_vae_disc", "(", "self", ".", "cfg", ",", "lSet", ",", "uSet", ",", "dataset", ",", "self", ".", "dataObj", ",", "debug", ")", "\n", "uSetLoader", "=", "self", ".", "dataObj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "self", ".", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "/", "self", ".", "cfg", ".", "NUM_GPUS", ")", ",", "data", "=", "dataset", ")", "\n", "\n", "# Do active sampling", "\n", "vae", ".", "eval", "(", ")", "\n", "disc", ".", "eval", "(", ")", "\n", "\n", "return", "vae", ",", "disc", ",", "uSetLoader", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.greedy_k_center": [[646, 681], ["numpy.min", "min_dist.reshape.reshape.reshape", "range", "numpy.argmax", "greedy_indices.append", "range", "numpy.array", "Sampling.AdversarySampler.compute_dists", "numpy.vstack", "numpy.min", "min_dist.reshape.reshape.reshape", "Sampling.AdversarySampler.compute_dists", "numpy.vstack", "numpy.min", "min_dist.reshape.reshape.reshape", "numpy.argmax", "greedy_indices.append", "set", "set", "list", "labeled[].reshape", "Sampling.AdversarySampler.compute_dists", "Sampling.AdversarySampler.compute_dists", "print", "unlabeled[].reshape", "numpy.arange", "numpy.min().reshape", "Sampling.AdversarySampler.reshape", "numpy.min"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.compute_dists"], ["", "def", "greedy_k_center", "(", "self", ",", "labeled", ",", "unlabeled", ")", ":", "\n", "        ", "greedy_indices", "=", "[", "]", "\n", "\n", "# get the minimum distances between the labeled and unlabeled examples (iteratively, to avoid memory issues):", "\n", "min_dist", "=", "np", ".", "min", "(", "self", ".", "compute_dists", "(", "labeled", "[", "0", ",", ":", "]", ".", "reshape", "(", "(", "1", ",", "labeled", ".", "shape", "[", "1", "]", ")", ")", ",", "unlabeled", ")", ",", "axis", "=", "0", ")", "\n", "min_dist", "=", "min_dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "temp_range", "=", "1000", "\n", "for", "j", "in", "range", "(", "1", ",", "labeled", ".", "shape", "[", "0", "]", ",", "temp_range", ")", ":", "\n", "            ", "if", "j", "+", "temp_range", "<", "labeled", ".", "shape", "[", "0", "]", ":", "\n", "                ", "dist", "=", "self", ".", "compute_dists", "(", "labeled", "[", "j", ":", "j", "+", "temp_range", ",", ":", "]", ",", "unlabeled", ")", "\n", "", "else", ":", "\n", "# for last iteration only :)", "\n", "                ", "dist", "=", "self", ".", "compute_dists", "(", "labeled", "[", "j", ":", ",", ":", "]", ",", "unlabeled", ")", "\n", "", "min_dist", "=", "np", ".", "vstack", "(", "(", "min_dist", ",", "np", ".", "min", "(", "dist", ",", "axis", "=", "0", ")", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "1", "]", ")", ")", ")", ")", "\n", "min_dist", "=", "np", ".", "min", "(", "min_dist", ",", "axis", "=", "0", ")", "\n", "min_dist", "=", "min_dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "# iteratively insert the farthest index and recalculate the minimum distances:", "\n", "", "farthest", "=", "np", ".", "argmax", "(", "min_dist", ")", "\n", "greedy_indices", ".", "append", "(", "farthest", ")", "\n", "\n", "amount", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "BUDGET_SIZE", "-", "1", "\n", "for", "i", "in", "range", "(", "amount", ")", ":", "\n", "            ", "if", "i", "!=", "0", "and", "i", "%", "500", "==", "0", ":", "\n", "                ", "print", "(", "\"{} Sampled out of {}\"", ".", "format", "(", "i", ",", "amount", "+", "1", ")", ")", "\n", "", "dist", "=", "self", ".", "compute_dists", "(", "unlabeled", "[", "greedy_indices", "[", "-", "1", "]", ",", ":", "]", ".", "reshape", "(", "(", "1", ",", "unlabeled", ".", "shape", "[", "1", "]", ")", ")", ",", "unlabeled", ")", "\n", "min_dist", "=", "np", ".", "vstack", "(", "(", "min_dist", ",", "dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "1", "]", ")", ")", ")", ")", "\n", "min_dist", "=", "np", ".", "min", "(", "min_dist", ",", "axis", "=", "0", ")", "\n", "min_dist", "=", "min_dist", ".", "reshape", "(", "(", "1", ",", "min_dist", ".", "shape", "[", "0", "]", ")", ")", "\n", "farthest", "=", "np", ".", "argmax", "(", "min_dist", ")", "\n", "greedy_indices", ".", "append", "(", "farthest", ")", "\n", "\n", "", "remainSet", "=", "set", "(", "np", ".", "arange", "(", "unlabeled", ".", "shape", "[", "0", "]", ")", ")", "-", "set", "(", "greedy_indices", ")", "\n", "remainSet", "=", "np", ".", "array", "(", "list", "(", "remainSet", ")", ")", "\n", "return", "greedy_indices", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_vae_activations": [[683, 702], ["vae.eval", "len", "print", "numpy.concatenate", "x.cuda.cuda.type", "x.cuda.cuda.cuda", "vae", "numpy.concatenate.append", "mu.cpu().numpy", "print", "mu.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "get_vae_activations", "(", "self", ",", "vae", ",", "dataLoader", ")", ":", "\n", "        ", "acts", "=", "[", "]", "\n", "vae", ".", "eval", "(", ")", "\n", "\n", "temp_max_iter", "=", "len", "(", "dataLoader", ")", "\n", "print", "(", "\"len(dataloader): {}\"", ".", "format", "(", "temp_max_iter", ")", ")", "\n", "temp_iter", "=", "0", "\n", "for", "x", ",", "y", "in", "dataLoader", ":", "\n", "            ", "x", "=", "x", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "x", "=", "x", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "_", ",", "_", ",", "mu", ",", "_", "=", "vae", "(", "x", ")", "\n", "acts", ".", "append", "(", "mu", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "temp_iter", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "f\"Iteration [{temp_iter}/{temp_max_iter}] Done!!\"", ")", "\n", "\n", "", "temp_iter", "+=", "1", "\n", "\n", "", "acts", "=", "np", ".", "concatenate", "(", "acts", ",", "axis", "=", "0", ")", "\n", "return", "acts", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions": [[704, 729], ["numpy.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "all_preds.cpu().numpy.cpu().numpy.view", "all_preds.cpu().numpy.cpu().numpy.cpu().numpy", "all_preds.cpu().numpy.cpu().numpy.extend", "images.cuda.cuda.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vae", "discriminator", "discriminator.cpu", "all_preds.cpu().numpy.cpu().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "get_predictions", "(", "self", ",", "vae", ",", "discriminator", ",", "data", ",", "cuda", ")", ":", "\n", "        ", "all_preds", "=", "[", "]", "\n", "all_indices", "=", "[", "]", "\n", "\n", "assert", "vae", ".", "training", "==", "False", ",", "\"Expected vae model to be in eval mode\"", "\n", "assert", "discriminator", ".", "training", "==", "False", ",", "\"Expected discriminator model to be in eval mode\"", "\n", "\n", "temp_idx", "=", "0", "\n", "for", "images", ",", "_", "in", "data", ":", "\n", "            ", "if", "cuda", ":", "\n", "                ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "_", ",", "mu", ",", "_", "=", "vae", "(", "images", ")", "\n", "preds", "=", "discriminator", "(", "mu", ")", "\n", "\n", "", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "data", "\n", "all_preds", ".", "extend", "(", "preds", ")", "\n", "temp_idx", "+=", "images", ".", "shape", "[", "0", "]", "\n", "\n", "", "all_indices", "=", "np", ".", "arange", "(", "temp_idx", ")", "\n", "all_preds", "=", "torch", ".", "stack", "(", "all_preds", ")", "\n", "all_preds", "=", "all_preds", ".", "view", "(", "-", "1", ")", "\n", "all_preds", "=", "all_preds", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "all_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists": [[731, 746], ["torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.mm", "torch.mm", "torch.mm", "torch.mm"], "methods", ["None"], ["", "def", "gpu_compute_dists", "(", "self", ",", "M1", ",", "M2", ")", ":", "\n", "        ", "\"\"\"\n        Computes L2 norm square on gpu\n        Assume \n        M1: M x D matrix\n        M2: N x D matrix\n\n        output: M x N matrix\n        \"\"\"", "\n", "M1_norm", "=", "(", "M1", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "M2_t", "=", "torch", ".", "transpose", "(", "M2", ",", "0", ",", "1", ")", "\n", "M2_norm", "=", "(", "M2", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "dists", "=", "M1_norm", "+", "M2_norm", "-", "2.0", "*", "torch", ".", "mm", "(", "M1", ",", "M2_t", ")", "\n", "return", "dists", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.efficient_compute_dists": [[748, 774], ["torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "numpy.empty", "tqdm.tqdm.tqdm", "torch.reshape.cpu().numpy", "torch.reshape.cpu().numpy", "range", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "Sampling.AdversarySampler.gpu_compute_dists", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.min", "torch.min", "torch.min", "torch.min", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape.cpu", "torch.reshape.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.gpu_compute_dists", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "efficient_compute_dists", "(", "self", ",", "labeled", ",", "unlabeled", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "N_L", "=", "labeled", ".", "shape", "[", "0", "]", "\n", "N_U", "=", "unlabeled", ".", "shape", "[", "0", "]", "\n", "dist_matrix", "=", "None", "\n", "\n", "temp_range", "=", "1000", "\n", "\n", "unlabeled", "=", "torch", ".", "from_numpy", "(", "unlabeled", ")", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "temp_dist_matrix", "=", "np", ".", "empty", "(", "(", "N_U", ",", "temp_range", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "0", ",", "N_L", ",", "temp_range", ")", ",", "desc", "=", "\"Computing Distance Matrix\"", ")", ":", "\n", "            ", "end_index", "=", "i", "+", "temp_range", "if", "i", "+", "temp_range", "<", "N_L", "else", "N_L", "\n", "temp_labeled", "=", "labeled", "[", "i", ":", "end_index", ",", ":", "]", "\n", "temp_labeled", "=", "torch", ".", "from_numpy", "(", "temp_labeled", ")", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "temp_dist_matrix", "=", "self", ".", "gpu_compute_dists", "(", "unlabeled", ",", "temp_labeled", ")", "\n", "temp_dist_matrix", "=", "torch", ".", "min", "(", "temp_dist_matrix", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "temp_dist_matrix", "=", "torch", ".", "reshape", "(", "temp_dist_matrix", ",", "(", "temp_dist_matrix", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "if", "dist_matrix", "is", "None", ":", "\n", "                ", "dist_matrix", "=", "temp_dist_matrix", "\n", "", "else", ":", "\n", "                ", "dist_matrix", "=", "torch", ".", "cat", "(", "(", "dist_matrix", ",", "temp_dist_matrix", ")", ",", "dim", "=", "1", ")", "\n", "dist_matrix", "=", "torch", ".", "min", "(", "dist_matrix", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "dist_matrix", "=", "torch", ".", "reshape", "(", "dist_matrix", ",", "(", "dist_matrix", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "\n", "", "", "return", "dist_matrix", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.vae_sample_for_labeling": [[776, 798], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vae.eval", "print", "Sampling.AdversarySampler.get_vae_activations", "print", "Sampling.AdversarySampler.get_vae_activations", "print", "print", "Sampling.AdversarySampler.efficient_compute_dists", "print", "numpy.min", "numpy.argsort"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_vae_activations", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_vae_activations", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.efficient_compute_dists"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "vae_sample_for_labeling", "(", "self", ",", "vae", ",", "uSet", ",", "lSet", ",", "unlabeled_dataloader", ",", "lSetLoader", ")", ":", "\n", "\n", "        ", "vae", ".", "eval", "(", ")", "\n", "print", "(", "\"Computing activattions for uset....\"", ")", "\n", "u_scores", "=", "self", ".", "get_vae_activations", "(", "vae", ",", "unlabeled_dataloader", ")", "\n", "print", "(", "\"Computing activattions for lset....\"", ")", "\n", "l_scores", "=", "self", ".", "get_vae_activations", "(", "vae", ",", "lSetLoader", ")", "\n", "\n", "print", "(", "\"l_scores.shape: \"", ",", "l_scores", ".", "shape", ")", "\n", "print", "(", "\"u_scores.shape: \"", ",", "u_scores", ".", "shape", ")", "\n", "\n", "dist_matrix", "=", "self", ".", "efficient_compute_dists", "(", "l_scores", ",", "u_scores", ")", "\n", "print", "(", "\"Dist_matrix.shape: \"", ",", "dist_matrix", ".", "shape", ")", "\n", "\n", "min_scores", "=", "np", ".", "min", "(", "dist_matrix", ",", "axis", "=", "1", ")", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "min_scores", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "activeSet", "=", "uSet", "[", "sorted_idx", "[", "0", ":", "self", ".", "budget", "]", "]", "\n", "remainSet", "=", "uSet", "[", "sorted_idx", "[", "self", ".", "budget", ":", "]", "]", "\n", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.sample_vaal_plus": [[800, 834], ["numpy.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "all_preds.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "querry_indices.numpy.numpy.numpy", "numpy.asarray", "all_preds.view.view.extend", "int", "list", "len", "images.cuda.cuda.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vae", "disc_task", "preds.cpu", "len", "len", "set", "set"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "sample_vaal_plus", "(", "self", ",", "vae", ",", "disc_task", ",", "data", ",", "cuda", ")", ":", "\n", "        ", "all_preds", "=", "[", "]", "\n", "all_indices", "=", "[", "]", "\n", "\n", "assert", "vae", ".", "training", "==", "False", ",", "\"Expected vae model to be in eval mode\"", "\n", "assert", "disc_task", ".", "training", "==", "False", ",", "\"Expected disc_task model to be in eval mode\"", "\n", "\n", "temp_idx", "=", "0", "\n", "for", "images", ",", "_", "in", "data", ":", "\n", "            ", "if", "cuda", ":", "\n", "                ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "_", ",", "mu", ",", "_", "=", "vae", "(", "images", ")", "\n", "preds", ",", "_", "=", "disc_task", "(", "mu", ")", "\n", "\n", "", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "data", "\n", "all_preds", ".", "extend", "(", "preds", ")", "\n", "temp_idx", "+=", "images", ".", "shape", "[", "0", "]", "\n", "\n", "", "all_indices", "=", "np", ".", "arange", "(", "temp_idx", ")", "\n", "all_preds", "=", "torch", ".", "stack", "(", "all_preds", ")", "\n", "all_preds", "=", "all_preds", ".", "view", "(", "-", "1", ")", "\n", "# need to multiply by -1 to be able to use torch.topk ", "\n", "all_preds", "*=", "-", "1", "\n", "\n", "# select the points which the discriminator things are the most likely to be unlabeled", "\n", "_", ",", "querry_indices", "=", "torch", ".", "topk", "(", "all_preds", ",", "int", "(", "self", ".", "budget", ")", ")", "\n", "querry_indices", "=", "querry_indices", ".", "numpy", "(", ")", "\n", "remain_indices", "=", "np", ".", "asarray", "(", "list", "(", "set", "(", "all_indices", ")", "-", "set", "(", "querry_indices", ")", ")", ")", "\n", "assert", "len", "(", "remain_indices", ")", "+", "len", "(", "querry_indices", ")", "==", "len", "(", "all_indices", ")", ",", "\" Indices are overlapped between activeSet and uSet\"", "\n", "activeSet", "=", "all_indices", "[", "querry_indices", "]", "\n", "uSet", "=", "all_indices", "[", "remain_indices", "]", "\n", "return", "activeSet", ",", "uSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.sample": [[836, 873], ["vae.cuda", "discriminator.cuda", "numpy.arange", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "all_preds.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "querry_indices.numpy.numpy.numpy", "numpy.asarray", "images.cuda.cuda.type", "images.cuda.cuda.cuda", "all_preds.view.view.extend", "int", "list", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "vae", "discriminator", "discriminator.cpu", "len", "len", "set", "set"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "sample", "(", "self", ",", "vae", ",", "discriminator", ",", "data", ")", ":", "\n", "        ", "all_preds", "=", "[", "]", "\n", "all_indices", "=", "[", "]", "\n", "\n", "assert", "vae", ".", "training", "==", "False", ",", "\"Expected vae model to be in eval mode\"", "\n", "assert", "discriminator", ".", "training", "==", "False", ",", "\"Expected discriminator model to be in eval mode\"", "\n", "\n", "vae", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "discriminator", ".", "cuda", "(", "self", ".", "cuda_id", ")", "\n", "\n", "temp_idx", "=", "0", "\n", "for", "images", ",", "_", "in", "data", ":", "\n", "            ", "images", "=", "images", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "images", "=", "images", ".", "cuda", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "_", ",", "_", ",", "mu", ",", "_", "=", "vae", "(", "images", ")", "\n", "preds", "=", "discriminator", "(", "mu", ")", "\n", "\n", "", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "data", "\n", "all_preds", ".", "extend", "(", "preds", ")", "\n", "temp_idx", "+=", "images", ".", "shape", "[", "0", "]", "\n", "\n", "", "all_indices", "=", "np", ".", "arange", "(", "temp_idx", ")", "\n", "all_preds", "=", "torch", ".", "stack", "(", "all_preds", ")", "\n", "all_preds", "=", "all_preds", ".", "view", "(", "-", "1", ")", "\n", "# need to multiply by -1 to be able to use torch.topk ", "\n", "all_preds", "*=", "-", "1", "\n", "\n", "# select the points which the discriminator things are the most likely to be unlabeled", "\n", "_", ",", "querry_indices", "=", "torch", ".", "topk", "(", "all_preds", ",", "int", "(", "self", ".", "budget", ")", ")", "\n", "querry_indices", "=", "querry_indices", ".", "numpy", "(", ")", "\n", "remain_indices", "=", "np", ".", "asarray", "(", "list", "(", "set", "(", "all_indices", ")", "-", "set", "(", "querry_indices", ")", ")", ")", "\n", "assert", "len", "(", "remain_indices", ")", "+", "len", "(", "querry_indices", ")", "==", "len", "(", "all_indices", ")", ",", "\" Indices are overlapped between activeSet and uSet\"", "\n", "activeSet", "=", "all_indices", "[", "querry_indices", "]", "\n", "uSet", "=", "all_indices", "[", "remain_indices", "]", "\n", "return", "activeSet", ",", "uSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.sample_for_labeling": [[875, 908], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "Sampling.AdversarySampler.sample"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.sample"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "sample_for_labeling", "(", "self", ",", "vae", ",", "discriminator", ",", "unlabeled_dataloader", ",", "uSet", ")", ":", "\n", "        ", "\"\"\"\n        Picks samples from uSet to form activeSet.\n\n        INPUT\n        ------\n        vae: object of model VAE\n\n        discriminator: object of model discriminator\n\n        unlabeled_dataloader: Sequential dataloader iterating over uSet\n\n        uSet: Collection of unlabelled datapoints\n\n        NOTE: Please pass the unlabelled dataloader as sequential dataloader else the\n        results won't be appropriate.\n\n        OUTPUT\n        -------\n\n        Returns activeSet, [remaining]uSet\n        \"\"\"", "\n", "unlabeled_dataloader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "activeSet", ",", "remainSet", "=", "self", ".", "sample", "(", "vae", ",", "\n", "discriminator", ",", "\n", "unlabeled_dataloader", ",", "\n", ")", "\n", "\n", "activeSet", "=", "uSet", "[", "activeSet", "]", "\n", "remainSet", "=", "uSet", "[", "remainSet", "]", "\n", "unlabeled_dataloader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.data_parallel_wrapper": [[18, 22], ["torch.nn.DataParallel.cuda", "torch.nn.DataParallel", "range", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["def", "data_parallel_wrapper", "(", "model", ",", "cur_device", ",", "cfg", ")", ":", "\n", "    ", "model", ".", "cuda", "(", "cur_device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "i", "for", "i", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.distributed_wrapper": [[23, 36], ["torch.nn.parallel.DistributedDataParallel.cuda", "torch.nn.parallel.DistributedDataParallel"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "def", "distributed_wrapper", "(", "cfg", ",", "model", ",", "cur_device", ")", ":", "\n", "# Transfer the model to the current GPU device", "\n", "    ", "model", "=", "model", ".", "cuda", "(", "device", "=", "cur_device", ")", "\n", "\n", "# Use multi-process data parallel model in the multi-gpu setting", "\n", "if", "cfg", ".", "NUM_GPUS", ">", "1", ":", "\n", "# Make model replica operate on the current device", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "module", "=", "model", ",", "\n", "device_ids", "=", "[", "cur_device", "]", ",", "\n", "output_device", "=", "cur_device", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.read_data": [[37, 46], ["None"], "function", ["None"], ["", "def", "read_data", "(", "dataloader", ",", "labels", "=", "True", ")", ":", "\n", "    ", "if", "labels", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "for", "img", ",", "label", "in", "dataloader", ":", "\n", "                ", "yield", "img", ",", "label", "\n", "", "", "", "else", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "for", "img", ",", "_", "in", "dataloader", ":", "\n", "                ", "yield", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.vae_loss": [[47, 55], ["torch.nn.MSELoss().cuda", "recon.cuda.cuda", "x.cuda.cuda", "torch.nn.MSELoss().cuda.", "torch.sum", "torch.nn.MSELoss", "logvar.exp", "mu.pow"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "", "", "", "def", "vae_loss", "(", "x", ",", "recon", ",", "mu", ",", "logvar", ",", "beta", ")", ":", "\n", "    ", "mse_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", ".", "cuda", "(", ")", "\n", "recon", "=", "recon", ".", "cuda", "(", ")", "\n", "x", "=", "x", ".", "cuda", "(", ")", "\n", "MSE", "=", "mse_loss", "(", "recon", ",", "x", ")", "\n", "KLD", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "logvar", "-", "mu", ".", "pow", "(", "2", ")", "-", "logvar", ".", "exp", "(", ")", ")", "\n", "KLD", "=", "KLD", "*", "beta", "\n", "return", "MSE", "+", "KLD", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.train_vae_disc_epoch": [[56, 146], ["print", "print", "vaal_util.read_data", "vaal_util.read_data", "vae_model.train", "disc_model.train", "int", "int", "range", "lSetLoader.sampler.set_epoch", "uSetLoader.sampler.set_epoch", "disc_model.eval", "vae_model.train", "next", "next", "labeled_imgs.cuda.type", "unlabeled_imgs.cuda.type", "labeled_imgs.cuda.cuda", "unlabeled_imgs.cuda.cuda", "vae_model", "recon.view.view", "vaal_util.vae_loss", "vae_model", "unlab_recon.view.view", "vaal_util.vae_loss", "disc_model", "disc_model", "torch.ones().cuda", "torch.ones().cuda", "optim_vae.zero_grad", "total_vae_loss.backward", "optim_vae.step", "vae_model.eval", "disc_model.train", "disc_model", "disc_model", "torch.ones().cuda", "torch.zeros().cuda", "optim_disc.zero_grad", "dsc_loss.backward", "optim_disc.step", "len", "len", "bce_loss", "bce_loss", "torch.no_grad", "vae_model", "vae_model", "bce_loss", "bce_loss", "print", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "labeled_imgs.cuda.size", "unlabeled_imgs.cuda.size", "labeled_imgs.cuda.size", "unlabeled_imgs.cuda.size", "total_vae_loss.item", "dsc_loss.item"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.read_data", "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.read_data", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.vae_loss", "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.vae_loss", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "def", "train_vae_disc_epoch", "(", "cfg", ",", "vae_model", ",", "disc_model", ",", "optim_vae", ",", "optim_disc", ",", "lSetLoader", ",", "uSetLoader", ",", "cur_epoch", ",", "n_lu", ",", "curr_vae_disc_iter", ",", "max_vae_disc_iters", ",", "change_lr_iter", ",", "isDistributed", "=", "False", ")", ":", "\n", "\n", "    ", "if", "isDistributed", ":", "\n", "        ", "lSetLoader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "uSetLoader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "", "print", "(", "'len(lSetLoader): {}'", ".", "format", "(", "len", "(", "lSetLoader", ")", ")", ")", "\n", "print", "(", "'len(uSetLoader): {}'", ".", "format", "(", "len", "(", "uSetLoader", ")", ")", ")", "\n", "\n", "labeled_data", "=", "read_data", "(", "lSetLoader", ")", "\n", "unlabeled_data", "=", "read_data", "(", "uSetLoader", ",", "labels", "=", "False", ")", "\n", "\n", "vae_model", ".", "train", "(", ")", "\n", "disc_model", ".", "train", "(", ")", "\n", "\n", "temp_bs", "=", "int", "(", "cfg", ".", "VAAL", ".", "VAE_BS", ")", "\n", "train_iterations", "=", "int", "(", "n_lu", "/", "temp_bs", ")", "\n", "\n", "for", "temp_iter", "in", "range", "(", "train_iterations", ")", ":", "\n", "\n", "        ", "if", "curr_vae_disc_iter", "!=", "0", "and", "curr_vae_disc_iter", "%", "change_lr_iter", "==", "0", ":", "\n", "#print(\"Changing LR ---- ))__((---- \")", "\n", "            ", "for", "param", "in", "optim_vae", ".", "param_groups", ":", "\n", "                ", "param", "[", "'lr'", "]", "=", "param", "[", "'lr'", "]", "*", "0.9", "\n", "\n", "", "for", "param", "in", "optim_disc", ".", "param_groups", ":", "\n", "                ", "param", "[", "'lr'", "]", "=", "param", "[", "'lr'", "]", "*", "0.9", "\n", "\n", "", "", "curr_vae_disc_iter", "+=", "1", "\n", "\n", "## VAE Step", "\n", "disc_model", ".", "eval", "(", ")", "\n", "vae_model", ".", "train", "(", ")", "\n", "labeled_imgs", ",", "labels", "=", "next", "(", "labeled_data", ")", "\n", "unlabeled_imgs", "=", "next", "(", "unlabeled_data", ")", "\n", "\n", "labeled_imgs", "=", "labeled_imgs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "unlabeled_imgs", "=", "unlabeled_imgs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "\n", "labeled_imgs", "=", "labeled_imgs", ".", "cuda", "(", ")", "\n", "unlabeled_imgs", "=", "unlabeled_imgs", ".", "cuda", "(", ")", "\n", "\n", "recon", ",", "z", ",", "mu", ",", "logvar", "=", "vae_model", "(", "labeled_imgs", ")", "\n", "recon", "=", "recon", ".", "view", "(", "(", "labeled_imgs", ".", "shape", "[", "0", "]", ",", "labeled_imgs", ".", "shape", "[", "1", "]", ",", "labeled_imgs", ".", "shape", "[", "2", "]", ",", "labeled_imgs", ".", "shape", "[", "3", "]", ")", ")", "\n", "unsup_loss", "=", "vae_loss", "(", "labeled_imgs", ",", "recon", ",", "mu", ",", "logvar", ",", "cfg", ".", "VAAL", ".", "BETA", ")", "\n", "unlab_recon", ",", "unlab_z", ",", "unlab_mu", ",", "unlab_logvar", "=", "vae_model", "(", "unlabeled_imgs", ")", "\n", "unlab_recon", "=", "unlab_recon", ".", "view", "(", "(", "unlabeled_imgs", ".", "shape", "[", "0", "]", ",", "unlabeled_imgs", ".", "shape", "[", "1", "]", ",", "unlabeled_imgs", ".", "shape", "[", "2", "]", ",", "unlabeled_imgs", ".", "shape", "[", "3", "]", ")", ")", "\n", "transductive_loss", "=", "vae_loss", "(", "unlabeled_imgs", ",", "unlab_recon", ",", "unlab_mu", ",", "unlab_logvar", ",", "cfg", ".", "VAAL", ".", "BETA", ")", "\n", "\n", "labeled_preds", "=", "disc_model", "(", "mu", ")", "\n", "unlabeled_preds", "=", "disc_model", "(", "unlab_mu", ")", "\n", "\n", "lab_real_preds", "=", "torch", ".", "ones", "(", "labeled_imgs", ".", "size", "(", "0", ")", ",", "1", ")", ".", "cuda", "(", ")", "\n", "unlab_real_preds", "=", "torch", ".", "ones", "(", "unlabeled_imgs", ".", "size", "(", "0", ")", ",", "1", ")", ".", "cuda", "(", ")", "\n", "dsc_loss", "=", "bce_loss", "(", "labeled_preds", ",", "lab_real_preds", ")", "+", "bce_loss", "(", "unlabeled_preds", ",", "unlab_real_preds", ")", "\n", "\n", "total_vae_loss", "=", "unsup_loss", "+", "transductive_loss", "+", "cfg", ".", "VAAL", ".", "ADVERSARY_PARAM", "*", "dsc_loss", "\n", "\n", "optim_vae", ".", "zero_grad", "(", ")", "\n", "total_vae_loss", ".", "backward", "(", ")", "\n", "optim_vae", ".", "step", "(", ")", "\n", "\n", "##DISC STEP", "\n", "vae_model", ".", "eval", "(", ")", "\n", "disc_model", ".", "train", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "_", ",", "_", ",", "mu", ",", "_", "=", "vae_model", "(", "labeled_imgs", ")", "\n", "_", ",", "_", ",", "unlab_mu", ",", "_", "=", "vae_model", "(", "unlabeled_imgs", ")", "\n", "\n", "", "labeled_preds", "=", "disc_model", "(", "mu", ")", "\n", "unlabeled_preds", "=", "disc_model", "(", "unlab_mu", ")", "\n", "\n", "lab_real_preds", "=", "torch", ".", "ones", "(", "labeled_imgs", ".", "size", "(", "0", ")", ",", "1", ")", ".", "cuda", "(", ")", "\n", "unlab_fake_preds", "=", "torch", ".", "zeros", "(", "unlabeled_imgs", ".", "size", "(", "0", ")", ",", "1", ")", ".", "cuda", "(", ")", "\n", "\n", "dsc_loss", "=", "bce_loss", "(", "labeled_preds", ",", "lab_real_preds", ")", "+", "bce_loss", "(", "unlabeled_preds", ",", "unlab_fake_preds", ")", "\n", "\n", "optim_disc", ".", "zero_grad", "(", ")", "\n", "dsc_loss", ".", "backward", "(", ")", "\n", "optim_disc", ".", "step", "(", ")", "\n", "\n", "\n", "if", "temp_iter", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "\"Epoch[{}],Iteration [{}/{}], VAE Loss: {:.3f}, Disc Loss: {:.4f}\"", ".", "format", "(", "cur_epoch", ",", "temp_iter", ",", "train_iterations", ",", "total_vae_loss", ".", "item", "(", ")", ",", "dsc_loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "", "", "return", "vae_model", ",", "disc_model", ",", "optim_vae", ",", "optim_disc", ",", "curr_vae_disc_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.train_vae_disc": [[147, 221], ["torch.cuda.current_device", "dataObj.getIndexesDataLoader", "dataObj.getIndexesDataLoader", "print", "logger.info", "torch.optim.Adam", "print", "logger.info", "torch.optim.Adam", "print", "logger.info", "print", "logger.info", "vm.VAE.cuda", "vm.Discriminator.cuda", "range", "os.makedirs", "os.path.join", "os.path.join", "torch.save", "torch.save", "pycls.models.vaal_model.VAE", "pycls.models.vaal_model.Discriminator", "pycls.models.vaal_model.VAE", "pycls.models.vaal_model.Discriminator", "vm.VAE.parameters", "vm.Discriminator.parameters", "len", "len", "int", "vaal_util.train_vae_disc_epoch", "vm.VAE.module.state_dict", "vm.VAE.state_dict", "vm.Discriminator.module.state_dict", "vm.Discriminator.state_dict", "torch.optim.Adam.state_dict", "cfg.dump", "torch.optim.Adam.state_dict", "cfg.dump", "print", "print", "int", "int"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.al.vaal_util.train_vae_disc_epoch"], ["", "def", "train_vae_disc", "(", "cfg", ",", "lSet", ",", "uSet", ",", "trainDataset", ",", "dataObj", ",", "debug", "=", "False", ")", ":", "\n", "\n", "    ", "cur_device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "if", "cfg", ".", "DATASET", ".", "NAME", "==", "'MNIST'", ":", "\n", "        ", "vae_model", "=", "vm", ".", "VAE", "(", "cur_device", ",", "z_dim", "=", "cfg", ".", "VAAL", ".", "Z_DIM", ",", "nc", "=", "1", ")", "\n", "disc_model", "=", "vm", ".", "Discriminator", "(", "z_dim", "=", "cfg", ".", "VAAL", ".", "Z_DIM", ")", "\n", "", "else", ":", "\n", "        ", "vae_model", "=", "vm", ".", "VAE", "(", "cur_device", ",", "z_dim", "=", "cfg", ".", "VAAL", ".", "Z_DIM", ")", "\n", "disc_model", "=", "vm", ".", "Discriminator", "(", "z_dim", "=", "cfg", ".", "VAAL", ".", "Z_DIM", ")", "\n", "\n", "\n", "# vae_model = data_parallel_wrapper(vae_model, cur_device, cfg)", "\n", "# disc_model = data_parallel_wrapper(disc_model, cur_device, cfg)", "\n", "\n", "# if cfg.TRAIN.DATASET == \"IMAGENET\":", "\n", "#     lSetLoader = imagenet_loader.construct_loader_no_aug(cfg, indices=lSet, isDistributed=False, isVaalSampling=True)", "\n", "#     uSetLoader = imagenet_loader.construct_loader_no_aug(cfg, indices=uSet, isDistributed=False, isVaalSampling=True)", "\n", "# else:", "\n", "", "lSetLoader", "=", "dataObj", ".", "getIndexesDataLoader", "(", "indexes", "=", "lSet", ",", "batch_size", "=", "int", "(", "cfg", ".", "VAAL", ".", "VAE_BS", ")", ",", "data", "=", "trainDataset", ")", "\n", "\n", "uSetLoader", "=", "dataObj", ".", "getIndexesDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "int", "(", "cfg", ".", "VAAL", ".", "VAE_BS", ")", ",", "data", "=", "trainDataset", ")", "\n", "\n", "print", "(", "\"Initializing VAE and discriminator\"", ")", "\n", "logger", ".", "info", "(", "\"Initializing VAE and discriminator\"", ")", "\n", "optim_vae", "=", "torch", ".", "optim", ".", "Adam", "(", "vae_model", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", ".", "VAAL", ".", "VAE_LR", ")", "\n", "print", "(", "f\"VAE Optimizer ==> {optim_vae}\"", ")", "\n", "logger", ".", "info", "(", "f\"VAE Optimizer ==> {optim_vae}\"", ")", "\n", "optim_disc", "=", "torch", ".", "optim", ".", "Adam", "(", "disc_model", ".", "parameters", "(", ")", ",", "lr", "=", "cfg", ".", "VAAL", ".", "DISC_LR", ")", "\n", "print", "(", "f\"Disc Optimizer ==> {optim_disc}\"", ")", "\n", "logger", ".", "info", "(", "f\"Disc Optimizer ==> {optim_disc}\"", ")", "\n", "print", "(", "\"==================================\"", ")", "\n", "logger", ".", "info", "(", "\"==================================\\n\"", ")", "\n", "\n", "n_lu_points", "=", "len", "(", "lSet", ")", "+", "len", "(", "uSet", ")", "\n", "max_vae_disc_iters", "=", "int", "(", "n_lu_points", "/", "cfg", ".", "VAAL", ".", "VAE_BS", ")", "*", "cfg", ".", "VAAL", ".", "VAE_EPOCHS", "\n", "change_lr_iter", "=", "max_vae_disc_iters", "//", "25", "\n", "curr_vae_disc_iter", "=", "0", "\n", "\n", "vae_model", "=", "vae_model", ".", "cuda", "(", ")", "\n", "disc_model", "=", "disc_model", ".", "cuda", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "cfg", ".", "VAAL", ".", "VAE_EPOCHS", ")", ":", "\n", "        ", "vae_model", ",", "disc_model", ",", "optim_vae", ",", "optim_disc", ",", "curr_vae_disc_iter", "=", "train_vae_disc_epoch", "(", "cfg", ",", "vae_model", ",", "disc_model", ",", "optim_vae", ",", "optim_disc", ",", "lSetLoader", ",", "uSetLoader", ",", "epoch", ",", "n_lu_points", ",", "curr_vae_disc_iter", ",", "max_vae_disc_iters", ",", "change_lr_iter", ")", "\n", "\n", "#Save vae and disc models", "\n", "", "vae_sd", "=", "vae_model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "vae_model", ".", "state_dict", "(", ")", "\n", "disc_sd", "=", "disc_model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "disc_model", ".", "state_dict", "(", ")", "\n", "# Record the state", "\n", "vae_checkpoint", "=", "{", "\n", "'epoch'", ":", "cfg", ".", "VAAL", ".", "VAE_EPOCHS", "+", "1", ",", "\n", "'model_state'", ":", "vae_sd", ",", "\n", "'optimizer_state'", ":", "optim_vae", ".", "state_dict", "(", ")", ",", "\n", "'cfg'", ":", "cfg", ".", "dump", "(", ")", "\n", "}", "\n", "disc_checkpoint", "=", "{", "\n", "'epoch'", ":", "cfg", ".", "VAAL", ".", "VAE_EPOCHS", "+", "1", ",", "\n", "'model_state'", ":", "disc_sd", ",", "\n", "'optimizer_state'", ":", "optim_disc", ".", "state_dict", "(", ")", ",", "\n", "'cfg'", ":", "cfg", ".", "dump", "(", ")", "\n", "}", "\n", "# Write the checkpoint", "\n", "os", ".", "makedirs", "(", "cfg", ".", "EPISODE_DIR", ",", "exist_ok", "=", "True", ")", "\n", "vae_checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EPISODE_DIR", ",", "\"vae.pyth\"", ")", "\n", "disc_checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EPISODE_DIR", ",", "\"disc.pyth\"", ")", "\n", "torch", ".", "save", "(", "vae_checkpoint", ",", "vae_checkpoint_file", ")", "\n", "torch", ".", "save", "(", "disc_checkpoint", ",", "disc_checkpoint_file", ")", "\n", "\n", "if", "debug", ":", "print", "(", "\"Saved VAE model at {}\"", ".", "format", "(", "vae_checkpoint_file", ")", ")", "\n", "if", "debug", ":", "print", "(", "\"Saved DISC model at {}\"", ".", "format", "(", "disc_checkpoint_file", ")", ")", "\n", "\n", "return", "vae_model", ",", "disc_model", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.__init__": [[7, 19], ["prob_cover.ProbCover.load_features", "numpy.concatenate().astype", "prob_cover.ProbCover.construct_graph", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.load_features", "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.construct_graph"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "lSet", ",", "uSet", ",", "budgetSize", ",", "delta", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "ds_name", "=", "self", ".", "cfg", "[", "'DATASET'", "]", "[", "'NAME'", "]", "\n", "self", ".", "seed", "=", "self", ".", "cfg", "[", "'RNG_SEED'", "]", "\n", "self", ".", "all_features", "=", "self", ".", "load_features", "(", ")", "\n", "self", ".", "lSet", "=", "lSet", "\n", "self", ".", "uSet", "=", "uSet", "\n", "self", ".", "budgetSize", "=", "budgetSize", "\n", "self", ".", "delta", "=", "delta", "\n", "self", ".", "relevant_indices", "=", "np", ".", "concatenate", "(", "[", "self", ".", "lSet", ",", "self", ".", "uSet", "]", ")", ".", "astype", "(", "int", ")", "\n", "self", ".", "rel_features", "=", "self", ".", "all_features", "[", "self", ".", "relevant_indices", "]", "\n", "self", ".", "graph_df", "=", "self", ".", "construct_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.load_features": [[20, 31], ["numpy.load", "numpy.linalg.norm"], "methods", ["None"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "fname_dict", "=", "{", "'CIFAR10'", ":", "f'../../scan/results/cifar-10/pretext/features_seed{self.seed}.npy'", ",", "\n", "'CIFAR100'", ":", "f'../../scan/results/cifar-100/pretext/features_seed{self.seed}.npy'", ",", "\n", "'TINYIMAGENET'", ":", "f'../../scan/results/tiny-imagenet/pretext/features_seed{self.seed}.npy'", ",", "\n", "'IMAGENET50'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "'IMAGENET100'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "'IMAGENET200'", ":", "'../../../dino/runs/trainfeat.pth'", ",", "\n", "}", "\n", "fname", "=", "fname_dict", "[", "self", ".", "ds_name", "]", "\n", "features", "=", "np", ".", "load", "(", "fname", ")", "\n", "return", "features", "/", "np", ".", "linalg", ".", "norm", "(", "features", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.construct_graph": [[32, 63], ["print", "torch.tensor().cuda", "range", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "pandas.DataFrame", "print", "print", "torch.cdist", "torch.cat().numpy.append", "torch.cat().numpy.append", "torch.cat().numpy.append", "torch.tensor", "len", "mask.nonzero", "y.cpu", "dist[].cpu", "torch.cat", "torch.cat", "torch.cat", "x.cpu", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["", "def", "construct_graph", "(", "self", ",", "batch_size", "=", "500", ")", ":", "\n", "        ", "\"\"\"\n        creates a directed graph where:\n        x->y iff l2(x,y) < delta.\n\n        represented by a list of edges (a sparse matrix).\n        stored in a dataframe\n        \"\"\"", "\n", "xs", ",", "ys", ",", "ds", ",", "dlts", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "print", "(", "f'Start constructing graph using delta={self.delta}'", ")", "\n", "# distance computations are done in GPU", "\n", "cuda_feats", "=", "torch", ".", "tensor", "(", "self", ".", "rel_features", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "rel_features", ")", "//", "batch_size", ")", ":", "\n", "# distance comparisons are done in batches to reduce memory consumption", "\n", "            ", "cur_feats", "=", "cuda_feats", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "\n", "dist", "=", "torch", ".", "cdist", "(", "cur_feats", ",", "cuda_feats", ")", "\n", "mask", "=", "dist", "<", "self", ".", "delta", "\n", "# saving edges using indices list - saves memory.", "\n", "x", ",", "y", "=", "mask", ".", "nonzero", "(", ")", ".", "T", "\n", "xs", ".", "append", "(", "x", ".", "cpu", "(", ")", "+", "batch_size", "*", "i", ")", "\n", "ys", ".", "append", "(", "y", ".", "cpu", "(", ")", ")", "\n", "ds", ".", "append", "(", "dist", "[", "mask", "]", ".", "cpu", "(", ")", ")", "\n", "\n", "", "xs", "=", "torch", ".", "cat", "(", "xs", ")", ".", "numpy", "(", ")", "\n", "ys", "=", "torch", ".", "cat", "(", "ys", ")", ".", "numpy", "(", ")", "\n", "ds", "=", "torch", ".", "cat", "(", "ds", ")", ".", "numpy", "(", ")", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "{", "'x'", ":", "xs", ",", "'y'", ":", "ys", ",", "'d'", ":", "ds", "}", ")", "\n", "print", "(", "f'Finished constructing graph using delta={self.delta}'", ")", "\n", "print", "(", "f'Graph contains {len(df)} edges.'", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.al.prob_cover.ProbCover.select_samples": [[64, 101], ["print", "numpy.isin", "prob_cover.ProbCover.graph_df.y[].unique", "range", "numpy.array", "print", "print", "numpy.arange", "numpy.bincount", "print", "numpy.bincount.argmax", "numpy.concatenate", "selected.append", "len", "sorted", "len", "len", "len", "len", "list", "numpy.isin", "len", "numpy.intersect1d", "len", "len", "numpy.bincount.max", "numpy.isin", "set", "set"], "methods", ["None"], ["", "def", "select_samples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        selecting samples using the greedy algorithm.\n        iteratively:\n        - removes incoming edges to all covered samples\n        - selects the sample high the highest out degree (covers most new samples)\n\n        \"\"\"", "\n", "print", "(", "f'Start selecting {self.budgetSize} samples.'", ")", "\n", "selected", "=", "[", "]", "\n", "# removing incoming edges to all covered samples", "\n", "edge_from_seen", "=", "np", ".", "isin", "(", "self", ".", "graph_df", ".", "x", ",", "np", ".", "arange", "(", "len", "(", "self", ".", "lSet", ")", ")", ")", "\n", "covered_samples", "=", "self", ".", "graph_df", ".", "y", "[", "edge_from_seen", "]", ".", "unique", "(", ")", "\n", "cur_df", "=", "self", ".", "graph_df", "[", "(", "~", "np", ".", "isin", "(", "self", ".", "graph_df", ".", "y", ",", "covered_samples", ")", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "budgetSize", ")", ":", "\n", "\n", "            ", "coverage", "=", "len", "(", "covered_samples", ")", "/", "len", "(", "self", ".", "relevant_indices", ")", "\n", "# selecting the sample with the highest degree", "\n", "degrees", "=", "np", ".", "bincount", "(", "cur_df", ".", "x", ",", "minlength", "=", "len", "(", "self", ".", "relevant_indices", ")", ")", "\n", "print", "(", "f'Iteration is {i}.\\tGraph has {len(cur_df)} edges.\\tMax degree is {degrees.max()}.\\tCoverage is {coverage:.3f}'", ")", "\n", "cur", "=", "degrees", ".", "argmax", "(", ")", "\n", "\n", "# removing incoming edges to newly covered samples", "\n", "new_covered_samples", "=", "cur_df", ".", "y", "[", "(", "cur_df", ".", "x", "==", "cur", ")", "]", ".", "values", "\n", "assert", "len", "(", "np", ".", "intersect1d", "(", "covered_samples", ",", "new_covered_samples", ")", ")", "==", "0", ",", "'all samples should be new'", "\n", "cur_df", "=", "cur_df", "[", "(", "~", "np", ".", "isin", "(", "cur_df", ".", "y", ",", "new_covered_samples", ")", ")", "]", "\n", "\n", "covered_samples", "=", "np", ".", "concatenate", "(", "[", "covered_samples", ",", "new_covered_samples", "]", ")", "\n", "selected", ".", "append", "(", "cur", ")", "\n", "\n", "", "assert", "len", "(", "selected", ")", "==", "self", ".", "budgetSize", ",", "'added a different number of samples'", "\n", "activeSet", "=", "self", ".", "relevant_indices", "[", "selected", "]", "\n", "remainSet", "=", "np", ".", "array", "(", "sorted", "(", "list", "(", "set", "(", "self", ".", "uSet", ")", "-", "set", "(", "activeSet", ")", ")", ")", ")", "\n", "\n", "print", "(", "f'Finished the selection of {len(activeSet)} samples.'", ")", "\n", "print", "(", "f'Active set is {activeSet}'", ")", "\n", "return", "activeSet", ",", "remainSet", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.add_path": [[12, 15], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.argparser": [[43, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Active Learning - Image Classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "help", "=", "'Config file'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-name'", ",", "dest", "=", "'exp_name'", ",", "help", "=", "'Experiment Name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.plot_arrays": [[50, 65], ["plt.xlabel", "plt.ylabel", "plt.title", "plt.plot", "plt.savefig", "plt.close", "print", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "plot_arrays", "(", "x_vals", ",", "y_vals", ",", "x_name", ",", "y_name", ",", "dataset_name", ",", "out_dir", ",", "isDebug", "=", "False", ")", ":", "\n", "# if not du.is_master_proc():", "\n", "#     return", "\n", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "temp_name", "=", "\"{}_vs_{}\"", ".", "format", "(", "x_name", ",", "y_name", ")", "\n", "plt", ".", "xlabel", "(", "x_name", ")", "\n", "plt", ".", "ylabel", "(", "y_name", ")", "\n", "plt", ".", "title", "(", "\"Dataset: {}; {}\"", ".", "format", "(", "dataset_name", ",", "temp_name", ")", ")", "\n", "plt", ".", "plot", "(", "x_vals", ",", "y_vals", ")", "\n", "\n", "if", "isDebug", ":", "print", "(", "\"plot_saved at : {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "'.png'", ")", ")", ")", "\n", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "\".png\"", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.save_plot_values": [[66, 88], ["range", "len", "numpy.array", "os.path.exists", "os.makedirs", "numpy.savetxt", "numpy.save"], "function", ["None"], ["", "def", "save_plot_values", "(", "temp_arrays", ",", "temp_names", ",", "out_dir", ",", "isParallel", "=", "True", ",", "saveInTextFormat", "=", "True", ",", "isDebug", "=", "True", ")", ":", "\n", "\n", "    ", "\"\"\" Saves arrays provided in the list in npy format \"\"\"", "\n", "# Return if not master process", "\n", "# if isParallel:", "\n", "#     if not du.is_master_proc():", "\n", "#         return", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "temp_arrays", ")", ")", ":", "\n", "        ", "temp_arrays", "[", "i", "]", "=", "np", ".", "array", "(", "temp_arrays", "[", "i", "]", ")", "\n", "temp_dir", "=", "out_dir", "\n", "# if cfg.TRAIN.TRANSFER_EXP:", "\n", "#     temp_dir += os.path.join(\"transfer_experiment\",cfg.MODEL.TRANSFER_MODEL_TYPE+\"_depth_\"+str(cfg.MODEL.TRANSFER_MODEL_DEPTH))+\"/\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "temp_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "temp_dir", ")", "\n", "", "if", "saveInTextFormat", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.txt in text format!!\")", "\n", "            ", "np", ".", "savetxt", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".txt\"", ",", "temp_arrays", "[", "i", "]", ",", "fmt", "=", "\"%1.2f\"", ")", "\n", "", "else", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.npy in numpy format!!\")", "\n", "            ", "np", ".", "save", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".npy\"", ",", "temp_arrays", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.is_eval_epoch": [[89, 94], ["None"], "function", ["None"], ["", "", "", "def", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Determines if the model should be evaluated at the current epoch.\"\"\"", "\n", "return", "(", "\n", "(", "cur_epoch", "+", "1", ")", "%", "cfg", ".", "TRAIN", ".", "EVAL_PERIOD", "==", "0", "or", "\n", "(", "cur_epoch", "+", "1", ")", "==", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.main": [[97, 289], ["torch.device", "os.path.join", "os.path.join", "os.path.join", "pycls.core.config.dump_cfg", "pycls.setup_logging", "print", "os.path.join", "pycls.datasets.data.Data", "pycls.datasets.data.Data.getDataset", "pycls.datasets.data.Data.getDataset", "print", "logger.info", "pycls.datasets.data.Data.makeLUVSets", "pycls.datasets.data.Data.loadPartitions", "print", "logger.info", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getTestLoader", "range", "print", "logger.info", "print", "logger.info", "range", "torch.cuda.is_available", "numpy.random.randint", "os.path.abspath", "os.path.exists", "os.mkdir", "os.path.exists", "os.makedirs", "datetime.datetime.now", "os.path.exists", "os.mkdir", "print", "print", "os.path.abspath", "models.append", "print", "logger.info", "os.path.join", "print", "logger.info", "range", "print", "logger.info", "numpy.mean", "print", "logger.info", "plot_episode_xvalues.append", "plot_episode_yvalues.append", "ensemble_al.plot_arrays", "ensemble_al.save_plot_values", "print", "logger.info", "pycls.al.ActiveLearning.ActiveLearning", "range", "pycls.al.ActiveLearning.ActiveLearning.sample_from_uSet", "pycls.datasets.data.Data.saveSets", "numpy.append", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "print", "logger.info", "print", "logger.info", "len", "len", "len", "len", "len", "len", "pycls.build_model", "os.path.exists", "os.mkdir", "print", "pycls.construct_optimizer", "print", "logger.info", "os.path.join", "ensemble_al.ensemble_train_model", "best_model_paths.append", "print", "logger.info", "print", "ensemble_al.ensemble_test_model", "test_accs.append", "print", "logger.info", "pycls.datasets.data.Data.saveSet", "pycls.datasets.data.Data.saveSet", "pycls.build_model", "clf_models.append", "round", "pycls.load_checkpoint", "len", "len", "len", "len", "len", "len", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeLUVSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadPartitions", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.al.ActiveLearning.ActiveLearning.sample_from_uSet", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_train_model", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_test_model", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSet", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSet", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "\n", "# Setting up GPU args", "\n", "    ", "use_cuda", "=", "(", "cfg", ".", "NUM_GPUS", ">", "0", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", ",", "'pin_memory'", ":", "cfg", ".", "DATA_LOADER", ".", "PIN_MEMORY", "}", "if", "use_cuda", "else", "{", "}", "\n", "\n", "# Auto assign a RNG_SEED when not supplied a value", "\n", "if", "cfg", ".", "RNG_SEED", "is", "None", ":", "\n", "        ", "cfg", ".", "RNG_SEED", "=", "np", ".", "random", ".", "randint", "(", "100", ")", "\n", "\n", "# Using specific GPU", "\n", "# os.environ['NVIDIA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'", "\n", "# print(\"Using GPU : {}.\\n\".format(cfg.GPU_ID))", "\n", "\n", "# Getting the output directory ready (default is \"/output\")", "\n", "", "cfg", ".", "OUT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "OUT_DIR", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "OUT_DIR", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "OUT_DIR", ")", "\n", "# Create \"DATASET/MODEL TYPE\" specific directory", "\n", "", "dataset_out_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUT_DIR", ",", "cfg", ".", "DATASET", ".", "NAME", ",", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_out_dir", ")", "\n", "# Creating the experiment directory inside the dataset specific directory ", "\n", "# all logs, labeled, unlabeled, validation sets are stroed here ", "\n", "# E.g., output/CIFAR10/resnet18/{timestamp or cfg.EXP_NAME based on arguments passed}", "\n", "", "if", "cfg", ".", "EXP_NAME", "==", "'auto'", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "exp_dir", "=", "f'{now.year}_{now.month}_{now.day}_{now.hour}{now.minute}{now.second}'", "\n", "", "else", ":", "\n", "        ", "exp_dir", "=", "cfg", ".", "EXP_NAME", "\n", "\n", "", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_out_dir", ",", "exp_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "exp_dir", ")", "\n", "print", "(", "\"Experiment Directory is {}.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Experiment Directory Already Exists: {}. Reusing it may lead to loss of old logs in the directory.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "cfg", ".", "EXP_DIR", "=", "exp_dir", "\n", "\n", "# Save the config file in EXP_DIR", "\n", "dump_cfg", "(", "cfg", ")", "\n", "\n", "# Setup Logger", "\n", "lu", ".", "setup_logging", "(", "cfg", ")", "\n", "\n", "# Dataset preparing steps", "\n", "print", "(", "\"\\n======== PREPARING DATA AND MODEL ========\\n\"", ")", "\n", "cfg", ".", "DATASET", ".", "ROOT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "DATASET", ".", "ROOT_DIR", ")", "\n", "data_obj", "=", "Data", "(", "cfg", ")", "\n", "train_data", ",", "train_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "True", ",", "isDownload", "=", "True", ")", "\n", "test_data", ",", "test_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "False", ",", "isDownload", "=", "True", ")", "\n", "\n", "print", "(", "\"\\nDataset {} Loaded Sucessfully.\\nTotal Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "logger", ".", "info", "(", "\"Dataset {} Loaded Sucessfully. Total Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "\n", "lSet_path", ",", "uSet_path", ",", "valSet_path", "=", "data_obj", ".", "makeLUVSets", "(", "train_split_ratio", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "INIT_L_RATIO", ",", "val_split_ratio", "=", "cfg", ".", "DATASET", ".", "VAL_RATIO", ",", "data", "=", "train_data", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ",", "save_dir", "=", "cfg", ".", "EXP_DIR", ")", "\n", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "LSET_PATH", "=", "lSet_path", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "USET_PATH", "=", "uSet_path", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "VALSET_PATH", "=", "valSet_path", "\n", "\n", "lSet", ",", "uSet", ",", "valSet", "=", "data_obj", ".", "loadPartitions", "(", "lSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "LSET_PATH", ",", "uSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "USET_PATH", ",", "valSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "VALSET_PATH", ")", "\n", "\n", "print", "(", "\"Data Partitioning Complete. \\nLabeled Set: {}, Unlabeled Set: {}, Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Labeled Set: {}, Unlabeled Set: {}, Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "\n", "# Preparing dataloaders for initial training", "\n", "lSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "lSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "test_loader", "=", "data_obj", ".", "getTestLoader", "(", "data", "=", "test_data", ",", "test_batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "# Initialize the models", "\n", "num_ensembles", "=", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", "\n", "models", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ensembles", ")", ":", "\n", "        ", "models", ".", "append", "(", "model_builder", ".", "build_model", "(", "cfg", ")", ")", "\n", "", "print", "(", "\"{} ensemble models of type: {}\\n\"", ".", "format", "(", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", ",", "cfg", ".", "ENSEMBLE", ".", "MODEL_TYPE", ")", ")", "\n", "logger", ".", "info", "(", "\"{} ensemble models of type: {}\\n\"", ".", "format", "(", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", ",", "cfg", ".", "ENSEMBLE", ".", "MODEL_TYPE", ")", ")", "\n", "\n", "\n", "\n", "print", "(", "\"Max AL Episodes: {}\\n\"", ".", "format", "(", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ")", ")", "\n", "logger", ".", "info", "(", "\"Max AL Episodes: {}\\n\"", ".", "format", "(", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ")", ")", "\n", "\n", "for", "cur_episode", "in", "range", "(", "0", ",", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", "+", "1", ")", ":", "\n", "\n", "        ", "print", "(", "\"======== EPISODE {} BEGINS ========\\n\"", ".", "format", "(", "cur_episode", ")", ")", "\n", "logger", ".", "info", "(", "\"======== EPISODE {} BEGINS ========\\n\"", ".", "format", "(", "cur_episode", ")", ")", "\n", "\n", "# Creating output directory for the episode", "\n", "episode_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EXP_DIR", ",", "f'episode_{cur_episode}'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "episode_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "episode_dir", ")", "\n", "", "cfg", ".", "EPISODE_DIR", "=", "episode_dir", "\n", "\n", "# Train models", "\n", "print", "(", "\"======== ENSEMBLE TRAINING ========\"", ")", "\n", "logger", ".", "info", "(", "\"======== ENSEMBLE TRAINING ========\"", ")", "\n", "\n", "best_model_paths", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ensembles", ")", ":", "\n", "            ", "print", "(", "\"=== Training ensemble [{}/{}] ===\"", ".", "format", "(", "i", "+", "1", ",", "num_ensembles", ")", ")", "\n", "\n", "# Construct the optimizer", "\n", "optimizer", "=", "optim", ".", "construct_optimizer", "(", "cfg", ",", "models", "[", "i", "]", ")", "\n", "print", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "logger", ".", "info", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "\n", "# Each ensemble gets its own output directory ", "\n", "cfg", ".", "EPISODE_DIR", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EPISODE_DIR", ",", "'model_{}'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "\n", "# Train the model", "\n", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "=", "ensemble_train_model", "(", "lSet_loader", ",", "valSet_loader", ",", "models", "[", "i", "]", ",", "optimizer", ",", "cfg", ")", "\n", "best_model_paths", ".", "append", "(", "checkpoint_file", ")", "\n", "\n", "print", "(", "\"Best Validation Accuracy by Model {}: {}\\nBest Epoch: {}\\n\"", ".", "format", "(", "i", "+", "1", ",", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\"EPISODE {} Best Validation Accuracy by Model {}: {}\\tBest Epoch: {}\\n\"", ".", "format", "(", "cur_episode", ",", "i", "+", "1", ",", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "\n", "# Test the model", "\n", "print", "(", "\"=== Testing ensemble [{}/{}] ===\"", ".", "format", "(", "i", "+", "1", ",", "num_ensembles", ")", ")", "\n", "test_acc", "=", "ensemble_test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "\n", "print", "(", "\"Test Accuracy by Model {}: {}.\\n\"", ".", "format", "(", "i", "+", "1", ",", "round", "(", "test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EPISODE {} Test Accuracy by Model {}: {}.\\n\"", ".", "format", "(", "cur_episode", ",", "i", "+", "1", ",", "test_acc", ")", ")", "\n", "\n", "# Reset EPISODE_DIR", "\n", "cfg", ".", "EPISODE_DIR", "=", "episode_dir", "\n", "\n", "# Test each best model checkpoint and report the average ", "\n", "", "print", "(", "\"======== ENSEMBLE TESTING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== ENSEMBLE TESTING ========\\n\"", ")", "\n", "mean_test_acc", "=", "np", ".", "mean", "(", "test_accs", ")", "\n", "print", "(", "\"Average Ensemble Test Accuracy: {}.\\n\"", ".", "format", "(", "round", "(", "mean_test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EPISODE {} Average Ensemble Test Accuracy: {}.\\n\"", ".", "format", "(", "cur_episode", ",", "mean_test_acc", ")", ")", "\n", "\n", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "plot_episode_xvalues", ".", "append", "(", "cur_episode", ")", "\n", "plot_episode_yvalues", ".", "append", "(", "mean_test_acc", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_episode_xvalues", ",", "y_vals", "=", "plot_episode_yvalues", ",", "x_name", "=", "\"Episodes\"", ",", "y_name", "=", "\"Test Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EXP_DIR", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_episode_xvalues", ",", "plot_episode_yvalues", "]", ",", "[", "\"plot_episode_xvalues\"", ",", "\"plot_episode_yvalues\"", "]", ",", "out_dir", "=", "cfg", ".", "EXP_DIR", ",", "saveInTextFormat", "=", "True", ")", "\n", "\n", "\n", "# No need to perform active sampling in the last episode iteration", "\n", "if", "cur_episode", "==", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ":", "\n", "# Save lSet, uSet in the final episode directory", "\n", "            ", "data_obj", ".", "saveSet", "(", "lSet", ",", "'lSet'", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "data_obj", ".", "saveSet", "(", "uSet", ",", "'uSet'", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "break", "\n", "\n", "# Active Sample ", "\n", "", "print", "(", "\"======== ENSEMBLE ACTIVE SAMPLING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== ENSEMBLE ACTIVE SAMPLING ========\\n\"", ")", "\n", "al_obj", "=", "ActiveLearning", "(", "data_obj", ",", "cfg", ")", "\n", "clf_models", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ensembles", ")", ":", "\n", "            ", "temp", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "clf_models", ".", "append", "(", "cu", ".", "load_checkpoint", "(", "best_model_paths", "[", "i", "]", ",", "temp", ")", ")", "\n", "\n", "", "activeSet", ",", "new_uSet", "=", "al_obj", ".", "sample_from_uSet", "(", "None", ",", "lSet", ",", "uSet", ",", "train_data", ",", "supportingModels", "=", "clf_models", ")", "\n", "\n", "# Save current lSet, new_uSet and activeSet in the episode directory", "\n", "data_obj", ".", "saveSets", "(", "lSet", ",", "uSet", ",", "activeSet", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "# Add activeSet to lSet, save new_uSet as uSet and update dataloader for the next episode", "\n", "lSet", "=", "np", ".", "append", "(", "lSet", ",", "activeSet", ")", "\n", "uSet", "=", "new_uSet", "\n", "\n", "lSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "lSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "\n", "print", "(", "\"Ensemble Active Sampling Complete. After Episode {}:\\nNew Labeled Set: {}, New Unlabeled Set: {}, Active Set: {}\\n\"", ".", "format", "(", "cur_episode", ",", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "activeSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Ensemble Active Sampling Complete. After Episode {}:\\nNew Labeled Set: {}, New Unlabeled Set: {}, Active Set: {}\\n\"", ".", "format", "(", "cur_episode", ",", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "activeSet", ")", ")", ")", "\n", "print", "(", "\"================================\\n\\n\"", ")", "\n", "logger", ".", "info", "(", "\"================================\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.ensemble_train_model": [[290, 403], ["pycls.get_loss_fun", "pycls.utils.meters.TrainMeter", "pycls.utils.meters.ValMeter", "logger.info", "range", "pycls.save_checkpoint", "print", "logger.info", "ensemble_al.plot_arrays", "ensemble_al.plot_arrays", "ensemble_al.plot_arrays", "len", "len", "int", "ensemble_al.train_epoch", "ensemble_al.is_eval_epoch", "plot_epoch_xvalues.append", "plot_epoch_yvalues.append", "ensemble_al.save_plot_values", "logger.info", "ensemble_al.plot_arrays", "ensemble_al.plot_arrays", "ensemble_al.save_plot_values", "print", "pycls.compute_precise_bn_stats", "ensemble_al.test_epoch", "val_acc_epochs_x.append", "val_acc_epochs_y.append", "len", "model.eval", "optimizer.state_dict", "model.train", "round", "round", "str", "cu.save_checkpoint.split", "model.module.state_dict", "model.state_dict", "int", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.save_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.train_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.is_eval_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.compute_precise_bn_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "", "def", "ensemble_train_model", "(", "train_loader", ",", "val_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", ":", "\n", "    ", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "start_epoch", "=", "0", "\n", "loss_fun", "=", "losses", ".", "get_loss_fun", "(", ")", "\n", "\n", "# Create meters", "\n", "train_meter", "=", "TrainMeter", "(", "len", "(", "train_loader", ")", ")", "\n", "val_meter", "=", "ValMeter", "(", "len", "(", "val_loader", ")", ")", "\n", "\n", "# Perform the training loop", "\n", "# print(\"Len(train_loader):{}\".format(len(train_loader)))", "\n", "logger", ".", "info", "(", "'Start epoch: {}'", ".", "format", "(", "start_epoch", "+", "1", ")", ")", "\n", "val_set_acc", "=", "0.", "\n", "\n", "temp_best_val_acc", "=", "0.", "\n", "temp_best_val_epoch", "=", "0", "\n", "\n", "# Best checkpoint model and optimizer states", "\n", "best_model_state", "=", "None", "\n", "best_opt_state", "=", "None", "\n", "\n", "val_acc_epochs_x", "=", "[", "]", "\n", "val_acc_epochs_y", "=", "[", "]", "\n", "\n", "clf_train_iterations", "=", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "*", "int", "(", "len", "(", "train_loader", ")", "/", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", "\n", "clf_change_lr_iter", "=", "clf_train_iterations", "//", "25", "\n", "clf_iter_count", "=", "0", "\n", "\n", "for", "cur_epoch", "in", "range", "(", "start_epoch", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ":", "\n", "# Train for one epoch", "\n", "        ", "train_loss", ",", "clf_iter_count", "=", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_train_iterations", ")", "\n", "\n", "# Compute precise BN stats", "\n", "if", "cfg", ".", "BN", ".", "USE_PRECISE_STATS", ":", "\n", "            ", "nu", ".", "compute_precise_bn_stats", "(", "model", ",", "train_loader", ")", "\n", "\n", "\n", "# Model evaluation", "\n", "", "if", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "# Original code[PYCLS] passes on testLoader but we want to compute on val Set", "\n", "            ", "val_loader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "val_set_err", "=", "test_epoch", "(", "val_loader", ",", "model", ",", "val_meter", ",", "cur_epoch", ")", "\n", "val_set_acc", "=", "100.", "-", "val_set_err", "\n", "val_loader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "if", "temp_best_val_acc", "<", "val_set_acc", ":", "\n", "                ", "temp_best_val_acc", "=", "val_set_acc", "\n", "temp_best_val_epoch", "=", "cur_epoch", "+", "1", "\n", "\n", "# Save best model and optimizer state for checkpointing", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_model_state", "=", "model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "model", ".", "state_dict", "(", ")", "\n", "best_opt_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Since we start from 0 epoch", "\n", "", "val_acc_epochs_x", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "val_acc_epochs_y", ".", "append", "(", "val_set_acc", ")", "\n", "\n", "", "plot_epoch_xvalues", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "plot_epoch_yvalues", ".", "append", "(", "train_loss", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "logger", ".", "info", "(", "\"Successfully logged numpy arrays!!\"", ")", "\n", "\n", "# Plot arrays", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "print", "(", "'Training Epoch: {}/{}\\tTrain Loss: {}\\tVal Accuracy: {}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "round", "(", "train_loss", ",", "4", ")", ",", "round", "(", "val_set_acc", ",", "4", ")", ")", ")", "\n", "\n", "# Save the best model checkpoint (Episode level)", "\n", "", "checkpoint_file", "=", "cu", ".", "save_checkpoint", "(", "info", "=", "\"vlBest_acc_\"", "+", "str", "(", "int", "(", "temp_best_val_acc", ")", ")", ",", "model_state", "=", "best_model_state", ",", "optimizer_state", "=", "best_opt_state", ",", "epoch", "=", "temp_best_val_epoch", ",", "cfg", "=", "cfg", ")", "\n", "\n", "print", "(", "'\\nWrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", ")", "\n", "logger", ".", "info", "(", "'Wrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ")", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_epoch_xvalues", "=", "[", "]", "\n", "plot_epoch_yvalues", "=", "[", "]", "\n", "plot_it_x_values", "=", "[", "]", "\n", "plot_it_y_values", "=", "[", "]", "\n", "\n", "best_val_acc", "=", "temp_best_val_acc", "\n", "best_val_epoch", "=", "temp_best_val_epoch", "\n", "\n", "return", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.ensemble_test_model": [[405, 416], ["pycls.utils.meters.TestMeter", "pycls.build_model", "pycls.load_checkpoint", "ensemble_al.test_epoch", "len", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "ensemble_test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", ":", "\n", "\n", "    ", "test_meter", "=", "TestMeter", "(", "len", "(", "test_loader", ")", ")", "\n", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "model", ")", "\n", "\n", "test_err", "=", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_episode", ")", "\n", "test_acc", "=", "100.", "-", "test_err", "\n", "\n", "return", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.train_epoch": [[418, 495], ["pycls.get_epoch_lr", "torch.cuda.is_available", "model.train", "train_meter.iter_tic", "len", "enumerate", "train_meter.log_epoch_stats", "train_meter.reset", "train_loader.sampler.set_epoch", "pycls.set_lr", "model.cuda", "inputs.type.type", "model", "loss_fun", "optimizer.zero_grad", "loss_fun.backward", "optimizer.step", "pycls.topk_errors", "train_meter.iter_toc", "train_meter.update_stats", "train_meter.log_iter_stats", "train_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "loss_fun.item", "top1_err.item", "plot_it_x_values.append", "plot_it_y_values.append", "ensemble_al.save_plot_values", "ensemble_al.plot_arrays", "print", "len", "inputs.type.size", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.set_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays"], ["", "def", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_max_iter", ")", ":", "\n", "    ", "\"\"\"Performs one epoch of training.\"\"\"", "\n", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "# Shuffle the data", "\n", "#loader.shuffle(train_loader, cur_epoch)", "\n", "if", "cfg", ".", "NUM_GPUS", ">", "1", ":", "train_loader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "# Update the learning rate", "\n", "# Currently we only support LR schedules for only 'SGD' optimizer", "\n", "lr", "=", "optim", ".", "get_epoch_lr", "(", "cfg", ",", "cur_epoch", ")", "\n", "if", "cfg", ".", "OPTIM", ".", "TYPE", "==", "\"sgd\"", ":", "\n", "        ", "optim", ".", "set_lr", "(", "optimizer", ",", "lr", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "#This basically notes the start time in timer class defined in utils/timer.py", "\n", "\n", "len_train_loader", "=", "len", "(", "train_loader", ")", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "#ensuring that inputs are floatTensor as model weights are", "\n", "        ", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# Perform the forward pass", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the loss", "\n", "loss", "=", "loss_fun", "(", "preds", ",", "labels", ")", "\n", "# Perform the backward pass", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update the parametersSWA", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the stats across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     #Average error and losses across GPUs", "\n", "#     #Also this this calls wait method on reductions so we are ensured", "\n", "#     #to obtain synchronized results", "\n", "#     loss, top1_err = du.scaled_all_reduce(", "\n", "#         [loss, top1_err]", "\n", "#     )", "\n", "# Copy the stats from GPU to CPU (sync point)", "\n", "loss", ",", "top1_err", "=", "loss", ".", "item", "(", ")", ",", "top1_err", ".", "item", "(", ")", "\n", "# #Only master process writes the logs which are used for plotting", "\n", "# if du.is_master_proc():", "\n", "if", "cur_iter", "!=", "0", "and", "cur_iter", "%", "19", "==", "0", ":", "\n", "#because cur_epoch starts with 0", "\n", "            ", "plot_it_x_values", ".", "append", "(", "(", "cur_epoch", ")", "*", "len_train_loader", "+", "cur_iter", ")", "\n", "plot_it_y_values", ".", "append", "(", "loss", ")", "\n", "save_plot_values", "(", "[", "plot_it_x_values", ",", "plot_it_y_values", "]", ",", "[", "\"plot_it_x_values.npy\"", ",", "\"plot_it_y_values.npy\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "# print(plot_it_x_values)", "\n", "# print(plot_it_y_values)", "\n", "#Plot loss graphs", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", ")", "\n", "print", "(", "'Training Epoch: {}/{}\\tIter: {}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "cur_iter", ",", "len", "(", "train_loader", ")", ")", ")", "\n", "\n", "#Compute the difference in time now from start time initialized just before this for loop.", "\n", "", "train_meter", ".", "iter_toc", "(", ")", "\n", "train_meter", ".", "update_stats", "(", "top1_err", "=", "top1_err", ",", "loss", "=", "loss", ",", "lr", "=", "lr", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", ")", "\n", "train_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "train_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "train_meter", ".", "reset", "(", ")", "\n", "return", "loss", ",", "clf_iter_count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_al.test_epoch": [[497, 551], ["torch.no_grad", "torch.cuda.is_available", "model.eval", "test_meter.iter_tic", "enumerate", "test_meter.log_epoch_stats", "test_meter.reset", "model.cuda", "torch.no_grad", "inputs.type.type", "model", "pycls.topk_errors", "top1_err.item.item", "test_meter.iter_toc", "test_meter.update_stats", "test_meter.log_iter_stats", "test_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "inputs.type.size", "inputs.type.size", "inputs.type.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on the test set.\"\"\"", "\n", "\n", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "\n", "misclassifications", "=", "0.", "\n", "totalSamples", "=", "0.", "\n", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Transfer the data to the current GPU device", "\n", "            ", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "# Compute the predictions", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the errors across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     top1_err = du.scaled_all_reduce([top1_err])", "\n", "#     #as above returns a list", "\n", "#     top1_err = top1_err[0]", "\n", "# Copy the errors from GPU to CPU (sync point)", "\n", "top1_err", "=", "top1_err", ".", "item", "(", ")", "\n", "# Multiply by Number of GPU's as top1_err is scaled by 1/Num_GPUs", "\n", "misclassifications", "+=", "top1_err", "*", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "totalSamples", "+=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "test_meter", ".", "iter_toc", "(", ")", "\n", "# Update and log stats", "\n", "test_meter", ".", "update_stats", "(", "\n", "top1_err", "=", "top1_err", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", ")", "\n", "test_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "", "test_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "test_meter", ".", "reset", "(", ")", "\n", "\n", "return", "misclassifications", "/", "totalSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.add_path": [[13, 16], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.argparser": [[29, 34], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Passive Learning - Image Classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "help", "=", "'Config file'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.plot_arrays": [[35, 50], ["plt.xlabel", "plt.ylabel", "plt.title", "plt.plot", "plt.savefig", "plt.close", "print", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "plot_arrays", "(", "x_vals", ",", "y_vals", ",", "x_name", ",", "y_name", ",", "dataset_name", ",", "out_dir", ",", "isDebug", "=", "False", ")", ":", "\n", "# if not du.is_master_proc():", "\n", "#     return", "\n", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "temp_name", "=", "\"{}_vs_{}\"", ".", "format", "(", "x_name", ",", "y_name", ")", "\n", "plt", ".", "xlabel", "(", "x_name", ")", "\n", "plt", ".", "ylabel", "(", "y_name", ")", "\n", "plt", ".", "title", "(", "\"Dataset: {}; {}\"", ".", "format", "(", "dataset_name", ",", "temp_name", ")", ")", "\n", "plt", ".", "plot", "(", "x_vals", ",", "y_vals", ")", "\n", "\n", "if", "isDebug", ":", "print", "(", "\"plot_saved at : {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "'.png'", ")", ")", ")", "\n", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "\".png\"", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.save_plot_values": [[51, 73], ["range", "len", "numpy.array", "os.path.exists", "os.makedirs", "numpy.savetxt", "numpy.save"], "function", ["None"], ["", "def", "save_plot_values", "(", "temp_arrays", ",", "temp_names", ",", "out_dir", ",", "isParallel", "=", "True", ",", "saveInTextFormat", "=", "False", ",", "isDebug", "=", "True", ")", ":", "\n", "\n", "    ", "\"\"\" Saves arrays provided in the list in npy format \"\"\"", "\n", "# Return if not master process", "\n", "# if isParallel:", "\n", "#     if not du.is_master_proc():", "\n", "#         return", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "temp_arrays", ")", ")", ":", "\n", "        ", "temp_arrays", "[", "i", "]", "=", "np", ".", "array", "(", "temp_arrays", "[", "i", "]", ")", "\n", "temp_dir", "=", "out_dir", "\n", "# if cfg.TRAIN.TRANSFER_EXP:", "\n", "#     temp_dir += os.path.join(\"transfer_experiment\",cfg.MODEL.TRANSFER_MODEL_TYPE+\"_depth_\"+str(cfg.MODEL.TRANSFER_MODEL_DEPTH))+\"/\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "temp_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "temp_dir", ")", "\n", "", "if", "saveInTextFormat", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.txt in text format!!\")", "\n", "            ", "np", ".", "savetxt", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".txt\"", ",", "temp_arrays", "[", "i", "]", ",", "fmt", "=", "\"%d\"", ")", "\n", "", "else", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.npy in numpy format!!\")", "\n", "            ", "np", ".", "save", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".npy\"", ",", "temp_arrays", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.is_eval_epoch": [[74, 79], ["None"], "function", ["None"], ["", "", "", "def", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Determines if the model should be evaluated at the current epoch.\"\"\"", "\n", "return", "(", "\n", "(", "cur_epoch", "+", "1", ")", "%", "cfg", ".", "TRAIN", ".", "EVAL_PERIOD", "==", "0", "or", "\n", "(", "cur_epoch", "+", "1", ")", "==", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.main": [[82, 147], ["torch.device", "os.path.join", "os.path.join", "os.path.join", "pycls.core.config.dump_cfg", "pycls.setup_logging", "print", "os.path.join", "pycls.datasets.data.Data", "pycls.datasets.data.Data.getDataset", "print", "logger.info", "pycls.datasets.data.Data.getTestLoader", "print", "logger.info", "test_model.test_model", "print", "logger.info", "print", "print", "logger.info", "torch.cuda.is_available", "os.path.abspath", "os.path.exists", "os.mkdir", "os.path.exists", "os.makedirs", "datetime.datetime.now", "os.path.exists", "os.mkdir", "print", "print", "os.path.abspath", "os.path.join", "os.path.abspath", "round"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.test_model"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "\n", "# Setting up GPU args", "\n", "    ", "use_cuda", "=", "(", "cfg", ".", "NUM_GPUS", ">", "0", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", ",", "'pin_memory'", ":", "cfg", ".", "DATA_LOADER", ".", "PIN_MEMORY", "}", "if", "use_cuda", "else", "{", "}", "\n", "\n", "# Using specific GPU", "\n", "# os.environ['NVIDIA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'", "\n", "# print(\"Using GPU : {}.\\n\".format(cfg.GPU_ID))", "\n", "\n", "# Getting the output directory ready (default is \"/output\")", "\n", "cfg", ".", "OUT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "OUT_DIR", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "OUT_DIR", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "OUT_DIR", ")", "\n", "# Create \"DATASET/MODEL TYPE\" specific directory", "\n", "", "dataset_out_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUT_DIR", ",", "cfg", ".", "DATASET", ".", "NAME", ",", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_out_dir", ")", "\n", "# Creating the experiment directory inside the dataset specific directory ", "\n", "# all logs, labeled, unlabeled, validation sets are stroed here ", "\n", "# E.g., output/CIFAR10/resnet18/{timestamp or cfg.EXP_NAME based on arguments passed}", "\n", "", "if", "cfg", ".", "EXP_NAME", "==", "'auto'", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "exp_dir", "=", "f'{now.year}_{now.month}_{now.day}_{now.hour}{now.minute}{now.second}'", "\n", "", "else", ":", "\n", "        ", "exp_dir", "=", "cfg", ".", "EXP_NAME", "\n", "\n", "", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_out_dir", ",", "exp_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "exp_dir", ")", "\n", "print", "(", "\"Experiment Directory is {}.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Experiment Directory Already Exists: {}. Reusing it may lead to loss of old logs in the directory.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "cfg", ".", "EXP_DIR", "=", "exp_dir", "\n", "\n", "# Save the config file in EXP_DIR", "\n", "dump_cfg", "(", "cfg", ")", "\n", "\n", "# Setup Logger", "\n", "lu", ".", "setup_logging", "(", "cfg", ")", "\n", "\n", "# Dataset preparing steps", "\n", "print", "(", "\"\\n======== PREPARING TEST DATA ========\\n\"", ")", "\n", "cfg", ".", "DATASET", ".", "ROOT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "DATASET", ".", "ROOT_DIR", ")", "\n", "data_obj", "=", "Data", "(", "cfg", ")", "\n", "test_data", ",", "test_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "False", ",", "isDownload", "=", "True", ")", "\n", "\n", "print", "(", "\"\\nDataset {} Loaded Sucessfully. Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "test_size", ")", ")", "\n", "logger", ".", "info", "(", "\"Dataset {} Loaded Sucessfully. Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "test_size", ")", ")", "\n", "\n", "# Preparing dataloaders for testing", "\n", "test_loader", "=", "data_obj", ".", "getTestLoader", "(", "data", "=", "test_data", ",", "test_batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "print", "(", "\"======== TESTING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== TESTING ========\\n\"", ")", "\n", "test_acc", "=", "test_model", "(", "test_loader", ",", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "TEST", ".", "MODEL_PATH", ")", ",", "cfg", ")", "\n", "print", "(", "\"Test Accuracy: {}.\\n\"", ".", "format", "(", "round", "(", "test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy {}.\\n\"", ".", "format", "(", "test_acc", ")", ")", "\n", "\n", "print", "(", "'Check the test accuracy inside {}/stdout.log'", ".", "format", "(", "cfg", ".", "EXP_DIR", ")", ")", "\n", "\n", "print", "(", "\"================================\\n\\n\"", ")", "\n", "logger", ".", "info", "(", "\"================================\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.test_model": [[149, 160], ["pycls.utils.meters.TestMeter", "pycls.build_model", "pycls.load_checkpoint", "test_model.test_epoch", "len", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", "=", "0", ")", ":", "\n", "\n", "    ", "test_meter", "=", "TestMeter", "(", "len", "(", "test_loader", ")", ")", "\n", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "model", ")", "\n", "\n", "test_err", "=", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_episode", ")", "\n", "test_acc", "=", "100.", "-", "test_err", "\n", "\n", "return", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.test_model.test_epoch": [[162, 207], ["torch.no_grad", "torch.cuda.is_available", "model.eval", "test_meter.iter_tic", "enumerate", "test_meter.log_epoch_stats", "test_meter.reset", "model.cuda", "tqdm.tqdm", "torch.no_grad", "inputs.type.type", "model", "pycls.topk_errors", "top1_err.item.item", "test_meter.iter_toc", "test_meter.update_stats", "test_meter.log_iter_stats", "test_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "inputs.type.size", "inputs.type.size", "inputs.type.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on the test set.\"\"\"", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "\n", "misclassifications", "=", "0.", "\n", "totalSamples", "=", "0.", "\n", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "tqdm", "(", "test_loader", ",", "desc", "=", "\"Test Data\"", ")", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Transfer the data to the current GPU device", "\n", "            ", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "# Compute the predictions", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the errors across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     top1_err = du.scaled_all_reduce([top1_err])", "\n", "#     #as above returns a list", "\n", "#     top1_err = top1_err[0]", "\n", "# Copy the errors from GPU to CPU (sync point)", "\n", "top1_err", "=", "top1_err", ".", "item", "(", ")", "\n", "# Multiply by Number of GPU's as top1_err is scaled by 1/Num_GPUs", "\n", "misclassifications", "+=", "top1_err", "*", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "totalSamples", "+=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "test_meter", ".", "iter_toc", "(", ")", "\n", "# Update and log stats", "\n", "test_meter", ".", "update_stats", "(", "\n", "top1_err", "=", "top1_err", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", ")", "\n", "test_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "", "test_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "test_meter", ".", "reset", "(", ")", "\n", "\n", "return", "misclassifications", "/", "totalSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.add_path": [[12, 15], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.argparser": [[39, 44], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Passive Learning - Image Classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "help", "=", "'Config file'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-name'", ",", "dest", "=", "'exp_name'", ",", "help", "=", "'Experiment Name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.plot_arrays": [[45, 60], ["plt.xlabel", "plt.ylabel", "plt.title", "plt.plot", "plt.savefig", "plt.close", "print", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "plot_arrays", "(", "x_vals", ",", "y_vals", ",", "x_name", ",", "y_name", ",", "dataset_name", ",", "out_dir", ",", "isDebug", "=", "False", ")", ":", "\n", "# if not du.is_master_proc():", "\n", "#     return", "\n", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "temp_name", "=", "\"{}_vs_{}\"", ".", "format", "(", "x_name", ",", "y_name", ")", "\n", "plt", ".", "xlabel", "(", "x_name", ")", "\n", "plt", ".", "ylabel", "(", "y_name", ")", "\n", "plt", ".", "title", "(", "\"Dataset: {}; {}\"", ".", "format", "(", "dataset_name", ",", "temp_name", ")", ")", "\n", "plt", ".", "plot", "(", "x_vals", ",", "y_vals", ")", "\n", "\n", "if", "isDebug", ":", "print", "(", "\"plot_saved at : {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "'.png'", ")", ")", ")", "\n", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "\".png\"", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.save_plot_values": [[61, 83], ["range", "len", "numpy.array", "os.path.exists", "os.makedirs", "numpy.savetxt", "numpy.save"], "function", ["None"], ["", "def", "save_plot_values", "(", "temp_arrays", ",", "temp_names", ",", "out_dir", ",", "isParallel", "=", "True", ",", "saveInTextFormat", "=", "False", ",", "isDebug", "=", "True", ")", ":", "\n", "\n", "    ", "\"\"\" Saves arrays provided in the list in npy format \"\"\"", "\n", "# Return if not master process", "\n", "# if isParallel:", "\n", "#     if not du.is_master_proc():", "\n", "#         return", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "temp_arrays", ")", ")", ":", "\n", "        ", "temp_arrays", "[", "i", "]", "=", "np", ".", "array", "(", "temp_arrays", "[", "i", "]", ")", "\n", "temp_dir", "=", "out_dir", "\n", "# if cfg.TRAIN.TRANSFER_EXP:", "\n", "#     temp_dir += os.path.join(\"transfer_experiment\",cfg.MODEL.TRANSFER_MODEL_TYPE+\"_depth_\"+str(cfg.MODEL.TRANSFER_MODEL_DEPTH))+\"/\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "temp_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "temp_dir", ")", "\n", "", "if", "saveInTextFormat", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.txt in text format!!\")", "\n", "            ", "np", ".", "savetxt", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".txt\"", ",", "temp_arrays", "[", "i", "]", ",", "fmt", "=", "\"%d\"", ")", "\n", "", "else", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.npy in numpy format!!\")", "\n", "            ", "np", ".", "save", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".npy\"", ",", "temp_arrays", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.is_eval_epoch": [[84, 89], ["None"], "function", ["None"], ["", "", "", "def", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Determines if the model should be evaluated at the current epoch.\"\"\"", "\n", "return", "(", "\n", "(", "cur_epoch", "+", "1", ")", "%", "cfg", ".", "TRAIN", ".", "EVAL_PERIOD", "==", "0", "or", "\n", "(", "cur_epoch", "+", "1", ")", "==", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.main": [[92, 192], ["torch.device", "os.path.join", "os.path.join", "os.path.join", "pycls.core.config.dump_cfg", "pycls.setup_logging", "print", "os.path.join", "pycls.datasets.data.Data", "pycls.datasets.data.Data.getDataset", "pycls.datasets.data.Data.getDataset", "print", "logger.info", "pycls.datasets.data.Data.makeTVSets", "pycls.datasets.data.Data.loadTVPartitions", "print", "logger.info", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getTestLoader", "pycls.build_model", "print", "logger.info", "pycls.construct_optimizer", "print", "logger.info", "print", "logger.info", "train.train_model", "print", "logger.info", "print", "logger.info", "train.test_model", "print", "logger.info", "print", "logger.info", "torch.cuda.is_available", "numpy.random.randint", "os.path.abspath", "os.path.exists", "os.mkdir", "os.path.exists", "os.makedirs", "datetime.datetime.now", "os.path.exists", "os.mkdir", "print", "print", "os.path.abspath", "len", "len", "len", "len", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeTVSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadTVPartitions", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.train_model", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.test_model"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "\n", "# Setting up GPU args", "\n", "    ", "use_cuda", "=", "(", "cfg", ".", "NUM_GPUS", ">", "0", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", ",", "'pin_memory'", ":", "cfg", ".", "DATA_LOADER", ".", "PIN_MEMORY", "}", "if", "use_cuda", "else", "{", "}", "\n", "\n", "# Auto assign a RNG_SEED when not supplied a value", "\n", "if", "cfg", ".", "RNG_SEED", "is", "None", ":", "\n", "        ", "cfg", ".", "RNG_SEED", "=", "np", ".", "random", ".", "randint", "(", "100", ")", "\n", "\n", "# Using specific GPU", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)", "\n", "# print(\"Using GPU : {}.\\n\".format(cfg.GPU_ID))", "\n", "\n", "# Getting the output directory ready (default is \"/output\")", "\n", "", "cfg", ".", "OUT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "OUT_DIR", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "OUT_DIR", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "OUT_DIR", ")", "\n", "# Create \"DATASET/MODEL TYPE\" specific directory", "\n", "", "dataset_out_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUT_DIR", ",", "cfg", ".", "DATASET", ".", "NAME", ",", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_out_dir", ")", "\n", "# Creating the experiment directory inside the dataset specific directory ", "\n", "# all logs, labeled, unlabeled, validation sets are stroed here ", "\n", "# E.g., output/CIFAR10/resnet18/{timestamp or cfg.EXP_NAME based on arguments passed}", "\n", "", "if", "cfg", ".", "EXP_NAME", "==", "'auto'", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "exp_dir", "=", "f'{now.year}_{now.month}_{now.day}_{now.hour}{now.minute}{now.second}'", "\n", "", "else", ":", "\n", "        ", "exp_dir", "=", "cfg", ".", "EXP_NAME", "\n", "\n", "", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_out_dir", ",", "exp_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "exp_dir", ")", "\n", "print", "(", "\"Experiment Directory is {}.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Experiment Directory Already Exists: {}. Reusing it may lead to loss of old logs in the directory.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "cfg", ".", "EXP_DIR", "=", "exp_dir", "\n", "\n", "# Save the config file in EXP_DIR", "\n", "dump_cfg", "(", "cfg", ")", "\n", "\n", "# Setup Logger", "\n", "lu", ".", "setup_logging", "(", "cfg", ")", "\n", "\n", "# Dataset preparing steps", "\n", "print", "(", "\"\\n======== PREPARING DATA AND MODEL ========\\n\"", ")", "\n", "cfg", ".", "DATASET", ".", "ROOT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "DATASET", ".", "ROOT_DIR", ")", "\n", "data_obj", "=", "Data", "(", "cfg", ")", "\n", "train_data", ",", "train_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "True", ",", "isDownload", "=", "True", ")", "\n", "test_data", ",", "test_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "False", ",", "isDownload", "=", "True", ")", "\n", "\n", "print", "(", "\"\\nDataset {} Loaded Sucessfully.\\nTotal Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "logger", ".", "info", "(", "\"Dataset {} Loaded Sucessfully. Total Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "\n", "trainSet_path", ",", "valSet_path", "=", "data_obj", ".", "makeTVSets", "(", "val_split_ratio", "=", "cfg", ".", "DATASET", ".", "VAL_RATIO", ",", "data", "=", "train_data", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ",", "save_dir", "=", "cfg", ".", "EXP_DIR", ")", "\n", "\n", "trainSet", ",", "valSet", "=", "data_obj", ".", "loadTVPartitions", "(", "trainSetPath", "=", "trainSet_path", ",", "valSetPath", "=", "valSet_path", ")", "\n", "\n", "print", "(", "\"Data Partitioning Complete. \\nTrain Set: {},  Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "trainSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"\\nTrain Set: {},  Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "trainSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "\n", "# Preparing dataloaders for initial training", "\n", "trainSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "trainSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "test_loader", "=", "data_obj", ".", "getTestLoader", "(", "data", "=", "test_data", ",", "test_batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "# Initialize the model.  ", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "print", "(", "\"model: {}\\n\"", ".", "format", "(", "cfg", ".", "MODEL", ".", "TYPE", ")", ")", "\n", "logger", ".", "info", "(", "\"model: {}\\n\"", ".", "format", "(", "cfg", ".", "MODEL", ".", "TYPE", ")", ")", "\n", "\n", "# Construct the optimizer", "\n", "optimizer", "=", "optim", ".", "construct_optimizer", "(", "cfg", ",", "model", ")", "\n", "print", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "logger", ".", "info", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "\n", "# This is to seamlessly use the code originally written for AL episodes ", "\n", "cfg", ".", "EPISODE_DIR", "=", "cfg", ".", "EXP_DIR", "\n", "\n", "# Train model", "\n", "print", "(", "\"======== TRAINING ========\"", ")", "\n", "logger", ".", "info", "(", "\"======== TRAINING ========\"", ")", "\n", "\n", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "=", "train_model", "(", "trainSet_loader", ",", "valSet_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", "\n", "\n", "print", "(", "\"Best Validation Accuracy: {}\\nBest Epoch: {}\\n\"", ".", "format", "(", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\"Best Validation Accuracy: {}\\tBest Epoch: {}\\n\"", ".", "format", "(", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "\n", "# Test best model checkpoint", "\n", "print", "(", "\"======== TESTING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== TESTING ========\\n\"", ")", "\n", "test_acc", "=", "test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", "=", "0", ")", "\n", "print", "(", "\"Test Accuracy: {}.\\n\"", ".", "format", "(", "round", "(", "test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy {}.\\n\"", ".", "format", "(", "test_acc", ")", ")", "\n", "\n", "print", "(", "\"================================\\n\\n\"", ")", "\n", "logger", ".", "info", "(", "\"================================\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.train_model": [[194, 306], ["pycls.get_loss_fun", "pycls.utils.meters.TrainMeter", "pycls.utils.meters.ValMeter", "logger.info", "range", "pycls.save_checkpoint", "print", "logger.info", "train.plot_arrays", "train.plot_arrays", "train.plot_arrays", "len", "len", "int", "train.train_epoch", "train.is_eval_epoch", "plot_epoch_xvalues.append", "plot_epoch_yvalues.append", "train.save_plot_values", "logger.info", "train.plot_arrays", "train.plot_arrays", "train.save_plot_values", "print", "pycls.compute_precise_bn_stats", "train.test_epoch", "val_acc_epochs_x.append", "val_acc_epochs_y.append", "len", "model.eval", "optimizer.state_dict", "model.train", "round", "round", "str", "cu.save_checkpoint.split", "model.module.state_dict", "model.state_dict", "int", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.save_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.train_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.is_eval_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.compute_precise_bn_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "train_model", "(", "train_loader", ",", "val_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", ":", "\n", "    ", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "start_epoch", "=", "0", "\n", "loss_fun", "=", "losses", ".", "get_loss_fun", "(", ")", "\n", "\n", "# Create meters", "\n", "train_meter", "=", "TrainMeter", "(", "len", "(", "train_loader", ")", ")", "\n", "val_meter", "=", "ValMeter", "(", "len", "(", "val_loader", ")", ")", "\n", "\n", "# Perform the training loop", "\n", "# print(\"Len(train_loader):{}\".format(len(train_loader)))", "\n", "logger", ".", "info", "(", "'Start epoch: {}'", ".", "format", "(", "start_epoch", "+", "1", ")", ")", "\n", "val_set_acc", "=", "0.", "\n", "\n", "temp_best_val_acc", "=", "0.", "\n", "temp_best_val_epoch", "=", "0", "\n", "\n", "# Best checkpoint model and optimizer states", "\n", "best_model_state", "=", "None", "\n", "best_opt_state", "=", "None", "\n", "\n", "val_acc_epochs_x", "=", "[", "]", "\n", "val_acc_epochs_y", "=", "[", "]", "\n", "\n", "clf_train_iterations", "=", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "*", "int", "(", "len", "(", "train_loader", ")", "/", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", "\n", "clf_change_lr_iter", "=", "clf_train_iterations", "//", "25", "\n", "clf_iter_count", "=", "0", "\n", "\n", "for", "cur_epoch", "in", "range", "(", "start_epoch", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ":", "\n", "# Train for one epoch", "\n", "        ", "train_loss", ",", "clf_iter_count", "=", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_train_iterations", ")", "\n", "\n", "# Compute precise BN stats", "\n", "if", "cfg", ".", "BN", ".", "USE_PRECISE_STATS", ":", "\n", "            ", "nu", ".", "compute_precise_bn_stats", "(", "model", ",", "train_loader", ")", "\n", "\n", "\n", "# Model evaluation", "\n", "", "if", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "# Original code[PYCLS] passes on testLoader but we want to compute on val Set", "\n", "            ", "val_loader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "val_set_err", "=", "test_epoch", "(", "val_loader", ",", "model", ",", "val_meter", ",", "cur_epoch", ")", "\n", "val_set_acc", "=", "100.", "-", "val_set_err", "\n", "val_loader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "\n", "if", "temp_best_val_acc", "<", "val_set_acc", ":", "\n", "                ", "temp_best_val_acc", "=", "val_set_acc", "\n", "temp_best_val_epoch", "=", "cur_epoch", "+", "1", "\n", "\n", "# Save best model and optimizer state for checkpointing", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_model_state", "=", "model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "model", ".", "state_dict", "(", ")", "\n", "best_opt_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Since we start from 0 epoch", "\n", "", "val_acc_epochs_x", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "val_acc_epochs_y", ".", "append", "(", "val_set_acc", ")", "\n", "\n", "", "plot_epoch_xvalues", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "plot_epoch_yvalues", ".", "append", "(", "train_loss", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "logger", ".", "info", "(", "\"Successfully logged numpy arrays!!\"", ")", "\n", "\n", "# Plot arrays", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "print", "(", "'Training Epoch: {}/{}\\tTrain Loss: {}\\tVal Accuracy: {}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "round", "(", "train_loss", ",", "4", ")", ",", "round", "(", "val_set_acc", ",", "4", ")", ")", ")", "\n", "\n", "# Save the best model checkpoint (Episode level)", "\n", "", "checkpoint_file", "=", "cu", ".", "save_checkpoint", "(", "info", "=", "\"vlBest_acc_\"", "+", "str", "(", "int", "(", "temp_best_val_acc", ")", ")", ",", "model_state", "=", "best_model_state", ",", "optimizer_state", "=", "best_opt_state", ",", "epoch", "=", "temp_best_val_epoch", ",", "cfg", "=", "cfg", ")", "\n", "\n", "print", "(", "'\\nWrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", ")", "\n", "logger", ".", "info", "(", "'Wrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ")", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_epoch_xvalues", "=", "[", "]", "\n", "plot_epoch_yvalues", "=", "[", "]", "\n", "\n", "plot_it_x_values", "=", "[", "]", "\n", "plot_it_y_values", "=", "[", "]", "\n", "\n", "best_val_acc", "=", "temp_best_val_acc", "\n", "best_val_epoch", "=", "temp_best_val_epoch", "\n", "\n", "return", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.test_model": [[308, 325], ["pycls.utils.meters.TestMeter", "pycls.build_model", "pycls.load_checkpoint", "train.test_epoch", "len", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", ":", "\n", "\n", "    ", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "test_meter", "=", "TestMeter", "(", "len", "(", "test_loader", ")", ")", "\n", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "model", ")", "\n", "\n", "test_err", "=", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_episode", ")", "\n", "test_acc", "=", "100.", "-", "test_err", "\n", "\n", "return", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.train_epoch": [[327, 401], ["pycls.get_epoch_lr", "torch.cuda.is_available", "model.train", "train_meter.iter_tic", "len", "enumerate", "train_meter.log_epoch_stats", "train_meter.reset", "train_loader.sampler.set_epoch", "pycls.set_lr", "model.cuda", "inputs.type.type", "model", "loss_fun", "optimizer.zero_grad", "loss_fun.backward", "optimizer.step", "pycls.topk_errors", "train_meter.iter_toc", "train_meter.update_stats", "train_meter.log_iter_stats", "train_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "loss_fun.item", "top1_err.item", "plot_it_x_values.append", "plot_it_y_values.append", "train.save_plot_values", "train.plot_arrays", "print", "len", "inputs.type.size", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.set_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays"], ["", "def", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_max_iter", ")", ":", "\n", "    ", "\"\"\"Performs one epoch of training.\"\"\"", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "# Shuffle the data", "\n", "#loader.shuffle(train_loader, cur_epoch)", "\n", "if", "cfg", ".", "NUM_GPUS", ">", "1", ":", "train_loader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "# Update the learning rate", "\n", "# Currently we only support LR schedules for only 'SGD' optimizer", "\n", "lr", "=", "optim", ".", "get_epoch_lr", "(", "cfg", ",", "cur_epoch", ")", "\n", "if", "cfg", ".", "OPTIM", ".", "TYPE", "==", "\"sgd\"", ":", "\n", "        ", "optim", ".", "set_lr", "(", "optimizer", ",", "lr", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "#This basically notes the start time in timer class defined in utils/timer.py", "\n", "\n", "len_train_loader", "=", "len", "(", "train_loader", ")", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "#ensuring that inputs are floatTensor as model weights are", "\n", "        ", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# Perform the forward pass", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the loss", "\n", "loss", "=", "loss_fun", "(", "preds", ",", "labels", ")", "\n", "# Perform the backward pass", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update the parametersSWA", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the stats across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     #Average error and losses across GPUs", "\n", "#     #Also this this calls wait method on reductions so we are ensured", "\n", "#     #to obtain synchronized results", "\n", "#     loss, top1_err = du.scaled_all_reduce(", "\n", "#         [loss, top1_err]", "\n", "#     )", "\n", "# Copy the stats from GPU to CPU (sync point)", "\n", "loss", ",", "top1_err", "=", "loss", ".", "item", "(", ")", ",", "top1_err", ".", "item", "(", ")", "\n", "# #Only master process writes the logs which are used for plotting", "\n", "# if du.is_master_proc():", "\n", "if", "cur_iter", "!=", "0", "and", "cur_iter", "%", "19", "==", "0", ":", "\n", "#because cur_epoch starts with 0", "\n", "            ", "plot_it_x_values", ".", "append", "(", "(", "cur_epoch", ")", "*", "len_train_loader", "+", "cur_iter", ")", "\n", "plot_it_y_values", ".", "append", "(", "loss", ")", "\n", "save_plot_values", "(", "[", "plot_it_x_values", ",", "plot_it_y_values", "]", ",", "[", "\"plot_it_x_values.npy\"", ",", "\"plot_it_y_values.npy\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "# print(plot_it_x_values)", "\n", "# print(plot_it_y_values)", "\n", "#Plot loss graphs", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", ")", "\n", "print", "(", "'Training Epoch: {}/{}\\tIter: {}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "cur_iter", ",", "len", "(", "train_loader", ")", ")", ")", "\n", "\n", "#Compute the difference in time now from start time initialized just before this for loop.", "\n", "", "train_meter", ".", "iter_toc", "(", ")", "\n", "train_meter", ".", "update_stats", "(", "top1_err", "=", "top1_err", ",", "loss", "=", "loss", ",", "lr", "=", "lr", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", ")", "\n", "train_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "train_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "train_meter", ".", "reset", "(", ")", "\n", "return", "loss", ",", "clf_iter_count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train.test_epoch": [[403, 454], ["torch.no_grad", "torch.cuda.is_available", "model.eval", "test_meter.iter_tic", "enumerate", "test_meter.log_epoch_stats", "test_meter.reset", "model.cuda", "torch.no_grad", "inputs.type.type", "model", "pycls.topk_errors", "top1_err.item.item", "test_meter.iter_toc", "test_meter.update_stats", "test_meter.log_iter_stats", "test_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "inputs.type.size", "inputs.type.size", "inputs.type.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on the test set.\"\"\"", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "\n", "misclassifications", "=", "0.", "\n", "totalSamples", "=", "0.", "\n", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Transfer the data to the current GPU device", "\n", "            ", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "# Compute the predictions", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the errors across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     top1_err = du.scaled_all_reduce([top1_err])", "\n", "#     #as above returns a list", "\n", "#     top1_err = top1_err[0]", "\n", "# Copy the errors from GPU to CPU (sync point)", "\n", "top1_err", "=", "top1_err", ".", "item", "(", ")", "\n", "# Multiply by Number of GPU's as top1_err is scaled by 1/Num_GPUs", "\n", "misclassifications", "+=", "top1_err", "*", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "totalSamples", "+=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "test_meter", ".", "iter_toc", "(", ")", "\n", "# Update and log stats", "\n", "test_meter", ".", "update_stats", "(", "\n", "top1_err", "=", "top1_err", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", ")", "\n", "test_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "", "test_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "test_meter", ".", "reset", "(", ")", "\n", "\n", "return", "misclassifications", "/", "totalSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.add_path": [[12, 15], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.str2bool": [[43, 52], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "        ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.argparser": [[54, 67], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "", "def", "argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Active Learning - Image Classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "help", "=", "'Config file'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-name'", ",", "help", "=", "'Experiment Name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--al'", ",", "help", "=", "'AL Method'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--budget'", ",", "help", "=", "'Budget Per Round'", ",", "required", "=", "True", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_size'", ",", "help", "=", "'Size of the initial random labeled set'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'Random seed'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune'", ",", "help", "=", "'Whether to continue with existing model between rounds'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--linear_from_features'", ",", "help", "=", "'Whether to use a linear layer from self-supervised features'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--delta'", ",", "help", "=", "'Relevant only for ProbCover'", ",", "default", "=", "0.6", ",", "type", "=", "float", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.is_eval_epoch": [[69, 74], ["None"], "function", ["None"], ["", "def", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Determines if the model should be evaluated at the current epoch.\"\"\"", "\n", "return", "(", "\n", "(", "cur_epoch", "+", "1", ")", "%", "cfg", ".", "TRAIN", ".", "EVAL_PERIOD", "==", "0", "or", "\n", "(", "cur_epoch", "+", "1", ")", "==", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.main": [[77, 247], ["torch.device", "os.path.join", "os.path.join", "os.path.join", "pycls.core.config.dump_cfg", "pycls.setup_logging", "print", "os.path.join", "pycls.datasets.data.Data", "pycls.datasets.data.Data.getDataset", "pycls.datasets.data.Data.getDataset", "print", "logger.info", "pycls.datasets.data.Data.makeLUVSets", "pycls.datasets.data.Data.loadPartitions", "pycls.build_model().cuda", "print", "logger.info", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getTestLoader", "pycls.build_model", "print", "logger.info", "pycls.construct_optimizer", "copy.deepcopy", "copy.deepcopy", "print", "logger.info", "print", "logger.info", "range", "torch.cuda.is_available", "numpy.random.randint", "os.path.abspath", "os.path.exists", "os.mkdir", "os.path.exists", "os.makedirs", "datetime.datetime.now", "os.path.exists", "os.mkdir", "print", "print", "os.path.abspath", "len", "print", "pycls.al.ActiveLearning.ActiveLearning", "pycls.al.ActiveLearning.ActiveLearning.sample_from_uSet", "print", "numpy.append", "optim.construct_optimizer.state_dict", "model_builder.build_model.state_dict().copy", "print", "logger.info", "os.path.join", "print", "logger.info", "train_al.train_model", "print", "logger.info", "print", "logger.info", "train_al.test_model", "print", "logger.info", "print", "logger.info", "pycls.al.ActiveLearning.ActiveLearning", "pycls.build_model", "pycls.load_checkpoint", "pycls.al.ActiveLearning.ActiveLearning.sample_from_uSet", "pycls.datasets.data.Data.saveSets", "numpy.append", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getSequentialDataLoader", "print", "logger.info", "print", "logger.info", "os.remove", "pycls.build_model", "len", "len", "len", "len", "len", "len", "os.path.exists", "os.mkdir", "pycls.datasets.data.Data.saveSet", "pycls.datasets.data.Data.saveSet", "print", "pycls.build_model", "pycls.construct_optimizer", "print", "print", "model_builder.build_model.state_dict", "round", "round", "round", "len", "len", "len", "len", "len", "len", "model_builder.build_model.load_state_dict", "optim.construct_optimizer.load_state_dict"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeLUVSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadPartitions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.al.ActiveLearning.ActiveLearning.sample_from_uSet", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.train_model", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.test_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.al.ActiveLearning.ActiveLearning.sample_from_uSet", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getSequentialDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSet", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.saveSet", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "\n", "# Setting up GPU args", "\n", "    ", "use_cuda", "=", "(", "cfg", ".", "NUM_GPUS", ">", "0", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", ",", "'pin_memory'", ":", "cfg", ".", "DATA_LOADER", ".", "PIN_MEMORY", "}", "if", "use_cuda", "else", "{", "}", "\n", "\n", "# Auto assign a RNG_SEED when not supplied a value", "\n", "if", "cfg", ".", "RNG_SEED", "is", "None", ":", "\n", "        ", "cfg", ".", "RNG_SEED", "=", "np", ".", "random", ".", "randint", "(", "100", ")", "\n", "\n", "# Using specific GPU", "\n", "# os.environ['NVIDIA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'", "\n", "# print(\"Using GPU : {}.\\n\".format(cfg.GPU_ID))", "\n", "\n", "# Getting the output directory ready (default is \"/output\")", "\n", "", "cfg", ".", "OUT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "OUT_DIR", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "OUT_DIR", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "OUT_DIR", ")", "\n", "# Create \"DATASET/MODEL TYPE\" specific directory", "\n", "", "dataset_out_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUT_DIR", ",", "cfg", ".", "DATASET", ".", "NAME", ",", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_out_dir", ")", "\n", "# Creating the experiment directory inside the dataset specific directory ", "\n", "# all logs, labeled, unlabeled, validation sets are stroed here ", "\n", "# E.g., output/CIFAR10/resnet18/{timestamp or cfg.EXP_NAME based on arguments passed}", "\n", "", "if", "cfg", ".", "EXP_NAME", "==", "'auto'", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "exp_dir", "=", "f'{now.year}_{now.month}_{now.day}_{now.hour}{now.minute}{now.second}'", "\n", "", "else", ":", "\n", "        ", "exp_dir", "=", "cfg", ".", "EXP_NAME", "\n", "\n", "", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_out_dir", ",", "exp_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "exp_dir", ")", "\n", "print", "(", "\"Experiment Directory is {}.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Experiment Directory Already Exists: {}. Reusing it may lead to loss of old logs in the directory.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "cfg", ".", "EXP_DIR", "=", "exp_dir", "\n", "\n", "# Save the config file in EXP_DIR", "\n", "dump_cfg", "(", "cfg", ")", "\n", "\n", "# Setup Logger", "\n", "lu", ".", "setup_logging", "(", "cfg", ")", "\n", "\n", "# Dataset preparing steps", "\n", "print", "(", "\"\\n======== PREPARING DATA AND MODEL ========\\n\"", ")", "\n", "cfg", ".", "DATASET", ".", "ROOT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "DATASET", ".", "ROOT_DIR", ")", "\n", "data_obj", "=", "Data", "(", "cfg", ")", "\n", "train_data", ",", "train_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "True", ",", "isDownload", "=", "True", ")", "\n", "test_data", ",", "test_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "False", ",", "isDownload", "=", "True", ")", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "INIT_L_RATIO", "=", "args", ".", "initial_size", "/", "train_size", "\n", "print", "(", "\"\\nDataset {} Loaded Sucessfully.\\nTotal Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "logger", ".", "info", "(", "\"Dataset {} Loaded Sucessfully. Total Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "\n", "lSet_path", ",", "uSet_path", ",", "valSet_path", "=", "data_obj", ".", "makeLUVSets", "(", "train_split_ratio", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "INIT_L_RATIO", ",", "val_split_ratio", "=", "cfg", ".", "DATASET", ".", "VAL_RATIO", ",", "data", "=", "train_data", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ",", "save_dir", "=", "cfg", ".", "EXP_DIR", ")", "\n", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "LSET_PATH", "=", "lSet_path", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "USET_PATH", "=", "uSet_path", "\n", "cfg", ".", "ACTIVE_LEARNING", ".", "VALSET_PATH", "=", "valSet_path", "\n", "\n", "lSet", ",", "uSet", ",", "valSet", "=", "data_obj", ".", "loadPartitions", "(", "lSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "LSET_PATH", ",", "uSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "USET_PATH", ",", "valSetPath", "=", "cfg", ".", "ACTIVE_LEARNING", ".", "VALSET_PATH", ")", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", ".", "cuda", "(", ")", "\n", "if", "len", "(", "lSet", ")", "==", "0", ":", "\n", "        ", "print", "(", "'Labeled Set is Empty - Sampling an Initial Pool'", ")", "\n", "al_obj", "=", "ActiveLearning", "(", "data_obj", ",", "cfg", ")", "\n", "activeSet", ",", "new_uSet", "=", "al_obj", ".", "sample_from_uSet", "(", "model", ",", "lSet", ",", "uSet", ",", "train_data", ")", "\n", "print", "(", "f'Initial Pool is {activeSet}'", ")", "\n", "# Save current lSet, new_uSet and activeSet in the episode directory", "\n", "# data_obj.saveSets(lSet, uSet, activeSet, cfg.EPISODE_DIR)", "\n", "# Add activeSet to lSet, save new_uSet as uSet and update dataloader for the next episode", "\n", "lSet", "=", "np", ".", "append", "(", "lSet", ",", "activeSet", ")", "\n", "uSet", "=", "new_uSet", "\n", "\n", "", "print", "(", "\"Data Partitioning Complete. \\nLabeled Set: {}, Unlabeled Set: {}, Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Labeled Set: {}, Unlabeled Set: {}, Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "\n", "# Preparing dataloaders for initial training", "\n", "lSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "lSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "test_loader", "=", "data_obj", ".", "getTestLoader", "(", "data", "=", "test_data", ",", "test_batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "# Initialize the model.  ", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "print", "(", "\"model: {}\\n\"", ".", "format", "(", "cfg", ".", "MODEL", ".", "TYPE", ")", ")", "\n", "logger", ".", "info", "(", "\"model: {}\\n\"", ".", "format", "(", "cfg", ".", "MODEL", ".", "TYPE", ")", ")", "\n", "\n", "# Construct the optimizer", "\n", "optimizer", "=", "optim", ".", "construct_optimizer", "(", "cfg", ",", "model", ")", "\n", "opt_init_state", "=", "deepcopy", "(", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "model_init_state", "=", "deepcopy", "(", "model", ".", "state_dict", "(", ")", ".", "copy", "(", ")", ")", "\n", "\n", "print", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "logger", ".", "info", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "\n", "print", "(", "\"AL Query Method: {}\\nMax AL Episodes: {}\\n\"", ".", "format", "(", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ",", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ")", ")", "\n", "logger", ".", "info", "(", "\"AL Query Method: {}\\nMax AL Episodes: {}\\n\"", ".", "format", "(", "cfg", ".", "ACTIVE_LEARNING", ".", "SAMPLING_FN", ",", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ")", ")", "\n", "\n", "for", "cur_episode", "in", "range", "(", "0", ",", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", "+", "1", ")", ":", "\n", "\n", "        ", "print", "(", "\"======== EPISODE {} BEGINS ========\\n\"", ".", "format", "(", "cur_episode", ")", ")", "\n", "logger", ".", "info", "(", "\"======== EPISODE {} BEGINS ========\\n\"", ".", "format", "(", "cur_episode", ")", ")", "\n", "\n", "# Creating output directory for the episode", "\n", "episode_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EXP_DIR", ",", "f'episode_{cur_episode}'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "episode_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "episode_dir", ")", "\n", "", "cfg", ".", "EPISODE_DIR", "=", "episode_dir", "\n", "\n", "# Train model", "\n", "print", "(", "\"======== TRAINING ========\"", ")", "\n", "logger", ".", "info", "(", "\"======== TRAINING ========\"", ")", "\n", "\n", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "=", "train_model", "(", "lSet_loader", ",", "valSet_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", "\n", "\n", "print", "(", "\"Best Validation Accuracy: {}\\nBest Epoch: {}\\n\"", ".", "format", "(", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\"EPISODE {} Best Validation Accuracy: {}\\tBest Epoch: {}\\n\"", ".", "format", "(", "cur_episode", ",", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "\n", "# Test best model checkpoint", "\n", "print", "(", "\"======== TESTING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== TESTING ========\\n\"", ")", "\n", "test_acc", "=", "test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", "\n", "print", "(", "\"Test Accuracy: {}.\\n\"", ".", "format", "(", "round", "(", "test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"EPISODE {} Test Accuracy {}.\\n\"", ".", "format", "(", "cur_episode", ",", "test_acc", ")", ")", "\n", "\n", "# No need to perform active sampling in the last episode iteration", "\n", "if", "cur_episode", "==", "cfg", ".", "ACTIVE_LEARNING", ".", "MAX_ITER", ":", "\n", "# Save current lSet, uSet in the final episode directory", "\n", "            ", "data_obj", ".", "saveSet", "(", "lSet", ",", "'lSet'", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "data_obj", ".", "saveSet", "(", "uSet", ",", "'uSet'", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "break", "\n", "\n", "# Active Sample ", "\n", "", "print", "(", "\"======== ACTIVE SAMPLING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== ACTIVE SAMPLING ========\\n\"", ")", "\n", "al_obj", "=", "ActiveLearning", "(", "data_obj", ",", "cfg", ")", "\n", "clf_model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "clf_model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "clf_model", ")", "\n", "activeSet", ",", "new_uSet", "=", "al_obj", ".", "sample_from_uSet", "(", "clf_model", ",", "lSet", ",", "uSet", ",", "train_data", ")", "\n", "\n", "# Save current lSet, new_uSet and activeSet in the episode directory", "\n", "data_obj", ".", "saveSets", "(", "lSet", ",", "uSet", ",", "activeSet", ",", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "# Add activeSet to lSet, save new_uSet as uSet and update dataloader for the next episode", "\n", "lSet", "=", "np", ".", "append", "(", "lSet", ",", "activeSet", ")", "\n", "uSet", "=", "new_uSet", "\n", "\n", "lSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "lSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "uSet_loader", "=", "data_obj", ".", "getSequentialDataLoader", "(", "indexes", "=", "uSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "\n", "print", "(", "\"Active Sampling Complete. After Episode {}:\\nNew Labeled Set: {}, New Unlabeled Set: {}, Active Set: {}\\n\"", ".", "format", "(", "cur_episode", ",", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "activeSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Active Sampling Complete. After Episode {}:\\nNew Labeled Set: {}, New Unlabeled Set: {}, Active Set: {}\\n\"", ".", "format", "(", "cur_episode", ",", "len", "(", "lSet", ")", ",", "len", "(", "uSet", ")", ",", "len", "(", "activeSet", ")", ")", ")", "\n", "print", "(", "\"================================\\n\\n\"", ")", "\n", "logger", ".", "info", "(", "\"================================\\n\\n\"", ")", "\n", "\n", "if", "not", "cfg", ".", "ACTIVE_LEARNING", ".", "FINE_TUNE", ":", "\n", "# start model from scratch", "\n", "            ", "print", "(", "'Starting model from scratch - ignoring existing weights.'", ")", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "# Construct the optimizer", "\n", "optimizer", "=", "optim", ".", "construct_optimizer", "(", "cfg", ",", "model", ")", "\n", "print", "(", "model", ".", "load_state_dict", "(", "model_init_state", ")", ")", "\n", "print", "(", "optimizer", ".", "load_state_dict", "(", "opt_init_state", ")", ")", "\n", "\n", "", "os", ".", "remove", "(", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.train_model": [[250, 364], ["pycls.get_loss_fun", "pycls.utils.meters.TrainMeter", "pycls.utils.meters.ValMeter", "logger.info", "range", "pycls.save_checkpoint", "print", "logger.info", "len", "len", "int", "train_al.train_epoch", "train_al.is_eval_epoch", "plot_epoch_xvalues.append", "plot_epoch_yvalues.append", "logger.info", "print", "pycls.compute_precise_bn_stats", "train_al.test_epoch", "val_acc_epochs_x.append", "val_acc_epochs_y.append", "len", "model.eval", "optimizer.state_dict", "model.train", "round", "round", "str", "cu.save_checkpoint.split", "model.module.state_dict", "model.state_dict", "int", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.save_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.train_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.is_eval_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.compute_precise_bn_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "", "def", "train_model", "(", "train_loader", ",", "val_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", ":", "\n", "    ", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "start_epoch", "=", "0", "\n", "loss_fun", "=", "losses", ".", "get_loss_fun", "(", ")", "\n", "\n", "# Create meters", "\n", "train_meter", "=", "TrainMeter", "(", "len", "(", "train_loader", ")", ")", "\n", "val_meter", "=", "ValMeter", "(", "len", "(", "val_loader", ")", ")", "\n", "\n", "# Perform the training loop", "\n", "# print(\"Len(train_loader):{}\".format(len(train_loader)))", "\n", "logger", ".", "info", "(", "'Start epoch: {}'", ".", "format", "(", "start_epoch", "+", "1", ")", ")", "\n", "val_set_acc", "=", "0.", "\n", "\n", "temp_best_val_acc", "=", "0.", "\n", "temp_best_val_epoch", "=", "0", "\n", "\n", "# Best checkpoint model and optimizer states", "\n", "best_model_state", "=", "None", "\n", "best_opt_state", "=", "None", "\n", "\n", "val_acc_epochs_x", "=", "[", "]", "\n", "val_acc_epochs_y", "=", "[", "]", "\n", "\n", "clf_train_iterations", "=", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "*", "int", "(", "len", "(", "train_loader", ")", "/", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", "\n", "clf_change_lr_iter", "=", "clf_train_iterations", "//", "25", "\n", "clf_iter_count", "=", "0", "\n", "\n", "for", "cur_epoch", "in", "range", "(", "start_epoch", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ":", "\n", "\n", "# Train for one epoch", "\n", "        ", "train_loss", ",", "clf_iter_count", "=", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_train_iterations", ")", "\n", "\n", "# Compute precise BN stats", "\n", "if", "cfg", ".", "BN", ".", "USE_PRECISE_STATS", ":", "\n", "            ", "nu", ".", "compute_precise_bn_stats", "(", "model", ",", "train_loader", ")", "\n", "\n", "\n", "# Model evaluation", "\n", "", "if", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "# Original code[PYCLS] passes on testLoader but we want to compute on val Set", "\n", "            ", "val_loader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "val_set_err", "=", "test_epoch", "(", "val_loader", ",", "model", ",", "val_meter", ",", "cur_epoch", ")", "\n", "val_set_acc", "=", "100.", "-", "val_set_err", "\n", "val_loader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "if", "temp_best_val_acc", "<", "val_set_acc", ":", "\n", "                ", "temp_best_val_acc", "=", "val_set_acc", "\n", "temp_best_val_epoch", "=", "cur_epoch", "+", "1", "\n", "\n", "# Save best model and optimizer state for checkpointing", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_model_state", "=", "model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "model", ".", "state_dict", "(", ")", "\n", "best_opt_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Since we start from 0 epoch", "\n", "", "val_acc_epochs_x", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "val_acc_epochs_y", ".", "append", "(", "val_set_acc", ")", "\n", "\n", "", "plot_epoch_xvalues", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "plot_epoch_yvalues", ".", "append", "(", "train_loss", ")", "\n", "\n", "# save_plot_values([plot_epoch_xvalues, plot_epoch_yvalues, plot_it_x_values, plot_it_y_values, val_acc_epochs_x, val_acc_epochs_y],\\", "\n", "#     [\"plot_epoch_xvalues\", \"plot_epoch_yvalues\", \"plot_it_x_values\", \"plot_it_y_values\",\"val_acc_epochs_x\",\"val_acc_epochs_y\"], out_dir=cfg.EPISODE_DIR, isDebug=False)", "\n", "logger", ".", "info", "(", "\"Successfully logged numpy arrays!!\"", ")", "\n", "\n", "# Plot arrays", "\n", "# plot_arrays(x_vals=plot_epoch_xvalues, y_vals=plot_epoch_yvalues, \\", "\n", "# x_name=\"Epochs\", y_name=\"Loss\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR)", "\n", "#", "\n", "# plot_arrays(x_vals=val_acc_epochs_x, y_vals=val_acc_epochs_y, \\", "\n", "# x_name=\"Epochs\", y_name=\"Validation Accuracy\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR)", "\n", "\n", "# save_plot_values([plot_epoch_xvalues, plot_epoch_yvalues, plot_it_x_values, plot_it_y_values, val_acc_epochs_x, val_acc_epochs_y], \\", "\n", "#         [\"plot_epoch_xvalues\", \"plot_epoch_yvalues\", \"plot_it_x_values\", \"plot_it_y_values\",\"val_acc_epochs_x\",\"val_acc_epochs_y\"], out_dir=cfg.EPISODE_DIR)", "\n", "\n", "print", "(", "'Training Epoch: {}/{}\\tTrain Loss: {}\\tVal Accuracy: {}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "round", "(", "train_loss", ",", "4", ")", ",", "round", "(", "val_set_acc", ",", "4", ")", ")", ")", "\n", "\n", "# Save the best model checkpoint (Episode level)", "\n", "", "checkpoint_file", "=", "cu", ".", "save_checkpoint", "(", "info", "=", "\"vlBest_acc_\"", "+", "str", "(", "int", "(", "temp_best_val_acc", ")", ")", ",", "model_state", "=", "best_model_state", ",", "optimizer_state", "=", "best_opt_state", ",", "epoch", "=", "temp_best_val_epoch", ",", "cfg", "=", "cfg", ")", "\n", "\n", "print", "(", "'\\nWrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", ")", "\n", "logger", ".", "info", "(", "'Wrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ")", ")", "\n", "\n", "# plot_arrays(x_vals=plot_epoch_xvalues, y_vals=plot_epoch_yvalues, \\", "\n", "#     x_name=\"Epochs\", y_name=\"Loss\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR)", "\n", "#", "\n", "# plot_arrays(x_vals=plot_it_x_values, y_vals=plot_it_y_values, \\", "\n", "#     x_name=\"Iterations\", y_name=\"Loss\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR)", "\n", "#", "\n", "# plot_arrays(x_vals=val_acc_epochs_x, y_vals=val_acc_epochs_y, \\", "\n", "#     x_name=\"Epochs\", y_name=\"Validation Accuracy\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR)", "\n", "\n", "plot_epoch_xvalues", "=", "[", "]", "\n", "plot_epoch_yvalues", "=", "[", "]", "\n", "plot_it_x_values", "=", "[", "]", "\n", "plot_it_y_values", "=", "[", "]", "\n", "\n", "best_val_acc", "=", "temp_best_val_acc", "\n", "best_val_epoch", "=", "temp_best_val_epoch", "\n", "\n", "return", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.test_model": [[366, 395], ["pycls.utils.meters.TestMeter", "pycls.build_model", "pycls.load_checkpoint", "train_al.test_epoch", "plot_episode_xvalues.append", "plot_episode_yvalues.append", "len", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", ":", "\n", "\n", "    ", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "test_meter", "=", "TestMeter", "(", "len", "(", "test_loader", ")", ")", "\n", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "model", ")", "\n", "\n", "test_err", "=", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_episode", ")", "\n", "test_acc", "=", "100.", "-", "test_err", "\n", "\n", "plot_episode_xvalues", ".", "append", "(", "cur_episode", ")", "\n", "plot_episode_yvalues", ".", "append", "(", "test_acc", ")", "\n", "\n", "# plot_arrays(x_vals=plot_episode_xvalues, y_vals=plot_episode_yvalues, \\", "\n", "#     x_name=\"Episodes\", y_name=\"Test Accuracy\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EXP_DIR)", "\n", "#", "\n", "# save_plot_values([plot_episode_xvalues, plot_episode_yvalues], \\", "\n", "#     [\"plot_episode_xvalues\", \"plot_episode_yvalues\"], out_dir=cfg.EXP_DIR)", "\n", "\n", "return", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.train_epoch": [[397, 474], ["pycls.get_epoch_lr", "torch.cuda.is_available", "model.train", "train_meter.iter_tic", "len", "enumerate", "train_meter.log_epoch_stats", "train_meter.reset", "train_loader.sampler.set_epoch", "pycls.set_lr", "model.cuda", "inputs.type.type", "model", "loss_fun", "optimizer.zero_grad", "loss_fun.backward", "optimizer.step", "pycls.topk_errors", "train_meter.iter_toc", "train_meter.update_stats", "train_meter.log_iter_stats", "train_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "loss_fun.item", "top1_err.item", "plot_it_x_values.append", "plot_it_y_values.append", "print", "len", "inputs.type.size", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.set_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "def", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_max_iter", ")", ":", "\n", "    ", "\"\"\"Performs one epoch of training.\"\"\"", "\n", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "# Shuffle the data", "\n", "#loader.shuffle(train_loader, cur_epoch)", "\n", "if", "cfg", ".", "NUM_GPUS", ">", "1", ":", "train_loader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "# Update the learning rate", "\n", "# Currently we only support LR schedules for only 'SGD' optimizer", "\n", "lr", "=", "optim", ".", "get_epoch_lr", "(", "cfg", ",", "cur_epoch", ")", "\n", "if", "cfg", ".", "OPTIM", ".", "TYPE", "==", "\"sgd\"", ":", "\n", "        ", "optim", ".", "set_lr", "(", "optimizer", ",", "lr", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "#This basically notes the start time in timer class defined in utils/timer.py", "\n", "\n", "len_train_loader", "=", "len", "(", "train_loader", ")", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "#ensuring that inputs are floatTensor as model weights are", "\n", "        ", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# Perform the forward pass", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the loss", "\n", "loss", "=", "loss_fun", "(", "preds", ",", "labels", ")", "\n", "# Perform the backward pass", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update the parametersSWA", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the stats across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     #Average error and losses across GPUs", "\n", "#     #Also this this calls wait method on reductions so we are ensured", "\n", "#     #to obtain synchronized results", "\n", "#     loss, top1_err = du.scaled_all_reduce(", "\n", "#         [loss, top1_err]", "\n", "#     )", "\n", "# Copy the stats from GPU to CPU (sync point)", "\n", "loss", ",", "top1_err", "=", "loss", ".", "item", "(", ")", ",", "top1_err", ".", "item", "(", ")", "\n", "# #Only master process writes the logs which are used for plotting", "\n", "# if du.is_master_proc():", "\n", "if", "cur_iter", "!=", "0", "and", "cur_iter", "%", "19", "==", "0", ":", "\n", "#because cur_epoch starts with 0", "\n", "            ", "plot_it_x_values", ".", "append", "(", "(", "cur_epoch", ")", "*", "len_train_loader", "+", "cur_iter", ")", "\n", "plot_it_y_values", ".", "append", "(", "loss", ")", "\n", "# save_plot_values([plot_it_x_values, plot_it_y_values],[\"plot_it_x_values\", \"plot_it_y_values\"], out_dir=cfg.EPISODE_DIR, isDebug=False)", "\n", "# print(plot_it_x_values)", "\n", "# print(plot_it_y_values)", "\n", "#Plot loss graphs", "\n", "# plot_arrays(x_vals=plot_it_x_values, y_vals=plot_it_y_values, x_name=\"Iterations\", y_name=\"Loss\", dataset_name=cfg.DATASET.NAME, out_dir=cfg.EPISODE_DIR,)", "\n", "print", "(", "'Training Epoch: {}/{}\\tIter: {}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "cur_iter", ",", "len", "(", "train_loader", ")", ")", ")", "\n", "\n", "#Compute the difference in time now from start time initialized just before this for loop.", "\n", "", "train_meter", ".", "iter_toc", "(", ")", "\n", "train_meter", ".", "update_stats", "(", "top1_err", "=", "top1_err", ",", "loss", "=", "loss", ",", "lr", "=", "lr", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", ")", "\n", "train_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "train_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "train_meter", ".", "reset", "(", ")", "\n", "return", "loss", ",", "clf_iter_count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.train_al.test_epoch": [[476, 530], ["torch.no_grad", "torch.cuda.is_available", "model.eval", "test_meter.iter_tic", "enumerate", "test_meter.log_epoch_stats", "test_meter.reset", "model.cuda", "torch.no_grad", "inputs.type.type", "model", "pycls.topk_errors", "top1_err.item.item", "test_meter.iter_toc", "test_meter.update_stats", "test_meter.log_iter_stats", "test_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "inputs.type.size", "inputs.type.size", "inputs.type.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on the test set.\"\"\"", "\n", "\n", "global", "plot_episode_xvalues", "\n", "global", "plot_episode_yvalues", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "\n", "misclassifications", "=", "0.", "\n", "totalSamples", "=", "0.", "\n", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Transfer the data to the current GPU device", "\n", "            ", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "# Compute the predictions", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the errors across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     top1_err = du.scaled_all_reduce([top1_err])", "\n", "#     #as above returns a list", "\n", "#     top1_err = top1_err[0]", "\n", "# Copy the errors from GPU to CPU (sync point)", "\n", "top1_err", "=", "top1_err", ".", "item", "(", ")", "\n", "# Multiply by Number of GPU's as top1_err is scaled by 1/Num_GPUs", "\n", "misclassifications", "+=", "top1_err", "*", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "totalSamples", "+=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "test_meter", ".", "iter_toc", "(", ")", "\n", "# Update and log stats", "\n", "test_meter", ".", "update_stats", "(", "\n", "top1_err", "=", "top1_err", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", ")", "\n", "test_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "", "test_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "test_meter", ".", "reset", "(", ")", "\n", "\n", "return", "misclassifications", "/", "totalSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.add_path": [[12, 15], ["sys.path.insert"], "function", ["None"], ["def", "add_path", "(", "path", ")", ":", "\n", "    ", "if", "path", "not", "in", "sys", ".", "path", ":", "\n", "        ", "sys", ".", "path", ".", "insert", "(", "0", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.argparser": [[42, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "argparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Active Learning - Image Classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "help", "=", "'Config file'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--exp-name'", ",", "dest", "=", "'exp_name'", ",", "help", "=", "'Experiment Name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays": [[49, 64], ["plt.xlabel", "plt.ylabel", "plt.title", "plt.plot", "plt.savefig", "plt.close", "print", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "plot_arrays", "(", "x_vals", ",", "y_vals", ",", "x_name", ",", "y_name", ",", "dataset_name", ",", "out_dir", ",", "isDebug", "=", "False", ")", ":", "\n", "# if not du.is_master_proc():", "\n", "#     return", "\n", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "temp_name", "=", "\"{}_vs_{}\"", ".", "format", "(", "x_name", ",", "y_name", ")", "\n", "plt", ".", "xlabel", "(", "x_name", ")", "\n", "plt", ".", "ylabel", "(", "y_name", ")", "\n", "plt", ".", "title", "(", "\"Dataset: {}; {}\"", ".", "format", "(", "dataset_name", ",", "temp_name", ")", ")", "\n", "plt", ".", "plot", "(", "x_vals", ",", "y_vals", ")", "\n", "\n", "if", "isDebug", ":", "print", "(", "\"plot_saved at : {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "'.png'", ")", ")", ")", "\n", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "temp_name", "+", "\".png\"", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values": [[65, 87], ["range", "len", "numpy.array", "os.path.exists", "os.makedirs", "numpy.savetxt", "numpy.save"], "function", ["None"], ["", "def", "save_plot_values", "(", "temp_arrays", ",", "temp_names", ",", "out_dir", ",", "isParallel", "=", "True", ",", "saveInTextFormat", "=", "True", ",", "isDebug", "=", "True", ")", ":", "\n", "\n", "    ", "\"\"\" Saves arrays provided in the list in npy format \"\"\"", "\n", "# Return if not master process", "\n", "# if isParallel:", "\n", "#     if not du.is_master_proc():", "\n", "#         return", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "temp_arrays", ")", ")", ":", "\n", "        ", "temp_arrays", "[", "i", "]", "=", "np", ".", "array", "(", "temp_arrays", "[", "i", "]", ")", "\n", "temp_dir", "=", "out_dir", "\n", "# if cfg.TRAIN.TRANSFER_EXP:", "\n", "#     temp_dir += os.path.join(\"transfer_experiment\",cfg.MODEL.TRANSFER_MODEL_TYPE+\"_depth_\"+str(cfg.MODEL.TRANSFER_MODEL_DEPTH))+\"/\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "temp_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "temp_dir", ")", "\n", "", "if", "saveInTextFormat", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.txt in text format!!\")", "\n", "            ", "np", ".", "savetxt", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".txt\"", ",", "temp_arrays", "[", "i", "]", ",", "fmt", "=", "\"%1.2f\"", ")", "\n", "", "else", ":", "\n", "# if isDebug: print(f\"Saving {temp_names[i]} at {temp_dir+temp_names[i]}.npy in numpy format!!\")", "\n", "            ", "np", ".", "save", "(", "temp_dir", "+", "'/'", "+", "temp_names", "[", "i", "]", "+", "\".npy\"", ",", "temp_arrays", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.is_eval_epoch": [[88, 93], ["None"], "function", ["None"], ["", "", "", "def", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Determines if the model should be evaluated at the current epoch.\"\"\"", "\n", "return", "(", "\n", "(", "cur_epoch", "+", "1", ")", "%", "cfg", ".", "TRAIN", ".", "EVAL_PERIOD", "==", "0", "or", "\n", "(", "cur_epoch", "+", "1", ")", "==", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.main": [[96, 221], ["torch.device", "os.path.join", "os.path.join", "os.path.join", "pycls.core.config.dump_cfg", "pycls.setup_logging", "print", "os.path.join", "pycls.datasets.data.Data", "pycls.datasets.data.Data.getDataset", "pycls.datasets.data.Data.getDataset", "print", "logger.info", "pycls.datasets.data.Data.makeTVSets", "pycls.datasets.data.Data.loadTVPartitions", "print", "logger.info", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getIndexesDataLoader", "pycls.datasets.data.Data.getTestLoader", "range", "print", "logger.info", "print", "logger.info", "range", "print", "logger.info", "numpy.mean", "print", "logger.info", "print", "logger.info", "torch.cuda.is_available", "numpy.random.randint", "os.path.abspath", "os.path.exists", "os.mkdir", "os.path.exists", "os.makedirs", "datetime.datetime.now", "os.path.exists", "os.mkdir", "print", "print", "os.path.abspath", "models.append", "print", "pycls.construct_optimizer", "print", "logger.info", "os.path.join", "ensemble_train.ensemble_train_model", "best_model_paths.append", "print", "logger.info", "print", "ensemble_train.ensemble_test_model", "test_accs.append", "print", "logger.info", "len", "len", "len", "len", "pycls.build_model", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.config.dump_cfg", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.logging.setup_logging", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getDataset", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.makeTVSets", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.loadTVPartitions", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getIndexesDataLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.datasets.data.Data.getTestLoader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.construct_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_train_model", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_test_model", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model"], ["", "def", "main", "(", "cfg", ")", ":", "\n", "\n", "# Setting up GPU args", "\n", "    ", "use_cuda", "=", "(", "cfg", ".", "NUM_GPUS", ">", "0", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "kwargs", "=", "{", "'num_workers'", ":", "cfg", ".", "DATA_LOADER", ".", "NUM_WORKERS", ",", "'pin_memory'", ":", "cfg", ".", "DATA_LOADER", ".", "PIN_MEMORY", "}", "if", "use_cuda", "else", "{", "}", "\n", "\n", "# Auto assign a RNG_SEED when not supplied a value", "\n", "if", "cfg", ".", "RNG_SEED", "is", "None", ":", "\n", "        ", "cfg", ".", "RNG_SEED", "=", "np", ".", "random", ".", "randint", "(", "100", ")", "\n", "\n", "# Using specific GPU", "\n", "# os.environ['NVIDIA_VISIBLE_DEVICES'] = str(cfg.GPU_ID)", "\n", "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'", "\n", "# print(\"Using GPU : {}.\\n\".format(cfg.GPU_ID))", "\n", "\n", "# Getting the output directory ready (default is \"/output\")", "\n", "", "cfg", ".", "OUT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "OUT_DIR", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cfg", ".", "OUT_DIR", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "cfg", ".", "OUT_DIR", ")", "\n", "# Create \"DATASET/MODEL TYPE\" specific directory", "\n", "", "dataset_out_dir", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUT_DIR", ",", "cfg", ".", "DATASET", ".", "NAME", ",", "cfg", ".", "MODEL", ".", "TYPE", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dataset_out_dir", ")", "\n", "# Creating the experiment directory inside the dataset specific directory ", "\n", "# all logs, labeled, unlabeled, validation sets are stroed here ", "\n", "# E.g., output/CIFAR10/resnet18/{timestamp or cfg.EXP_NAME based on arguments passed}", "\n", "", "if", "cfg", ".", "EXP_NAME", "==", "'auto'", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "exp_dir", "=", "f'{now.year}_{now.month}_{now.day}_{now.hour}{now.minute}{now.second}'", "\n", "", "else", ":", "\n", "        ", "exp_dir", "=", "cfg", ".", "EXP_NAME", "\n", "\n", "", "exp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_out_dir", ",", "exp_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "exp_dir", ")", "\n", "print", "(", "\"Experiment Directory is {}.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Experiment Directory Already Exists: {}. Reusing it may lead to loss of old logs in the directory.\\n\"", ".", "format", "(", "exp_dir", ")", ")", "\n", "", "cfg", ".", "EXP_DIR", "=", "exp_dir", "\n", "\n", "# Save the config file in EXP_DIR", "\n", "dump_cfg", "(", "cfg", ")", "\n", "\n", "# Setup Logger", "\n", "lu", ".", "setup_logging", "(", "cfg", ")", "\n", "\n", "# Dataset preparing steps", "\n", "print", "(", "\"\\n======== PREPARING DATA AND MODEL ========\\n\"", ")", "\n", "cfg", ".", "DATASET", ".", "ROOT_DIR", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "abspath", "(", "'../..'", ")", ",", "cfg", ".", "DATASET", ".", "ROOT_DIR", ")", "\n", "data_obj", "=", "Data", "(", "cfg", ")", "\n", "train_data", ",", "train_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "True", ",", "isDownload", "=", "True", ")", "\n", "test_data", ",", "test_size", "=", "data_obj", ".", "getDataset", "(", "save_dir", "=", "cfg", ".", "DATASET", ".", "ROOT_DIR", ",", "isTrain", "=", "False", ",", "isDownload", "=", "True", ")", "\n", "\n", "print", "(", "\"\\nDataset {} Loaded Sucessfully.\\nTotal Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "logger", ".", "info", "(", "\"Dataset {} Loaded Sucessfully. Total Train Size: {} and Total Test Size: {}\\n\"", ".", "format", "(", "cfg", ".", "DATASET", ".", "NAME", ",", "train_size", ",", "test_size", ")", ")", "\n", "\n", "trainSet_path", ",", "valSet_path", "=", "data_obj", ".", "makeTVSets", "(", "val_split_ratio", "=", "cfg", ".", "DATASET", ".", "VAL_RATIO", ",", "data", "=", "train_data", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ",", "save_dir", "=", "cfg", ".", "EXP_DIR", ")", "\n", "\n", "trainSet", ",", "valSet", "=", "data_obj", ".", "loadTVPartitions", "(", "trainSetPath", "=", "trainSet_path", ",", "valSetPath", "=", "valSet_path", ")", "\n", "\n", "print", "(", "\"Data Partitioning Complete. \\nTrain Set: {},  Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "trainSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"\\nTrain Set: {},  Validation Set: {}\\n\"", ".", "format", "(", "len", "(", "trainSet", ")", ",", "len", "(", "valSet", ")", ")", ")", "\n", "\n", "# Preparing dataloaders for initial training", "\n", "trainSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "trainSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "valSet_loader", "=", "data_obj", ".", "getIndexesDataLoader", "(", "indexes", "=", "valSet", ",", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "data", "=", "train_data", ")", "\n", "test_loader", "=", "data_obj", ".", "getTestLoader", "(", "data", "=", "test_data", ",", "test_batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "seed_id", "=", "cfg", ".", "RNG_SEED", ")", "\n", "\n", "# Initialize the models", "\n", "num_ensembles", "=", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", "\n", "models", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ensembles", ")", ":", "\n", "        ", "models", ".", "append", "(", "model_builder", ".", "build_model", "(", "cfg", ")", ")", "\n", "", "print", "(", "\"{} ensemble models of type: {}\\n\"", ".", "format", "(", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", ",", "cfg", ".", "ENSEMBLE", ".", "MODEL_TYPE", ")", ")", "\n", "logger", ".", "info", "(", "\"{} ensemble models of type: {}\\n\"", ".", "format", "(", "cfg", ".", "ENSEMBLE", ".", "NUM_MODELS", ",", "cfg", ".", "ENSEMBLE", ".", "MODEL_TYPE", ")", ")", "\n", "\n", "# This is to seamlessly use the code originally written for AL episodes    ", "\n", "cfg", ".", "EPISODE_DIR", "=", "cfg", ".", "EXP_DIR", "\n", "\n", "# Train models", "\n", "print", "(", "\"======== ENSEMBLE TRAINING ========\"", ")", "\n", "logger", ".", "info", "(", "\"======== ENSEMBLE TRAINING ========\"", ")", "\n", "\n", "best_model_paths", "=", "[", "]", "\n", "test_accs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_ensembles", ")", ":", "\n", "        ", "print", "(", "\"=== Training ensemble [{}/{}] ===\"", ".", "format", "(", "i", "+", "1", ",", "num_ensembles", ")", ")", "\n", "\n", "# Construct the optimizer", "\n", "optimizer", "=", "optim", ".", "construct_optimizer", "(", "cfg", ",", "models", "[", "i", "]", ")", "\n", "print", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "logger", ".", "info", "(", "\"optimizer: {}\\n\"", ".", "format", "(", "optimizer", ")", ")", "\n", "\n", "# Each ensemble gets its own output directory ", "\n", "cfg", ".", "EPISODE_DIR", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "EPISODE_DIR", ",", "'model_{}   '", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "\n", "# Train the model", "\n", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "=", "ensemble_train_model", "(", "trainSet_loader", ",", "valSet_loader", ",", "models", "[", "i", "]", ",", "optimizer", ",", "cfg", ")", "\n", "best_model_paths", ".", "append", "(", "checkpoint_file", ")", "\n", "\n", "print", "(", "\"Best Validation Accuracy by Model {}: {}\\nBest Epoch: {}\\n\"", ".", "format", "(", "i", "+", "1", ",", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "logger", ".", "info", "(", "\"Best Validation Accuracy by Model {}: {}\\tBest Epoch: {}\\n\"", ".", "format", "(", "i", "+", "1", ",", "round", "(", "best_val_acc", ",", "4", ")", ",", "best_val_epoch", ")", ")", "\n", "\n", "# Test the model", "\n", "print", "(", "\"=== Testing ensemble [{}/{}] ===\"", ".", "format", "(", "i", "+", "1", ",", "num_ensembles", ")", ")", "\n", "test_acc", "=", "ensemble_test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", "=", "0", ")", "\n", "test_accs", ".", "append", "(", "test_acc", ")", "\n", "\n", "print", "(", "\"Test Accuracy by Model {}: {}.\\n\"", ".", "format", "(", "i", "+", "1", ",", "round", "(", "test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Test Accuracy by Model {}: {}.\\n\"", ".", "format", "(", "i", "+", "1", ",", "test_acc", ")", ")", "\n", "\n", "# Reset EPISODE_DIR", "\n", "cfg", ".", "EPISODE_DIR", "=", "cfg", ".", "EXP_DIR", "\n", "\n", "# Test each best model checkpoint and report the average ", "\n", "", "print", "(", "\"======== ENSEMBLE TESTING ========\\n\"", ")", "\n", "logger", ".", "info", "(", "\"======== ENSEMBLE TESTING ========\\n\"", ")", "\n", "\n", "mean_test_acc", "=", "np", ".", "mean", "(", "test_accs", ")", "\n", "print", "(", "\"Average Ensemble Test Accuracy: {}.\\n\"", ".", "format", "(", "round", "(", "mean_test_acc", ",", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Average Ensemble Test Accuracy: {}.\\n\"", ".", "format", "(", "mean_test_acc", ")", ")", "\n", "\n", "print", "(", "\"================================\\n\\n\"", ")", "\n", "logger", ".", "info", "(", "\"================================\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_train_model": [[223, 334], ["pycls.get_loss_fun", "pycls.utils.meters.TrainMeter", "pycls.utils.meters.ValMeter", "logger.info", "range", "pycls.save_checkpoint", "print", "logger.info", "ensemble_train.plot_arrays", "ensemble_train.plot_arrays", "ensemble_train.plot_arrays", "len", "len", "int", "ensemble_train.train_epoch", "ensemble_train.is_eval_epoch", "plot_epoch_xvalues.append", "plot_epoch_yvalues.append", "ensemble_train.save_plot_values", "logger.info", "ensemble_train.plot_arrays", "ensemble_train.plot_arrays", "ensemble_train.save_plot_values", "print", "pycls.compute_precise_bn_stats", "ensemble_train.test_epoch", "val_acc_epochs_x.append", "val_acc_epochs_y.append", "len", "model.eval", "optimizer.state_dict", "model.train", "round", "round", "str", "cu.save_checkpoint.split", "model.module.state_dict", "model.state_dict", "int", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.losses.get_loss_fun", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.save_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.train_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.is_eval_epoch", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.net.compute_precise_bn_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "ensemble_train_model", "(", "train_loader", ",", "val_loader", ",", "model", ",", "optimizer", ",", "cfg", ")", ":", "\n", "\n", "    ", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "start_epoch", "=", "0", "\n", "loss_fun", "=", "losses", ".", "get_loss_fun", "(", ")", "\n", "\n", "# Create meters", "\n", "train_meter", "=", "TrainMeter", "(", "len", "(", "train_loader", ")", ")", "\n", "val_meter", "=", "ValMeter", "(", "len", "(", "val_loader", ")", ")", "\n", "\n", "# Perform the training loop", "\n", "# print(\"Len(train_loader):{}\".format(len(train_loader)))", "\n", "logger", ".", "info", "(", "'Start epoch: {}'", ".", "format", "(", "start_epoch", "+", "1", ")", ")", "\n", "val_set_acc", "=", "0.", "\n", "\n", "temp_best_val_acc", "=", "0.", "\n", "temp_best_val_epoch", "=", "0", "\n", "\n", "# Best checkpoint model and optimizer states", "\n", "best_model_state", "=", "None", "\n", "best_opt_state", "=", "None", "\n", "\n", "val_acc_epochs_x", "=", "[", "]", "\n", "val_acc_epochs_y", "=", "[", "]", "\n", "\n", "clf_train_iterations", "=", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", "*", "int", "(", "len", "(", "train_loader", ")", "/", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ")", "\n", "clf_change_lr_iter", "=", "clf_train_iterations", "//", "25", "\n", "clf_iter_count", "=", "0", "\n", "\n", "for", "cur_epoch", "in", "range", "(", "start_epoch", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ")", ":", "\n", "# Train for one epoch", "\n", "        ", "train_loss", ",", "clf_iter_count", "=", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_train_iterations", ")", "\n", "\n", "# Compute precise BN stats", "\n", "if", "cfg", ".", "BN", ".", "USE_PRECISE_STATS", ":", "\n", "            ", "nu", ".", "compute_precise_bn_stats", "(", "model", ",", "train_loader", ")", "\n", "\n", "\n", "# Model evaluation", "\n", "", "if", "is_eval_epoch", "(", "cur_epoch", ")", ":", "\n", "# Original code[PYCLS] passes on testLoader but we want to compute on val Set", "\n", "            ", "val_loader", ".", "dataset", ".", "no_aug", "=", "True", "\n", "val_set_err", "=", "test_epoch", "(", "val_loader", ",", "model", ",", "val_meter", ",", "cur_epoch", ")", "\n", "val_set_acc", "=", "100.", "-", "val_set_err", "\n", "val_loader", ".", "dataset", ".", "no_aug", "=", "False", "\n", "if", "temp_best_val_acc", "<", "val_set_acc", ":", "\n", "                ", "temp_best_val_acc", "=", "val_set_acc", "\n", "temp_best_val_epoch", "=", "cur_epoch", "+", "1", "\n", "\n", "# Save best model and optimizer state for checkpointing", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "best_model_state", "=", "model", ".", "module", ".", "state_dict", "(", ")", "if", "cfg", ".", "NUM_GPUS", ">", "1", "else", "model", ".", "state_dict", "(", ")", "\n", "best_opt_state", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "# Since we start from 0 epoch", "\n", "", "val_acc_epochs_x", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "val_acc_epochs_y", ".", "append", "(", "val_set_acc", ")", "\n", "\n", "", "plot_epoch_xvalues", ".", "append", "(", "cur_epoch", "+", "1", ")", "\n", "plot_epoch_yvalues", ".", "append", "(", "train_loss", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "logger", ".", "info", "(", "\"Successfully logged numpy arrays!!\"", ")", "\n", "\n", "# Plot arrays", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "save_plot_values", "(", "[", "plot_epoch_xvalues", ",", "plot_epoch_yvalues", ",", "plot_it_x_values", ",", "plot_it_y_values", ",", "val_acc_epochs_x", ",", "val_acc_epochs_y", "]", ",", "[", "\"plot_epoch_xvalues\"", ",", "\"plot_epoch_yvalues\"", ",", "\"plot_it_x_values\"", ",", "\"plot_it_y_values\"", ",", "\"val_acc_epochs_x\"", ",", "\"val_acc_epochs_y\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "print", "(", "'Training Epoch: {}/{}\\tTrain Loss: {}\\tVal Accuracy: {}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "round", "(", "train_loss", ",", "4", ")", ",", "round", "(", "val_set_acc", ",", "4", ")", ")", ")", "\n", "\n", "# Save the best model checkpoint (Episode level)", "\n", "", "checkpoint_file", "=", "cu", ".", "save_checkpoint", "(", "info", "=", "\"vlBest_acc_\"", "+", "str", "(", "int", "(", "temp_best_val_acc", ")", ")", ",", "model_state", "=", "best_model_state", ",", "optimizer_state", "=", "best_opt_state", ",", "epoch", "=", "temp_best_val_epoch", ",", "cfg", "=", "cfg", ")", "\n", "\n", "print", "(", "'\\nWrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", ")", "\n", "logger", ".", "info", "(", "'Wrote Best Model Checkpoint to: {}\\n'", ".", "format", "(", "checkpoint_file", ")", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_epoch_xvalues", ",", "y_vals", "=", "plot_epoch_yvalues", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_arrays", "(", "x_vals", "=", "val_acc_epochs_x", ",", "y_vals", "=", "val_acc_epochs_y", ",", "x_name", "=", "\"Epochs\"", ",", "y_name", "=", "\"Validation Accuracy\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ")", "\n", "\n", "plot_epoch_xvalues", "=", "[", "]", "\n", "plot_epoch_yvalues", "=", "[", "]", "\n", "plot_it_x_values", "=", "[", "]", "\n", "plot_it_y_values", "=", "[", "]", "\n", "\n", "best_val_acc", "=", "temp_best_val_acc", "\n", "best_val_epoch", "=", "temp_best_val_epoch", "\n", "\n", "return", "best_val_acc", ",", "best_val_epoch", ",", "checkpoint_file", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.ensemble_test_model": [[336, 347], ["pycls.utils.meters.TestMeter", "pycls.build_model", "pycls.load_checkpoint", "ensemble_train.test_epoch", "len", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.build_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.checkpoint.load_checkpoint", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch"], ["", "def", "ensemble_test_model", "(", "test_loader", ",", "checkpoint_file", ",", "cfg", ",", "cur_episode", ")", ":", "\n", "\n", "    ", "test_meter", "=", "TestMeter", "(", "len", "(", "test_loader", ")", ")", "\n", "\n", "model", "=", "model_builder", ".", "build_model", "(", "cfg", ")", "\n", "model", "=", "cu", ".", "load_checkpoint", "(", "checkpoint_file", ",", "model", ")", "\n", "\n", "test_err", "=", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_episode", ")", "\n", "test_acc", "=", "100.", "-", "test_err", "\n", "\n", "return", "test_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.train_epoch": [[349, 424], ["pycls.get_epoch_lr", "torch.cuda.is_available", "model.train", "train_meter.iter_tic", "len", "enumerate", "train_meter.log_epoch_stats", "train_meter.reset", "train_loader.sampler.set_epoch", "pycls.set_lr", "model.cuda", "inputs.type.type", "model", "loss_fun", "optimizer.zero_grad", "loss_fun.backward", "optimizer.step", "pycls.topk_errors", "train_meter.iter_toc", "train_meter.update_stats", "train_meter.log_iter_stats", "train_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "loss_fun.item", "top1_err.item", "plot_it_x_values.append", "plot_it_y_values.append", "ensemble_train.save_plot_values", "ensemble_train.plot_arrays", "print", "len", "inputs.type.size", "pycls.core.config.cfg"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.get_epoch_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.core.optimizer.set_lr", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.save_plot_values", "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.plot_arrays"], ["", "def", "train_epoch", "(", "train_loader", ",", "model", ",", "loss_fun", ",", "optimizer", ",", "train_meter", ",", "cur_epoch", ",", "cfg", ",", "clf_iter_count", ",", "clf_change_lr_iter", ",", "clf_max_iter", ")", ":", "\n", "    ", "\"\"\"Performs one epoch of training.\"\"\"", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "# Shuffle the data", "\n", "#loader.shuffle(train_loader, cur_epoch)", "\n", "if", "cfg", ".", "NUM_GPUS", ">", "1", ":", "train_loader", ".", "sampler", ".", "set_epoch", "(", "cur_epoch", ")", "\n", "\n", "# Update the learning rate", "\n", "# Currently we only support LR schedules for only 'SGD' optimizer", "\n", "lr", "=", "optim", ".", "get_epoch_lr", "(", "cfg", ",", "cur_epoch", ")", "\n", "if", "cfg", ".", "OPTIM", ".", "TYPE", "==", "\"sgd\"", ":", "\n", "        ", "optim", ".", "set_lr", "(", "optimizer", ",", "lr", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "#This basically notes the start time in timer class defined in utils/timer.py", "\n", "\n", "len_train_loader", "=", "len", "(", "train_loader", ")", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "#ensuring that inputs are floatTensor as model weights are", "\n", "        ", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# Perform the forward pass", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the loss", "\n", "loss", "=", "loss_fun", "(", "preds", ",", "labels", ")", "\n", "# Perform the backward pass", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update the parametersSWA", "\n", "optimizer", ".", "step", "(", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the stats across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     #Average error and losses across GPUs", "\n", "#     #Also this this calls wait method on reductions so we are ensured", "\n", "#     #to obtain synchronized results", "\n", "#     loss, top1_err = du.scaled_all_reduce(", "\n", "#         [loss, top1_err]", "\n", "#     )", "\n", "# Copy the stats from GPU to CPU (sync point)", "\n", "loss", ",", "top1_err", "=", "loss", ".", "item", "(", ")", ",", "top1_err", ".", "item", "(", ")", "\n", "# #Only master process writes the logs which are used for plotting", "\n", "# if du.is_master_proc():", "\n", "if", "cur_iter", "!=", "0", "and", "cur_iter", "%", "19", "==", "0", ":", "\n", "#because cur_epoch starts with 0", "\n", "            ", "plot_it_x_values", ".", "append", "(", "(", "cur_epoch", ")", "*", "len_train_loader", "+", "cur_iter", ")", "\n", "plot_it_y_values", ".", "append", "(", "loss", ")", "\n", "save_plot_values", "(", "[", "plot_it_x_values", ",", "plot_it_y_values", "]", ",", "[", "\"plot_it_x_values.npy\"", ",", "\"plot_it_y_values.npy\"", "]", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", "isDebug", "=", "False", ")", "\n", "# print(plot_it_x_values)", "\n", "# print(plot_it_y_values)", "\n", "#Plot loss graphs", "\n", "plot_arrays", "(", "x_vals", "=", "plot_it_x_values", ",", "y_vals", "=", "plot_it_y_values", ",", "x_name", "=", "\"Iterations\"", ",", "y_name", "=", "\"Loss\"", ",", "dataset_name", "=", "cfg", ".", "DATASET", ".", "NAME", ",", "out_dir", "=", "cfg", ".", "EPISODE_DIR", ",", ")", "\n", "print", "(", "'Training Epoch: {}/{}\\tIter: {}/{}'", ".", "format", "(", "cur_epoch", "+", "1", ",", "cfg", ".", "OPTIM", ".", "MAX_EPOCH", ",", "cur_iter", ",", "len", "(", "train_loader", ")", ")", ")", "\n", "\n", "#Compute the difference in time now from start time initialized just before this for loop.", "\n", "", "train_meter", ".", "iter_toc", "(", ")", "\n", "train_meter", ".", "update_stats", "(", "top1_err", "=", "top1_err", ",", "loss", "=", "loss", ",", "lr", "=", "lr", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", ")", "\n", "train_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "train_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "train_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "train_meter", ".", "reset", "(", ")", "\n", "return", "loss", ",", "clf_iter_count", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.tools.ensemble_train.test_epoch": [[426, 477], ["torch.no_grad", "torch.cuda.is_available", "model.eval", "test_meter.iter_tic", "enumerate", "test_meter.log_epoch_stats", "test_meter.reset", "model.cuda", "torch.no_grad", "inputs.type.type", "model", "pycls.topk_errors", "top1_err.item.item", "test_meter.iter_toc", "test_meter.update_stats", "test_meter.log_iter_stats", "test_meter.iter_tic", "inputs.type.cuda", "labels.cuda", "inputs.type.size", "inputs.type.size", "inputs.type.size"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_epoch_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.reset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.metrics.topk_errors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_toc", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.update_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.log_iter_stats", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.meters.ValMeter.iter_tic", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_epoch", "(", "test_loader", ",", "model", ",", "test_meter", ",", "cur_epoch", ")", ":", "\n", "    ", "\"\"\"Evaluates the model on the test set.\"\"\"", "\n", "\n", "global", "plot_epoch_xvalues", "\n", "global", "plot_epoch_yvalues", "\n", "\n", "global", "plot_it_x_values", "\n", "global", "plot_it_y_values", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "# Enable eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "\n", "misclassifications", "=", "0.", "\n", "totalSamples", "=", "0.", "\n", "\n", "for", "cur_iter", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Transfer the data to the current GPU device", "\n", "            ", "inputs", ",", "labels", "=", "inputs", ".", "cuda", "(", ")", ",", "labels", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "inputs", "=", "inputs", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "# Compute the predictions", "\n", "preds", "=", "model", "(", "inputs", ")", "\n", "# Compute the errors", "\n", "top1_err", ",", "top5_err", "=", "mu", ".", "topk_errors", "(", "preds", ",", "labels", ",", "[", "1", ",", "5", "]", ")", "\n", "# Combine the errors across the GPUs", "\n", "# if cfg.NUM_GPUS > 1:", "\n", "#     top1_err = du.scaled_all_reduce([top1_err])", "\n", "#     #as above returns a list", "\n", "#     top1_err = top1_err[0]", "\n", "# Copy the errors from GPU to CPU (sync point)", "\n", "top1_err", "=", "top1_err", ".", "item", "(", ")", "\n", "# Multiply by Number of GPU's as top1_err is scaled by 1/Num_GPUs", "\n", "misclassifications", "+=", "top1_err", "*", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "totalSamples", "+=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", "test_meter", ".", "iter_toc", "(", ")", "\n", "# Update and log stats", "\n", "test_meter", ".", "update_stats", "(", "\n", "top1_err", "=", "top1_err", ",", "mb_size", "=", "inputs", ".", "size", "(", "0", ")", "*", "cfg", ".", "NUM_GPUS", "\n", ")", "\n", "test_meter", ".", "log_iter_stats", "(", "cur_epoch", ",", "cur_iter", ")", "\n", "test_meter", ".", "iter_tic", "(", ")", "\n", "# Log epoch stats", "\n", "", "", "test_meter", ".", "log_epoch_stats", "(", "cur_epoch", ")", "\n", "test_meter", ".", "reset", "(", ")", "\n", "\n", "return", "misclassifications", "/", "totalSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.simclr.main": [[32, 162], ["utils.config.create_config", "print", "print", "utils.common_config.get_model", "print", "print", "print", "model.cuda.cuda", "print", "print", "utils.common_config.get_train_transformations", "print", "utils.common_config.get_val_transformations", "print", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataset", "utils.common_config.get_train_dataloader", "utils.common_config.get_val_dataloader", "print", "print", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataloader", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "print", "utils.common_config.get_criterion", "print", "criterion.cuda.cuda", "print", "utils.common_config.get_optimizer", "print", "os.path.exists", "print", "range", "torch.save", "print", "utils.utils.fill_memory_bank", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "numpy.save", "numpy.save", "print", "utils.utils.fill_memory_bank", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "len", "len", "termcolor.colored", "termcolor.colored", "print", "torch.load", "utils.common_config.get_optimizer.load_state_dict", "model.cuda.load_state_dict", "model.cuda.cuda", "print", "model.cuda.cuda", "termcolor.colored", "print", "print", "utils.common_config.adjust_learning_rate", "print", "print", "utils.train_utils.simclr_train", "print", "utils.utils.fill_memory_bank", "print", "utils.evaluate_utils.contrastive_evaluate", "print", "print", "torch.save", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "numpy.save", "numpy.save", "numpy.save", "model.cuda.state_dict", "termcolor.colored", "utils.memory.MemoryBank.pre_lasts.cpu().numpy", "p[].replace", "utils.memory.MemoryBank.pre_lasts.cpu().numpy", "termcolor.colored", "len", "len", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "utils.memory.MemoryBank.pre_lasts.cpu().numpy", "p[].replace", "utils.memory.MemoryBank.pre_lasts.cpu().numpy", "sum", "utils.common_config.get_optimizer.state_dict", "model.cuda.state_dict", "utils.memory.MemoryBank.pre_lasts.cpu", "utils.memory.MemoryBank.pre_lasts.cpu", "utils.memory.MemoryBank.pre_lasts.cpu", "utils.memory.MemoryBank.pre_lasts.cpu", "utils.config.create_config.numel", "model.cuda.parameters"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_criterion", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.adjust_learning_rate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.train_utils.simclr_train", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.contrastive_evaluate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cpu"], ["def", "main", "(", ")", ":", "\n", "\n", "# Retrieve config file", "\n", "    ", "p", "=", "create_config", "(", "args", ".", "config_env", ",", "args", ".", "config_exp", ",", "args", ".", "seed", ")", "\n", "print", "(", "colored", "(", "p", ",", "'red'", ")", ")", "\n", "\n", "# Model", "\n", "print", "(", "colored", "(", "'Retrieve model'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "p", ")", "\n", "print", "(", "'Model is {}'", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ")", ")", "\n", "print", "(", "'Model parameters: {:.2f}M'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", "/", "1e6", ")", ")", "\n", "print", "(", "model", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "# CUDNN", "\n", "print", "(", "colored", "(", "'Set CuDNN benchmark'", ",", "'blue'", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Dataset", "\n", "print", "(", "colored", "(", "'Retrieve dataset'", ",", "'blue'", ")", ")", "\n", "train_transforms", "=", "get_train_transformations", "(", "p", ")", "\n", "print", "(", "'Train transforms:'", ",", "train_transforms", ")", "\n", "val_transforms", "=", "get_val_transformations", "(", "p", ")", "\n", "print", "(", "'Validation transforms:'", ",", "val_transforms", ")", "\n", "train_dataset", "=", "get_train_dataset", "(", "p", ",", "train_transforms", ",", "to_augmented_dataset", "=", "True", ",", "\n", "split", "=", "'train+unlabeled'", ")", "# Split is for stl-10", "\n", "val_dataset", "=", "get_val_dataset", "(", "p", ",", "val_transforms", ")", "\n", "train_dataloader", "=", "get_train_dataloader", "(", "p", ",", "train_dataset", ")", "\n", "val_dataloader", "=", "get_val_dataloader", "(", "p", ",", "val_dataset", ")", "\n", "print", "(", "'Dataset contains {}/{} train/val samples'", ".", "format", "(", "len", "(", "train_dataset", ")", ",", "len", "(", "val_dataset", ")", ")", ")", "\n", "\n", "# Memory Bank", "\n", "print", "(", "colored", "(", "'Build MemoryBank'", ",", "'blue'", ")", ")", "\n", "base_dataset", "=", "get_train_dataset", "(", "p", ",", "val_transforms", ",", "split", "=", "'train'", ")", "# Dataset w/o augs for knn eval", "\n", "base_dataloader", "=", "get_val_dataloader", "(", "p", ",", "base_dataset", ")", "\n", "memory_bank_base", "=", "MemoryBank", "(", "len", "(", "base_dataset", ")", ",", "\n", "p", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "p", "[", "'num_classes'", "]", ",", "p", "[", "'criterion_kwargs'", "]", "[", "'temperature'", "]", ")", "\n", "memory_bank_base", ".", "cuda", "(", ")", "\n", "memory_bank_val", "=", "MemoryBank", "(", "len", "(", "val_dataset", ")", ",", "\n", "p", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "p", "[", "'num_classes'", "]", ",", "p", "[", "'criterion_kwargs'", "]", "[", "'temperature'", "]", ")", "\n", "memory_bank_val", ".", "cuda", "(", ")", "\n", "\n", "# Criterion", "\n", "print", "(", "colored", "(", "'Retrieve criterion'", ",", "'blue'", ")", ")", "\n", "criterion", "=", "get_criterion", "(", "p", ")", "\n", "print", "(", "'Criterion is {}'", ".", "format", "(", "criterion", ".", "__class__", ".", "__name__", ")", ")", "\n", "criterion", "=", "criterion", ".", "cuda", "(", ")", "\n", "\n", "# Optimizer and scheduler", "\n", "print", "(", "colored", "(", "'Retrieve optimizer'", ",", "'blue'", ")", ")", "\n", "optimizer", "=", "get_optimizer", "(", "p", ",", "model", ")", "\n", "print", "(", "optimizer", ")", "\n", "\n", "# Checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "p", "[", "'pretext_checkpoint'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Restart from checkpoint {}'", ".", "format", "(", "p", "[", "'pretext_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "p", "[", "'pretext_checkpoint'", "]", ",", "map_location", "=", "'cpu'", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "colored", "(", "'No checkpoint file at {}'", ".", "format", "(", "p", "[", "'pretext_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "start_epoch", "=", "0", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "# Training", "\n", "", "print", "(", "colored", "(", "'Starting main loop'", ",", "'blue'", ")", ")", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "p", "[", "'epochs'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Epoch %d/%d'", "%", "(", "epoch", ",", "p", "[", "'epochs'", "]", ")", ",", "'yellow'", ")", ")", "\n", "print", "(", "colored", "(", "'-'", "*", "15", ",", "'yellow'", ")", ")", "\n", "\n", "# Adjust lr", "\n", "lr", "=", "adjust_learning_rate", "(", "p", ",", "optimizer", ",", "epoch", ")", "\n", "print", "(", "'Adjusted learning rate to {:.5f}'", ".", "format", "(", "lr", ")", ")", "\n", "\n", "# Train", "\n", "print", "(", "'Train ...'", ")", "\n", "simclr_train", "(", "train_dataloader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ")", "\n", "\n", "# Fill memory bank", "\n", "print", "(", "'Fill memory bank for kNN...'", ")", "\n", "fill_memory_bank", "(", "base_dataloader", ",", "model", ",", "memory_bank_base", ")", "\n", "\n", "# Evaluate (To monitor progress - Not for validation)", "\n", "print", "(", "'Evaluate ...'", ")", "\n", "top1", "=", "contrastive_evaluate", "(", "val_dataloader", ",", "model", ",", "memory_bank_base", ")", "\n", "print", "(", "'Result of kNN evaluation is %.2f'", "%", "(", "top1", ")", ")", "\n", "\n", "# Checkpoint", "\n", "print", "(", "'Checkpoint ...'", ")", "\n", "torch", ".", "save", "(", "{", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", "+", "1", "}", ",", "p", "[", "'pretext_checkpoint'", "]", ")", "\n", "\n", "topk", "=", "20", "\n", "print", "(", "'Mine the nearest neighbors (Top-%d)'", "%", "(", "topk", ")", ")", "\n", "indices", ",", "acc", "=", "memory_bank_base", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_train_path'", "]", ",", "indices", ")", "\n", "np", ".", "save", "(", "p", "[", "'pretext_features'", "]", ",", "memory_bank_base", ".", "pre_lasts", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'pretext_features'", "]", ".", "replace", "(", "'features'", ",", "'test_features'", ")", ",", "memory_bank_val", ".", "pre_lasts", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "# Save final model", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "p", "[", "'pretext_model'", "]", ")", "\n", "\n", "# Mine the topk nearest neighbors at the very end (Train) ", "\n", "# These will be served as input to the SCAN loss.", "\n", "print", "(", "colored", "(", "'Fill memory bank for mining the nearest neighbors (train) ...'", ",", "'blue'", ")", ")", "\n", "fill_memory_bank", "(", "base_dataloader", ",", "model", ",", "memory_bank_base", ")", "\n", "topk", "=", "20", "\n", "print", "(", "'Mine the nearest neighbors (Top-%d)'", "%", "(", "topk", ")", ")", "\n", "indices", ",", "acc", "=", "memory_bank_base", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on train set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_train_path'", "]", ",", "indices", ")", "\n", "# save features", "\n", "np", ".", "save", "(", "p", "[", "'pretext_features'", "]", ",", "memory_bank_base", ".", "pre_lasts", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'pretext_features'", "]", ".", "replace", "(", "'features'", ",", "'test_features'", ")", ",", "memory_bank_val", ".", "pre_lasts", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "# Mine the topk nearest neighbors at the very end (Val)", "\n", "# These will be used for validation.", "\n", "print", "(", "colored", "(", "'Fill memory bank for mining the nearest neighbors (val) ...'", ",", "'blue'", ")", ")", "\n", "fill_memory_bank", "(", "val_dataloader", ",", "model", ",", "memory_bank_val", ")", "\n", "topk", "=", "5", "\n", "print", "(", "'Mine the nearest neighbors (Top-%d)'", "%", "(", "topk", ")", ")", "\n", "indices", ",", "acc", "=", "memory_bank_val", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on val set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_val_path'", "]", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.tutorial_nn.main": [[29, 96], ["utils.config.create_config", "print", "print", "utils.common_config.get_model", "print", "print", "print", "model.cuda.cuda", "print", "utils.common_config.get_val_transformations", "print", "utils.common_config.get_val_dataset", "utils.common_config.get_val_dataloader", "print", "print", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataloader", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "os.path.exists", "print", "torch.load", "model.cuda.load_state_dict", "model.cuda.cuda", "torch.save", "print", "utils.utils.fill_memory_bank", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "print", "utils.utils.fill_memory_bank", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "len", "len", "termcolor.colored", "model.cuda.state_dict", "termcolor.colored", "termcolor.colored", "len", "sum", "utils.config.create_config.numel", "model.cuda.parameters"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors"], ["def", "main", "(", ")", ":", "\n", "\n", "# Retrieve config file", "\n", "    ", "p", "=", "create_config", "(", "args", ".", "config_env", ",", "args", ".", "config_exp", ")", "\n", "print", "(", "colored", "(", "p", ",", "'red'", ")", ")", "\n", "\n", "# Model", "\n", "print", "(", "colored", "(", "'Retrieve model'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "p", ")", "\n", "print", "(", "'Model is {}'", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ")", ")", "\n", "print", "(", "'Model parameters: {:.2f}M'", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", "/", "1e6", ")", ")", "\n", "print", "(", "model", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "# CUDNN", "\n", "print", "(", "colored", "(", "'Set CuDNN benchmark'", ",", "'blue'", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Dataset", "\n", "val_transforms", "=", "get_val_transformations", "(", "p", ")", "\n", "print", "(", "'Validation transforms:'", ",", "val_transforms", ")", "\n", "val_dataset", "=", "get_val_dataset", "(", "p", ",", "val_transforms", ")", "\n", "val_dataloader", "=", "get_val_dataloader", "(", "p", ",", "val_dataset", ")", "\n", "print", "(", "'Dataset contains {} val samples'", ".", "format", "(", "len", "(", "val_dataset", ")", ")", ")", "\n", "\n", "# Memory Bank", "\n", "print", "(", "colored", "(", "'Build MemoryBank'", ",", "'blue'", ")", ")", "\n", "base_dataset", "=", "get_train_dataset", "(", "p", ",", "val_transforms", ",", "split", "=", "'train'", ")", "# Dataset w/o augs for knn eval", "\n", "base_dataloader", "=", "get_val_dataloader", "(", "p", ",", "base_dataset", ")", "\n", "memory_bank_base", "=", "MemoryBank", "(", "len", "(", "base_dataset", ")", ",", "\n", "p", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "p", "[", "'num_classes'", "]", ",", "p", "[", "'criterion_kwargs'", "]", "[", "'temperature'", "]", ")", "\n", "memory_bank_base", ".", "cuda", "(", ")", "\n", "memory_bank_val", "=", "MemoryBank", "(", "len", "(", "val_dataset", ")", ",", "\n", "p", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "p", "[", "'num_classes'", "]", ",", "p", "[", "'criterion_kwargs'", "]", "[", "'temperature'", "]", ")", "\n", "memory_bank_val", ".", "cuda", "(", ")", "\n", "\n", "# Checkpoint", "\n", "assert", "os", ".", "path", ".", "exists", "(", "p", "[", "'pretext_checkpoint'", "]", ")", "\n", "print", "(", "colored", "(", "'Restart from checkpoint {}'", ".", "format", "(", "p", "[", "'pretext_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "p", "[", "'pretext_checkpoint'", "]", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "# Save model", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "p", "[", "'pretext_model'", "]", ")", "\n", "\n", "# Mine the topk nearest neighbors at the very end (Train) ", "\n", "# These will be served as input to the SCAN loss.", "\n", "print", "(", "colored", "(", "'Fill memory bank for mining the nearest neighbors (train) ...'", ",", "'blue'", ")", ")", "\n", "fill_memory_bank", "(", "base_dataloader", ",", "model", ",", "memory_bank_base", ")", "\n", "topk", "=", "20", "\n", "print", "(", "'Mine the nearest neighbors (Top-%d)'", "%", "(", "topk", ")", ")", "\n", "indices", ",", "acc", "=", "memory_bank_base", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on train set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_train_path'", "]", ",", "indices", ")", "\n", "\n", "# Mine the topk nearest neighbors at the very end (Val)", "\n", "# These will be used for validation.", "\n", "print", "(", "colored", "(", "'Fill memory bank for mining the nearest neighbors (val) ...'", ",", "'blue'", ")", ")", "\n", "fill_memory_bank", "(", "val_dataloader", ",", "model", ",", "memory_bank_val", ")", "\n", "topk", "=", "5", "\n", "print", "(", "'Mine the nearest neighbors (Top-%d)'", "%", "(", "topk", ")", ")", "\n", "indices", ",", "acc", "=", "memory_bank_val", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on val set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_val_path'", "]", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.selflabel.main": [[28, 122], ["utils.config.create_config", "print", "print", "utils.common_config.get_model", "print", "torch.nn.DataParallel", "model.cuda.cuda", "print", "utils.common_config.get_criterion", "utils.common_config.get_criterion.cuda", "print", "print", "print", "utils.common_config.get_optimizer", "print", "print", "utils.common_config.get_train_transformations", "utils.common_config.get_val_transformations", "utils.common_config.get_train_dataset", "utils.common_config.get_train_dataloader", "utils.common_config.get_val_dataset", "utils.common_config.get_val_dataloader", "print", "os.path.exists", "print", "range", "print", "utils.evaluate_utils.get_predictions", "utils.evaluate_utils.hungarian_evaluate", "print", "torch.save", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "print", "torch.load", "model.cuda.load_state_dict", "utils.common_config.get_optimizer.load_state_dict", "print", "utils.ema.EMA", "termcolor.colored", "print", "print", "utils.common_config.adjust_learning_rate", "print", "print", "selflabel..", "print", "utils.evaluate_utils.get_predictions", "utils.evaluate_utils.hungarian_evaluate", "print", "print", "torch.save", "torch.save", "termcolor.colored", "model.cuda.module.state_dict", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "model.cuda.module.state_dict", "os.path.join", "utils.common_config.get_optimizer.state_dict", "model.cuda.state_dict", "len", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_criterion", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.adjust_learning_rate", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate"], ["def", "main", "(", ")", ":", "\n", "# Retrieve config file", "\n", "    ", "p", "=", "create_config", "(", "args", ".", "config_env", ",", "args", ".", "config_exp", ")", "\n", "print", "(", "colored", "(", "p", ",", "'red'", ")", ")", "\n", "\n", "# Get model", "\n", "print", "(", "colored", "(", "'Retrieve model'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "p", ",", "p", "[", "'scan_model'", "]", ")", "\n", "print", "(", "model", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "# Get criterion", "\n", "print", "(", "colored", "(", "'Get loss'", ",", "'blue'", ")", ")", "\n", "criterion", "=", "get_criterion", "(", "p", ")", "\n", "criterion", ".", "cuda", "(", ")", "\n", "print", "(", "criterion", ")", "\n", "\n", "# CUDNN", "\n", "print", "(", "colored", "(", "'Set CuDNN benchmark'", ",", "'blue'", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Optimizer", "\n", "print", "(", "colored", "(", "'Retrieve optimizer'", ",", "'blue'", ")", ")", "\n", "optimizer", "=", "get_optimizer", "(", "p", ",", "model", ")", "\n", "print", "(", "optimizer", ")", "\n", "\n", "# Dataset", "\n", "print", "(", "colored", "(", "'Retrieve dataset'", ",", "'blue'", ")", ")", "\n", "\n", "# Transforms ", "\n", "strong_transforms", "=", "get_train_transformations", "(", "p", ")", "\n", "val_transforms", "=", "get_val_transformations", "(", "p", ")", "\n", "train_dataset", "=", "get_train_dataset", "(", "p", ",", "{", "'standard'", ":", "val_transforms", ",", "'augment'", ":", "strong_transforms", "}", ",", "\n", "split", "=", "'train'", ",", "to_augmented_dataset", "=", "True", ")", "\n", "train_dataloader", "=", "get_train_dataloader", "(", "p", ",", "train_dataset", ")", "\n", "val_dataset", "=", "get_val_dataset", "(", "p", ",", "val_transforms", ")", "\n", "val_dataloader", "=", "get_val_dataloader", "(", "p", ",", "val_dataset", ")", "\n", "print", "(", "colored", "(", "'Train samples %d - Val samples %d'", "%", "(", "len", "(", "train_dataset", ")", ",", "len", "(", "val_dataset", ")", ")", ",", "'yellow'", ")", ")", "\n", "\n", "# Checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "p", "[", "'selflabel_checkpoint'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Restart from checkpoint {}'", ".", "format", "(", "p", "[", "'selflabel_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "p", "[", "'selflabel_checkpoint'", "]", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "colored", "(", "'No checkpoint file at {}'", ".", "format", "(", "p", "[", "'selflabel_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "start_epoch", "=", "0", "\n", "\n", "# EMA", "\n", "", "if", "p", "[", "'use_ema'", "]", ":", "\n", "        ", "ema", "=", "EMA", "(", "model", ",", "alpha", "=", "p", "[", "'ema_alpha'", "]", ")", "\n", "", "else", ":", "\n", "        ", "ema", "=", "None", "\n", "\n", "# Main loop", "\n", "", "print", "(", "colored", "(", "'Starting main loop'", ",", "'blue'", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "p", "[", "'epochs'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Epoch %d/%d'", "%", "(", "epoch", "+", "1", ",", "p", "[", "'epochs'", "]", ")", ",", "'yellow'", ")", ")", "\n", "print", "(", "colored", "(", "'-'", "*", "10", ",", "'yellow'", ")", ")", "\n", "\n", "# Adjust lr", "\n", "lr", "=", "adjust_learning_rate", "(", "p", ",", "optimizer", ",", "epoch", ")", "\n", "print", "(", "'Adjusted learning rate to {:.5f}'", ".", "format", "(", "lr", ")", ")", "\n", "\n", "# Perform self-labeling ", "\n", "print", "(", "'Train ...'", ")", "\n", "selflabel_train", "(", "train_dataloader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "ema", "=", "ema", ")", "\n", "\n", "# Evaluate (To monitor progress - Not for validation)", "\n", "print", "(", "'Evaluate ...'", ")", "\n", "predictions", "=", "get_predictions", "(", "p", ",", "val_dataloader", ",", "model", ")", "\n", "clustering_stats", "=", "hungarian_evaluate", "(", "0", ",", "predictions", ",", "compute_confusion_matrix", "=", "False", ")", "\n", "print", "(", "clustering_stats", ")", "\n", "\n", "# Checkpoint", "\n", "print", "(", "'Checkpoint ...'", ")", "\n", "torch", ".", "save", "(", "{", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", "+", "1", "}", ",", "p", "[", "'selflabel_checkpoint'", "]", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "p", "[", "'selflabel_model'", "]", ")", "\n", "\n", "# Evaluate and save the final model", "\n", "", "print", "(", "colored", "(", "'Evaluate model at the end'", ",", "'blue'", ")", ")", "\n", "predictions", "=", "get_predictions", "(", "p", ",", "val_dataloader", ",", "model", ")", "\n", "clustering_stats", "=", "hungarian_evaluate", "(", "0", ",", "predictions", ",", "\n", "class_names", "=", "val_dataset", ".", "classes", ",", "\n", "compute_confusion_matrix", "=", "True", ",", "\n", "confusion_matrix_file", "=", "os", ".", "path", ".", "join", "(", "p", "[", "'selflabel_dir'", "]", ",", "'confusion_matrix.png'", ")", ")", "\n", "print", "(", "clustering_stats", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "p", "[", "'selflabel_model'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.eval.main": [[23, 94], ["print", "print", "print", "utils.common_config.get_val_transformations", "utils.common_config.get_val_dataset", "utils.common_config.get_val_dataloader", "print", "print", "utils.common_config.get_model", "print", "print", "torch.load", "utils.common_config.get_model.cuda", "termcolor.colored", "open", "yaml.safe_load", "termcolor.colored", "termcolor.colored", "termcolor.colored", "utils.common_config.get_model.load_state_dict", "print", "print", "utils.memory.MemoryBank.cuda", "print", "utils.utils.fill_memory_bank", "print", "len", "utils.common_config.get_model.load_state_dict", "termcolor.colored", "utils.memory.MemoryBank", "utils.memory.MemoryBank", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "print", "utils.evaluate_utils.get_predictions", "utils.evaluate_utils.hungarian_evaluate", "print", "len", "len", "termcolor.colored", "eval.get_prototypes", "eval.visualize_indices"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate", "home.repos.pwc.inspect_result.avihu111_typiclust.scan.eval.get_prototypes", "home.repos.pwc.inspect_result.avihu111_typiclust.scan.eval.visualize_indices"], ["def", "main", "(", ")", ":", "\n", "\n", "# Read config file", "\n", "    ", "print", "(", "colored", "(", "'Read config file {} ...'", ".", "format", "(", "args", ".", "config_exp", ")", ",", "'blue'", ")", ")", "\n", "with", "open", "(", "args", ".", "config_exp", ",", "'r'", ")", "as", "stream", ":", "\n", "        ", "config", "=", "yaml", ".", "safe_load", "(", "stream", ")", "\n", "", "config", "[", "'batch_size'", "]", "=", "512", "# To make sure we can evaluate on a single 1080ti", "\n", "print", "(", "config", ")", "\n", "\n", "# Get dataset", "\n", "print", "(", "colored", "(", "'Get validation dataset ...'", ",", "'blue'", ")", ")", "\n", "transforms", "=", "get_val_transformations", "(", "config", ")", "\n", "dataset", "=", "get_val_dataset", "(", "config", ",", "transforms", ")", "\n", "dataloader", "=", "get_val_dataloader", "(", "config", ",", "dataset", ")", "\n", "print", "(", "'Number of samples: {}'", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "# Get model", "\n", "print", "(", "colored", "(", "'Get model ...'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "config", ")", "\n", "print", "(", "model", ")", "\n", "\n", "# Read model weights", "\n", "print", "(", "colored", "(", "'Load model weights ...'", ",", "'blue'", ")", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "model", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "config", "[", "'setup'", "]", "in", "[", "'simclr'", ",", "'moco'", ",", "'selflabel'", "]", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "elif", "config", "[", "'setup'", "]", "==", "'scan'", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state_dict", "[", "'model'", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# CUDA", "\n", "", "model", ".", "cuda", "(", ")", "\n", "\n", "# Perform evaluation", "\n", "if", "config", "[", "'setup'", "]", "in", "[", "'simclr'", ",", "'moco'", "]", ":", "\n", "        ", "print", "(", "colored", "(", "'Perform evaluation of the pretext task (setup={}).'", ".", "format", "(", "config", "[", "'setup'", "]", ")", ",", "'blue'", ")", ")", "\n", "print", "(", "'Create Memory Bank'", ")", "\n", "if", "config", "[", "'setup'", "]", "==", "'simclr'", ":", "# Mine neighbors after MLP", "\n", "            ", "memory_bank", "=", "MemoryBank", "(", "len", "(", "dataset", ")", ",", "config", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "config", "[", "'num_classes'", "]", ",", "config", "[", "'criterion_kwargs'", "]", "[", "'temperature'", "]", ")", "\n", "\n", "", "else", ":", "# Mine neighbors before MLP", "\n", "            ", "memory_bank", "=", "MemoryBank", "(", "len", "(", "dataset", ")", ",", "config", "[", "'model_kwargs'", "]", "[", "'features_dim'", "]", ",", "\n", "config", "[", "'num_classes'", "]", ",", "config", "[", "'temperature'", "]", ")", "\n", "", "memory_bank", ".", "cuda", "(", ")", "\n", "\n", "print", "(", "'Fill Memory Bank'", ")", "\n", "fill_memory_bank", "(", "dataloader", ",", "model", ",", "memory_bank", ")", "\n", "\n", "print", "(", "'Mine the nearest neighbors'", ")", "\n", "for", "topk", "in", "[", "1", ",", "5", ",", "20", "]", ":", "# Similar to Fig 2 in paper ", "\n", "            ", "_", ",", "acc", "=", "memory_bank", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-{} nearest neighbors on validation set is {:.2f}'", ".", "format", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "\n", "\n", "", "", "elif", "config", "[", "'setup'", "]", "in", "[", "'scan'", ",", "'selflabel'", "]", ":", "\n", "        ", "print", "(", "colored", "(", "'Perform evaluation of the clustering model (setup={}).'", ".", "format", "(", "config", "[", "'setup'", "]", ")", ",", "'blue'", ")", ")", "\n", "head", "=", "state_dict", "[", "'head'", "]", "if", "config", "[", "'setup'", "]", "==", "'scan'", "else", "0", "\n", "predictions", ",", "features", "=", "get_predictions", "(", "config", ",", "dataloader", ",", "model", ",", "return_features", "=", "True", ")", "\n", "clustering_stats", "=", "hungarian_evaluate", "(", "head", ",", "predictions", ",", "dataset", ".", "classes", ",", "\n", "compute_confusion_matrix", "=", "True", ")", "\n", "print", "(", "clustering_stats", ")", "\n", "if", "args", ".", "visualize_prototypes", ":", "\n", "            ", "prototype_indices", "=", "get_prototypes", "(", "config", ",", "predictions", "[", "head", "]", ",", "features", ",", "model", ")", "\n", "visualize_indices", "(", "prototype_indices", ",", "dataset", ",", "clustering_stats", "[", "'hungarian_match'", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.eval.get_prototypes": [[95, 130], ["torch.no_grad", "print", "torch.max", "torch.zeros", "range", "torch.index_select", "selected_features.unsqueeze().view.unsqueeze().view", "torch.mean", "torch.norm", "torch.min", "F.one_hot().byte", "torch.masked_select", "proto_indices.int().tolist.int().tolist", "max_probs.clone", "torch.topk", "torch.mean.unsqueeze", "torch.zeros.view", "F.one_hot().byte.view", "torch.zeros.view().long", "selected_features.unsqueeze().view.unsqueeze", "F.one_hot", "proto_indices.int().tolist.int", "best_indices.long", "torch.zeros.size", "torch.zeros.view"], "function", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "get_prototypes", "(", "config", ",", "predictions", ",", "features", ",", "model", ",", "topk", "=", "10", ")", ":", "\n", "    ", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "\n", "# Get topk most certain indices and pred labels", "\n", "print", "(", "'Get topk'", ")", "\n", "probs", "=", "predictions", "[", "'probabilities'", "]", "\n", "n_classes", "=", "probs", ".", "shape", "[", "1", "]", "\n", "dims", "=", "features", ".", "shape", "[", "1", "]", "\n", "max_probs", ",", "pred_labels", "=", "torch", ".", "max", "(", "probs", ",", "dim", "=", "1", ")", "\n", "indices", "=", "torch", ".", "zeros", "(", "(", "n_classes", ",", "topk", ")", ")", "\n", "for", "pred_id", "in", "range", "(", "n_classes", ")", ":", "\n", "        ", "probs_copy", "=", "max_probs", ".", "clone", "(", ")", "\n", "mask_out", "=", "~", "(", "pred_labels", "==", "pred_id", ")", "\n", "probs_copy", "[", "mask_out", "]", "=", "-", "1", "\n", "conf_vals", ",", "conf_idx", "=", "torch", ".", "topk", "(", "probs_copy", ",", "k", "=", "topk", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "indices", "[", "pred_id", ",", ":", "]", "=", "conf_idx", "\n", "\n", "# Get corresponding features", "\n", "", "selected_features", "=", "torch", ".", "index_select", "(", "features", ",", "dim", "=", "0", ",", "index", "=", "indices", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", ")", "\n", "selected_features", "=", "selected_features", ".", "unsqueeze", "(", "1", ")", ".", "view", "(", "n_classes", ",", "-", "1", ",", "dims", ")", "\n", "\n", "# Get mean feature per class", "\n", "mean_features", "=", "torch", ".", "mean", "(", "selected_features", ",", "dim", "=", "1", ")", "\n", "\n", "# Get min distance wrt to mean", "\n", "diff_features", "=", "selected_features", "-", "mean_features", ".", "unsqueeze", "(", "1", ")", "\n", "diff_norm", "=", "torch", ".", "norm", "(", "diff_features", ",", "2", ",", "dim", "=", "2", ")", "\n", "\n", "# Get final indices", "\n", "_", ",", "best_indices", "=", "torch", ".", "min", "(", "diff_norm", ",", "dim", "=", "1", ")", "\n", "one_hot", "=", "F", ".", "one_hot", "(", "best_indices", ".", "long", "(", ")", ",", "indices", ".", "size", "(", "1", ")", ")", ".", "byte", "(", ")", "\n", "proto_indices", "=", "torch", ".", "masked_select", "(", "indices", ".", "view", "(", "-", "1", ")", ",", "one_hot", ".", "view", "(", "-", "1", ")", ")", "\n", "proto_indices", "=", "proto_indices", ".", "int", "(", ")", ".", "tolist", "(", ")", "\n", "return", "proto_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.eval.visualize_indices": [[131, 142], ["np.array().astype", "PIL.Image.fromarray", "plt.figure", "plt.axis", "plt.imshow", "plt.show", "np.array", "dataset.get_image"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNetSubset.get_image"], ["", "def", "visualize_indices", "(", "indices", ",", "dataset", ",", "hungarian_match", ")", ":", "\n", "    ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "import", "numpy", "as", "np", "\n", "\n", "for", "idx", "in", "indices", ":", "\n", "        ", "img", "=", "np", ".", "array", "(", "dataset", ".", "get_image", "(", "idx", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "imshow", "(", "img", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.moco.main": [[25, 118], ["utils.config.create_config", "print", "print", "utils.common_config.get_model", "print", "print", "torch.nn.DataParallel", "model.cuda.cuda", "print", "print", "utils.common_config.get_val_transformations", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataset", "utils.common_config.get_val_dataloader", "utils.common_config.get_val_dataloader", "print", "print", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "utils.memory.MemoryBank", "utils.memory.MemoryBank.cuda", "print", "os.system", "torch.load", "print", "list", "model.cuda.load_state_dict", "os.system", "print", "torch.save", "torch.nn.Identity", "print", "utils.common_config.get_val_transformations", "utils.common_config.get_train_dataset", "utils.utils.fill_memory_bank", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "print", "utils.utils.fill_memory_bank", "print", "utils.memory.MemoryBank.mine_nearest_neighbors", "print", "numpy.save", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "len", "len", "termcolor.colored", "termcolor.colored", "state_dict.keys", "termcolor.colored", "model.cuda.module.state_dict", "termcolor.colored", "termcolor.colored", "len", "len", "k.startswith", "k.startswith", "k.startswith", "ValueError", "len", "len"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Identity", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.utils.fill_memory_bank", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.mine_nearest_neighbors"], ["def", "main", "(", ")", ":", "\n", "# Retrieve config file", "\n", "    ", "p", "=", "create_config", "(", "args", ".", "config_env", ",", "args", ".", "config_exp", ")", "\n", "print", "(", "colored", "(", "p", ",", "'red'", ")", ")", "\n", "\n", "\n", "# Model", "\n", "print", "(", "colored", "(", "'Retrieve model'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "p", ")", "\n", "print", "(", "'Model is {}'", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ")", ")", "\n", "print", "(", "model", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "\n", "# CUDNN", "\n", "print", "(", "colored", "(", "'Set CuDNN benchmark'", ",", "'blue'", ")", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "\n", "# Dataset", "\n", "print", "(", "colored", "(", "'Retrieve dataset'", ",", "'blue'", ")", ")", "\n", "transforms", "=", "get_val_transformations", "(", "p", ")", "\n", "train_dataset", "=", "get_train_dataset", "(", "p", ",", "transforms", ")", "\n", "val_dataset", "=", "get_val_dataset", "(", "p", ",", "transforms", ")", "\n", "train_dataloader", "=", "get_val_dataloader", "(", "p", ",", "train_dataset", ")", "\n", "val_dataloader", "=", "get_val_dataloader", "(", "p", ",", "val_dataset", ")", "\n", "print", "(", "'Dataset contains {}/{} train/val samples'", ".", "format", "(", "len", "(", "train_dataset", ")", ",", "len", "(", "val_dataset", ")", ")", ")", "\n", "\n", "\n", "# Memory Bank", "\n", "print", "(", "colored", "(", "'Build MemoryBank'", ",", "'blue'", ")", ")", "\n", "memory_bank_train", "=", "MemoryBank", "(", "len", "(", "train_dataset", ")", ",", "2048", ",", "p", "[", "'num_classes'", "]", ",", "p", "[", "'temperature'", "]", ")", "\n", "memory_bank_train", ".", "cuda", "(", ")", "\n", "memory_bank_val", "=", "MemoryBank", "(", "len", "(", "val_dataset", ")", ",", "2048", ",", "p", "[", "'num_classes'", "]", ",", "p", "[", "'temperature'", "]", ")", "\n", "memory_bank_val", ".", "cuda", "(", ")", "\n", "\n", "\n", "# Load the official MoCoV2 checkpoint", "\n", "print", "(", "colored", "(", "'Downloading moco v2 checkpoint'", ",", "'blue'", ")", ")", "\n", "os", ".", "system", "(", "'wget -L https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar'", ")", "\n", "moco_state", "=", "torch", ".", "load", "(", "'moco_v2_800ep_pretrain.pth.tar'", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "\n", "# Transfer moco weights", "\n", "print", "(", "colored", "(", "'Transfer MoCo weights to model'", ",", "'blue'", ")", ")", "\n", "new_state_dict", "=", "{", "}", "\n", "state_dict", "=", "moco_state", "[", "'state_dict'", "]", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# Copy backbone weights", "\n", "        ", "if", "k", ".", "startswith", "(", "'module.encoder_q'", ")", "and", "not", "k", ".", "startswith", "(", "'module.encoder_q.fc'", ")", ":", "\n", "            ", "new_k", "=", "'module.backbone.'", "+", "k", "[", "len", "(", "'module.encoder_q.'", ")", ":", "]", "\n", "new_state_dict", "[", "new_k", "]", "=", "state_dict", "[", "k", "]", "\n", "\n", "# Copy mlp weights", "\n", "", "elif", "k", ".", "startswith", "(", "'module.encoder_q.fc'", ")", ":", "\n", "            ", "new_k", "=", "'module.contrastive_head.'", "+", "k", "[", "len", "(", "'module.encoder_q.fc.'", ")", ":", "]", "\n", "new_state_dict", "[", "new_k", "]", "=", "state_dict", "[", "k", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unexpected key {}'", ".", "format", "(", "k", ")", ")", "\n", "\n", "", "", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "os", ".", "system", "(", "'rm -rf moco_v2_800ep_pretrain.pth.tar'", ")", "\n", "\n", "\n", "# Save final model", "\n", "print", "(", "colored", "(", "'Save pretext model'", ",", "'blue'", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "module", ".", "state_dict", "(", ")", ",", "p", "[", "'pretext_model'", "]", ")", "\n", "model", ".", "module", ".", "contrastive_head", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "# In this case, we mine the neighbors before the MLP. ", "\n", "\n", "\n", "# Mine the topk nearest neighbors (Train)", "\n", "# These will be used for training with the SCAN-Loss.", "\n", "topk", "=", "50", "\n", "print", "(", "colored", "(", "'Mine the nearest neighbors (Train)(Top-%d)'", "%", "(", "topk", ")", ",", "'blue'", ")", ")", "\n", "transforms", "=", "get_val_transformations", "(", "p", ")", "\n", "train_dataset", "=", "get_train_dataset", "(", "p", ",", "transforms", ")", "\n", "fill_memory_bank", "(", "train_dataloader", ",", "model", ",", "memory_bank_train", ")", "\n", "indices", ",", "acc", "=", "memory_bank_train", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on train set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_train_path'", "]", ",", "indices", ")", "\n", "\n", "\n", "# Mine the topk nearest neighbors (Validation)", "\n", "# These will be used for validation.", "\n", "topk", "=", "5", "\n", "print", "(", "colored", "(", "'Mine the nearest neighbors (Val)(Top-%d)'", "%", "(", "topk", ")", ",", "'blue'", ")", ")", "\n", "fill_memory_bank", "(", "val_dataloader", ",", "model", ",", "memory_bank_val", ")", "\n", "print", "(", "'Mine the neighbors'", ")", "\n", "indices", ",", "acc", "=", "memory_bank_val", ".", "mine_nearest_neighbors", "(", "topk", ")", "\n", "print", "(", "'Accuracy of top-%d nearest neighbors on val set is %.2f'", "%", "(", "topk", ",", "100", "*", "acc", ")", ")", "\n", "np", ".", "save", "(", "p", "[", "'topk_neighbors_val_path'", "]", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.scan.scan.main": [[27, 157], ["FLAGS.parse_args", "utils.config.create_config", "print", "print", "utils.common_config.get_train_transformations", "utils.common_config.get_val_transformations", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataset", "utils.common_config.get_train_dataloader", "utils.common_config.get_val_dataloader", "print", "print", "print", "print", "utils.common_config.get_model", "print", "torch.nn.DataParallel", "model.cuda.cuda", "print", "utils.common_config.get_optimizer", "print", "print", "utils.common_config.get_criterion", "utils.common_config.get_criterion.cuda", "print", "os.path.exists", "print", "range", "utils.common_config.get_train_dataset", "utils.common_config.get_val_dataloader", "utils.evaluate_utils.get_predictions", "os.path.dirname", "os.path.join", "os.path.join", "numpy.save", "numpy.save", "print", "torch.load", "model.cuda.module.load_state_dict", "utils.evaluate_utils.get_predictions", "utils.evaluate_utils.hungarian_evaluate", "print", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "print", "termcolor.colored", "print", "torch.load", "model.cuda.load_state_dict", "utils.common_config.get_optimizer.load_state_dict", "print", "termcolor.colored", "print", "print", "utils.common_config.adjust_learning_rate", "print", "print", "utils.train_utils.scan_train", "print", "utils.evaluate_utils.get_predictions", "print", "utils.evaluate_utils.scan_evaluate", "print", "print", "utils.evaluate_utils.hungarian_evaluate", "print", "print", "torch.save", "train_features.numpy", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "termcolor.colored", "print", "print", "torch.save", "print", "print", "os.path.join", "len", "len", "utils.common_config.get_optimizer.state_dict", "model.cuda.state_dict", "model.cuda.module.state_dict"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.config.create_config", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_transformations", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.core.builders.get_model", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_optimizer", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_criterion", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_train_dataset", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.get_val_dataloader", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.common_config.adjust_learning_rate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.train_utils.scan_train", "home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.AdversarySampler.get_predictions", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.scan_evaluate", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.evaluate_utils.hungarian_evaluate"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "FLAGS", ".", "parse_args", "(", ")", "\n", "p", "=", "create_config", "(", "args", ".", "config_env", ",", "args", ".", "config_exp", ",", "args", ".", "seed", ",", "args", ".", "num_clusters", ")", "\n", "print", "(", "colored", "(", "p", ",", "'red'", ")", ")", "\n", "\n", "# CUDNN", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data", "\n", "print", "(", "colored", "(", "'Get dataset and dataloaders'", ",", "'blue'", ")", ")", "\n", "train_transformations", "=", "get_train_transformations", "(", "p", ")", "\n", "val_transformations", "=", "get_val_transformations", "(", "p", ")", "\n", "train_dataset", "=", "get_train_dataset", "(", "p", ",", "train_transformations", ",", "\n", "split", "=", "'train'", ",", "to_neighbors_dataset", "=", "True", ")", "\n", "val_dataset", "=", "get_val_dataset", "(", "p", ",", "val_transformations", ",", "to_neighbors_dataset", "=", "True", ")", "\n", "train_dataloader", "=", "get_train_dataloader", "(", "p", ",", "train_dataset", ")", "\n", "val_dataloader", "=", "get_val_dataloader", "(", "p", ",", "val_dataset", ")", "\n", "print", "(", "'Train transforms:'", ",", "train_transformations", ")", "\n", "print", "(", "'Validation transforms:'", ",", "val_transformations", ")", "\n", "print", "(", "'Train samples %d - Val samples %d'", "%", "(", "len", "(", "train_dataset", ")", ",", "len", "(", "val_dataset", ")", ")", ")", "\n", "\n", "# Model", "\n", "print", "(", "colored", "(", "'Get model'", ",", "'blue'", ")", ")", "\n", "model", "=", "get_model", "(", "p", ",", "p", "[", "'pretext_model'", "]", ")", "\n", "print", "(", "model", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "# Optimizer", "\n", "print", "(", "colored", "(", "'Get optimizer'", ",", "'blue'", ")", ")", "\n", "optimizer", "=", "get_optimizer", "(", "p", ",", "model", ",", "p", "[", "'update_cluster_head_only'", "]", ")", "\n", "print", "(", "optimizer", ")", "\n", "\n", "# Warning", "\n", "if", "p", "[", "'update_cluster_head_only'", "]", ":", "\n", "        ", "print", "(", "colored", "(", "'WARNING: SCAN will only update the cluster head'", ",", "'red'", ")", ")", "\n", "\n", "# Loss function", "\n", "", "print", "(", "colored", "(", "'Get loss'", ",", "'blue'", ")", ")", "\n", "criterion", "=", "get_criterion", "(", "p", ")", "\n", "criterion", ".", "cuda", "(", ")", "\n", "print", "(", "criterion", ")", "\n", "\n", "# Checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "p", "[", "'scan_checkpoint'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Restart from checkpoint {}'", ".", "format", "(", "p", "[", "'scan_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "p", "[", "'scan_checkpoint'", "]", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_loss", "=", "checkpoint", "[", "'best_loss'", "]", "\n", "best_loss_head", "=", "checkpoint", "[", "'best_loss_head'", "]", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "colored", "(", "'No checkpoint file at {}'", ".", "format", "(", "p", "[", "'scan_checkpoint'", "]", ")", ",", "'blue'", ")", ")", "\n", "start_epoch", "=", "0", "\n", "best_loss", "=", "1e4", "\n", "best_loss_head", "=", "None", "\n", "\n", "# Main loop", "\n", "", "print", "(", "colored", "(", "'Starting main loop'", ",", "'blue'", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "p", "[", "'epochs'", "]", ")", ":", "\n", "        ", "print", "(", "colored", "(", "'Epoch %d/%d'", "%", "(", "epoch", "+", "1", ",", "p", "[", "'epochs'", "]", ")", ",", "'yellow'", ")", ")", "\n", "print", "(", "colored", "(", "'-'", "*", "15", ",", "'yellow'", ")", ")", "\n", "\n", "# Adjust lr", "\n", "lr", "=", "adjust_learning_rate", "(", "p", ",", "optimizer", ",", "epoch", ")", "\n", "print", "(", "'Adjusted learning rate to {:.5f}'", ".", "format", "(", "lr", ")", ")", "\n", "\n", "# Train", "\n", "print", "(", "'Train ...'", ")", "\n", "scan_train", "(", "train_dataloader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "p", "[", "'update_cluster_head_only'", "]", ")", "\n", "\n", "# Evaluate ", "\n", "print", "(", "'Make prediction on validation set ...'", ")", "\n", "predictions", "=", "get_predictions", "(", "p", ",", "val_dataloader", ",", "model", ")", "\n", "\n", "print", "(", "'Evaluate based on SCAN loss ...'", ")", "\n", "scan_stats", "=", "scan_evaluate", "(", "predictions", ")", "\n", "print", "(", "scan_stats", ")", "\n", "lowest_loss_head", "=", "scan_stats", "[", "'lowest_loss_head'", "]", "\n", "lowest_loss", "=", "scan_stats", "[", "'lowest_loss'", "]", "\n", "\n", "if", "lowest_loss", "<", "best_loss", ":", "\n", "            ", "print", "(", "'New lowest loss on validation set: %.4f -> %.4f'", "%", "(", "best_loss", ",", "lowest_loss", ")", ")", "\n", "print", "(", "'Lowest loss head is %d'", "%", "(", "lowest_loss_head", ")", ")", "\n", "best_loss", "=", "lowest_loss", "\n", "best_loss_head", "=", "lowest_loss_head", "\n", "torch", ".", "save", "(", "{", "'model'", ":", "model", ".", "module", ".", "state_dict", "(", ")", ",", "'head'", ":", "best_loss_head", "}", ",", "p", "[", "'scan_model'", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "'No new lowest loss on validation set: %.4f -> %.4f'", "%", "(", "best_loss", ",", "lowest_loss", ")", ")", "\n", "print", "(", "'Lowest loss head is %d'", "%", "(", "best_loss_head", ")", ")", "\n", "\n", "", "print", "(", "'Evaluate with hungarian matching algorithm ...'", ")", "\n", "clustering_stats", "=", "hungarian_evaluate", "(", "lowest_loss_head", ",", "predictions", ",", "compute_confusion_matrix", "=", "False", ")", "\n", "print", "(", "clustering_stats", ")", "\n", "\n", "# Checkpoint", "\n", "print", "(", "'Checkpoint ...'", ")", "\n", "torch", ".", "save", "(", "{", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "'best_loss'", ":", "best_loss", ",", "'best_loss_head'", ":", "best_loss_head", "}", ",", "\n", "p", "[", "'scan_checkpoint'", "]", ")", "\n", "\n", "# save features", "\n", "", "train_dataset_eval", "=", "get_train_dataset", "(", "p", ",", "val_transformations", ",", "\n", "split", "=", "'train'", ",", "to_neighbors_dataset", "=", "True", ")", "\n", "train_loader_eval", "=", "get_val_dataloader", "(", "p", ",", "train_dataset_eval", ")", "\n", "train_preds", ",", "train_features", "=", "get_predictions", "(", "p", ",", "train_loader_eval", ",", "model", ",", "return_features", "=", "True", ")", "\n", "\n", "probs", "=", "train_preds", "[", "0", "]", "[", "'probabilities'", "]", "\n", "savedir", "=", "os", ".", "path", ".", "dirname", "(", "p", "[", "'scan_checkpoint'", "]", ")", "\n", "features_path", "=", "os", ".", "path", ".", "join", "(", "savedir", ",", "f'features_seed{args.seed}_clusters{args.num_clusters}.npy'", ")", "\n", "probs_path", "=", "os", ".", "path", ".", "join", "(", "savedir", ",", "f'probs_seed{args.seed}_clusters{args.num_clusters}.npy'", ")", "\n", "\n", "np", ".", "save", "(", "features_path", ",", "train_features", ".", "numpy", "(", ")", ")", "\n", "np", ".", "save", "(", "probs_path", ",", "probs", ")", "\n", "\n", "\n", "# Evaluate and save the final model", "\n", "print", "(", "colored", "(", "'Evaluate best model based on SCAN metric at the end'", ",", "'blue'", ")", ")", "\n", "model_checkpoint", "=", "torch", ".", "load", "(", "p", "[", "'scan_model'", "]", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "module", ".", "load_state_dict", "(", "model_checkpoint", "[", "'model'", "]", ")", "\n", "predictions", "=", "get_predictions", "(", "p", ",", "val_dataloader", ",", "model", ")", "\n", "clustering_stats", "=", "hungarian_evaluate", "(", "model_checkpoint", "[", "'head'", "]", ",", "predictions", ",", "\n", "class_names", "=", "val_dataset", ".", "dataset", ".", "classes", ",", "\n", "compute_confusion_matrix", "=", "True", ",", "\n", "confusion_matrix_file", "=", "os", ".", "path", ".", "join", "(", "p", "[", "'scan_dir'", "]", ",", "'confusion_matrix.png'", ")", ")", "\n", "print", "(", "clustering_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__init__": [[48, 93], ["utils.mypath.MyPath.db_root_dir", "torch.utils.data.Dataset.__init__", "torchvision.datasets.utils.verify_str_arg", "stl.STL10._verify_folds", "os.path.join", "os.path.isfile", "stl.STL10.download", "stl.STL10.__loadfile", "stl.STL10.__load_folds", "stl.STL10._check_integrity", "RuntimeError", "stl.STL10.__loadfile", "stl.STL10.__load_folds", "stl.STL10.__loadfile", "numpy.concatenate", "numpy.concatenate", "open", "f.read().splitlines", "stl.STL10.__loadfile", "numpy.asarray", "stl.STL10.__loadfile", "numpy.asarray", "f.read"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10._verify_folds", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.download", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__load_folds", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__load_folds", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile", "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile"], ["def", "__init__", "(", "self", ",", "root", "=", "MyPath", ".", "db_root_dir", "(", "'stl-10'", ")", ",", "\n", "split", "=", "'train'", ",", "folds", "=", "None", ",", "transform", "=", "None", ",", "\n", "download", "=", "False", ")", ":", "\n", "        ", "super", "(", "STL10", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "split", "=", "verify_str_arg", "(", "split", ",", "\"split\"", ",", "self", ".", "splits", ")", "\n", "self", ".", "folds", "=", "self", ".", "_verify_folds", "(", "folds", ")", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "", "elif", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "'Dataset not found or corrupted. '", "\n", "'You can use download=True to download it'", ")", "\n", "\n", "# now load the picked numpy arrays", "\n", "", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "data", ",", "self", ".", "labels", "=", "self", ".", "__loadfile", "(", "\n", "self", ".", "train_list", "[", "0", "]", "[", "0", "]", ",", "self", ".", "train_list", "[", "1", "]", "[", "0", "]", ")", "\n", "self", ".", "__load_folds", "(", "folds", ")", "\n", "\n", "", "elif", "self", ".", "split", "==", "'train+unlabeled'", ":", "\n", "            ", "self", ".", "data", ",", "self", ".", "labels", "=", "self", ".", "__loadfile", "(", "\n", "self", ".", "train_list", "[", "0", "]", "[", "0", "]", ",", "self", ".", "train_list", "[", "1", "]", "[", "0", "]", ")", "\n", "self", ".", "__load_folds", "(", "folds", ")", "\n", "unlabeled_data", ",", "_", "=", "self", ".", "__loadfile", "(", "self", ".", "train_list", "[", "2", "]", "[", "0", "]", ")", "\n", "self", ".", "data", "=", "np", ".", "concatenate", "(", "(", "self", ".", "data", ",", "unlabeled_data", ")", ")", "\n", "self", ".", "labels", "=", "np", ".", "concatenate", "(", "\n", "(", "self", ".", "labels", ",", "np", ".", "asarray", "(", "[", "-", "1", "]", "*", "unlabeled_data", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "\n", "", "elif", "self", ".", "split", "==", "'unlabeled'", ":", "\n", "            ", "self", ".", "data", ",", "_", "=", "self", ".", "__loadfile", "(", "self", ".", "train_list", "[", "2", "]", "[", "0", "]", ")", "\n", "self", ".", "labels", "=", "np", ".", "asarray", "(", "[", "-", "1", "]", "*", "self", ".", "data", ".", "shape", "[", "0", "]", ")", "\n", "", "else", ":", "# self.split == 'test':", "\n", "            ", "self", ".", "data", ",", "self", ".", "labels", "=", "self", ".", "__loadfile", "(", "\n", "self", ".", "test_list", "[", "0", "]", "[", "0", "]", ",", "self", ".", "test_list", "[", "1", "]", "[", "0", "]", ")", "\n", "\n", "", "class_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "root", ",", "self", ".", "base_folder", ",", "self", ".", "class_names_file", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "class_file", ")", ":", "\n", "            ", "with", "open", "(", "class_file", ")", "as", "f", ":", "\n", "                ", "self", ".", "classes", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "", "if", "self", ".", "split", "==", "'train'", ":", "# Added this to be able to filter out fp from neighbors", "\n", "            ", "self", ".", "targets", "=", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10._verify_folds": [[95, 107], ["isinstance", "ValueError", "ValueError", "range", "msg.format", "msg.format", "type"], "methods", ["None"], ["", "", "def", "_verify_folds", "(", "self", ",", "folds", ")", ":", "\n", "        ", "if", "folds", "is", "None", ":", "\n", "            ", "return", "folds", "\n", "", "elif", "isinstance", "(", "folds", ",", "int", ")", ":", "\n", "            ", "if", "folds", "in", "range", "(", "10", ")", ":", "\n", "                ", "return", "folds", "\n", "", "msg", "=", "(", "\"Value for argument folds should be in the range [0, 10), \"", "\n", "\"but got {}.\"", ")", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "folds", ")", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "\"Expected type None or int for argument folds, but got type {}.\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "type", "(", "folds", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__getitem__": [[109, 134], ["PIL.Image.fromarray", "numpy.transpose", "stl.STL10.transform", "int"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "if", "self", ".", "labels", "is", "not", "None", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", "class_name", "=", "self", ".", "classes", "[", "target", "]", "\n", "", "else", ":", "\n", "            ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "255", "# 255 is an ignore index", "\n", "class_name", "=", "'unlabeled'", "\n", "\n", "# make consistent with all other datasets", "\n", "# return a PIL Image", "\n", "", "img", "=", "Image", ".", "fromarray", "(", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "img_size", "=", "img", ".", "size", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "out", "=", "{", "'image'", ":", "img", ",", "'target'", ":", "target", ",", "'meta'", ":", "{", "'im_size'", ":", "img_size", ",", "'index'", ":", "index", ",", "'class_name'", ":", "class_name", "}", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.get_image": [[135, 139], ["numpy.transpose"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "img", "=", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__len__": [[140, 142], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__loadfile": [[143, 159], ["os.path.join", "os.path.join", "open", "numpy.fromfile", "numpy.reshape", "numpy.transpose", "open", "numpy.fromfile"], "methods", ["None"], ["", "def", "__loadfile", "(", "self", ",", "data_file", ",", "labels_file", "=", "None", ")", ":", "\n", "        ", "labels", "=", "None", "\n", "if", "labels_file", ":", "\n", "            ", "path_to_labels", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "root", ",", "self", ".", "base_folder", ",", "labels_file", ")", "\n", "with", "open", "(", "path_to_labels", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "labels", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "uint8", ")", "-", "1", "# 0-based", "\n", "\n", "", "", "path_to_data", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "data_file", ")", "\n", "with", "open", "(", "path_to_data", ",", "'rb'", ")", "as", "f", ":", "\n", "# read whole file in uint8 chunks", "\n", "            ", "everything", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "images", "=", "np", ".", "reshape", "(", "everything", ",", "(", "-", "1", ",", "3", ",", "96", ",", "96", ")", ")", "\n", "images", "=", "np", ".", "transpose", "(", "images", ",", "(", "0", ",", "1", ",", "3", ",", "2", ")", ")", "\n", "\n", "", "return", "images", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10._check_integrity": [[160, 168], ["os.path.join", "torchvision.datasets.utils.check_integrity"], "methods", ["None"], ["", "def", "_check_integrity", "(", "self", ")", ":", "\n", "        ", "root", "=", "self", ".", "root", "\n", "for", "fentry", "in", "(", "self", ".", "train_list", "+", "self", ".", "test_list", ")", ":", "\n", "            ", "filename", ",", "md5", "=", "fentry", "[", "0", "]", ",", "fentry", "[", "1", "]", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "base_folder", ",", "filename", ")", "\n", "if", "not", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.download": [[169, 175], ["stl.STL10._check_integrity", "torchvision.datasets.utils.download_and_extract_archive", "stl.STL10._check_integrity", "print"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "print", "(", "'Files already downloaded and verified'", ")", "\n", "return", "\n", "", "download_and_extract_archive", "(", "self", ".", "url", ",", "self", ".", "root", ",", "filename", "=", "self", ".", "filename", ",", "md5", "=", "self", ".", "tgz_md5", ")", "\n", "self", ".", "_check_integrity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.extra_repr": [[176, 178], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"Split: {split}\"", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.stl.STL10.__load_folds": [[179, 189], ["os.path.join", "open", "numpy.fromstring", "f.read().splitlines", "f.read"], "methods", ["None"], ["", "def", "__load_folds", "(", "self", ",", "folds", ")", ":", "\n", "# loads one of the folds if specified", "\n", "        ", "if", "folds", "is", "None", ":", "\n", "            ", "return", "\n", "", "path_to_folds", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "root", ",", "self", ".", "base_folder", ",", "self", ".", "folds_list_file", ")", "\n", "with", "open", "(", "path_to_folds", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "str_idx", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "[", "folds", "]", "\n", "list_idx", "=", "np", ".", "fromstring", "(", "str_idx", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "' '", ")", "\n", "self", ".", "data", ",", "self", ".", "labels", "=", "self", ".", "data", "[", "list_idx", ",", ":", ",", ":", ",", ":", "]", ",", "self", ".", "labels", "[", "list_idx", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.__init__": [[49, 91], ["utils.mypath.MyPath.db_root_dir", "torch.utils.data.Dataset.__init__", "numpy.vstack().reshape", "cifar.CIFAR10.data.transpose", "cifar.CIFAR10._load_meta", "cifar.CIFAR10.download", "cifar.CIFAR10._check_integrity", "RuntimeError", "os.path.join", "open", "cifar.CIFAR10.data.append", "numpy.vstack", "pickle.load", "pickle.load", "cifar.CIFAR10.targets.extend", "cifar.CIFAR10.targets.extend"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._load_meta", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.download", "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity"], ["def", "__init__", "(", "self", ",", "root", "=", "MyPath", ".", "db_root_dir", "(", "'cifar-10'", ")", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "\n", "download", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "CIFAR10", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "classes", "=", "[", "'plane'", ",", "'car'", ",", "'bird'", ",", "'cat'", ",", "'deer'", ",", "'dog'", ",", "'frog'", ",", "'horse'", ",", "'ship'", ",", "'truck'", "]", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "train_list", "\n", "", "else", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "test_list", "\n", "\n", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "# now load the picked numpy arrays", "\n", "for", "file_name", ",", "checksum", "in", "downloaded_list", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "file_name", ")", "\n", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "entry", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "                    ", "entry", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", ".", "append", "(", "entry", "[", "'data'", "]", ")", "\n", "if", "'labels'", "in", "entry", ":", "\n", "                    ", "self", ".", "targets", ".", "extend", "(", "entry", "[", "'labels'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "targets", ".", "extend", "(", "entry", "[", "'fine_labels'", "]", ")", "\n", "\n", "", "", "", "self", ".", "data", "=", "np", ".", "vstack", "(", "self", ".", "data", ")", ".", "reshape", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n", "self", ".", "_load_meta", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._load_meta": [[92, 104], ["os.path.join", "torchvision.datasets.utils.check_integrity", "RuntimeError", "open", "pickle.load", "pickle.load", "enumerate"], "methods", ["None"], ["", "def", "_load_meta", "(", "self", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "self", ".", "meta", "[", "'filename'", "]", ")", "\n", "if", "not", "check_integrity", "(", "path", ",", "self", ".", "meta", "[", "'md5'", "]", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset metadata file not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "", "with", "open", "(", "path", ",", "'rb'", ")", "as", "infile", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "infile", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "infile", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "classes", "=", "data", "[", "self", ".", "meta", "[", "'key'", "]", "]", "\n", "", "self", ".", "class_to_idx", "=", "{", "_class", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "self", ".", "classes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.__getitem__": [[105, 123], ["PIL.Image.fromarray", "cifar.CIFAR10.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            dict: {'image': image, 'target': index of target class, 'meta': dict}\n        \"\"\"", "\n", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "img_size", "=", "(", "img", ".", "shape", "[", "0", "]", ",", "img", ".", "shape", "[", "1", "]", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "class_name", "=", "self", ".", "classes", "[", "target", "]", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "out", "=", "{", "'image'", ":", "img", ",", "'target'", ":", "target", ",", "'meta'", ":", "{", "'im_size'", ":", "img_size", ",", "'index'", ":", "index", ",", "'class_name'", ":", "class_name", "}", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.get_image": [[124, 127], ["None"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "self", ".", "data", "[", "index", "]", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.__len__": [[128, 130], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity": [[131, 139], ["os.path.join", "torchvision.datasets.utils.check_integrity"], "methods", ["None"], ["", "def", "_check_integrity", "(", "self", ")", ":", "\n", "        ", "root", "=", "self", ".", "root", "\n", "for", "fentry", "in", "(", "self", ".", "train_list", "+", "self", ".", "test_list", ")", ":", "\n", "            ", "filename", ",", "md5", "=", "fentry", "[", "0", "]", ",", "fentry", "[", "1", "]", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "base_folder", ",", "filename", ")", "\n", "if", "not", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.download": [[140, 145], ["cifar.CIFAR10._check_integrity", "torchvision.datasets.utils.download_and_extract_archive", "print"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10._check_integrity"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "print", "(", "'Files already downloaded and verified'", ")", "\n", "return", "\n", "", "download_and_extract_archive", "(", "self", ".", "url", ",", "self", ".", "root", ",", "filename", "=", "self", ".", "filename", ",", "md5", "=", "self", ".", "tgz_md5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR10.extra_repr": [[146, 148], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"Split: {}\"", ".", "format", "(", "\"Train\"", "if", "self", ".", "train", "is", "True", "else", "\"Test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.cifar.CIFAR100.__init__": [[171, 176], ["utils.mypath.MyPath.db_root_dir", "cifar.CIFAR10.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "__init__", "(", "self", ",", "root", "=", "MyPath", ".", "db_root_dir", "(", "'cifar-100'", ")", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "\n", "download", "=", "False", ")", ":", "\n", "        ", "super", "(", "CIFAR100", ",", "self", ")", ".", "__init__", "(", "root", ",", "train", "=", "train", ",", "transform", "=", "transform", ",", "\n", "download", "=", "download", ")", "\n", "self", ".", "classes", "=", "self", ".", "targets", "", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Augment.__init__": [[102, 105], ["augment.augment_list"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.augment_list"], ["\"posterize\"", ":", "(", "0", ",", "4", ",", "False", ")", ",", "\n", "\"posterize_inc\"", ":", "(", "0", ",", "4", ",", "False", ")", ",", "\n", "\"solarize\"", ":", "(", "0", ",", "256", ",", "False", ")", ",", "\n", "\"solarize_inc\"", ":", "(", "0", ",", "256", ",", "False", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Augment.__call__": [[106, 113], ["random.choices", "op", "random.random", "float"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], ["\"solarize_add\"", ":", "(", "0", ",", "110", ",", "False", ")", ",", "\n", "\"color\"", ":", "(", "0.1", ",", "1.9", ",", "False", ")", ",", "\n", "\"contrast\"", ":", "(", "0.1", ",", "1.9", ",", "False", ")", ",", "\n", "\"brightness\"", ":", "(", "0.1", ",", "1.9", ",", "False", ")", ",", "\n", "\"sharpness\"", ":", "(", "0.1", ",", "1.9", ",", "False", ")", ",", "\n", "\"color_inc\"", ":", "(", "0", ",", "0.9", ",", "True", ")", ",", "\n", "\"contrast_inc\"", ":", "(", "0", ",", "0.9", ",", "True", ")", ",", "\n", "\"brightness_inc\"", ":", "(", "0", ",", "0.9", ",", "True", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Cutout.__init__": [[122, 126], ["None"], "methods", ["None"], ["AUTOAUG_POLICY", "=", "[", "\n", "# AutoAugment \"policy_v0\" in form of (op, prob, magnitude), where magnitude <= 1.", "\n", "[", "(", "\"equalize\"", ",", "0.8", ",", "0.1", ")", ",", "(", "\"shear_y\"", ",", "0.8", ",", "0.4", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.4", ",", "0.9", ")", ",", "(", "\"equalize\"", ",", "0.6", ",", "0.3", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.4", ",", "0.1", ")", ",", "(", "\"rotate\"", ",", "0.6", ",", "0.8", ")", "]", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Cutout.__call__": [[127, 149], ["img.size", "img.size", "random.randint", "numpy.ones", "range", "torch.from_numpy", "mask.expand_as.expand_as.expand_as", "numpy.random.randint", "numpy.random.randint", "numpy.clip", "numpy.clip", "numpy.clip", "numpy.clip"], "methods", ["None"], ["[", "(", "\"solarize\"", ",", "0.8", ",", "0.3", ")", ",", "(", "\"equalize\"", ",", "0.4", ",", "0.7", ")", "]", ",", "\n", "[", "(", "\"solarize\"", ",", "0.4", ",", "0.2", ")", ",", "(", "\"solarize\"", ",", "0.6", ",", "0.2", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.2", ",", "0.0", ")", ",", "(", "\"equalize\"", ",", "0.8", ",", "0.8", ")", "]", ",", "\n", "[", "(", "\"equalize\"", ",", "0.4", ",", "0.8", ")", ",", "(", "\"solarize_add\"", ",", "0.8", ",", "0.3", ")", "]", ",", "\n", "[", "(", "\"shear_x\"", ",", "0.2", ",", "0.9", ")", ",", "(", "\"rotate\"", ",", "0.6", ",", "0.8", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.6", ",", "0.1", ")", ",", "(", "\"equalize\"", ",", "1.0", ",", "0.2", ")", "]", ",", "\n", "[", "(", "\"invert\"", ",", "0.4", ",", "0.9", ")", ",", "(", "\"rotate\"", ",", "0.6", ",", "0.0", ")", "]", ",", "\n", "[", "(", "\"equalize\"", ",", "1.0", ",", "0.9", ")", ",", "(", "\"shear_y\"", ",", "0.6", ",", "0.3", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.4", ",", "0.7", ")", ",", "(", "\"equalize\"", ",", "0.6", ",", "0.0", ")", "]", ",", "\n", "[", "(", "\"posterize\"", ",", "0.4", ",", "0.6", ")", ",", "(", "\"auto_contrast\"", ",", "0.4", ",", "0.7", ")", "]", ",", "\n", "[", "(", "\"solarize\"", ",", "0.6", ",", "0.8", ")", ",", "(", "\"color\"", ",", "0.6", ",", "0.9", ")", "]", ",", "\n", "[", "(", "\"solarize\"", ",", "0.2", ",", "0.4", ")", ",", "(", "\"rotate\"", ",", "0.8", ",", "0.9", ")", "]", ",", "\n", "[", "(", "\"rotate\"", ",", "1.0", ",", "0.7", ")", ",", "(", "\"trans_y\"", ",", "0.8", ",", "0.9", ")", "]", ",", "\n", "[", "(", "\"shear_x\"", ",", "0.0", ",", "0.0", ")", ",", "(", "\"solarize\"", ",", "0.8", ",", "0.4", ")", "]", ",", "\n", "[", "(", "\"shear_y\"", ",", "0.8", ",", "0.0", ")", ",", "(", "\"color\"", ",", "0.6", ",", "0.4", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "1.0", ",", "0.0", ")", ",", "(", "\"rotate\"", ",", "0.6", ",", "0.2", ")", "]", ",", "\n", "[", "(", "\"equalize\"", ",", "0.8", ",", "0.4", ")", ",", "(", "\"equalize\"", ",", "0.0", ",", "0.8", ")", "]", ",", "\n", "[", "(", "\"equalize\"", ",", "1.0", ",", "0.4", ")", ",", "(", "\"auto_contrast\"", ",", "0.6", ",", "0.2", ")", "]", ",", "\n", "[", "(", "\"shear_y\"", ",", "0.4", ",", "0.7", ")", ",", "(", "\"solarize_add\"", ",", "0.6", ",", "0.7", ")", "]", ",", "\n", "[", "(", "\"posterize\"", ",", "0.8", ",", "0.2", ")", ",", "(", "\"solarize\"", ",", "0.6", ",", "1.0", ")", "]", ",", "\n", "[", "(", "\"solarize\"", ",", "0.6", ",", "0.8", ")", ",", "(", "\"equalize\"", ",", "0.6", ",", "0.1", ")", "]", ",", "\n", "[", "(", "\"color\"", ",", "0.8", ",", "0.6", ")", ",", "(", "\"rotate\"", ",", "0.4", ",", "0.5", ")", "]", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.ShearX": [[11, 15], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.ShearY": [[16, 20], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Identity": [[21, 23], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.TranslateX": [[24, 29], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.TranslateY": [[30, 35], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.TranslateXAbs": [[36, 40], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.TranslateYAbs": [[41, 45], ["img.transform", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Rotate": [[46, 50], ["img.rotate", "random.random"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.al.Sampling.Sampling.random"], ["\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.AutoContrast": [[51, 53], ["PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast", "PIL.ImageOps.autocontrast"], "function", ["None"], ["\n", "import", "random", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Invert": [[54, 56], ["PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert", "PIL.ImageOps.invert"], "function", ["None"], ["import", "numpy", "as", "np", "\n", "from", "PIL", "import", "Image", ",", "ImageEnhance", ",", "ImageOps", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Equalize": [[57, 59], ["PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize", "PIL.ImageOps.equalize"], "function", ["None"], ["\n", "# Minimum value for posterize (0 in EfficientNet implementation)", "\n", "POSTERIZE_MIN", "=", "1", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Solarize": [[60, 62], ["PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize", "PIL.ImageOps.solarize"], "function", ["None"], ["\n", "# Parameters for affine warping and rotation", "\n", "WARP_PARAMS", "=", "{", "\"fillcolor\"", ":", "(", "128", ",", "128", ",", "128", ")", ",", "\"resample\"", ":", "Image", ".", "BILINEAR", "}", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Posterize": [[63, 66], ["int", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize", "PIL.ImageOps.posterize"], "function", ["None"], ["\n", "\n", "def", "affine_warp", "(", "im", ",", "data", ")", ":", "\n", "    ", "\"\"\"Applies affine transform to image.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Contrast": [[67, 69], ["PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast().enhance", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast", "PIL.ImageEnhance.Contrast"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Contrast", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Contrast", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Contrast", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Contrast"], ["return", "im", ".", "transform", "(", "im", ".", "size", ",", "Image", ".", "AFFINE", ",", "data", ",", "**", "WARP_PARAMS", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Color": [[70, 72], ["PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color().enhance", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color", "PIL.ImageEnhance.Color"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Color", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Color", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Color", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Color"], ["", "OP_FUNCTIONS", "=", "{", "\n", "# Each op takes an image x and a level v and returns an augmented image.", "\n", "\"auto_contrast\"", ":", "lambda", "x", ",", "_", ":", "ImageOps", ".", "autocontrast", "(", "x", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Brightness": [[73, 75], ["PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness().enhance", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness", "PIL.ImageEnhance.Brightness"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Brightness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Brightness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Brightness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Brightness"], ["\"equalize\"", ":", "lambda", "x", ",", "_", ":", "ImageOps", ".", "equalize", "(", "x", ")", ",", "\n", "\"invert\"", ":", "lambda", "x", ",", "_", ":", "ImageOps", ".", "invert", "(", "x", ")", ",", "\n", "\"rotate\"", ":", "lambda", "x", ",", "v", ":", "x", ".", "rotate", "(", "v", ",", "**", "WARP_PARAMS", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Sharpness": [[76, 78], ["PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness().enhance", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness", "PIL.ImageEnhance.Sharpness"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Sharpness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Sharpness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Sharpness", "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.Sharpness"], ["\"posterize\"", ":", "lambda", "x", ",", "v", ":", "ImageOps", ".", "posterize", "(", "x", ",", "max", "(", "POSTERIZE_MIN", ",", "int", "(", "v", ")", ")", ")", ",", "\n", "\"posterize_inc\"", ":", "lambda", "x", ",", "v", ":", "ImageOps", ".", "posterize", "(", "x", ",", "max", "(", "POSTERIZE_MIN", ",", "4", "-", "int", "(", "v", ")", ")", ")", ",", "\n", "\"solarize\"", ":", "lambda", "x", ",", "v", ":", "x", ".", "point", "(", "lambda", "i", ":", "i", "if", "i", "<", "int", "(", "v", ")", "else", "255", "-", "i", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.augment_list": [[79, 97], ["None"], "function", ["None"], ["\"solarize_inc\"", ":", "lambda", "x", ",", "v", ":", "x", ".", "point", "(", "lambda", "i", ":", "i", "if", "i", "<", "256", "-", "v", "else", "255", "-", "i", ")", ",", "\n", "\"solarize_add\"", ":", "lambda", "x", ",", "v", ":", "x", ".", "point", "(", "lambda", "i", ":", "min", "(", "255", ",", "v", "+", "i", ")", "if", "i", "<", "128", "else", "i", ")", ",", "\n", "\"color\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Color", "(", "x", ")", ".", "enhance", "(", "v", ")", ",", "\n", "\"contrast\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Contrast", "(", "x", ")", ".", "enhance", "(", "v", ")", ",", "\n", "\"brightness\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Brightness", "(", "x", ")", ".", "enhance", "(", "v", ")", ",", "\n", "\"sharpness\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Sharpness", "(", "x", ")", ".", "enhance", "(", "v", ")", ",", "\n", "\"color_inc\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Color", "(", "x", ")", ".", "enhance", "(", "1", "+", "v", ")", ",", "\n", "\"contrast_inc\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Contrast", "(", "x", ")", ".", "enhance", "(", "1", "+", "v", ")", ",", "\n", "\"brightness_inc\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Brightness", "(", "x", ")", ".", "enhance", "(", "1", "+", "v", ")", ",", "\n", "\"sharpness_inc\"", ":", "lambda", "x", ",", "v", ":", "ImageEnhance", ".", "Sharpness", "(", "x", ")", ".", "enhance", "(", "1", "+", "v", ")", ",", "\n", "\"shear_x\"", ":", "lambda", "x", ",", "v", ":", "affine_warp", "(", "x", ",", "(", "1", ",", "v", ",", "0", ",", "0", ",", "1", ",", "0", ")", ")", ",", "\n", "\"shear_y\"", ":", "lambda", "x", ",", "v", ":", "affine_warp", "(", "x", ",", "(", "1", ",", "0", ",", "0", ",", "v", ",", "1", ",", "0", ")", ")", ",", "\n", "\"trans_x\"", ":", "lambda", "x", ",", "v", ":", "affine_warp", "(", "x", ",", "(", "1", ",", "0", ",", "v", "*", "x", ".", "size", "[", "0", "]", ",", "0", ",", "1", ",", "0", ")", ")", ",", "\n", "\"trans_y\"", ":", "lambda", "x", ",", "v", ":", "affine_warp", "(", "x", ",", "(", "1", ",", "0", ",", "0", ",", "0", ",", "1", ",", "v", "*", "x", ".", "size", "[", "1", "]", ")", ")", ",", "\n", "}", "\n", "\n", "\n", "OP_RANGES", "=", "{", "\n", "# Ranges for each op in the form of a (min, max, negate).", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.get_augment": [[114, 116], ["None"], "function", ["None"], ["\"sharpness_inc\"", ":", "(", "0", ",", "0.9", ",", "True", ")", ",", "\n", "\"shear_x\"", ":", "(", "0.0", ",", "0.3", ",", "True", ")", ",", "\n", "\"shear_y\"", ":", "(", "0.0", ",", "0.3", ",", "True", ")", ",", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.apply_augment": [[117, 120], ["augment.get_augment", "augment_fn", "img.copy"], "function", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.augment.get_augment"], ["\"trans_x\"", ":", "(", "0.0", ",", "0.45", ",", "True", ")", ",", "\n", "\"trans_y\"", ":", "(", "0.0", ",", "0.45", ",", "True", ")", ",", "\n", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.TinyImageNet.__init__": [[39, 55], ["torchvision.datasets.utils.verify_str_arg", "tinyimagenet.TinyImageNet.targets.astype", "list", "torchvision.datasets.VisionDataset.__init__", "tinyimagenet.unpickle_object", "tinyimagenet.TinyImageNet.cls_to_id.keys", "tinyimagenet.unpickle_object", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__", "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.unpickle_object", "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.unpickle_object"], ["def", "__init__", "(", "self", ",", "root", ":", "str", ",", "split", ":", "str", "=", "'train'", ",", "transform", "=", "None", ",", "**", "kwargs", ":", "Any", ")", "->", "None", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "if", "split", "==", "'train+unlabeled'", ":", "\n", "            ", "split", "=", "'train'", "\n", "", "self", ".", "split", "=", "datasets", ".", "utils", ".", "verify_str_arg", "(", "split", ",", "\"split\"", ",", "(", "\"train\"", ",", "\"val\"", ")", ")", "\n", "\n", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "images", ",", "self", ".", "targets", ",", "self", ".", "cls_to_id", "=", "unpickle_object", "(", "'../../../daphna/data/tiny_imagenet/tiny-imagenet-200/train.pkl'", ")", "\n", "", "elif", "self", ".", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "images", ",", "self", ".", "targets", ",", "self", ".", "cls_to_id", "=", "unpickle_object", "(", "'../../../daphna/data/tiny_imagenet/tiny-imagenet-200/val.pkl'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'unknown split'", ")", "\n", "", "self", ".", "targets", "=", "self", ".", "targets", ".", "astype", "(", "int", ")", "\n", "self", ".", "classes", "=", "list", "(", "self", ".", "cls_to_id", ".", "keys", "(", ")", ")", "\n", "super", "(", "TinyImageNet", ",", "self", ")", ".", "__init__", "(", "root", ",", "**", "kwargs", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.TinyImageNet.split_folder": [[58, 61], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "split_folder", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.TinyImageNet.__getitem__": [[62, 78], ["PIL.Image.fromarray", "int", "tinyimagenet.TinyImageNet.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n\n        Returns:\n            tuple: (sample, target) where target is class_index of the target class.\n        \"\"\"", "\n", "sample", "=", "Image", ".", "fromarray", "(", "self", ".", "images", "[", "index", "]", ")", "\n", "target", "=", "int", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "\n", "", "out", "=", "{", "'image'", ":", "sample", ",", "'target'", ":", "target", ",", "'meta'", ":", "{", "'im_size'", ":", "64", ",", "'index'", ":", "index", ",", "'class_name'", ":", "target", "}", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.TinyImageNet.__len__": [[79, 81], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.tinyimagenet.unpickle_object": [[12, 16], ["open", "pickle.load"], "function", ["None"], ["def", "unpickle_object", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'rb+'", ")", "as", "file_pi", ":", "\n", "        ", "res", "=", "pickle", ".", "load", "(", "file_pi", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNet.__init__": [[16, 22], ["utils.mypath.MyPath.db_root_dir", "torchvision.ImageFolder.__init__", "torchvision.transforms.Resize", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root", "=", "MyPath", ".", "db_root_dir", "(", "'imagenet'", ")", ",", "split", "=", "'train'", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "ImageNet", ",", "self", ")", ".", "__init__", "(", "root", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'ILSVRC2012_img_%s'", "%", "(", "split", ")", ")", ",", "\n", "transform", "=", "None", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "resize", "=", "tf", ".", "Resize", "(", "256", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNet.__len__": [[23, 25], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNet.__getitem__": [[26, 39], ["imagenet.ImageNet.resize", "open", "PIL.Image.open().convert", "imagenet.ImageNet.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "im_size", "=", "img", ".", "size", "\n", "img", "=", "self", ".", "resize", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "out", "=", "{", "'image'", ":", "img", ",", "'target'", ":", "target", ",", "'meta'", ":", "{", "'im_size'", ":", "im_size", ",", "'index'", ":", "index", "}", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNet.get_image": [[40, 46], ["imagenet.ImageNet.resize", "open", "PIL.Image.open().convert", "PIL.Image.open"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "img", "=", "self", ".", "resize", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNetSubset.__init__": [[49, 78], ["utils.mypath.MyPath.db_root_dir", "torch.Dataset.__init__", "os.path.join", "enumerate", "torchvision.transforms.Resize", "open", "f.read().splitlines", "line.split", "subdirs.append", "class_names.append", "os.path.join", "sorted", "glob.glob.glob", "imgs.append", "f.read", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.mypath.MyPath.db_root_dir", "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "subset_file", ",", "root", "=", "MyPath", ".", "db_root_dir", "(", "'imagenet'", ")", ",", "split", "=", "'train'", ",", "\n", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "ImageNetSubset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "root", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'ILSVRC2012_img_%s'", "%", "(", "split", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "split", "=", "split", "\n", "\n", "# Read the subset of classes to include (sorted)", "\n", "with", "open", "(", "subset_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "result", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "subdirs", ",", "class_names", "=", "[", "]", ",", "[", "]", "\n", "for", "line", "in", "result", ":", "\n", "            ", "subdir", ",", "class_name", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "subdirs", ".", "append", "(", "subdir", ")", "\n", "class_names", ".", "append", "(", "class_name", ")", "\n", "\n", "# Gather the files (sorted)", "\n", "", "imgs", "=", "[", "]", "\n", "for", "i", ",", "subdir", "in", "enumerate", "(", "subdirs", ")", ":", "\n", "            ", "subdir_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "subdir", ")", "\n", "files", "=", "sorted", "(", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "subdir", ",", "'*.JPEG'", ")", ")", ")", "\n", "for", "f", "in", "files", ":", "\n", "                ", "imgs", ".", "append", "(", "(", "f", ",", "i", ")", ")", "\n", "", "", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "classes", "=", "class_names", "\n", "\n", "# Resize", "\n", "self", ".", "resize", "=", "tf", ".", "Resize", "(", "256", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNetSubset.get_image": [[79, 85], ["imagenet.ImageNetSubset.resize", "open", "PIL.Image.open().convert", "PIL.Image.open"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "img", "=", "self", ".", "resize", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNetSubset.__len__": [[86, 88], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imgs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.imagenet.ImageNetSubset.__getitem__": [[89, 103], ["imagenet.ImageNetSubset.resize", "open", "PIL.Image.open().convert", "imagenet.ImageNetSubset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", ",", "target", "=", "self", ".", "imgs", "[", "index", "]", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "im_size", "=", "img", ".", "size", "\n", "img", "=", "self", ".", "resize", "(", "img", ")", "\n", "class_name", "=", "self", ".", "classes", "[", "target", "]", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "out", "=", "{", "'image'", ":", "img", ",", "'target'", ":", "target", ",", "'meta'", ":", "{", "'im_size'", ":", "im_size", ",", "'index'", ":", "index", ",", "'class_name'", ":", "class_name", "}", "}", "\n", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.AugmentedDataset.__init__": [[14, 27], ["torch.utils.data.Dataset.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "super", "(", "AugmentedDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "transform", "=", "dataset", ".", "transform", "\n", "dataset", ".", "transform", "=", "None", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "isinstance", "(", "transform", ",", "dict", ")", ":", "\n", "            ", "self", ".", "image_transform", "=", "transform", "[", "'standard'", "]", "\n", "self", ".", "augmentation_transform", "=", "transform", "[", "'augment'", "]", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "image_transform", "=", "transform", "\n", "self", ".", "augmentation_transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.AugmentedDataset.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.AugmentedDataset.__getitem__": [[31, 39], ["custom_dataset.AugmentedDataset.dataset.__getitem__", "custom_dataset.AugmentedDataset.image_transform", "custom_dataset.AugmentedDataset.augmentation_transform"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "image", "=", "sample", "[", "'image'", "]", "\n", "\n", "sample", "[", "'image'", "]", "=", "self", ".", "image_transform", "(", "image", ")", "\n", "sample", "[", "'image_augmented'", "]", "=", "self", ".", "augmentation_transform", "(", "image", ")", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__init__": [[46, 63], ["torch.utils.data.Dataset.__init__", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "indices", ",", "num_neighbors", "=", "None", ")", ":", "\n", "        ", "super", "(", "NeighborsDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "transform", "=", "dataset", ".", "transform", "\n", "\n", "if", "isinstance", "(", "transform", ",", "dict", ")", ":", "\n", "            ", "self", ".", "anchor_transform", "=", "transform", "[", "'standard'", "]", "\n", "self", ".", "neighbor_transform", "=", "transform", "[", "'augment'", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "anchor_transform", "=", "transform", "\n", "self", ".", "neighbor_transform", "=", "transform", "\n", "\n", "", "dataset", ".", "transform", "=", "None", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "indices", "=", "indices", "# Nearest neighbor indices (np.array  [len(dataset) x k])", "\n", "if", "num_neighbors", "is", "not", "None", ":", "\n", "            ", "self", ".", "indices", "=", "self", ".", "indices", "[", ":", ",", ":", "num_neighbors", "+", "1", "]", "\n", "", "assert", "(", "self", ".", "indices", ".", "shape", "[", "0", "]", "==", "len", "(", "self", ".", "dataset", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__len__": [[64, 66], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__getitem__": [[67, 83], ["custom_dataset.NeighborsDataset.dataset.__getitem__", "custom_dataset.NeighborsDataset.dataset.__getitem__", "custom_dataset.NeighborsDataset.anchor_transform", "custom_dataset.NeighborsDataset.neighbor_transform", "torch.from_numpy", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__getitem__", "home.repos.pwc.inspect_result.avihu111_typiclust.data.custom_dataset.NeighborsDataset.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "output", "=", "{", "}", "\n", "anchor", "=", "self", ".", "dataset", ".", "__getitem__", "(", "index", ")", "\n", "\n", "neighbor_index", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "indices", "[", "index", "]", ",", "1", ")", "[", "0", "]", "\n", "neighbor", "=", "self", ".", "dataset", ".", "__getitem__", "(", "neighbor_index", ")", "\n", "\n", "anchor", "[", "'image'", "]", "=", "self", ".", "anchor_transform", "(", "anchor", "[", "'image'", "]", ")", "\n", "neighbor", "[", "'image'", "]", "=", "self", ".", "neighbor_transform", "(", "neighbor", "[", "'image'", "]", ")", "\n", "\n", "output", "[", "'anchor'", "]", "=", "anchor", "[", "'image'", "]", "\n", "output", "[", "'neighbor'", "]", "=", "neighbor", "[", "'image'", "]", "\n", "output", "[", "'possible_neighbors'", "]", "=", "torch", ".", "from_numpy", "(", "self", ".", "indices", "[", "index", "]", ")", "\n", "output", "[", "'target'", "]", "=", "anchor", "[", "'target'", "]", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.MaskedCrossEntropyLoss.__init__": [[12, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], ["def", "get_loss_fun", "(", ")", ":", "\n", "    ", "\"\"\"Retrieves the loss function.\"\"\"", "\n", "assert", "cfg", ".", "MODEL", ".", "LOSS_FUN", "in", "_loss_funs", ".", "keys", "(", ")", ","]], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.MaskedCrossEntropyLoss.forward": [[15, 23], ["torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select().view.size", "torch.masked_select().view.size", "torch.masked_select().view.size", "torch.masked_select.size", "torch.masked_select.size", "torch.masked_select.size", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.masked_select().view", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "ValueError", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "mask.view"], "methods", ["None"], ["'Loss function \\'{}\\' not supported'", ".", "format", "(", "cfg", ".", "TRAIN", ".", "LOSS", ")", "\n", "return", "_loss_funs", "[", "cfg", ".", "MODEL", ".", "LOSS_FUN", "]", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "\n", "", "def", "register_loss_fun", "(", "name", ",", "ctor", ")", ":", "\n", "    ", "\"\"\"Registers a loss function dynamically.\"\"\"", "\n", "_loss_funs", "[", "name", "]", "=", "ctor", "\n", "", ""]], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.ConfidenceBasedCE.__init__": [[26, 32], ["torch.Module.__init__", "losses.MaskedCrossEntropyLoss", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.ConfidenceBasedCE.forward": [[33, 65], ["losses.ConfidenceBasedCE.softmax", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "losses.ConfidenceBasedCE.size", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select.size", "torch.masked_select.size", "torch.masked_select.size", "losses.ConfidenceBasedCE.loss", "mask.squeeze", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "torch.ones().cuda", "counts.float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SCANLoss.__init__": [[90, 95], ["torch.Module.__init__", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SCANLoss.forward": [[96, 122], ["anchors.size", "losses.SCANLoss.softmax", "losses.SCANLoss.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "losses.SCANLoss.bce", "losses.entropy", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "losses.SCANLoss.view", "losses.SCANLoss.view"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.entropy"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__": [[126, 129], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.__init__"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.SimCLRLoss.forward": [[131, 166], ["features.size", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "mask.repeat.repeat.repeat", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.scatter", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "logits_max.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.arange().view().cuda", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "exp_logits.sum", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "mask.repeat.repeat.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda", "home.repos.pwc.inspect_result.avihu111_typiclust.utils.memory.MemoryBank.cuda"], []], "home.repos.pwc.inspect_result.avihu111_typiclust.losses.losses.entropy": [[67, 87], ["torch.clamp", "torch.clamp", "torch.clamp", "len", "torch.log", "torch.log", "torch.log", "torch.softmax", "torch.log_softmax", "b.size", "b.sum().mean", "len", "ValueError", "b.size", "b.sum", "b.sum", "len", "b.size"], "function", ["None"], []]}