{"home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.setup_logging": [[25, 38], ["logging.basicConfig", "logger.warning", "bool"], "function", ["None"], ["def", "setup_logging", "(", "training_args", ")", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "training_args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "training_args", ".", "local_rank", ",", "\n", "training_args", ".", "device", ",", "\n", "training_args", ".", "n_gpu", ",", "\n", "bool", "(", "training_args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "training_args", ".", "fp16", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.parse_cmd_args": [[41, 64], ["transformers.HfArgumentParser", "logger.info", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "len", "os.path.abspath"], "function", ["None"], ["", "def", "parse_cmd_args", "(", ")", ":", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "\n", "(", "\n", "CaMtlArguments", ",", "\n", "MultiTaskDataArguments", ",", "\n", "MultiTaskTrainingArguments", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "\n", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "(", "\n", "model_args", ",", "\n", "data_args", ",", "\n", "training_args", ",", "\n", ")", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "return", "model_args", ",", "data_args", ",", "training_args", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.create_eval_datasets": [[66, 79], ["enumerate", "src.data.task_dataset.TaskDataset", "src.data.task_dataset.TaskDataset", "src.utils.misc.Split.dev", "src.utils.misc.Split.test"], "function", ["None"], ["", "def", "create_eval_datasets", "(", "mode", ",", "data_args", ",", "tokenizer", ")", ":", "\n", "    ", "eval_datasets", "=", "{", "}", "\n", "for", "task_id", ",", "task_name", "in", "enumerate", "(", "data_args", ".", "tasks", ")", ":", "\n", "        ", "eval_datasets", "[", "task_name", "]", "=", "TaskDataset", "(", "\n", "task_name", ",", "task_id", ",", "data_args", ",", "tokenizer", ",", "mode", "=", "mode", "\n", ")", "\n", "if", "task_name", "==", "\"mnli\"", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "            ", "eval_datasets", "[", "\"mnli-mm\"", "]", "=", "TaskDataset", "(", "\n", "\"mnli-mm\"", ",", "task_id", ",", "data_args", ",", "tokenizer", ",", "mode", "=", "mode", "\n", ")", "\n", "\n", "", "", "return", "eval_datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.main": [[81, 135], ["run.parse_cmd_args", "run.setup_logging", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "src.model.ca_mtl.CaMtl.from_pretrained", "CaMtl.from_pretrained.freeze_encoder_layers", "logger.info", "transformers.AutoTokenizer.from_pretrained", "logger.info", "src.mtl_trainer.MultiTaskTrainer", "src.model.ca_mtl.CaMtl.get_base_model", "src.model.ca_mtl.CaMtl.get_base_model", "src.model.ca_mtl.CaMtl.get_base_model", "src.mtl_trainer.MultiTaskTrainer.train", "src.mtl_trainer.MultiTaskTrainer.evaluate", "src.mtl_trainer.MultiTaskTrainer.predict", "src.data.mtl_dataset.MultiTaskDataset", "run.create_eval_datasets", "run.create_eval_datasets", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.parse_cmd_args", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.setup_logging", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.freeze_encoder_layers", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.get_base_model", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.get_base_model", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.get_base_model", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.evaluate", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.predict", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.create_eval_datasets", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.create_eval_datasets"], ["", "def", "main", "(", ")", ":", "\n", "    ", "model_args", ",", "data_args", ",", "training_args", "=", "parse_cmd_args", "(", ")", "\n", "\n", "setup_logging", "(", "training_args", ")", "\n", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "CaMtl", ".", "get_base_model", "(", "model_args", ".", "model_name_or_path", ")", ",", "\n", ")", "\n", "\n", "model", "=", "CaMtl", ".", "from_pretrained", "(", "\n", "CaMtl", ".", "get_base_model", "(", "model_args", ".", "model_name_or_path", ")", ",", "\n", "model_args", ",", "\n", "data_args", ",", "\n", "config", "=", "config", ")", "\n", "model", ".", "freeze_encoder_layers", "(", "model_args", ")", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "CaMtl", ".", "get_base_model", "(", "model_args", ".", "model_name_or_path", ")", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training tasks: %s\"", ",", "\", \"", ".", "join", "(", "[", "t", "for", "t", "in", "data_args", ".", "tasks", "]", ")", ")", "\n", "\n", "trainer", "=", "MultiTaskTrainer", "(", "\n", "tokenizer", ",", "\n", "data_args", ",", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "MultiTaskDataset", "(", "data_args", ",", "tokenizer", ")", "\n", "if", "training_args", ".", "do_train", "\n", "else", "None", ",", "\n", "eval_datasets", "=", "create_eval_datasets", "(", "Split", ".", "dev", ",", "data_args", ",", "tokenizer", ")", "\n", "if", "training_args", ".", "do_eval", "or", "training_args", ".", "evaluate_during_training", "\n", "else", "None", ",", "\n", "test_datasets", "=", "create_eval_datasets", "(", "Split", ".", "test", ",", "data_args", ",", "tokenizer", ")", "\n", "if", "training_args", ".", "do_predict", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "train", "(", "\n", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "if", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", "\n", "else", "None", "\n", ")", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "trainer", ".", "predict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run._mp_fn": [[137, 140], ["run.main"], "function", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.None.run.main"], ["", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.__init__": [[45, 60], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "data_args", ",", "\n", "eval_datasets", "=", "None", ",", "\n", "test_datasets", "=", "None", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", "MultiTaskTrainer", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "eval_datasets", "=", "eval_datasets", "\n", "self", ".", "test_datasets", "=", "test_datasets", "\n", "self", ".", "eval_results", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.get_optimizers": [[61, 107], ["transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "mtl_trainer.MultiTaskTrainer.model.named_parameters", "mtl_trainer.MultiTaskTrainer.model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "get_optimizers", "(", "\n", "self", ",", "num_training_steps", ":", "int", "\n", ")", "->", "Tuple", "[", "torch", ".", "optim", ".", "Optimizer", ",", "torch", ".", "optim", ".", "lr_scheduler", ".", "LambdaLR", "]", ":", "\n", "        ", "\"\"\"\n        Setup the optimizer and the learning rate scheduler.\n\n        We provide a reasonable default that works well.\n        If you want to use something else, you can pass a tuple in the Trainer's init,\n        or override this method in a subclass.\n        \"\"\"", "\n", "if", "self", ".", "optimizers", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "optimizers", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "self", ".", "model", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "num_warmup_steps", "=", "(", "\n", "self", ".", "args", ".", "warmup_proportion", "*", "num_training_steps", "\n", ")", "# this is different from overridden function", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "self", ".", "args", ".", "learning_rate", ",", "\n", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ",", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "num_warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "# this is different from overridden function", "\n", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.get_train_dataloader": [[108, 113], ["mtl_trainer.MultiTaskTrainer._create_custom_dataloader", "super().get_train_dataloader"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer._create_custom_dataloader", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.get_train_dataloader"], ["", "def", "get_train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "if", "self", ".", "args", ".", "use_mt_uncertainty", ":", "\n", "            ", "return", "self", ".", "_create_custom_dataloader", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "get_train_dataloader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer._create_custom_dataloader": [[114, 262], ["CustomLoader", "torch.utils.data.dataloader.DataLoader", "data_loaders.append", "len", "enumerate", "mtl_trainer.MultiTaskTrainer.items", "inputs.items", "min", "torch.topk", "mtl_trainer.MultiTaskTrainer.items", "data.keys", "MtUcertaintyIterator", "torch.utils.data.sampler.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "iter", "len", "StopIteration", "mtl_trainer.MultiTaskTrainer.batchify_data", "torch.no_grad", "model", "min", "torch.index_select", "isinstance", "len", "int", "loader_iter.__next__", "v.detach().to", "tasks.index", "tasks.index", "len", "len", "stsb_idx.nonzero", "mrpc_idx.nonzero", "curr_batch.keys", "torch.cat", "l.sampler.set_epoch", "int", "sum", "iter", "iter.__next__", "v.detach", "len", "max", "max", "len"], "methods", ["None"], ["", "", "def", "_create_custom_dataloader", "(", "self", ")", ":", "\n", "        ", "class", "MtUcertaintyIterator", ":", "\n", "            ", "\"\"\"Sample tasks using uncertainty measure.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "my_loader", ")", ":", "\n", "                ", "self", ".", "my_loader", "=", "my_loader", "\n", "self", ".", "loader_iters", "=", "[", "iter", "(", "loader", ")", "for", "loader", "in", "self", ".", "my_loader", ".", "loaders", "]", "\n", "self", ".", "loader_iter_sizes", "=", "[", "len", "(", "i", ")", "for", "i", "in", "self", ".", "loader_iters", "]", "\n", "self", ".", "max_count", "=", "len", "(", "self", ".", "my_loader", ")", "\n", "self", ".", "batch_count", "=", "0", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "                ", "return", "self", "\n", "\n", "", "def", "__next__", "(", "self", ")", ":", "\n", "                ", "if", "self", ".", "batch_count", "==", "self", ".", "max_count", ":", "\n", "                    ", "self", ".", "batch_count", "=", "0", "\n", "raise", "StopIteration", "(", ")", "\n", "\n", "", "test_batch", "=", "{", "}", "\n", "for", "idx", ",", "loader_iter", "in", "enumerate", "(", "self", ".", "loader_iters", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "batch", "=", "loader_iter", ".", "__next__", "(", ")", "\n", "", "except", "StopIteration", ":", "\n", "                        ", "new_loader_iter", "=", "iter", "(", "self", ".", "my_loader", ".", "loaders", "[", "idx", "]", ")", "\n", "self", ".", "loader_iters", "[", "idx", "]", "=", "new_loader_iter", "\n", "batch", "=", "new_loader_iter", ".", "__next__", "(", ")", "\n", "\n", "", "test_batch", "=", "self", ".", "batchify_data", "(", "batch", ",", "test_batch", ")", "\n", "\n", "", "inputs", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "test_batch", ".", "items", "(", ")", ":", "\n", "                    ", "if", "k", "not", "in", "[", "\"labels\"", "]", ":", "\n", "                        ", "inputs", "[", "k", "]", "=", "v", ".", "detach", "(", ")", ".", "to", "(", "self", ".", "my_loader", ".", "args", ".", "device", ")", "\n", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "model", ".", "select_batch_mode", "=", "True", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "model", ".", "select_batch_mode", "=", "False", "\n", "\n", "", "(", "\n", "test_batch_entropy", ",", "\n", "test_batch_entropy_mean", ",", "\n", "max_mean_batch_entropy", ",", "\n", ")", "=", "outputs", "[", "-", "3", ":", "]", "\n", "\n", "for", "_", ",", "v", "in", "inputs", ".", "items", "(", ")", ":", "\n", "                    ", "del", "v", "# free GPU mem", "\n", "", "del", "inputs", "\n", "\n", "test_batch_entropy_mean", "=", "(", "\n", "test_batch_entropy_mean", "/", "max_mean_batch_entropy", "\n", ")", "\n", "test_batch_entropy", "=", "test_batch_entropy", "*", "test_batch_entropy_mean", "\n", "\n", "if", "\"sts-b\"", "in", "tasks", "and", "\"mrpc\"", "in", "tasks", ":", "\n", "                    ", "stsb_idx", "=", "test_batch", "[", "\"task_id\"", "]", "==", "tasks", ".", "index", "(", "\"sts-b\"", ")", "\n", "mrpc_idx", "=", "test_batch", "[", "\"task_id\"", "]", "==", "tasks", ".", "index", "(", "\"mrpc\"", ")", "\n", "num_items", "=", "min", "(", "\n", "len", "(", "test_batch_entropy", "[", "stsb_idx", "]", ")", ",", "\n", "len", "(", "test_batch_entropy", "[", "mrpc_idx", "]", ")", ",", "\n", ")", "\n", "stsb_idx", "=", "stsb_idx", ".", "nonzero", "(", ")", "[", ":", "num_items", "]", "\n", "mrpc_idx", "=", "mrpc_idx", ".", "nonzero", "(", ")", "[", ":", "num_items", "]", "\n", "test_batch_entropy", "[", "stsb_idx", "]", "=", "test_batch_entropy", "[", "mrpc_idx", "]", "\n", "test_batch_entropy_mean", "[", "stsb_idx", "]", "=", "test_batch_entropy_mean", "[", "\n", "mrpc_idx", "\n", "]", "\n", "\n", "", "select_size", "=", "min", "(", "\n", "self", ".", "my_loader", ".", "args", ".", "train_batch_size", ",", "\n", "test_batch", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", ",", "\n", ")", "# Handled the last batch if it is lower than the batch size", "\n", "\n", "top_entropy", "=", "torch", ".", "topk", "(", "test_batch_entropy", ",", "select_size", ")", "\n", "\n", "for", "k", ",", "v", "in", "test_batch", ".", "items", "(", ")", ":", "\n", "                    ", "test_batch", "[", "k", "]", "=", "torch", ".", "index_select", "(", "v", ",", "0", ",", "top_entropy", ".", "indices", ")", "\n", "\n", "", "self", ".", "batch_count", "+=", "1", "\n", "\n", "return", "test_batch", "\n", "\n", "", "@", "staticmethod", "\n", "def", "batchify_data", "(", "data", ",", "curr_batch", ")", ":", "\n", "                ", "for", "k", "in", "data", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "k", "in", "curr_batch", ".", "keys", "(", ")", ":", "\n", "                        ", "curr_batch", "[", "k", "]", "=", "torch", ".", "cat", "(", "(", "curr_batch", "[", "k", "]", ",", "data", "[", "k", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                        ", "curr_batch", "[", "k", "]", "=", "data", "[", "k", "]", "\n", "", "", "return", "curr_batch", "\n", "\n", "", "", "class", "CustomLoader", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "loaders", ",", "datasets", ",", "loader_args", ")", ":", "\n", "                ", "self", ".", "loaders", "=", "loaders", "\n", "self", ".", "dataset", "=", "datasets", "\n", "self", ".", "args", "=", "loader_args", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "                ", "iterator", "=", "MtUcertaintyIterator", "(", "self", ")", "\n", "\n", "# for determinism across runs", "\n", "# https://github.com/pytorch/examples/issues/501", "\n", "for", "l", "in", "self", ".", "loaders", ":", "\n", "                    ", "if", "isinstance", "(", "l", ".", "sampler", ",", "DistributedSampler", ")", ":", "\n", "                        ", "l", ".", "sampler", ".", "set_epoch", "(", "self", ".", "current_epoch", ")", "\n", "", "", "self", ".", "current_epoch", "+=", "1", "\n", "return", "iterator", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "                ", "loader_len", "=", "[", "len", "(", "loader", ")", "for", "loader", "in", "self", ".", "loaders", "]", "\n", "if", "self", ".", "args", ".", "uniform_mt_sampling", ":", "\n", "                    ", "return", "int", "(", "\n", "self", ".", "args", ".", "percent_of_max_data_size", "\n", "*", "max", "(", "loader_len", ")", "\n", "*", "len", "(", "self", ".", "loaders", ")", "\n", "/", "self", ".", "args", ".", "train_batch_size", "\n", ")", "\n", "", "elif", "self", ".", "args", ".", "use_mt_uncertainty", ":", "\n", "                    ", "return", "int", "(", "\n", "max", "(", "loader_len", ")", "\n", "*", "len", "(", "self", ".", "loaders", ")", "\n", "*", "self", ".", "args", ".", "percent_of_max_data_size", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "return", "sum", "(", "loader_len", ")", "\n", "\n", "", "", "", "model", "=", "self", ".", "model", "\n", "tasks", "=", "self", ".", "data_args", ".", "tasks", "\n", "\n", "data_loaders", "=", "[", "]", "\n", "for", "dataset", "in", "self", ".", "train_dataset", ".", "datasets", ":", "\n", "            ", "train_sampler", "=", "(", "\n", "RandomSampler", "(", "dataset", ")", "\n", "if", "self", ".", "args", ".", "local_rank", "==", "-", "1", "\n", "else", "DistributedSampler", "(", "dataset", ")", "\n", ")", "\n", "\n", "data_loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "self", ".", "args", ".", "train_batch_size", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "collate_fn", "=", "self", ".", "data_collator", ".", "collate_batch", ",", "\n", ")", "\n", "data_loaders", ".", "append", "(", "data_loader", ")", "\n", "\n", "", "return", "CustomLoader", "(", "data_loaders", ",", "self", ".", "train_dataset", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.evaluate": [[263, 281], ["logger.info", "datasets.items", "logger.info", "mtl_trainer.MultiTaskTrainer.build_compute_metrics_fn", "super().evaluate", "mtl_trainer.MultiTaskTrainer.update_eval_results", "mtl_trainer.MultiTaskTrainer.eval_results[].items", "logger.info"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.build_compute_metrics_fn", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.evaluate", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.update_eval_results"], ["", "def", "evaluate", "(", "\n", "self", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "context", ":", "str", "=", "None", ",", "\n", "do_test_if_needed", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "datasets", "=", "eval_dataset", "or", "self", ".", "eval_datasets", "\n", "logger", ".", "info", "(", "\"*** Evaluate on dev ***\"", ")", "\n", "for", "task_name", ",", "eval_dataset", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "task_name", ")", "\n", "self", ".", "compute_metrics", "=", "self", ".", "build_compute_metrics_fn", "(", "eval_dataset", ")", "\n", "eval_result", "=", "super", "(", ")", ".", "evaluate", "(", "\n", "eval_dataset", "=", "eval_dataset", ",", "prediction_loss_only", "=", "True", "\n", ")", "\n", "self", ".", "update_eval_results", "(", "eval_result", ",", "task_name", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "eval_results", "[", "task_name", "]", ".", "items", "(", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.predict": [[282, 310], ["logging.info", "datasets.items", "logger.info", "os.path.join", "mtl_trainer.MultiTaskTrainer.is_world_master", "super().predict", "numpy.argmax", "open", "logger.info", "writer.write", "enumerate", "writer.write", "writer.write", "test_dataset.get_labels"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.predict", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.get_labels"], ["", "", "", "def", "predict", "(", "\n", "self", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "prediction_loss_only", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"*** Test ***\"", ")", "\n", "datasets", "=", "eval_dataset", "or", "self", ".", "test_datasets", "\n", "for", "task_name", ",", "test_dataset", "in", "datasets", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "task_name", ")", "\n", "predictions", "=", "super", "(", ")", ".", "predict", "(", "test_dataset", "=", "test_dataset", ")", ".", "predictions", "\n", "output_mode", "=", "glue_output_modes", "[", "task_name", "]", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "                ", "predictions", "=", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "\n", "", "output_test_file", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", ".", "output_dir", ",", "\n", "f\"{task_name}_test_iter_{self.global_step}.tsv\"", ",", "\n", ")", "\n", "if", "self", ".", "is_world_master", "(", ")", ":", "\n", "                ", "with", "open", "(", "output_test_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                    ", "logger", ".", "info", "(", "\"***** Test results {} *****\"", ".", "format", "(", "task_name", ")", ")", "\n", "writer", ".", "write", "(", "\"index\\tprediction\\n\"", ")", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "predictions", ")", ":", "\n", "                        ", "if", "output_mode", "==", "\"regression\"", ":", "\n", "                            ", "writer", ".", "write", "(", "\"%d\\t%3.3f\\n\"", "%", "(", "index", ",", "item", ")", ")", "\n", "", "else", ":", "\n", "                            ", "writer", ".", "write", "(", "\n", "\"%d\\t%s\\n\"", "%", "(", "index", ",", "test_dataset", ".", "get_labels", "(", ")", "[", "item", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.update_eval_results": [[312, 318], ["mtl_trainer.MultiTaskTrainer.eval_results.get", "results.items", "max"], "methods", ["None"], ["", "", "", "", "", "", "def", "update_eval_results", "(", "self", ",", "results", ",", "task_name", ")", ":", "\n", "        ", "self", ".", "eval_results", "[", "task_name", "]", "=", "self", ".", "eval_results", ".", "get", "(", "task_name", ",", "{", "}", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "eval_results", "[", "task_name", "]", "and", "'loss'", "not", "in", "key", "and", "'epoch'", "not", "in", "key", ":", "\n", "                ", "value", "=", "max", "(", "self", ".", "eval_results", "[", "task_name", "]", "[", "key", "]", ",", "value", ")", "\n", "", "self", ".", "eval_results", "[", "task_name", "]", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.src.mtl_trainer.MultiTaskTrainer.build_compute_metrics_fn": [[320, 328], ["src.data.glue_utils.compute_glue_metrics"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.compute_glue_metrics"], ["", "", "@", "staticmethod", "\n", "def", "build_compute_metrics_fn", "(", "\n", "eval_dataset", "\n", ")", "->", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", ":", "\n", "        ", "def", "compute_metrics_fn", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "            ", "return", "compute_glue_metrics", "(", "eval_dataset", ".", "task_name", ",", "p", ")", "\n", "\n", "", "return", "compute_metrics_fn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.utils.misc.MultiTaskDataArguments.__post_init__": [[48, 60], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "tasks", "is", "None", ":", "\n", "            ", "self", ".", "tasks", "=", "[", "\n", "\"cola\"", ",", "\n", "\"mnli\"", ",", "\n", "\"rte\"", ",", "\n", "\"wnli\"", ",", "\n", "\"qqp\"", ",", "\n", "\"sts-b\"", ",", "\n", "\"sst-2\"", ",", "\n", "\"qnli\"", ",", "\n", "\"mrpc\"", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.decoder.Decoder.__init__": [[9, 14], ["super().__init__", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "task_name", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_labels", "=", "glue_tasks_num_labels", "[", "task_name", "]", "\n", "self", ".", "dropout", "=", "Dropout", "(", "0.1", ")", "\n", "self", ".", "model", "=", "Linear", "(", "hidden_size", ",", "self", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.decoder.Decoder.forward": [[15, 32], ["decoder.Decoder.dropout", "decoder.Decoder.model", "decoder.Decoder.calculate_entropy", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "decoder.Decoder.view", "labels.float().view", "decoder.Decoder.view", "labels.long().view", "labels.float", "labels.long"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.decoder.Decoder.calculate_entropy"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ",", "labels", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "model", "(", "pooled_output", ")", "\n", "\n", "batch_entropy", "=", "self", ".", "calculate_entropy", "(", "logits", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "return", "logits", ",", "loss", ",", "batch_entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.decoder.Decoder.calculate_entropy": [[33, 43], ["scipy.stats.entropy", "numpy.array", "scipy.stats.entropy", "torch.tensor", "torch.nn.Softmax", "logits.detach", "probas.transpose().cpu", "scipy.stats.entropy.item", "probas.transpose", "range"], "methods", ["None"], ["", "def", "calculate_entropy", "(", "self", ",", "logits", ")", ":", "\n", "        ", "probas", "=", "Softmax", "(", "dim", "=", "1", ")", "(", "logits", ".", "detach", "(", ")", ")", "\n", "samples_entropy", "=", "entropy", "(", "probas", ".", "transpose", "(", "0", ",", "1", ")", ".", "cpu", "(", ")", ")", "\n", "even_preds", "=", "numpy", ".", "array", "(", "\n", "[", "[", "1", "/", "self", ".", "num_labels", "for", "_", "in", "range", "(", "self", ".", "num_labels", ")", "]", "]", "\n", ")", "\n", "max_entropy", "=", "entropy", "(", "even_preds", ".", "T", ")", "\n", "epsilon", "=", "1e-5", "\n", "samples_entropy", "=", "samples_entropy", "/", "(", "max_entropy", ".", "item", "(", ")", "+", "epsilon", ")", "\n", "return", "torch", ".", "tensor", "(", "samples_entropy", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.__init__": [[37, 52], ["transformers.BertPreTrainedModel.__init__", "ca_mtl.CaMtl._create_encoder", "torch.ModuleList", "torch.ModuleList", "ca_mtl.CaMtl.init_weights", "ca_mtl.CaMtl.decoders.append", "src.model.decoder.Decoder"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl._create_encoder"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "config", ",", "\n", "model_args", ",", "\n", "data_args", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "bert", "=", "self", ".", "_create_encoder", "(", "model_args", ".", "model_name_or_path", ")", "\n", "self", ".", "decoders", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "task", "in", "data_args", ".", "tasks", ":", "\n", "            ", "self", ".", "decoders", ".", "append", "(", "Decoder", "(", "config", ".", "hidden_size", ",", "task", ")", ")", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.forward": [[53, 133], ["ca_mtl.CaMtl.bert", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.zeros_like().repeat().float", "torch.zeros_like().repeat().float", "torch.zeros_like().repeat().float", "torch.zeros_like().repeat().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.unique.cpu().numpy", "torch.unique.cpu().numpy", "torch.unique.numpy", "torch.unique.numpy", "ca_mtl.CaMtl.decoders[].forward", "batch_entropy.mean().item", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.zeros_like().repeat", "torch.zeros_like().repeat", "torch.zeros_like().repeat", "torch.zeros_like().repeat", "loss_list.append", "torch.unique.cpu", "torch.unique.cpu", "len", "batch_entropy.mean", "torch.zeros_like().repeat().float.view", "torch.zeros_like().repeat().float.view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.stack.mean", "torch.stack.mean"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalBottleNeck.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "task_id", "=", "None", ",", "\n", "span_locs", "=", "None", ",", "\n", "sample_id", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "task_id", "=", "task_id", ",", "\n", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "loss_list", "=", "[", "]", "\n", "unique_task_ids", "=", "torch", ".", "unique", "(", "task_id", ")", "\n", "unique_task_ids_list", "=", "(", "\n", "unique_task_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "unique_task_ids", ".", "is_cuda", "\n", "else", "unique_task_ids", ".", "numpy", "(", ")", "\n", ")", "\n", "loss_grouped_per_task", "=", "(", "\n", "torch", ".", "zeros_like", "(", "task_id", "[", "0", "]", ")", ".", "repeat", "(", "len", "(", "self", ".", "data_args", ".", "tasks", ")", ")", ".", "float", "(", ")", "\n", ")", "\n", "batch_entropy_per_task", "=", "torch", ".", "zeros", "(", "input_ids", ".", "shape", "[", "0", "]", ")", "\n", "batch_entropy_mean_per_task", "=", "torch", ".", "zeros", "(", "input_ids", ".", "shape", "[", "0", "]", ")", "\n", "max_mean_batch_entropy", "=", "None", "\n", "logits", "=", "None", "\n", "for", "unique_task_id", "in", "unique_task_ids_list", ":", "\n", "            ", "task_id_filter", "=", "task_id", "==", "unique_task_id", "\n", "decoder_id", "=", "unique_task_id", "\n", "logits", ",", "current_loss", ",", "batch_entropy", "=", "self", ".", "decoders", "[", "decoder_id", "]", ".", "forward", "(", "\n", "sequence_output", "[", "task_id_filter", "]", ",", "\n", "pooled_output", "[", "task_id_filter", "]", ",", "\n", "labels", "=", "None", "if", "labels", "is", "None", "else", "labels", "[", "task_id_filter", "]", ",", "\n", "attention_mask", "=", "attention_mask", "[", "task_id_filter", "]", ",", "\n", ")", "\n", "\n", "batch_entropy_mean", "=", "batch_entropy", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "batch_entropy_per_task", "[", "task_id_filter", "]", "=", "batch_entropy", "\n", "batch_entropy_mean_per_task", "[", "task_id_filter", "]", "=", "torch", ".", "full_like", "(", "\n", "batch_entropy", ",", "batch_entropy_mean", "\n", ")", "\n", "if", "(", "\n", "max_mean_batch_entropy", "is", "None", "\n", "or", "batch_entropy_mean", ">", "max_mean_batch_entropy", "\n", ")", ":", "\n", "                ", "max_mean_batch_entropy", "=", "batch_entropy_mean", "\n", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "                ", "loss_grouped_per_task", "[", "unique_task_id", "]", "=", "current_loss", "\n", "loss_list", ".", "append", "(", "current_loss", ")", "\n", "\n", "", "", "outputs", "=", "(", "\n", "(", "logits", ",", ")", "\n", "+", "outputs", "[", "2", ":", "]", "\n", "+", "(", "\n", "batch_entropy_per_task", ",", "\n", "batch_entropy_mean_per_task", ",", "\n", "max_mean_batch_entropy", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "loss_list", ":", "\n", "            ", "loss", "=", "torch", ".", "stack", "(", "loss_list", ")", "\n", "outputs", "=", "(", "loss", ".", "mean", "(", ")", ",", ")", "+", "outputs", "+", "(", "loss_grouped_per_task", ".", "view", "(", "1", ",", "-", "1", ")", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl._create_encoder": [[134, 141], ["src.model.encoders.ca_mtl_large.CaMtlLargeEncoder", "src.model.encoders.ca_mtl_base.CaMtlBaseEncoder", "src.model.encoders.bert._BertEncoder"], "methods", ["None"], ["", "def", "_create_encoder", "(", "self", ",", "model_name_or_path", ")", ":", "\n", "        ", "if", "model_name_or_path", "==", "\"CA-MTL-large\"", ":", "\n", "            ", "return", "CaMtlLargeEncoder", "(", "self", ".", "config", ",", "data_args", "=", "self", ".", "data_args", ")", "\n", "", "elif", "model_name_or_path", "==", "\"CA-MTL-base\"", ":", "\n", "            ", "return", "CaMtlBaseEncoder", "(", "self", ".", "config", ",", "data_args", "=", "self", ".", "data_args", ")", "\n", "", "else", ":", "\n", "            ", "return", "_BertEncoder", "(", "self", ".", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.get_base_model": [[142, 150], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "get_base_model", "(", "model_name_or_path", ")", ":", "\n", "        ", "if", "model_name_or_path", "==", "\"CA-MTL-large\"", ":", "\n", "            ", "return", "\"bert-large-cased\"", "\n", "", "elif", "model_name_or_path", "==", "\"CA-MTL-base\"", ":", "\n", "            ", "return", "\"bert-base-cased\"", "\n", "", "else", ":", "\n", "            ", "return", "model_name_or_path", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.model.ca_mtl.CaMtl.freeze_encoder_layers": [[151, 179], ["ca_mtl.CaMtl.bert.named_parameters", "model_args.freeze_encoder_layers.split", "ca_mtl.CaMtl.bert.named_parameters", "logger.info", "re.match", "ca_mtl.CaMtl.bert.get_layer_regexp", "int", "name.startswith", "any", "re.match.groups", "int", "int"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.get_layer_regexp"], ["", "", "def", "freeze_encoder_layers", "(", "\n", "self", ",", "\n", "model_args", ",", "\n", "unfrozen_modules", "=", "[", "\n", "\"random_weight_matrix\"", ",", "\n", "\"film.gb_weights\"", ",", "\n", "\"ln_weight_modulation.gb_weights\"", ",", "\n", "\"adapter\"", ",", "\n", "]", ",", "\n", ")", ":", "\n", "        ", "if", "model_args", ".", "freeze_encoder_layers", "is", "not", "None", ":", "\n", "            ", "start_layer", ",", "end_layer", "=", "model_args", ".", "freeze_encoder_layers", ".", "split", "(", "\"-\"", ")", "\n", "\n", "for", "name", ",", "param", "in", "self", ".", "bert", ".", "named_parameters", "(", ")", ":", "\n", "                ", "requires_grad", "=", "True", "\n", "match", "=", "re", ".", "match", "(", "self", ".", "bert", ".", "get_layer_regexp", "(", ")", ",", "name", ")", "\n", "if", "match", ":", "\n", "                    ", "layer_number", "=", "int", "(", "match", ".", "groups", "(", ")", "[", "0", "]", ")", "\n", "requires_grad", "=", "not", "int", "(", "start_layer", ")", "<=", "layer_number", "<=", "int", "(", "\n", "end_layer", "\n", ")", "or", "any", "(", "[", "module", "in", "match", ".", "string", "for", "module", "in", "unfrozen_modules", "]", ")", "\n", "", "elif", "name", ".", "startswith", "(", "\"embedding\"", ")", ":", "\n", "                    ", "requires_grad", "=", "False", "\n", "", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n", "", "", "for", "name", ",", "param", "in", "self", ".", "bert", ".", "named_parameters", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"%s - %s\"", ",", "name", ",", "(", "\"Unfrozen\"", "if", "param", ".", "requires_grad", "else", "\"FROZEN\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.bert._BertEncoder.__init__": [[5, 7], ["transformers.BertModel.__init__"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "_BertEncoder", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.bert._BertEncoder.forward": [[8, 25], ["super().forward"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalBottleNeck.forward"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "return", "super", "(", "_BertEncoder", ",", "self", ")", ".", "forward", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertSelfAttention9.__init__": [[18, 51], ["torch.Module.__init__", "int", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "src.model.encoders.conditional_modules.CBDA", "torch.Parameter", "torch.Parameter", "ValueError", "math.ceil", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "hasattr", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "\n", "config", ",", "\"embedding_size\"", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n", "self", ".", "max_seq_length", "=", "config", ".", "max_seq_length", "\n", "assert", "config", ".", "hidden_size", "%", "self", ".", "max_seq_length", "==", "0", ",", "\"Block decomposed attention will only work if this condition is met.\"", "\n", "self", ".", "num_blocks", "=", "config", ".", "hidden_size", "//", "self", ".", "max_seq_length", "\n", "self", ".", "cond_block_diag_attn", "=", "CBDA", "(", "\n", "config", ".", "hidden_size", ",", "math", ".", "ceil", "(", "self", ".", "max_seq_length", "/", "self", ".", "num_blocks", ")", ",", "self", ".", "num_blocks", "\n", ")", "# d x L/N", "\n", "\n", "self", ".", "random_weight_matrix", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "[", "config", ".", "max_seq_length", ",", "math", ".", "ceil", "(", "self", ".", "max_seq_length", "/", "self", ".", "num_blocks", ")", "]", "\n", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertSelfAttention9.transpose_for_scores": [[53, 60], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "\n", "self", ".", "num_attention_heads", ",", "\n", "self", ".", "attention_head_size", ",", "\n", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertSelfAttention9.forward": [[61, 129], ["ca_mtl_base.MyBertSelfAttention9.transpose_for_scores", "ca_mtl_base.MyBertSelfAttention9.key", "ca_mtl_base.MyBertSelfAttention9.query", "ca_mtl_base.MyBertSelfAttention9.transpose_for_scores", "ca_mtl_base.MyBertSelfAttention9.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "ca_mtl_base.MyBertSelfAttention9.cond_block_diag_attn", "ca_mtl_base.MyBertSelfAttention9.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "ca_mtl_base.MyBertSelfAttention9.value", "ca_mtl_base.MyBertSelfAttention9.value", "ca_mtl_base.MyBertSelfAttention9.transpose", "math.sqrt", "ca_mtl_base.MyBertSelfAttention9.unsqueeze", "torch.Softmax", "torch.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", ")", ":", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "        ", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "attention_scores1", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores1", "=", "attention_scores1", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "\n", "attention_scores2", "=", "self", ".", "cond_block_diag_attn", "(", "\n", "x_cond", "=", "task_embedding", ",", "\n", "x_to_film", "=", "self", ".", "random_weight_matrix", ",", "\n", ")", "\n", "\n", "attention_scores", "=", "attention_scores1", "+", "attention_scores2", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# b x seq len x hid dim", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# y = ax + b(task_emb)", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "\n", "attention_scores", "\n", ")", "# b x num heads x seq length x head dim", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "\n", "(", "context_layer", ",", "attention_probs", ")", "\n", "if", "self", ".", "output_attentions", "\n", "else", "(", "context_layer", ",", ")", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertSelfOutput9.__init__": [[132, 137], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "src.model.encoders.conditional_modules.ConditionalLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "ConditionalLayerNorm", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertSelfOutput9.forward": [[138, 143], ["ca_mtl_base.MyBertSelfOutput9.dense", "ca_mtl_base.MyBertSelfOutput9.dropout", "ca_mtl_base.MyBertSelfOutput9.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "task_embedding", ",", "task_id", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "task_embedding", ",", "task_id", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertOutput9.__init__": [[146, 151], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "src.model.encoders.conditional_modules.ConditionalLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "ConditionalLayerNorm", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertOutput9.forward": [[152, 157], ["ca_mtl_base.MyBertOutput9.dense", "ca_mtl_base.MyBertOutput9.dropout", "ca_mtl_base.MyBertOutput9.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "task_embedding", ",", "task_id", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "task_embedding", ",", "task_id", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertAttention9.__init__": [[160, 169], ["transformers.modeling_bert.BertAttention.__init__", "ca_mtl_base.MyBertSelfAttention9", "set", "ca_mtl_base.MyBertSelfOutput9", "transformers.modeling_bert.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "add_conditional_layernorm", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "self", "=", "MyBertSelfAttention9", "(", "config", ")", "\n", "self", ".", "add_conditional_layernorm", "=", "add_conditional_layernorm", "\n", "if", "add_conditional_layernorm", ":", "\n", "            ", "self", ".", "output", "=", "MyBertSelfOutput9", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertAttention9.forward": [[170, 196], ["ca_mtl_base.MyBertAttention9.self", "ca_mtl_base.MyBertAttention9.output", "ca_mtl_base.MyBertAttention9.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "task_embedding", "=", "task_embedding", ",", "\n", ")", "\n", "if", "self", ".", "add_conditional_layernorm", ":", "\n", "            ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "task_embedding", ",", "task_id", ")", "\n", "", "else", ":", "\n", "            ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "\n", "1", ":", "\n", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.BertAdapter9.__init__": [[199, 203], ["torch.Module.__init__", "src.model.encoders.conditional_modules.ConditionalBottleNeck", "src.model.encoders.conditional_modules.ConditionalLayerNorm"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bottleneck", "=", "ConditionalBottleNeck", "(", "config", ")", "\n", "self", ".", "condlayernorm", "=", "ConditionalLayerNorm", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.BertAdapter9.forward": [[204, 208], ["ca_mtl_base.BertAdapter9.bottleneck", "ca_mtl_base.BertAdapter9.condlayernorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "bert_layer_input", ",", "hidden_states", ",", "task_embedding", ",", "task_id", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "bottleneck", "(", "task_embedding", ",", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "condlayernorm", "(", "hidden_states", "+", "bert_layer_input", ",", "task_embedding", ",", "task_id", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertAdapterLayer9.__init__": [[212, 218], ["torch.Module.__init__", "ca_mtl_base.MyBertAttention9", "transformers.modeling_bert.BertIntermediate", "ca_mtl_base.MyBertOutput9", "ca_mtl_base.BertAdapter9"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MyBertAdapterLayer9", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "new_attention", "=", "MyBertAttention9", "(", "config", ")", "\n", "self", ".", "new_intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "new_output", "=", "MyBertOutput9", "(", "config", ")", "\n", "self", ".", "adapter", "=", "BertAdapter9", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertAdapterLayer9.forward": [[219, 246], ["ca_mtl_base.MyBertAdapterLayer9.new_attention", "ca_mtl_base.MyBertAdapterLayer9.new_intermediate", "ca_mtl_base.MyBertAdapterLayer9.new_output", "ca_mtl_base.MyBertAdapterLayer9.adapter"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "new_attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "\n", "1", ":", "\n", "]", "# add self attentions if we output attention weights", "\n", "\n", "intermediate_output", "=", "self", ".", "new_intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "new_output", "(", "\n", "intermediate_output", ",", "attention_output", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "adapted_layer_output", "=", "self", ".", "adapter", "(", "\n", "attention_output", ",", "layer_output", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "outputs", "=", "(", "adapted_layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertLayer9.__init__": [[249, 257], ["torch.Module.__init__", "ca_mtl_base.MyBertAttention9", "transformers.modeling_bert.BertIntermediate", "ca_mtl_base.MyBertOutput9", "transformers.modeling_bert.BertAttention"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "MyBertAttention9", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "crossattention", "=", "BertAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "MyBertOutput9", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertLayer9.forward": [[258, 293], ["ca_mtl_base.MyBertLayer9.attention", "ca_mtl_base.MyBertLayer9.intermediate", "ca_mtl_base.MyBertLayer9.output", "ca_mtl_base.MyBertLayer9.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "\n", "1", ":", "\n", "]", "# add self attentions if we output attention weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "(", "\n", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "\n", ")", "# add cross attentions if we output attention weights", "\n", "\n", "", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "task_embedding", ",", "task_id", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.BertLayer9.__init__": [[297, 300], ["transformers.modeling_bert.BertLayer.__init__", "ca_mtl_base.MyBertAttention9"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "MyBertAttention9", "(", "config", ",", "add_conditional_layernorm", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.BertLayer9.forward": [[301, 321], ["ca_mtl_base.BertLayer9.attention", "ca_mtl_base.BertLayer9.intermediate", "ca_mtl_base.BertLayer9.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertEncoder9.__init__": [[324, 336], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "ca_mtl_base.MyBertAdapterLayer9", "ca_mtl_base.BertLayer9", "ca_mtl_base.MyBertLayer9", "range", "range"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "tasks", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "task_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "num_bert_layers", "=", "config", ".", "num_hidden_layers", "//", "2", "\n", "num_mybert_layers", "=", "config", ".", "num_hidden_layers", "//", "2", "-", "1", "\n", "assert", "num_bert_layers", "+", "num_mybert_layers", "+", "1", "==", "config", ".", "num_hidden_layers", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "BertLayer9", "(", "config", ")", "for", "_", "in", "range", "(", "num_bert_layers", ")", "]", "+", "\n", "[", "MyBertLayer9", "(", "config", ")", "for", "_", "in", "range", "(", "num_mybert_layers", ")", "]", "+", "\n", "[", "MyBertAdapterLayer9", "(", "config", ")", "]", "# FiLM8", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.MyBertEncoder9.forward": [[338, 379], ["ca_mtl_base.MyBertEncoder9.task_transformation", "enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_type", "=", "None", ",", "\n", "task_embedding", "=", "None", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "task_embedding", "=", "self", ".", "task_transformation", "(", "task_embedding", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "task_embedding", ",", "\n", "task_type", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder.__init__": [[417, 434], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "len", "torch.Embedding", "torch.Embedding", "src.model.encoders.conditional_modules.FiLM", "transformers.modeling_bert.BertEmbeddings", "ca_mtl_base.MyBertEncoder9", "transformers.modeling_bert.BertPooler", "ca_mtl_base.CaMtlBaseEncoder.init_weights", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "data_args", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "tasks", "=", "data_args", ".", "tasks", "\n", "self", ".", "task_id_2_task_idx", "=", "{", "i", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "tasks", ")", "}", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "config", ".", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "config", ".", "max_seq_length", "=", "data_args", ".", "max_seq_length", "\n", "self", ".", "task_type_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tasks", ")", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "conditional_alignment", "=", "FiLM", "(", "\n", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "\n", ")", "# FiLM5", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "MyBertEncoder9", "(", "config", ",", "tasks", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder.get_input_embeddings": [[435, 437], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder.set_input_embeddings": [[438, 440], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder._prune_heads": [[441, 448], ["heads_to_prune.items", "ca_mtl_base.CaMtlBaseEncoder.encoder.layer[].attention.prune_heads"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder.forward": [[449, 614], ["ca_mtl_base.CaMtlBaseEncoder._create_task_type", "ca_mtl_base.CaMtlBaseEncoder.task_type_embeddings", "extended_attention_mask.to.to.to", "ca_mtl_base.CaMtlBaseEncoder.embeddings", "ca_mtl_base.CaMtlBaseEncoder.conditional_alignment", "ca_mtl_base.CaMtlBaseEncoder.encoder", "ca_mtl_base.CaMtlBaseEncoder.pooler", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones.dim", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.dim", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones.dim", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "ca_mtl_base.CaMtlBaseEncoder.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "ca_mtl_base.CaMtlBaseEncoder.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "ca_mtl_base.CaMtlBaseEncoder.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder._create_task_type"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Forward pass on the Model.\n\n        The model can behave as an encoder (with only self-attention) as well\n        as a decoder, in which case a layer of cross-attention is added between\n        the self-attention layers, following the architecture described in:\n        .. _`Attention is all you need`:\n            https://arxiv.org/abs/1706.03762\n\n        \"\"\"", "\n", "task_type", "=", "self", ".", "_create_task_type", "(", "kwargs", "[", "\"task_id\"", "]", ")", "\n", "task_embedding", "=", "self", ".", "task_type_embeddings", "(", "task_type", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", "\n", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "(", "\n", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "\n", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", ")", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "\n", "torch", ".", "long", "\n", ")", "# not converting to long will cause errors with pytorch version < 1.3", "\n", "extended_attention_mask", "=", "(", "\n", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "(", "\n", "encoder_batch_size", ",", "\n", "encoder_sequence_length", ",", "\n", "_", ",", "\n", ")", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", "\n", ":", ",", "None", ",", "None", ",", ":", "\n", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "\n", "1.0", "-", "encoder_extended_attention_mask", "\n", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "\n", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "\n", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "embedding_output", "=", "self", ".", "conditional_alignment", "(", "\n", "x_cond", "=", "task_embedding", ",", "\n", "x_to_film", "=", "embedding_output", ",", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "task_type", "=", "task_type", ",", "\n", "task_embedding", "=", "task_embedding", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder._create_task_type": [[615, 628], ["task_id.clone", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique.cpu().numpy", "torch.unique.cpu().numpy", "torch.unique.numpy", "torch.unique.numpy", "torch.unique.cpu", "torch.unique.cpu"], "methods", ["None"], ["", "def", "_create_task_type", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "task_type", "=", "task_id", ".", "clone", "(", ")", "\n", "unique_task_ids", "=", "torch", ".", "unique", "(", "task_type", ")", "\n", "unique_task_ids_list", "=", "(", "\n", "unique_task_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "unique_task_ids", ".", "is_cuda", "\n", "else", "unique_task_ids", ".", "numpy", "(", ")", "\n", ")", "\n", "for", "unique_task_id", "in", "unique_task_ids_list", ":", "\n", "            ", "task_type", "[", "task_type", "==", "unique_task_id", "]", "=", "self", ".", "task_id_2_task_idx", "[", "\n", "unique_task_id", "\n", "]", "\n", "", "return", "task_type", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_base.CaMtlBaseEncoder.get_layer_regexp": [[629, 632], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_layer_regexp", "(", "cls", ")", ":", "\n", "        ", "return", "r\"encoder.layer.*\\.([0-9]+)\\..*\"", "", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.__init__": [[18, 51], ["torch.Module.__init__", "int", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "src.model.encoders.conditional_modules.CBDA", "torch.Parameter", "torch.Parameter", "ValueError", "math.ceil", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "hasattr", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "\n", "config", ",", "\"embedding_size\"", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n", "self", ".", "max_seq_length", "=", "config", ".", "max_seq_length", "\n", "assert", "config", ".", "hidden_size", "%", "self", ".", "max_seq_length", "==", "0", ",", "\"Block decomposed attention will only work if this condition is met.\"", "\n", "self", ".", "num_blocks", "=", "config", ".", "hidden_size", "//", "self", ".", "max_seq_length", "\n", "self", ".", "cond_block_diag_attn", "=", "CBDA", "(", "\n", "config", ".", "hidden_size", ",", "math", ".", "ceil", "(", "self", ".", "max_seq_length", "/", "self", ".", "num_blocks", ")", ",", "self", ".", "num_blocks", "\n", ")", "# d x L/N", "\n", "\n", "self", ".", "random_weight_matrix", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "[", "config", ".", "max_seq_length", ",", "math", ".", "ceil", "(", "self", ".", "max_seq_length", "/", "self", ".", "num_blocks", ")", "]", "\n", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores": [[53, 60], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "\n", "self", ".", "num_attention_heads", ",", "\n", "self", ".", "attention_head_size", ",", "\n", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.forward": [[61, 129], ["ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "ca_mtl_large.MyBertSelfAttention10.key", "ca_mtl_large.MyBertSelfAttention10.query", "ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "ca_mtl_large.MyBertSelfAttention10.cond_block_diag_attn", "ca_mtl_large.MyBertSelfAttention10.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "ca_mtl_large.MyBertSelfAttention10.value", "ca_mtl_large.MyBertSelfAttention10.value", "ca_mtl_large.MyBertSelfAttention10.transpose", "math.sqrt", "ca_mtl_large.MyBertSelfAttention10.unsqueeze", "torch.Softmax", "torch.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfAttention10.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", ")", ":", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "        ", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "attention_scores1", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores1", "=", "attention_scores1", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "\n", "attention_scores2", "=", "self", ".", "cond_block_diag_attn", "(", "\n", "x_cond", "=", "task_embedding", ",", "\n", "x_to_film", "=", "self", ".", "random_weight_matrix", ",", "\n", ")", "\n", "\n", "attention_scores", "=", "attention_scores1", "+", "attention_scores2", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# b x seq len x hid dim", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# y = ax + b(task_emb)", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "\n", "attention_scores", "\n", ")", "# b x num heads x seq length x head dim", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "\n", "(", "context_layer", ",", "attention_probs", ")", "\n", "if", "self", ".", "output_attentions", "\n", "else", "(", "context_layer", ",", ")", "\n", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfOutput10.__init__": [[132, 137], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "src.model.encoders.conditional_modules.ConditionalLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "ConditionalLayerNorm", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertSelfOutput10.forward": [[138, 143], ["ca_mtl_large.MyBertSelfOutput10.dense", "ca_mtl_large.MyBertSelfOutput10.dropout", "ca_mtl_large.MyBertSelfOutput10.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "task_embedding", ",", "task_id", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "task_embedding", ",", "task_id", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertOutput10.__init__": [[146, 151], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "src.model.encoders.conditional_modules.ConditionalLayerNorm", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "ConditionalLayerNorm", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertOutput10.forward": [[152, 157], ["ca_mtl_large.MyBertOutput10.dense", "ca_mtl_large.MyBertOutput10.dropout", "ca_mtl_large.MyBertOutput10.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ",", "task_embedding", ",", "task_id", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ",", "task_embedding", ",", "task_id", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertAttention10.__init__": [[160, 169], ["transformers.modeling_bert.BertAttention.__init__", "ca_mtl_large.MyBertSelfAttention10", "set", "ca_mtl_large.MyBertSelfOutput10", "transformers.modeling_bert.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "add_conditional_layernorm", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "self", "=", "MyBertSelfAttention10", "(", "config", ")", "\n", "self", ".", "add_conditional_layernorm", "=", "add_conditional_layernorm", "\n", "if", "add_conditional_layernorm", ":", "\n", "            ", "self", ".", "output", "=", "MyBertSelfOutput10", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertAttention10.forward": [[170, 196], ["ca_mtl_large.MyBertAttention10.self", "ca_mtl_large.MyBertAttention10.output", "ca_mtl_large.MyBertAttention10.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "task_embedding", "=", "task_embedding", ",", "\n", ")", "\n", "if", "self", ".", "add_conditional_layernorm", ":", "\n", "            ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ",", "task_embedding", ",", "task_id", ")", "\n", "", "else", ":", "\n", "            ", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "\n", "1", ":", "\n", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertLayer10.__init__": [[199, 207], ["torch.Module.__init__", "ca_mtl_large.MyBertAttention10", "transformers.modeling_bert.BertIntermediate", "ca_mtl_large.MyBertOutput10", "transformers.modeling_bert.BertAttention"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "MyBertAttention10", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "crossattention", "=", "BertAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "MyBertOutput10", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertLayer10.forward": [[208, 243], ["ca_mtl_large.MyBertLayer10.attention", "ca_mtl_large.MyBertLayer10.intermediate", "ca_mtl_large.MyBertLayer10.output", "ca_mtl_large.MyBertLayer10.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "\n", "1", ":", "\n", "]", "# add self attentions if we output attention weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "(", "\n", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "\n", ")", "# add cross attentions if we output attention weights", "\n", "\n", "", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ",", "task_embedding", ",", "task_id", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.BertLayer10.__init__": [[247, 250], ["transformers.modeling_bert.BertLayer.__init__", "ca_mtl_large.MyBertAttention10"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attention", "=", "MyBertAttention10", "(", "config", ",", "add_conditional_layernorm", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.BertLayer10.forward": [[251, 271], ["ca_mtl_large.BertLayer10.attention", "ca_mtl_large.BertLayer10.intermediate", "ca_mtl_large.BertLayer10.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_embedding", "=", "None", ",", "\n", "task_id", "=", "None", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "task_embedding", "=", "task_embedding", ",", "task_id", "=", "task_id", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertEncoder10.__init__": [[274, 292], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "len", "src.model.encoders.conditional_modules.ConditionalBottleNeck", "ca_mtl_large.BertLayer10", "ca_mtl_large.MyBertLayer10", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "tasks", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "task_transformation", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "num_bert_layers", "=", "config", ".", "num_hidden_layers", "//", "2", "+", "config", ".", "num_hidden_layers", "%", "2", "\n", "num_mybert_layers", "=", "config", ".", "num_hidden_layers", "//", "2", "\n", "assert", "num_bert_layers", "+", "num_mybert_layers", "==", "config", ".", "num_hidden_layers", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "BertLayer10", "(", "config", ")", "for", "_", "in", "range", "(", "num_bert_layers", ")", "]", "+", "\n", "[", "MyBertLayer10", "(", "config", ")", "for", "_", "in", "range", "(", "num_mybert_layers", ")", "]", "\n", ")", "\n", "assert", "len", "(", "self", ".", "layer", ")", "==", "config", ".", "num_hidden_layers", "\n", "#FiLM6", "\n", "self", ".", "adapter_layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ConditionalBottleNeck", "(", "config", ")", "\n", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.MyBertEncoder10.forward": [[295, 341], ["ca_mtl_large.MyBertEncoder10.task_transformation", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "enumerate", "zip", "layer_module", "adapter_module"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "task_type", "=", "None", ",", "\n", "task_embedding", "=", "None", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "task_embedding", "=", "self", ".", "task_transformation", "(", "task_embedding", ")", "\n", "hidden_film", "=", "torch", ".", "zeros_like", "(", "hidden_states", ")", "\n", "for", "i", ",", "(", "layer_module", ",", "adapter_module", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "layer", ",", "self", ".", "adapter_layer", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "i", "]", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "task_embedding", ",", "\n", "task_type", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "# FiLM layer with a skip connection", "\n", "", "hidden_film", "=", "adapter_module", "(", "\n", "x_cond", "=", "task_embedding", ",", "hidden_states", "=", "hidden_states", "+", "hidden_film", "\n", ")", "\n", "\n", "# Add last layer", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_film", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.__init__": [[379, 396], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "len", "torch.Embedding", "torch.Embedding", "src.model.encoders.conditional_modules.FiLM", "transformers.modeling_bert.BertEmbeddings", "ca_mtl_large.MyBertEncoder10", "transformers.modeling_bert.BertPooler", "ca_mtl_large.CaMtlLargeEncoder.init_weights", "len", "enumerate"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "data_args", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "tasks", "=", "data_args", ".", "tasks", "\n", "self", ".", "task_id_2_task_idx", "=", "{", "i", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "tasks", ")", "}", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "config", ".", "num_tasks", "=", "len", "(", "tasks", ")", "\n", "config", ".", "max_seq_length", "=", "data_args", ".", "max_seq_length", "\n", "self", ".", "task_type_embeddings", "=", "nn", ".", "Embedding", "(", "len", "(", "tasks", ")", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "conditional_alignment", "=", "FiLM", "(", "\n", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "\n", ")", "# FiLM5", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "MyBertEncoder10", "(", "config", ",", "tasks", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.get_input_embeddings": [[397, 399], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.set_input_embeddings": [[400, 402], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder._prune_heads": [[403, 410], ["heads_to_prune.items", "ca_mtl_large.CaMtlLargeEncoder.encoder.layer[].attention.prune_heads"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"Prunes heads of the model.\n        heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.forward": [[411, 576], ["ca_mtl_large.CaMtlLargeEncoder._create_task_type", "ca_mtl_large.CaMtlLargeEncoder.task_type_embeddings", "extended_attention_mask.to.to.to", "ca_mtl_large.CaMtlLargeEncoder.embeddings", "ca_mtl_large.CaMtlLargeEncoder.conditional_alignment", "ca_mtl_large.CaMtlLargeEncoder.encoder", "ca_mtl_large.CaMtlLargeEncoder.pooler", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones.dim", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.dim", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones.dim", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "ca_mtl_large.CaMtlLargeEncoder.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "ca_mtl_large.CaMtlLargeEncoder.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "ca_mtl_large.CaMtlLargeEncoder.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder._create_task_type"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Forward pass on the Model.\n\n        The model can behave as an encoder (with only self-attention) as well\n        as a decoder, in which case a layer of cross-attention is added between\n        the self-attention layers, following the architecture described in:\n        .. _`Attention is all you need`:\n            https://arxiv.org/abs/1706.03762\n\n        \"\"\"", "\n", "task_type", "=", "self", ".", "_create_task_type", "(", "kwargs", "[", "\"task_id\"", "]", ")", "\n", "task_embedding", "=", "self", ".", "task_type_embeddings", "(", "task_type", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", "\n", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "(", "\n", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "\n", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", ")", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "\n", "torch", ".", "long", "\n", ")", "# not converting to long will cause errors with pytorch version < 1.3", "\n", "extended_attention_mask", "=", "(", "\n", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "(", "\n", "encoder_batch_size", ",", "\n", "encoder_sequence_length", ",", "\n", "_", ",", "\n", ")", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", "\n", ":", ",", "None", ",", "None", ",", ":", "\n", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "\n", "1.0", "-", "encoder_extended_attention_mask", "\n", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "\n", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "\n", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "embedding_output", "=", "self", ".", "conditional_alignment", "(", "\n", "x_cond", "=", "task_embedding", ",", "\n", "x_to_film", "=", "embedding_output", ",", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "task_type", "=", "task_type", ",", "\n", "task_embedding", "=", "task_embedding", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder._create_task_type": [[577, 590], ["task_id.clone", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique.cpu().numpy", "torch.unique.cpu().numpy", "torch.unique.numpy", "torch.unique.numpy", "torch.unique.cpu", "torch.unique.cpu"], "methods", ["None"], ["", "def", "_create_task_type", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "task_type", "=", "task_id", ".", "clone", "(", ")", "\n", "unique_task_ids", "=", "torch", ".", "unique", "(", "task_type", ")", "\n", "unique_task_ids_list", "=", "(", "\n", "unique_task_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "unique_task_ids", ".", "is_cuda", "\n", "else", "unique_task_ids", ".", "numpy", "(", ")", "\n", ")", "\n", "for", "unique_task_id", "in", "unique_task_ids_list", ":", "\n", "            ", "task_type", "[", "task_type", "==", "unique_task_id", "]", "=", "self", ".", "task_id_2_task_idx", "[", "\n", "unique_task_id", "\n", "]", "\n", "", "return", "task_type", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.ca_mtl_large.CaMtlLargeEncoder.get_layer_regexp": [[591, 594], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_layer_regexp", "(", "cls", ")", ":", "\n", "        ", "return", "r\"encoder.layer.*\\.([0-9]+)\\..*\"", "", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.FiLM.__init__": [[9, 23], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "conditional_modules.FiLM.gb_weights.bias.data.fill_", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "num_film_layers", "=", "1", ",", "layer_norm", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"", "\n", "super", "(", "FiLM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "num_film_layers", "=", "num_film_layers", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "output_size", ")", "if", "layer_norm", "else", "None", "\n", "film_output_size", "=", "self", ".", "output_size", "*", "num_film_layers", "*", "2", "\n", "self", ".", "gb_weights", "=", "nn", ".", "Linear", "(", "self", ".", "input_size", ",", "film_output_size", ")", "\n", "self", ".", "gb_weights", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.FiLM.forward": [[24, 31], ["conditional_modules.FiLM.gb_weights().unsqueeze", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "conditional_modules.FiLM.layer_norm", "conditional_modules.FiLM.gb_weights"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_cond", ",", "x_to_film", ")", ":", "\n", "        ", "gb", "=", "self", ".", "gb_weights", "(", "x_cond", ")", ".", "unsqueeze", "(", "1", ")", "\n", "gamma", ",", "beta", "=", "torch", ".", "chunk", "(", "gb", ",", "2", ",", "dim", "=", "-", "1", ")", "\n", "out", "=", "(", "1", "+", "gamma", ")", "*", "x_to_film", "+", "beta", "\n", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "layer_norm", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.CBDA.__init__": [[35, 50], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "conditional_modules.CBDA.gb_weights.bias.data.fill_", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "blocks", "=", "1", ",", "num_film_layers", "=", "1", ",", "layer_norm", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param input_size: feature size of x_cond\n        :param output_size: feature size of x_to_film\n        :param layer_norm: true or false\n        \"\"\"", "\n", "super", "(", "CBDA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "num_film_layers", "=", "num_film_layers", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "output_size", ")", "if", "layer_norm", "else", "None", "\n", "self", ".", "blocks", "=", "blocks", "\n", "film_output_size", "=", "self", ".", "output_size", "*", "num_film_layers", "*", "2", "\n", "self", ".", "gb_weights", "=", "nn", ".", "Linear", "(", "self", ".", "input_size", ",", "film_output_size", ")", "\n", "self", ".", "gb_weights", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.CBDA.forward": [[51, 60], ["conditional_modules.CBDA.gb_weights().unsqueeze", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "conditional_modules.CBDA.layer_norm", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "torch.block_diag", "conditional_modules.CBDA.gb_weights", "list", "conditional_modules.CBDA.size", "out_b.chunk"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_cond", ",", "x_to_film", ")", ":", "\n", "        ", "gb", "=", "self", ".", "gb_weights", "(", "x_cond", ")", ".", "unsqueeze", "(", "1", ")", "\n", "gamma", ",", "beta", "=", "torch", ".", "chunk", "(", "gb", ",", "2", ",", "dim", "=", "-", "1", ")", "\n", "out", "=", "(", "1", "+", "gamma", ")", "*", "x_to_film", "+", "beta", "\n", "if", "self", ".", "layer_norm", "is", "not", "None", ":", "\n", "            ", "out", "=", "self", ".", "layer_norm", "(", "out", ")", "\n", "", "out", "=", "[", "torch", ".", "block_diag", "(", "*", "list", "(", "out_b", ".", "chunk", "(", "self", ".", "blocks", ",", "0", ")", ")", ")", "for", "out_b", "in", "out", "]", "\n", "out", "=", "torch", ".", "stack", "(", "out", ")", "\n", "return", "out", "[", ":", ",", ":", ",", ":", "out", ".", "size", "(", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalLayerNorm.__init__": [[119, 132], ["torch.Module.__init__", "isinstance", "tuple", "torch.Parameter", "torch.Parameter", "torch.Parameter", "conditional_modules.FiLM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "conditional_modules.ConditionalLayerNorm.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sum", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalLayerNorm.reset_parameters"], ["def", "__init__", "(", "self", ",", "normalized_shape", ",", "condition_size", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "ConditionalLayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "normalized_shape", ",", "numbers", ".", "Integral", ")", ":", "\n", "            ", "normalized_shape", "=", "(", "normalized_shape", ",", ")", "\n", "", "self", ".", "normalized_shape", "=", "tuple", "(", "normalized_shape", ")", "\n", "\n", "self", ".", "condition_size", "=", "condition_size", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "normalized_shape", ")", ")", "\n", "self", ".", "ln_weight_modulation", "=", "FiLM", "(", "condition_size", ",", "sum", "(", "normalized_shape", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "normalized_shape", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalLayerNorm.reset_parameters": [[133, 136], ["torch.init.ones_", "torch.init.ones_", "torch.init.ones_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "ones_", "(", "self", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalLayerNorm.forward": [[137, 146], ["torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "[].unsqueeze", "conditional_modules.ConditionalLayerNorm.ln_weight_modulation().view", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "conditional_modules.ConditionalLayerNorm.ln_weight_modulation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_", ",", "condition", ",", "task_id", ")", ":", "\n", "        ", "unique_task_ids", "=", "torch", ".", "unique", "(", "task_id", ")", "\n", "cln_output", "=", "torch", ".", "zeros_like", "(", "input_", ")", "\n", "for", "unique_task_id", "in", "unique_task_ids", ":", "\n", "            ", "task_id_filter", "=", "task_id", "==", "unique_task_id", "\n", "task_emb", "=", "condition", "[", "task_id_filter", "]", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", "\n", "weight", "=", "self", ".", "ln_weight_modulation", "(", "task_emb", ",", "self", ".", "weight", ")", ".", "view", "(", "-", "1", ")", "\n", "cln_output", "[", "task_id_filter", "]", "=", "F", ".", "layer_norm", "(", "input_", "[", "task_id_filter", "]", ",", "self", ".", "normalized_shape", ",", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "", "return", "cln_output", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalLayerNorm.extra_repr": [[147, 149], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'{normalized_shape}, {condition_size}, eps={eps}'", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalBottleNeck.__init__": [[153, 159], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "conditional_modules.FiLM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ConditionalBottleNeck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_transf", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "hidden_modulation", "=", "FiLM", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "down_proj_layer", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", "//", "3", ")", "\n", "self", ".", "up_proj_layer", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "//", "3", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.encoders.conditional_modules.ConditionalBottleNeck.forward": [[160, 166], ["conditional_modules.ConditionalBottleNeck.emb_transf", "conditional_modules.ConditionalBottleNeck.hidden_modulation", "conditional_modules.ConditionalBottleNeck.down_proj_layer", "conditional_modules.ConditionalBottleNeck.up_proj_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_cond", ",", "hidden_states", ")", ":", "\n", "        ", "x_cond", "=", "self", ".", "emb_transf", "(", "x_cond", ")", "\n", "hidden_states", "=", "self", ".", "hidden_modulation", "(", "x_cond", "=", "x_cond", ",", "x_to_film", "=", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "down_proj_layer", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "up_proj_layer", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.__init__": [[15, 27], ["src.data.glue_utils.load_glue_task_features"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.load_glue_task_features"], ["def", "__init__", "(", "\n", "self", ",", "\n", "task_name", ":", "str", ",", "\n", "task_id", ":", "int", ",", "\n", "args", ":", "MultiTaskDataArguments", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "limit_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "mode", ":", "Union", "[", "str", ",", "Split", "]", "=", "Split", ".", "train", ",", "\n", ")", ":", "\n", "        ", "self", ".", "task_name", "=", "task_name", "\n", "self", ".", "features", ",", "self", ".", "labels", "=", "load_glue_task_features", "(", "\n", "task_name", ",", "task_id", ",", "args", ",", "tokenizer", ",", "mode", ",", "limit_length", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.__len__": [[29, 31], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.__getitem__": [[32, 34], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", "->", "MultiTaskInputFeatures", ":", "\n", "        ", "return", "self", ".", "features", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.get_labels": [[35, 37], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__": [[12, 27], ["torch.utils.data.ConcatDataset.__init__", "src.data.task_dataset.TaskDataset", "enumerate"], "methods", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.mtl_dataset.MultiTaskDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data_args", ":", "MultiTaskDataArguments", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "limit_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "mode", ":", "Split", "=", "Split", ".", "train", ",", "\n", ")", ":", "\n", "        ", "datasets", "=", "[", "\n", "TaskDataset", "(", "\n", "task_name", ",", "task_id", ",", "data_args", ",", "tokenizer", ",", "limit_length", "=", "limit_length", ",", "mode", "=", "mode", "\n", ")", "\n", "for", "task_id", ",", "task_name", "in", "enumerate", "(", "data_args", ".", "tasks", ")", "\n", "]", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "datasets", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.convert_glue_examples_to_multi_task_features": [[39, 98], ["tokenizer.batch_encode_plus", "range", "enumerate", "processor.get_labels", "logger.info", "logger.info", "KeyError", "glue_utils.convert_glue_examples_to_multi_task_features.label_from_example"], "function", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.get_labels"], ["def", "convert_glue_examples_to_multi_task_features", "(", "\n", "examples", ":", "List", "[", "InputExample", "]", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "task_name", ",", "\n", "task_id", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", ")", ":", "\n", "    ", "if", "max_length", "is", "None", ":", "\n", "        ", "max_length", "=", "tokenizer", ".", "max_len", "\n", "\n", "", "processor", "=", "glue_processors", "[", "task_name", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "        ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task_name", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "        ", "output_mode", "=", "glue_output_modes", "[", "task_name", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task_name", ")", ")", "\n", "\n", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "def", "label_from_example", "(", "example", ":", "InputExample", ")", "->", "Union", "[", "int", ",", "float", ",", "None", "]", ":", "\n", "        ", "if", "example", ".", "label", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "return", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "return", "float", "(", "example", ".", "label", ")", "\n", "", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "labels", "=", "[", "label_from_example", "(", "example", ")", "for", "example", "in", "examples", "]", "\n", "\n", "batch_encoding", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ")", "for", "example", "in", "examples", "]", ",", "\n", "max_length", "=", "max_length", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", ")", "\n", "\n", "features", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "examples", ")", ")", ":", "\n", "        ", "inputs", "=", "{", "k", ":", "batch_encoding", "[", "k", "]", "[", "i", "]", "for", "k", "in", "batch_encoding", "}", "\n", "\n", "if", "task_name", ".", "lower", "(", ")", "==", "\"mnli-mm\"", ":", "\n", "            ", "task_name", "=", "\"mnli\"", "\n", "\n", "", "feature", "=", "MultiTaskInputFeatures", "(", "\n", "**", "inputs", ",", "\n", "label", "=", "labels", "[", "i", "]", ",", "\n", "task_id", "=", "task_id", ",", "\n", ")", "\n", "features", ".", "append", "(", "feature", ")", "\n", "\n", "", "for", "i", ",", "example", "in", "enumerate", "(", "examples", "[", ":", "5", "]", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"features: %s\"", "%", "features", "[", "i", "]", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.load_glue_task_features": [[100, 166], ["os.path.join", "os.path.join", "processor.get_labels", "filelock.FileLock", "str", "os.path.exists", "time.time", "torch.load", "logger.info", "logger.info", "glue_utils.convert_glue_examples_to_multi_task_features", "time.time", "torch.save", "logger.info", "task_name.lower", "processor.get_dev_examples", "time.time", "processor.get_test_examples", "processor.get_train_examples", "time.time"], "function", ["home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.task_dataset.TaskDataset.get_labels", "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.convert_glue_examples_to_multi_task_features"], ["", "def", "load_glue_task_features", "(", "task_name", ",", "task_id", ",", "args", ",", "tokenizer", ",", "mode", ",", "limit_length", ")", ":", "\n", "    ", "processor", "=", "glue_processors", "[", "task_name", "]", "(", ")", "\n", "\n", "# Load data features from cache or dataset file", "\n", "task_data_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "glue_data_folder", "[", "task_name", ".", "lower", "(", ")", "]", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "task_data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ".", "value", ",", "\n", "tokenizer", ".", "__class__", ".", "__name__", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "task_name", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "task_name", "in", "[", "\"mnli\"", ",", "\"mnli-mm\"", "]", "and", "tokenizer", ".", "__class__", "in", "(", "\n", "RobertaTokenizer", ",", "\n", "RobertaTokenizerFast", ",", "\n", "XLMRobertaTokenizer", ",", "\n", ")", ":", "\n", "# HACK(label indices are swapped in RoBERTa pretrained model)", "\n", "        ", "label_list", "[", "1", "]", ",", "label_list", "[", "2", "]", "=", "label_list", "[", "2", "]", ",", "label_list", "[", "1", "]", "\n", "\n", "# Make sure only the first process in distributed training processes the dataset,", "\n", "# and the others will use the cache.", "\n", "", "lock_path", "=", "cached_features_file", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "logger", ".", "info", "(", "\n", "f\"Loading features from cached file {cached_features_file} [took %.3f s]\"", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Creating features from dataset file at {task_data_dir}\"", ")", "\n", "\n", "if", "mode", "==", "Split", ".", "dev", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "task_data_dir", ")", "\n", "", "elif", "mode", "==", "Split", ".", "test", ":", "\n", "                ", "examples", "=", "processor", ".", "get_test_examples", "(", "task_data_dir", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "task_data_dir", ")", "\n", "", "if", "limit_length", "is", "not", "None", ":", "\n", "                ", "examples", "=", "examples", "[", ":", "limit_length", "]", "\n", "\n", "", "features", "=", "convert_glue_examples_to_multi_task_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "task_name", ",", "\n", "task_id", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "label_list", "=", "label_list", ",", "\n", "output_mode", "=", "glue_output_modes", "[", "task_name", "]", ",", "\n", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "logger", ".", "info", "(", "\n", "\"Saving features into cached file %s [took %.3f s]\"", ",", "\n", "cached_features_file", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ",", "\n", ")", "\n", "\n", "", "", "return", "features", ",", "label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.CAMTL_CA-MTL.data.glue_utils.compute_glue_metrics": [[168, 176], ["transformers.glue_compute_metrics", "numpy.argmax", "numpy.squeeze"], "function", ["None"], ["", "def", "compute_glue_metrics", "(", "task_name", ",", "p", ")", ":", "\n", "    ", "output_mode", "=", "glue_output_modes", "[", "task_name", "]", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "preds", "=", "np", ".", "argmax", "(", "p", ".", "predictions", ",", "axis", "=", "1", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "preds", "=", "np", ".", "squeeze", "(", "p", ".", "predictions", ")", "\n", "", "return", "glue_compute_metrics", "(", "task_name", ",", "preds", ",", "p", ".", "label_ids", ")", "\n", "", ""]]}