{"home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.train.parse_args": [[36, 63], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "lib.core.config.update_config", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.update_config", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Pytorch SynFace'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "help", "=", "'experiment configure file name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "args", ",", "rest", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "update_config", "(", "args", ".", "cfg", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--frequent'", ",", "help", "=", "'frequency of logging'", ",", "default", "=", "config", ".", "TRAIN", ".", "PRINT_FREQ", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "help", "=", "'gpus'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "help", "=", "'num of dataloader workers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "help", "=", "'init learning rate'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "help", "=", "'optimizer type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "help", "=", "'whether use pretrained model'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "help", "=", "'whether debug'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "help", "=", "' model name'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_type'", ",", "help", "=", "'loss type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--focal'", ",", "help", "=", "'focal loss'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "help", "=", "' training dataset name'", ",", "default", "=", "'WebFace'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--syn'", ",", "help", "=", "'new syn root'", ",", "default", "=", "''", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dm'", ",", "help", "=", "'whether mixup with real data for training (i.e., domain mixup)'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_id'", ",", "help", "=", "'num of id'", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_perid'", ",", "help", "=", "'samples per id'", ",", "default", "=", "50", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "help", "=", "'batch size'", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--real_num_id'", ",", "help", "=", "'num of real id'", ",", "default", "=", "1000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--real_samples_perid'", ",", "help", "=", "'real samples per id'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.train.reset_config": [[64, 99], ["print", "print", "print", "print", "print", "print", "lib.core.config.config"], "function", ["None"], ["", "def", "reset_config", "(", "config", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "gpus", ":", "\n", "        ", "config", ".", "TRAIN", ".", "GPUS", "=", "args", ".", "gpus", "\n", "", "if", "args", ".", "workers", ":", "\n", "        ", "config", ".", "TRAIN", ".", "WORKERS", "=", "args", ".", "workers", "\n", "", "if", "args", ".", "model", ":", "\n", "        ", "print", "(", "'update model type'", ")", "\n", "config", ".", "TRAIN", ".", "MODEL", "=", "args", ".", "model", "\n", "", "if", "args", ".", "lr", ":", "\n", "        ", "print", "(", "'update learning rate'", ")", "\n", "config", ".", "TRAIN", ".", "LR", "=", "args", ".", "lr", "\n", "", "if", "args", ".", "pretrained", "==", "'No'", ":", "\n", "        ", "print", "(", "'update pretrained'", ")", "\n", "config", ".", "NETWORK", ".", "PRETRAINED", "=", "''", "\n", "", "if", "args", ".", "optim", ":", "\n", "        ", "print", "(", "'update optimizer type'", ")", "\n", "config", ".", "TRAIN", ".", "OPTIMIZER", "=", "args", ".", "optim", "\n", "", "if", "args", ".", "loss_type", ":", "\n", "        ", "config", ".", "LOSS", ".", "TYPE", "=", "{", "\n", "'Arc'", ":", "'ArcMargin'", ",", "\n", "'Cos'", ":", "'CosMargin'", "\n", "}", "[", "args", ".", "loss_type", "]", "\n", "", "if", "args", ".", "syn", ":", "\n", "        ", "print", "(", "'update syn root: {}'", ".", "format", "(", "args", ".", "syn", ")", ")", "\n", "config", ".", "DATASET", ".", "SYN_ROOT", "=", "args", ".", "syn", "\n", "", "if", "args", ".", "dm", ":", "\n", "        ", "print", "(", "'update dm'", ")", "\n", "config", ".", "TRAIN", ".", "DM", "=", "args", ".", "dm", "\n", "", "config", ".", "TRAIN", ".", "NUM_ID", "=", "args", ".", "num_id", "\n", "config", ".", "TRAIN", ".", "SAMPLES_PERID", "=", "args", ".", "samples_perid", "\n", "config", ".", "REAL", ".", "NUM_ID", "=", "args", ".", "real_num_id", "\n", "config", ".", "REAL", ".", "SAMPLES_PERID", "=", "args", ".", "real_samples_perid", "\n", "\n", "config", ".", "TRAIN", ".", "BATCH_SIZE", "=", "args", ".", "batch_size", "\n", "config", ".", "TEST", ".", "BATCH_SIZE", "=", "args", ".", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.train.main": [[100, 260], ["train.parse_args", "train.reset_config", "range", "torchvision.Compose", "torchvision.Compose", "logger.info", "logger.info", "lib.datasets.dataset.Img_Folder_Mix", "lib.datasets.dataset.Img_Folder_Num", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "lib.models.resnets.LResNet50E_IR", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "range", "time.strftime", "shutil.move", "int", "len", "lib.create_temp_logger", "lib.create_logger", "len", "len", "len", "len", "lib.datasets.dataset.LFW_Image", "len", "len", "lib.models.loss.FocalLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "lib.load_pretrained", "lib.load_checkpoint", "lib.core.functions.train", "lib.core.lfw_eval.eval", "logger.info", "logger.info", "lib.save_checkpoint", "os.path.join", "os.path.join", "lib.core.config.config.TRAIN.GPUS.split", "torchvision.RandomApply", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.Normalize", "torchvision.RandomErasing", "torchvision.ToTensor", "torchvision.Normalize", "lib.models.metrics.ArcMarginProduct", "lib.models.metrics.CosMarginProduct", "ValueError", "len", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "json.dumps", "json.dumps", "str", "str", "str", "len", "len", "len", "torch.nn.DataParallel().cuda.parameters", "torch.nn.DataParallel().cuda.parameters", "torch.nn.DataParallel().cuda.parameters", "torch.nn.DataParallel().cuda.parameters", "lib.models.loss.FocalLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "vars", "len", "len", "torch.nn.DataParallel().cuda.module.state_dict", "optimizer.state_dict", "torch.nn.DataParallel().cuda.module.state_dict", "torchvision.Resize", "torchvision.RandomCrop", "str", "len"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.test.reset_config", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet50E_IR", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_temp_logger", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_logger", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.load_pretrained", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.load_checkpoint", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.functions.train", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.save_checkpoint"], ["", "def", "main", "(", ")", ":", "\n", "# --------------------------------------model----------------------------------------", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "reset_config", "(", "config", ",", "args", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "config", ".", "TRAIN", ".", "GPUS", "\n", "gpus", "=", "[", "int", "(", "i", ")", "for", "i", "in", "config", ".", "TRAIN", ".", "GPUS", ".", "split", "(", "','", ")", "]", "\n", "gpus", "=", "range", "(", "len", "(", "gpus", ")", ")", "\n", "\n", "dataset_root", "=", "{", "\n", "'WebFace'", ":", "config", ".", "DATASET", ".", "WEBFACE_ROOT", ",", "\n", "'Syn'", ":", "config", ".", "DATASET", ".", "SYN_ROOT", "\n", "}", "[", "args", ".", "dataset", "]", "\n", "\n", "if", "args", ".", "debug", ":", "\n", "        ", "logger", ",", "final_output_dir", ",", "tb_log_dir", "=", "utils", ".", "create_temp_logger", "(", ")", "\n", "", "else", ":", "\n", "        ", "logger", ",", "final_output_dir", ",", "tb_log_dir", "=", "utils", ".", "create_logger", "(", "\n", "config", ",", "args", ".", "cfg", ",", "dataset_root", ",", "'train'", ")", "\n", "\n", "# ------------------------------------load image---------------------------------------", "\n", "", "train_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "# transforms.ColorJitter(brightness=0.35, contrast=0.5, saturation=0.5, hue=0.1),", "\n", "transforms", ".", "RandomApply", "(", "[", "transforms", ".", "Resize", "(", "112", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "config", ".", "NETWORK", ".", "IMAGE_SIZE", ")", "]", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "std", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "transforms", ".", "RandomErasing", "(", ")", "\n", "]", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "# range [0, 255] -> [0.0,1.0]", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "std", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "# range [0.0, 1.0] -> [-1.0,1.0]", "\n", "]", ")", "\n", "\n", "# albu_transform = A.Compose([", "\n", "# A.OneOf([", "\n", "# A.GaussianBlur(),", "\n", "# A.MotionBlur(),", "\n", "# A.MedianBlur(),", "\n", "# A.Blur(),", "\n", "# ], p=0.8),", "\n", "# A.OneOf([", "\n", "# A.OpticalDistortion(p=0.3),", "\n", "# A.GridDistortion(p=0.1),", "\n", "# ], p=0.5),", "\n", "# ])", "\n", "albu_transform", "=", "None", "\n", "logger", ".", "info", "(", "train_transform", ")", "\n", "logger", ".", "info", "(", "albu_transform", ")", "\n", "\n", "syn_dataset", "=", "Img_Folder_Mix", "(", "config", ".", "DATASET", ".", "SYN_ROOT", ",", "albu_transform", ",", "train_transform", ",", "num_id", "=", "config", ".", "TRAIN", ".", "NUM_ID", ",", "samples_perid", "=", "config", ".", "TRAIN", ".", "SAMPLES_PERID", ")", "\n", "real_dataset", "=", "Img_Folder_Num", "(", "config", ".", "DATASET", ".", "WEBFACE_ROOT", ",", "len", "(", "syn_dataset", ".", "classes", ")", ",", "len", "(", "syn_dataset", ")", ",", "albu_transform", ",", "train_transform", ",", "num_id", "=", "config", ".", "REAL", ".", "NUM_ID", ",", "samples_perid", "=", "config", ".", "REAL", ".", "SAMPLES_PERID", ")", "\n", "# pdb.set_trace()", "\n", "\n", "real_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "real_dataset", ",", "\n", "batch_size", "=", "config", ".", "TRAIN", ".", "BATCH_SIZE", "*", "len", "(", "gpus", ")", ",", "\n", "shuffle", "=", "config", ".", "TRAIN", ".", "SHUFFLE", ",", "\n", "num_workers", "=", "config", ".", "TRAIN", ".", "WORKERS", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ")", "\n", "\n", "syn_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "syn_dataset", ",", "\n", "batch_size", "=", "config", ".", "TRAIN", ".", "BATCH_SIZE", "*", "len", "(", "gpus", ")", ",", "\n", "shuffle", "=", "config", ".", "TRAIN", ".", "SHUFFLE", ",", "\n", "num_workers", "=", "config", ".", "TRAIN", ".", "WORKERS", ",", "\n", "pin_memory", "=", "True", ",", "\n", "drop_last", "=", "True", ")", "\n", "\n", "assert", "len", "(", "real_loader", ")", "==", "len", "(", "syn_loader", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "LFW_Image", "(", "config", ".", "DATASET", ".", "LFW_PATH", ",", "config", ".", "DATASET", ".", "LFW_PAIRS", ",", "test_transform", ")", ",", "\n", "batch_size", "=", "config", ".", "TEST", ".", "BATCH_SIZE", "*", "len", "(", "gpus", ")", ",", "\n", "shuffle", "=", "config", ".", "TEST", ".", "SHUFFLE", ",", "\n", "num_workers", "=", "config", ".", "TEST", ".", "WORKERS", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "num_class", "=", "len", "(", "syn_dataset", ".", "classes", ")", "+", "len", "(", "real_dataset", ".", "classes", ")", "\n", "\n", "model", "=", "LResNet50E_IR", "(", "input_size", "=", "config", ".", "NETWORK", ".", "IMAGE_SIZE", ")", "\n", "# choose the type of loss 512 is dimension of feature", "\n", "classifier", "=", "{", "\n", "'ArcMargin'", ":", "ArcMarginProduct", "(", "512", ",", "num_class", ")", ",", "\n", "'CosMargin'", ":", "CosMarginProduct", "(", "512", ",", "num_class", ")", ",", "\n", "}", "[", "config", ".", "LOSS", ".", "TYPE", "]", "\n", "\n", "# --------------------------------loss function and optimizer-----------------------------", "\n", "optimizer_sgd", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "model", ".", "parameters", "(", ")", "}", ",", "{", "'params'", ":", "classifier", ".", "parameters", "(", ")", "}", "]", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", ",", "\n", "momentum", "=", "config", ".", "TRAIN", ".", "MOMENTUM", ",", "\n", "weight_decay", "=", "config", ".", "TRAIN", ".", "WD", ")", "\n", "optimizer_adam", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "model", ".", "parameters", "(", ")", "}", ",", "{", "'params'", ":", "classifier", ".", "parameters", "(", ")", "}", "]", ",", "\n", "lr", "=", "config", ".", "TRAIN", ".", "LR", ")", "\n", "\n", "if", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "optimizer_sgd", "\n", "", "elif", "config", ".", "TRAIN", ".", "OPTIMIZER", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "optimizer_adam", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unknown optimizer type'", ")", "\n", "\n", "", "if", "args", ".", "focal", ":", "\n", "        ", "criterion", "=", "FocalLoss", "(", "gamma", "=", "2", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", ".", "cuda", "(", ")", "\n", "\n", "", "start_epoch", "=", "config", ".", "TRAIN", ".", "START_EPOCH", "\n", "if", "config", ".", "NETWORK", ".", "PRETRAINED", ":", "\n", "        ", "model", ",", "classifier", "=", "utils", ".", "load_pretrained", "(", "model", ",", "classifier", ",", "final_output_dir", ")", "\n", "\n", "", "if", "config", ".", "TRAIN", ".", "RESUME", ":", "\n", "        ", "start_epoch", ",", "model", ",", "optimizer", ",", "classifier", "=", "utils", ".", "load_checkpoint", "(", "model", ",", "optimizer", ",", "classifier", ",", "final_output_dir", ")", "\n", "\n", "", "lr_step", "=", "[", "step", "*", "len", "(", "real_loader", ")", "for", "step", "in", "config", ".", "TRAIN", ".", "LR_STEP", "]", "\n", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "\n", "optimizer", ",", "lr_step", ",", "config", ".", "TRAIN", ".", "LR_FACTOR", ")", "\n", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "gpus", ")", ".", "cuda", "(", ")", "\n", "classifier", "=", "torch", ".", "nn", ".", "DataParallel", "(", "classifier", ",", "device_ids", "=", "gpus", ")", ".", "cuda", "(", ")", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "'Configs: \\n'", "+", "json", ".", "dumps", "(", "config", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", "\n", "logger", ".", "info", "(", "'Args: \\n'", "+", "json", ".", "dumps", "(", "vars", "(", "args", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n", "logger", ".", "info", "(", "'length of train Database: '", "+", "str", "(", "len", "(", "syn_loader", ".", "dataset", ")", ")", "+", "'  Batches: '", "+", "str", "(", "len", "(", "syn_loader", ")", ")", ")", "\n", "logger", ".", "info", "(", "'length of real Database: '", "+", "str", "(", "len", "(", "real_loader", ".", "dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Number of Identities: '", "+", "str", "(", "num_class", ")", ")", "\n", "\n", "# ----------------------------------------train----------------------------------------", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "False", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "config", ".", "TRAIN", ".", "END_EPOCH", ")", ":", "\n", "\n", "        ", "train", "(", "syn_loader", ",", "real_loader", ",", "model", ",", "classifier", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tb_log_dir", ",", "config", ",", "lr_scheduler", ")", "\n", "perf_acc", ",", "_", "=", "lfw_eval", "(", "model", ",", "None", ",", "config", ",", "test_loader", ",", "tb_log_dir", ",", "epoch", ")", "\n", "\n", "if", "perf_acc", ">", "best_acc", ":", "\n", "            ", "best_acc", "=", "perf_acc", "\n", "best_model", "=", "True", "\n", "", "else", ":", "\n", "            ", "best_model", "=", "False", "\n", "\n", "", "logger", ".", "info", "(", "'current best accuracy {:.5f}'", ".", "format", "(", "best_acc", ")", ")", "\n", "logger", ".", "info", "(", "'saving checkpoint to {}'", ".", "format", "(", "final_output_dir", ")", ")", "\n", "utils", ".", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'model'", ":", "args", ".", "cfg", ",", "\n", "'state_dict'", ":", "model", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'perf'", ":", "perf_acc", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'classifier'", ":", "classifier", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "best_model", ",", "final_output_dir", ")", "\n", "# save best model with its acc", "\n", "", "time_str", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M'", ")", "\n", "shutil", ".", "move", "(", "os", ".", "path", ".", "join", "(", "final_output_dir", ",", "'model_best.pth.tar'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "final_output_dir", ",", "'model_best_{}_{:.4f}.pth.tar'", ".", "format", "(", "time_str", ",", "best_acc", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.test.parse_args": [[29, 56], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "lib.core.config.update_config", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.update_config", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Pytorch SynFace'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "help", "=", "'experiment configure file name'", ",", "required", "=", "True", ",", "type", "=", "str", ")", "\n", "args", ",", "rest", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "update_config", "(", "args", ".", "cfg", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--frequent'", ",", "help", "=", "'frequency of logging'", ",", "default", "=", "config", ".", "TRAIN", ".", "PRINT_FREQ", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--gpus'", ",", "help", "=", "'gpus'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "help", "=", "'num of dataloader workers'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "help", "=", "'init learning rate'", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "help", "=", "'optimizer type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained'", ",", "help", "=", "'whether use pretrained model'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "help", "=", "'whether debug'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "help", "=", "' model name'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--loss_type'", ",", "help", "=", "'loss type'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--focal'", ",", "help", "=", "'focal loss'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "help", "=", "' training dataset name'", ",", "default", "=", "'WebFace'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--syn'", ",", "help", "=", "'new syn root'", ",", "default", "=", "''", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--dm'", ",", "help", "=", "'whether mixup with real data for training (i.e., domain mixup)'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_id'", ",", "help", "=", "'num of id'", ",", "default", "=", "10000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_perid'", ",", "help", "=", "'samples per id'", ",", "default", "=", "50", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "help", "=", "'batch size'", ",", "default", "=", "512", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--real_num_id'", ",", "help", "=", "'num of real id'", ",", "default", "=", "1000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--real_samples_perid'", ",", "help", "=", "'real samples per id'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.test.reset_config": [[57, 92], ["print", "print", "print", "print", "print", "print", "lib.core.config.config"], "function", ["None"], ["", "def", "reset_config", "(", "config", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "gpus", ":", "\n", "        ", "config", ".", "TRAIN", ".", "GPUS", "=", "args", ".", "gpus", "\n", "", "if", "args", ".", "workers", ":", "\n", "        ", "config", ".", "TRAIN", ".", "WORKERS", "=", "args", ".", "workers", "\n", "", "if", "args", ".", "model", ":", "\n", "        ", "print", "(", "'update model type'", ")", "\n", "config", ".", "TRAIN", ".", "MODEL", "=", "args", ".", "model", "\n", "", "if", "args", ".", "lr", ":", "\n", "        ", "print", "(", "'update learning rate'", ")", "\n", "config", ".", "TRAIN", ".", "LR", "=", "args", ".", "lr", "\n", "", "if", "args", ".", "pretrained", "==", "'No'", ":", "\n", "        ", "print", "(", "'update pretrained'", ")", "\n", "config", ".", "NETWORK", ".", "PRETRAINED", "=", "''", "\n", "", "if", "args", ".", "optim", ":", "\n", "        ", "print", "(", "'update optimizer type'", ")", "\n", "config", ".", "TRAIN", ".", "OPTIMIZER", "=", "args", ".", "optim", "\n", "", "if", "args", ".", "loss_type", ":", "\n", "        ", "config", ".", "LOSS", ".", "TYPE", "=", "{", "\n", "'Arc'", ":", "'ArcMargin'", ",", "\n", "'Cos'", ":", "'CosMargin'", "\n", "}", "[", "args", ".", "loss_type", "]", "\n", "", "if", "args", ".", "syn", ":", "\n", "        ", "print", "(", "'update syn root: {}'", ".", "format", "(", "args", ".", "syn", ")", ")", "\n", "config", ".", "DATASET", ".", "SYN_ROOT", "=", "args", ".", "syn", "\n", "", "if", "args", ".", "dm", ":", "\n", "        ", "print", "(", "'update dm'", ")", "\n", "config", ".", "TRAIN", ".", "DM", "=", "args", ".", "dm", "\n", "", "config", ".", "TRAIN", ".", "NUM_ID", "=", "args", ".", "num_id", "\n", "config", ".", "TRAIN", ".", "SAMPLES_PERID", "=", "args", ".", "samples_perid", "\n", "config", ".", "REAL", ".", "NUM_ID", "=", "args", ".", "real_num_id", "\n", "config", ".", "REAL", ".", "SAMPLES_PERID", "=", "args", ".", "real_samples_perid", "\n", "\n", "config", ".", "TRAIN", ".", "BATCH_SIZE", "=", "args", ".", "batch_size", "\n", "config", ".", "TEST", ".", "BATCH_SIZE", "=", "args", ".", "batch_size", "\n", "", "def", "main", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.test.main": [[92, 135], ["test.parse_args", "test.reset_config", "range", "lib.create_temp_logger", "torchvision.Compose", "logger.info", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "lib.models.resnets.LResNet50E_IR", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "logger.info", "logger.info", "logger.info", "int", "len", "lib.datasets.dataset.LFW_Image", "logger.info", "os.path.join", "lib.core.lfw_eval.eval", "lib.core.config.config.TRAIN.GPUS.split", "torchvision.ToTensor", "torchvision.Normalize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "json.dumps", "json.dumps", "len", "vars"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.None.test.reset_config", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_temp_logger", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet50E_IR", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval"], ["", "def", "main", "(", ")", ":", "\n", "# --------------------------------------model----------------------------------------", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "reset_config", "(", "config", ",", "args", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "config", ".", "TRAIN", ".", "GPUS", "\n", "gpus", "=", "[", "int", "(", "i", ")", "for", "i", "in", "config", ".", "TRAIN", ".", "GPUS", ".", "split", "(", "','", ")", "]", "\n", "gpus", "=", "range", "(", "len", "(", "gpus", ")", ")", "\n", "\n", "logger", ",", "final_output_dir", ",", "tb_log_dir", "=", "utils", ".", "create_temp_logger", "(", ")", "\n", "\n", "# ------------------------------------load image---------------------------------------", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "# range [0, 255] -> [0.0,1.0]", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "std", "=", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "# range [0.0, 1.0] -> [-1.0,1.0]", "\n", "]", ")", "\n", "\n", "logger", ".", "info", "(", "test_transform", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "LFW_Image", "(", "config", ".", "DATASET", ".", "LFW_PATH", ",", "config", ".", "DATASET", ".", "LFW_PAIRS", ",", "test_transform", ")", ",", "\n", "batch_size", "=", "config", ".", "TEST", ".", "BATCH_SIZE", "*", "len", "(", "gpus", ")", ",", "\n", "shuffle", "=", "config", ".", "TEST", ".", "SHUFFLE", ",", "\n", "num_workers", "=", "config", ".", "TEST", ".", "WORKERS", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "model", "=", "LResNet50E_IR", "(", "input_size", "=", "config", ".", "NETWORK", ".", "IMAGE_SIZE", ")", "\n", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "gpus", ")", ".", "cuda", "(", ")", "\n", "\n", "logger", ".", "info", "(", "model", ")", "\n", "logger", ".", "info", "(", "'Configs: \\n'", "+", "json", ".", "dumps", "(", "config", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", "\n", "logger", ".", "info", "(", "'Args: \\n'", "+", "json", ".", "dumps", "(", "vars", "(", "args", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n", "model_root", "=", "'pretrained/'", "\n", "model_paths", "=", "[", "'model_10k_50_nomix_8898.pth.tar'", ",", "\n", "'model_10k_50_idmix_9197.pth.tar'", ",", "\n", "'model_10k_50_2k_10_9578.pth.tar'", ",", "\n", "'model_10k_50_2k_20_9765.pth.tar'", "]", "\n", "\n", "for", "model_path", "in", "model_paths", ":", "\n", "        ", "logger", ".", "info", "(", "model_path", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "model_root", ",", "model_path", ")", "\n", "lfw_eval", "(", "model", ",", "model_path", ",", "config", ",", "test_loader", ",", "'temp'", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Num.__init__": [[10, 18], ["torch.utils.data.Dataset.__init__", "dataset.Img_Folder_Num.load_db", "list", "dataset.Img_Folder_Num.class_to_label.keys"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.load_db"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "refer_classes", ",", "refer_length", ",", "albu_transform", "=", "None", ",", "transform", "=", "None", ",", "num_id", "=", "1000", ",", "samples_perid", "=", "10", ")", ":", "\n", "        ", "super", "(", "Img_Folder_Num", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "refer_length", "=", "refer_length", "\n", "self", ".", "db", ",", "self", ".", "class_to_label", "=", "self", ".", "load_db", "(", "refer_classes", ",", "refer_length", ",", "num_id", ",", "samples_perid", ")", "\n", "self", ".", "classes", "=", "list", "(", "self", ".", "class_to_label", ".", "keys", "(", ")", ")", "\n", "self", ".", "albu_transform", "=", "albu_transform", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Num.load_db": [[20, 51], ["sorted", "enumerate", "os.listdir", "len", "os.listdir", "len", "random.choices", "len", "os.path.join", "len", "db.append", "len", "os.path.join", "len"], "methods", ["None"], ["", "def", "load_db", "(", "self", ",", "refer_classes", ",", "refer_length", ",", "num_id", ",", "samples_perid", ")", ":", "\n", "        ", "db", "=", "[", "]", "\n", "class_to_label", "=", "{", "}", "\n", "classes", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "root", ")", ")", "\n", "# np.random.shuffle(classes)", "\n", "\n", "assert", "num_id", "<=", "len", "(", "classes", ")", "\n", "classes", "=", "classes", "[", ":", "num_id", "]", "\n", "# classes = sorted(random.sample(classes, k=num_id)) ", "\n", "\n", "for", "i", ",", "class_name", "in", "enumerate", "(", "classes", ")", ":", "\n", "            ", "if", "class_name", "not", "in", "class_to_label", ":", "\n", "                ", "class_to_label", "[", "class_name", "]", "=", "i", "+", "refer_classes", "\n", "\n", "", "img_names", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "class_name", ")", ")", "\n", "if", "samples_perid", "<=", "len", "(", "img_names", ")", ":", "\n", "                ", "img_names", "=", "img_names", "[", ":", "samples_perid", "]", "\n", "\n", "", "for", "img_name", "in", "img_names", ":", "\n", "                ", "datum", "=", "[", "os", ".", "path", ".", "join", "(", "class_name", ",", "img_name", ")", ",", "i", "+", "refer_classes", "]", "\n", "db", ".", "append", "(", "datum", ")", "\n", "\n", "", "", "k", "=", "refer_length", "//", "len", "(", "db", ")", "\n", "db", "*=", "k", "\n", "if", "refer_length", "-", "len", "(", "db", ")", ">", "0", ":", "\n", "            ", "samples", "=", "random", ".", "choices", "(", "db", ",", "k", "=", "refer_length", "-", "len", "(", "db", ")", ")", "\n", "db", "+=", "samples", "\n", "\n", "", "assert", "len", "(", "db", ")", "==", "refer_length", "\n", "\n", "return", "db", ",", "class_to_label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Num.PIL_loader": [[53, 59], ["open", "PIL.Image.open().convert", "print", "PIL.Image.open"], "methods", ["None"], ["", "def", "PIL_loader", "(", "self", ",", "path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "return", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "", "except", "IOError", ":", "\n", "            ", "print", "(", "'Cannot load image '", "+", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Num.__getitem__": [[60, 75], ["dataset.Img_Folder_Num.PIL_loader", "os.path.join", "numpy.array", "dataset.Img_Folder_Num.albu_transform", "PIL.Image.fromarray", "dataset.Img_Folder_Num.transform"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.PIL_loader"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "datum", "=", "self", ".", "db", "[", "index", "]", "\n", "img_path", ",", "label", "=", "datum", "\n", "\n", "img", "=", "self", ".", "PIL_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "img_path", ")", ")", "\n", "\n", "if", "self", ".", "albu_transform", "is", "not", "None", ":", "\n", "            ", "img_np", "=", "np", ".", "array", "(", "img", ")", "\n", "augmented", "=", "self", ".", "albu_transform", "(", "image", "=", "img_np", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "augmented", "[", "'image'", "]", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Num.__len__": [[76, 78], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "db", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.__init__": [[81, 88], ["torch.utils.data.Dataset.__init__", "dataset.Img_Folder_Mix.load_db", "list", "dataset.Img_Folder_Mix.class_to_label.keys"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.load_db"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "albu_transform", "=", "None", ",", "transform", "=", "None", ",", "num_id", "=", "10000", ",", "samples_perid", "=", "50", ")", ":", "\n", "        ", "super", "(", "Img_Folder_Mix", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "db", ",", "self", ".", "class_to_label", "=", "self", ".", "load_db", "(", "num_id", ",", "samples_perid", ")", "\n", "self", ".", "classes", "=", "list", "(", "self", ".", "class_to_label", ".", "keys", "(", ")", ")", "\n", "self", ".", "albu_transform", "=", "albu_transform", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.load_db": [[89, 109], ["sorted", "enumerate", "os.listdir", "len", "os.listdir", "os.path.join", "len", "db.append", "os.path.join"], "methods", ["None"], ["", "def", "load_db", "(", "self", ",", "num_id", ",", "samples_perid", ")", ":", "\n", "        ", "db", "=", "[", "]", "\n", "class_to_label", "=", "{", "}", "\n", "classes", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "root", ")", ")", "\n", "if", "num_id", "<", "len", "(", "classes", ")", ":", "\n", "            ", "classes", "=", "classes", "[", ":", "num_id", "]", "\n", "\n", "", "for", "i", ",", "class_name", "in", "enumerate", "(", "classes", ")", ":", "\n", "            ", "if", "class_name", "not", "in", "class_to_label", ":", "\n", "                ", "class_to_label", "[", "class_name", "]", "=", "i", "\n", "\n", "", "img_names", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "class_name", ")", ")", "\n", "if", "samples_perid", "<", "len", "(", "img_names", ")", ":", "\n", "                ", "img_names", "=", "img_names", "[", ":", "samples_perid", "]", "\n", "\n", "", "for", "img_name", "in", "img_names", ":", "\n", "                ", "datum", "=", "[", "os", ".", "path", ".", "join", "(", "class_name", ",", "img_name", ")", ",", "i", "]", "\n", "db", ".", "append", "(", "datum", ")", "\n", "\n", "", "", "return", "db", ",", "class_to_label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.PIL_loader": [[110, 116], ["open", "PIL.Image.open().convert", "print", "PIL.Image.open"], "methods", ["None"], ["", "def", "PIL_loader", "(", "self", ",", "path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "return", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "", "except", "IOError", ":", "\n", "            ", "print", "(", "'Cannot load image '", "+", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.get_label": [[117, 125], ["os.path.basename", "re.match", "torch.tensor().float", "int", "float", "int", "float", "re.match.group", "re.match.group", "re.match.group", "re.match.group", "torch.tensor"], "methods", ["None"], ["", "", "def", "get_label", "(", "self", ",", "path", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "template", "=", "r'(.*)_(.*)x(.*)_\\((.*)\\)x(.*).jpg'", "\n", "info", "=", "re", ".", "match", "(", "template", ",", "path", ")", "\n", "l_1", ",", "w_1", "=", "int", "(", "info", ".", "group", "(", "2", ")", ")", ",", "float", "(", "info", ".", "group", "(", "3", ")", ")", "\n", "l_2", ",", "w_2", "=", "int", "(", "info", ".", "group", "(", "4", ")", ")", ",", "float", "(", "info", ".", "group", "(", "5", ")", ")", "\n", "label", "=", "torch", ".", "tensor", "(", "(", "l_1", "-", "1", ",", "w_1", ",", "l_2", "-", "1", ",", "w_2", ")", ")", ".", "float", "(", ")", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.__getitem__": [[126, 142], ["dataset.Img_Folder_Mix.PIL_loader", "dataset.Img_Folder_Mix.get_label", "os.path.join", "numpy.array", "dataset.Img_Folder_Mix.albu_transform", "PIL.Image.fromarray", "dataset.Img_Folder_Mix.transform"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.PIL_loader", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.get_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "datum", "=", "self", ".", "db", "[", "index", "]", "\n", "img_path", ",", "label", "=", "datum", "\n", "\n", "img", "=", "self", ".", "PIL_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "img_path", ")", ")", "\n", "label", "=", "self", ".", "get_label", "(", "img_path", ")", "\n", "\n", "if", "self", ".", "albu_transform", "is", "not", "None", ":", "\n", "            ", "img_np", "=", "np", ".", "array", "(", "img", ")", "\n", "augmented", "=", "self", ".", "albu_transform", "(", "image", "=", "img_np", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "augmented", "[", "'image'", "]", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder_Mix.__len__": [[143, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "db", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.__init__": [[147, 156], ["torch.utils.data.Dataset.__init__", "dataset.Img_Folder.load_db", "list", "dataset.Img_Folder.class_to_label.keys"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.load_db"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "refer_length", ",", "sync", "=", "False", ",", "albu_transform", "=", "None", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "Img_Folder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "sync", "=", "sync", "\n", "self", ".", "refer_length", "=", "refer_length", "\n", "self", ".", "db", ",", "self", ".", "class_to_label", "=", "self", ".", "load_db", "(", ")", "\n", "self", ".", "classes", "=", "list", "(", "self", ".", "class_to_label", ".", "keys", "(", ")", ")", "\n", "self", ".", "albu_transform", "=", "albu_transform", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.load_db": [[157, 180], ["enumerate", "len", "os.listdir", "os.listdir", "random.choices", "len", "os.path.join", "random.choices.append", "random.choices", "os.path.join"], "methods", ["None"], ["", "def", "load_db", "(", "self", ")", ":", "\n", "        ", "db", "=", "[", "]", "\n", "class_to_label", "=", "{", "}", "\n", "for", "i", ",", "class_name", "in", "enumerate", "(", "os", ".", "listdir", "(", "self", ".", "root", ")", ")", ":", "\n", "            ", "if", "class_name", "not", "in", "class_to_label", ":", "\n", "                ", "class_to_label", "[", "class_name", "]", "=", "i", "\n", "\n", "", "for", "img_name", "in", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "class_name", ")", ")", ")", ":", "\n", "                ", "datum", "=", "[", "os", ".", "path", ".", "join", "(", "class_name", ",", "img_name", ")", ",", "i", "]", "\n", "db", ".", "append", "(", "datum", ")", "\n", "\n", "# align the real to syn dataset length", "\n", "", "", "length", "=", "len", "(", "db", ")", "\n", "if", "length", "<", "self", ".", "refer_length", ":", "\n", "            ", "over_samples", "=", "random", ".", "choices", "(", "db", ",", "k", "=", "self", ".", "refer_length", "-", "length", ")", "\n", "db", "+=", "over_samples", "\n", "\n", "", "elif", "length", ">", "self", ".", "refer_length", ":", "\n", "            ", "db", "=", "random", ".", "choices", "(", "db", ",", "k", "=", "self", ".", "refer_length", ")", "\n", "\n", "", "assert", "len", "(", "db", ")", "==", "self", ".", "refer_length", "\n", "\n", "return", "db", ",", "class_to_label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.PIL_loader": [[181, 187], ["open", "PIL.Image.open().convert", "print", "PIL.Image.open"], "methods", ["None"], ["", "def", "PIL_loader", "(", "self", ",", "path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "return", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "", "", "except", "IOError", ":", "\n", "            ", "print", "(", "'Cannot load image '", "+", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.__getitem__": [[188, 203], ["dataset.Img_Folder.PIL_loader", "os.path.join", "numpy.array", "dataset.Img_Folder.albu_transform", "PIL.Image.fromarray", "dataset.Img_Folder.transform"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.PIL_loader"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "datum", "=", "self", ".", "db", "[", "index", "]", "\n", "img_path", ",", "label", "=", "datum", "\n", "\n", "img", "=", "self", ".", "PIL_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "img_path", ")", ")", "\n", "\n", "if", "self", ".", "albu_transform", "is", "not", "None", ":", "\n", "            ", "img_np", "=", "np", ".", "array", "(", "img", ")", "\n", "augmented", "=", "self", ".", "albu_transform", "(", "image", "=", "img_np", ")", "\n", "img", "=", "Image", ".", "fromarray", "(", "augmented", "[", "'image'", "]", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.Img_Folder.__len__": [[204, 206], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "db", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.LFW_Image.__init__": [[208, 214], ["torch.utils.data.Dataset.__init__", "dataset.LFW_Image.get_pairs_lines"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.LFW_Image.get_pairs_lines"], ["    ", "def", "__init__", "(", "self", ",", "lfw_path", ",", "lfw_pairs", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "LFW_Image", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lfw_path", "=", "lfw_path", "\n", "self", ".", "pairs", "=", "self", ".", "get_pairs_lines", "(", "lfw_pairs", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.LFW_Image.get_pairs_lines": [[215, 219], ["open", "f.readlines"], "methods", ["None"], ["", "def", "get_pairs_lines", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "            ", "pairs_lines", "=", "f", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "", "return", "pairs_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.LFW_Image.__getitem__": [[220, 244], ["dataset.LFW_Image.pairs[].replace().split", "len", "open", "PIL.Image.open().convert", "open", "PIL.Image.open().convert", "dataset.LFW_Image.transform", "dataset.LFW_Image.transform", "dataset.LFW_Image.pairs[].replace", "len", "ValueError", "int", "int", "PIL.Image.open", "PIL.Image.open", "int", "int"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "p", "=", "self", ".", "pairs", "[", "index", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "'\\t'", ")", "\n", "\n", "if", "3", "==", "len", "(", "p", ")", ":", "\n", "            ", "sameflag", "=", "1", "\n", "name1", "=", "p", "[", "0", "]", "+", "'/'", "+", "p", "[", "0", "]", "+", "'_'", "+", "'{:04}.jpg'", ".", "format", "(", "int", "(", "p", "[", "1", "]", ")", ")", "\n", "name2", "=", "p", "[", "0", "]", "+", "'/'", "+", "p", "[", "0", "]", "+", "'_'", "+", "'{:04}.jpg'", ".", "format", "(", "int", "(", "p", "[", "2", "]", ")", ")", "\n", "", "elif", "4", "==", "len", "(", "p", ")", ":", "\n", "            ", "sameflag", "=", "0", "\n", "name1", "=", "p", "[", "0", "]", "+", "'/'", "+", "p", "[", "0", "]", "+", "'_'", "+", "'{:04}.jpg'", ".", "format", "(", "int", "(", "p", "[", "1", "]", ")", ")", "\n", "name2", "=", "p", "[", "2", "]", "+", "'/'", "+", "p", "[", "2", "]", "+", "'_'", "+", "'{:04}.jpg'", ".", "format", "(", "int", "(", "p", "[", "3", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"WRONG LINE IN 'pairs.txt! \"", ")", "\n", "\n", "", "with", "open", "(", "self", ".", "lfw_path", "+", "name1", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img1", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "", "with", "open", "(", "self", ".", "lfw_path", "+", "name2", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "img2", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img1", "=", "self", ".", "transform", "(", "img1", ")", "\n", "img2", "=", "self", ".", "transform", "(", "img2", ")", "\n", "", "return", "img1", ",", "img2", ",", "sameflag", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.datasets.dataset.LFW_Image.__len__": [[245, 247], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "pairs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.ArcMarginProduct.__init__": [[20, 34], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "math.cos", "math.sin", "math.cos", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "math.sin"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "s", "=", "30.0", ",", "m", "=", "0.50", ",", "easy_margin", "=", "False", ")", ":", "\n", "        ", "super", "(", "ArcMarginProduct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "s", "=", "s", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "\n", "self", ".", "easy_margin", "=", "easy_margin", "\n", "self", ".", "cos_m", "=", "math", ".", "cos", "(", "m", ")", "\n", "self", ".", "sin_m", "=", "math", ".", "sin", "(", "m", ")", "\n", "self", ".", "th", "=", "math", ".", "cos", "(", "math", ".", "pi", "-", "m", ")", "\n", "self", ".", "mm", "=", "math", ".", "sin", "(", "math", ".", "pi", "-", "m", ")", "*", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.ArcMarginProduct.forward": [[35, 54], ["torch.linear", "torch.linear", "torch.linear", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros.scatter_", "torch.zeros.scatter_", "torch.zeros.scatter_", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.linear.size", "label.view().long", "label.view", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "label", ")", ":", "\n", "# --------------------------- cos(theta) & phi(theta) ---------------------------", "\n", "        ", "cosine", "=", "F", ".", "linear", "(", "F", ".", "normalize", "(", "input", ")", ",", "F", ".", "normalize", "(", "self", ".", "weight", ")", ")", "\n", "sine", "=", "torch", ".", "sqrt", "(", "(", "1.0", "-", "torch", ".", "pow", "(", "cosine", ",", "2", ")", ")", ".", "clamp", "(", "0", ",", "1", ")", ")", "\n", "phi", "=", "cosine", "*", "self", ".", "cos_m", "-", "sine", "*", "self", ".", "sin_m", "\n", "if", "self", ".", "easy_margin", ":", "\n", "            ", "phi", "=", "torch", ".", "where", "(", "cosine", ">", "0", ",", "phi", ",", "cosine", ")", "\n", "", "else", ":", "\n", "            ", "phi", "=", "torch", ".", "where", "(", "cosine", ">", "self", ".", "th", ",", "phi", ",", "cosine", "-", "self", ".", "mm", ")", "\n", "# --------------------------- convert label to one-hot ---------------------------", "\n", "# one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')", "\n", "", "one_hot", "=", "torch", ".", "zeros", "(", "cosine", ".", "size", "(", ")", ",", "device", "=", "'cuda'", ")", "\n", "one_hot", ".", "scatter_", "(", "1", ",", "label", ".", "view", "(", "-", "1", ",", "1", ")", ".", "long", "(", ")", ",", "1", ")", "\n", "# -------------torch.where(out_i = {x_i if condition_i else y_i) -------------", "\n", "output", "=", "(", "one_hot", "*", "phi", ")", "+", "(", "(", "1.0", "-", "one_hot", ")", "*", "cosine", ")", "# you can use torch.where if your torch.__version__ is 0.4", "\n", "output", "*=", "self", ".", "s", "\n", "# print(output)", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.CosMarginProduct.__init__": [[72, 80], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "s", "=", "30.0", ",", "m", "=", "0.4", ")", ":", "\n", "        ", "super", "(", "CosMarginProduct", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "s", "=", "s", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "#stdv = 1. / math.sqrt(self.weight.size(1))", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.CosMarginProduct.forward": [[83, 94], ["metrics.cosine_sim", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "torch.zeros_like.scatter_", "label.view"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.cosine_sim"], ["", "def", "forward", "(", "self", ",", "input", ",", "label", ")", ":", "\n", "        ", "cosine", "=", "cosine_sim", "(", "input", ",", "self", ".", "weight", ")", "\n", "# cosine = F.linear(F.normalize(input), F.normalize(self.weight))", "\n", "# --------------------------- convert label to one-hot ---------------------------", "\n", "# https://discuss.pytorch.org/t/convert-int-into-one-hot-format/507", "\n", "one_hot", "=", "torch", ".", "zeros_like", "(", "cosine", ")", "\n", "one_hot", ".", "scatter_", "(", "1", ",", "label", ".", "view", "(", "-", "1", ",", "1", ")", ",", "1.0", ")", "\n", "# -------------torch.where(out_i = {x_i if condition_i else y_i) -------------", "\n", "output", "=", "self", ".", "s", "*", "(", "cosine", "-", "one_hot", "*", "self", ".", "m", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.CosMarginProduct.__repr__": [[95, 101], ["str", "str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'('", "+", "'in_features='", "+", "str", "(", "self", ".", "in_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "', s='", "+", "str", "(", "self", ".", "s", ")", "+", "', m='", "+", "str", "(", "self", ".", "m", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.metrics.cosine_sim": [[56, 61], ["torch.mm", "torch.mm", "torch.mm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "x2.t", "torch.ger().clamp", "torch.ger().clamp", "torch.ger().clamp", "torch.ger", "torch.ger", "torch.ger"], "function", ["None"], ["", "", "def", "cosine_sim", "(", "x1", ",", "x2", ",", "dim", "=", "1", ",", "eps", "=", "1e-8", ")", ":", "\n", "    ", "ip", "=", "torch", ".", "mm", "(", "x1", ",", "x2", ".", "t", "(", ")", ")", "\n", "w1", "=", "torch", ".", "norm", "(", "x1", ",", "2", ",", "dim", ")", "\n", "w2", "=", "torch", ".", "norm", "(", "x2", ",", "2", ",", "dim", ")", "\n", "return", "ip", "/", "torch", ".", "ger", "(", "w1", ",", "w2", ")", ".", "clamp", "(", "min", "=", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.loss.FocalLoss.__init__": [[7, 12], ["torch.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gamma", "=", "0", ",", "eps", "=", "1e-7", ")", ":", "\n", "        ", "super", "(", "FocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "ce", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.loss.FocalLoss.forward": [[13, 18], ["loss.FocalLoss.ce", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "loss.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "logp", "=", "self", ".", "ce", "(", "input", ",", "target", ")", "\n", "p", "=", "torch", ".", "exp", "(", "-", "logp", ")", "\n", "loss", "=", "(", "1", "-", "p", ")", "**", "self", ".", "gamma", "*", "logp", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.BlockIR.__init__": [[5, 20], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", ",", "dim_match", ")", ":", "\n", "        ", "super", "(", "BlockIR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "inplanes", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "prelu1", "=", "nn", ".", "PReLU", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "if", "dim_match", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.BlockIR.forward": [[22, 38], ["resnets.BlockIR.bn1", "resnets.BlockIR.conv1", "resnets.BlockIR.bn2", "resnets.BlockIR.prelu1", "resnets.BlockIR.conv2", "resnets.BlockIR.bn3", "resnets.BlockIR.downsample"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "bn1", "(", "x", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "prelu1", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.__init__": [[42, 74], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.PReLU", "torch.PReLU", "resnets.LResNet._make_layer", "resnets.LResNet._make_layer", "resnets.LResNet._make_layer", "resnets.LResNet._make_layer", "torch.Sequential", "torch.Sequential", "resnets.LResNet.modules", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Dropout", "torch.Dropout", "torch.Flatten", "torch.Flatten", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "isinstance", "isinstance", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet._make_layer", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet._make_layer", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet._make_layer", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "filter_list", ",", "fmap_size", ",", "is_gray", "=", "False", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "LResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# input is (mini-batch,3 or 1,112,96)", "\n", "# use (conv3x3, stride=1, padding=1) instead of (conv7x7, stride=2, padding=3)", "\n", "if", "is_gray", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "filter_list", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "# gray", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "filter_list", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "filter_list", "[", "0", "]", ")", "\n", "self", ".", "prelu1", "=", "nn", ".", "PReLU", "(", "filter_list", "[", "0", "]", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "filter_list", "[", "0", "]", ",", "filter_list", "[", "1", "]", ",", "layers", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "filter_list", "[", "1", "]", ",", "filter_list", "[", "2", "]", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "filter_list", "[", "2", "]", ",", "filter_list", "[", "3", "]", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "filter_list", "[", "3", "]", ",", "filter_list", "[", "4", "]", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "BatchNorm2d", "(", "filter_list", "[", "4", "]", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "0.5", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "filter_list", "[", "4", "]", "*", "fmap_size", "[", "0", "]", "*", "fmap_size", "[", "1", "]", ",", "512", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "512", ")", ",", "# fix gamma ???", "\n", ")", "\n", "\n", "# Weight initialization", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm1d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet._make_layer": [[76, 83], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "block", "layers.append", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "inplanes", ",", "planes", ",", "blocks", ",", "stride", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "inplanes", ",", "planes", ",", "stride", ",", "False", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "planes", ",", "planes", ",", "stride", "=", "1", ",", "dim_match", "=", "True", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.forward": [[84, 98], ["resnets.LResNet.conv1", "resnets.LResNet.bn1", "resnets.LResNet.prelu1", "resnets.LResNet.layer1", "resnets.LResNet.layer2", "resnets.LResNet.layer3", "resnets.LResNet.layer4", "resnets.LResNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "# x = x.view(x.size(0), -1)", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save": [[99, 102], ["open", "torch.save", "torch.save", "torch.save", "torch.save", "resnets.LResNet.state_dict"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save"], ["", "def", "save", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "with", "open", "(", "file_path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet50E_IR": [[104, 109], ["resnets.LResNet"], "function", ["None"], ["", "", "", "def", "LResNet50E_IR", "(", "input_size", ",", "is_gray", "=", "False", ")", ":", "\n", "    ", "filter_list", "=", "[", "64", ",", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "layers", "=", "[", "3", ",", "4", ",", "14", ",", "3", "]", "\n", "fmap_size", "=", "[", "v", "//", "16", "for", "v", "in", "input_size", "]", "\n", "return", "LResNet", "(", "BlockIR", ",", "layers", ",", "filter_list", ",", "fmap_size", ",", "is_gray", ")", "\n", "# ---------------------------------- LResNet50E-IR network End ----------------------------------", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config._update_dict": [[89, 95], ["v.items", "ValueError"], "function", ["None"], ["def", "_update_dict", "(", "k", ",", "v", ")", ":", "\n", "    ", "for", "vk", ",", "vv", "in", "v", ".", "items", "(", ")", ":", "\n", "        ", "if", "vk", "in", "config", "[", "k", "]", ":", "\n", "            ", "config", "[", "k", "]", "[", "vk", "]", "=", "vv", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"{}.{} not exist in config.py\"", ".", "format", "(", "k", ",", "vk", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.update_config": [[97, 107], ["open", "easydict.EasyDict", "easydict.EasyDict.items", "yaml.load", "isinstance", "ValueError", "config._update_dict"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config._update_dict"], ["", "", "", "def", "update_config", "(", "config_file", ")", ":", "\n", "    ", "exp_config", "=", "None", "\n", "with", "open", "(", "config_file", ")", "as", "f", ":", "\n", "        ", "exp_config", "=", "edict", "(", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", ")", "\n", "for", "k", ",", "v", "in", "exp_config", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "config", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                    ", "_update_dict", "(", "k", ",", "v", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} not exist in config.py\"", ".", "format", "(", "k", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.gen_config": [[109, 118], ["dict", "dict.items", "isinstance", "open", "yaml.dump", "dict", "dict"], "function", ["None"], ["", "", "", "", "def", "gen_config", "(", "config_file", "=", "''", ")", ":", "\n", "    ", "cfg", "=", "dict", "(", "config", ")", "\n", "for", "k", ",", "v", "in", "cfg", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "edict", ")", ":", "\n", "            ", "cfg", "[", "k", "]", "=", "dict", "(", "v", ")", "\n", "\n", "", "", "config_file", "=", "config", ".", "DATASET", ".", "TRAIN_DATASET", "+", "'.yaml'", "\n", "with", "open", "(", "config_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "dict", "(", "cfg", ")", ",", "f", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.update_dir": [[120, 136], ["os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "update_dir", "(", "model_dir", ",", "log_dir", ",", "data_dir", ")", ":", "\n", "    ", "if", "model_dir", ":", "\n", "        ", "config", ".", "OUTPUT_DIR", "=", "model_dir", "\n", "\n", "", "if", "log_dir", ":", "\n", "        ", "config", ".", "LOG_DIR", "=", "log_dir", "\n", "\n", "", "if", "data_dir", ":", "\n", "        ", "config", ".", "DATA_DIR", "=", "data_dir", "\n", "\n", "", "config", ".", "DATASET", ".", "ROOT", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "config", ".", "DATASET", ".", "ROOT", ")", "\n", "\n", "config", ".", "TEST", ".", "BBOX_FILE", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "config", ".", "TEST", ".", "BBOX_FILE", ")", "\n", "\n", "config", ".", "NETWORK", ".", "PRETRAINED", "=", "os", ".", "path", ".", "join", "(", "config", ".", "DATA_DIR", ",", "\n", "config", ".", "NETWORK", ".", "PRETRAINED", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.get_model_name": [[138, 157], ["os.path.basename"], "function", ["None"], ["", "def", "get_model_name", "(", "cfg", ")", ":", "\n", "    ", "name", "=", "'{model}_{loss_type}_{lr}_{epoch}_{dm}_{num_id}k_{samples_perid}_{real_num_id}k_{real_samples_perid}_{batch_size}'", ".", "format", "(", "\n", "model", "=", "cfg", ".", "TRAIN", ".", "MODEL", ",", "\n", "loss_type", "=", "cfg", ".", "LOSS", ".", "TYPE", ",", "\n", "lr", "=", "cfg", ".", "TRAIN", ".", "LR", ",", "\n", "epoch", "=", "cfg", ".", "TRAIN", ".", "END_EPOCH", ",", "\n", "dm", "=", "cfg", ".", "TRAIN", ".", "DM", ",", "\n", "num_id", "=", "cfg", ".", "TRAIN", ".", "NUM_ID", "//", "1000", ",", "\n", "samples_perid", "=", "cfg", ".", "TRAIN", ".", "SAMPLES_PERID", ",", "\n", "real_num_id", "=", "cfg", ".", "REAL", ".", "NUM_ID", "//", "1000", ",", "\n", "real_samples_perid", "=", "cfg", ".", "REAL", ".", "SAMPLES_PERID", ",", "\n", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "\n", ")", "\n", "\n", "full_name", "=", "'{dataset}_{name}'", ".", "format", "(", "\n", "dataset", "=", "os", ".", "path", ".", "basename", "(", "config", ".", "DATASET", ".", "WEBFACE_ROOT", ")", ",", "\n", "name", "=", "name", ")", "\n", "\n", "return", "name", ",", "full_name", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.functions.train": [[17, 85], ["model.train", "time.time", "enumerate", "zip", "model", "syn_label[].squeeze().long", "syn_label[].squeeze().float", "syn_label[].squeeze().long", "syn_label[].squeeze().float", "w_a.reshape().repeat.reshape().repeat", "w_b.reshape().repeat.reshape().repeat", "loss.item", "optimizer.zero_grad", "loss.backward", "optimizer.step", "lr_scheduler.step", "syn_img.cuda", "real_img.cuda", "syn_label.cuda", "real_label.cuda", "random.choice", "w_a[].squeeze", "criterion", "w_b[].squeeze", "criterion", "logger.info", "time.time", "numpy.linspace", "syn_label[].squeeze", "syn_label[].squeeze", "syn_label[].squeeze", "syn_label[].squeeze", "w_a.reshape().repeat.reshape", "w_b.reshape().repeat.reshape", "classifier", "classifier", "classifier", "criterion().mean", "len", "time.time", "tensorboardX.SummaryWriter", "sw.add_scalar", "loss_a.mean", "loss_b.mean", "w_a.reshape().repeat.size", "w_b.reshape().repeat.size", "criterion", "len", "len"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.functions.train"], ["def", "train", "(", "syn_loader", ",", "real_loader", ",", "model", ",", "classifier", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "tb_log_dir", ",", "config", ",", "lr_scheduler", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "time_curr", "=", "time", ".", "time", "(", ")", "\n", "loss_display", "=", "0.0", "\n", "\n", "for", "batch_idx", ",", "(", "syn_data", ",", "real_data", ")", "in", "enumerate", "(", "zip", "(", "syn_loader", ",", "real_loader", ")", ")", ":", "\n", "        ", "syn_img", ",", "syn_label", "=", "syn_data", "\n", "real_img", ",", "real_label", "=", "real_data", "\n", "\n", "syn_img", ",", "real_img", ",", "syn_label", ",", "real_label", "=", "syn_img", ".", "cuda", "(", ")", ",", "real_img", ".", "cuda", "(", ")", ",", "syn_label", ".", "cuda", "(", ")", ",", "real_label", ".", "cuda", "(", ")", "\n", "\n", "# mixup syn img with real img", "\n", "if", "config", ".", "TRAIN", ".", "DM", ":", "\n", "            ", "lam", "=", "random", ".", "choice", "(", "np", ".", "linspace", "(", "0", ",", "1.05", ",", "21", ",", "endpoint", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "lam", "=", "1", "\n", "", "img", "=", "lam", "*", "syn_img", "+", "(", "1", "-", "lam", ")", "*", "real_img", "\n", "\n", "feature", "=", "model", "(", "img", ")", "\n", "\n", "# for syn img", "\n", "label_a", "=", "syn_label", "[", ":", ",", "0", "]", ".", "squeeze", "(", ")", ".", "long", "(", ")", "\n", "w_a", "=", "syn_label", "[", ":", ",", "1", "]", ".", "squeeze", "(", ")", ".", "float", "(", ")", "\n", "label_b", "=", "syn_label", "[", ":", ",", "2", "]", ".", "squeeze", "(", ")", ".", "long", "(", ")", "\n", "w_b", "=", "syn_label", "[", ":", ",", "3", "]", ".", "squeeze", "(", ")", ".", "float", "(", ")", "\n", "\n", "# extend", "\n", "w_a", "=", "w_a", ".", "reshape", "(", "(", "w_a", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "repeat", "(", "1", ",", "config", ".", "TRAIN", ".", "NUM_ID", "+", "config", ".", "REAL", ".", "NUM_ID", ")", "\n", "w_b", "=", "w_b", ".", "reshape", "(", "(", "w_b", ".", "size", "(", "0", ")", ",", "1", ")", ")", ".", "repeat", "(", "1", ",", "config", ".", "TRAIN", ".", "NUM_ID", "+", "config", ".", "REAL", ".", "NUM_ID", ")", "\n", "# pdb.set_trace()", "\n", "\n", "# compute output", "\n", "output", "=", "w_a", "*", "classifier", "(", "feature", ",", "label_a", ")", "+", "w_b", "*", "classifier", "(", "feature", ",", "label_b", ")", "\n", "output", "=", "lam", "*", "output", "+", "(", "1", "-", "lam", ")", "*", "classifier", "(", "feature", ",", "real_label", ")", "\n", "\n", "loss_a", "=", "w_a", "[", ":", ",", "0", "]", ".", "squeeze", "(", ")", "*", "criterion", "(", "output", ",", "label_a", ")", "\n", "loss_b", "=", "w_b", "[", ":", ",", "0", "]", ".", "squeeze", "(", ")", "*", "criterion", "(", "output", ",", "label_b", ")", "\n", "\n", "loss", "=", "lam", "*", "(", "loss_a", ".", "mean", "(", ")", "+", "loss_b", ".", "mean", "(", ")", ")", "+", "(", "1", "-", "lam", ")", "*", "criterion", "(", "output", ",", "real_label", ")", ".", "mean", "(", ")", "\n", "\n", "loss_display", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "iters", "=", "epoch", "*", "len", "(", "syn_loader", ")", "+", "batch_idx", "\n", "\n", "if", "iters", "%", "config", ".", "TRAIN", ".", "PRINT_FREQ", "==", "0", "and", "iters", "!=", "0", ":", "\n", "            ", "time_used", "=", "time", ".", "time", "(", ")", "-", "time_curr", "\n", "if", "batch_idx", "<", "config", ".", "TRAIN", ".", "PRINT_FREQ", ":", "\n", "                ", "num_freq", "=", "batch_idx", "+", "1", "\n", "", "else", ":", "\n", "                ", "num_freq", "=", "config", ".", "TRAIN", ".", "PRINT_FREQ", "\n", "", "speed", "=", "num_freq", "/", "time_used", "\n", "loss_display", "/=", "num_freq", "\n", "\n", "INFO", "=", "' Margin: {:.2f}, Scale: {:.2f}'", ".", "format", "(", "classifier", ".", "module", ".", "m", ",", "classifier", ".", "module", ".", "s", ")", "\n", "logger", ".", "info", "(", "\n", "'Train Epoch: {} [{:03}/{} ({:.0f}%)]{:05}, Loss: {:.6f}, Lr:{:.4e}, Elapsed time: {:.4f}s, Batches/s {:.4f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", ",", "len", "(", "syn_loader", ")", ",", "100.", "*", "batch_idx", "/", "len", "(", "syn_loader", ")", ",", "\n", "iters", ",", "loss_display", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "time_used", ",", "speed", ")", "+", "INFO", ")", "\n", "with", "SummaryWriter", "(", "tb_log_dir", ")", "as", "sw", ":", "\n", "                ", "sw", ".", "add_scalar", "(", "'TRAIN_LOSS'", ",", "loss_display", ",", "iters", ")", "\n", "", "time_curr", "=", "time", ".", "time", "(", ")", "\n", "loss_display", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.extractDeepFeature": [[13, 19], ["img.to.to", "model", "fc.to().squeeze.to().squeeze", "fc.to().squeeze.to"], "function", ["None"], ["def", "extractDeepFeature", "(", "img", ",", "model", ",", "is_gray", ")", ":", "\n", "    ", "img", "=", "img", ".", "to", "(", "'cuda'", ")", "\n", "fc", "=", "model", "(", "img", ")", "\n", "fc", "=", "fc", ".", "to", "(", "'cpu'", ")", ".", "squeeze", "(", ")", "\n", "\n", "return", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.KFold": [[20, 28], ["list", "range", "range", "list", "folds.append", "int", "int", "set", "set"], "function", ["None"], ["", "def", "KFold", "(", "n", "=", "6000", ",", "n_folds", "=", "10", ")", ":", "\n", "    ", "folds", "=", "[", "]", "\n", "base", "=", "list", "(", "range", "(", "n", ")", ")", "\n", "for", "i", "in", "range", "(", "n_folds", ")", ":", "\n", "        ", "test", "=", "base", "[", "int", "(", "i", "*", "n", "/", "n_folds", ")", ":", "int", "(", "(", "i", "+", "1", ")", "*", "n", "/", "n_folds", ")", "]", "\n", "train", "=", "list", "(", "set", "(", "base", ")", "-", "set", "(", "test", ")", ")", "\n", "folds", ".", "append", "(", "[", "train", ",", "test", "]", ")", "\n", "", "return", "folds", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval_acc": [[30, 41], ["numpy.array", "numpy.array", "np.array.append", "np.array.append", "len", "int", "numpy.count_nonzero", "float"], "function", ["None"], ["", "def", "eval_acc", "(", "threshold", ",", "diff", ")", ":", "\n", "    ", "y_true", "=", "[", "]", "\n", "y_predict", "=", "[", "]", "\n", "for", "d", "in", "diff", ":", "\n", "        ", "same", "=", "1", "if", "float", "(", "d", "[", "0", "]", ")", ">", "threshold", "else", "0", "\n", "y_predict", ".", "append", "(", "same", ")", "\n", "y_true", ".", "append", "(", "int", "(", "d", "[", "1", "]", ")", ")", "\n", "", "y_true", "=", "np", ".", "array", "(", "y_true", ")", "\n", "y_predict", "=", "np", ".", "array", "(", "y_predict", ")", "\n", "accuracy", "=", "1.0", "*", "np", ".", "count_nonzero", "(", "y_true", "==", "y_predict", ")", "/", "len", "(", "y_true", ")", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.find_best_threshold": [[43, 51], ["lfw_eval.eval_acc"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval_acc"], ["", "def", "find_best_threshold", "(", "thresholds", ",", "predicts", ")", ":", "\n", "    ", "best_threshold", "=", "best_acc", "=", "0", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "accuracy", "=", "eval_acc", "(", "threshold", ",", "predicts", ")", "\n", "if", "accuracy", ">=", "best_acc", ":", "\n", "            ", "best_acc", "=", "accuracy", "\n", "best_threshold", "=", "threshold", "\n", "", "", "return", "best_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.cosine_similarity": [[52, 61], ["f1.numpy.numpy", "f2.numpy.numpy", "numpy.sum", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cosine_similarity", "(", "f1", ",", "f2", ")", ":", "\n", "# compute cosine_similarity for 2-D array", "\n", "    ", "f1", "=", "f1", ".", "numpy", "(", ")", "\n", "f2", "=", "f2", ".", "numpy", "(", ")", "\n", "\n", "A", "=", "np", ".", "sum", "(", "f1", "*", "f2", ",", "axis", "=", "1", ")", "\n", "B", "=", "np", ".", "linalg", ".", "norm", "(", "f1", ",", "axis", "=", "1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "f2", ",", "axis", "=", "1", ")", "+", "1e-5", "\n", "\n", "return", "A", "/", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.compute_distance": [[62, 70], ["lfw_eval.extractDeepFeature", "lfw_eval.extractDeepFeature", "lfw_eval.cosine_similarity", "flag.squeeze().numpy.squeeze().numpy", "numpy.stack", "flag.squeeze().numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.extractDeepFeature", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.extractDeepFeature", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.cosine_similarity"], ["", "def", "compute_distance", "(", "img1", ",", "img2", ",", "model", ",", "flag", ",", "is_gray", ")", ":", "\n", "        ", "f1", "=", "extractDeepFeature", "(", "img1", ",", "model", ",", "is_gray", ")", "\n", "f2", "=", "extractDeepFeature", "(", "img2", ",", "model", ",", "is_gray", ")", "\n", "\n", "distance", "=", "cosine_similarity", "(", "f1", ",", "f2", ")", "\n", "\n", "flag", "=", "flag", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", "\n", "return", "np", ".", "stack", "(", "(", "distance", ",", "flag", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.obtain_acc": [[71, 86], ["lfw_eval.KFold", "numpy.arange", "enumerate", "time.time", "logger.info", "numpy.mean", "lfw_eval.find_best_threshold", "accuracy.append", "thd.append", "lfw_eval.eval_acc", "numpy.mean", "numpy.std", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.KFold", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.find_best_threshold", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval_acc"], ["", "def", "obtain_acc", "(", "predicts", ",", "num_class", ",", "start", ")", ":", "\n", "    ", "accuracy", "=", "[", "]", "\n", "thd", "=", "[", "]", "\n", "folds", "=", "KFold", "(", "n", "=", "num_class", ",", "n_folds", "=", "10", ")", "\n", "thresholds", "=", "np", ".", "arange", "(", "-", "1.0", ",", "1.0", ",", "0.005", ")", "\n", "\n", "for", "idx", ",", "(", "train", ",", "test", ")", "in", "enumerate", "(", "folds", ")", ":", "\n", "        ", "best_thresh", "=", "find_best_threshold", "(", "thresholds", ",", "predicts", "[", "train", "]", ")", "\n", "accuracy", ".", "append", "(", "eval_acc", "(", "best_thresh", ",", "predicts", "[", "test", "]", ")", ")", "\n", "thd", ".", "append", "(", "best_thresh", ")", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "time_used", "=", "(", "end", "-", "start", ")", "/", "60.0", "\n", "logger", ".", "info", "(", "'LFW_ACC={:.4f} std={:.4f} thd={:.4f} time_used={:.4f} mins'", ".", "format", "(", "np", ".", "mean", "(", "accuracy", ")", ",", "np", ".", "std", "(", "accuracy", ")", ",", "np", ".", "mean", "(", "thd", ")", ",", "time_used", ")", ")", "\n", "# print('LFW_ACC={:.4f} std={:.4f} thd={:.4f} time_used={:.4f} mins'.format(np.mean(accuracy), np.std(accuracy), np.mean(thd), time_used))", "\n", "return", "np", ".", "mean", "(", "accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval": [[88, 118], ["numpy.zeros", "model.eval", "time.time", "lfw_eval.obtain_acc", "tensorboardX.SummaryWriter", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.close", "torch.load", "torch.load", "isinstance", "torch.no_grad", "torch.no_grad", "enumerate", "numpy.mean", "numpy.mean", "model.module.load_state_dict", "model.load_state_dict", "lfw_eval.compute_distance", "len"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.obtain_acc", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.compute_distance"], ["", "def", "eval", "(", "model", ",", "model_path", ",", "config", ",", "test_loader", ",", "tb_log_dir", ",", "epoch", ",", "is_gray", "=", "False", ")", ":", "\n", "    ", "if", "model_path", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "\n", "if", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "model", ".", "module", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "\n", "", "", "predicts", "=", "np", ".", "zeros", "(", "shape", "=", "(", "len", "(", "test_loader", ".", "dataset", ")", ",", "2", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "cur", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch_idx", ",", "(", "img1", ",", "img2", ",", "flag", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "            ", "predicts", "[", "cur", ":", "cur", "+", "flag", ".", "shape", "[", "0", "]", "]", "=", "compute_distance", "(", "img1", ",", "img2", ",", "model", ",", "flag", ",", "is_gray", ")", "\n", "cur", "+=", "flag", ".", "shape", "[", "0", "]", "\n", "", "", "assert", "cur", "==", "predicts", ".", "shape", "[", "0", "]", "\n", "\n", "accuracy", "=", "obtain_acc", "(", "predicts", ",", "config", ".", "DATASET", ".", "LFW_CLASS", ",", "start", ")", "\n", "\n", "# visualize the masks stats", "\n", "writer", "=", "SummaryWriter", "(", "tb_log_dir", ")", "\n", "writer", ".", "add_scalar", "(", "'LFW_ACC'", ",", "np", ".", "mean", "(", "accuracy", ")", ",", "epoch", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n", "return", "np", ".", "mean", "(", "accuracy", ")", ",", "predicts", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.accuracy": [[14, 27], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "output_sorted", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_temp_logger": [[29, 57], ["pathlib.Path", "final_output_dir.mkdir", "time.strftime", "logging.basicConfig", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.getLogger().addHandler", "print", "tensorboard_log_dir.mkdir", "pathlib.Path.exists", "print", "pathlib.Path.mkdir", "str", "str", "str", "logging.getLogger"], "function", ["None"], ["", "def", "create_temp_logger", "(", ")", ":", "\n", "    ", "output_dir", "=", "'temp'", "\n", "root_output_dir", "=", "Path", "(", "output_dir", ")", "\n", "# set up logger", "\n", "if", "not", "root_output_dir", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "'creating {}'", ".", "format", "(", "root_output_dir", ")", ")", "\n", "root_output_dir", ".", "mkdir", "(", ")", "\n", "\n", "", "final_output_dir", "=", "root_output_dir", "\n", "\n", "final_output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "time_str", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M'", ")", "\n", "log_file", "=", "'{}.log'", ".", "format", "(", "time_str", ")", "\n", "final_log_file", "=", "final_output_dir", "/", "log_file", "\n", "head", "=", "'%(asctime)-15s %(message)s'", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "str", "(", "final_log_file", ")", ",", "\n", "format", "=", "head", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "console", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "logging", ".", "getLogger", "(", "''", ")", ".", "addHandler", "(", "console", ")", "\n", "\n", "tensorboard_log_dir", "=", "root_output_dir", "/", "'tensorboard'", "\n", "print", "(", "'creating {}'", ".", "format", "(", "tensorboard_log_dir", ")", ")", "\n", "tensorboard_log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "return", "logger", ",", "str", "(", "final_output_dir", ")", ",", "str", "(", "tensorboard_log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_logger": [[58, 101], ["pathlib.Path", "lib.core.config.get_model_name", "print", "final_output_dir.mkdir", "time.strftime", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.FileHandler.setLevel", "logging.getLogger.addHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.StreamHandler.setLevel", "logging.getLogger.addHandler", "print", "tensorboard_log_dir.mkdir", "pathlib.Path.exists", "print", "pathlib.Path.mkdir", "os.path.basename().split", "dataset.split", "logging.Formatter", "logging.Formatter", "str", "str", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.config.get_model_name"], ["", "def", "create_logger", "(", "cfg", ",", "cfg_name", ",", "dataset", ",", "phase", "=", "'train'", ")", ":", "\n", "    ", "root_output_dir", "=", "Path", "(", "cfg", ".", "TRAIN", ".", "OUTPUT_DIR", ")", "\n", "# set up logger", "\n", "if", "not", "root_output_dir", ".", "exists", "(", ")", ":", "\n", "        ", "print", "(", "'creating {}'", ".", "format", "(", "root_output_dir", ")", ")", "\n", "root_output_dir", ".", "mkdir", "(", ")", "\n", "\n", "", "model", ",", "_", "=", "get_model_name", "(", "cfg", ")", "\n", "cfg_name", "=", "os", ".", "path", ".", "basename", "(", "cfg_name", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "dataset", "=", "dataset", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "\n", "final_output_dir", "=", "root_output_dir", "/", "dataset", "/", "model", "/", "cfg_name", "\n", "\n", "print", "(", "'creating {}'", ".", "format", "(", "final_output_dir", ")", ")", "\n", "final_output_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "time_str", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M'", ")", "\n", "log_file", "=", "'{}_{}_{}.log'", ".", "format", "(", "cfg_name", ",", "time_str", ",", "phase", ")", "\n", "final_log_file", "=", "final_output_dir", "/", "log_file", "\n", "\n", "fmt", "=", "\"[%(asctime)s] %(message)s\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "# add file handler to save the log to file", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "final_log_file", ")", "\n", "fh", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "fmt", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "# add console handler to output log on screen", "\n", "sh", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "sh", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "fmt", ")", ")", "\n", "sh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "addHandler", "(", "sh", ")", "\n", "logger", ".", "propagate", "=", "False", "\n", "\n", "tensorboard_file", "=", "'tensorboard_{}'", ".", "format", "(", "time_str", ")", "\n", "tensorboard_log_dir", "=", "final_output_dir", "/", "tensorboard_file", "\n", "print", "(", "'creating {}'", ".", "format", "(", "tensorboard_log_dir", ")", ")", "\n", "tensorboard_log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "return", "logger", ",", "str", "(", "final_output_dir", ")", ",", "str", "(", "tensorboard_log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.checkdir": [[106, 111], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "checkdir", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.create_dir": [[112, 115], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "create_dir", "(", "dir_name", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.get_run_name": [[119, 123], ["socket.gethostname", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "", "def", "get_run_name", "(", ")", ":", "\n", "    ", "\"\"\" A unique name for each run \"\"\"", "\n", "return", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\n", "'%b%d-%H-%M-%S'", ")", "+", "'_'", "+", "socket", ".", "gethostname", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.adjust_learning_rate": [[124, 135], ["print_with_time", "step_size.index"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "iteration", ",", "step_size", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 each step size\"\"\"", "\n", "if", "iteration", "in", "step_size", ":", "\n", "        ", "lr", "=", "args", ".", "lr", "*", "(", "0.1", "**", "(", "step_size", ".", "index", "(", "iteration", ")", "+", "1", ")", ")", "\n", "print_with_time", "(", "'Adjust learning rate to {}'", ".", "format", "(", "lr", ")", ")", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "args", ".", "lr_freeze", "*", "lr", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "'lr'", "]", "=", "lr", "\n", "#for param_group in optimizer.param_groups:", "\n", "#    param_group['lr'] = lr", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.load_pretrained": [[139, 153], ["os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "print", "torch.load", "model.load_state_dict", "classifier.load_state_dict", "print"], "function", ["None"], ["", "", "def", "load_pretrained", "(", "model", ",", "classifier", ",", "output_dir", ",", "filename", "=", "'model_baseline_9443.pth.tar'", ")", ":", "\n", "    ", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", "\n", "file", "=", "file", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", "else", "os", ".", "path", ".", "join", "(", "'model'", ",", "filename", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "        ", "print", "(", "'load pretrained model from {}'", ".", "format", "(", "file", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "file", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "False", ")", "\n", "classifier", ".", "load_state_dict", "(", "checkpoint", "[", "'classifier'", "]", ")", "\n", "\n", "return", "model", ",", "classifier", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'no checkpoint found at {}'", ".", "format", "(", "file", ")", ")", "\n", "return", "model", ",", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.load_checkpoint": [[154, 170], ["os.path.join", "os.path.isfile", "torch.load", "model.load_state_dict", "optimizer.load_state_dict", "classifier.load_state_dict", "print", "print"], "function", ["None"], ["", "", "def", "load_checkpoint", "(", "model", ",", "optimizer", ",", "classifier", ",", "output_dir", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "file", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "classifier", ".", "load_state_dict", "(", "checkpoint", "[", "'classifier'", "]", ")", "\n", "print", "(", "'load checkpoint {} (epoch {})'", "\n", ".", "format", "(", "file", ",", "start_epoch", ")", ")", "\n", "\n", "return", "start_epoch", ",", "model", ",", "optimizer", ",", "classifier", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "'no checkpoint found at {}'", ".", "format", "(", "file", ")", ")", "\n", "return", "0", ",", "model", ",", "optimizer", ",", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.save_checkpoint": [[171, 180], ["torch.save", "time.strftime", "os.path.join", "torch.save", "os.path.join"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save"], ["", "", "def", "save_checkpoint", "(", "states", ",", "is_best", ",", "output_dir", ",", "\n", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "states", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "filename", ")", ")", "\n", "time_str", "=", "time", ".", "strftime", "(", "'%Y-%m-%d-%H-%M'", ")", "\n", "if", "is_best", "and", "'state_dict'", "in", "states", ":", "\n", "        ", "state_info", "=", "{", "'state_dict'", ":", "states", "[", "'state_dict'", "]", ",", "\n", "'classifier'", ":", "states", "[", "'classifier'", "]", "}", "\n", "# torch.save(state_info, os.path.join(output_dir, 'model_best_{}_{:.4f}.pth.tar'.format(time_str, states['perf'])))", "\n", "torch", ".", "save", "(", "state_info", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'model_best.pth.tar'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.mixup_data": [[184, 196], ["torch.randperm().cuda", "numpy.random.beta", "x.size", "torch.randperm"], "function", ["None"], ["", "", "def", "mixup_data", "(", "x", ",", "y", ",", "alpha", "=", "1.0", ")", ":", "\n", "    ", "if", "alpha", ">", "0", ":", "\n", "        ", "lam", "=", "np", ".", "random", ".", "beta", "(", "alpha", ",", "alpha", ")", "\n", "", "else", ":", "\n", "        ", "lam", "=", "1", "\n", "\n", "", "batch_size", "=", "x", ".", "size", "(", ")", "[", "0", "]", "\n", "index", "=", "torch", ".", "randperm", "(", "batch_size", ")", ".", "cuda", "(", ")", "\n", "\n", "mixed_x", "=", "lam", "*", "x", "+", "(", "1", "-", "lam", ")", "*", "x", "[", "index", ",", ":", "]", "\n", "y_a", ",", "y_b", "=", "y", ",", "y", "[", "index", "]", "\n", "return", "mixed_x", ",", "y_a", ",", "y_b", ",", "lam", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.utils.mixup_criterion": [[197, 199], ["criterion", "criterion"], "function", ["None"], ["", "def", "mixup_criterion", "(", "criterion", ",", "pred", ",", "y_a", ",", "y_b", ",", "lam", ")", ":", "\n", "    ", "return", "lam", "*", "criterion", "(", "pred", ",", "y_a", ")", "+", "(", "1", "-", "lam", ")", "*", "criterion", "(", "pred", ",", "y_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.CoeffDecoder": [[18, 29], ["tensorflow.variable_scope", "tensorflow.variable_scope", "range", "tensorflow.layers.dense", "tensorflow.stop_gradient", "tensorflow.layers.dense", "str"], "function", ["None"], ["def", "CoeffDecoder", "(", "z", ",", "ch_depth", "=", "3", ",", "ch_dim", "=", "512", ",", "coeff_length", "=", "128", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'stage1'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'decoder'", ")", ":", "\n", "            ", "y", "=", "z", "\n", "for", "i", "in", "range", "(", "ch_depth", ")", ":", "\n", "                ", "y", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "ch_dim", ",", "tf", ".", "nn", ".", "relu", ",", "name", "=", "'fc'", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "x_hat", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "coeff_length", ",", "name", "=", "'x_hat'", ")", "\n", "x_hat", "=", "tf", ".", "stop_gradient", "(", "x_hat", ")", "\n", "\n", "", "", "return", "x_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.restore_weights_and_initialize": [[31, 54], ["tensorflow.trainable_variables", "tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tf.train.Saver.restore", "tf.train.Saver.restore", "tf.train.Saver.restore", "tf.train.Saver.restore", "tensorflow.get_default_session", "tensorflow.get_default_session", "tensorflow.get_default_session", "tensorflow.get_default_session"], "function", ["None"], ["", "def", "restore_weights_and_initialize", "(", ")", ":", "\n", "    ", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "g_list", "=", "tf", ".", "global_variables", "(", ")", "\n", "\n", "# add batch normalization params into trainable variables ", "\n", "bn_moving_vars", "=", "[", "g", "for", "g", "in", "g_list", "if", "'moving_mean'", "in", "g", ".", "name", "]", "\n", "bn_moving_vars", "+=", "[", "g", "for", "g", "in", "g_list", "if", "'moving_variance'", "in", "g", ".", "name", "]", "\n", "var_list", "+=", "bn_moving_vars", "\n", "\n", "var_id_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'id'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_exp_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'exp'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_gamma_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'gamma'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_rot_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'rot'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "\n", "saver_id", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_id_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_exp", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_exp_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_gamma", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_gamma_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_rot", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_rot_list", ",", "max_to_keep", "=", "100", ")", "\n", "\n", "saver_id", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/id/stage1_epoch_395.ckpt'", ")", "\n", "saver_exp", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/exp/stage1_epoch_395.ckpt'", ")", "\n", "saver_gamma", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/gamma/stage1_epoch_395.ckpt'", ")", "\n", "saver_rot", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/rot/stage1_epoch_395.ckpt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.z_to_lambda_mapping": [[55, 69], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "syn_factors.CoeffDecoder", "tensorflow.variable_scope", "syn_factors.CoeffDecoder", "tensorflow.variable_scope", "syn_factors.CoeffDecoder", "tensorflow.variable_scope", "syn_factors.CoeffDecoder"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder"], ["", "def", "z_to_lambda_mapping", "(", "latents", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'id'", ")", ":", "\n", "            ", "IDcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", ":", "128", "]", ",", "coeff_length", "=", "160", ",", "ch_dim", "=", "512", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'exp'", ")", ":", "\n", "            ", "EXPcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", ":", "128", "+", "32", "]", ",", "coeff_length", "=", "64", ",", "ch_dim", "=", "256", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'gamma'", ")", ":", "\n", "            ", "GAMMAcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", "+", "32", ":", "128", "+", "32", "+", "16", "]", ",", "coeff_length", "=", "27", ",", "ch_dim", "=", "128", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'rot'", ")", ":", "\n", "            ", "Rotcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", "+", "32", "+", "16", ":", "128", "+", "32", "+", "16", "+", "3", "]", ",", "coeff_length", "=", "3", ",", "ch_dim", "=", "32", ",", "ch_depth", "=", "3", ")", "\n", "\n", "", "INPUTcoeff", "=", "tf", ".", "concat", "(", "[", "IDcoeff", ",", "EXPcoeff", ",", "Rotcoeff", ",", "GAMMAcoeff", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "INPUTcoeff", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.truncate_generation": [[71, 95], ["numpy.reshape().astype", "tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "Gs.components.mapping.get_output_for", "Gs.components.mapping.get_output_for", "tensorflow.concat", "Gs.components.synthesis.get_output_for", "tensorflow.clip_by_value", "tensorflow.transpose", "dnnlib.util.open_url", "dnnlib.util.open_url", "numpy.loadtxt", "numpy.reshape", "tensorflow.zeros"], "function", ["None"], ["", "", "def", "truncate_generation", "(", "Gs", ",", "inputcoeff", ",", "inputcoeff_else", ",", "ratio", ",", "rate", "=", "0.7", ",", "dlatent_average_id", "=", "None", ")", ":", "\n", "    ", "if", "dlatent_average_id", "is", "None", ":", "\n", "        ", "url_pretrained_model_ffhq_average_w_id", "=", "'https://drive.google.com/uc?id=17L6-ENX3NbMsS3MSCshychZETLPtJnbS'", "\n", "with", "dnnlib", ".", "util", ".", "open_url", "(", "url_pretrained_model_ffhq_average_w_id", ",", "cache_dir", "=", "config", ".", "cache_dir", ")", "as", "f", ":", "\n", "            ", "dlatent_average_id", "=", "np", ".", "loadtxt", "(", "f", ")", "\n", "", "", "dlatent_average_id", "=", "np", ".", "reshape", "(", "dlatent_average_id", ",", "[", "1", ",", "14", ",", "512", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dlatent_average_id", "=", "tf", ".", "constant", "(", "dlatent_average_id", ")", "\n", "\n", "id_coeff", "=", "ratio", "*", "inputcoeff", "[", ":", ",", ":", "160", "]", "+", "(", "1", "-", "ratio", ")", "*", "inputcoeff_else", "[", ":", ",", ":", "160", "]", "\n", "inputcoeff", "=", "tf", ".", "concat", "(", "[", "id_coeff", ",", "\n", "inputcoeff", "[", ":", ",", "160", ":", "160", "+", "64", "+", "3", "+", "27", "+", "32", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "inputcoeff_id", "=", "tf", ".", "concat", "(", "[", "inputcoeff", "[", ":", ",", ":", "160", "]", ",", "tf", ".", "zeros", "(", "[", "1", ",", "126", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "dlatent_out", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "inputcoeff", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "# original w space output", "\n", "dlatent_out_id", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "inputcoeff_id", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "\n", "\n", "dlatent_out_trun", "=", "dlatent_out", "+", "(", "dlatent_average_id", "-", "dlatent_out_id", ")", "*", "(", "1", "-", "rate", ")", "\n", "dlatent_out_final", "=", "tf", ".", "concat", "(", "[", "dlatent_out_trun", "[", ":", ",", ":", "8", ",", ":", "]", ",", "dlatent_out", "[", ":", ",", "8", ":", ",", ":", "]", "]", ",", "axis", "=", "1", ")", "# w space latent vector with truncation trick", "\n", "\n", "fake_images_out", "=", "Gs", ".", "components", ".", "synthesis", ".", "get_output_for", "(", "dlatent_out_final", ",", "randomize_noise", "=", "False", ")", "\n", "fake_images_out", "=", "tf", ".", "clip_by_value", "(", "(", "fake_images_out", "+", "1", ")", "*", "127.5", ",", "0", ",", "255", ")", "\n", "fake_images_out", "=", "tf", ".", "transpose", "(", "fake_images_out", ",", "perm", "=", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "fake_images_out", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.get_model_and_average_w_id": [[97, 124], ["training.misc.load_pkl", "model_name.replace", "os.path.isfile", "print", "tensorflow.placeholder", "tensorflow.placeholder", "syn_factors.z_to_lambda_mapping", "tensorflow.concat", "Gs.components.mapping.get_output_for", "syn_factors.restore_weights_and_initialize", "numpy.random.seed", "range", "numpy.concatenate", "numpy.mean", "numpy.savetxt", "numpy.loadtxt", "numpy.random.normal", "numpy.random.normal", "dnnlib.run", "np.loadtxt.append", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.restore_weights_and_initialize"], ["", "def", "get_model_and_average_w_id", "(", "model_name", ")", ":", "\n", "    ", "G", ",", "D", ",", "Gs", "=", "misc", ".", "load_pkl", "(", "model_name", ")", "\n", "average_w_name", "=", "model_name", ".", "replace", "(", "'.pkl'", ",", "'-average_w_id.txt'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "average_w_name", ")", ":", "\n", "        ", "print", "(", "'Calculating average w id...\\n'", ")", "\n", "latents", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'noise'", ",", "shape", "=", "[", "1", ",", "32", "]", ")", "\n", "INPUTcoeff", "=", "z_to_lambda_mapping", "(", "latents", ")", "\n", "INPUTcoeff_id", "=", "INPUTcoeff", "[", ":", ",", ":", "160", "]", "\n", "INPUTcoeff_w_noise", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff_id", ",", "tf", ".", "zeros", "(", "[", "1", ",", "64", "+", "27", "+", "3", "]", ")", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "dlatent_out", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "INPUTcoeff_w_noise", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "\n", "restore_weights_and_initialize", "(", ")", "\n", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "average_w_id", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "50000", ")", ":", "\n", "            ", "lats", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise_", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "]", ")", "\n", "w_out", "=", "tflib", ".", "run", "(", "dlatent_out", ",", "{", "latents", ":", "lats", ",", "noise", ":", "noise_", "}", ")", "\n", "average_w_id", ".", "append", "(", "w_out", ")", "\n", "\n", "", "average_w_id", "=", "np", ".", "concatenate", "(", "average_w_id", ",", "axis", "=", "0", ")", "\n", "average_w_id", "=", "np", ".", "mean", "(", "average_w_id", ",", "axis", "=", "0", ")", "\n", "np", ".", "savetxt", "(", "average_w_name", ",", "average_w_id", ")", "\n", "", "else", ":", "\n", "        ", "average_w_id", "=", "np", ".", "loadtxt", "(", "average_w_name", ")", "\n", "\n", "", "return", "Gs", ",", "average_w_id", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.parse_args": [[125, 140], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "desc", "=", "\"Disentangled face image generation\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "desc", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--factor'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'factor variation mode. 0 = non, 1 = expression, 2 = lighting, 3 = pose.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_id'", ",", "type", "=", "int", ",", "default", "=", "5000", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_perid'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'dataset'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "CODE_ROOT", "+", "'cache/network-snapshot-020126.pkl'", ",", "help", "=", "'pkl file name of the generator. If None, use the default pre-trained model.'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.check_dir": [[141, 145], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "check_dir", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.load_Gs": [[146, 150], ["dnnlib.util.open_url", "dnnlib.util.open_url", "pickle.load"], "function", ["None"], ["", "", "def", "load_Gs", "(", "url", ")", ":", "\n", "    ", "with", "dnnlib", ".", "util", ".", "open_url", "(", "url", ",", "cache_dir", "=", "config", ".", "cache_dir", ")", "as", "f", ":", "\n", "        ", "_G", ",", "_D", ",", "Gs", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "Gs", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_factors.main": [[151, 233], ["syn_factors.parse_args", "dnnlib.init_tf", "syn_factors.restore_weights_and_initialize", "numpy.random.seed", "numpy.random.normal", "tqdm.tqdm", "tensorflow.device", "load_Gs.print_layers", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "syn_factors.z_to_lambda_mapping", "syn_factors.z_to_lambda_mapping", "tensorflow.concat", "tensorflow.concat", "syn_factors.truncate_generation", "range", "id_coeffs[].reshape", "list", "list.remove", "random.sample", "numpy.random.normal", "numpy.random.normal", "enumerate", "syn_factors.load_Gs", "syn_factors.get_model_and_average_w_id", "range", "id_coeffs[].reshape", "random.choice", "numpy.round", "numpy.random.normal", "dnnlib.run", "PIL.Image.fromarray", "os.path.join", "syn_factors.check_dir", "PIL.Image.fromarray.save", "numpy.linspace", "numpy.concatenate", "numpy.concatenate", "fake[].astype", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.restore_weights_and_initialize", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.truncate_generation", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.load_Gs", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.get_model_and_average_w_id", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.check_dir", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "\"0\"", "\n", "args", "=", "parse_args", "(", ")", "\n", "\n", "tflib", ".", "init_tf", "(", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/gpu:0'", ")", ":", "\n", "\n", "# Use default pre-trained model", "\n", "        ", "if", "args", ".", "model", "is", "None", ":", "\n", "            ", "url_pretrained_model_ffhq", "=", "'https://drive.google.com/uc?id=1nT_cf610q5mxD_jACvV43w4SYBxsPUBq'", "\n", "Gs", "=", "load_Gs", "(", "url_pretrained_model_ffhq", ")", "\n", "average_w_id", "=", "None", "\n", "\n", "", "else", ":", "\n", "            ", "Gs", ",", "average_w_id", "=", "get_model_and_average_w_id", "(", "args", ".", "model", ")", "\n", "# Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.", "\n", "# average_w_id = average w space latent vector with zero expression, lighting, and pose.", "\n", "\n", "# Print network details.", "\n", "", "Gs", ".", "print_layers", "(", ")", "\n", "\n", "# Pick latent vector.", "\n", "latents", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "latents_else", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents_else'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'noise'", ",", "shape", "=", "[", "1", ",", "32", "]", ")", "\n", "ratio", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'ratio'", ",", "shape", "=", "[", "]", ")", "\n", "\n", "INPUTcoeff", "=", "z_to_lambda_mapping", "(", "latents", ")", "\n", "INPUTcoeff_else", "=", "z_to_lambda_mapping", "(", "latents_else", ")", "\n", "\n", "INPUTcoeff_w_noise", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "INPUTcoeff_w_noise_else", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff_else", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Generate images", "\n", "fake_images_out", "=", "truncate_generation", "(", "Gs", ",", "INPUTcoeff_w_noise", ",", "INPUTcoeff_w_noise_else", ",", "ratio", ",", "dlatent_average_id", "=", "average_w_id", ")", "\n", "\n", "", "restore_weights_and_initialize", "(", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "10", ")", "\n", "num_ids", "=", "args", ".", "num_id", "\n", "samples_per_id", "=", "[", "args", ".", "samples_perid", "]", "*", "num_ids", "\n", "\n", "id_coeffs", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "num_ids", ",", "128", "]", ")", "\n", "\n", "identities", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "num_ids", ")", ")", ":", "\n", "        ", "class_name", "=", "'{:05}'", ".", "format", "(", "i", "+", "1", ")", "\n", "id_coeff", "=", "id_coeffs", "[", "i", "]", ".", "reshape", "(", "(", "1", ",", "128", ")", ")", "\n", "\n", "remains_idx", "=", "list", "(", "range", "(", "num_ids", ")", ")", "\n", "remains_idx", ".", "remove", "(", "i", ")", "\n", "chosen_idx", "=", "random", ".", "sample", "(", "remains_idx", ",", "k", "=", "samples_per_id", "[", "i", "]", ")", "\n", "\n", "exp_light_rot", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "+", "16", "+", "3", "]", ")", "\n", "noi", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "]", ")", "\n", "\n", "for", "j", ",", "idx", "in", "enumerate", "(", "chosen_idx", ")", ":", "\n", "            ", "else_id", "=", "id_coeffs", "[", "idx", "]", ".", "reshape", "(", "(", "1", ",", "128", ")", ")", "\n", "ratio_", "=", "random", ".", "choice", "(", "np", ".", "linspace", "(", "0", ",", "1.05", ",", "21", ",", "endpoint", "=", "False", ")", ")", "\n", "ratio_", "=", "np", ".", "round", "(", "ratio_", ",", "3", ")", "\n", "img_name", "=", "'{:03}_{:05}x{:.3f}_({:05})x{:.3f}.jpg'", ".", "format", "(", "j", "+", "1", ",", "i", "+", "1", ",", "ratio_", ",", "idx", "+", "1", ",", "1", "-", "ratio_", ")", "\n", "\n", "exp_light_rot_changed", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "+", "16", "+", "3", "]", ")", "\n", "if", "args", ".", "factor", "==", "0", ":", "\n", "                ", "lats", "=", "np", ".", "concatenate", "(", "[", "id_coeff", ",", "exp_light_rot", "]", ",", "axis", "=", "1", ")", "\n", "lats_else", "=", "np", ".", "concatenate", "(", "[", "else_id", ",", "exp_light_rot", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "factor", "==", "1", ":", "# change expression only", "\n", "                ", "lats", "=", "np", ".", "concatenate", "(", "[", "id_coeff", ",", "exp_light_rot_changed", "[", ":", ",", ":", "32", "]", ",", "exp_light_rot", "[", ":", ",", "32", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "lats_else", "=", "np", ".", "concatenate", "(", "[", "else_id", ",", "exp_light_rot_changed", "[", ":", ",", ":", "32", "]", ",", "exp_light_rot", "[", ":", ",", "32", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "factor", "==", "2", ":", "# change light only", "\n", "                ", "lats", "=", "np", ".", "concatenate", "(", "[", "id_coeff", ",", "exp_light_rot", "[", ":", ",", ":", "32", "]", ",", "exp_light_rot_changed", "[", ":", ",", "32", ":", "32", "+", "16", "]", ",", "exp_light_rot", "[", ":", ",", "32", "+", "16", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "lats_else", "=", "np", ".", "concatenate", "(", "[", "else_id", ",", "exp_light_rot", "[", ":", ",", ":", "32", "]", ",", "exp_light_rot_changed", "[", ":", ",", "32", ":", "32", "+", "16", "]", ",", "exp_light_rot", "[", ":", ",", "32", "+", "16", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "factor", "==", "3", ":", "# change pose only", "\n", "                ", "lats", "=", "np", ".", "concatenate", "(", "[", "id_coeff", ",", "exp_light_rot", "[", ":", ",", ":", "32", "+", "16", "]", ",", "exp_light_rot_changed", "[", ":", ",", "32", "+", "16", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "lats_else", "=", "np", ".", "concatenate", "(", "[", "else_id", ",", "exp_light_rot", "[", ":", ",", ":", "32", "+", "16", "]", ",", "exp_light_rot_changed", "[", ":", ",", "32", "+", "16", ":", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "fake", "=", "tflib", ".", "run", "(", "fake_images_out", ",", "{", "latents", ":", "lats", ",", "latents_else", ":", "lats_else", ",", "noise", ":", "noi", ",", "ratio", ":", "ratio_", "}", ")", "\n", "fake_img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "fake", "[", "0", "]", ".", "astype", "(", "np", ".", "uint8", ")", ",", "'RGB'", ")", "\n", "fake_img_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "class_name", ",", "img_name", ")", "\n", "check_dir", "(", "fake_img_path", ")", "\n", "fake_img", ".", "save", "(", "fake_img_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder": [[18, 29], ["tensorflow.variable_scope", "tensorflow.variable_scope", "range", "tensorflow.layers.dense", "tensorflow.stop_gradient", "tensorflow.layers.dense", "str"], "function", ["None"], ["def", "CoeffDecoder", "(", "z", ",", "ch_depth", "=", "3", ",", "ch_dim", "=", "512", ",", "coeff_length", "=", "128", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'stage1'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'decoder'", ")", ":", "\n", "            ", "y", "=", "z", "\n", "for", "i", "in", "range", "(", "ch_depth", ")", ":", "\n", "                ", "y", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "ch_dim", ",", "tf", ".", "nn", ".", "relu", ",", "name", "=", "'fc'", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "x_hat", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "coeff_length", ",", "name", "=", "'x_hat'", ")", "\n", "x_hat", "=", "tf", ".", "stop_gradient", "(", "x_hat", ")", "\n", "\n", "", "", "return", "x_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.restore_weights_and_initialize": [[31, 54], ["tensorflow.trainable_variables", "tensorflow.global_variables", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tf.train.Saver.restore", "tf.train.Saver.restore", "tf.train.Saver.restore", "tf.train.Saver.restore", "tensorflow.get_default_session", "tensorflow.get_default_session", "tensorflow.get_default_session", "tensorflow.get_default_session"], "function", ["None"], ["", "def", "restore_weights_and_initialize", "(", ")", ":", "\n", "    ", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "g_list", "=", "tf", ".", "global_variables", "(", ")", "\n", "\n", "# add batch normalization params into trainable variables ", "\n", "bn_moving_vars", "=", "[", "g", "for", "g", "in", "g_list", "if", "'moving_mean'", "in", "g", ".", "name", "]", "\n", "bn_moving_vars", "+=", "[", "g", "for", "g", "in", "g_list", "if", "'moving_variance'", "in", "g", ".", "name", "]", "\n", "var_list", "+=", "bn_moving_vars", "\n", "\n", "var_id_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'id'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_exp_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'exp'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_gamma_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'gamma'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "var_rot_list", "=", "[", "v", "for", "v", "in", "var_list", "if", "'rot'", "in", "v", ".", "name", "and", "'stage1'", "in", "v", ".", "name", "]", "\n", "\n", "saver_id", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_id_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_exp", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_exp_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_gamma", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_gamma_list", ",", "max_to_keep", "=", "100", ")", "\n", "saver_rot", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "var_rot_list", ",", "max_to_keep", "=", "100", ")", "\n", "\n", "saver_id", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/id/stage1_epoch_395.ckpt'", ")", "\n", "saver_exp", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/exp/stage1_epoch_395.ckpt'", ")", "\n", "saver_gamma", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/gamma/stage1_epoch_395.ckpt'", ")", "\n", "saver_rot", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "CODE_ROOT", "+", "'vae/weights/rot/stage1_epoch_395.ckpt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping": [[55, 69], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.get_variable_scope", "tensorflow.variable_scope", "syn_images.CoeffDecoder", "tensorflow.variable_scope", "syn_images.CoeffDecoder", "tensorflow.variable_scope", "syn_images.CoeffDecoder", "tensorflow.variable_scope", "syn_images.CoeffDecoder"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.CoeffDecoder"], ["", "def", "z_to_lambda_mapping", "(", "latents", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'id'", ")", ":", "\n", "            ", "IDcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", ":", "128", "]", ",", "coeff_length", "=", "160", ",", "ch_dim", "=", "512", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'exp'", ")", ":", "\n", "            ", "EXPcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", ":", "128", "+", "32", "]", ",", "coeff_length", "=", "64", ",", "ch_dim", "=", "256", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'gamma'", ")", ":", "\n", "            ", "GAMMAcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", "+", "32", ":", "128", "+", "32", "+", "16", "]", ",", "coeff_length", "=", "27", ",", "ch_dim", "=", "128", ",", "ch_depth", "=", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'rot'", ")", ":", "\n", "            ", "Rotcoeff", "=", "CoeffDecoder", "(", "z", "=", "latents", "[", ":", ",", "128", "+", "32", "+", "16", ":", "128", "+", "32", "+", "16", "+", "3", "]", ",", "coeff_length", "=", "3", ",", "ch_dim", "=", "32", ",", "ch_depth", "=", "3", ")", "\n", "\n", "", "INPUTcoeff", "=", "tf", ".", "concat", "(", "[", "IDcoeff", ",", "EXPcoeff", ",", "Rotcoeff", ",", "GAMMAcoeff", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "INPUTcoeff", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.truncate_generation": [[71, 96], ["numpy.reshape().astype", "tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "Gs.components.mapping.get_output_for", "Gs.components.mapping.get_output_for", "tensorflow.concat", "Gs.components.synthesis.get_output_for", "tensorflow.clip_by_value", "tensorflow.transpose", "dnnlib.util.open_url", "dnnlib.util.open_url", "numpy.loadtxt", "numpy.reshape", "tensorflow.zeros"], "function", ["None"], ["", "", "def", "truncate_generation", "(", "Gs", ",", "inputcoeff", ",", "inputcoeff_else", ",", "ratio", ",", "rate", "=", "0.7", ",", "dlatent_average_id", "=", "None", ")", ":", "\n", "\n", "    ", "if", "dlatent_average_id", "is", "None", ":", "\n", "        ", "url_pretrained_model_ffhq_average_w_id", "=", "'https://drive.google.com/uc?id=17L6-ENX3NbMsS3MSCshychZETLPtJnbS'", "\n", "with", "dnnlib", ".", "util", ".", "open_url", "(", "url_pretrained_model_ffhq_average_w_id", ",", "cache_dir", "=", "config", ".", "cache_dir", ")", "as", "f", ":", "\n", "            ", "dlatent_average_id", "=", "np", ".", "loadtxt", "(", "f", ")", "\n", "", "", "dlatent_average_id", "=", "np", ".", "reshape", "(", "dlatent_average_id", ",", "[", "1", ",", "14", ",", "512", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "dlatent_average_id", "=", "tf", ".", "constant", "(", "dlatent_average_id", ")", "\n", "\n", "id_coeff", "=", "ratio", "*", "inputcoeff", "[", ":", ",", ":", "160", "]", "+", "(", "1", "-", "ratio", ")", "*", "inputcoeff_else", "[", ":", ",", ":", "160", "]", "\n", "inputcoeff", "=", "tf", ".", "concat", "(", "[", "id_coeff", ",", "\n", "inputcoeff", "[", ":", ",", "160", ":", "160", "+", "64", "+", "3", "+", "27", "+", "32", "]", "]", ",", "axis", "=", "1", ")", "\n", "\n", "inputcoeff_id", "=", "tf", ".", "concat", "(", "[", "inputcoeff", "[", ":", ",", ":", "160", "]", ",", "tf", ".", "zeros", "(", "[", "1", ",", "126", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "dlatent_out", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "inputcoeff", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "# original w space output", "\n", "dlatent_out_id", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "inputcoeff_id", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "\n", "\n", "dlatent_out_trun", "=", "dlatent_out", "+", "(", "dlatent_average_id", "-", "dlatent_out_id", ")", "*", "(", "1", "-", "rate", ")", "\n", "dlatent_out_final", "=", "tf", ".", "concat", "(", "[", "dlatent_out_trun", "[", ":", ",", ":", "8", ",", ":", "]", ",", "dlatent_out", "[", ":", ",", "8", ":", ",", ":", "]", "]", ",", "axis", "=", "1", ")", "# w space latent vector with truncation trick", "\n", "\n", "fake_images_out", "=", "Gs", ".", "components", ".", "synthesis", ".", "get_output_for", "(", "dlatent_out_final", ",", "randomize_noise", "=", "False", ")", "\n", "fake_images_out", "=", "tf", ".", "clip_by_value", "(", "(", "fake_images_out", "+", "1", ")", "*", "127.5", ",", "0", ",", "255", ")", "\n", "fake_images_out", "=", "tf", ".", "transpose", "(", "fake_images_out", ",", "perm", "=", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "fake_images_out", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.get_model_and_average_w_id": [[98, 125], ["training.misc.load_pkl", "model_name.replace", "os.path.isfile", "print", "tensorflow.placeholder", "tensorflow.placeholder", "syn_images.z_to_lambda_mapping", "tensorflow.concat", "Gs.components.mapping.get_output_for", "syn_images.restore_weights_and_initialize", "numpy.random.seed", "range", "numpy.concatenate", "numpy.mean", "numpy.savetxt", "numpy.loadtxt", "numpy.random.normal", "numpy.random.normal", "dnnlib.run", "np.loadtxt.append", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.restore_weights_and_initialize"], ["", "def", "get_model_and_average_w_id", "(", "model_name", ")", ":", "\n", "    ", "G", ",", "D", ",", "Gs", "=", "misc", ".", "load_pkl", "(", "model_name", ")", "\n", "average_w_name", "=", "model_name", ".", "replace", "(", "'.pkl'", ",", "'-average_w_id.txt'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "average_w_name", ")", ":", "\n", "        ", "print", "(", "'Calculating average w id...\\n'", ")", "\n", "latents", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'noise'", ",", "shape", "=", "[", "1", ",", "32", "]", ")", "\n", "INPUTcoeff", "=", "z_to_lambda_mapping", "(", "latents", ")", "\n", "INPUTcoeff_id", "=", "INPUTcoeff", "[", ":", ",", ":", "160", "]", "\n", "INPUTcoeff_w_noise", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff_id", ",", "tf", ".", "zeros", "(", "[", "1", ",", "64", "+", "27", "+", "3", "]", ")", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "dlatent_out", "=", "Gs", ".", "components", ".", "mapping", ".", "get_output_for", "(", "INPUTcoeff_w_noise", ",", "None", ",", "is_training", "=", "False", ",", "is_validation", "=", "True", ")", "\n", "restore_weights_and_initialize", "(", ")", "\n", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "average_w_id", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "50000", ")", ":", "\n", "            ", "lats", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise_", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "]", ")", "\n", "w_out", "=", "tflib", ".", "run", "(", "dlatent_out", ",", "{", "latents", ":", "lats", ",", "noise", ":", "noise_", "}", ")", "\n", "average_w_id", ".", "append", "(", "w_out", ")", "\n", "\n", "", "average_w_id", "=", "np", ".", "concatenate", "(", "average_w_id", ",", "axis", "=", "0", ")", "\n", "average_w_id", "=", "np", ".", "mean", "(", "average_w_id", ",", "axis", "=", "0", ")", "\n", "np", ".", "savetxt", "(", "average_w_name", ",", "average_w_id", ")", "\n", "", "else", ":", "\n", "        ", "average_w_id", "=", "np", ".", "loadtxt", "(", "average_w_name", ")", "\n", "\n", "", "return", "Gs", ",", "average_w_id", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args": [[126, 139], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "desc", "=", "\"Disentangled face image generation\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "desc", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_id'", ",", "type", "=", "int", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_perid'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'dataset'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "CODE_ROOT", "+", "'cache/network-snapshot-020126.pkl'", ",", "help", "=", "'pkl file name of the generator. If None, use the default pre-trained model.'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.check_dir": [[140, 144], ["os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "check_dir", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.load_Gs": [[145, 149], ["dnnlib.util.open_url", "dnnlib.util.open_url", "pickle.load"], "function", ["None"], ["", "", "def", "load_Gs", "(", "url", ")", ":", "\n", "    ", "with", "dnnlib", ".", "util", ".", "open_url", "(", "url", ",", "cache_dir", "=", "config", ".", "cache_dir", ")", "as", "f", ":", "\n", "        ", "_G", ",", "_D", ",", "Gs", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "return", "Gs", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.duplicate_check": [[150, 156], ["int", "numpy.random.normal", "int"], "function", ["None"], ["", "def", "duplicate_check", "(", "vec", ",", "lists", ")", ":", "\n", "    ", "indicator", "=", "[", "int", "(", "(", "vec", "==", "v", ")", ".", "all", "(", ")", ")", "for", "v", "in", "lists", "]", "\n", "while", "1", "in", "indicator", ":", "\n", "        ", "vec", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "vec", ".", "shape", ")", "\n", "indicator", "=", "[", "int", "(", "(", "vec", "==", "v", ")", ".", "all", "(", ")", ")", "for", "v", "in", "lists", "]", "\n", "", "return", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.main": [[157, 227], ["syn_images.parse_args", "dnnlib.init_tf", "syn_images.restore_weights_and_initialize", "numpy.random.seed", "numpy.random.normal", "tqdm.tqdm", "tensorflow.device", "load_Gs.print_layers", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "syn_images.z_to_lambda_mapping", "syn_images.z_to_lambda_mapping", "tensorflow.concat", "tensorflow.concat", "syn_images.truncate_generation", "range", "id_coeffs[].reshape", "list", "list.remove", "random.sample", "enumerate", "syn_images.load_Gs", "syn_images.get_model_and_average_w_id", "range", "id_coeffs[].reshape", "random.choice", "numpy.round", "numpy.random.normal", "numpy.hstack", "numpy.hstack", "numpy.random.normal", "dnnlib.run", "PIL.Image.fromarray", "os.path.join", "syn_images.check_dir", "PIL.Image.fromarray.save", "numpy.linspace", "fake[].astype"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.parse_args", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.restore_weights_and_initialize", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.z_to_lambda_mapping", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.truncate_generation", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.load_Gs", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.get_model_and_average_w_id", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.data.syn_images.check_dir", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "\"0\"", "\n", "args", "=", "parse_args", "(", ")", "\n", "\n", "tflib", ".", "init_tf", "(", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/gpu:0'", ")", ":", "\n", "\n", "# Use default pre-trained model", "\n", "        ", "if", "args", ".", "model", "is", "None", ":", "\n", "            ", "url_pretrained_model_ffhq", "=", "'https://drive.google.com/uc?id=1nT_cf610q5mxD_jACvV43w4SYBxsPUBq'", "\n", "Gs", "=", "load_Gs", "(", "url_pretrained_model_ffhq", ")", "\n", "average_w_id", "=", "None", "\n", "\n", "", "else", ":", "\n", "            ", "Gs", ",", "average_w_id", "=", "get_model_and_average_w_id", "(", "args", ".", "model", ")", "\n", "# Gs = Long-term average of the generator. Yields higher-quality results than the instantaneous snapshot.", "\n", "# average_w_id = average w space latent vector with zero expression, lighting, and pose.", "\n", "\n", "# Print network details.", "\n", "", "Gs", ".", "print_layers", "(", ")", "\n", "\n", "# Pick latent vector.", "\n", "latents", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "latents_else", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'latents_else'", ",", "shape", "=", "[", "1", ",", "128", "+", "32", "+", "16", "+", "3", "]", ")", "\n", "noise", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'noise'", ",", "shape", "=", "[", "1", ",", "32", "]", ")", "\n", "ratio", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'ratio'", ",", "shape", "=", "[", "]", ")", "\n", "\n", "INPUTcoeff", "=", "z_to_lambda_mapping", "(", "latents", ")", "\n", "INPUTcoeff_else", "=", "z_to_lambda_mapping", "(", "latents_else", ")", "\n", "\n", "INPUTcoeff_w_noise", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "INPUTcoeff_w_noise_else", "=", "tf", ".", "concat", "(", "[", "INPUTcoeff_else", ",", "noise", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Generate images", "\n", "fake_images_out", "=", "truncate_generation", "(", "Gs", ",", "INPUTcoeff_w_noise", ",", "INPUTcoeff_w_noise_else", ",", "ratio", ",", "dlatent_average_id", "=", "average_w_id", ")", "\n", "\n", "", "restore_weights_and_initialize", "(", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "10", ")", "\n", "num_ids", "=", "args", ".", "num_id", "\n", "samples_per_id", "=", "[", "args", ".", "samples_perid", "]", "*", "num_ids", "\n", "\n", "id_coeffs", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "num_ids", ",", "128", "]", ")", "\n", "\n", "identities", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "num_ids", ")", ")", ":", "\n", "        ", "class_name", "=", "'{:05}'", ".", "format", "(", "i", "+", "1", ")", "\n", "id_coeff", "=", "id_coeffs", "[", "i", "]", ".", "reshape", "(", "(", "1", ",", "128", ")", ")", "\n", "\n", "remains_idx", "=", "list", "(", "range", "(", "num_ids", ")", ")", "\n", "remains_idx", ".", "remove", "(", "i", ")", "\n", "chosen_idx", "=", "random", ".", "sample", "(", "remains_idx", ",", "k", "=", "samples_per_id", "[", "i", "]", ")", "\n", "\n", "for", "j", ",", "idx", "in", "enumerate", "(", "chosen_idx", ")", ":", "\n", "            ", "else_id", "=", "id_coeffs", "[", "idx", "]", ".", "reshape", "(", "(", "1", ",", "128", ")", ")", "\n", "ratio_", "=", "random", ".", "choice", "(", "np", ".", "linspace", "(", "0", ",", "1.05", ",", "21", ",", "endpoint", "=", "False", ")", ")", "\n", "ratio_", "=", "np", ".", "round", "(", "ratio_", ",", "3", ")", "\n", "img_name", "=", "'{:03}_{:05}x{:.3f}_({:05})x{:.3f}.jpg'", ".", "format", "(", "j", "+", "1", ",", "i", "+", "1", ",", "ratio_", ",", "idx", "+", "1", ",", "1", "-", "ratio_", ")", "\n", "\n", "exp_light_rot", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "+", "16", "+", "3", "]", ")", "\n", "lats", "=", "np", ".", "hstack", "(", "(", "id_coeff", ",", "exp_light_rot", ")", ")", "\n", "lats_else", "=", "np", ".", "hstack", "(", "(", "else_id", ",", "exp_light_rot", ")", ")", "\n", "noi", "=", "np", ".", "random", ".", "normal", "(", "size", "=", "[", "1", ",", "32", "]", ")", "\n", "\n", "fake", "=", "tflib", ".", "run", "(", "fake_images_out", ",", "{", "latents", ":", "lats", ",", "latents_else", ":", "lats_else", ",", "noise", ":", "noi", ",", "ratio", ":", "ratio_", "}", ")", "\n", "fake_img", "=", "PIL", ".", "Image", ".", "fromarray", "(", "fake", "[", "0", "]", ".", "astype", "(", "np", ".", "uint8", ")", ",", "'RGB'", ")", "\n", "fake_img_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save_path", ",", "class_name", ",", "img_name", ")", "\n", "check_dir", "(", "fake_img_path", ")", "\n", "fake_img", ".", "save", "(", "fake_img_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.first_stage.run_first_stage": [[9, 45], ["image.resize", "numpy.asarray", "torch.autograd.Variable().cuda", "net", "output[].data.cpu().numpy", "first_stage._generate_bboxes", "box_utils.nms", "math.ceil", "math.ceil", "output[].data.cpu().numpy", "len", "torch.autograd.Variable", "output[].data.cpu", "torch.FloatTensor", "output[].data.cpu", "box_utils._preprocess"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.first_stage._generate_bboxes", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.nms", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils._preprocess"], ["def", "run_first_stage", "(", "image", ",", "net", ",", "scale", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Run P-Net, generate bounding boxes, and do NMS.\n\n    Arguments:\n        image: an instance of PIL.Image.\n        net: an instance of pytorch's nn.Module, P-Net.\n        scale: a float number,\n            scale width and height of the image by this number.\n        threshold: a float number,\n            threshold on the probability of a face when generating\n            bounding boxes from predictions of the net.\n\n    Returns:\n        a float numpy array of shape [n_boxes, 9],\n            bounding boxes with scores and offsets (4 + 1 + 4).\n    \"\"\"", "\n", "\n", "# scale the image and convert it to a float array", "\n", "width", ",", "height", "=", "image", ".", "size", "\n", "sw", ",", "sh", "=", "math", ".", "ceil", "(", "width", "*", "scale", ")", ",", "math", ".", "ceil", "(", "height", "*", "scale", ")", "\n", "img", "=", "image", ".", "resize", "(", "(", "sw", ",", "sh", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img", "=", "np", ".", "asarray", "(", "img", ",", "'float32'", ")", "\n", "\n", "img", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "_preprocess", "(", "img", ")", ")", ",", "volatile", "=", "True", ")", ".", "cuda", "(", ")", "\n", "output", "=", "net", "(", "img", ")", "\n", "probs", "=", "output", "[", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", ",", "1", ",", ":", ",", ":", "]", "\n", "offsets", "=", "output", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# probs: probability of a face at each sliding window", "\n", "# offsets: transformations to true bounding boxes", "\n", "\n", "boxes", "=", "_generate_bboxes", "(", "probs", ",", "offsets", ",", "scale", ",", "threshold", ")", "\n", "if", "len", "(", "boxes", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "keep", "=", "nms", "(", "boxes", "[", ":", ",", "0", ":", "5", "]", ",", "overlap_threshold", "=", "0.5", ")", "\n", "return", "boxes", "[", "keep", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.first_stage._generate_bboxes": [[47, 98], ["numpy.where", "numpy.array", "numpy.vstack", "numpy.array", "range", "numpy.round", "numpy.round", "numpy.round", "numpy.round"], "function", ["None"], ["", "def", "_generate_bboxes", "(", "probs", ",", "offsets", ",", "scale", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Generate bounding boxes at places\n    where there is probably a face.\n\n    Arguments:\n        probs: a float numpy array of shape [n, m].\n        offsets: a float numpy array of shape [1, 4, n, m].\n        scale: a float number,\n            width and height of the image were scaled by this number.\n        threshold: a float number.\n\n    Returns:\n        a float numpy array of shape [n_boxes, 9]\n    \"\"\"", "\n", "\n", "# applying P-Net is equivalent, in some sense, to", "\n", "# moving 12x12 window with stride 2", "\n", "stride", "=", "2", "\n", "cell_size", "=", "12", "\n", "\n", "# indices of boxes where there is probably a face", "\n", "inds", "=", "np", ".", "where", "(", "probs", ">", "threshold", ")", "\n", "\n", "if", "inds", "[", "0", "]", ".", "size", "==", "0", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "# transformations of bounding boxes", "\n", "", "tx1", ",", "ty1", ",", "tx2", ",", "ty2", "=", "[", "offsets", "[", "0", ",", "i", ",", "inds", "[", "0", "]", ",", "inds", "[", "1", "]", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "# they are defined as:", "\n", "# w = x2 - x1 + 1", "\n", "# h = y2 - y1 + 1", "\n", "# x1_true = x1 + tx1*w", "\n", "# x2_true = x2 + tx2*w", "\n", "# y1_true = y1 + ty1*h", "\n", "# y2_true = y2 + ty2*h", "\n", "\n", "offsets", "=", "np", ".", "array", "(", "[", "tx1", ",", "ty1", ",", "tx2", ",", "ty2", "]", ")", "\n", "score", "=", "probs", "[", "inds", "[", "0", "]", ",", "inds", "[", "1", "]", "]", "\n", "\n", "# P-Net is applied to scaled images", "\n", "# so we need to rescale bounding boxes back", "\n", "bounding_boxes", "=", "np", ".", "vstack", "(", "[", "\n", "np", ".", "round", "(", "(", "stride", "*", "inds", "[", "1", "]", "+", "1.0", ")", "/", "scale", ")", ",", "\n", "np", ".", "round", "(", "(", "stride", "*", "inds", "[", "0", "]", "+", "1.0", ")", "/", "scale", ")", ",", "\n", "np", ".", "round", "(", "(", "stride", "*", "inds", "[", "1", "]", "+", "1.0", "+", "cell_size", ")", "/", "scale", ")", ",", "\n", "np", ".", "round", "(", "(", "stride", "*", "inds", "[", "0", "]", "+", "1.0", "+", "cell_size", ")", "/", "scale", ")", ",", "\n", "score", ",", "offsets", "\n", "]", ")", "\n", "# why one is added?", "\n", "\n", "return", "bounding_boxes", ".", "T", "\n", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.Flatten.__init__": [[11, 13], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Flatten", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.Flatten.forward": [[14, 26], ["x.transpose().contiguous.transpose().contiguous.transpose().contiguous", "x.transpose().contiguous.transpose().contiguous.view", "x.transpose().contiguous.transpose().contiguous.size", "x.transpose().contiguous.transpose().contiguous.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x: a float tensor with shape [batch_size, c, h, w].\n        Returns:\n            a float tensor with shape [batch_size, c*h*w].\n        \"\"\"", "\n", "\n", "# without this pretrained model isn't working", "\n", "x", "=", "x", ".", "transpose", "(", "3", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.PNet.__init__": [[30, 59], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "get_nets.PNet.named_parameters", "collections.OrderedDict", "numpy.load", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "PNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# suppose we have input with size HxW, then", "\n", "# after first layer: H - 2,", "\n", "# after pool: ceil((H - 2)/2),", "\n", "# after second conv: ceil((H - 2)/2) - 2,", "\n", "# after last conv: ceil((H - 2)/2) - 4,", "\n", "# and the same for W", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "3", ",", "10", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu1'", ",", "nn", ".", "PReLU", "(", "10", ")", ")", ",", "\n", "(", "'pool1'", ",", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "10", ",", "16", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu2'", ",", "nn", ".", "PReLU", "(", "16", ")", ")", ",", "\n", "\n", "(", "'conv3'", ",", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu3'", ",", "nn", ".", "PReLU", "(", "32", ")", ")", "\n", "]", ")", ")", "\n", "\n", "self", ".", "conv4_1", "=", "nn", ".", "Conv2d", "(", "32", ",", "2", ",", "1", ",", "1", ")", "\n", "self", ".", "conv4_2", "=", "nn", ".", "Conv2d", "(", "32", ",", "4", ",", "1", ",", "1", ")", "\n", "\n", "weights", "=", "np", ".", "load", "(", "CODE_ROOT", "+", "\"pnet.npy\"", ",", "allow_pickle", "=", "True", ")", "[", "(", ")", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", "=", "torch", ".", "FloatTensor", "(", "weights", "[", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.PNet.forward": [[60, 73], ["get_nets.PNet.features", "get_nets.PNet.conv4_1", "get_nets.PNet.conv4_2", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x: a float tensor with shape [batch_size, 3, h, w].\n        Returns:\n            b: a float tensor with shape [batch_size, 4, h', w'].\n            a: a float tensor with shape [batch_size, 2, h', w'].\n        \"\"\"", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "a", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "b", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "a", "=", "F", ".", "softmax", "(", "a", ")", "\n", "return", "b", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.RNet.__init__": [[77, 104], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "get_nets.RNet.named_parameters", "collections.OrderedDict", "numpy.load", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "get_nets.Flatten", "torch.Linear", "torch.Linear", "torch.Linear", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "RNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "3", ",", "28", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu1'", ",", "nn", ".", "PReLU", "(", "28", ")", ")", ",", "\n", "(", "'pool1'", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "28", ",", "48", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu2'", ",", "nn", ".", "PReLU", "(", "48", ")", ")", ",", "\n", "(", "'pool2'", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv3'", ",", "nn", ".", "Conv2d", "(", "48", ",", "64", ",", "2", ",", "1", ")", ")", ",", "\n", "(", "'prelu3'", ",", "nn", ".", "PReLU", "(", "64", ")", ")", ",", "\n", "\n", "(", "'flatten'", ",", "Flatten", "(", ")", ")", ",", "\n", "(", "'conv4'", ",", "nn", ".", "Linear", "(", "576", ",", "128", ")", ")", ",", "\n", "(", "'prelu4'", ",", "nn", ".", "PReLU", "(", "128", ")", ")", "\n", "]", ")", ")", "\n", "\n", "self", ".", "conv5_1", "=", "nn", ".", "Linear", "(", "128", ",", "2", ")", "\n", "self", ".", "conv5_2", "=", "nn", ".", "Linear", "(", "128", ",", "4", ")", "\n", "\n", "weights", "=", "np", ".", "load", "(", "CODE_ROOT", "+", "\"rnet.npy\"", ",", "allow_pickle", "=", "True", ")", "[", "(", ")", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", "=", "torch", ".", "FloatTensor", "(", "weights", "[", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.RNet.forward": [[105, 118], ["get_nets.RNet.features", "get_nets.RNet.conv5_1", "get_nets.RNet.conv5_2", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x: a float tensor with shape [batch_size, 3, h, w].\n        Returns:\n            b: a float tensor with shape [batch_size, 4].\n            a: a float tensor with shape [batch_size, 2].\n        \"\"\"", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "a", "=", "self", ".", "conv5_1", "(", "x", ")", "\n", "b", "=", "self", ".", "conv5_2", "(", "x", ")", "\n", "a", "=", "F", ".", "softmax", "(", "a", ")", "\n", "return", "b", ",", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.ONet.__init__": [[122, 155], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "get_nets.ONet.named_parameters", "collections.OrderedDict", "numpy.load", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "get_nets.Flatten", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "ONet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "'conv1'", ",", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu1'", ",", "nn", ".", "PReLU", "(", "32", ")", ")", ",", "\n", "(", "'pool1'", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv2'", ",", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu2'", ",", "nn", ".", "PReLU", "(", "64", ")", ")", ",", "\n", "(", "'pool2'", ",", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv3'", ",", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "1", ")", ")", ",", "\n", "(", "'prelu3'", ",", "nn", ".", "PReLU", "(", "64", ")", ")", ",", "\n", "(", "'pool3'", ",", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ",", "ceil_mode", "=", "True", ")", ")", ",", "\n", "\n", "(", "'conv4'", ",", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "2", ",", "1", ")", ")", ",", "\n", "(", "'prelu4'", ",", "nn", ".", "PReLU", "(", "128", ")", ")", ",", "\n", "\n", "(", "'flatten'", ",", "Flatten", "(", ")", ")", ",", "\n", "(", "'conv5'", ",", "nn", ".", "Linear", "(", "1152", ",", "256", ")", ")", ",", "\n", "(", "'drop5'", ",", "nn", ".", "Dropout", "(", "0.25", ")", ")", ",", "\n", "(", "'prelu5'", ",", "nn", ".", "PReLU", "(", "256", ")", ")", ",", "\n", "]", ")", ")", "\n", "\n", "self", ".", "conv6_1", "=", "nn", ".", "Linear", "(", "256", ",", "2", ")", "\n", "self", ".", "conv6_2", "=", "nn", ".", "Linear", "(", "256", ",", "4", ")", "\n", "self", ".", "conv6_3", "=", "nn", ".", "Linear", "(", "256", ",", "10", ")", "\n", "\n", "weights", "=", "np", ".", "load", "(", "CODE_ROOT", "+", "\"onet.npy\"", ",", "allow_pickle", "=", "True", ")", "[", "(", ")", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", "=", "torch", ".", "FloatTensor", "(", "weights", "[", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.get_nets.ONet.forward": [[156, 171], ["get_nets.ONet.features", "get_nets.ONet.conv6_1", "get_nets.ONet.conv6_2", "get_nets.ONet.conv6_3", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n            x: a float tensor with shape [batch_size, 3, h, w].\n        Returns:\n            c: a float tensor with shape [batch_size, 10].\n            b: a float tensor with shape [batch_size, 4].\n            a: a float tensor with shape [batch_size, 2].\n        \"\"\"", "\n", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "a", "=", "self", ".", "conv6_1", "(", "x", ")", "\n", "b", "=", "self", ".", "conv6_2", "(", "x", ")", "\n", "c", "=", "self", ".", "conv6_3", "(", "x", ")", "\n", "a", "=", "F", ".", "softmax", "(", "a", ")", "\n", "return", "c", ",", "b", ",", "a", "\n", "", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.mp_print": [[27, 30], ["print", "torch.get_rank"], "function", ["None"], ["def", "mp_print", "(", "msg", ",", "i", ")", ":", "\n", "    ", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "i", "%", "400", "==", "0", ":", "\n", "        ", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.make_dirs": [[31, 35], ["os.listdir", "os.path.isdir", "os.makedirs", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "def", "make_dirs", "(", "source_root", ",", "dest_root", ")", ":", "\n", "    ", "for", "subfolder", "in", "os", ".", "listdir", "(", "source_root", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "dest_root", ",", "subfolder", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "dest_root", ",", "subfolder", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.main": [[36, 49], ["print", "face_align_crop.make_dirs", "print", "torch.multiprocessing.set_start_method", "torch.multiprocessing.set_start_method", "torch.multiprocessing.set_start_method", "torch.multiprocessing.set_sharing_strategy", "torch.multiprocessing.set_sharing_strategy", "torch.multiprocessing.set_sharing_strategy", "torch.multiprocessing.spawn", "torch.multiprocessing.spawn", "torch.multiprocessing.spawn", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.make_dirs"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "global", "args", "\n", "print", "(", "args", ")", "\n", "# to use mp, dirs need to be created first", "\n", "make_dirs", "(", "args", ".", "source_root", ",", "args", ".", "dest_root", ")", "\n", "print", "(", "'Done making new dirs'", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "'0'", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "torch", ".", "multiprocessing", ".", "set_start_method", "(", "'spawn'", ")", "\n", "torch", ".", "multiprocessing", ".", "set_sharing_strategy", "(", "'file_system'", ")", "\n", "nprocs", "=", "args", ".", "procs", "*", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "torch", ".", "multiprocessing", ".", "spawn", "(", "test", ",", "args", "=", "(", "args", ",", "nprocs", ")", ",", "nprocs", "=", "nprocs", ",", "join", "=", "True", ",", "daemon", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.test": [[50, 99], ["torch.init_process_group", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "get_nets.PNet().cuda", "get_nets.RNet().cuda", "get_nets.ONet().cuda", "dataset.Dataset_Folder", "range", "align_trans.get_reference_facial_points", "os.path.isdir", "os.mkdir", "len", "torch.get_world_size", "str", "face_align_crop.mp_print", "align_trans.warp_and_crop_face", "PIL.Image.fromarray", "str.split", "os.path.join", "Image.fromarray.save", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "get_nets.PNet", "get_nets.RNet", "get_nets.ONet", "torch.get_rank", "PIL.Image.open", "detector.detect_faces", "len", "print", "numpy.array", "print", "torch.get_rank", "len", "print", "range", "torch.get_world_size", "range", "torch.get_rank", "torch.get_rank", "torch.get_world_size", "torch.get_rank", "torch.get_rank"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.get_reference_facial_points", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.face_align_crop.mp_print", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.warp_and_crop_face", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.models.resnets.LResNet.save", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.detector.detect_faces"], ["", "def", "test", "(", "rank", ",", "args", ",", "world_size", ")", ":", "\n", "    ", "dist", ".", "init_process_group", "(", "backend", "=", "args", ".", "dist_backend", ",", "init_method", "=", "args", ".", "dist_url", ",", "world_size", "=", "world_size", ",", "rank", "=", "rank", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "\n", "source_root", "=", "args", ".", "source_root", "# specify your source dir", "\n", "dest_root", "=", "args", ".", "dest_root", "# specify your destination dir", "\n", "crop_size", "=", "args", ".", "crop_size", "# specify size of aligned faces, align and crop with padding", "\n", "scale", "=", "crop_size", "/", "112.", "\n", "reference", "=", "get_reference_facial_points", "(", "default_square", "=", "False", ")", "*", "scale", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dest_root", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "dest_root", ")", "\n", "\n", "# LOAD MODELS", "\n", "", "pnet", "=", "PNet", "(", ")", ".", "cuda", "(", ")", "\n", "rnet", "=", "RNet", "(", ")", ".", "cuda", "(", ")", "\n", "onet", "=", "ONet", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "data", "=", "Dataset_Folder", "(", "source_root", ")", "\n", "start_index", ",", "end_index", "=", "0", ",", "len", "(", "data", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_index", "+", "dist", ".", "get_rank", "(", ")", ",", "end_index", ",", "dist", ".", "get_world_size", "(", ")", ")", ":", "\n", "        ", "img_path", "=", "str", "(", "data", ".", "imgs", "[", "i", "]", ")", "\n", "try", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "img_path", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "print", "(", "\"process[{}]: {} is discarded due to read exception!\"", ".", "format", "(", "dist", ".", "get_rank", "(", ")", ",", "img_path", ")", ")", "\n", "continue", "\n", "\n", "# logger.info(\"process[{}]: dealing with {}\".format(dist.get_rank(), img_path))", "\n", "", "mp_print", "(", "\"process[{}]: {}/{}\"", ".", "format", "(", "dist", ".", "get_rank", "(", ")", ",", "i", "//", "dist", ".", "get_world_size", "(", ")", ",", "len", "(", "range", "(", "start_index", "+", "dist", ".", "get_rank", "(", ")", ",", "end_index", ",", "dist", ".", "get_world_size", "(", ")", ")", ")", ")", ",", "i", ")", "\n", "try", ":", "# Handle exception", "\n", "            ", "_", ",", "landmarks", "=", "detect_faces", "(", "img", ",", "nets", "=", "[", "pnet", ",", "rnet", ",", "onet", "]", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "print", "(", "\"process[{}]: {} is discarded due to exception!\"", ".", "format", "(", "dist", ".", "get_rank", "(", ")", ",", "img_path", ")", ")", "\n", "continue", "\n", "", "if", "len", "(", "landmarks", ")", "==", "0", ":", "# If the landmarks cannot be detected, the img will be discarded", "\n", "            ", "print", "(", "\"process[{}]: {} is discarded due to non-detected landmarks!\"", ".", "format", "(", "dist", ".", "get_rank", "(", ")", ",", "img_path", ")", ")", "\n", "# raise ValueError('error!!!')", "\n", "continue", "\n", "\n", "", "facial5points", "=", "[", "[", "landmarks", "[", "0", "]", "[", "j", "]", ",", "landmarks", "[", "0", "]", "[", "j", "+", "5", "]", "]", "for", "j", "in", "range", "(", "5", ")", "]", "\n", "warped_face", "=", "warp_and_crop_face", "(", "np", ".", "array", "(", "img", ")", ",", "facial5points", ",", "reference", ")", "\n", "img_warped", "=", "Image", ".", "fromarray", "(", "warped_face", ")", "\n", "\n", "file_names", "=", "img_path", ".", "split", "(", "'/'", ")", "\n", "img_name", "=", "'/'", ".", "join", "(", "file_names", "[", "-", "2", ":", "]", ")", "\n", "dest_path", "=", "os", ".", "path", ".", "join", "(", "dest_root", ",", "img_name", ")", "\n", "img_warped", ".", "save", "(", "dest_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.nms": [[5, 69], ["numpy.argsort", "len", "len", "pick.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.delete", "range", "len", "numpy.concatenate", "numpy.minimum", "numpy.where"], "function", ["None"], ["def", "nms", "(", "boxes", ",", "overlap_threshold", "=", "0.5", ",", "mode", "=", "'union'", ")", ":", "\n", "    ", "\"\"\"Non-maximum suppression.\n\n    Arguments:\n        boxes: a float numpy array of shape [n, 5],\n            where each row is (xmin, ymin, xmax, ymax, score).\n        overlap_threshold: a float number.\n        mode: 'union' or 'min'.\n\n    Returns:\n        list with indices of the selected boxes\n    \"\"\"", "\n", "\n", "# if there are no boxes, return the empty list", "\n", "if", "len", "(", "boxes", ")", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "# list of picked indices", "\n", "", "pick", "=", "[", "]", "\n", "\n", "# grab the coordinates of the bounding boxes", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "score", "=", "[", "boxes", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "\n", "area", "=", "(", "x2", "-", "x1", "+", "1.0", ")", "*", "(", "y2", "-", "y1", "+", "1.0", ")", "\n", "ids", "=", "np", ".", "argsort", "(", "score", ")", "# in increasing order", "\n", "\n", "while", "len", "(", "ids", ")", ">", "0", ":", "\n", "\n", "# grab index of the largest value", "\n", "        ", "last", "=", "len", "(", "ids", ")", "-", "1", "\n", "i", "=", "ids", "[", "last", "]", "\n", "pick", ".", "append", "(", "i", ")", "\n", "\n", "# compute intersections", "\n", "# of the box with the largest score", "\n", "# with the rest of boxes", "\n", "\n", "# left top corner of intersection boxes", "\n", "ix1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "ids", "[", ":", "last", "]", "]", ")", "\n", "iy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "ids", "[", ":", "last", "]", "]", ")", "\n", "\n", "# right bottom corner of intersection boxes", "\n", "ix2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "ids", "[", ":", "last", "]", "]", ")", "\n", "iy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "ids", "[", ":", "last", "]", "]", ")", "\n", "\n", "# width and height of intersection boxes", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "ix2", "-", "ix1", "+", "1.0", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "iy2", "-", "iy1", "+", "1.0", ")", "\n", "\n", "# intersections' areas", "\n", "inter", "=", "w", "*", "h", "\n", "if", "mode", "==", "'min'", ":", "\n", "            ", "overlap", "=", "inter", "/", "np", ".", "minimum", "(", "area", "[", "i", "]", ",", "area", "[", "ids", "[", ":", "last", "]", "]", ")", "\n", "", "elif", "mode", "==", "'union'", ":", "\n", "# intersection over union (IoU)", "\n", "            ", "overlap", "=", "inter", "/", "(", "area", "[", "i", "]", "+", "area", "[", "ids", "[", ":", "last", "]", "]", "-", "inter", ")", "\n", "\n", "# delete all boxes where overlap is too big", "\n", "", "ids", "=", "np", ".", "delete", "(", "\n", "ids", ",", "\n", "np", ".", "concatenate", "(", "[", "[", "last", "]", ",", "np", ".", "where", "(", "overlap", ">", "overlap_threshold", ")", "[", "0", "]", "]", ")", "\n", ")", "\n", "\n", "", "return", "pick", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.convert_to_square": [[71, 92], ["numpy.zeros_like", "numpy.maximum", "range"], "function", ["None"], ["", "def", "convert_to_square", "(", "bboxes", ")", ":", "\n", "    ", "\"\"\"Convert bounding boxes to a square form.\n\n    Arguments:\n        bboxes: a float numpy array of shape [n, 5].\n\n    Returns:\n        a float numpy array of shape [n, 5],\n            squared bounding boxes.\n    \"\"\"", "\n", "\n", "square_bboxes", "=", "np", ".", "zeros_like", "(", "bboxes", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "bboxes", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "h", "=", "y2", "-", "y1", "+", "1.0", "\n", "w", "=", "x2", "-", "x1", "+", "1.0", "\n", "max_side", "=", "np", ".", "maximum", "(", "h", ",", "w", ")", "\n", "square_bboxes", "[", ":", ",", "0", "]", "=", "x1", "+", "w", "*", "0.5", "-", "max_side", "*", "0.5", "\n", "square_bboxes", "[", ":", ",", "1", "]", "=", "y1", "+", "h", "*", "0.5", "-", "max_side", "*", "0.5", "\n", "square_bboxes", "[", ":", ",", "2", "]", "=", "square_bboxes", "[", ":", ",", "0", "]", "+", "max_side", "-", "1.0", "\n", "square_bboxes", "[", ":", ",", "3", "]", "=", "square_bboxes", "[", ":", ",", "1", "]", "+", "max_side", "-", "1.0", "\n", "return", "square_bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.calibrate_box": [[94, 125], ["numpy.expand_dims", "numpy.expand_dims", "numpy.hstack", "range"], "function", ["None"], ["", "def", "calibrate_box", "(", "bboxes", ",", "offsets", ")", ":", "\n", "    ", "\"\"\"Transform bounding boxes to be more like true bounding boxes.\n    'offsets' is one of the outputs of the nets.\n\n    Arguments:\n        bboxes: a float numpy array of shape [n, 5].\n        offsets: a float numpy array of shape [n, 4].\n\n    Returns:\n        a float numpy array of shape [n, 5].\n    \"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "bboxes", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "w", "=", "x2", "-", "x1", "+", "1.0", "\n", "h", "=", "y2", "-", "y1", "+", "1.0", "\n", "w", "=", "np", ".", "expand_dims", "(", "w", ",", "1", ")", "\n", "h", "=", "np", ".", "expand_dims", "(", "h", ",", "1", ")", "\n", "\n", "# this is what happening here:", "\n", "# tx1, ty1, tx2, ty2 = [offsets[:, i] for i in range(4)]", "\n", "# x1_true = x1 + tx1*w", "\n", "# y1_true = y1 + ty1*h", "\n", "# x2_true = x2 + tx2*w", "\n", "# y2_true = y2 + ty2*h", "\n", "# below is just more compact form of this", "\n", "\n", "# are offsets always such that", "\n", "# x1 < x2 and y1 < y2 ?", "\n", "\n", "translation", "=", "np", ".", "hstack", "(", "[", "w", ",", "h", ",", "w", ",", "h", "]", ")", "*", "offsets", "\n", "bboxes", "[", ":", ",", "0", ":", "4", "]", "=", "bboxes", "[", ":", ",", "0", ":", "4", "]", "+", "translation", "\n", "return", "bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.get_image_boxes": [[127, 160], ["len", "box_utils.correct_bboxes", "numpy.zeros", "range", "numpy.zeros", "numpy.asarray", "PIL.Image.fromarray", "np.asarray.resize", "numpy.asarray", "box_utils._preprocess"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.correct_bboxes", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils._preprocess"], ["", "def", "get_image_boxes", "(", "bounding_boxes", ",", "img", ",", "size", "=", "24", ")", ":", "\n", "    ", "\"\"\"Cut out boxes from the image.\n\n    Arguments:\n        bounding_boxes: a float numpy array of shape [n, 5].\n        img: an instance of PIL.Image.\n        size: an integer, size of cutouts.\n\n    Returns:\n        a float numpy array of shape [n, 3, size, size].\n    \"\"\"", "\n", "\n", "num_boxes", "=", "len", "(", "bounding_boxes", ")", "\n", "width", ",", "height", "=", "img", ".", "size", "\n", "\n", "[", "dy", ",", "edy", ",", "dx", ",", "edx", ",", "y", ",", "ey", ",", "x", ",", "ex", ",", "w", ",", "h", "]", "=", "correct_bboxes", "(", "bounding_boxes", ",", "width", ",", "height", ")", "\n", "img_boxes", "=", "np", ".", "zeros", "(", "(", "num_boxes", ",", "3", ",", "size", ",", "size", ")", ",", "'float32'", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_boxes", ")", ":", "\n", "        ", "img_box", "=", "np", ".", "zeros", "(", "(", "h", "[", "i", "]", ",", "w", "[", "i", "]", ",", "3", ")", ",", "'uint8'", ")", "\n", "\n", "img_array", "=", "np", ".", "asarray", "(", "img", ",", "'uint8'", ")", "\n", "img_box", "[", "dy", "[", "i", "]", ":", "(", "edy", "[", "i", "]", "+", "1", ")", ",", "dx", "[", "i", "]", ":", "(", "edx", "[", "i", "]", "+", "1", ")", ",", ":", "]", "=", "img_array", "[", "y", "[", "i", "]", ":", "(", "ey", "[", "i", "]", "+", "1", ")", ",", "x", "[", "i", "]", ":", "(", "ex", "[", "i", "]", "+", "1", ")", ",", ":", "]", "\n", "\n", "# resize", "\n", "img_box", "=", "Image", ".", "fromarray", "(", "img_box", ")", "\n", "img_box", "=", "img_box", ".", "resize", "(", "(", "size", ",", "size", ")", ",", "Image", ".", "BILINEAR", ")", "\n", "img_box", "=", "np", ".", "asarray", "(", "img_box", ",", "'float32'", ")", "\n", "\n", "img_boxes", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "_preprocess", "(", "img_box", ")", "\n", "\n", "", "return", "img_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.correct_bboxes": [[162, 224], ["numpy.zeros", "numpy.zeros", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "i.astype", "range", "w.copy", "h.copy"], "function", ["None"], ["", "def", "correct_bboxes", "(", "bboxes", ",", "width", ",", "height", ")", ":", "\n", "    ", "\"\"\"Crop boxes that are too big and get coordinates\n    with respect to cutouts.\n\n    Arguments:\n        bboxes: a float numpy array of shape [n, 5],\n            where each row is (xmin, ymin, xmax, ymax, score).\n        width: a float number.\n        height: a float number.\n\n    Returns:\n        dy, dx, edy, edx: a int numpy arrays of shape [n],\n            coordinates of the boxes with respect to the cutouts.\n        y, x, ey, ex: a int numpy arrays of shape [n],\n            corrected ymin, xmin, ymax, xmax.\n        h, w: a int numpy arrays of shape [n],\n            just heights and widths of boxes.\n\n        in the following order:\n            [dy, edy, dx, edx, y, ey, x, ex, w, h].\n    \"\"\"", "\n", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "bboxes", "[", ":", ",", "i", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "w", ",", "h", "=", "x2", "-", "x1", "+", "1.0", ",", "y2", "-", "y1", "+", "1.0", "\n", "num_boxes", "=", "bboxes", ".", "shape", "[", "0", "]", "\n", "\n", "# 'e' stands for end", "\n", "# (x, y) -> (ex, ey)", "\n", "x", ",", "y", ",", "ex", ",", "ey", "=", "x1", ",", "y1", ",", "x2", ",", "y2", "\n", "\n", "# we need to cut out a box from the image.", "\n", "# (x, y, ex, ey) are corrected coordinates of the box", "\n", "# in the image.", "\n", "# (dx, dy, edx, edy) are coordinates of the box in the cutout", "\n", "# from the image.", "\n", "dx", ",", "dy", "=", "np", ".", "zeros", "(", "(", "num_boxes", ",", ")", ")", ",", "np", ".", "zeros", "(", "(", "num_boxes", ",", ")", ")", "\n", "edx", ",", "edy", "=", "w", ".", "copy", "(", ")", "-", "1.0", ",", "h", ".", "copy", "(", ")", "-", "1.0", "\n", "\n", "# if box's bottom right corner is too far right", "\n", "ind", "=", "np", ".", "where", "(", "ex", ">", "width", "-", "1.0", ")", "[", "0", "]", "\n", "edx", "[", "ind", "]", "=", "w", "[", "ind", "]", "+", "width", "-", "2.0", "-", "ex", "[", "ind", "]", "\n", "ex", "[", "ind", "]", "=", "width", "-", "1.0", "\n", "\n", "# if box's bottom right corner is too low", "\n", "ind", "=", "np", ".", "where", "(", "ey", ">", "height", "-", "1.0", ")", "[", "0", "]", "\n", "edy", "[", "ind", "]", "=", "h", "[", "ind", "]", "+", "height", "-", "2.0", "-", "ey", "[", "ind", "]", "\n", "ey", "[", "ind", "]", "=", "height", "-", "1.0", "\n", "\n", "# if box's top left corner is too far left", "\n", "ind", "=", "np", ".", "where", "(", "x", "<", "0.0", ")", "[", "0", "]", "\n", "dx", "[", "ind", "]", "=", "0.0", "-", "x", "[", "ind", "]", "\n", "x", "[", "ind", "]", "=", "0.0", "\n", "\n", "# if box's top left corner is too high", "\n", "ind", "=", "np", ".", "where", "(", "y", "<", "0.0", ")", "[", "0", "]", "\n", "dy", "[", "ind", "]", "=", "0.0", "-", "y", "[", "ind", "]", "\n", "y", "[", "ind", "]", "=", "0.0", "\n", "\n", "return_list", "=", "[", "dy", ",", "edy", ",", "dx", ",", "edx", ",", "y", ",", "ey", ",", "x", ",", "ex", ",", "w", ",", "h", "]", "\n", "return_list", "=", "[", "i", ".", "astype", "(", "'int32'", ")", "for", "i", "in", "return_list", "]", "\n", "\n", "return", "return_list", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils._preprocess": [[226, 239], ["np.expand_dims.transpose", "numpy.expand_dims"], "function", ["None"], ["", "def", "_preprocess", "(", "img", ")", ":", "\n", "    ", "\"\"\"Preprocessing step before feeding the network.\n\n    Arguments:\n        img: a float numpy array of shape [h, w, c].\n\n    Returns:\n        a float numpy array of shape [1, c, h, w].\n    \"\"\"", "\n", "img", "=", "img", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "0", ")", "\n", "img", "=", "(", "img", "-", "127.5", ")", "*", "0.0078125", "\n", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__init__": [[4, 7], ["dataset.Dataset_Folder.get_imgs"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.get_imgs"], ["import", "torch", "\n", "import", "numpy", "as", "np", "\n", "from", "PIL", "import", "Image", "\n", "from", "torch", ".", "utils", ".", "data", "import", "Dataset", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.get_imgs": [[8, 14], ["pathlib.Path", "sorted", "list", "len", "sorted", "pathlib.Path.glob", "list", "pathlib.Path.glob"], "methods", ["None"], ["\n", "class", "Img_Folder_Num", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "root", ",", "refer_classes", ",", "refer_length", ",", "albu_transform", "=", "None", ",", "transform", "=", "None", ",", "num_id", "=", "1000", ",", "samples_perid", "=", "10", ")", ":", "\n", "        ", "super", "(", "Img_Folder_Num", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "refer_length", "=", "refer_length", "\n", "self", ".", "db", ",", "self", ".", "class_to_label", "=", "self", ".", "load_db", "(", "refer_classes", ",", "refer_length", ",", "num_id", ",", "samples_perid", ")", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.dataset.Dataset_Folder.__len__": [[15, 17], ["len"], "methods", ["None"], ["self", ".", "classes", "=", "list", "(", "self", ".", "class_to_label", ".", "keys", "(", ")", ")", "\n", "self", ".", "albu_transform", "=", "albu_transform", "\n", "self", ".", "transform", "=", "transform", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.FaceWarpException.__str__": [[20, 23], ["super.__str__"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.MatlabCp2tormException.__str__"], ["    ", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'In File {}:{}'", ".", "format", "(", "\n", "__file__", ",", "super", ".", "__str__", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.get_reference_facial_points": [[25, 154], ["numpy.array", "numpy.array", "align_trans.FaceWarpException", "numpy.array", "align_trans.FaceWarpException", "numpy.round().astype", "numpy.array", "align_trans.FaceWarpException", "size_bf_outer_pad[].astype", "numpy.array", "max", "align_trans.FaceWarpException", "numpy.array", "numpy.round"], "function", ["None"], ["", "", "def", "get_reference_facial_points", "(", "output_size", "=", "None", ",", "\n", "inner_padding_factor", "=", "0.0", ",", "\n", "outer_padding", "=", "(", "0", ",", "0", ")", ",", "\n", "default_square", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        get reference 5 key points according to crop settings:\n        0. Set default crop_size:\n            if default_square: \n                crop_size = (112, 112)\n            else: \n                crop_size = (96, 112)\n        1. Pad the crop_size by inner_padding_factor in each side;\n        2. Resize crop_size into (output_size - outer_padding*2),\n            pad into output_size with outer_padding;\n        3. Output reference_5point;\n    Parameters:\n    ----------\n        @output_size: (w, h) or None\n            size of aligned face image\n        @inner_padding_factor: (w_factor, h_factor)\n            padding factor for inner (w, h)\n        @outer_padding: (w_pad, h_pad)\n            each row is a pair of coordinates (x, y)\n        @default_square: True or False\n            if True:\n                default crop_size = (112, 112)\n            else:\n                default crop_size = (96, 112);\n        !!! make sure, if output_size is not None:\n                (output_size - outer_padding) \n                = some_scale * (default crop_size * (1.0 + inner_padding_factor))\n    Returns:\n    ----------\n        @reference_5point: 5x2 np.array\n            each row is a pair of transformed coordinates (x, y)\n    \"\"\"", "\n", "#print('\\n===> get_reference_facial_points():')", "\n", "\n", "#print('---> Params:')", "\n", "#print('            output_size: ', output_size)", "\n", "#print('            inner_padding_factor: ', inner_padding_factor)", "\n", "#print('            outer_padding:', outer_padding)", "\n", "#print('            default_square: ', default_square)", "\n", "\n", "tmp_5pts", "=", "np", ".", "array", "(", "REFERENCE_FACIAL_POINTS", ")", "\n", "tmp_crop_size", "=", "np", ".", "array", "(", "DEFAULT_CROP_SIZE", ")", "\n", "\n", "# 0) make the inner region a square", "\n", "if", "default_square", ":", "\n", "        ", "size_diff", "=", "max", "(", "tmp_crop_size", ")", "-", "tmp_crop_size", "\n", "tmp_5pts", "+=", "size_diff", "/", "2", "\n", "tmp_crop_size", "+=", "size_diff", "\n", "\n", "#print('---> default:')", "\n", "#print('              crop_size = ', tmp_crop_size)", "\n", "#print('              reference_5pts = ', tmp_5pts)", "\n", "\n", "", "if", "(", "output_size", "and", "\n", "output_size", "[", "0", "]", "==", "tmp_crop_size", "[", "0", "]", "and", "\n", "output_size", "[", "1", "]", "==", "tmp_crop_size", "[", "1", "]", ")", ":", "\n", "#print('output_size == DEFAULT_CROP_SIZE {}: return default reference points'.format(tmp_crop_size))", "\n", "        ", "return", "tmp_5pts", "\n", "\n", "", "if", "(", "inner_padding_factor", "==", "0", "and", "\n", "outer_padding", "==", "(", "0", ",", "0", ")", ")", ":", "\n", "        ", "if", "output_size", "is", "None", ":", "\n", "#print('No paddings to do: return default reference points')", "\n", "            ", "return", "tmp_5pts", "\n", "", "else", ":", "\n", "            ", "raise", "FaceWarpException", "(", "\n", "'No paddings to do, output_size must be None or {}'", ".", "format", "(", "tmp_crop_size", ")", ")", "\n", "\n", "# check output size", "\n", "", "", "if", "not", "(", "0", "<=", "inner_padding_factor", "<=", "1.0", ")", ":", "\n", "        ", "raise", "FaceWarpException", "(", "'Not (0 <= inner_padding_factor <= 1.0)'", ")", "\n", "\n", "", "if", "(", "(", "inner_padding_factor", ">", "0", "or", "outer_padding", "[", "0", "]", ">", "0", "or", "outer_padding", "[", "1", "]", ">", "0", ")", "\n", "and", "output_size", "is", "None", ")", ":", "\n", "        ", "output_size", "=", "tmp_crop_size", "*", "(", "1", "+", "inner_padding_factor", "*", "2", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "output_size", "+=", "np", ".", "array", "(", "outer_padding", ")", "\n", "#print('              deduced from paddings, output_size = ', output_size)", "\n", "\n", "", "if", "not", "(", "outer_padding", "[", "0", "]", "<", "output_size", "[", "0", "]", "\n", "and", "outer_padding", "[", "1", "]", "<", "output_size", "[", "1", "]", ")", ":", "\n", "        ", "raise", "FaceWarpException", "(", "'Not (outer_padding[0] < output_size[0]'", "\n", "'and outer_padding[1] < output_size[1])'", ")", "\n", "\n", "# 1) pad the inner region according inner_padding_factor", "\n", "#print('---> STEP1: pad the inner region according inner_padding_factor')", "\n", "", "if", "inner_padding_factor", ">", "0", ":", "\n", "        ", "size_diff", "=", "tmp_crop_size", "*", "inner_padding_factor", "*", "2", "\n", "tmp_5pts", "+=", "size_diff", "/", "2", "\n", "tmp_crop_size", "+=", "np", ".", "round", "(", "size_diff", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "#print('              crop_size = ', tmp_crop_size)", "\n", "#print('              reference_5pts = ', tmp_5pts)", "\n", "\n", "# 2) resize the padded inner region", "\n", "#print('---> STEP2: resize the padded inner region')", "\n", "", "size_bf_outer_pad", "=", "np", ".", "array", "(", "output_size", ")", "-", "np", ".", "array", "(", "outer_padding", ")", "*", "2", "\n", "#print('              crop_size = ', tmp_crop_size)", "\n", "#print('              size_bf_outer_pad = ', size_bf_outer_pad)", "\n", "\n", "if", "size_bf_outer_pad", "[", "0", "]", "*", "tmp_crop_size", "[", "1", "]", "!=", "size_bf_outer_pad", "[", "1", "]", "*", "tmp_crop_size", "[", "0", "]", ":", "\n", "        ", "raise", "FaceWarpException", "(", "'Must have (output_size - outer_padding)'", "\n", "'= some_scale * (crop_size * (1.0 + inner_padding_factor)'", ")", "\n", "\n", "", "scale_factor", "=", "size_bf_outer_pad", "[", "0", "]", ".", "astype", "(", "np", ".", "float32", ")", "/", "tmp_crop_size", "[", "0", "]", "\n", "#print('              resize scale_factor = ', scale_factor)", "\n", "tmp_5pts", "=", "tmp_5pts", "*", "scale_factor", "\n", "#    size_diff = tmp_crop_size * (scale_factor - min(scale_factor))", "\n", "#    tmp_5pts = tmp_5pts + size_diff / 2", "\n", "tmp_crop_size", "=", "size_bf_outer_pad", "\n", "#print('              crop_size = ', tmp_crop_size)", "\n", "#print('              reference_5pts = ', tmp_5pts)", "\n", "\n", "# 3) add outer_padding to make output_size", "\n", "reference_5point", "=", "tmp_5pts", "+", "np", ".", "array", "(", "outer_padding", ")", "\n", "tmp_crop_size", "=", "output_size", "\n", "#print('---> STEP3: add outer_padding to make output_size')", "\n", "#print('              crop_size = ', tmp_crop_size)", "\n", "#print('              reference_5pts = ', tmp_5pts)", "\n", "\n", "#print('===> end get_reference_facial_points\\n')", "\n", "\n", "return", "reference_5point", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.get_affine_transform_matrix": [[156, 201], ["numpy.float32", "numpy.ones", "numpy.hstack", "numpy.hstack", "numpy.linalg.lstsq", "numpy.float32", "numpy.float32"], "function", ["None"], ["", "def", "get_affine_transform_matrix", "(", "src_pts", ",", "dst_pts", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        get affine transform matrix 'tfm' from src_pts to dst_pts\n    Parameters:\n    ----------\n        @src_pts: Kx2 np.array\n            source points matrix, each row is a pair of coordinates (x, y)\n        @dst_pts: Kx2 np.array\n            destination points matrix, each row is a pair of coordinates (x, y)\n    Returns:\n    ----------\n        @tfm: 2x3 np.array\n            transform matrix from src_pts to dst_pts\n    \"\"\"", "\n", "\n", "tfm", "=", "np", ".", "float32", "(", "[", "[", "1", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", "]", "]", ")", "\n", "n_pts", "=", "src_pts", ".", "shape", "[", "0", "]", "\n", "ones", "=", "np", ".", "ones", "(", "(", "n_pts", ",", "1", ")", ",", "src_pts", ".", "dtype", ")", "\n", "src_pts_", "=", "np", ".", "hstack", "(", "[", "src_pts", ",", "ones", "]", ")", "\n", "dst_pts_", "=", "np", ".", "hstack", "(", "[", "dst_pts", ",", "ones", "]", ")", "\n", "\n", "#    #print(('src_pts_:\\n' + str(src_pts_))", "\n", "#    #print(('dst_pts_:\\n' + str(dst_pts_))", "\n", "\n", "A", ",", "res", ",", "rank", ",", "s", "=", "np", ".", "linalg", ".", "lstsq", "(", "src_pts_", ",", "dst_pts_", ")", "\n", "\n", "#    #print(('np.linalg.lstsq return A: \\n' + str(A))", "\n", "#    #print(('np.linalg.lstsq return res: \\n' + str(res))", "\n", "#    #print(('np.linalg.lstsq return rank: \\n' + str(rank))", "\n", "#    #print(('np.linalg.lstsq return s: \\n' + str(s))", "\n", "\n", "if", "rank", "==", "3", ":", "\n", "        ", "tfm", "=", "np", ".", "float32", "(", "[", "\n", "[", "A", "[", "0", ",", "0", "]", ",", "A", "[", "1", ",", "0", "]", ",", "A", "[", "2", ",", "0", "]", "]", ",", "\n", "[", "A", "[", "0", ",", "1", "]", ",", "A", "[", "1", ",", "1", "]", ",", "A", "[", "2", ",", "1", "]", "]", "\n", "]", ")", "\n", "", "elif", "rank", "==", "2", ":", "\n", "        ", "tfm", "=", "np", ".", "float32", "(", "[", "\n", "[", "A", "[", "0", ",", "0", "]", ",", "A", "[", "1", ",", "0", "]", ",", "0", "]", ",", "\n", "[", "A", "[", "0", ",", "1", "]", ",", "A", "[", "1", ",", "1", "]", ",", "0", "]", "\n", "]", ")", "\n", "\n", "", "return", "tfm", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.warp_and_crop_face": [[203, 299], ["numpy.float32", "numpy.float32", "cv2.warpAffine", "align_trans.FaceWarpException", "align_trans.FaceWarpException", "align_trans.FaceWarpException", "cv2.getAffineTransform", "align_trans.get_reference_facial_points", "max", "min", "max", "min", "align_trans.get_affine_transform_matrix", "align_trans.similarity_transform"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.get_reference_facial_points", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.get_affine_transform_matrix", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.similarity_transform"], ["", "def", "warp_and_crop_face", "(", "src_img", ",", "\n", "facial_pts", ",", "\n", "reference_pts", "=", "None", ",", "\n", "crop_size", "=", "(", "96", ",", "112", ")", ",", "\n", "align_type", "=", "'smilarity'", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        apply affine transform 'trans' to uv\n    Parameters:\n    ----------\n        @src_img: 3x3 np.array\n            input image\n        @facial_pts: could be\n            1)a list of K coordinates (x,y)\n        or\n            2) Kx2 or 2xK np.array\n            each row or col is a pair of coordinates (x, y)\n        @reference_pts: could be\n            1) a list of K coordinates (x,y)\n        or\n            2) Kx2 or 2xK np.array\n            each row or col is a pair of coordinates (x, y)\n        or\n            3) None\n            if None, use default reference facial points\n        @crop_size: (w, h)\n            output face image size\n        @align_type: transform type, could be one of\n            1) 'similarity': use similarity transform\n            2) 'cv2_affine': use the first 3 points to do affine transform,\n                    by calling cv2.getAffineTransform()\n            3) 'affine': use all points to do affine transform\n    Returns:\n    ----------\n        @face_img: output face image with size (w, h) = @crop_size\n    \"\"\"", "\n", "\n", "if", "reference_pts", "is", "None", ":", "\n", "        ", "if", "crop_size", "[", "0", "]", "==", "96", "and", "crop_size", "[", "1", "]", "==", "112", ":", "\n", "            ", "reference_pts", "=", "REFERENCE_FACIAL_POINTS", "\n", "", "else", ":", "\n", "            ", "default_square", "=", "False", "\n", "inner_padding_factor", "=", "0", "\n", "outer_padding", "=", "(", "0", ",", "0", ")", "\n", "output_size", "=", "crop_size", "\n", "\n", "reference_pts", "=", "get_reference_facial_points", "(", "output_size", ",", "\n", "inner_padding_factor", ",", "\n", "outer_padding", ",", "\n", "default_square", ")", "\n", "\n", "", "", "ref_pts", "=", "np", ".", "float32", "(", "reference_pts", ")", "\n", "ref_pts_shp", "=", "ref_pts", ".", "shape", "\n", "if", "max", "(", "ref_pts_shp", ")", "<", "3", "or", "min", "(", "ref_pts_shp", ")", "!=", "2", ":", "\n", "        ", "raise", "FaceWarpException", "(", "\n", "'reference_pts.shape must be (K,2) or (2,K) and K>2'", ")", "\n", "\n", "", "if", "ref_pts_shp", "[", "0", "]", "==", "2", ":", "\n", "        ", "ref_pts", "=", "ref_pts", ".", "T", "\n", "\n", "", "src_pts", "=", "np", ".", "float32", "(", "facial_pts", ")", "\n", "src_pts_shp", "=", "src_pts", ".", "shape", "\n", "if", "max", "(", "src_pts_shp", ")", "<", "3", "or", "min", "(", "src_pts_shp", ")", "!=", "2", ":", "\n", "        ", "raise", "FaceWarpException", "(", "\n", "'facial_pts.shape must be (K,2) or (2,K) and K>2'", ")", "\n", "\n", "", "if", "src_pts_shp", "[", "0", "]", "==", "2", ":", "\n", "        ", "src_pts", "=", "src_pts", ".", "T", "\n", "\n", "#    #print('--->src_pts:\\n', src_pts", "\n", "#    #print('--->ref_pts\\n', ref_pts", "\n", "\n", "", "if", "src_pts", ".", "shape", "!=", "ref_pts", ".", "shape", ":", "\n", "        ", "raise", "FaceWarpException", "(", "\n", "'facial_pts and reference_pts must have the same shape'", ")", "\n", "\n", "", "if", "align_type", "is", "'cv2_affine'", ":", "\n", "        ", "tfm", "=", "cv2", ".", "getAffineTransform", "(", "src_pts", "[", "0", ":", "3", "]", ",", "ref_pts", "[", "0", ":", "3", "]", ")", "\n", "#        #print(('cv2.getAffineTransform() returns tfm=\\n' + str(tfm))", "\n", "", "elif", "align_type", "is", "'affine'", ":", "\n", "        ", "tfm", "=", "get_affine_transform_matrix", "(", "src_pts", ",", "ref_pts", ")", "\n", "#        #print(('get_affine_transform_matrix() returns tfm=\\n' + str(tfm))", "\n", "", "else", ":", "\n", "# tfm = get_similarity_transform_for_cv2(src_pts, ref_pts)", "\n", "        ", "tfm", "=", "similarity_transform", "(", "src_pts", ",", "ref_pts", ")", "\n", "#        #print(('get_similarity_transform_for_cv2() returns tfm=\\n' + str(tfm))", "\n", "\n", "#    #print('--->Transform matrix: '", "\n", "#    #print(('type(tfm):' + str(type(tfm)))", "\n", "#    #print(('tfm.dtype:' + str(tfm.dtype))", "\n", "#    #print( tfm", "\n", "\n", "", "face_img", "=", "cv2", ".", "warpAffine", "(", "src_img", ",", "tfm", ",", "(", "crop_size", "[", "0", "]", ",", "crop_size", "[", "1", "]", ")", ")", "\n", "\n", "return", "face_img", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.align_trans.similarity_transform": [[300, 305], ["skimage.transform.SimilarityTransform", "trans.SimilarityTransform.estimate"], "function", ["None"], ["", "def", "similarity_transform", "(", "src_pts", ",", "ref_pts", ")", ":", "\n", "    ", "tform", "=", "trans", ".", "SimilarityTransform", "(", ")", "\n", "tform", ".", "estimate", "(", "src_pts", ",", "ref_pts", ")", "\n", "M", "=", "tform", ".", "params", "[", "0", ":", "2", ",", ":", "]", "\n", "return", "M", "\n", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.detector.detect_faces": [[9, 131], ["min", "pnet.eval", "numpy.vstack", "box_utils.nms", "box_utils.calibrate_box", "box_utils.convert_to_square", "numpy.round", "rnet.eval", "output[].data.cpu().numpy", "output[].data.cpu().numpy", "probs[].reshape", "box_utils.nms", "box_utils.calibrate_box", "box_utils.convert_to_square", "numpy.round", "onet.eval", "box_utils.get_image_boxes", "output[].data.cpu().numpy", "output[].data.cpu().numpy", "output[].data.cpu().numpy", "probs[].reshape", "box_utils.calibrate_box", "box_utils.nms", "scales.append", "torch.no_grad", "torch.no_grad", "box_utils.get_image_boxes", "torch.autograd.Variable().cuda", "rnet", "numpy.where", "len", "len", "torch.no_grad", "torch.autograd.Variable().cuda", "onet", "numpy.where", "len", "numpy.expand_dims", "numpy.expand_dims", "first_stage.run_first_stage", "box_utils.calibrate_box.append", "output[].data.cpu", "output[].data.cpu", "output[].data.cpu", "output[].data.cpu", "output[].data.cpu", "numpy.expand_dims", "numpy.expand_dims", "torch.autograd.Variable", "torch.autograd.Variable", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.nms", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.calibrate_box", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.convert_to_square", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.nms", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.calibrate_box", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.convert_to_square", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.core.lfw_eval.eval", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.get_image_boxes", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.calibrate_box", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.nms", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.box_utils.get_image_boxes", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.first_stage.run_first_stage"], ["def", "detect_faces", "(", "image", ",", "nets", ",", "min_face_size", "=", "20.0", ",", "\n", "thresholds", "=", "[", "0.6", ",", "0.7", ",", "0.7", "]", ",", "\n", "nms_thresholds", "=", "[", "0.7", ",", "0.7", ",", "0.7", "]", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        image: an instance of PIL.Image.\n        min_face_size: a float number.\n        thresholds: a list of length 3.\n        nms_thresholds: a list of length 3.\n\n    Returns:\n        two float numpy arrays of shapes [n_boxes, 4] and [n_boxes, 10],\n        bounding boxes and facial landmarks.\n    \"\"\"", "\n", "\n", "# LOAD MODELS", "\n", "pnet", ",", "rnet", ",", "onet", "=", "nets", "\n", "\n", "# BUILD AN IMAGE PYRAMID", "\n", "width", ",", "height", "=", "image", ".", "size", "\n", "min_length", "=", "min", "(", "height", ",", "width", ")", "\n", "\n", "min_detection_size", "=", "12", "\n", "factor", "=", "0.709", "# sqrt(0.5)", "\n", "\n", "# scales for scaling the image", "\n", "scales", "=", "[", "]", "\n", "\n", "# scales the image so that", "\n", "# minimum size that we can detect equals to", "\n", "# minimum face size that we want to detect", "\n", "m", "=", "min_detection_size", "/", "min_face_size", "\n", "min_length", "*=", "m", "\n", "\n", "factor_count", "=", "0", "\n", "while", "min_length", ">", "min_detection_size", ":", "\n", "        ", "scales", ".", "append", "(", "m", "*", "factor", "**", "factor_count", ")", "\n", "min_length", "*=", "factor", "\n", "factor_count", "+=", "1", "\n", "\n", "# STAGE 1", "\n", "\n", "# it will be returned", "\n", "", "bounding_boxes", "=", "[", "]", "\n", "\n", "# run P-Net on different scales", "\n", "pnet", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "s", "in", "scales", ":", "\n", "            ", "boxes", "=", "run_first_stage", "(", "image", ",", "pnet", ",", "scale", "=", "s", ",", "threshold", "=", "thresholds", "[", "0", "]", ")", "\n", "bounding_boxes", ".", "append", "(", "boxes", ")", "\n", "\n", "# collect boxes (and offsets, and scores) from different scales", "\n", "", "", "bounding_boxes", "=", "[", "i", "for", "i", "in", "bounding_boxes", "if", "i", "is", "not", "None", "]", "\n", "bounding_boxes", "=", "np", ".", "vstack", "(", "bounding_boxes", ")", "\n", "\n", "keep", "=", "nms", "(", "bounding_boxes", "[", ":", ",", "0", ":", "5", "]", ",", "nms_thresholds", "[", "0", "]", ")", "\n", "bounding_boxes", "=", "bounding_boxes", "[", "keep", "]", "\n", "\n", "# use offsets predicted by pnet to transform bounding boxes", "\n", "bounding_boxes", "=", "calibrate_box", "(", "bounding_boxes", "[", ":", ",", "0", ":", "5", "]", ",", "bounding_boxes", "[", ":", ",", "5", ":", "]", ")", "\n", "# shape [n_boxes, 5]", "\n", "\n", "bounding_boxes", "=", "convert_to_square", "(", "bounding_boxes", ")", "\n", "bounding_boxes", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "round", "(", "bounding_boxes", "[", ":", ",", "0", ":", "4", "]", ")", "\n", "\n", "# STAGE 2", "\n", "rnet", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_boxes", "=", "get_image_boxes", "(", "bounding_boxes", ",", "image", ",", "size", "=", "24", ")", "\n", "img_boxes", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "img_boxes", ")", ",", "volatile", "=", "True", ")", ".", "cuda", "(", ")", "\n", "output", "=", "rnet", "(", "img_boxes", ")", "\n", "", "offsets", "=", "output", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# shape [n_boxes, 4]", "\n", "probs", "=", "output", "[", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# shape [n_boxes, 2]", "\n", "\n", "keep", "=", "np", ".", "where", "(", "probs", "[", ":", ",", "1", "]", ">", "thresholds", "[", "1", "]", ")", "[", "0", "]", "\n", "if", "len", "(", "keep", ")", "==", "0", ":", "\n", "        ", "keep", "=", "[", "0", "]", "\n", "", "bounding_boxes", "=", "bounding_boxes", "[", "keep", "]", "\n", "bounding_boxes", "[", ":", ",", "4", "]", "=", "probs", "[", "keep", ",", "1", "]", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "offsets", "=", "offsets", "[", "keep", "]", "\n", "\n", "keep", "=", "nms", "(", "bounding_boxes", ",", "nms_thresholds", "[", "1", "]", ")", "\n", "bounding_boxes", "=", "bounding_boxes", "[", "keep", "]", "\n", "bounding_boxes", "=", "calibrate_box", "(", "bounding_boxes", ",", "offsets", "[", "keep", "]", ")", "\n", "bounding_boxes", "=", "convert_to_square", "(", "bounding_boxes", ")", "\n", "bounding_boxes", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "round", "(", "bounding_boxes", "[", ":", ",", "0", ":", "4", "]", ")", "\n", "\n", "# STAGE 3", "\n", "\n", "onet", ".", "eval", "(", ")", "\n", "img_boxes", "=", "get_image_boxes", "(", "bounding_boxes", ",", "image", ",", "size", "=", "48", ")", "\n", "if", "len", "(", "img_boxes", ")", "==", "0", ":", "\n", "        ", "return", "[", "]", ",", "[", "]", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "img_boxes", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "img_boxes", ")", ",", "volatile", "=", "True", ")", ".", "cuda", "(", ")", "\n", "output", "=", "onet", "(", "img_boxes", ")", "\n", "", "landmarks", "=", "output", "[", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# shape [n_boxes, 10]", "\n", "offsets", "=", "output", "[", "1", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# shape [n_boxes, 4]", "\n", "probs", "=", "output", "[", "2", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# shape [n_boxes, 2]", "\n", "\n", "keep", "=", "np", ".", "where", "(", "probs", "[", ":", ",", "1", "]", ">", "thresholds", "[", "2", "]", ")", "[", "0", "]", "\n", "if", "len", "(", "keep", ")", "==", "0", ":", "\n", "        ", "keep", "=", "[", "0", "]", "\n", "", "bounding_boxes", "=", "bounding_boxes", "[", "keep", "]", "\n", "bounding_boxes", "[", ":", ",", "4", "]", "=", "probs", "[", "keep", ",", "1", "]", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "offsets", "=", "offsets", "[", "keep", "]", "\n", "landmarks", "=", "landmarks", "[", "keep", "]", "\n", "\n", "# compute landmark points", "\n", "width", "=", "bounding_boxes", "[", ":", ",", "2", "]", "-", "bounding_boxes", "[", ":", ",", "0", "]", "+", "1.0", "\n", "height", "=", "bounding_boxes", "[", ":", ",", "3", "]", "-", "bounding_boxes", "[", ":", ",", "1", "]", "+", "1.0", "\n", "xmin", ",", "ymin", "=", "bounding_boxes", "[", ":", ",", "0", "]", ",", "bounding_boxes", "[", ":", ",", "1", "]", "\n", "landmarks", "[", ":", ",", "0", ":", "5", "]", "=", "np", ".", "expand_dims", "(", "xmin", ",", "1", ")", "+", "np", ".", "expand_dims", "(", "width", ",", "1", ")", "*", "landmarks", "[", ":", ",", "0", ":", "5", "]", "\n", "landmarks", "[", ":", ",", "5", ":", "10", "]", "=", "np", ".", "expand_dims", "(", "ymin", ",", "1", ")", "+", "np", ".", "expand_dims", "(", "height", ",", "1", ")", "*", "landmarks", "[", ":", ",", "5", ":", "10", "]", "\n", "\n", "bounding_boxes", "=", "calibrate_box", "(", "bounding_boxes", ",", "offsets", ")", "\n", "keep", "=", "nms", "(", "bounding_boxes", ",", "nms_thresholds", "[", "2", "]", ",", "mode", "=", "'min'", ")", "\n", "bounding_boxes", "=", "bounding_boxes", "[", "keep", "]", "\n", "landmarks", "=", "landmarks", "[", "keep", "]", "\n", "\n", "return", "bounding_boxes", ",", "landmarks", "\n", "", ""]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.MatlabCp2tormException.__str__": [[7, 10], ["super.__str__"], "methods", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.MatlabCp2tormException.__str__"], ["    ", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"In File {}:{}\"", ".", "format", "(", "\n", "__file__", ",", "super", ".", "__str__", "(", "self", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.tformfwd": [[11, 35], ["numpy.hstack", "numpy.dot", "numpy.ones"], "function", ["None"], ["", "", "def", "tformfwd", "(", "trans", ",", "uv", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        apply affine transform 'trans' to uv\n\n    Parameters:\n    ----------\n        @trans: 3x3 np.array\n            transform matrix\n        @uv: Kx2 np.array\n            each row is a pair of coordinates (x, y)\n\n    Returns:\n    ----------\n        @xy: Kx2 np.array\n            each row is a pair of transformed coordinates (x, y)\n    \"\"\"", "\n", "uv", "=", "np", ".", "hstack", "(", "(", "\n", "uv", ",", "np", ".", "ones", "(", "(", "uv", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", ")", ")", "\n", "xy", "=", "np", ".", "dot", "(", "uv", ",", "trans", ")", "\n", "xy", "=", "xy", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "return", "xy", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.tforminv": [[37, 58], ["numpy.linalg.inv", "matlab_cp2tform.tformfwd"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.tformfwd"], ["", "def", "tforminv", "(", "trans", ",", "uv", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        apply the inverse of affine transform 'trans' to uv\n\n    Parameters:\n    ----------\n        @trans: 3x3 np.array\n            transform matrix\n        @uv: Kx2 np.array\n            each row is a pair of coordinates (x, y)\n\n    Returns:\n    ----------\n        @xy: Kx2 np.array\n            each row is a pair of inverse-transformed coordinates (x, y)\n    \"\"\"", "\n", "Tinv", "=", "inv", "(", "trans", ")", "\n", "xy", "=", "tformfwd", "(", "Tinv", ",", "uv", ")", "\n", "return", "xy", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findNonreflectiveSimilarity": [[60, 110], ["xy[].reshape", "xy[].reshape", "numpy.hstack", "numpy.hstack", "numpy.vstack", "uv[].reshape", "uv[].reshape", "numpy.vstack", "numpy.array", "numpy.linalg.inv", "numpy.array", "numpy.linalg.matrix_rank", "numpy.linalg.lstsq", "numpy.squeeze", "Exception", "numpy.ones", "numpy.zeros", "numpy.zeros", "numpy.ones"], "function", ["None"], ["", "def", "findNonreflectiveSimilarity", "(", "uv", ",", "xy", ",", "options", "=", "None", ")", ":", "\n", "\n", "    ", "options", "=", "{", "'K'", ":", "2", "}", "\n", "\n", "K", "=", "options", "[", "'K'", "]", "\n", "M", "=", "xy", ".", "shape", "[", "0", "]", "\n", "x", "=", "xy", "[", ":", ",", "0", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "# use reshape to keep a column vector", "\n", "y", "=", "xy", "[", ":", ",", "1", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "# use reshape to keep a column vector", "\n", "# print('--->x, y:\\n', x, y", "\n", "\n", "tmp1", "=", "np", ".", "hstack", "(", "(", "x", ",", "y", ",", "np", ".", "ones", "(", "(", "M", ",", "1", ")", ")", ",", "np", ".", "zeros", "(", "(", "M", ",", "1", ")", ")", ")", ")", "\n", "tmp2", "=", "np", ".", "hstack", "(", "(", "y", ",", "-", "x", ",", "np", ".", "zeros", "(", "(", "M", ",", "1", ")", ")", ",", "np", ".", "ones", "(", "(", "M", ",", "1", ")", ")", ")", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "tmp1", ",", "tmp2", ")", ")", "\n", "# print('--->X.shape: ', X.shape", "\n", "# print('X:\\n', X", "\n", "\n", "u", "=", "uv", "[", ":", ",", "0", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "# use reshape to keep a column vector", "\n", "v", "=", "uv", "[", ":", ",", "1", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "# use reshape to keep a column vector", "\n", "U", "=", "np", ".", "vstack", "(", "(", "u", ",", "v", ")", ")", "\n", "# print('--->U.shape: ', U.shape", "\n", "# print('U:\\n', U", "\n", "\n", "# We know that X * r = U", "\n", "if", "rank", "(", "X", ")", ">=", "2", "*", "K", ":", "\n", "        ", "r", ",", "_", ",", "_", ",", "_", "=", "lstsq", "(", "X", ",", "U", ")", "\n", "r", "=", "np", ".", "squeeze", "(", "r", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"cp2tform: two Unique Points Req\"", ")", "\n", "\n", "# print('--->r:\\n', r", "\n", "\n", "", "sc", "=", "r", "[", "0", "]", "\n", "ss", "=", "r", "[", "1", "]", "\n", "tx", "=", "r", "[", "2", "]", "\n", "ty", "=", "r", "[", "3", "]", "\n", "\n", "Tinv", "=", "np", ".", "array", "(", "[", "\n", "[", "sc", ",", "-", "ss", ",", "0", "]", ",", "\n", "[", "ss", ",", "sc", ",", "0", "]", ",", "\n", "[", "tx", ",", "ty", ",", "1", "]", "\n", "]", ")", "\n", "\n", "# print('--->Tinv:\\n', Tinv", "\n", "\n", "T", "=", "inv", "(", "Tinv", ")", "\n", "# print('--->T:\\n', T", "\n", "\n", "T", "[", ":", ",", "2", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", "]", ")", "\n", "\n", "return", "T", ",", "Tinv", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findSimilarity": [[112, 151], ["matlab_cp2tform.findNonreflectiveSimilarity", "matlab_cp2tform.findNonreflectiveSimilarity", "numpy.array", "numpy.dot", "matlab_cp2tform.tformfwd", "numpy.linalg.norm", "matlab_cp2tform.tformfwd", "numpy.linalg.norm", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findNonreflectiveSimilarity", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findNonreflectiveSimilarity", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.tformfwd", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.tformfwd"], ["", "def", "findSimilarity", "(", "uv", ",", "xy", ",", "options", "=", "None", ")", ":", "\n", "\n", "    ", "options", "=", "{", "'K'", ":", "2", "}", "\n", "\n", "#    uv = np.array(uv)", "\n", "#    xy = np.array(xy)", "\n", "\n", "# Solve for trans1", "\n", "trans1", ",", "trans1_inv", "=", "findNonreflectiveSimilarity", "(", "uv", ",", "xy", ",", "options", ")", "\n", "\n", "# Solve for trans2", "\n", "\n", "# manually reflect the xy data across the Y-axis", "\n", "xyR", "=", "xy", "\n", "xyR", "[", ":", ",", "0", "]", "=", "-", "1", "*", "xyR", "[", ":", ",", "0", "]", "\n", "\n", "trans2r", ",", "trans2r_inv", "=", "findNonreflectiveSimilarity", "(", "uv", ",", "xyR", ",", "options", ")", "\n", "\n", "# manually reflect the tform to undo the reflection done on xyR", "\n", "TreflectY", "=", "np", ".", "array", "(", "[", "\n", "[", "-", "1", ",", "0", ",", "0", "]", ",", "\n", "[", "0", ",", "1", ",", "0", "]", ",", "\n", "[", "0", ",", "0", ",", "1", "]", "\n", "]", ")", "\n", "\n", "trans2", "=", "np", ".", "dot", "(", "trans2r", ",", "TreflectY", ")", "\n", "\n", "# Figure out if trans1 or trans2 is better", "\n", "xy1", "=", "tformfwd", "(", "trans1", ",", "uv", ")", "\n", "norm1", "=", "norm", "(", "xy1", "-", "xy", ")", "\n", "\n", "xy2", "=", "tformfwd", "(", "trans2", ",", "uv", ")", "\n", "norm2", "=", "norm", "(", "xy2", "-", "xy", ")", "\n", "\n", "if", "norm1", "<=", "norm2", ":", "\n", "        ", "return", "trans1", ",", "trans1_inv", "\n", "", "else", ":", "\n", "        ", "trans2_inv", "=", "inv", "(", "trans2", ")", "\n", "return", "trans2", ",", "trans2_inv", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.get_similarity_transform": [[153, 191], ["matlab_cp2tform.findSimilarity", "matlab_cp2tform.findNonreflectiveSimilarity"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findSimilarity", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.findNonreflectiveSimilarity"], ["", "", "def", "get_similarity_transform", "(", "src_pts", ",", "dst_pts", ",", "reflective", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        Find Similarity Transform Matrix 'trans':\n            u = src_pts[:, 0]\n            v = src_pts[:, 1]\n            x = dst_pts[:, 0]\n            y = dst_pts[:, 1]\n            [x, y, 1] = [u, v, 1] * trans\n\n    Parameters:\n    ----------\n        @src_pts: Kx2 np.array\n            source points, each row is a pair of coordinates (x, y)\n        @dst_pts: Kx2 np.array\n            destination points, each row is a pair of transformed\n            coordinates (x, y)\n        @reflective: True or False\n            if True:\n                use reflective similarity transform\n            else:\n                use non-reflective similarity transform\n\n    Returns:\n    ----------\n       @trans: 3x3 np.array\n            transform matrix from uv to xy\n        trans_inv: 3x3 np.array\n            inverse of trans, transform matrix from xy to uv\n    \"\"\"", "\n", "\n", "if", "reflective", ":", "\n", "        ", "trans", ",", "trans_inv", "=", "findSimilarity", "(", "src_pts", ",", "dst_pts", ")", "\n", "", "else", ":", "\n", "        ", "trans", ",", "trans_inv", "=", "findNonreflectiveSimilarity", "(", "src_pts", ",", "dst_pts", ")", "\n", "\n", "", "return", "trans", ",", "trans_inv", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.cvt_tform_mat_for_cv2": [[193, 219], ["None"], "function", ["None"], ["", "def", "cvt_tform_mat_for_cv2", "(", "trans", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        Convert Transform Matrix 'trans' into 'cv2_trans' which could be\n        directly used by cv2.warpAffine():\n            u = src_pts[:, 0]\n            v = src_pts[:, 1]\n            x = dst_pts[:, 0]\n            y = dst_pts[:, 1]\n            [x, y].T = cv_trans * [u, v, 1].T\n\n    Parameters:\n    ----------\n        @trans: 3x3 np.array\n            transform matrix from uv to xy\n\n    Returns:\n    ----------\n        @cv2_trans: 2x3 np.array\n            transform matrix from src_pts to dst_pts, could be directly used\n            for cv2.warpAffine()\n    \"\"\"", "\n", "cv2_trans", "=", "trans", "[", ":", ",", "0", ":", "2", "]", ".", "T", "\n", "\n", "return", "cv2_trans", "\n", "\n"]], "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.get_similarity_transform_for_cv2": [[221, 256], ["matlab_cp2tform.get_similarity_transform", "matlab_cp2tform.cvt_tform_mat_for_cv2"], "function", ["home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.get_similarity_transform", "home.repos.pwc.inspect_result.haibo-qiu_SynFace.imgs_crop.matlab_cp2tform.cvt_tform_mat_for_cv2"], ["", "def", "get_similarity_transform_for_cv2", "(", "src_pts", ",", "dst_pts", ",", "reflective", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Function:\n    ----------\n        Find Similarity Transform Matrix 'cv2_trans' which could be\n        directly used by cv2.warpAffine():\n            u = src_pts[:, 0]\n            v = src_pts[:, 1]\n            x = dst_pts[:, 0]\n            y = dst_pts[:, 1]\n            [x, y].T = cv_trans * [u, v, 1].T\n\n    Parameters:\n    ----------\n        @src_pts: Kx2 np.array\n            source points, each row is a pair of coordinates (x, y)\n        @dst_pts: Kx2 np.array\n            destination points, each row is a pair of transformed\n            coordinates (x, y)\n        reflective: True or False\n            if True:\n                use reflective similarity transform\n            else:\n                use non-reflective similarity transform\n\n    Returns:\n    ----------\n        @cv2_trans: 2x3 np.array\n            transform matrix from src_pts to dst_pts, could be directly used\n            for cv2.warpAffine()\n    \"\"\"", "\n", "trans", ",", "trans_inv", "=", "get_similarity_transform", "(", "src_pts", ",", "dst_pts", ",", "reflective", ")", "\n", "cv2_trans", "=", "cvt_tform_mat_for_cv2", "(", "trans", ")", "\n", "\n", "return", "cv2_trans", "\n", "\n"]]}