{"home.repos.pwc.inspect_result.mikahama_murre.murre.generator.UnknownDialectException.__init__": [[17, 19], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.mikahama_murre.murre.generator.UnknownDialectException.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "super", "(", "UnknownDialectException", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._chunks": [[29, 33], ["range", "len"], "function", ["None"], ["def", "_chunks", "(", "l", ",", "n", ")", ":", "\n", "\t", "\"\"\"Yield successive n-sized chunks from l.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", ":", "\n", "\t\t", "yield", "l", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator.generate": [[34, 57], ["dialects.supported_dialects", "generator.UnknownDialectException", "isinstance", "generator._chunks", "generator._translate", "zip", "res.append", "sentence.split.split", "r_part.split", "o_part.split", "r.append", "r.replace", "len", "len", "dialects.supported_dialects", "len"], "function", ["home.repos.pwc.inspect_result.mikahama_murre.murre.dialects.supported_dialects", "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._chunks", "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._translate", "home.repos.pwc.inspect_result.mikahama_murre.murre.dialects.supported_dialects"], ["", "", "def", "generate", "(", "sentences", ",", "dialect", ")", ":", "\n", "\t", "if", "dialect", "not", "in", "supported_dialects", "(", ")", ":", "\n", "\t\t", "raise", "UnknownDialectException", "(", "dialect", "+", "\" is not a supported dialect! The supported dialects are: \"", "+", "\", \"", ".", "join", "(", "supported_dialects", "(", ")", ")", ")", "\n", "", "res", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "\t\t", "if", "isinstance", "(", "sentence", ",", "str", ")", ":", "\n", "\t\t\t", "sentence", "=", "sentence", ".", "split", "(", "\" \"", ")", "\n", "", "s", "=", "[", "\" \"", ".", "join", "(", "w", ")", "for", "w", "in", "sentence", "]", "\n", "chunks", "=", "_chunks", "(", "s", ",", "3", ")", "\n", "parts", "=", "[", "dialect", "+", "\" \"", "+", "\" _ \"", ".", "join", "(", "x", ")", ".", "lower", "(", ")", "for", "x", "in", "chunks", "]", "\n", "r_parts", "=", "_translate", "(", "parts", ")", "\n", "r", "=", "[", "]", "\n", "for", "r_part", ",", "o_part", "in", "zip", "(", "r_parts", ",", "parts", ")", ":", "\n", "\t\t\t", "res_tokens", "=", "r_part", ".", "split", "(", "\"_\"", ")", "\n", "o_tokens", "=", "o_part", ".", "split", "(", "\"_\"", ")", "\n", "if", "len", "(", "res_tokens", ")", ">", "len", "(", "o_tokens", ")", ":", "\n", "\t\t\t\t", "res_tokens", "=", "res_tokens", "[", ":", "len", "(", "o_tokens", ")", "]", "\n", "", "r", ".", "append", "(", "\"_\"", ".", "join", "(", "res_tokens", ")", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ")", "\n", "\n", "\n", "", "r", "=", "\"_\"", ".", "join", "(", "r", ")", "\n", "res", ".", "append", "(", "r", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._load_model": [[59, 64], ["tensorflow.saved_model.load", "pyonmttok.Tokenizer", "script_path"], "function", ["None"], ["", "def", "_load_model", "(", ")", ":", "\n", "\t", "global", "model", "\n", "global", "tokenizer", "\n", "model", "=", "tf", ".", "saved_model", ".", "load", "(", "script_path", "(", "\"models/generate/flags_dist\"", ")", ")", "\n", "tokenizer", "=", "pyonmttok", ".", "Tokenizer", "(", "\"none\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._translate": [[66, 74], ["generator._preprocess", "_translate_fn", "generator._postprocess", "generator._load_model"], "function", ["home.repos.pwc.inspect_result.mikahama_murre.murre.generator._preprocess", "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._postprocess", "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._load_model"], ["", "def", "_translate", "(", "texts", ")", ":", "\n", "\t", "if", "model", "is", "None", ":", "\n", "\t\t", "_load_model", "(", ")", "\n", "", "_translate_fn", "=", "model", ".", "signatures", "[", "\"serving_default\"", "]", "\n", "\n", "inputs", "=", "_preprocess", "(", "texts", ")", "\n", "outputs", "=", "_translate_fn", "(", "**", "inputs", ")", "\n", "return", "_postprocess", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._preprocess": [[75, 93], ["zip", "text.split", "len", "all_tokens.append", "lengths.append", "max", "tensorflow.constant", "tensorflow.constant"], "function", ["None"], ["", "def", "_preprocess", "(", "texts", ")", ":", "\n", "\t", "all_tokens", "=", "[", "]", "\n", "lengths", "=", "[", "]", "\n", "max_length", "=", "0", "\n", "for", "text", "in", "texts", ":", "\n", "\t\t", "tokens", "=", "text", ".", "split", "(", "\" \"", ")", "\n", "length", "=", "len", "(", "tokens", ")", "\n", "all_tokens", ".", "append", "(", "tokens", ")", "\n", "lengths", ".", "append", "(", "length", ")", "\n", "max_length", "=", "max", "(", "max_length", ",", "length", ")", "\n", "", "for", "tokens", ",", "length", "in", "zip", "(", "all_tokens", ",", "lengths", ")", ":", "\n", "\t\t", "if", "length", "<", "max_length", ":", "\n", "\t\t\t", "tokens", "+=", "[", "\"\"", "]", "*", "(", "max_length", "-", "length", ")", "\n", "\n", "", "", "inputs", "=", "{", "\n", "\"tokens\"", ":", "tf", ".", "constant", "(", "all_tokens", ",", "dtype", "=", "tf", ".", "string", ")", ",", "\n", "\"length\"", ":", "tf", ".", "constant", "(", "lengths", ",", "dtype", "=", "tf", ".", "int32", ")", "}", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.generator._postprocess": [[94, 100], ["zip", "outputs[].numpy", "outputs[].numpy", "[].tolist", "texts.append", "tokenizer.detokenize"], "function", ["None"], ["", "def", "_postprocess", "(", "outputs", ")", ":", "\n", "\t", "texts", "=", "[", "]", "\n", "for", "tokens", ",", "length", "in", "zip", "(", "outputs", "[", "\"tokens\"", "]", ".", "numpy", "(", ")", ",", "outputs", "[", "\"length\"", "]", ".", "numpy", "(", ")", ")", ":", "\n", "\t\t", "tokens", "=", "tokens", "[", "0", "]", "[", ":", "length", "[", "0", "]", "]", ".", "tolist", "(", ")", "\n", "texts", ".", "append", "(", "tokenizer", ".", "detokenize", "(", "tokens", ")", ")", "\n", "", "return", "texts", "", "", ""]], "home.repos.pwc.inspect_result.mikahama_murre.murre.download.main": [[4, 16], ["enumerate", "os.makedirs", "os.makedirs", "enumerate", "print", "download_file", "script_path", "script_path", "print", "download_file", "len", "script_path", "len", "script_path"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "\t", "url", "=", "\"https://github.com/mikahama/murre/raw/master/murre/models/\"", "\n", "models", "=", "[", "\"murre_norm_default.pt\"", ",", "\"murre_norm_paper.pt\"", ",", "\"swedish_normalization.pt\"", ",", "\"agricola.pt\"", "]", "\n", "for", "i", ",", "model", "in", "enumerate", "(", "models", ")", ":", "\n", "\t\t", "print", "(", "\"Downloading normalizer \"", ",", "i", "+", "1", ",", "\"out of\"", ",", "len", "(", "models", ")", ")", "\n", "download_file", "(", "url", "+", "model", ",", "script_path", "(", "\"models/\"", "+", "model", ")", ",", "show_progress", "=", "True", ")", "\n", "", "files", "=", "[", "\"generate/flags_dist/saved_model.pb\"", ",", "\"generate/flags_dist/variables/variables.data-00000-of-00002\"", ",", "\"generate/flags_dist/variables/variables.data-00001-of-00002\"", ",", "\"generate/flags_dist/variables/variables.index\"", "]", "\n", "os", ".", "makedirs", "(", "script_path", "(", "\"models/generate/flags_dist/variables/\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "script_path", "(", "\"models/generate/flags_dist/assets/\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "for", "i", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "\t\t", "print", "(", "\"Downloading generator \"", ",", "i", "+", "1", ",", "\"out of\"", ",", "len", "(", "files", ")", ")", "\n", "download_file", "(", "url", "+", "file", ",", "script_path", "(", "\"models/\"", "+", "file", ")", ",", "show_progress", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.dialects.supported_dialects": [[27, 29], ["None"], "function", ["None"], ["def", "supported_dialects", "(", ")", ":", "\n", "    ", "return", "dialects", "", "", ""]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer.dummy_picker": [[4, 9], ["len"], "function", ["None"], ["def", "dummy_picker", "(", "list", ",", "current_index", ",", "original_tokens", ")", ":", "\n", "\t", "if", "len", "(", "list", ")", "==", "0", ":", "\n", "\t\t", "return", "\"\"", "\n", "", "else", ":", "\n", "\t\t", "return", "list", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._chunks": [[10, 13], ["max", "range", "len"], "function", ["None"], ["", "", "def", "_chunks", "(", "l", ",", "n", ")", ":", "\n", "\t", "n", "=", "max", "(", "1", ",", "n", ")", "\n", "return", "[", "l", "[", "i", ":", "i", "+", "n", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "l", ")", ",", "n", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._dechunk": [[14, 19], ["c.replace.replace", "best_picker", "enumerate", "y.replace"], "function", ["None"], ["", "def", "_dechunk", "(", "l", ",", "n_best", "=", "1", ",", "best_picker", "=", "dummy_picker", ",", "orig", "=", "[", "]", ")", ":", "\n", "\t", "c", "=", "[", "best_picker", "(", "[", "y", ".", "replace", "(", "\" \"", ",", "\"\"", ")", "for", "y", "in", "x", "]", ",", "i", ",", "orig", ")", "for", "i", ",", "x", "in", "enumerate", "(", "l", ")", "]", "\n", "c", "=", "\"_\"", ".", "join", "(", "c", ")", "\n", "c", "=", "c", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer.normalize_sentences": [[20, 51], ["enumerate", "normalizer._normalize_chunks", "enumerate", "normalized_sentences.append", "isinstance", "normalizer._chunks", "normalizer._dechunk", "tokenized_sentence.split.split", "chunks.append", "sentence_map.append", "normalized_sentences.append", "norm.append", "zip"], "function", ["home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._normalize_chunks", "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._chunks", "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._dechunk"], ["", "def", "normalize_sentences", "(", "tokenized_sentences", ",", "wnut19_model", "=", "False", ",", "model_path", "=", "None", ",", "chunk_size", "=", "3", ",", "n_best", "=", "1", ",", "best_picker", "=", "dummy_picker", ",", "language", "=", "\"fin\"", ")", ":", "\n", "\t", "if", "language", "==", "\"swe\"", ":", "\n", "\t\t", "chunk_size", "=", "1", "\n", "", "elif", "language", "==", "\"fin_hist\"", ":", "\n", "\t\t", "chunk_size", "=", "3", "\n", "", "chunks", "=", "[", "]", "\n", "sentence_map", "=", "[", "]", "\n", "for", "i", ",", "tokenized_sentence", "in", "enumerate", "(", "tokenized_sentences", ")", ":", "\n", "\t\t", "if", "isinstance", "(", "tokenized_sentence", ",", "str", ")", ":", "\n", "\t\t\t", "tokenized_sentence", "=", "tokenized_sentence", ".", "split", "(", "\" \"", ")", "\n", "tokenized_sentences", "[", "i", "]", "=", "tokenized_sentence", "\n", "", "chunks_l", "=", "_chunks", "(", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "tokenized_sentence", "]", ",", "chunk_size", ")", "\n", "sent_chunks", "=", "[", "\" _ \"", ".", "join", "(", "x", ")", "for", "x", "in", "chunks_l", "]", "\n", "for", "c", "in", "sent_chunks", ":", "\n", "\t\t\t", "chunks", ".", "append", "(", "c", ")", "\n", "sentence_map", ".", "append", "(", "i", ")", "\n", "", "", "res", "=", "_normalize_chunks", "(", "chunks", ",", "wnut19_model", "=", "wnut19_model", ",", "model_path", "=", "model_path", ",", "n_best", "=", "n_best", ",", "language", "=", "language", ")", "\n", "normalized_sentences", "=", "[", "]", "\n", "cur", "=", "0", "\n", "norm", "=", "[", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "res", ")", ":", "\n", "\t\t", "sent_i", "=", "sentence_map", "[", "i", "]", "\n", "if", "sent_i", "!=", "cur", ":", "\n", "\t\t\t", "cur", "=", "sent_i", "\n", "normalized_sentences", ".", "append", "(", "norm", ")", "\n", "norm", "=", "[", "]", "\n", "", "if", "sent_i", "==", "cur", ":", "\n", "\t\t\t", "norm", ".", "append", "(", "s", ")", "\n", "", "", "normalized_sentences", ".", "append", "(", "norm", ")", "\n", "r", "=", "[", "_dechunk", "(", "x", ",", "n_best", "=", "n_best", ",", "best_picker", "=", "best_picker", ",", "orig", "=", "y", ")", "for", "x", ",", "y", "in", "zip", "(", "normalized_sentences", ",", "tokenized_sentences", ")", "]", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer.normalize_sentence": [[55, 66], ["isinstance", "normalizer._chunks", "normalizer._normalize_chunks", "normalizer._dechunk", "tokens.split.split"], "function", ["home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._chunks", "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._normalize_chunks", "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._dechunk"], ["", "def", "normalize_sentence", "(", "tokens", ",", "wnut19_model", "=", "False", ",", "model_path", "=", "None", ",", "chunk_size", "=", "3", ",", "n_best", "=", "1", ",", "best_picker", "=", "dummy_picker", ",", "language", "=", "\"fin\"", ")", ":", "\n", "\t", "if", "language", "==", "\"swe\"", ":", "\n", "\t\t", "chunk_size", "=", "1", "\n", "", "elif", "language", "==", "\"fin_hist\"", ":", "\n", "\t\t", "chunk_size", "=", "3", "\n", "", "if", "isinstance", "(", "tokens", ",", "str", ")", ":", "\n", "\t\t", "tokens", "=", "tokens", ".", "split", "(", "\" \"", ")", "\n", "", "chunks_l", "=", "_chunks", "(", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "tokens", "]", ",", "chunk_size", ")", "\n", "chunks", "=", "[", "\" _ \"", ".", "join", "(", "x", ")", "for", "x", "in", "chunks_l", "]", "\n", "res", "=", "_normalize_chunks", "(", "chunks", ",", "wnut19_model", "=", "wnut19_model", ",", "model_path", "=", "model_path", ",", "n_best", "=", "n_best", ",", "language", "=", "language", ")", "\n", "return", "_dechunk", "(", "res", ",", "n_best", "=", "n_best", ",", "best_picker", "=", "best_picker", ",", "orig", "=", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mikahama_murre.murre.normalizer._normalize_chunks": [[67, 87], ["natas.normalize.call_onmt", "script_path", "script_path", "script_path", "script_path"], "function", ["None"], ["", "def", "_normalize_chunks", "(", "chunks", ",", "wnut19_model", "=", "False", ",", "model_path", "=", "None", ",", "n_best", "=", "1", ",", "language", "=", "\"fin\"", ")", ":", "\n", "\t", "if", "model_path", ":", "\n", "\t\t", "model_name", "=", "model_path", "\n", "", "elif", "wnut19_model", ":", "\n", "#New default model, might not work on some systems", "\n", "\t\t", "model_name", "=", "\"murre_norm_paper.pt\"", "\n", "model_name", "=", "script_path", "(", "\"models/\"", "+", "model_name", ")", "\n", "", "elif", "language", "==", "\"swe\"", ":", "\n", "\t\t", "model_name", "=", "\"swedish_normalization.pt\"", "\n", "model_name", "=", "script_path", "(", "\"models/\"", "+", "model_name", ")", "\n", "", "elif", "language", "==", "\"fin_hist\"", ":", "\n", "\t\t", "model_name", "=", "\"agricola.pt\"", "\n", "model_name", "=", "script_path", "(", "\"models/\"", "+", "model_name", ")", "\n", "", "else", ":", "\n", "#Same model trained on MacOS, slightly higher character error rate", "\n", "\t\t", "model_name", "=", "\"murre_norm_default.pt\"", "\n", "model_name", "=", "script_path", "(", "\"models/\"", "+", "model_name", ")", "\n", "\n", "", "res", "=", "call_onmt", "(", "chunks", ",", "model_name", ",", "n_best", "=", "n_best", ")", "\n", "return", "res", "", "", ""]], "home.repos.pwc.inspect_result.mikahama_murre.murre.__init__.dialectalize_sentence": [[5, 7], ["generator.generate"], "function", ["home.repos.pwc.inspect_result.mikahama_murre.murre.generator.generate"], ["def", "dialectalize_sentence", "(", "sentence", ",", "dialect", ")", ":", "\n", "\t", "return", "dialectalize_sentences", "(", "[", "sentence", "]", ",", "dialect", ")", "[", "0", "]", "", "", ""]]}