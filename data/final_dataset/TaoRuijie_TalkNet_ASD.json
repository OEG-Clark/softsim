{"home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.train_loader.__init__": [[90, 105], ["open().read().splitlines", "sorted", "int", "min", "dataLoader.train_loader.miniBatch.append", "open().read", "len", "len", "sortedMixLst[].split", "max", "open", "int", "int", "int", "data.split", "data.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trialFileName", ",", "audioPath", ",", "visualPath", ",", "batchSize", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "audioPath", "=", "audioPath", "\n", "self", ".", "visualPath", "=", "visualPath", "\n", "self", ".", "miniBatch", "=", "[", "]", "\n", "mixLst", "=", "open", "(", "trialFileName", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "# sort the training set by the length of the videos, shuffle them to make more videos in the same batch belong to different movies", "\n", "sortedMixLst", "=", "sorted", "(", "mixLst", ",", "key", "=", "lambda", "data", ":", "(", "int", "(", "data", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ")", ",", "int", "(", "data", ".", "split", "(", "'\\t'", ")", "[", "-", "1", "]", ")", ")", ",", "reverse", "=", "True", ")", "\n", "start", "=", "0", "\n", "while", "True", ":", "\n", "          ", "length", "=", "int", "(", "sortedMixLst", "[", "start", "]", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ")", "\n", "end", "=", "min", "(", "len", "(", "sortedMixLst", ")", ",", "start", "+", "max", "(", "int", "(", "batchSize", "/", "length", ")", ",", "1", ")", ")", "\n", "self", ".", "miniBatch", ".", "append", "(", "sortedMixLst", "[", "start", ":", "end", "]", ")", "\n", "if", "end", "==", "len", "(", "sortedMixLst", ")", ":", "\n", "              ", "break", "\n", "", "start", "=", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.train_loader.__getitem__": [[106, 119], ["int", "dataLoader.generate_audio_set", "line.split", "audioFeatures.append", "visualFeatures.append", "labels.append", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "batchList[].split", "dataLoader.load_audio", "dataLoader.load_visual", "dataLoader.load_label", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.generate_audio_set", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_audio", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_visual", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_label"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "batchList", "=", "self", ".", "miniBatch", "[", "index", "]", "\n", "numFrames", "=", "int", "(", "batchList", "[", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ")", "\n", "audioFeatures", ",", "visualFeatures", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "audioSet", "=", "generate_audio_set", "(", "self", ".", "audioPath", ",", "batchList", ")", "# load the audios in this batch to do augmentation", "\n", "for", "line", "in", "batchList", ":", "\n", "            ", "data", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "audioFeatures", ".", "append", "(", "load_audio", "(", "data", ",", "self", ".", "audioPath", ",", "numFrames", ",", "audioAug", "=", "True", ",", "audioSet", "=", "audioSet", ")", ")", "\n", "visualFeatures", ".", "append", "(", "load_visual", "(", "data", ",", "self", ".", "visualPath", ",", "numFrames", ",", "visualAug", "=", "True", ")", ")", "\n", "labels", ".", "append", "(", "load_label", "(", "data", ",", "numFrames", ")", ")", "\n", "", "return", "torch", ".", "FloatTensor", "(", "numpy", ".", "array", "(", "audioFeatures", ")", ")", ",", "torch", ".", "FloatTensor", "(", "numpy", ".", "array", "(", "visualFeatures", ")", ")", ",", "torch", ".", "LongTensor", "(", "numpy", ".", "array", "(", "labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.train_loader.__len__": [[120, 122], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "miniBatch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.val_loader.__init__": [[125, 129], ["open().read().splitlines", "open().read", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trialFileName", ",", "audioPath", ",", "visualPath", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "audioPath", "=", "audioPath", "\n", "self", ".", "visualPath", "=", "visualPath", "\n", "self", ".", "miniBatch", "=", "open", "(", "trialFileName", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.val_loader.__getitem__": [[130, 141], ["int", "dataLoader.generate_audio_set", "line[].split", "dataLoader.load_audio", "dataLoader.load_visual", "dataLoader.load_label", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "line[].split", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.generate_audio_set", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_audio", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_visual", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_label"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "line", "=", "[", "self", ".", "miniBatch", "[", "index", "]", "]", "\n", "numFrames", "=", "int", "(", "line", "[", "0", "]", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ")", "\n", "audioSet", "=", "generate_audio_set", "(", "self", ".", "audioPath", ",", "line", ")", "\n", "data", "=", "line", "[", "0", "]", ".", "split", "(", "'\\t'", ")", "\n", "audioFeatures", "=", "[", "load_audio", "(", "data", ",", "self", ".", "audioPath", ",", "numFrames", ",", "audioAug", "=", "False", ",", "audioSet", "=", "audioSet", ")", "]", "\n", "visualFeatures", "=", "[", "load_visual", "(", "data", ",", "self", ".", "visualPath", ",", "numFrames", ",", "visualAug", "=", "False", ")", "]", "\n", "labels", "=", "[", "load_label", "(", "data", ",", "numFrames", ")", "]", "\n", "return", "torch", ".", "FloatTensor", "(", "numpy", ".", "array", "(", "audioFeatures", ")", ")", ",", "torch", ".", "FloatTensor", "(", "numpy", ".", "array", "(", "visualFeatures", ")", ")", ",", "torch", ".", "LongTensor", "(", "numpy", ".", "array", "(", "labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.val_loader.__len__": [[142, 144], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "miniBatch", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.generate_audio_set": [[5, 14], ["line.split", "scipy.io.wavfile.read", "os.path.join"], "function", ["None"], ["def", "generate_audio_set", "(", "dataPath", ",", "batchList", ")", ":", "\n", "    ", "audioSet", "=", "{", "}", "\n", "for", "line", "in", "batchList", ":", "\n", "        ", "data", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "videoName", "=", "data", "[", "0", "]", "[", ":", "11", "]", "\n", "dataName", "=", "data", "[", "0", "]", "\n", "_", ",", "audio", "=", "wavfile", ".", "read", "(", "os", ".", "path", ".", "join", "(", "dataPath", ",", "videoName", ",", "dataName", "+", "'.wav'", ")", ")", "\n", "audioSet", "[", "dataName", "]", "=", "audio", "\n", "", "return", "audioSet", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.overlap": [[15, 29], ["audio.astype", "random.sample", "random.uniform", "len", "len", "numpy.pad", "numpy.log10", "numpy.log10", "numpy.sqrt", "len", "len", "set", "len", "numpy.mean", "numpy.mean", "list", "abs", "abs", "audioSet.keys"], "function", ["None"], ["", "def", "overlap", "(", "dataName", ",", "audio", ",", "audioSet", ")", ":", "\n", "    ", "noiseName", "=", "random", ".", "sample", "(", "set", "(", "list", "(", "audioSet", ".", "keys", "(", ")", ")", ")", "-", "{", "dataName", "}", ",", "1", ")", "[", "0", "]", "\n", "noiseAudio", "=", "audioSet", "[", "noiseName", "]", "\n", "snr", "=", "[", "random", ".", "uniform", "(", "-", "5", ",", "5", ")", "]", "\n", "if", "len", "(", "noiseAudio", ")", "<", "len", "(", "audio", ")", ":", "\n", "        ", "shortage", "=", "len", "(", "audio", ")", "-", "len", "(", "noiseAudio", ")", "\n", "noiseAudio", "=", "numpy", ".", "pad", "(", "noiseAudio", ",", "(", "0", ",", "shortage", ")", ",", "'wrap'", ")", "\n", "", "else", ":", "\n", "        ", "noiseAudio", "=", "noiseAudio", "[", ":", "len", "(", "audio", ")", "]", "\n", "", "noiseDB", "=", "10", "*", "numpy", ".", "log10", "(", "numpy", ".", "mean", "(", "abs", "(", "noiseAudio", "**", "2", ")", ")", "+", "1e-4", ")", "\n", "cleanDB", "=", "10", "*", "numpy", ".", "log10", "(", "numpy", ".", "mean", "(", "abs", "(", "audio", "**", "2", ")", ")", "+", "1e-4", ")", "\n", "noiseAudio", "=", "numpy", ".", "sqrt", "(", "10", "**", "(", "(", "cleanDB", "-", "noiseDB", "-", "snr", ")", "/", "10", ")", ")", "*", "noiseAudio", "\n", "audio", "=", "audio", "+", "noiseAudio", "\n", "return", "audio", ".", "astype", "(", "numpy", ".", "int16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_audio": [[30, 48], ["float", "python_speech_features.mfcc", "int", "random.randint", "numpy.pad", "dataLoader.overlap", "int", "round"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.overlap"], ["", "def", "load_audio", "(", "data", ",", "dataPath", ",", "numFrames", ",", "audioAug", ",", "audioSet", "=", "None", ")", ":", "\n", "    ", "dataName", "=", "data", "[", "0", "]", "\n", "fps", "=", "float", "(", "data", "[", "2", "]", ")", "\n", "audio", "=", "audioSet", "[", "dataName", "]", "\n", "if", "audioAug", "==", "True", ":", "\n", "        ", "augType", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "if", "augType", "==", "1", ":", "\n", "            ", "audio", "=", "overlap", "(", "dataName", ",", "audio", ",", "audioSet", ")", "\n", "", "else", ":", "\n", "            ", "audio", "=", "audio", "\n", "# fps is not always 25, in order to align the visual, we modify the window and step in MFCC extraction process based on fps", "\n", "", "", "audio", "=", "python_speech_features", ".", "mfcc", "(", "audio", ",", "16000", ",", "numcep", "=", "13", ",", "winlen", "=", "0.025", "*", "25", "/", "fps", ",", "winstep", "=", "0.010", "*", "25", "/", "fps", ")", "\n", "maxAudio", "=", "int", "(", "numFrames", "*", "4", ")", "\n", "if", "audio", ".", "shape", "[", "0", "]", "<", "maxAudio", ":", "\n", "        ", "shortage", "=", "maxAudio", "-", "audio", ".", "shape", "[", "0", "]", "\n", "audio", "=", "numpy", ".", "pad", "(", "audio", ",", "(", "(", "0", ",", "shortage", ")", ",", "(", "0", ",", "0", ")", ")", ",", "'wrap'", ")", "\n", "", "audio", "=", "audio", "[", ":", "int", "(", "round", "(", "numFrames", "*", "4", ")", ")", ",", ":", "]", "\n", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_visual": [[49, 78], ["os.path.join", "glob.glob", "sorted", "numpy.array", "int", "cv2.getRotationMatrix2D", "random.choice", "cv2.imread", "cv2.cvtColor", "cv2.resize", "numpy.random.randint", "numpy.random.randint", "random.uniform", "numpy.array.append", "float", "random.uniform", "numpy.array.append", "cv2.flip", "numpy.array.append", "cv2.resize", "numpy.array.append", "data.split", "cv2.warpAffine"], "function", ["None"], ["", "def", "load_visual", "(", "data", ",", "dataPath", ",", "numFrames", ",", "visualAug", ")", ":", "\n", "    ", "dataName", "=", "data", "[", "0", "]", "\n", "videoName", "=", "data", "[", "0", "]", "[", ":", "11", "]", "\n", "faceFolderPath", "=", "os", ".", "path", ".", "join", "(", "dataPath", ",", "videoName", ",", "dataName", ")", "\n", "faceFiles", "=", "glob", ".", "glob", "(", "\"%s/*.jpg\"", "%", "faceFolderPath", ")", "\n", "sortedFaceFiles", "=", "sorted", "(", "faceFiles", ",", "key", "=", "lambda", "data", ":", "(", "float", "(", "data", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", ")", ",", "reverse", "=", "False", ")", "\n", "faces", "=", "[", "]", "\n", "H", "=", "112", "\n", "if", "visualAug", "==", "True", ":", "\n", "        ", "new", "=", "int", "(", "H", "*", "random", ".", "uniform", "(", "0.7", ",", "1", ")", ")", "\n", "x", ",", "y", "=", "numpy", ".", "random", ".", "randint", "(", "0", ",", "H", "-", "new", ")", ",", "numpy", ".", "random", ".", "randint", "(", "0", ",", "H", "-", "new", ")", "\n", "M", "=", "cv2", ".", "getRotationMatrix2D", "(", "(", "H", "/", "2", ",", "H", "/", "2", ")", ",", "random", ".", "uniform", "(", "-", "15", ",", "15", ")", ",", "1", ")", "\n", "augType", "=", "random", ".", "choice", "(", "[", "'orig'", ",", "'flip'", ",", "'crop'", ",", "'rotate'", "]", ")", "\n", "", "else", ":", "\n", "        ", "augType", "=", "'orig'", "\n", "", "for", "faceFile", "in", "sortedFaceFiles", "[", ":", "numFrames", "]", ":", "\n", "        ", "face", "=", "cv2", ".", "imread", "(", "faceFile", ")", "\n", "face", "=", "cv2", ".", "cvtColor", "(", "face", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "face", "=", "cv2", ".", "resize", "(", "face", ",", "(", "H", ",", "H", ")", ")", "\n", "if", "augType", "==", "'orig'", ":", "\n", "            ", "faces", ".", "append", "(", "face", ")", "\n", "", "elif", "augType", "==", "'flip'", ":", "\n", "            ", "faces", ".", "append", "(", "cv2", ".", "flip", "(", "face", ",", "1", ")", ")", "\n", "", "elif", "augType", "==", "'crop'", ":", "\n", "            ", "faces", ".", "append", "(", "cv2", ".", "resize", "(", "face", "[", "y", ":", "y", "+", "new", ",", "x", ":", "x", "+", "new", "]", ",", "(", "H", ",", "H", ")", ")", ")", "\n", "", "elif", "augType", "==", "'rotate'", ":", "\n", "            ", "faces", ".", "append", "(", "cv2", ".", "warpAffine", "(", "face", ",", "M", ",", "(", "H", ",", "H", ")", ")", ")", "\n", "", "", "faces", "=", "numpy", ".", "array", "(", "faces", ")", "\n", "return", "faces", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.load_label": [[80, 88], ["data[].replace().replace", "labels.split.split", "numpy.array", "numpy.array.append", "data[].replace", "int"], "function", ["None"], ["", "def", "load_label", "(", "data", ",", "numFrames", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "labels", "=", "data", "[", "3", "]", ".", "replace", "(", "'['", ",", "''", ")", ".", "replace", "(", "']'", ",", "''", ")", "\n", "labels", "=", "labels", ".", "split", "(", "','", ")", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "res", ".", "append", "(", "int", "(", "label", ")", ")", "\n", "", "res", "=", "numpy", ".", "array", "(", "res", "[", ":", "numFrames", "]", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossAV.__init__": [[6, 10], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "super", "(", "lossAV", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "FC", "=", "nn", ".", "Linear", "(", "256", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossAV.forward": [[11, 25], ["loss.lossAV.squeeze", "loss.lossAV.FC", "torch.softmax.t", "torch.softmax.view().detach().cpu().numpy", "loss.lossAV.criterion", "torch.softmax", "torch.softmax", "torch.softmax", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.softmax.view().detach().cpu", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.view().detach", "torch.softmax.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "labels", "=", "None", ")", ":", "\n", "\t\t", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "self", ".", "FC", "(", "x", ")", "\n", "if", "labels", "==", "None", ":", "\n", "\t\t\t", "predScore", "=", "x", "[", ":", ",", "1", "]", "\n", "predScore", "=", "predScore", ".", "t", "(", ")", "\n", "predScore", "=", "predScore", ".", "view", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "predScore", "\n", "", "else", ":", "\n", "\t\t\t", "nloss", "=", "self", ".", "criterion", "(", "x", ",", "labels", ")", "\n", "predScore", "=", "F", ".", "softmax", "(", "x", ",", "dim", "=", "-", "1", ")", "\n", "predLabel", "=", "torch", ".", "round", "(", "F", ".", "softmax", "(", "x", ",", "dim", "=", "-", "1", ")", ")", "[", ":", ",", "1", "]", "\n", "correctNum", "=", "(", "predLabel", "==", "labels", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "\n", "return", "nloss", ",", "predScore", ",", "predLabel", ",", "correctNum", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossA.__init__": [[27, 31], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "super", "(", "lossA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "FC", "=", "nn", ".", "Linear", "(", "128", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossA.forward": [[32, 37], ["loss.lossA.squeeze", "loss.lossA.FC", "loss.lossA.criterion"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "labels", ")", ":", "\n", "\t\t", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "self", ".", "FC", "(", "x", ")", "\n", "nloss", "=", "self", ".", "criterion", "(", "x", ",", "labels", ")", "\n", "return", "nloss", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossV.__init__": [[39, 44], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "super", "(", "lossV", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "FC", "=", "nn", ".", "Linear", "(", "128", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.loss.lossV.forward": [[45, 50], ["loss.lossV.squeeze", "loss.lossV.FC", "loss.lossV.criterion"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "labels", ")", ":", "\n", "\t\t", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "self", ".", "FC", "(", "x", ")", "\n", "nloss", "=", "self", ".", "criterion", "(", "x", ",", "labels", ")", "\n", "return", "nloss", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.trainTalkNet.main": [[7, 84], ["warnings.filterwarnings", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.tools.init_args", "dataLoader.train_loader", "torch.utils.data.DataLoader", "dataLoader.val_loader", "torch.utils.data.DataLoader", "glob.glob", "glob.glob.sort", "open", "utils.tools.preprocess_AVA", "quit", "utils.tools.download_pretrain_model_AVA", "talkNet.talkNet", "talkNet.talkNet.loadParameters", "print", "talkNet.talkNet.evaluate_network", "print", "quit", "len", "print", "talkNet.talkNet", "talkNet.talkNet.loadParameters", "talkNet.talkNet", "talkNet.talkNet.train_network", "os.path.join", "os.path.join", "vars", "os.path.join", "os.path.join", "vars", "int", "talkNet.talkNet.saveParameters", "mAPs.append", "print", "open.write", "open.flush", "quit", "vars", "vars", "vars", "vars", "vars", "talkNet.talkNet.evaluate_network", "time.strftime", "os.path.splitext", "vars", "max", "max", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.init_args", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.preprocess_AVA", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_pretrain_model_AVA", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.loadParameters", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.evaluate_network", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.loadParameters", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.train_network", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.saveParameters", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.evaluate_network"], ["def", "main", "(", ")", ":", "\n", "# The structure of this code is learnt from https://github.com/clovaai/voxceleb_trainer", "\n", "    ", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"TalkNet Training\"", ")", "\n", "# Training details", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'Learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--lrDecay'", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "help", "=", "'Learning rate decay rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--maxEpoch'", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "'Maximum number of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--testInterval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Test and save every [testInterval] epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "2500", ",", "help", "=", "'Dynamic batch size, default is 2500 frames, other batchsize (such as 1500) will not affect the performance'", ")", "\n", "parser", ".", "add_argument", "(", "'--nDataLoaderThread'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Number of loader threads'", ")", "\n", "# Data path", "\n", "parser", ".", "add_argument", "(", "'--dataPathAVA'", ",", "type", "=", "str", ",", "default", "=", "\"/data08/AVA\"", ",", "help", "=", "'Save path of AVA dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--savePath'", ",", "type", "=", "str", ",", "default", "=", "\"exps/exp1\"", ")", "\n", "# Data selection", "\n", "parser", ".", "add_argument", "(", "'--evalDataType'", ",", "type", "=", "str", ",", "default", "=", "\"val\"", ",", "help", "=", "'Only for AVA, to choose the dataset for evaluation, val or test'", ")", "\n", "# For download dataset only, for evaluation only", "\n", "parser", ".", "add_argument", "(", "'--downloadAVA'", ",", "dest", "=", "'downloadAVA'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only download AVA dataset and do related preprocess'", ")", "\n", "parser", ".", "add_argument", "(", "'--evaluation'", ",", "dest", "=", "'evaluation'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only do evaluation by using pretrained model [pretrain_AVA.model]'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "# Data loader", "\n", "args", "=", "init_args", "(", "args", ")", "\n", "\n", "if", "args", ".", "downloadAVA", "==", "True", ":", "\n", "        ", "preprocess_AVA", "(", "args", ")", "\n", "quit", "(", ")", "\n", "\n", "", "loader", "=", "train_loader", "(", "trialFileName", "=", "args", ".", "trainTrialAVA", ",", "audioPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "audioPathAVA", ",", "'train'", ")", ",", "visualPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualPathAVA", ",", "'train'", ")", ",", "**", "vars", "(", "args", ")", ")", "\n", "trainLoader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "loader", ",", "batch_size", "=", "1", ",", "shuffle", "=", "True", ",", "num_workers", "=", "args", ".", "nDataLoaderThread", ")", "\n", "\n", "loader", "=", "val_loader", "(", "trialFileName", "=", "args", ".", "evalTrialAVA", ",", "audioPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "audioPathAVA", ",", "args", ".", "evalDataType", ")", ",", "visualPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualPathAVA", ",", "args", ".", "evalDataType", ")", ",", "**", "vars", "(", "args", ")", ")", "\n", "valLoader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "loader", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "num_workers", "=", "16", ")", "\n", "\n", "if", "args", ".", "evaluation", "==", "True", ":", "\n", "        ", "download_pretrain_model_AVA", "(", ")", "\n", "s", "=", "talkNet", "(", "**", "vars", "(", "args", ")", ")", "\n", "s", ".", "loadParameters", "(", "'pretrain_AVA.model'", ")", "\n", "print", "(", "\"Model %s loaded from previous state!\"", "%", "(", "'pretrain_AVA.model'", ")", ")", "\n", "mAP", "=", "s", ".", "evaluate_network", "(", "loader", "=", "valLoader", ",", "**", "vars", "(", "args", ")", ")", "\n", "print", "(", "\"mAP %2.2f%%\"", "%", "(", "mAP", ")", ")", "\n", "quit", "(", ")", "\n", "\n", "", "modelfiles", "=", "glob", ".", "glob", "(", "'%s/model_0*.model'", "%", "args", ".", "modelSavePath", ")", "\n", "modelfiles", ".", "sort", "(", ")", "\n", "if", "len", "(", "modelfiles", ")", ">=", "1", ":", "\n", "        ", "print", "(", "\"Model %s loaded from previous state!\"", "%", "modelfiles", "[", "-", "1", "]", ")", "\n", "epoch", "=", "int", "(", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "modelfiles", "[", "-", "1", "]", ")", ")", "[", "0", "]", "[", "6", ":", "]", ")", "+", "1", "\n", "s", "=", "talkNet", "(", "epoch", "=", "epoch", ",", "**", "vars", "(", "args", ")", ")", "\n", "s", ".", "loadParameters", "(", "modelfiles", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "epoch", "=", "1", "\n", "s", "=", "talkNet", "(", "epoch", "=", "epoch", ",", "**", "vars", "(", "args", ")", ")", "\n", "\n", "", "mAPs", "=", "[", "]", "\n", "scoreFile", "=", "open", "(", "args", ".", "scoreSavePath", ",", "\"a+\"", ")", "\n", "\n", "while", "(", "1", ")", ":", "\n", "        ", "loss", ",", "lr", "=", "s", ".", "train_network", "(", "epoch", "=", "epoch", ",", "loader", "=", "trainLoader", ",", "**", "vars", "(", "args", ")", ")", "\n", "\n", "if", "epoch", "%", "args", ".", "testInterval", "==", "0", ":", "\n", "            ", "s", ".", "saveParameters", "(", "args", ".", "modelSavePath", "+", "\"/model_%04d.model\"", "%", "epoch", ")", "\n", "mAPs", ".", "append", "(", "s", ".", "evaluate_network", "(", "epoch", "=", "epoch", ",", "loader", "=", "valLoader", ",", "**", "vars", "(", "args", ")", ")", ")", "\n", "print", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", ",", "\"%d epoch, mAP %2.2f%%, bestmAP %2.2f%%\"", "%", "(", "epoch", ",", "mAPs", "[", "-", "1", "]", ",", "max", "(", "mAPs", ")", ")", ")", "\n", "scoreFile", ".", "write", "(", "\"%d epoch, LR %f, LOSS %f, mAP %2.2f%%, bestmAP %2.2f%%\\n\"", "%", "(", "epoch", ",", "lr", ",", "loss", ",", "mAPs", "[", "-", "1", "]", ",", "max", "(", "mAPs", ")", ")", ")", "\n", "scoreFile", ".", "flush", "(", ")", "\n", "\n", "", "if", "epoch", ">=", "args", ".", "maxEpoch", ":", "\n", "            ", "quit", "(", ")", "\n", "\n", "", "epoch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.scene_detect": [[76, 94], ["scenedetect.video_manager.VideoManager", "scenedetect.stats_manager.StatsManager", "scenedetect.scene_manager.SceneManager", "scenedetect.scene_manager.SceneManager.add_detector", "scenedetect.video_manager.VideoManager.get_base_timecode", "scenedetect.video_manager.VideoManager.set_downscale_factor", "scenedetect.video_manager.VideoManager.start", "scenedetect.scene_manager.SceneManager.detect_scenes", "scenedetect.scene_manager.SceneManager.get_scene_list", "os.path.join", "scenedetect.detectors.ContentDetector", "open", "pickle.dump", "sys.stderr.write", "scenedetect.video_manager.VideoManager.get_base_timecode", "scenedetect.video_manager.VideoManager.get_current_timecode", "len"], "function", ["None"], ["", "def", "scene_detect", "(", "args", ")", ":", "\n", "# CPU: Scene detection, output is the list of each shot's time duration", "\n", "\t", "videoManager", "=", "VideoManager", "(", "[", "args", ".", "videoFilePath", "]", ")", "\n", "statsManager", "=", "StatsManager", "(", ")", "\n", "sceneManager", "=", "SceneManager", "(", "statsManager", ")", "\n", "sceneManager", ".", "add_detector", "(", "ContentDetector", "(", ")", ")", "\n", "baseTimecode", "=", "videoManager", ".", "get_base_timecode", "(", ")", "\n", "videoManager", ".", "set_downscale_factor", "(", ")", "\n", "videoManager", ".", "start", "(", ")", "\n", "sceneManager", ".", "detect_scenes", "(", "frame_source", "=", "videoManager", ")", "\n", "sceneList", "=", "sceneManager", ".", "get_scene_list", "(", "baseTimecode", ")", "\n", "savePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyworkPath", ",", "'scene.pckl'", ")", "\n", "if", "sceneList", "==", "[", "]", ":", "\n", "\t\t", "sceneList", "=", "[", "(", "videoManager", ".", "get_base_timecode", "(", ")", ",", "videoManager", ".", "get_current_timecode", "(", ")", ")", "]", "\n", "", "with", "open", "(", "savePath", ",", "'wb'", ")", "as", "fil", ":", "\n", "\t\t", "pickle", ".", "dump", "(", "sceneList", ",", "fil", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "'%s - scenes detected %d\\n'", "%", "(", "args", ".", "videoFilePath", ",", "len", "(", "sceneList", ")", ")", ")", "\n", "", "return", "sceneList", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.inference_video": [[95, 113], ["model.faceDetector.s3fd.S3FD", "glob.glob", "glob.glob.sort", "enumerate", "os.path.join", "os.path.join", "cv2.imread", "cv2.cvtColor", "model.faceDetector.s3fd.S3FD.detect_faces", "dets.append", "sys.stderr.write", "open", "pickle.dump", "dets[].append", "bbox[].tolist", "len"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.detect_faces"], ["", "def", "inference_video", "(", "args", ")", ":", "\n", "# GPU: Face detection, output is the list contains the face location and score in this frame", "\n", "\t", "DET", "=", "S3FD", "(", "device", "=", "'cuda'", ")", "\n", "flist", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyframesPath", ",", "'*.jpg'", ")", ")", "\n", "flist", ".", "sort", "(", ")", "\n", "dets", "=", "[", "]", "\n", "for", "fidx", ",", "fname", "in", "enumerate", "(", "flist", ")", ":", "\n", "\t\t", "image", "=", "cv2", ".", "imread", "(", "fname", ")", "\n", "imageNumpy", "=", "cv2", ".", "cvtColor", "(", "image", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "bboxes", "=", "DET", ".", "detect_faces", "(", "imageNumpy", ",", "conf_th", "=", "0.9", ",", "scales", "=", "[", "args", ".", "facedetScale", "]", ")", "\n", "dets", ".", "append", "(", "[", "]", ")", "\n", "for", "bbox", "in", "bboxes", ":", "\n", "\t\t  ", "dets", "[", "-", "1", "]", ".", "append", "(", "{", "'frame'", ":", "fidx", ",", "'bbox'", ":", "(", "bbox", "[", ":", "-", "1", "]", ")", ".", "tolist", "(", ")", ",", "'conf'", ":", "bbox", "[", "-", "1", "]", "}", ")", "# dets has the frames info, bbox info, conf info", "\n", "", "sys", ".", "stderr", ".", "write", "(", "'%s-%05d; %d dets\\r'", "%", "(", "args", ".", "videoFilePath", ",", "fidx", ",", "len", "(", "dets", "[", "-", "1", "]", ")", ")", ")", "\n", "", "savePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyworkPath", ",", "'faces.pckl'", ")", "\n", "with", "open", "(", "savePath", ",", "'wb'", ")", "as", "fil", ":", "\n", "\t\t", "pickle", ".", "dump", "(", "dets", ",", "fil", ")", "\n", "", "return", "dets", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.bb_intersection_over_union": [[114, 128], ["max", "max", "min", "min", "max", "max", "float", "float"], "function", ["None"], ["", "def", "bb_intersection_over_union", "(", "boxA", ",", "boxB", ",", "evalCol", "=", "False", ")", ":", "\n", "# CPU: IOU Function to calculate overlap between two image", "\n", "\t", "xA", "=", "max", "(", "boxA", "[", "0", "]", ",", "boxB", "[", "0", "]", ")", "\n", "yA", "=", "max", "(", "boxA", "[", "1", "]", ",", "boxB", "[", "1", "]", ")", "\n", "xB", "=", "min", "(", "boxA", "[", "2", "]", ",", "boxB", "[", "2", "]", ")", "\n", "yB", "=", "min", "(", "boxA", "[", "3", "]", ",", "boxB", "[", "3", "]", ")", "\n", "interArea", "=", "max", "(", "0", ",", "xB", "-", "xA", ")", "*", "max", "(", "0", ",", "yB", "-", "yA", ")", "\n", "boxAArea", "=", "(", "boxA", "[", "2", "]", "-", "boxA", "[", "0", "]", ")", "*", "(", "boxA", "[", "3", "]", "-", "boxA", "[", "1", "]", ")", "\n", "boxBArea", "=", "(", "boxB", "[", "2", "]", "-", "boxB", "[", "0", "]", ")", "*", "(", "boxB", "[", "3", "]", "-", "boxB", "[", "1", "]", ")", "\n", "if", "evalCol", "==", "True", ":", "\n", "\t\t", "iou", "=", "interArea", "/", "float", "(", "boxAArea", ")", "\n", "", "else", ":", "\n", "\t\t", "iou", "=", "interArea", "/", "float", "(", "boxAArea", "+", "boxBArea", "-", "interArea", ")", "\n", "", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.track_shot": [[129, 162], ["len", "numpy.array", "numpy.array", "numpy.arange", "range", "numpy.stack", "track.append", "frameFaces.remove", "scipy.interpolate.interp1d", "numpy.stack.append", "max", "tracks.append", "demoTalkNet.bb_intersection_over_union", "numpy.array", "scipy.interpolate.interp1d.", "numpy.mean", "numpy.mean", "track.append", "frameFaces.remove"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.bb_intersection_over_union"], ["", "def", "track_shot", "(", "args", ",", "sceneFaces", ")", ":", "\n", "# CPU: Face tracking", "\n", "\t", "iouThres", "=", "0.5", "# Minimum IOU between consecutive face detections", "\n", "tracks", "=", "[", "]", "\n", "while", "True", ":", "\n", "\t\t", "track", "=", "[", "]", "\n", "for", "frameFaces", "in", "sceneFaces", ":", "\n", "\t\t\t", "for", "face", "in", "frameFaces", ":", "\n", "\t\t\t\t", "if", "track", "==", "[", "]", ":", "\n", "\t\t\t\t\t", "track", ".", "append", "(", "face", ")", "\n", "frameFaces", ".", "remove", "(", "face", ")", "\n", "", "elif", "face", "[", "'frame'", "]", "-", "track", "[", "-", "1", "]", "[", "'frame'", "]", "<=", "args", ".", "numFailedDet", ":", "\n", "\t\t\t\t\t", "iou", "=", "bb_intersection_over_union", "(", "face", "[", "'bbox'", "]", ",", "track", "[", "-", "1", "]", "[", "'bbox'", "]", ")", "\n", "if", "iou", ">", "iouThres", ":", "\n", "\t\t\t\t\t\t", "track", ".", "append", "(", "face", ")", "\n", "frameFaces", ".", "remove", "(", "face", ")", "\n", "continue", "\n", "", "", "else", ":", "\n", "\t\t\t\t\t", "break", "\n", "", "", "", "if", "track", "==", "[", "]", ":", "\n", "\t\t\t", "break", "\n", "", "elif", "len", "(", "track", ")", ">", "args", ".", "minTrack", ":", "\n", "\t\t\t", "frameNum", "=", "numpy", ".", "array", "(", "[", "f", "[", "'frame'", "]", "for", "f", "in", "track", "]", ")", "\n", "bboxes", "=", "numpy", ".", "array", "(", "[", "numpy", ".", "array", "(", "f", "[", "'bbox'", "]", ")", "for", "f", "in", "track", "]", ")", "\n", "frameI", "=", "numpy", ".", "arange", "(", "frameNum", "[", "0", "]", ",", "frameNum", "[", "-", "1", "]", "+", "1", ")", "\n", "bboxesI", "=", "[", "]", "\n", "for", "ij", "in", "range", "(", "0", ",", "4", ")", ":", "\n", "\t\t\t\t", "interpfn", "=", "interp1d", "(", "frameNum", ",", "bboxes", "[", ":", ",", "ij", "]", ")", "\n", "bboxesI", ".", "append", "(", "interpfn", "(", "frameI", ")", ")", "\n", "", "bboxesI", "=", "numpy", ".", "stack", "(", "bboxesI", ",", "axis", "=", "1", ")", "\n", "if", "max", "(", "numpy", ".", "mean", "(", "bboxesI", "[", ":", ",", "2", "]", "-", "bboxesI", "[", ":", ",", "0", "]", ")", ",", "numpy", ".", "mean", "(", "bboxesI", "[", ":", ",", "3", "]", "-", "bboxesI", "[", ":", ",", "1", "]", ")", ")", ">", "args", ".", "minFaceSize", ":", "\n", "\t\t\t\t", "tracks", ".", "append", "(", "{", "'frame'", ":", "frameI", ",", "'bbox'", ":", "bboxesI", "}", ")", "\n", "", "", "", "return", "tracks", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.crop_video": [[163, 199], ["glob.glob", "glob.glob.sort", "cv2.VideoWriter", "scipy.signal.medfilt", "scipy.signal.medfilt", "scipy.signal.medfilt", "enumerate", "cv2.VideoWriter.release", "subprocess.call", "scipy.io.wavfile.read", "subprocess.call", "os.remove", "os.path.join", "cv2.VideoWriter_fourcc", "dets[].append", "dets[].append", "dets[].append", "int", "cv2.imread", "numpy.pad", "cv2.VideoWriter.write", "cv2.resize", "max", "int", "int", "int", "int"], "function", ["None"], ["", "def", "crop_video", "(", "args", ",", "track", ",", "cropFile", ")", ":", "\n", "# CPU: crop the face clips", "\n", "\t", "flist", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyframesPath", ",", "'*.jpg'", ")", ")", "# Read the frames", "\n", "flist", ".", "sort", "(", ")", "\n", "vOut", "=", "cv2", ".", "VideoWriter", "(", "cropFile", "+", "'t.avi'", ",", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'XVID'", ")", ",", "25", ",", "(", "224", ",", "224", ")", ")", "# Write video", "\n", "dets", "=", "{", "'x'", ":", "[", "]", ",", "'y'", ":", "[", "]", ",", "'s'", ":", "[", "]", "}", "\n", "for", "det", "in", "track", "[", "'bbox'", "]", ":", "# Read the tracks", "\n", "\t\t", "dets", "[", "'s'", "]", ".", "append", "(", "max", "(", "(", "det", "[", "3", "]", "-", "det", "[", "1", "]", ")", ",", "(", "det", "[", "2", "]", "-", "det", "[", "0", "]", ")", ")", "/", "2", ")", "\n", "dets", "[", "'y'", "]", ".", "append", "(", "(", "det", "[", "1", "]", "+", "det", "[", "3", "]", ")", "/", "2", ")", "# crop center x ", "\n", "dets", "[", "'x'", "]", ".", "append", "(", "(", "det", "[", "0", "]", "+", "det", "[", "2", "]", ")", "/", "2", ")", "# crop center y", "\n", "", "dets", "[", "'s'", "]", "=", "signal", ".", "medfilt", "(", "dets", "[", "'s'", "]", ",", "kernel_size", "=", "13", ")", "# Smooth detections ", "\n", "dets", "[", "'x'", "]", "=", "signal", ".", "medfilt", "(", "dets", "[", "'x'", "]", ",", "kernel_size", "=", "13", ")", "\n", "dets", "[", "'y'", "]", "=", "signal", ".", "medfilt", "(", "dets", "[", "'y'", "]", ",", "kernel_size", "=", "13", ")", "\n", "for", "fidx", ",", "frame", "in", "enumerate", "(", "track", "[", "'frame'", "]", ")", ":", "\n", "\t\t", "cs", "=", "args", ".", "cropScale", "\n", "bs", "=", "dets", "[", "'s'", "]", "[", "fidx", "]", "# Detection box size", "\n", "bsi", "=", "int", "(", "bs", "*", "(", "1", "+", "2", "*", "cs", ")", ")", "# Pad videos by this amount ", "\n", "image", "=", "cv2", ".", "imread", "(", "flist", "[", "frame", "]", ")", "\n", "frame", "=", "numpy", ".", "pad", "(", "image", ",", "(", "(", "bsi", ",", "bsi", ")", ",", "(", "bsi", ",", "bsi", ")", ",", "(", "0", ",", "0", ")", ")", ",", "'constant'", ",", "constant_values", "=", "(", "110", ",", "110", ")", ")", "\n", "my", "=", "dets", "[", "'y'", "]", "[", "fidx", "]", "+", "bsi", "# BBox center Y", "\n", "mx", "=", "dets", "[", "'x'", "]", "[", "fidx", "]", "+", "bsi", "# BBox center X", "\n", "face", "=", "frame", "[", "int", "(", "my", "-", "bs", ")", ":", "int", "(", "my", "+", "bs", "*", "(", "1", "+", "2", "*", "cs", ")", ")", ",", "int", "(", "mx", "-", "bs", "*", "(", "1", "+", "cs", ")", ")", ":", "int", "(", "mx", "+", "bs", "*", "(", "1", "+", "cs", ")", ")", "]", "\n", "vOut", ".", "write", "(", "cv2", ".", "resize", "(", "face", ",", "(", "224", ",", "224", ")", ")", ")", "\n", "", "audioTmp", "=", "cropFile", "+", "'.wav'", "\n", "audioStart", "=", "(", "track", "[", "'frame'", "]", "[", "0", "]", ")", "/", "25", "\n", "audioEnd", "=", "(", "track", "[", "'frame'", "]", "[", "-", "1", "]", "+", "1", ")", "/", "25", "\n", "vOut", ".", "release", "(", ")", "\n", "command", "=", "(", "\"ffmpeg -y -i %s -async 1 -ac 1 -vn -acodec pcm_s16le -ar 16000 -threads %d -ss %.3f -to %.3f %s -loglevel panic\"", "%", "(", "args", ".", "audioFilePath", ",", "args", ".", "nDataLoaderThread", ",", "audioStart", ",", "audioEnd", ",", "audioTmp", ")", ")", "\n", "output", "=", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "# Crop audio file", "\n", "_", ",", "audio", "=", "wavfile", ".", "read", "(", "audioTmp", ")", "\n", "command", "=", "(", "\"ffmpeg -y -i %st.avi -i %s -threads %d -c:v copy -c:a copy %s.avi -loglevel panic\"", "%", "(", "cropFile", ",", "audioTmp", ",", "args", ".", "nDataLoaderThread", ",", "cropFile", ")", ")", "# Combine audio and video file", "\n", "output", "=", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "os", ".", "remove", "(", "cropFile", "+", "'t.avi'", ")", "\n", "return", "{", "'track'", ":", "track", ",", "'proc_track'", ":", "dets", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.extract_MFCC": [[200, 206], ["scipy.io.wavfile.read", "python_speech_features.mfcc", "os.path.join", "numpy.save", "[].replace", "file.split"], "function", ["None"], ["", "def", "extract_MFCC", "(", "file", ",", "outPath", ")", ":", "\n", "# CPU: extract mfcc", "\n", "\t", "sr", ",", "audio", "=", "wavfile", ".", "read", "(", "file", ")", "\n", "mfcc", "=", "python_speech_features", ".", "mfcc", "(", "audio", ",", "sr", ")", "# (N_frames, 13)   [1s = 100 frames]", "\n", "featuresPath", "=", "os", ".", "path", ".", "join", "(", "outPath", ",", "file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "replace", "(", "'.wav'", ",", "'.npy'", ")", ")", "\n", "numpy", ".", "save", "(", "featuresPath", ",", "mfcc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.evaluate_network": [[207, 254], ["talkNet.talkNet", "talkNet.talkNet.loadParameters", "sys.stderr.write", "talkNet.talkNet.eval", "tqdm.tqdm", "scipy.io.wavfile.read", "python_speech_features.mfcc", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "cv2.VideoCapture.release", "numpy.array", "min", "numpy.round().astype", "allScores.append", "len", "os.path.splitext", "os.path.join", "os.path.join", "cv2.VideoCapture.read", "int", "numpy.round().astype.append", "cv2.cvtColor", "cv2.resize", "numpy.array.append", "math.ceil", "torch.no_grad", "range", "numpy.round", "file.split", "int", "int", "torch.FloatTensor().unsqueeze().cuda", "torch.FloatTensor().unsqueeze().cuda", "talkNet.talkNet.model.forward_audio_frontend", "talkNet.talkNet.model.forward_visual_frontend", "talkNet.talkNet.model.forward_cross_attention", "talkNet.talkNet.model.forward_audio_visual_backend", "talkNet.talkNet.lossAV.forward", "scores.extend", "numpy.mean", "round", "round", "numpy.array", "int", "int", "int", "int", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.loadParameters", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_cross_attention", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_visual_backend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward"], ["", "def", "evaluate_network", "(", "files", ",", "args", ")", ":", "\n", "# GPU: active speaker detection by pretrained TalkNet", "\n", "\t", "s", "=", "talkNet", "(", ")", "\n", "s", ".", "loadParameters", "(", "args", ".", "pretrainModel", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "\"Model %s loaded from previous state! \\r\\n\"", "%", "args", ".", "pretrainModel", ")", "\n", "s", ".", "eval", "(", ")", "\n", "allScores", "=", "[", "]", "\n", "# durationSet = {1,2,4,6} # To make the result more reliable", "\n", "durationSet", "=", "{", "1", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", ",", "3", ",", "3", ",", "4", ",", "5", ",", "6", "}", "# Use this line can get more reliable result", "\n", "for", "file", "in", "tqdm", ".", "tqdm", "(", "files", ",", "total", "=", "len", "(", "files", ")", ")", ":", "\n", "\t\t", "fileName", "=", "os", ".", "path", ".", "splitext", "(", "file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "[", "0", "]", "# Load audio and video", "\n", "_", ",", "audio", "=", "wavfile", ".", "read", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pycropPath", ",", "fileName", "+", "'.wav'", ")", ")", "\n", "audioFeature", "=", "python_speech_features", ".", "mfcc", "(", "audio", ",", "16000", ",", "numcep", "=", "13", ",", "winlen", "=", "0.025", ",", "winstep", "=", "0.010", ")", "\n", "video", "=", "cv2", ".", "VideoCapture", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pycropPath", ",", "fileName", "+", "'.avi'", ")", ")", "\n", "videoFeature", "=", "[", "]", "\n", "while", "video", ".", "isOpened", "(", ")", ":", "\n", "\t\t\t", "ret", ",", "frames", "=", "video", ".", "read", "(", ")", "\n", "if", "ret", "==", "True", ":", "\n", "\t\t\t\t", "face", "=", "cv2", ".", "cvtColor", "(", "frames", ",", "cv2", ".", "COLOR_BGR2GRAY", ")", "\n", "face", "=", "cv2", ".", "resize", "(", "face", ",", "(", "224", ",", "224", ")", ")", "\n", "face", "=", "face", "[", "int", "(", "112", "-", "(", "112", "/", "2", ")", ")", ":", "int", "(", "112", "+", "(", "112", "/", "2", ")", ")", ",", "int", "(", "112", "-", "(", "112", "/", "2", ")", ")", ":", "int", "(", "112", "+", "(", "112", "/", "2", ")", ")", "]", "\n", "videoFeature", ".", "append", "(", "face", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "break", "\n", "", "", "video", ".", "release", "(", ")", "\n", "videoFeature", "=", "numpy", ".", "array", "(", "videoFeature", ")", "\n", "length", "=", "min", "(", "(", "audioFeature", ".", "shape", "[", "0", "]", "-", "audioFeature", ".", "shape", "[", "0", "]", "%", "4", ")", "/", "100", ",", "videoFeature", ".", "shape", "[", "0", "]", ")", "\n", "audioFeature", "=", "audioFeature", "[", ":", "int", "(", "round", "(", "length", "*", "100", ")", ")", ",", ":", "]", "\n", "videoFeature", "=", "videoFeature", "[", ":", "int", "(", "round", "(", "length", "*", "25", ")", ")", ",", ":", ",", ":", "]", "\n", "allScore", "=", "[", "]", "# Evaluation use TalkNet", "\n", "for", "duration", "in", "durationSet", ":", "\n", "\t\t\t", "batchSize", "=", "int", "(", "math", ".", "ceil", "(", "length", "/", "duration", ")", ")", "\n", "scores", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "for", "i", "in", "range", "(", "batchSize", ")", ":", "\n", "\t\t\t\t\t", "inputA", "=", "torch", ".", "FloatTensor", "(", "audioFeature", "[", "i", "*", "duration", "*", "100", ":", "(", "i", "+", "1", ")", "*", "duration", "*", "100", ",", ":", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "cuda", "(", ")", "\n", "inputV", "=", "torch", ".", "FloatTensor", "(", "videoFeature", "[", "i", "*", "duration", "*", "25", ":", "(", "i", "+", "1", ")", "*", "duration", "*", "25", ",", ":", ",", ":", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "cuda", "(", ")", "\n", "embedA", "=", "s", ".", "model", ".", "forward_audio_frontend", "(", "inputA", ")", "\n", "embedV", "=", "s", ".", "model", ".", "forward_visual_frontend", "(", "inputV", ")", "\n", "embedA", ",", "embedV", "=", "s", ".", "model", ".", "forward_cross_attention", "(", "embedA", ",", "embedV", ")", "\n", "out", "=", "s", ".", "model", ".", "forward_audio_visual_backend", "(", "embedA", ",", "embedV", ")", "\n", "score", "=", "s", ".", "lossAV", ".", "forward", "(", "out", ",", "labels", "=", "None", ")", "\n", "scores", ".", "extend", "(", "score", ")", "\n", "", "", "allScore", ".", "append", "(", "scores", ")", "\n", "", "allScore", "=", "numpy", ".", "round", "(", "(", "numpy", ".", "mean", "(", "numpy", ".", "array", "(", "allScore", ")", ",", "axis", "=", "0", ")", ")", ",", "1", ")", ".", "astype", "(", "float", ")", "\n", "allScores", ".", "append", "(", "allScore", ")", "\n", "", "return", "allScores", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.visualization": [[255, 284], ["glob.glob", "glob.glob.sort", "enumerate", "cv2.imread", "cv2.VideoWriter", "tqdm.tqdm", "cv2.VideoWriter.release", "subprocess.call", "os.path.join", "enumerate", "os.path.join", "cv2.VideoWriter_fourcc", "enumerate", "cv2.imread", "cv2.VideoWriter.write", "range", "[].tolist", "numpy.mean", "faces[].append", "len", "round", "cv2.rectangle", "cv2.putText", "os.path.join", "os.path.join", "os.path.join", "len", "max", "min", "float", "int", "int", "int", "int", "int", "int", "int", "len"], "function", ["None"], ["", "def", "visualization", "(", "tracks", ",", "scores", ",", "args", ")", ":", "\n", "# CPU: visulize the result for video format", "\n", "\t", "flist", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyframesPath", ",", "'*.jpg'", ")", ")", "\n", "flist", ".", "sort", "(", ")", "\n", "faces", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "flist", ")", ")", "]", "\n", "for", "tidx", ",", "track", "in", "enumerate", "(", "tracks", ")", ":", "\n", "\t\t", "score", "=", "scores", "[", "tidx", "]", "\n", "for", "fidx", ",", "frame", "in", "enumerate", "(", "track", "[", "'track'", "]", "[", "'frame'", "]", ".", "tolist", "(", ")", ")", ":", "\n", "\t\t\t", "s", "=", "score", "[", "max", "(", "fidx", "-", "2", ",", "0", ")", ":", "min", "(", "fidx", "+", "3", ",", "len", "(", "score", ")", "-", "1", ")", "]", "# average smoothing", "\n", "s", "=", "numpy", ".", "mean", "(", "s", ")", "\n", "faces", "[", "frame", "]", ".", "append", "(", "{", "'track'", ":", "tidx", ",", "'score'", ":", "float", "(", "s", ")", ",", "'s'", ":", "track", "[", "'proc_track'", "]", "[", "'s'", "]", "[", "fidx", "]", ",", "'x'", ":", "track", "[", "'proc_track'", "]", "[", "'x'", "]", "[", "fidx", "]", ",", "'y'", ":", "track", "[", "'proc_track'", "]", "[", "'y'", "]", "[", "fidx", "]", "}", ")", "\n", "", "", "firstImage", "=", "cv2", ".", "imread", "(", "flist", "[", "0", "]", ")", "\n", "fw", "=", "firstImage", ".", "shape", "[", "1", "]", "\n", "fh", "=", "firstImage", ".", "shape", "[", "0", "]", "\n", "vOut", "=", "cv2", ".", "VideoWriter", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'video_only.avi'", ")", ",", "cv2", ".", "VideoWriter_fourcc", "(", "*", "'XVID'", ")", ",", "25", ",", "(", "fw", ",", "fh", ")", ")", "\n", "colorDict", "=", "{", "0", ":", "0", ",", "1", ":", "255", "}", "\n", "for", "fidx", ",", "fname", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "flist", ")", ",", "total", "=", "len", "(", "flist", ")", ")", ":", "\n", "\t\t", "image", "=", "cv2", ".", "imread", "(", "fname", ")", "\n", "for", "face", "in", "faces", "[", "fidx", "]", ":", "\n", "\t\t\t", "clr", "=", "colorDict", "[", "int", "(", "(", "face", "[", "'score'", "]", ">=", "0", ")", ")", "]", "\n", "txt", "=", "round", "(", "face", "[", "'score'", "]", ",", "1", ")", "\n", "cv2", ".", "rectangle", "(", "image", ",", "(", "int", "(", "face", "[", "'x'", "]", "-", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'y'", "]", "-", "face", "[", "'s'", "]", ")", ")", ",", "(", "int", "(", "face", "[", "'x'", "]", "+", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'y'", "]", "+", "face", "[", "'s'", "]", ")", ")", ",", "(", "0", ",", "clr", ",", "255", "-", "clr", ")", ",", "10", ")", "\n", "cv2", ".", "putText", "(", "image", ",", "'%s'", "%", "(", "txt", ")", ",", "(", "int", "(", "face", "[", "'x'", "]", "-", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'y'", "]", "-", "face", "[", "'s'", "]", ")", ")", ",", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "1.5", ",", "(", "0", ",", "clr", ",", "255", "-", "clr", ")", ",", "5", ")", "\n", "", "vOut", ".", "write", "(", "image", ")", "\n", "", "vOut", ".", "release", "(", ")", "\n", "command", "=", "(", "\"ffmpeg -y -i %s -i %s -threads %d -c:v copy -c:a copy %s -loglevel panic\"", "%", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'video_only.avi'", ")", ",", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'audio.wav'", ")", ",", "args", ".", "nDataLoaderThread", ",", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'video_out.avi'", ")", ")", ")", "\n", "output", "=", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.evaluate_col_ASD": [[285, 351], ["glob.glob", "glob.glob", "glob.glob.sort", "enumerate", "tqdm.tqdm", "names.sort", "print", "open().read().splitlines", "os.path.join", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.int64", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "line.split", "int", "int", "int", "int", "range", "[].tolist", "numpy.mean", "faces[].append", "len", "print", "open().read", "file.split", "int", "int", "int", "int", "dictGT[].append", "len", "[].append", "[].append", "float", "demoTalkNet.bb_intersection_over_union", "len", "ious.sort", "open", "int", "max", "min", "int", "int", "int", "int", "ious.append", "int", "int", "int", "int", "len", "round"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.bb_intersection_over_union"], ["", "def", "evaluate_col_ASD", "(", "tracks", ",", "scores", ",", "args", ")", ":", "\n", "\t", "txtPath", "=", "args", ".", "videoFolder", "+", "'/col_labels/fusion/*.txt'", "# Load labels", "\n", "predictionSet", "=", "{", "}", "\n", "for", "name", "in", "{", "'long'", ",", "'bell'", ",", "'boll'", ",", "'lieb'", ",", "'sick'", ",", "'abbas'", "}", ":", "\n", "\t\t", "predictionSet", "[", "name", "]", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "", "dictGT", "=", "{", "}", "\n", "txtFiles", "=", "glob", ".", "glob", "(", "\"%s\"", "%", "txtPath", ")", "\n", "for", "file", "in", "txtFiles", ":", "\n", "\t\t", "lines", "=", "open", "(", "file", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "idName", "=", "file", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t\t", "data", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "frame", "=", "int", "(", "int", "(", "data", "[", "0", "]", ")", "/", "29.97", "*", "25", ")", "\n", "x1", "=", "int", "(", "data", "[", "1", "]", ")", "\n", "y1", "=", "int", "(", "data", "[", "2", "]", ")", "\n", "x2", "=", "int", "(", "data", "[", "1", "]", ")", "+", "int", "(", "data", "[", "3", "]", ")", "\n", "y2", "=", "int", "(", "data", "[", "2", "]", ")", "+", "int", "(", "data", "[", "3", "]", ")", "\n", "gt", "=", "int", "(", "data", "[", "4", "]", ")", "\n", "if", "frame", "in", "dictGT", ":", "\n", "\t\t\t\t", "dictGT", "[", "frame", "]", ".", "append", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "gt", ",", "idName", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "dictGT", "[", "frame", "]", "=", "[", "[", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "gt", ",", "idName", "]", "]", "\n", "", "", "", "flist", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "pyframesPath", ",", "'*.jpg'", ")", ")", "# Load files", "\n", "flist", ".", "sort", "(", ")", "\n", "faces", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "flist", ")", ")", "]", "\n", "for", "tidx", ",", "track", "in", "enumerate", "(", "tracks", ")", ":", "\n", "\t\t", "score", "=", "scores", "[", "tidx", "]", "\n", "for", "fidx", ",", "frame", "in", "enumerate", "(", "track", "[", "'track'", "]", "[", "'frame'", "]", ".", "tolist", "(", ")", ")", ":", "\n", "\t\t\t", "s", "=", "numpy", ".", "mean", "(", "score", "[", "max", "(", "fidx", "-", "2", ",", "0", ")", ":", "min", "(", "fidx", "+", "3", ",", "len", "(", "score", ")", "-", "1", ")", "]", ")", "# average smoothing", "\n", "faces", "[", "frame", "]", ".", "append", "(", "{", "'track'", ":", "tidx", ",", "'score'", ":", "float", "(", "s", ")", ",", "'s'", ":", "track", "[", "'proc_track'", "]", "[", "'s'", "]", "[", "fidx", "]", ",", "'x'", ":", "track", "[", "'proc_track'", "]", "[", "'x'", "]", "[", "fidx", "]", ",", "'y'", ":", "track", "[", "'proc_track'", "]", "[", "'y'", "]", "[", "fidx", "]", "}", ")", "\n", "", "", "for", "fidx", ",", "fname", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "flist", ")", ",", "total", "=", "len", "(", "flist", ")", ")", ":", "\n", "\t\t", "if", "fidx", "in", "dictGT", ":", "# This frame has label", "\n", "\t\t\t", "for", "gtThisFrame", "in", "dictGT", "[", "fidx", "]", ":", "# What this label is ?", "\n", "\t\t\t\t", "faceGT", "=", "gtThisFrame", "[", "0", ":", "4", "]", "\n", "labelGT", "=", "gtThisFrame", "[", "4", "]", "\n", "idGT", "=", "gtThisFrame", "[", "5", "]", "\n", "ious", "=", "[", "]", "\n", "for", "face", "in", "faces", "[", "fidx", "]", ":", "# Find the right face in my result", "\n", "\t\t\t\t\t", "faceLocation", "=", "[", "int", "(", "face", "[", "'x'", "]", "-", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'y'", "]", "-", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'x'", "]", "+", "face", "[", "'s'", "]", ")", ",", "int", "(", "face", "[", "'y'", "]", "+", "face", "[", "'s'", "]", ")", "]", "\n", "faceLocation_new", "=", "[", "int", "(", "face", "[", "'x'", "]", "-", "face", "[", "'s'", "]", ")", "//", "2", ",", "int", "(", "face", "[", "'y'", "]", "-", "face", "[", "'s'", "]", ")", "//", "2", ",", "int", "(", "face", "[", "'x'", "]", "+", "face", "[", "'s'", "]", ")", "//", "2", ",", "int", "(", "face", "[", "'y'", "]", "+", "face", "[", "'s'", "]", ")", "//", "2", "]", "\n", "iou", "=", "bb_intersection_over_union", "(", "faceLocation_new", ",", "faceGT", ",", "evalCol", "=", "True", ")", "\n", "if", "iou", ">", "0.5", ":", "\n", "\t\t\t\t\t\t", "ious", ".", "append", "(", "[", "iou", ",", "round", "(", "face", "[", "'score'", "]", ",", "2", ")", "]", ")", "\n", "", "", "if", "len", "(", "ious", ")", ">", "0", ":", "# Find my result", "\n", "\t\t\t\t\t", "ious", ".", "sort", "(", ")", "\n", "labelPredict", "=", "ious", "[", "-", "1", "]", "[", "1", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "labelPredict", "=", "0", "\n", "", "x1", "=", "faceGT", "[", "0", "]", "\n", "y1", "=", "faceGT", "[", "1", "]", "\n", "width", "=", "faceGT", "[", "2", "]", "-", "faceGT", "[", "0", "]", "\n", "predictionSet", "[", "idGT", "]", "[", "0", "]", ".", "append", "(", "labelPredict", ")", "\n", "predictionSet", "[", "idGT", "]", "[", "1", "]", ".", "append", "(", "labelGT", ")", "\n", "", "", "", "names", "=", "[", "'long'", ",", "'bell'", ",", "'boll'", ",", "'lieb'", ",", "'sick'", ",", "'abbas'", "]", "# Evaluate", "\n", "names", ".", "sort", "(", ")", "\n", "F1s", "=", "0", "\n", "for", "i", "in", "names", ":", "\n", "\t\t", "scores", "=", "numpy", ".", "array", "(", "predictionSet", "[", "i", "]", "[", "0", "]", ")", "\n", "labels", "=", "numpy", ".", "array", "(", "predictionSet", "[", "i", "]", "[", "1", "]", ")", "\n", "scores", "=", "numpy", ".", "int64", "(", "scores", ">", "0", ")", "\n", "F1", "=", "f1_score", "(", "labels", ",", "scores", ")", "\n", "ACC", "=", "accuracy_score", "(", "labels", ",", "scores", ")", "\n", "if", "i", "!=", "'abbas'", ":", "\n", "\t\t\t", "F1s", "+=", "F1", "\n", "print", "(", "\"%s, ACC:%.2f, F1:%.2f\"", "%", "(", "i", ",", "100", "*", "ACC", ",", "100", "*", "F1", ")", ")", "\n", "", "", "print", "(", "\"Average F1:%.2f\"", "%", "(", "100", "*", "(", "F1s", "/", "5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.main": [[353, 456], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.path.join", "subprocess.call", "sys.stderr.write", "os.path.join", "subprocess.call", "sys.stderr.write", "subprocess.call", "sys.stderr.write", "demoTalkNet.scene_detect", "sys.stderr.write", "demoTalkNet.inference_video", "sys.stderr.write", "sys.stderr.write", "tqdm.tqdm", "os.path.join", "sys.stderr.write", "open", "pickle.load", "glob.glob", "glob.glob.sort", "demoTalkNet.evaluate_network", "os.path.join", "sys.stderr.write", "shutil.rmtree", "enumerate", "pickle.load.append", "open", "pickle.dump", "open", "pickle.dump", "demoTalkNet.evaluate_col_ASD", "quit", "demoTalkNet.visualization", "time.strftime", "time.strftime", "os.path.join", "time.strftime", "time.strftime", "time.strftime", "allTracks.extend", "time.strftime", "len", "demoTalkNet.crop_video", "time.strftime", "time.strftime", "demoTalkNet.track_shot", "len", "os.path.join"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.scene_detect", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.inference_video", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.evaluate_network", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.evaluate_col_ASD", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.visualization", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.crop_video", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.demoTalkNet.track_shot"], ["", "def", "main", "(", ")", ":", "\n", "# This preprocesstion is modified based on this [repository](https://github.com/joonson/syncnet_python).", "\n", "# ```", "\n", "# .", "\n", "# \u251c\u2500\u2500 pyavi", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 audio.wav (Audio from input video)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 video.avi (Copy of the input video)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 video_only.avi (Output video without audio)", "\n", "# \u2502\u00a0\u00a0 \u2514\u2500\u2500 video_out.avi  (Output video with audio)", "\n", "# \u251c\u2500\u2500 pycrop (The detected face videos and audios)", "\n", "# \u2502   \u251c\u2500\u2500 000000.avi", "\n", "# \u2502   \u251c\u2500\u2500 000000.wav", "\n", "# \u2502   \u251c\u2500\u2500 000001.avi", "\n", "# \u2502   \u251c\u2500\u2500 000001.wav", "\n", "# \u2502   \u2514\u2500\u2500 ...", "\n", "# \u251c\u2500\u2500 pyframes (All the video frames in this video)", "\n", "# \u2502   \u251c\u2500\u2500 000001.jpg", "\n", "# \u2502   \u251c\u2500\u2500 000002.jpg", "\n", "# \u2502   \u2514\u2500\u2500 ...\t", "\n", "# \u2514\u2500\u2500 pywork", "\n", "#     \u251c\u2500\u2500 faces.pckl (face detection result)", "\n", "#     \u251c\u2500\u2500 scene.pckl (scene detection result)", "\n", "#     \u251c\u2500\u2500 scores.pckl (ASD result)", "\n", "#     \u2514\u2500\u2500 tracks.pckl (face tracking result)", "\n", "# ```", "\n", "\n", "# Initialization ", "\n", "\t", "args", ".", "pyaviPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'pyavi'", ")", "\n", "args", ".", "pyframesPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'pyframes'", ")", "\n", "args", ".", "pyworkPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'pywork'", ")", "\n", "args", ".", "pycropPath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'pycrop'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "savePath", ")", ":", "\n", "\t\t", "rmtree", "(", "args", ".", "savePath", ")", "\n", "", "os", ".", "makedirs", "(", "args", ".", "pyaviPath", ",", "exist_ok", "=", "True", ")", "# The path for the input video, input audio, output video", "\n", "os", ".", "makedirs", "(", "args", ".", "pyframesPath", ",", "exist_ok", "=", "True", ")", "# Save all the video frames", "\n", "os", ".", "makedirs", "(", "args", ".", "pyworkPath", ",", "exist_ok", "=", "True", ")", "# Save the results in this process by the pckl method", "\n", "os", ".", "makedirs", "(", "args", ".", "pycropPath", ",", "exist_ok", "=", "True", ")", "# Save the detected face clips (audio+video) in this process", "\n", "\n", "# Extract video", "\n", "args", ".", "videoFilePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'video.avi'", ")", "\n", "# If duration did not set, extract the whole video, otherwise extract the video from 'args.start' to 'args.start + args.duration'", "\n", "if", "args", ".", "duration", "==", "0", ":", "\n", "\t\t", "command", "=", "(", "\"ffmpeg -y -i %s -qscale:v 2 -threads %d -async 1 -r 25 %s -loglevel panic\"", "%", "(", "args", ".", "videoPath", ",", "args", ".", "nDataLoaderThread", ",", "args", ".", "videoFilePath", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "command", "=", "(", "\"ffmpeg -y -i %s -qscale:v 2 -threads %d -ss %.3f -to %.3f -async 1 -r 25 %s -loglevel panic\"", "%", "(", "args", ".", "videoPath", ",", "args", ".", "nDataLoaderThread", ",", "args", ".", "start", ",", "args", ".", "start", "+", "args", ".", "duration", ",", "args", ".", "videoFilePath", ")", ")", "\n", "", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Extract the video and save in %s \\r\\n\"", "%", "(", "args", ".", "videoFilePath", ")", ")", "\n", "\n", "# Extract audio", "\n", "args", ".", "audioFilePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyaviPath", ",", "'audio.wav'", ")", "\n", "command", "=", "(", "\"ffmpeg -y -i %s -qscale:a 0 -ac 1 -vn -threads %d -ar 16000 %s -loglevel panic\"", "%", "(", "args", ".", "videoFilePath", ",", "args", ".", "nDataLoaderThread", ",", "args", ".", "audioFilePath", ")", ")", "\n", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Extract the audio and save in %s \\r\\n\"", "%", "(", "args", ".", "audioFilePath", ")", ")", "\n", "\n", "# Extract the video frames", "\n", "command", "=", "(", "\"ffmpeg -y -i %s -qscale:v 2 -threads %d -f image2 %s -loglevel panic\"", "%", "(", "args", ".", "videoFilePath", ",", "args", ".", "nDataLoaderThread", ",", "os", ".", "path", ".", "join", "(", "args", ".", "pyframesPath", ",", "'%06d.jpg'", ")", ")", ")", "\n", "subprocess", ".", "call", "(", "command", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Extract the frames and save in %s \\r\\n\"", "%", "(", "args", ".", "pyframesPath", ")", ")", "\n", "\n", "# Scene detection for the video frames", "\n", "scene", "=", "scene_detect", "(", "args", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Scene detection and save in %s \\r\\n\"", "%", "(", "args", ".", "pyworkPath", ")", ")", "\n", "\n", "# Face detection for the video frames", "\n", "faces", "=", "inference_video", "(", "args", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Face detection and save in %s \\r\\n\"", "%", "(", "args", ".", "pyworkPath", ")", ")", "\n", "\n", "# Face tracking", "\n", "allTracks", ",", "vidTracks", "=", "[", "]", ",", "[", "]", "\n", "for", "shot", "in", "scene", ":", "\n", "\t\t", "if", "shot", "[", "1", "]", ".", "frame_num", "-", "shot", "[", "0", "]", ".", "frame_num", ">=", "args", ".", "minTrack", ":", "# Discard the shot frames less than minTrack frames", "\n", "\t\t\t", "allTracks", ".", "extend", "(", "track_shot", "(", "args", ",", "faces", "[", "shot", "[", "0", "]", ".", "frame_num", ":", "shot", "[", "1", "]", ".", "frame_num", "]", ")", ")", "# 'frames' to present this tracks' timestep, 'bbox' presents the location of the faces", "\n", "", "", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Face track and detected %d tracks \\r\\n\"", "%", "len", "(", "allTracks", ")", ")", "\n", "\n", "# Face clips cropping", "\n", "for", "ii", ",", "track", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "allTracks", ")", ",", "total", "=", "len", "(", "allTracks", ")", ")", ":", "\n", "\t\t", "vidTracks", ".", "append", "(", "crop_video", "(", "args", ",", "track", ",", "os", ".", "path", ".", "join", "(", "args", ".", "pycropPath", ",", "'%05d'", "%", "ii", ")", ")", ")", "\n", "", "savePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyworkPath", ",", "'tracks.pckl'", ")", "\n", "with", "open", "(", "savePath", ",", "'wb'", ")", "as", "fil", ":", "\n", "\t\t", "pickle", ".", "dump", "(", "vidTracks", ",", "fil", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Face Crop and saved in %s tracks \\r\\n\"", "%", "args", ".", "pycropPath", ")", "\n", "fil", "=", "open", "(", "savePath", ",", "'rb'", ")", "\n", "vidTracks", "=", "pickle", ".", "load", "(", "fil", ")", "\n", "\n", "# Active Speaker Detection by TalkNet", "\n", "files", "=", "glob", ".", "glob", "(", "\"%s/*.avi\"", "%", "args", ".", "pycropPath", ")", "\n", "files", ".", "sort", "(", ")", "\n", "scores", "=", "evaluate_network", "(", "files", ",", "args", ")", "\n", "savePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "pyworkPath", ",", "'scores.pckl'", ")", "\n", "with", "open", "(", "savePath", ",", "'wb'", ")", "as", "fil", ":", "\n", "\t\t", "pickle", ".", "dump", "(", "scores", ",", "fil", ")", "\n", "", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", "+", "\" Scores extracted and saved in %s \\r\\n\"", "%", "args", ".", "pyworkPath", ")", "\n", "\n", "if", "args", ".", "evalCol", "==", "True", ":", "\n", "\t\t", "evaluate_col_ASD", "(", "vidTracks", ",", "scores", ",", "args", ")", "# The columnbia video is too big for visualization. You can still add the `visualization` funcition here if you want", "\n", "quit", "(", ")", "\n", "", "else", ":", "\n", "# Visualization, save the result as the new video\t", "\n", "\t\t", "visualization", "(", "vidTracks", ",", "scores", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.__init__": [[11, 20], ["torch.Module.__init__", "model.talkNetModel.talkNetModel().cuda", "loss.lossAV().cuda", "loss.lossA().cuda", "loss.lossV().cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "print", "talkNet.talkNet.parameters", "model.talkNetModel.talkNetModel", "loss.lossAV", "loss.lossA", "loss.lossV", "time.strftime", "sum", "param.numel", "talkNet.talkNet.model.parameters"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lr", "=", "0.0001", ",", "lrDecay", "=", "0.95", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "talkNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "talkNetModel", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "lossAV", "=", "lossAV", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "lossA", "=", "lossA", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "lossV", "=", "lossV", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "optim", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "optim", ",", "step_size", "=", "1", ",", "gamma", "=", "lrDecay", ")", "\n", "print", "(", "time", ".", "strftime", "(", "\"%m-%d %H:%M:%S\"", ")", "+", "\" Model para number = %.2f\"", "%", "(", "sum", "(", "param", ".", "numel", "(", ")", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ")", "/", "1024", "/", "1024", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.train_network": [[21, 50], ["talkNet.talkNet.train", "talkNet.talkNet.scheduler.step", "enumerate", "sys.stdout.write", "talkNet.talkNet.zero_grad", "talkNet.talkNet.model.forward_audio_frontend", "talkNet.talkNet.model.forward_visual_frontend", "talkNet.talkNet.model.forward_cross_attention", "talkNet.talkNet.model.forward_audio_visual_backend", "talkNet.talkNet.model.forward_audio_backend", "talkNet.talkNet.model.forward_visual_backend", "labels[].reshape().cuda", "talkNet.talkNet.lossAV.forward", "talkNet.talkNet.lossA.forward", "talkNet.talkNet.lossV.forward", "nloss.detach().cpu().numpy", "nloss.backward", "talkNet.talkNet.optim.step", "len", "sys.stderr.write", "sys.stderr.flush", "audioFeature[].cuda", "visualFeature[].cuda", "labels[].reshape", "nloss.detach().cpu", "time.strftime", "nloss.detach", "loader.__len__"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_cross_attention", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_visual_backend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_backend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_backend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.dataLoader.val_loader.__len__"], ["", "def", "train_network", "(", "self", ",", "loader", ",", "epoch", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "self", ".", "scheduler", ".", "step", "(", "epoch", "-", "1", ")", "\n", "index", ",", "top1", ",", "loss", "=", "0", ",", "0", ",", "0", "\n", "lr", "=", "self", ".", "optim", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "for", "num", ",", "(", "audioFeature", ",", "visualFeature", ",", "labels", ")", "in", "enumerate", "(", "loader", ",", "start", "=", "1", ")", ":", "\n", "            ", "self", ".", "zero_grad", "(", ")", "\n", "audioEmbed", "=", "self", ".", "model", ".", "forward_audio_frontend", "(", "audioFeature", "[", "0", "]", ".", "cuda", "(", ")", ")", "# feedForward", "\n", "visualEmbed", "=", "self", ".", "model", ".", "forward_visual_frontend", "(", "visualFeature", "[", "0", "]", ".", "cuda", "(", ")", ")", "\n", "audioEmbed", ",", "visualEmbed", "=", "self", ".", "model", ".", "forward_cross_attention", "(", "audioEmbed", ",", "visualEmbed", ")", "\n", "outsAV", "=", "self", ".", "model", ".", "forward_audio_visual_backend", "(", "audioEmbed", ",", "visualEmbed", ")", "\n", "outsA", "=", "self", ".", "model", ".", "forward_audio_backend", "(", "audioEmbed", ")", "\n", "outsV", "=", "self", ".", "model", ".", "forward_visual_backend", "(", "visualEmbed", ")", "\n", "labels", "=", "labels", "[", "0", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ".", "cuda", "(", ")", "# Loss", "\n", "nlossAV", ",", "_", ",", "_", ",", "prec", "=", "self", ".", "lossAV", ".", "forward", "(", "outsAV", ",", "labels", ")", "\n", "nlossA", "=", "self", ".", "lossA", ".", "forward", "(", "outsA", ",", "labels", ")", "\n", "nlossV", "=", "self", ".", "lossV", ".", "forward", "(", "outsV", ",", "labels", ")", "\n", "nloss", "=", "nlossAV", "+", "0.4", "*", "nlossA", "+", "0.4", "*", "nlossV", "\n", "loss", "+=", "nloss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "top1", "+=", "prec", "\n", "nloss", ".", "backward", "(", ")", "\n", "self", ".", "optim", ".", "step", "(", ")", "\n", "index", "+=", "len", "(", "labels", ")", "\n", "sys", ".", "stderr", ".", "write", "(", "time", ".", "strftime", "(", "\"%m-%d %H:%M:%S\"", ")", "+", "\" [%2d] Lr: %5f, Training: %.2f%%, \"", "%", "(", "epoch", ",", "lr", ",", "100", "*", "(", "num", "/", "loader", ".", "__len__", "(", ")", ")", ")", "+", "\" Loss: %.5f, ACC: %2.2f%% \\r\"", "%", "(", "loss", "/", "(", "num", ")", ",", "100", "*", "(", "top1", "/", "index", ")", ")", ")", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "", "sys", ".", "stdout", ".", "write", "(", "\"\\n\"", ")", "\n", "return", "loss", "/", "num", ",", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.evaluate_network": [[51, 77], ["talkNet.talkNet.eval", "tqdm.tqdm", "pandas.Series", "pandas.Series", "pandas.read_csv", "pandas.read_csv.drop", "pandas.read_csv.drop", "pandas.read_csv.to_csv", "float", "open().read().splitlines", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "talkNet.talkNet.model.forward_audio_frontend", "talkNet.talkNet.model.forward_visual_frontend", "talkNet.talkNet.model.forward_cross_attention", "talkNet.talkNet.model.forward_audio_visual_backend", "labels[].reshape().cuda", "talkNet.talkNet.lossAV.forward", "predScore[].detach().cpu().numpy", "predScores.extend", "audioFeature[].cuda", "visualFeature[].cuda", "open().read", "str().split", "labels[].reshape", "predScore[].detach().cpu", "open", "str", "predScore[].detach", "subprocess.run"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_frontend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_cross_attention", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_visual_backend", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward"], ["", "def", "evaluate_network", "(", "self", ",", "loader", ",", "evalCsvSave", ",", "evalOrig", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "eval", "(", ")", "\n", "predScores", "=", "[", "]", "\n", "for", "audioFeature", ",", "visualFeature", ",", "labels", "in", "tqdm", ".", "tqdm", "(", "loader", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "audioEmbed", "=", "self", ".", "model", ".", "forward_audio_frontend", "(", "audioFeature", "[", "0", "]", ".", "cuda", "(", ")", ")", "\n", "visualEmbed", "=", "self", ".", "model", ".", "forward_visual_frontend", "(", "visualFeature", "[", "0", "]", ".", "cuda", "(", ")", ")", "\n", "audioEmbed", ",", "visualEmbed", "=", "self", ".", "model", ".", "forward_cross_attention", "(", "audioEmbed", ",", "visualEmbed", ")", "\n", "outsAV", "=", "self", ".", "model", ".", "forward_audio_visual_backend", "(", "audioEmbed", ",", "visualEmbed", ")", "\n", "labels", "=", "labels", "[", "0", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", ".", "cuda", "(", ")", "\n", "_", ",", "predScore", ",", "_", ",", "_", "=", "self", ".", "lossAV", ".", "forward", "(", "outsAV", ",", "labels", ")", "\n", "predScore", "=", "predScore", "[", ":", ",", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "predScores", ".", "extend", "(", "predScore", ")", "\n", "", "", "evalLines", "=", "open", "(", "evalOrig", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "[", "1", ":", "]", "\n", "labels", "=", "[", "]", "\n", "labels", "=", "pandas", ".", "Series", "(", "[", "'SPEAKING_AUDIBLE'", "for", "line", "in", "evalLines", "]", ")", "\n", "scores", "=", "pandas", ".", "Series", "(", "predScores", ")", "\n", "evalRes", "=", "pandas", ".", "read_csv", "(", "evalOrig", ")", "\n", "evalRes", "[", "'score'", "]", "=", "scores", "\n", "evalRes", "[", "'label'", "]", "=", "labels", "\n", "evalRes", ".", "drop", "(", "[", "'label_id'", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "evalRes", ".", "drop", "(", "[", "'instance_id'", "]", ",", "axis", "=", "1", ",", "inplace", "=", "True", ")", "\n", "evalRes", ".", "to_csv", "(", "evalCsvSave", ",", "index", "=", "False", ")", "\n", "cmd", "=", "\"python -O utils/get_ava_active_speaker_performance.py -g %s -p %s \"", "%", "(", "evalOrig", ",", "evalCsvSave", ")", "\n", "mAP", "=", "float", "(", "str", "(", "subprocess", ".", "run", "(", "cmd", ",", "shell", "=", "True", ",", "capture_output", "=", "True", ")", ".", "stdout", ")", ".", "split", "(", "' '", ")", "[", "2", "]", "[", ":", "5", "]", ")", "\n", "return", "mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.saveParameters": [[78, 80], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "talkNet.talkNet.state_dict"], "methods", ["None"], ["", "def", "saveParameters", "(", "self", ",", "path", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.None.talkNet.talkNet.loadParameters": [[81, 95], ["talkNet.talkNet.state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load.items", "torch.load.items", "torch.load.items", "talkNet.talkNet.copy_", "name.replace.replace.replace", "talkNet.talkNet.size", "loadedState[].size", "sys.stderr.write", "print", "talkNet.talkNet.size", "loadedState[].size"], "methods", ["None"], ["", "def", "loadParameters", "(", "self", ",", "path", ")", ":", "\n", "        ", "selfState", "=", "self", ".", "state_dict", "(", ")", "\n", "loadedState", "=", "torch", ".", "load", "(", "path", ")", "\n", "for", "name", ",", "param", "in", "loadedState", ".", "items", "(", ")", ":", "\n", "            ", "origName", "=", "name", ";", "\n", "if", "name", "not", "in", "selfState", ":", "\n", "                ", "name", "=", "name", ".", "replace", "(", "\"module.\"", ",", "\"\"", ")", "\n", "if", "name", "not", "in", "selfState", ":", "\n", "                    ", "print", "(", "\"%s is not in the model.\"", "%", "origName", ")", "\n", "continue", "\n", "", "", "if", "selfState", "[", "name", "]", ".", "size", "(", ")", "!=", "loadedState", "[", "origName", "]", ".", "size", "(", ")", ":", "\n", "                ", "sys", ".", "stderr", ".", "write", "(", "\"Wrong parameter length: %s, model: %s, loaded: %s\"", "%", "(", "origName", ",", "selfState", "[", "name", "]", ".", "size", "(", ")", ",", "loadedState", "[", "origName", "]", ".", "size", "(", ")", ")", ")", "\n", "continue", "\n", "", "selfState", "[", "name", "]", ".", "copy_", "(", "param", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.init_args": [[4, 27], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "init_args", "(", "args", ")", ":", "\n", "# The details for the following folders/files can be found in the annotation of the function 'preprocess_AVA' below", "\n", "    ", "args", ".", "modelSavePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'model'", ")", "\n", "args", ".", "scoreSavePath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'score.txt'", ")", "\n", "args", ".", "trialPathAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataPathAVA", ",", "'csv'", ")", "\n", "args", ".", "audioOrigPathAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataPathAVA", ",", "'orig_audios'", ")", "\n", "args", ".", "visualOrigPathAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataPathAVA", ",", "'orig_videos'", ")", "\n", "args", ".", "audioPathAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataPathAVA", ",", "'clips_audios'", ")", "\n", "args", ".", "visualPathAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dataPathAVA", ",", "'clips_videos'", ")", "\n", "args", ".", "trainTrialAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'train_loader.csv'", ")", "\n", "\n", "if", "args", ".", "evalDataType", "==", "'val'", ":", "\n", "        ", "args", ".", "evalTrialAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'val_loader.csv'", ")", "\n", "args", ".", "evalOrig", "=", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'val_orig.csv'", ")", "\n", "args", ".", "evalCsvSave", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'val_res.csv'", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "evalTrialAVA", "=", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'test_loader.csv'", ")", "\n", "args", ".", "evalOrig", "=", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'test_orig.csv'", ")", "\n", "args", ".", "evalCsvSave", "=", "os", ".", "path", ".", "join", "(", "args", ".", "savePath", ",", "'test_res.csv'", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "args", ".", "modelSavePath", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "dataPathAVA", ",", "exist_ok", "=", "True", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_pretrain_model_AVA": [[29, 34], ["os.path.isfile", "subprocess.call"], "function", ["None"], ["", "def", "download_pretrain_model_AVA", "(", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "'pretrain_AVA.model'", ")", "==", "False", ":", "\n", "        ", "Link", "=", "\"1NVIkksrD3zbxbDuDbPc_846bLfPSZcZm\"", "\n", "cmd", "=", "\"gdown --id %s -O %s\"", "%", "(", "Link", ",", "'pretrain_AVA.model'", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.preprocess_AVA": [[35, 73], ["tools.download_csv", "tools.download_videos", "tools.extract_audio", "tools.extract_audio_clips", "tools.extract_video_clips"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_csv", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_videos", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_audio", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_audio_clips", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_video_clips"], ["", "", "def", "preprocess_AVA", "(", "args", ")", ":", "\n", "# This preprocesstion is modified based on this [repository](https://github.com/fuankarion/active-speakers-context).", "\n", "# The required space is 302 G. ", "\n", "# If you do not have enough space, you can delate `orig_videos`(167G) when you get `clips_videos(85G)`.", "\n", "#                             also you can delate `orig_audios`(44G) when you get `clips_audios`(6.4G).", "\n", "# So the final space is less than 100G.", "\n", "# The AVA dataset will be saved in 'AVApath' folder like the following format:", "\n", "# ```", "\n", "# \u251c\u2500\u2500 clips_audios  (The audio clips cut from the original movies)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 train", "\n", "# \u2502\u00a0\u00a0 \u2514\u2500\u2500 val", "\n", "# \u251c\u2500\u2500 clips_videos (The face clips cut from the original movies, be save in the image format, frame-by-frame)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 train", "\n", "# \u2502\u00a0\u00a0 \u2514\u2500\u2500 val", "\n", "# \u251c\u2500\u2500 csv", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_file_list.txt (name of the test videos)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_loader.csv (The csv file we generated to load data for testing)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test_orig.csv (The combination of the given test csv files)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 train_loader.csv (The csv file we generated to load data for training)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 train_orig.csv (The combination of the given training csv files)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 trainval_file_list.txt (name of the train/val videos)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 val_loader.csv (The csv file we generated to load data for validation)", "\n", "# \u2502\u00a0\u00a0 \u2514\u2500\u2500 val_orig.csv (The combination of the given validation csv files)", "\n", "# \u251c\u2500\u2500 orig_audios (The original audios from the movies)", "\n", "# \u2502\u00a0\u00a0 \u251c\u2500\u2500 test", "\n", "# \u2502\u00a0\u00a0 \u2514\u2500\u2500 trainval", "\n", "# \u2514\u2500\u2500 orig_videos (The original movies)", "\n", "#     \u251c\u2500\u2500 test", "\n", "#     \u2514\u2500\u2500 trainval", "\n", "# ```", "\n", "\n", "    ", "download_csv", "(", "args", ")", "# Take 1 minute ", "\n", "download_videos", "(", "args", ")", "# Take 6 hours", "\n", "extract_audio", "(", "args", ")", "# Take 1 hour", "\n", "extract_audio_clips", "(", "args", ")", "# Take 3 minutes", "\n", "extract_video_clips", "(", "args", ")", "# Take about 2 days", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_csv": [[74, 82], ["subprocess.call", "subprocess.call", "os.remove"], "function", ["None"], ["", "def", "download_csv", "(", "args", ")", ":", "\n", "# Take 1 minute to download the required csv files", "\n", "    ", "Link", "=", "\"1C1cGxPHaJAl1NQ2i7IhRgWmdvsPhBCUy\"", "\n", "cmd", "=", "\"gdown --id %s -O %s\"", "%", "(", "Link", ",", "args", ".", "dataPathAVA", "+", "'/csv.tar.gz'", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "cmd", "=", "\"tar -xzvf %s -C %s\"", "%", "(", "args", ".", "dataPathAVA", "+", "'/csv.tar.gz'", ",", "args", ".", "dataPathAVA", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "os", ".", "remove", "(", "args", ".", "dataPathAVA", "+", "'/csv.tar.gz'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.download_videos": [[83, 91], ["open().read().splitlines", "subprocess.call", "open().read", "open"], "function", ["None"], ["", "def", "download_videos", "(", "args", ")", ":", "\n", "# Take 6 hours to download the original movies, follow this repository: https://github.com/cvdfoundation/ava-dataset", "\n", "    ", "for", "dataType", "in", "[", "'trainval'", ",", "'test'", "]", ":", "\n", "        ", "fileList", "=", "open", "(", "'%s/%s_file_list.txt'", "%", "(", "args", ".", "trialPathAVA", ",", "dataType", ")", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "outFolder", "=", "'%s/%s'", "%", "(", "args", ".", "visualOrigPathAVA", ",", "dataType", ")", "\n", "for", "fileName", "in", "fileList", ":", "\n", "            ", "cmd", "=", "\"wget -P %s https://s3.amazonaws.com/ava-dataset/%s/%s\"", "%", "(", "outFolder", ",", "dataType", ",", "fileName", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_audio": [[92, 103], ["os.makedirs", "glob.glob", "tqdm.tqdm", "subprocess.call", "[].split", "videoPath.split"], "function", ["None"], ["", "", "", "def", "extract_audio", "(", "args", ")", ":", "\n", "# Take 1 hour to extract the audio from movies", "\n", "    ", "for", "dataType", "in", "[", "'trainval'", ",", "'test'", "]", ":", "\n", "        ", "inpFolder", "=", "'%s/%s'", "%", "(", "args", ".", "visualOrigPathAVA", ",", "dataType", ")", "\n", "outFolder", "=", "'%s/%s'", "%", "(", "args", ".", "audioOrigPathAVA", ",", "dataType", ")", "\n", "os", ".", "makedirs", "(", "outFolder", ",", "exist_ok", "=", "True", ")", "\n", "videos", "=", "glob", ".", "glob", "(", "\"%s/*\"", "%", "(", "inpFolder", ")", ")", "\n", "for", "videoPath", "in", "tqdm", ".", "tqdm", "(", "videos", ")", ":", "\n", "            ", "audioPath", "=", "'%s/%s'", "%", "(", "outFolder", ",", "videoPath", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.wav'", ")", "\n", "cmd", "=", "(", "\"ffmpeg -y -i %s -async 1 -ac 1 -vn -acodec pcm_s16le -ar 16000 -threads 8 %s -loglevel panic\"", "%", "(", "videoPath", ",", "audioPath", ")", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_audio_clips": [[105, 140], ["pandas.read_csv", "pandas.concat", "dfNeg[].unique().tolist", "dfPos[].unique().tolist", "pandas.concat().reset_index", "df.groupby.sort_values().reset_index", "df[].unique().tolist", "df.groupby.groupby", "os.path.join", "os.path.join", "df[].unique().tolist", "tqdm.tqdm", "os.path.join", "os.path.join", "df.groupby.get_group", "os.path.join", "int", "int", "scipy.io.wavfile.write", "dfNeg[].unique", "dfPos[].unique", "pandas.concat", "df.groupby.sort_values", "df[].unique", "df[].unique", "os.path.isdir", "os.makedirs", "len", "audioFeatures.keys", "os.path.join", "scipy.io.wavfile.read", "float", "float"], "function", ["None"], ["", "", "", "def", "extract_audio_clips", "(", "args", ")", ":", "\n", "# Take 3 minutes to extract the audio clips", "\n", "    ", "dic", "=", "{", "'train'", ":", "'trainval'", ",", "'val'", ":", "'trainval'", ",", "'test'", ":", "'test'", "}", "\n", "for", "dataType", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "        ", "df", "=", "pandas", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'%s_orig.csv'", "%", "(", "dataType", ")", ")", ",", "engine", "=", "'python'", ")", "\n", "dfNeg", "=", "pandas", ".", "concat", "(", "[", "df", "[", "df", "[", "'label_id'", "]", "==", "0", "]", ",", "df", "[", "df", "[", "'label_id'", "]", "==", "2", "]", "]", ")", "\n", "dfPos", "=", "df", "[", "df", "[", "'label_id'", "]", "==", "1", "]", "\n", "insNeg", "=", "dfNeg", "[", "'instance_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "insPos", "=", "dfPos", "[", "'instance_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "df", "=", "pandas", ".", "concat", "(", "[", "dfPos", ",", "dfNeg", "]", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "[", "'entity_id'", ",", "'frame_timestamp'", "]", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "entityList", "=", "df", "[", "'entity_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "df", "=", "df", ".", "groupby", "(", "'entity_id'", ")", "\n", "audioFeatures", "=", "{", "}", "\n", "outDir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "audioPathAVA", ",", "dataType", ")", "\n", "audioDir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "audioOrigPathAVA", ",", "dic", "[", "dataType", "]", ")", "\n", "for", "l", "in", "df", "[", "'video_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", ":", "\n", "            ", "d", "=", "os", ".", "path", ".", "join", "(", "outDir", ",", "l", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "d", ")", "\n", "", "", "for", "entity", "in", "tqdm", ".", "tqdm", "(", "entityList", ",", "total", "=", "len", "(", "entityList", ")", ")", ":", "\n", "            ", "insData", "=", "df", ".", "get_group", "(", "entity", ")", "\n", "videoKey", "=", "insData", ".", "iloc", "[", "0", "]", "[", "'video_id'", "]", "\n", "start", "=", "insData", ".", "iloc", "[", "0", "]", "[", "'frame_timestamp'", "]", "\n", "end", "=", "insData", ".", "iloc", "[", "-", "1", "]", "[", "'frame_timestamp'", "]", "\n", "entityID", "=", "insData", ".", "iloc", "[", "0", "]", "[", "'entity_id'", "]", "\n", "insPath", "=", "os", ".", "path", ".", "join", "(", "outDir", ",", "videoKey", ",", "entityID", "+", "'.wav'", ")", "\n", "if", "videoKey", "not", "in", "audioFeatures", ".", "keys", "(", ")", ":", "\n", "                ", "audioFile", "=", "os", ".", "path", ".", "join", "(", "audioDir", ",", "videoKey", "+", "'.wav'", ")", "\n", "sr", ",", "audio", "=", "wavfile", ".", "read", "(", "audioFile", ")", "\n", "audioFeatures", "[", "videoKey", "]", "=", "audio", "\n", "", "audioStart", "=", "int", "(", "float", "(", "start", ")", "*", "sr", ")", "\n", "audioEnd", "=", "int", "(", "float", "(", "end", ")", "*", "sr", ")", "\n", "audioData", "=", "audioFeatures", "[", "videoKey", "]", "[", "audioStart", ":", "audioEnd", "]", "\n", "wavfile", ".", "write", "(", "insPath", ",", "sr", ",", "audioData", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.tools.extract_video_clips": [[141, 187], ["pandas.read_csv", "pandas.concat", "dfNeg[].unique().tolist", "dfPos[].unique().tolist", "pandas.concat().reset_index", "df.groupby.sort_values().reset_index", "df[].unique().tolist", "df.groupby.groupby", "os.path.join", "os.path.join", "df[].unique().tolist", "tqdm.tqdm", "os.path.join", "os.path.join", "df.groupby.get_group", "os.path.join", "cv2.VideoCapture", "os.path.join", "df.get_group.iterrows", "dfNeg[].unique", "dfPos[].unique", "pandas.concat", "df.groupby.sort_values", "df[].unique", "df[].unique", "os.path.isdir", "os.makedirs", "len", "glob.glob", "os.path.join", "os.path.isdir", "os.makedirs", "os.path.join", "cv2.VideoCapture.set", "cv2.VideoCapture.read", "numpy.size", "numpy.size", "int", "int", "int", "int", "cv2.imwrite", "os.path.join", "str"], "function", ["None"], ["", "", "", "def", "extract_video_clips", "(", "args", ")", ":", "\n", "# Take about 2 days to crop the face clips.", "\n", "# You can optimize this code to save time, while this process is one-time.", "\n", "# If you do not need the data for the test set, you can only deal with the train and val part. That will take 1 day.", "\n", "# This procession may have many warning info, you can just ignore it.", "\n", "    ", "dic", "=", "{", "'train'", ":", "'trainval'", ",", "'val'", ":", "'trainval'", ",", "'test'", ":", "'test'", "}", "\n", "for", "dataType", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "        ", "df", "=", "pandas", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "args", ".", "trialPathAVA", ",", "'%s_orig.csv'", "%", "(", "dataType", ")", ")", ")", "\n", "dfNeg", "=", "pandas", ".", "concat", "(", "[", "df", "[", "df", "[", "'label_id'", "]", "==", "0", "]", ",", "df", "[", "df", "[", "'label_id'", "]", "==", "2", "]", "]", ")", "\n", "dfPos", "=", "df", "[", "df", "[", "'label_id'", "]", "==", "1", "]", "\n", "insNeg", "=", "dfNeg", "[", "'instance_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "insPos", "=", "dfPos", "[", "'instance_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "df", "=", "pandas", ".", "concat", "(", "[", "dfPos", ",", "dfNeg", "]", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "[", "'entity_id'", ",", "'frame_timestamp'", "]", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "entityList", "=", "df", "[", "'entity_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "df", "=", "df", ".", "groupby", "(", "'entity_id'", ")", "\n", "outDir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualPathAVA", ",", "dataType", ")", "\n", "audioDir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualOrigPathAVA", ",", "dic", "[", "dataType", "]", ")", "\n", "for", "l", "in", "df", "[", "'video_id'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", ":", "\n", "            ", "d", "=", "os", ".", "path", ".", "join", "(", "outDir", ",", "l", "[", "0", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "d", ")", "\n", "", "", "for", "entity", "in", "tqdm", ".", "tqdm", "(", "entityList", ",", "total", "=", "len", "(", "entityList", ")", ")", ":", "\n", "            ", "insData", "=", "df", ".", "get_group", "(", "entity", ")", "\n", "videoKey", "=", "insData", ".", "iloc", "[", "0", "]", "[", "'video_id'", "]", "\n", "entityID", "=", "insData", ".", "iloc", "[", "0", "]", "[", "'entity_id'", "]", "\n", "videoDir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualOrigPathAVA", ",", "dic", "[", "dataType", "]", ")", "\n", "videoFile", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "videoDir", ",", "'{}.*'", ".", "format", "(", "videoKey", ")", ")", ")", "[", "0", "]", "\n", "V", "=", "cv2", ".", "VideoCapture", "(", "videoFile", ")", "\n", "insDir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "outDir", ",", "videoKey", ",", "entityID", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "insDir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "insDir", ")", "\n", "", "j", "=", "0", "\n", "for", "_", ",", "row", "in", "insData", ".", "iterrows", "(", ")", ":", "\n", "                ", "imageFilename", "=", "os", ".", "path", ".", "join", "(", "insDir", ",", "str", "(", "\"%.2f\"", "%", "row", "[", "'frame_timestamp'", "]", ")", "+", "'.jpg'", ")", "\n", "V", ".", "set", "(", "cv2", ".", "CAP_PROP_POS_MSEC", ",", "row", "[", "'frame_timestamp'", "]", "*", "1e3", ")", "\n", "_", ",", "frame", "=", "V", ".", "read", "(", ")", "\n", "h", "=", "numpy", ".", "size", "(", "frame", ",", "0", ")", "\n", "w", "=", "numpy", ".", "size", "(", "frame", ",", "1", ")", "\n", "x1", "=", "int", "(", "row", "[", "'entity_box_x1'", "]", "*", "w", ")", "\n", "y1", "=", "int", "(", "row", "[", "'entity_box_y1'", "]", "*", "h", ")", "\n", "x2", "=", "int", "(", "row", "[", "'entity_box_x2'", "]", "*", "w", ")", "\n", "y2", "=", "int", "(", "row", "[", "'entity_box_y2'", "]", "*", "h", ")", "\n", "face", "=", "frame", "[", "y1", ":", "y2", ",", "x1", ":", "x2", ",", ":", "]", "\n", "j", "=", "j", "+", "1", "\n", "cv2", ".", "imwrite", "(", "imageFilename", ",", "face", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.compute_average_precision": [[23, 68], ["numpy.concatenate", "numpy.concatenate", "range", "numpy.sum", "ValueError", "ValueError", "len", "len", "ValueError", "ValueError", "ValueError", "all", "ValueError", "numpy.maximum", "ValueError", "isinstance", "isinstance", "numpy.amin", "numpy.amax", "numpy.amin", "numpy.amax", "len", "numpy.where", "range", "len"], "function", ["None"], ["def", "compute_average_precision", "(", "precision", ",", "recall", ")", ":", "\n", "  ", "\"\"\"Compute Average Precision according to the definition in VOCdevkit.\n  Precision is modified to ensure that it does not decrease as recall\n  decrease.\n  Args:\n    precision: A float [N, 1] numpy array of precisions\n    recall: A float [N, 1] numpy array of recalls\n  Raises:\n    ValueError: if the input is not of the correct format\n  Returns:\n    average_precison: The area under the precision recall curve. NaN if\n      precision and recall are None.\n  \"\"\"", "\n", "if", "precision", "is", "None", ":", "\n", "    ", "if", "recall", "is", "not", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\"If precision is None, recall must also be None\"", ")", "\n", "", "return", "np", ".", "NAN", "\n", "\n", "", "if", "not", "isinstance", "(", "precision", ",", "np", ".", "ndarray", ")", "or", "not", "isinstance", "(", "\n", "recall", ",", "np", ".", "ndarray", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"precision and recall must be numpy array\"", ")", "\n", "", "if", "precision", ".", "dtype", "!=", "np", ".", "float", "or", "recall", ".", "dtype", "!=", "np", ".", "float", ":", "\n", "    ", "raise", "ValueError", "(", "\"input must be float numpy array.\"", ")", "\n", "", "if", "len", "(", "precision", ")", "!=", "len", "(", "recall", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"precision and recall must be of the same size.\"", ")", "\n", "", "if", "not", "precision", ".", "size", ":", "\n", "    ", "return", "0.0", "\n", "", "if", "np", ".", "amin", "(", "precision", ")", "<", "0", "or", "np", ".", "amax", "(", "precision", ")", ">", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"Precision must be in the range of [0, 1].\"", ")", "\n", "", "if", "np", ".", "amin", "(", "recall", ")", "<", "0", "or", "np", ".", "amax", "(", "recall", ")", ">", "1", ":", "\n", "    ", "raise", "ValueError", "(", "\"recall must be in the range of [0, 1].\"", ")", "\n", "", "if", "not", "all", "(", "recall", "[", "i", "]", "<=", "recall", "[", "i", "+", "1", "]", "for", "i", "in", "range", "(", "len", "(", "recall", ")", "-", "1", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"recall must be a non-decreasing array\"", ")", "\n", "\n", "", "recall", "=", "np", ".", "concatenate", "(", "[", "[", "0", "]", ",", "recall", ",", "[", "1", "]", "]", ")", "\n", "precision", "=", "np", ".", "concatenate", "(", "[", "[", "0", "]", ",", "precision", ",", "[", "0", "]", "]", ")", "\n", "\n", "# Smooth precision to be monotonically decreasing.", "\n", "for", "i", "in", "range", "(", "len", "(", "precision", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "    ", "precision", "[", "i", "]", "=", "np", ".", "maximum", "(", "precision", "[", "i", "]", ",", "precision", "[", "i", "+", "1", "]", ")", "\n", "\n", "", "indices", "=", "np", ".", "where", "(", "recall", "[", "1", ":", "]", "!=", "recall", "[", ":", "-", "1", "]", ")", "[", "0", "]", "+", "1", "\n", "average_precision", "=", "np", ".", "sum", "(", "\n", "(", "recall", "[", "indices", "]", "-", "recall", "[", "indices", "-", "1", "]", ")", "*", "precision", "[", "indices", "]", ")", "\n", "return", "average_precision", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.load_csv": [[70, 87], ["pandas.read_csv", "df[].map"], "function", ["None"], ["", "def", "load_csv", "(", "filename", ",", "column_names", ")", ":", "\n", "  ", "\"\"\"Loads CSV from the filename using given column names.\n  Adds uid column.\n  Args:\n    filename: Path to the CSV file to load.\n    column_names: A list of column names for the data.\n  Returns:\n    df: A Pandas DataFrame containing the data.\n  \"\"\"", "\n", "# Here and elsewhere, df indicates a DataFrame variable.", "\n", "\n", "df", "=", "pd", ".", "read_csv", "(", "filename", ",", "usecols", "=", "column_names", ")", "\n", "#df = pd.read_csv(filename, header=None, names=column_names)", "\n", "\n", "# Creates a unique id from frame timestamp and entity id.", "\n", "df", "[", "\"uid\"", "]", "=", "(", "df", "[", "\"frame_timestamp\"", "]", ".", "map", "(", "str", ")", "+", "\":\"", "+", "df", "[", "\"entity_id\"", "]", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.eq": [[89, 92], ["abs"], "function", ["None"], ["", "def", "eq", "(", "a", ",", "b", ",", "tolerance", "=", "1e-09", ")", ":", "\n", "  ", "\"\"\"Returns true if values are approximately equal.\"\"\"", "\n", "return", "abs", "(", "a", "-", "b", ")", "<=", "tolerance", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.merge_groundtruth_and_predictions": [[94, 143], ["df_groundtruth.merge().sort_values().reset_index", "numpy.where", "df_groundtruth[].count", "df_predictions[].count", "ValueError", "df_predictions[].unique", "ValueError", "df_predictions[].count", "df_predictions[].count", "ValueError", "ValueError", "df_groundtruth.merge().sort_values", "get_ava_active_speaker_performance.eq", "get_ava_active_speaker_performance.eq", "str", "df_groundtruth.merge", "get_ava_active_speaker_performance.eq", "get_ava_active_speaker_performance.eq", "list"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.eq", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.eq", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.eq", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.eq"], ["", "def", "merge_groundtruth_and_predictions", "(", "df_groundtruth", ",", "df_predictions", ")", ":", "\n", "  ", "\"\"\"Merges groundtruth and prediction DataFrames.\n  The returned DataFrame is merged on uid field and sorted in descending order\n  by score field. Bounding boxes are checked to make sure they match between\n  groundtruth and predictions.\n  Args:\n    df_groundtruth: A DataFrame with groundtruth data.\n    df_predictions: A DataFrame with predictions data.\n  Returns:\n    df_merged: A merged DataFrame, with rows matched on uid column.\n  \"\"\"", "\n", "if", "df_groundtruth", "[", "\"uid\"", "]", ".", "count", "(", ")", "!=", "df_predictions", "[", "\"uid\"", "]", ".", "count", "(", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Groundtruth and predictions CSV must have the same number of \"", "\n", "\"unique rows.\"", ")", "\n", "# print(df_predictions[\"label\"].unique())", "\n", "", "if", "df_predictions", "[", "\"label\"", "]", ".", "unique", "(", ")", "!=", "[", "\"SPEAKING_AUDIBLE\"", "]", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Predictions CSV must contain only SPEAKING_AUDIBLE label.\"", ")", "\n", "\n", "", "if", "df_predictions", "[", "\"score\"", "]", ".", "count", "(", ")", "<", "df_predictions", "[", "\"uid\"", "]", ".", "count", "(", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\"Predictions CSV must contain score value for every row.\"", ")", "\n", "\n", "# Merges groundtruth and predictions on uid, validates that uid is unique", "\n", "# in both frames, and sorts the resulting frame by the predictions score.", "\n", "", "df_merged", "=", "df_groundtruth", ".", "merge", "(", "\n", "df_predictions", ",", "\n", "on", "=", "\"uid\"", ",", "\n", "suffixes", "=", "(", "\"_groundtruth\"", ",", "\"_prediction\"", ")", ",", "\n", "validate", "=", "\"1:1\"", ")", ".", "sort_values", "(", "\n", "by", "=", "[", "\"score\"", "]", ",", "ascending", "=", "False", ")", ".", "reset_index", "(", ")", "\n", "# Validates that bounding boxes in ground truth and predictions match for the", "\n", "# same uids.", "\n", "df_merged", "[", "\"bounding_box_correct\"", "]", "=", "np", ".", "where", "(", "\n", "eq", "(", "df_merged", "[", "\"entity_box_x1_groundtruth\"", "]", ",", "\n", "df_merged", "[", "\"entity_box_x1_prediction\"", "]", ")", "\n", "&", "eq", "(", "df_merged", "[", "\"entity_box_x2_groundtruth\"", "]", ",", "\n", "df_merged", "[", "\"entity_box_x2_prediction\"", "]", ")", "\n", "&", "eq", "(", "df_merged", "[", "\"entity_box_y1_groundtruth\"", "]", ",", "\n", "df_merged", "[", "\"entity_box_y1_prediction\"", "]", ")", "\n", "&", "eq", "(", "df_merged", "[", "\"entity_box_y2_groundtruth\"", "]", ",", "\n", "df_merged", "[", "\"entity_box_y2_prediction\"", "]", ")", ",", "True", ",", "False", ")", "\n", "\n", "if", "(", "~", "df_merged", "[", "\"bounding_box_correct\"", "]", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"Mismatch between groundtruth and predictions bounding boxes found at \"", "\n", "+", "str", "(", "list", "(", "df_merged", "[", "~", "df_merged", "[", "\"bounding_box_correct\"", "]", "]", "[", "\"uid\"", "]", ")", ")", ")", "\n", "\n", "", "return", "df_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.get_all_positives": [[145, 149], ["[].count"], "function", ["None"], ["", "def", "get_all_positives", "(", "df_merged", ")", ":", "\n", "  ", "\"\"\"Counts all positive examples in the groundtruth dataset.\"\"\"", "\n", "return", "df_merged", "[", "df_merged", "[", "\"label_groundtruth\"", "]", "==", "\n", "\"SPEAKING_AUDIBLE\"", "]", "[", "\"uid\"", "]", ".", "count", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.calculate_precision_recall": [[151, 178], ["get_ava_active_speaker_performance.get_all_positives", "numpy.where", "df_merged[].cumsum", "logging.info", "numpy.array", "numpy.array", "df_merged.head"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.get_all_positives"], ["", "def", "calculate_precision_recall", "(", "df_merged", ")", ":", "\n", "  ", "\"\"\"Calculates precision and recall arrays going through df_merged row-wise.\"\"\"", "\n", "all_positives", "=", "get_all_positives", "(", "df_merged", ")", "\n", "# Populates each row with 1 if this row is a true positive", "\n", "# (at its score level).", "\n", "df_merged", "[", "\"is_tp\"", "]", "=", "np", ".", "where", "(", "\n", "(", "df_merged", "[", "\"label_groundtruth\"", "]", "==", "\"SPEAKING_AUDIBLE\"", ")", "&", "\n", "(", "df_merged", "[", "\"label_prediction\"", "]", "==", "\"SPEAKING_AUDIBLE\"", ")", ",", "1", ",", "0", ")", "\n", "\n", "# Counts true positives up to and including that row.", "\n", "df_merged", "[", "\"tp\"", "]", "=", "df_merged", "[", "\"is_tp\"", "]", ".", "cumsum", "(", ")", "\n", "\n", "# Calculates precision for every row counting true positives up to", "\n", "# and including that row over the index (1-based) of that row.", "\n", "df_merged", "[", "\"precision\"", "]", "=", "df_merged", "[", "\"tp\"", "]", "/", "(", "df_merged", ".", "index", "+", "1", ")", "\n", "# Calculates recall for every row counting true positives up to", "\n", "# and including that row over all positives in the groundtruth dataset.", "\n", "\n", "df_merged", "[", "\"recall\"", "]", "=", "df_merged", "[", "\"tp\"", "]", "/", "all_positives", "\n", "logging", ".", "info", "(", "\n", "\"\\n%s\\n\"", ",", "\n", "df_merged", ".", "head", "(", "10", ")", "[", "[", "\n", "\"uid\"", ",", "\"score\"", ",", "\"label_groundtruth\"", ",", "\"is_tp\"", ",", "\"tp\"", ",", "\"precision\"", ",", "\n", "\"recall\"", "\n", "]", "]", ")", "\n", "\n", "return", "np", ".", "array", "(", "df_merged", "[", "\"precision\"", "]", ")", ",", "np", ".", "array", "(", "df_merged", "[", "\"recall\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.run_evaluation": [[180, 199], ["get_ava_active_speaker_performance.load_csv", "get_ava_active_speaker_performance.load_csv", "get_ava_active_speaker_performance.merge_groundtruth_and_predictions", "get_ava_active_speaker_performance.calculate_precision_recall", "print", "get_ava_active_speaker_performance.compute_average_precision"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.load_csv", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.load_csv", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.merge_groundtruth_and_predictions", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.calculate_precision_recall", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.compute_average_precision"], ["", "def", "run_evaluation", "(", "groundtruth", ",", "predictions", ")", ":", "\n", "  ", "\"\"\"Runs AVA Active Speaker evaluation, printing average precision result.\"\"\"", "\n", "df_groundtruth", "=", "load_csv", "(", "\n", "groundtruth", ",", "\n", "column_names", "=", "[", "\n", "\"video_id\"", ",", "\"frame_timestamp\"", ",", "\"entity_box_x1\"", ",", "\"entity_box_y1\"", ",", "\n", "\"entity_box_x2\"", ",", "\"entity_box_y2\"", ",", "\"label\"", ",", "\"entity_id\"", "\n", "]", ")", "\n", "df_predictions", "=", "load_csv", "(", "\n", "predictions", ",", "\n", "column_names", "=", "[", "\n", "\"video_id\"", ",", "\"frame_timestamp\"", ",", "\"entity_box_x1\"", ",", "\"entity_box_y1\"", ",", "\n", "\"entity_box_x2\"", ",", "\"entity_box_y2\"", ",", "\"label\"", ",", "\"entity_id\"", ",", "\"score\"", "\n", "]", ")", "\n", "df_merged", "=", "merge_groundtruth_and_predictions", "(", "df_groundtruth", ",", "df_predictions", ")", "\n", "precision", ",", "recall", "=", "calculate_precision_recall", "(", "df_merged", ")", "\n", "mAP", "=", "100", "*", "compute_average_precision", "(", "precision", ",", "recall", ")", "\n", "print", "(", "\"average precision: %2.2f%%\"", "%", "(", "mAP", ")", ")", "\n", "return", "mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.parse_arguments": [[201, 223], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "argparse.FileType", "argparse.FileType"], "function", ["None"], ["", "def", "parse_arguments", "(", ")", ":", "\n", "  ", "\"\"\"Parses command-line flags.\n  Returns:\n    args: a named tuple containing three file objects args.labelmap,\n    args.groundtruth, and args.detections.\n  \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-g\"", ",", "\n", "\"--groundtruth\"", ",", "\n", "help", "=", "\"CSV file containing ground truth.\"", ",", "\n", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-p\"", ",", "\n", "\"--predictions\"", ",", "\n", "help", "=", "\"CSV file containing active speaker predictions.\"", ",", "\n", "type", "=", "argparse", ".", "FileType", "(", "\"r\"", ")", ",", "\n", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-v\"", ",", "\"--verbose\"", ",", "help", "=", "\"Increase output verbosity.\"", ",", "action", "=", "\"store_true\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.main": [[225, 234], ["time.time", "get_ava_active_speaker_performance.parse_arguments", "get_ava_active_speaker_performance.run_evaluation", "logging.info", "logging.basicConfig", "vars", "time.time"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.parse_arguments", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.utils.get_ava_active_speaker_performance.run_evaluation"], ["", "def", "main", "(", ")", ":", "\n", "  ", "start", "=", "time", ".", "time", "(", ")", "\n", "args", "=", "parse_arguments", "(", ")", "\n", "if", "args", ".", "verbose", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "DEBUG", ")", "\n", "", "del", "args", ".", "verbose", "\n", "mAP", "=", "run_evaluation", "(", "**", "vars", "(", "args", ")", ")", "\n", "logging", ".", "info", "(", "\"Computed in %s seconds\"", ",", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "return", "mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.get_length": [[8, 11], ["subprocess.run", "float"], "function", ["None"], ["def", "get_length", "(", "input_video", ")", ":", "\n", "\t", "result", "=", "subprocess", ".", "run", "(", "[", "'ffprobe'", ",", "'-v'", ",", "'error'", ",", "'-show_entries'", ",", "'format=duration'", ",", "'-of'", ",", "'default=noprint_wrappers=1:nokey=1'", ",", "input_video", "]", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "return", "float", "(", "result", ".", "stdout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.read_Vox_lines": [[12, 24], ["open", "f_in.readline", "int", "Tlines.append", "Flines.append"], "function", ["None"], ["", "def", "read_Vox_lines", "(", "file", ")", ":", "\n", "\t", "Tlines", ",", "Flines", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f_in", ":", "\n", "\t\t", "while", "True", ":", "\n", "\t\t\t", "line", "=", "f_in", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "\t\t\t\t", "break", "\n", "", "if", "int", "(", "line", "[", "0", "]", ")", ":", "\n", "\t\t\t\t", "Tlines", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "Flines", ".", "append", "(", "line", ")", "\n", "", "", "", "return", "Tlines", ",", "Flines", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.read_LRS3_ST": [[25, 34], ["open", "f_in.readline", "lines.append"], "function", ["None"], ["", "def", "read_LRS3_ST", "(", "file", ")", ":", "\n", "\t", "lines", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f_in", ":", "\n", "\t\t", "while", "True", ":", "\n", "\t\t\t", "line", "=", "f_in", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "\t\t\t\t", "break", "\n", "", "lines", ".", "append", "(", "line", ")", "\n", "", "", "return", "lines", "[", ":", "30000", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.read_LRS3_S": [[35, 47], ["open", "f_in.readline", "int", "int", "lines.append", "f_in.readline.split", "f_in.readline.split"], "function", ["None"], ["", "def", "read_LRS3_S", "(", "file", ")", ":", "\n", "\t", "lines", "=", "[", "]", "\n", "with", "open", "(", "file", ")", "as", "f_in", ":", "\n", "\t\t", "while", "True", ":", "\n", "\t\t\t", "line", "=", "f_in", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "\t\t\t\t", "break", "\n", "", "start", "=", "int", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "/", "100", "\n", "end", "=", "int", "(", "line", ".", "split", "(", ")", "[", "2", "]", ")", "/", "100", "\n", "if", "end", "-", "start", "<=", "3", ":", "# Only select less than 3s", "\n", "\t\t\t\t", "lines", ".", "append", "(", "line", ")", "\n", "", "", "", "return", "lines", "[", ":", "30000", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.generate_TAudio": [[48, 82], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "pydub.AudioSegment.from_file", "generate_TalkSet.get_length", "AudioSegment.from_file.export", "subprocess.call", "audio_name.split", "os.path.join", "len", "int", "line.split", "line.split", "audio_name.split", "video_name.split", "int", "str", "min", "audio_name.split", "video_name.split", "str", "audio_name.split", "video_name.split", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.get_length"], ["", "def", "generate_TAudio", "(", "line", ",", "args", ")", ":", "\n", "# Get the id of the audio and video", "\n", "\t", "audio_name", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", ":", "-", "4", "]", "\n", "video_name", "=", "line", ".", "split", "(", ")", "[", "2", "]", "[", ":", "-", "4", "]", "\n", "id1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "name1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name2", "=", "video_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name", "=", "name1", "+", "'_'", "+", "name2", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_audio", ",", "audio_name", "+", "'.wav'", ")", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_video", ",", "video_name", "+", "'.mp4'", ")", "\n", "out_audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.wav'", ")", "\n", "out_video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.mp4'", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TAudio'", ",", "id1", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Read the audio data and the length of audio and video", "\n", "audio", "=", "AudioSegment", ".", "from_file", "(", "audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "length_audio", "=", "len", "(", "audio", ")", "/", "1000.0", "\n", "length_video", "=", "get_length", "(", "video_path", ")", "\n", "length_data", "=", "int", "(", "min", "(", "length_video", ",", "length_audio", ")", "*", "100", ")", "/", "100", "\n", "audio", "=", "audio", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "\n", "# Extract the video and audio", "\n", "start", "=", "0", "\n", "end", "=", "length_data", "\n", "audio", ".", "export", "(", "out_audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "cmd", "=", "\"ffmpeg -y -ss %.3f -t %.3f -i %s -i %s -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest %s -loglevel panic\"", "%", "(", "start", ",", "end", "-", "start", ",", "video_path", ",", "out_audio_path", ",", "out_video_path", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n", "# # Write the txt file", "\n", "start_T", ",", "end_T", "=", "0", ",", "length_data", "\n", "start_F", ",", "end_F", "=", "0", ",", "0", "\n", "line_new", "=", "\"TAudio\"", "+", "' '", "+", "str", "(", "audio_name", ")", "+", "' '", "+", "str", "(", "video_name", ")", "+", "' '", "+", "str", "(", "length_data", ")", "+", "' '", "+", "str", "(", "start_T", ")", "+", "' '", "+", "str", "(", "end_T", ")", "+", "' '", "+", "str", "(", "start_F", ")", "+", "' '", "+", "str", "(", "end_F", ")", "+", "'\\n'", "\n", "return", "line_new", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.generate_FAudio": [[83, 117], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "pydub.AudioSegment.from_file", "generate_TalkSet.get_length", "AudioSegment.from_file.export", "subprocess.call", "audio_name.split", "os.path.join", "len", "int", "line.split", "line.split", "audio_name.split", "video_name.split", "int", "str", "min", "audio_name.split", "video_name.split", "str", "audio_name.split", "video_name.split", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.get_length"], ["", "def", "generate_FAudio", "(", "line", ",", "args", ")", ":", "\n", "# Get the id of the audio and video", "\n", "\t", "audio_name", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", ":", "-", "4", "]", "\n", "video_name", "=", "line", ".", "split", "(", ")", "[", "2", "]", "[", ":", "-", "4", "]", "\n", "id1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "name1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name2", "=", "video_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name", "=", "name1", "+", "'_'", "+", "name2", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_audio", ",", "audio_name", "+", "'.wav'", ")", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_video", ",", "video_name", "+", "'.mp4'", ")", "\n", "out_audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.wav'", ")", "\n", "out_video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.mp4'", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FAudio'", ",", "id1", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Read the audio data and the length of audio and video\t", "\n", "audio", "=", "AudioSegment", ".", "from_file", "(", "audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "length_audio", "=", "len", "(", "audio", ")", "/", "1000.0", "\n", "length_video", "=", "get_length", "(", "video_path", ")", "\n", "length_data", "=", "int", "(", "min", "(", "length_video", ",", "length_audio", ")", "*", "100", ")", "/", "100", "\n", "audio", "=", "audio", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "\n", "# Extract the video and audio", "\n", "start", "=", "0", "\n", "end", "=", "length_data", "\n", "audio", ".", "export", "(", "out_audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "cmd", "=", "\"ffmpeg -y -ss %.3f -t %.3f -i %s -i %s -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest %s -loglevel panic\"", "%", "(", "start", ",", "end", "-", "start", ",", "video_path", ",", "out_audio_path", ",", "out_video_path", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n", "# Write the txt file", "\n", "start_T", ",", "end_T", "=", "0", ",", "0", "\n", "start_F", ",", "end_F", "=", "0", ",", "length_data", "\n", "line_new", "=", "\"FAudio\"", "+", "' '", "+", "str", "(", "audio_name", ")", "+", "' '", "+", "str", "(", "video_name", ")", "+", "' '", "+", "str", "(", "length_data", ")", "+", "' '", "+", "str", "(", "start_T", ")", "+", "' '", "+", "str", "(", "end_T", ")", "+", "' '", "+", "str", "(", "start_F", ")", "+", "' '", "+", "str", "(", "end_F", ")", "+", "'\\n'", "\n", "return", "line_new", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.generate_TFAudio": [[118, 170], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "pydub.AudioSegment.from_file", "pydub.AudioSegment.from_file", "generate_TalkSet.get_length", "random.randint", "audio.export", "subprocess.call", "audio_name.split", "os.path.join", "len", "len", "int", "int", "line.split", "line.split", "audio_name.split", "video_name.split", "int", "int", "str", "min", "audio_name.split", "video_name.split", "str", "audio_name.split", "video_name.split", "random.random", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.get_length"], ["", "def", "generate_TFAudio", "(", "line", ",", "args", ")", ":", "\n", "# Get the id of the audio and video", "\n", "\t", "audio_name", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", ":", "-", "4", "]", "\n", "video_name", "=", "line", ".", "split", "(", ")", "[", "2", "]", "[", ":", "-", "4", "]", "\n", "id1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "name1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name2", "=", "video_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name", "=", "name1", "+", "'_'", "+", "name2", "\n", "audio_T_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_audio", ",", "video_name", "+", "'.wav'", ")", "\n", "audio_F_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_audio", ",", "audio_name", "+", "'.wav'", ")", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_video", ",", "video_name", "+", "'.mp4'", ")", "\n", "out_audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TFAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.wav'", ")", "\n", "out_video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TFAudio'", ",", "id1", "+", "'/'", "+", "name", "+", "'.mp4'", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TFAudio'", ",", "id1", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Read the audio data and the length of audio and video\t", "\n", "audio_T", "=", "AudioSegment", ".", "from_file", "(", "audio_T_path", ",", "format", "=", "\"wav\"", ")", "\n", "audio_F", "=", "AudioSegment", ".", "from_file", "(", "audio_F_path", ",", "format", "=", "\"wav\"", ")", "\n", "length_audio_T", "=", "len", "(", "audio_T", ")", "/", "1000.0", "\n", "length_audio_F", "=", "len", "(", "audio_F", ")", "/", "1000.0", "\n", "length_video", "=", "get_length", "(", "video_path", ")", "\n", "length_data", "=", "int", "(", "min", "(", "length_audio_T", ",", "length_audio_F", ",", "length_video", ")", "*", "100", ")", "/", "100", "\n", "audio_T", "=", "audio_T", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "audio_F", "=", "audio_F", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "\n", "# Generate the audio", "\n", "changepoint", "=", "int", "(", "(", "length_data", "*", "0.25", "+", "length_data", "*", "random", ".", "random", "(", ")", "*", "0.5", ")", "*", "100", ")", "/", "100", "\n", "audio_dict", "=", "{", "}", "\n", "audio_dict", "[", "'T1'", "]", "=", "audio_T", "[", ":", "changepoint", "*", "1000", "]", "\n", "audio_dict", "[", "'T2'", "]", "=", "audio_T", "[", "changepoint", "*", "1000", ":", "]", "\n", "audio_dict", "[", "'F1'", "]", "=", "audio_F", "[", ":", "changepoint", "*", "1000", "]", "\n", "audio_dict", "[", "'F2'", "]", "=", "audio_F", "[", "changepoint", "*", "1000", ":", "]", "\n", "seed", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "if", "seed", "==", "1", ":", "\n", "\t\t", "audio", "=", "audio_dict", "[", "'T1'", "]", "+", "audio_dict", "[", "'F2'", "]", "\n", "", "else", ":", "\n", "\t\t", "audio", "=", "audio_dict", "[", "'F1'", "]", "+", "audio_dict", "[", "'T2'", "]", "\n", "# Extract the video and audio", "\n", "", "start", "=", "0", "\n", "end", "=", "length_data", "\n", "audio", ".", "export", "(", "out_audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "cmd", "=", "\"ffmpeg -y -ss %.3f -t %.3f -i %s -i %s -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest %s -loglevel panic\"", "%", "(", "start", ",", "end", "-", "start", ",", "video_path", ",", "out_audio_path", ",", "out_video_path", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n", "# Write the txt file", "\n", "if", "seed", "==", "1", ":", "\n", "\t\t", "start_T", ",", "end_T", ",", "start_F", ",", "end_F", "=", "0", ",", "changepoint", ",", "changepoint", ",", "length_data", "\n", "", "elif", "seed", "==", "0", ":", "\n", "\t\t", "start_F", ",", "end_F", ",", "start_T", ",", "end_T", "=", "0", ",", "changepoint", ",", "changepoint", ",", "length_data", "\n", "", "line_new", "=", "\"TFAudio\"", "+", "' '", "+", "str", "(", "audio_name", ")", "+", "' '", "+", "str", "(", "video_name", ")", "+", "' '", "+", "str", "(", "length_data", ")", "+", "' '", "+", "str", "(", "start_T", ")", "+", "' '", "+", "str", "(", "end_T", ")", "+", "' '", "+", "str", "(", "start_F", ")", "+", "' '", "+", "str", "(", "end_F", ")", "+", "'\\n'", "\n", "return", "line_new", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.generate_TSilence": [[171, 210], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "pydub.AudioSegment.from_file", "AudioSegment.from_file.export", "subprocess.call", "line.split", "line.split", "line.split", "audio_name.split", "int", "int", "int", "os.path.join", "int", "int", "line.split", "line.split", "os.path.join", "int", "int", "line.split", "line.split", "str", "line.split", "line.split", "line.split", "audio_name.split", "video_name.split", "str", "audio_name.split", "video_name.split", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "generate_TSilence", "(", "line", ",", "args", ")", ":", "\n", "# Get the id of the audio and video", "\n", "\t", "type_change", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "audio_name", "=", "line", ".", "split", "(", ")", "[", "1", "]", "\n", "video_name", "=", "line", ".", "split", "(", ")", "[", "1", "]", "\n", "id1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "name1", "=", "audio_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "line", ".", "split", "(", ")", "[", "5", "]", "\n", "name2", "=", "video_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "video_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "line", ".", "split", "(", ")", "[", "5", "]", "\n", "name", "=", "name1", "+", "'_'", "+", "name2", "\n", "start", "=", "int", "(", "line", ".", "split", "(", ")", "[", "2", "]", ")", "/", "100", "\n", "mid", "=", "int", "(", "line", ".", "split", "(", ")", "[", "3", "]", ")", "/", "100", "\n", "end", "=", "int", "(", "line", ".", "split", "(", ")", "[", "4", "]", ")", "/", "100", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "lrs3_audio", ",", "'pretrain'", ",", "audio_name", "[", "8", ":", "]", "+", "'.wav'", ")", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "lrs3_video", ",", "'pretrain'", ",", "video_name", "[", "8", ":", "]", "+", "'.mp4'", ")", "\n", "out_audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TSilence'", ",", "id1", "+", "'/'", "+", "name", "+", "'.wav'", ")", "\n", "out_video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TSilence'", ",", "id1", "+", "'/'", "+", "name", "+", "'.mp4'", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'TSilence'", ")", ",", "id1", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Read the audio data and the length of audio and video\t", "\n", "audio", "=", "AudioSegment", ".", "from_file", "(", "audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "\n", "# Get the required audio and video data", "\n", "length_data", "=", "int", "(", "(", "end", "-", "start", ")", "*", "100", ")", "/", "100", "\n", "audio", "=", "audio", "[", "int", "(", "start", "*", "1000", ")", ":", "int", "(", "end", "*", "1000", ")", "]", "\n", "audio", ".", "export", "(", "out_audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "cmd", "=", "\"ffmpeg -y -ss %.3f -t %.3f -i %s -i %s -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest %s -loglevel panic\"", "%", "(", "start", ",", "end", "-", "start", ",", "video_path", ",", "out_audio_path", ",", "out_video_path", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n", "changepoint", "=", "int", "(", "(", "mid", "-", "start", ")", "*", "100", ")", "/", "100", "\n", "if", "type_change", "==", "\"10\"", ":", "\n", "\t\t", "start_T", ",", "end_T", ",", "start_F", ",", "end_F", "=", "0", ",", "changepoint", ",", "changepoint", ",", "length_data", "\n", "", "elif", "type_change", "==", "\"01\"", ":", "\n", "\t\t", "start_T", ",", "end_T", ",", "start_F", ",", "end_F", "=", "changepoint", ",", "length_data", ",", "0", ",", "changepoint", "\n", "\n", "", "audio_name", "=", "audio_name", "[", ":", "-", "5", "]", "+", "line", ".", "split", "(", ")", "[", "5", "]", "\n", "video_name", "=", "video_name", "[", ":", "-", "5", "]", "+", "line", ".", "split", "(", ")", "[", "5", "]", "\n", "line_new", "=", "\"TSilence\"", "+", "' '", "+", "str", "(", "audio_name", ")", "+", "' '", "+", "str", "(", "video_name", ")", "+", "' '", "+", "str", "(", "length_data", ")", "+", "' '", "+", "str", "(", "start_T", ")", "+", "' '", "+", "str", "(", "end_T", ")", "+", "' '", "+", "str", "(", "start_F", ")", "+", "' '", "+", "str", "(", "end_F", ")", "+", "'\\n'", "\n", "return", "line_new", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.generate_FSilence": [[211, 275], ["random.choice", "float", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "pydub.AudioSegment.from_file", "pydub.AudioSegment.from_file", "generate_TalkSet.get_length", "random.randint", "audio.export", "subprocess.call", "line.split", "line.split", "int", "int", "int", "int", "random.choice", "float", "audio_F_name.split", "os.path.join", "len", "len", "int", "random.choice.split", "random.choice.split", "audio_F_name.split", "line.split", "int", "int", "int", "int", "line.split", "str", "line.split", "line.split", "random.choice.split", "min", "audio_F_name.split", "audio_T_name.split", "str", "audio_F_name.split", "audio_T_name.split", "random.random", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.TalkSet.generate_TalkSet.get_length"], ["", "def", "generate_FSilence", "(", "line", ",", "Flines", ",", "args", ")", ":", "\n", "# Get the id of the audio and video", "\n", "\t", "audio_T_name", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "video_name", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "start", "=", "int", "(", "line", ".", "split", "(", ")", "[", "1", "]", ")", "/", "100", "\n", "end", "=", "int", "(", "line", ".", "split", "(", ")", "[", "2", "]", ")", "/", "100", "\n", "length_data", "=", "int", "(", "(", "end", "-", "start", ")", "*", "100", ")", "/", "100", "\n", "changepoint", "=", "int", "(", "(", "length_data", "*", "0.25", "+", "length_data", "*", "random", ".", "random", "(", ")", "*", "0.5", ")", "*", "100", ")", "/", "100", "\n", "speech_line", "=", "random", ".", "choice", "(", "Flines", ")", "\n", "length_speech", "=", "float", "(", "speech_line", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "while", "length_speech", "<", "length_data", ":", "\n", "\t\t", "speech_line", "=", "random", ".", "choice", "(", "Flines", ")", "\n", "length_speech", "=", "float", "(", "speech_line", ".", "split", "(", ")", "[", "-", "1", "]", ")", "\n", "", "audio_F_name", "=", "speech_line", ".", "split", "(", ")", "[", "1", "]", "[", ":", "-", "4", "]", "\n", "id1", "=", "audio_F_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "name1", "=", "audio_F_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_F_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "audio_F_name", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "name2", "=", "audio_T_name", ".", "split", "(", "'/'", ")", "[", "0", "]", "+", "'_'", "+", "audio_T_name", ".", "split", "(", "'/'", ")", "[", "1", "]", "+", "'_'", "+", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "name", "=", "name1", "+", "'_'", "+", "name2", "\n", "\n", "# True: orig_video False: speech+slience", "\n", "video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "lrs3_video", ",", "'pretrain'", ",", "video_name", "[", "8", ":", "]", "+", "'.mp4'", ")", "\n", "audio_T_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "lrs3_audio", ",", "'pretrain'", ",", "audio_T_name", "[", "8", ":", "]", "+", "'.wav'", ")", "\n", "audio_F_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "Vox_audio", ",", "audio_F_name", "+", "'.wav'", ")", "\n", "out_audio_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FSilence'", ",", "id1", "+", "'/'", "+", "name", "+", "'.wav'", ")", "\n", "out_video_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FSilence'", ",", "id1", "+", "'/'", "+", "name", "+", "'.mp4'", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "out_path", ",", "'FSilence'", ",", "id1", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Read the audio data and the length of audio and video\t", "\n", "audio_T", "=", "AudioSegment", ".", "from_file", "(", "audio_T_path", ",", "format", "=", "\"wav\"", ")", "\n", "audio_T", "=", "audio_T", "[", "int", "(", "start", "*", "1000", ")", ":", "int", "(", "end", "*", "1000", ")", "]", "\n", "audio_F", "=", "AudioSegment", ".", "from_file", "(", "audio_F_path", ",", "format", "=", "\"wav\"", ")", "\n", "length_audio_T", "=", "len", "(", "audio_T", ")", "/", "1000.0", "\n", "length_audio_F", "=", "len", "(", "audio_F", ")", "/", "1000.0", "\n", "length_video", "=", "get_length", "(", "video_path", ")", "\n", "length_data", "=", "int", "(", "min", "(", "length_audio_T", ",", "length_audio_F", ",", "length_video", ")", "*", "100", ")", "/", "100", "\n", "audio_T", "=", "audio_T", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "audio_F", "=", "audio_F", "[", ":", "int", "(", "length_data", "*", "1000", ")", "]", "\n", "\n", "# Generate the audio", "\n", "audio_dict", "=", "{", "}", "\n", "audio_dict", "[", "'T1'", "]", "=", "audio_T", "[", ":", "changepoint", "*", "1000", "]", "\n", "audio_dict", "[", "'T2'", "]", "=", "audio_T", "[", "changepoint", "*", "1000", ":", "]", "\n", "audio_dict", "[", "'F1'", "]", "=", "audio_F", "[", ":", "changepoint", "*", "1000", "]", "\n", "audio_dict", "[", "'F2'", "]", "=", "audio_F", "[", "changepoint", "*", "1000", ":", "]", "\n", "seed", "=", "random", ".", "randint", "(", "0", ",", "1", ")", "\n", "if", "seed", "==", "1", ":", "\n", "\t\t", "audio", "=", "audio_dict", "[", "'T1'", "]", "+", "audio_dict", "[", "'F2'", "]", "\n", "", "else", ":", "\n", "\t\t", "audio", "=", "audio_dict", "[", "'F1'", "]", "+", "audio_dict", "[", "'T2'", "]", "\n", "# Extract the video and audio", "\n", "", "audio", ".", "export", "(", "out_audio_path", ",", "format", "=", "\"wav\"", ")", "\n", "cmd", "=", "\"ffmpeg -y -ss %.3f -t %.3f -i %s -i %s -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest %s -loglevel panic\"", "%", "(", "start", ",", "end", "-", "start", ",", "video_path", ",", "out_audio_path", ",", "out_video_path", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ",", "stdout", "=", "None", ")", "\n", "\n", "# Write the txt file", "\n", "if", "seed", "==", "1", ":", "\n", "\t\t", "start_T", ",", "end_T", ",", "start_F", ",", "end_F", "=", "0", ",", "changepoint", ",", "changepoint", ",", "length_data", "\n", "", "elif", "seed", "==", "0", ":", "\n", "\t\t", "start_F", ",", "end_F", ",", "start_T", ",", "end_T", "=", "0", ",", "changepoint", ",", "changepoint", ",", "length_data", "\n", "\n", "", "video_name", "=", "video_name", "[", ":", "-", "5", "]", "+", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "line_new", "=", "\"FSilence\"", "+", "' '", "+", "str", "(", "audio_F_name", ")", "+", "' '", "+", "str", "(", "video_name", ")", "+", "' '", "+", "str", "(", "length_data", ")", "+", "' '", "+", "str", "(", "start_T", ")", "+", "' '", "+", "str", "(", "end_T", ")", "+", "' '", "+", "str", "(", "start_F", ")", "+", "' '", "+", "str", "(", "end_F", ")", "+", "'\\n'", "\n", "return", "line_new", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.SEBasicBlock.__init__": [[8, 18], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "audioEncoder.SELayer"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "reduction", "=", "8", ")", ":", "\n", "        ", "super", "(", "SEBasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "planes", ",", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.SEBasicBlock.forward": [[19, 36], ["audioEncoder.SEBasicBlock.conv1", "audioEncoder.SEBasicBlock.relu", "audioEncoder.SEBasicBlock.bn1", "audioEncoder.SEBasicBlock.conv2", "audioEncoder.SEBasicBlock.bn2", "audioEncoder.SEBasicBlock.se", "audioEncoder.SEBasicBlock.relu", "audioEncoder.SEBasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.SELayer.__init__": [[38, 46], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "8", ")", ":", "\n", "        ", "super", "(", "SELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "channel", ",", "channel", "//", "reduction", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", "//", "reduction", ",", "channel", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.SELayer.forward": [[48, 53], ["x.size", "audioEncoder.SELayer.avg_pool().view", "audioEncoder.SELayer.fc().view", "audioEncoder.SELayer.avg_pool", "audioEncoder.SELayer.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", ",", "c", ",", "_", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "y", "=", "self", ".", "avg_pool", "(", "x", ")", ".", "view", "(", "b", ",", "c", ")", "\n", "y", "=", "self", ".", "fc", "(", "y", ")", ".", "view", "(", "b", ",", "c", ",", "1", ",", "1", ")", "\n", "return", "x", "*", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder.__init__": [[55, 77], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "audioEncoder.audioEncoder._make_layer", "audioEncoder.audioEncoder._make_layer", "audioEncoder.audioEncoder._make_layer", "audioEncoder.audioEncoder._make_layer", "audioEncoder.audioEncoder.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder._make_layer", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder._make_layer", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder._make_layer", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "num_filters", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "audioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "block", "=", "SEBasicBlock", "\n", "self", ".", "inplanes", "=", "num_filters", "[", "0", "]", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "num_filters", "[", "0", "]", ",", "kernel_size", "=", "7", ",", "stride", "=", "(", "2", ",", "1", ")", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "num_filters", "[", "0", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "0", "]", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "1", "]", ",", "layers", "[", "1", "]", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "2", "]", ",", "layers", "[", "2", "]", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "3", "]", ",", "layers", "[", "3", "]", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "out_dim", "=", "num_filters", "[", "3", "]", "*", "block", ".", "expansion", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder._make_layer": [[78, 94], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.audioEncoder.audioEncoder.forward": [[95, 109], ["audioEncoder.audioEncoder.conv1", "audioEncoder.audioEncoder.bn1", "audioEncoder.audioEncoder.relu", "audioEncoder.audioEncoder.layer1", "audioEncoder.audioEncoder.layer2", "audioEncoder.audioEncoder.layer3", "audioEncoder.audioEncoder.layer4", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "x.transpose.transpose.view", "x.transpose.transpose.transpose", "x.transpose.transpose.size", "x.transpose.transpose.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "x", ".", "view", "(", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "x", ".", "size", "(", ")", "[", "1", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.__init__": [[9, 28], ["torch.Module.__init__", "model.visualEncoder.visualFrontend", "model.visualEncoder.visualTCN", "model.visualEncoder.visualConv1D", "model.audioEncoder.audioEncoder", "model.attentionLayer.attentionLayer", "model.attentionLayer.attentionLayer", "model.attentionLayer.attentionLayer"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "talkNetModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Visual Temporal Encoder", "\n", "self", ".", "visualFrontend", "=", "visualFrontend", "(", ")", "# Visual Frontend ", "\n", "# self.visualFrontend.load_state_dict(torch.load('visual_frontend.pt', map_location=\"cuda\"))", "\n", "# for param in self.visualFrontend.parameters():", "\n", "#     param.requires_grad = False       ", "\n", "self", ".", "visualTCN", "=", "visualTCN", "(", ")", "# Visual Temporal Network TCN", "\n", "self", ".", "visualConv1D", "=", "visualConv1D", "(", ")", "# Visual Temporal Network Conv1d", "\n", "\n", "# Audio Temporal Encoder ", "\n", "self", ".", "audioEncoder", "=", "audioEncoder", "(", "layers", "=", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_filters", "=", "[", "16", ",", "32", ",", "64", ",", "128", "]", ")", "\n", "\n", "# Audio-visual Cross Attention", "\n", "self", ".", "crossA2V", "=", "attentionLayer", "(", "d_model", "=", "128", ",", "nhead", "=", "8", ")", "\n", "self", ".", "crossV2A", "=", "attentionLayer", "(", "d_model", "=", "128", ",", "nhead", "=", "8", ")", "\n", "\n", "# Audio-visual Self Attention", "\n", "self", ".", "selfAV", "=", "attentionLayer", "(", "d_model", "=", "256", ",", "nhead", "=", "8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_frontend": [[29, 40], ["x.transpose.transpose.view", "talkNetModel.talkNetModel.visualFrontend", "x.transpose.transpose.view", "x.transpose.transpose.transpose", "talkNetModel.talkNetModel.visualTCN", "talkNetModel.talkNetModel.visualConv1D", "x.transpose.transpose.transpose"], "methods", ["None"], ["", "def", "forward_visual_frontend", "(", "self", ",", "x", ")", ":", "\n", "        ", "B", ",", "T", ",", "W", ",", "H", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "B", "*", "T", ",", "1", ",", "1", ",", "W", ",", "H", ")", "\n", "x", "=", "(", "x", "/", "255", "-", "0.4161", ")", "/", "0.1688", "\n", "x", "=", "self", ".", "visualFrontend", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "B", ",", "T", ",", "512", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "x", "=", "self", ".", "visualTCN", "(", "x", ")", "\n", "x", "=", "self", ".", "visualConv1D", "(", "x", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_frontend": [[41, 45], ["talkNetModel.talkNetModel.unsqueeze().transpose", "talkNetModel.talkNetModel.audioEncoder", "talkNetModel.talkNetModel.unsqueeze"], "methods", ["None"], ["", "def", "forward_audio_frontend", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", ".", "transpose", "(", "2", ",", "3", ")", "\n", "x", "=", "self", ".", "audioEncoder", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_cross_attention": [[46, 50], ["talkNetModel.talkNetModel.crossA2V", "talkNetModel.talkNetModel.crossV2A"], "methods", ["None"], ["", "def", "forward_cross_attention", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x1_c", "=", "self", ".", "crossA2V", "(", "src", "=", "x1", ",", "tar", "=", "x2", ")", "\n", "x2_c", "=", "self", ".", "crossV2A", "(", "src", "=", "x2", ",", "tar", "=", "x1", ")", "\n", "return", "x1_c", ",", "x2_c", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_visual_backend": [[51, 56], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "talkNetModel.talkNetModel.selfAV", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "def", "forward_audio_visual_backend", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x1", ",", "x2", ")", ",", "2", ")", "\n", "x", "=", "self", ".", "selfAV", "(", "src", "=", "x", ",", "tar", "=", "x", ")", "\n", "x", "=", "torch", ".", "reshape", "(", "x", ",", "(", "-", "1", ",", "256", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_audio_backend": [[57, 60], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "def", "forward_audio_backend", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "torch", ".", "reshape", "(", "x", ",", "(", "-", "1", ",", "128", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.talkNetModel.talkNetModel.forward_visual_backend": [[61, 64], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "def", "forward_visual_backend", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "torch", ".", "reshape", "(", "x", ",", "(", "-", "1", ",", "128", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.attentionLayer.attentionLayer.__init__": [[8, 22], ["torch.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "attentionLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_model", "*", "4", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "d_model", "*", "4", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "F", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.attentionLayer.attentionLayer.forward": [[23, 37], ["src.transpose.transpose.transpose", "tar.transpose.transpose.transpose", "attentionLayer.attentionLayer.norm1", "attentionLayer.attentionLayer.linear2", "attentionLayer.attentionLayer.norm2", "src.transpose.transpose.transpose", "attentionLayer.attentionLayer.self_attn", "attentionLayer.attentionLayer.dropout1", "attentionLayer.attentionLayer.dropout", "attentionLayer.attentionLayer.dropout2", "attentionLayer.attentionLayer.activation", "attentionLayer.attentionLayer.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "tar", ")", ":", "\n", "# type: (Tensor, Optional[Tensor], Optional[Tensor]) -> Tensor", "\n", "        ", "src", "=", "src", ".", "transpose", "(", "0", ",", "1", ")", "# B, T, C -> T, B, C", "\n", "tar", "=", "tar", ".", "transpose", "(", "0", ",", "1", ")", "# B, T, C -> T, B, C", "\n", "src2", "=", "self", ".", "self_attn", "(", "tar", ",", "src", ",", "src", ",", "attn_mask", "=", "None", ",", "\n", "key_padding_mask", "=", "None", ")", "[", "0", "]", "\n", "src", "=", "src", "+", "self", ".", "dropout1", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm1", "(", "src", ")", "\n", "\n", "src2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "src", ")", ")", ")", ")", "\n", "src", "=", "src", "+", "self", ".", "dropout2", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm2", "(", "src", ")", "\n", "src", "=", "src", ".", "transpose", "(", "0", ",", "1", ")", "# T, B, C -> B, T, C", "\n", "return", "src", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.ResNetLayer.__init__": [[21, 35], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "outplanes", ",", "stride", ")", ":", "\n", "        ", "super", "(", "ResNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1a", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1a", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ",", "momentum", "=", "0.01", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "conv2a", "=", "nn", ".", "Conv2d", "(", "outplanes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "downsample", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "outplanes", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "self", ".", "outbna", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ",", "momentum", "=", "0.01", ",", "eps", "=", "0.001", ")", "\n", "\n", "self", ".", "conv1b", "=", "nn", ".", "Conv2d", "(", "outplanes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1b", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ",", "momentum", "=", "0.01", ",", "eps", "=", "0.001", ")", "\n", "self", ".", "conv2b", "=", "nn", ".", "Conv2d", "(", "outplanes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "outbnb", "=", "nn", ".", "BatchNorm2d", "(", "outplanes", ",", "momentum", "=", "0.01", ",", "eps", "=", "0.001", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.ResNetLayer.forward": [[37, 54], ["torch.relu", "torch.relu", "torch.relu", "visualEncoder.ResNetLayer.conv2a", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "visualEncoder.ResNetLayer.conv2b", "torch.relu", "torch.relu", "torch.relu", "visualEncoder.ResNetLayer.bn1a", "visualEncoder.ResNetLayer.downsample", "visualEncoder.ResNetLayer.outbna", "visualEncoder.ResNetLayer.bn1b", "visualEncoder.ResNetLayer.outbnb", "visualEncoder.ResNetLayer.conv1a", "visualEncoder.ResNetLayer.conv1b"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputBatch", ")", ":", "\n", "        ", "batch", "=", "F", ".", "relu", "(", "self", ".", "bn1a", "(", "self", ".", "conv1a", "(", "inputBatch", ")", ")", ")", "\n", "batch", "=", "self", ".", "conv2a", "(", "batch", ")", "\n", "if", "self", ".", "stride", "==", "1", ":", "\n", "            ", "residualBatch", "=", "inputBatch", "\n", "", "else", ":", "\n", "            ", "residualBatch", "=", "self", ".", "downsample", "(", "inputBatch", ")", "\n", "", "batch", "=", "batch", "+", "residualBatch", "\n", "intermediateBatch", "=", "batch", "\n", "batch", "=", "F", ".", "relu", "(", "self", ".", "outbna", "(", "batch", ")", ")", "\n", "\n", "batch", "=", "F", ".", "relu", "(", "self", ".", "bn1b", "(", "self", ".", "conv1b", "(", "batch", ")", ")", ")", "\n", "batch", "=", "self", ".", "conv2b", "(", "batch", ")", "\n", "residualBatch", "=", "intermediateBatch", "\n", "batch", "=", "batch", "+", "residualBatch", "\n", "outputBatch", "=", "F", ".", "relu", "(", "self", ".", "outbnb", "(", "batch", ")", ")", "\n", "return", "outputBatch", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.ResNet.__init__": [[63, 72], ["torch.Module.__init__", "visualEncoder.ResNetLayer", "visualEncoder.ResNetLayer", "visualEncoder.ResNetLayer", "visualEncoder.ResNetLayer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer1", "=", "ResNetLayer", "(", "64", ",", "64", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "ResNetLayer", "(", "64", ",", "128", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "ResNetLayer", "(", "128", ",", "256", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "ResNetLayer", "(", "256", ",", "512", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "(", "4", ",", "4", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.ResNet.forward": [[74, 81], ["visualEncoder.ResNet.layer1", "visualEncoder.ResNet.layer2", "visualEncoder.ResNet.layer3", "visualEncoder.ResNet.layer4", "visualEncoder.ResNet.avgpool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputBatch", ")", ":", "\n", "        ", "batch", "=", "self", ".", "layer1", "(", "inputBatch", ")", "\n", "batch", "=", "self", ".", "layer2", "(", "batch", ")", "\n", "batch", "=", "self", ".", "layer3", "(", "batch", ")", "\n", "batch", "=", "self", ".", "layer4", "(", "batch", ")", "\n", "outputBatch", "=", "self", ".", "avgpool", "(", "batch", ")", "\n", "return", "outputBatch", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.GlobalLayerNorm.__init__": [[84, 89], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "visualEncoder.GlobalLayerNorm.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.L2Norm.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "channel_size", ")", ":", "\n", "        ", "super", "(", "GlobalLayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "channel_size", ",", "1", ")", ")", "# [1, N, 1]", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "channel_size", ",", "1", ")", ")", "# [1, N, 1]", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.GlobalLayerNorm.reset_parameters": [[90, 93], ["visualEncoder.GlobalLayerNorm.gamma.data.fill_", "visualEncoder.GlobalLayerNorm.beta.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "gamma", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "beta", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.GlobalLayerNorm.forward": [[94, 99], ["y.mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "torch.pow().mean().mean", "y.mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow().mean", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "y", ")", ":", "\n", "        ", "mean", "=", "y", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "#[M, 1, 1]", "\n", "var", "=", "(", "torch", ".", "pow", "(", "y", "-", "mean", ",", "2", ")", ")", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "gLN_y", "=", "self", ".", "gamma", "*", "(", "y", "-", "mean", ")", "/", "torch", ".", "pow", "(", "var", "+", "1e-8", ",", "0.5", ")", "+", "self", ".", "beta", "\n", "return", "gLN_y", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualFrontend.__init__": [[107, 117], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "visualEncoder.ResNet", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "visualFrontend", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "frontend3D", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "1", ",", "64", ",", "kernel_size", "=", "(", "5", ",", "7", ",", "7", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "2", ",", "3", ",", "3", ")", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm3d", "(", "64", ",", "momentum", "=", "0.01", ",", "eps", "=", "0.001", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "1", ",", "1", ")", ")", "\n", ")", "\n", "self", ".", "resnet", "=", "ResNet", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualFrontend.forward": [[119, 131], ["inputBatch.transpose().transpose.transpose().transpose.transpose().transpose", "visualEncoder.visualFrontend.frontend3D", "batch.reshape.reshape.transpose", "batch.reshape.reshape.reshape", "visualEncoder.visualFrontend.resnet", "outputBatch.transpose().transpose.transpose().transpose.reshape", "outputBatch.transpose().transpose.transpose().transpose.transpose", "outputBatch.transpose().transpose.transpose().transpose.transpose().transpose", "inputBatch.transpose().transpose.transpose().transpose.transpose", "outputBatch.transpose().transpose.transpose().transpose.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputBatch", ")", ":", "\n", "        ", "inputBatch", "=", "inputBatch", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "batchsize", "=", "inputBatch", ".", "shape", "[", "0", "]", "\n", "batch", "=", "self", ".", "frontend3D", "(", "inputBatch", ")", "\n", "\n", "batch", "=", "batch", ".", "transpose", "(", "1", ",", "2", ")", "\n", "batch", "=", "batch", ".", "reshape", "(", "batch", ".", "shape", "[", "0", "]", "*", "batch", ".", "shape", "[", "1", "]", ",", "batch", ".", "shape", "[", "2", "]", ",", "batch", ".", "shape", "[", "3", "]", ",", "batch", ".", "shape", "[", "4", "]", ")", "\n", "outputBatch", "=", "self", ".", "resnet", "(", "batch", ")", "\n", "outputBatch", "=", "outputBatch", ".", "reshape", "(", "batchsize", ",", "-", "1", ",", "512", ")", "\n", "outputBatch", "=", "outputBatch", ".", "transpose", "(", "1", ",", "2", ")", "\n", "outputBatch", "=", "outputBatch", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "outputBatch", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.DSConv1d.__init__": [[133, 142], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "visualEncoder.GlobalLayerNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DSConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "512", ")", ",", "\n", "nn", ".", "Conv1d", "(", "512", ",", "512", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "dilation", "=", "1", ",", "groups", "=", "512", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "GlobalLayerNorm", "(", "512", ")", ",", "\n", "nn", ".", "Conv1d", "(", "512", ",", "512", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.DSConv1d.forward": [[144, 147], ["visualEncoder.DSConv1d.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "net", "(", "x", ")", "\n", "return", "out", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualTCN.__init__": [[149, 155], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "visualEncoder.DSConv1d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "visualTCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "stacks", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "5", ")", ":", "\n", "            ", "stacks", "+=", "[", "DSConv1d", "(", ")", "]", "\n", "", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "stacks", ")", "# Visual Temporal Network V-TCN", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualTCN.forward": [[156, 159], ["visualEncoder.visualTCN.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "net", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualConv1D.__init__": [[161, 168], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "visualConv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "512", ",", "256", ",", "5", ",", "stride", "=", "1", ",", "padding", "=", "2", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv1d", "(", "256", ",", "128", ",", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.model.visualEncoder.visualConv1D.forward": [[170, 173], ["visualEncoder.visualConv1D.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "net", "(", "x", ")", "\n", "return", "out", "", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.L2Norm.__init__": [[10, 17], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "nets.L2Norm.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.L2Norm.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "n_channels", ",", "scale", ")", ":", "\n", "        ", "super", "(", "L2Norm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "self", ".", "gamma", "=", "scale", "or", "None", "\n", "self", ".", "eps", "=", "1e-10", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_channels", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.L2Norm.reset_parameters": [[18, 20], ["torch.constant_", "torch.constant_", "torch.constant_", "torch.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "init", ".", "constant_", "(", "self", ".", "weight", ",", "self", ".", "gamma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.L2Norm.forward": [[21, 26], ["torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div.pow().sum().sqrt", "torch.div.pow().sum().sqrt", "torch.div.pow().sum().sqrt", "torch.div.pow().sum().sqrt", "nets.L2Norm.weight.unsqueeze().unsqueeze().unsqueeze().expand_as", "torch.div.pow().sum", "torch.div.pow().sum", "torch.div.pow().sum", "torch.div.pow().sum", "nets.L2Norm.weight.unsqueeze().unsqueeze().unsqueeze", "torch.div.pow", "torch.div.pow", "torch.div.pow", "torch.div.pow", "nets.L2Norm.weight.unsqueeze().unsqueeze", "nets.L2Norm.weight.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "norm", "=", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "self", ".", "eps", "\n", "x", "=", "torch", ".", "div", "(", "x", ",", "norm", ")", "\n", "out", "=", "self", ".", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "2", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand_as", "(", "x", ")", "*", "x", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.S3FDNet.__init__": [[30, 108], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "nets.L2Norm", "nets.L2Norm", "nets.L2Norm", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "box_utils.Detect", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "device", "=", "'cuda'", ")", ":", "\n", "        ", "super", "(", "S3FDNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "vgg", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "128", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ",", "ceil_mode", "=", "True", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "512", ",", "1024", ",", "3", ",", "1", ",", "padding", "=", "6", ",", "dilation", "=", "6", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "1024", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "L2Norm3_3", "=", "L2Norm", "(", "256", ",", "10", ")", "\n", "self", ".", "L2Norm4_3", "=", "L2Norm", "(", "512", ",", "8", ")", "\n", "self", ".", "L2Norm5_3", "=", "L2Norm", "(", "512", ",", "5", ")", "\n", "\n", "self", ".", "extras", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "256", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "3", ",", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "128", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "3", ",", "2", ",", "padding", "=", "1", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "loc", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "256", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "conf", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "Conv2d", "(", "256", ",", "4", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "2", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "2", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "2", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "512", ",", "2", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "2", ",", "3", ",", "1", ",", "padding", "=", "1", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "detect", "=", "Detect", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.nets.S3FDNet.forward": [[109, 175], ["list", "list", "list", "range", "nets.S3FDNet.L2Norm3_3", "list.append", "range", "nets.S3FDNet.L2Norm4_3", "list.append", "range", "nets.S3FDNet.L2Norm5_3", "list.append", "range", "list.append", "enumerate", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nets.S3FDNet.detect.forward", "torch.relu.size", "len", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "loc_x.permute().contiguous", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "len", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "box_utils.PriorBox", "nets.S3FDNet.priorbox.forward", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "nets.S3FDNet.softmax", "nets.S3FDNet.priors.type().to", "v", "list.append", "loc[].size", "loc[].size", "o.view", "o.view", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "loc_x.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "o.size", "o.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "nets.S3FDNet.priors.type", "type"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size", "=", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "sources", "=", "list", "(", ")", "\n", "loc", "=", "list", "(", ")", "\n", "conf", "=", "list", "(", ")", "\n", "\n", "for", "k", "in", "range", "(", "16", ")", ":", "\n", "            ", "x", "=", "self", ".", "vgg", "[", "k", "]", "(", "x", ")", "\n", "", "s", "=", "self", ".", "L2Norm3_3", "(", "x", ")", "\n", "sources", ".", "append", "(", "s", ")", "\n", "\n", "for", "k", "in", "range", "(", "16", ",", "23", ")", ":", "\n", "            ", "x", "=", "self", ".", "vgg", "[", "k", "]", "(", "x", ")", "\n", "", "s", "=", "self", ".", "L2Norm4_3", "(", "x", ")", "\n", "sources", ".", "append", "(", "s", ")", "\n", "\n", "for", "k", "in", "range", "(", "23", ",", "30", ")", ":", "\n", "            ", "x", "=", "self", ".", "vgg", "[", "k", "]", "(", "x", ")", "\n", "", "s", "=", "self", ".", "L2Norm5_3", "(", "x", ")", "\n", "sources", ".", "append", "(", "s", ")", "\n", "\n", "for", "k", "in", "range", "(", "30", ",", "len", "(", "self", ".", "vgg", ")", ")", ":", "\n", "            ", "x", "=", "self", ".", "vgg", "[", "k", "]", "(", "x", ")", "\n", "", "sources", ".", "append", "(", "x", ")", "\n", "\n", "# apply extra layers and cache source layer outputs", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "self", ".", "extras", ")", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "v", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "if", "k", "%", "2", "==", "1", ":", "\n", "                ", "sources", ".", "append", "(", "x", ")", "\n", "\n", "# apply multibox head to source layers", "\n", "", "", "loc_x", "=", "self", ".", "loc", "[", "0", "]", "(", "sources", "[", "0", "]", ")", "\n", "conf_x", "=", "self", ".", "conf", "[", "0", "]", "(", "sources", "[", "0", "]", ")", "\n", "\n", "max_conf", ",", "_", "=", "torch", ".", "max", "(", "conf_x", "[", ":", ",", "0", ":", "3", ",", ":", ",", ":", "]", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "conf_x", "=", "torch", ".", "cat", "(", "(", "max_conf", ",", "conf_x", "[", ":", ",", "3", ":", ",", ":", ",", ":", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "loc", ".", "append", "(", "loc_x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "conf", ".", "append", "(", "conf_x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "sources", ")", ")", ":", "\n", "            ", "x", "=", "sources", "[", "i", "]", "\n", "conf", ".", "append", "(", "self", ".", "conf", "[", "i", "]", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "loc", ".", "append", "(", "self", ".", "loc", "[", "i", "]", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ")", "\n", "\n", "", "features_maps", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "loc", ")", ")", ":", "\n", "            ", "feat", "=", "[", "]", "\n", "feat", "+=", "[", "loc", "[", "i", "]", ".", "size", "(", "1", ")", ",", "loc", "[", "i", "]", ".", "size", "(", "2", ")", "]", "\n", "features_maps", "+=", "[", "feat", "]", "\n", "\n", "", "loc", "=", "torch", ".", "cat", "(", "[", "o", ".", "view", "(", "o", ".", "size", "(", "0", ")", ",", "-", "1", ")", "for", "o", "in", "loc", "]", ",", "1", ")", "\n", "conf", "=", "torch", ".", "cat", "(", "[", "o", ".", "view", "(", "o", ".", "size", "(", "0", ")", ",", "-", "1", ")", "for", "o", "in", "conf", "]", ",", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "priorbox", "=", "PriorBox", "(", "size", ",", "features_maps", ")", "\n", "self", ".", "priors", "=", "self", ".", "priorbox", ".", "forward", "(", ")", "\n", "\n", "", "output", "=", "self", ".", "detect", ".", "forward", "(", "\n", "loc", ".", "view", "(", "loc", ".", "size", "(", "0", ")", ",", "-", "1", ",", "4", ")", ",", "\n", "self", ".", "softmax", "(", "conf", ".", "view", "(", "conf", ".", "size", "(", "0", ")", ",", "-", "1", ",", "2", ")", ")", ",", "\n", "self", ".", "priors", ".", "type", "(", "type", "(", "x", ".", "data", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.Detect.__init__": [[131, 141], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "2", ",", "\n", "top_k", "=", "750", ",", "nms_thresh", "=", "0.3", ",", "conf_thresh", "=", "0.05", ",", "\n", "variance", "=", "[", "0.1", ",", "0.2", "]", ",", "nms_top_k", "=", "5000", ")", ":", "\n", "\n", "        ", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "nms_thresh", "=", "nms_thresh", "\n", "self", ".", "conf_thresh", "=", "conf_thresh", "\n", "self", ".", "variance", "=", "variance", "\n", "self", ".", "nms_top_k", "=", "nms_top_k", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.Detect.forward": [[142, 174], ["loc_data.size", "prior_data.size", "conf_data.view().transpose", "prior_data.view().expand", "batch_priors.contiguous().view.contiguous().view.contiguous().view", "box_utils.decode", "decoded_boxes.view.view.view", "torch.zeros", "range", "loc_data.view", "decoded_boxes[].clone", "conf_preds[].clone", "range", "conf_data.view", "prior_data.view", "batch_priors.contiguous().view.contiguous().view.contiguous", "conf_scores[].gt", "conf_scores[].gt.unsqueeze().expand_as", "boxes[].view", "box_utils.nms", "torch.cat", "scores.dim", "conf_scores[].gt.unsqueeze", "scores[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.decode", "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.nms"], ["", "def", "forward", "(", "self", ",", "loc_data", ",", "conf_data", ",", "prior_data", ")", ":", "\n", "\n", "        ", "num", "=", "loc_data", ".", "size", "(", "0", ")", "\n", "num_priors", "=", "prior_data", ".", "size", "(", "0", ")", "\n", "\n", "conf_preds", "=", "conf_data", ".", "view", "(", "num", ",", "num_priors", ",", "self", ".", "num_classes", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "batch_priors", "=", "prior_data", ".", "view", "(", "-", "1", ",", "num_priors", ",", "4", ")", ".", "expand", "(", "num", ",", "num_priors", ",", "4", ")", "\n", "batch_priors", "=", "batch_priors", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "\n", "decoded_boxes", "=", "decode", "(", "loc_data", ".", "view", "(", "-", "1", ",", "4", ")", ",", "batch_priors", ",", "self", ".", "variance", ")", "\n", "decoded_boxes", "=", "decoded_boxes", ".", "view", "(", "num", ",", "num_priors", ",", "4", ")", "\n", "\n", "output", "=", "torch", ".", "zeros", "(", "num", ",", "self", ".", "num_classes", ",", "self", ".", "top_k", ",", "5", ")", "\n", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "            ", "boxes", "=", "decoded_boxes", "[", "i", "]", ".", "clone", "(", ")", "\n", "conf_scores", "=", "conf_preds", "[", "i", "]", ".", "clone", "(", ")", "\n", "\n", "for", "cl", "in", "range", "(", "1", ",", "self", ".", "num_classes", ")", ":", "\n", "                ", "c_mask", "=", "conf_scores", "[", "cl", "]", ".", "gt", "(", "self", ".", "conf_thresh", ")", "\n", "scores", "=", "conf_scores", "[", "cl", "]", "[", "c_mask", "]", "\n", "\n", "if", "scores", ".", "dim", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "l_mask", "=", "c_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "boxes", ")", "\n", "boxes_", "=", "boxes", "[", "l_mask", "]", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "ids", ",", "count", "=", "nms", "(", "boxes_", ",", "scores", ",", "self", ".", "nms_thresh", ",", "self", ".", "nms_top_k", ")", "\n", "count", "=", "count", "if", "count", "<", "self", ".", "top_k", "else", "self", ".", "top_k", "\n", "\n", "output", "[", "i", ",", "cl", ",", ":", "count", "]", "=", "torch", ".", "cat", "(", "(", "scores", "[", "ids", "[", ":", "count", "]", "]", ".", "unsqueeze", "(", "1", ")", ",", "boxes_", "[", "ids", "[", ":", "count", "]", "]", ")", ",", "1", ")", "\n", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.__init__": [[178, 194], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "feature_maps", ",", "\n", "variance", "=", "[", "0.1", ",", "0.2", "]", ",", "\n", "min_sizes", "=", "[", "16", ",", "32", ",", "64", ",", "128", ",", "256", ",", "512", "]", ",", "\n", "steps", "=", "[", "4", ",", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ",", "\n", "clip", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "PriorBox", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "imh", "=", "input_size", "[", "0", "]", "\n", "self", ".", "imw", "=", "input_size", "[", "1", "]", "\n", "self", ".", "feature_maps", "=", "feature_maps", "\n", "\n", "self", ".", "variance", "=", "variance", "\n", "self", ".", "min_sizes", "=", "min_sizes", "\n", "self", ".", "steps", "=", "steps", "\n", "self", ".", "clip", "=", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.PriorBox.forward": [[195, 218], ["enumerate", "torch.FloatTensor().view", "itertools.product", "torch.FloatTensor().view.clamp_", "range", "range", "torch.FloatTensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "mean", "=", "[", "]", "\n", "for", "k", ",", "fmap", "in", "enumerate", "(", "self", ".", "feature_maps", ")", ":", "\n", "            ", "feath", "=", "fmap", "[", "0", "]", "\n", "featw", "=", "fmap", "[", "1", "]", "\n", "for", "i", ",", "j", "in", "product", "(", "range", "(", "feath", ")", ",", "range", "(", "featw", ")", ")", ":", "\n", "                ", "f_kw", "=", "self", ".", "imw", "/", "self", ".", "steps", "[", "k", "]", "\n", "f_kh", "=", "self", ".", "imh", "/", "self", ".", "steps", "[", "k", "]", "\n", "\n", "cx", "=", "(", "j", "+", "0.5", ")", "/", "f_kw", "\n", "cy", "=", "(", "i", "+", "0.5", ")", "/", "f_kh", "\n", "\n", "s_kw", "=", "self", ".", "min_sizes", "[", "k", "]", "/", "self", ".", "imw", "\n", "s_kh", "=", "self", ".", "min_sizes", "[", "k", "]", "/", "self", ".", "imh", "\n", "\n", "mean", "+=", "[", "cx", ",", "cy", ",", "s_kw", ",", "s_kh", "]", "\n", "\n", "", "", "output", "=", "torch", ".", "FloatTensor", "(", "mean", ")", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "\n", "if", "self", ".", "clip", ":", "\n", "            ", "output", ".", "clamp_", "(", "max", "=", "1", ",", "min", "=", "0", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.nms_": [[7, 39], ["numpy.array().astype", "scores.argsort", "keep.append", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "int", "numpy.where", "numpy.array"], "function", ["None"], ["def", "nms_", "(", "dets", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"\n    Courtesy of Ross Girshick\n    [https://github.com/rbgirshick/py-faster-rcnn/blob/master/lib/nms/py_cpu_nms.py]\n    \"\"\"", "\n", "x1", "=", "dets", "[", ":", ",", "0", "]", "\n", "y1", "=", "dets", "[", ":", ",", "1", "]", "\n", "x2", "=", "dets", "[", ":", ",", "2", "]", "\n", "y2", "=", "dets", "[", ":", ",", "3", "]", "\n", "scores", "=", "dets", "[", ":", ",", "4", "]", "\n", "\n", "areas", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "order", "=", "scores", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "keep", "=", "[", "]", "\n", "while", "order", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "order", "[", "0", "]", "\n", "keep", ".", "append", "(", "int", "(", "i", ")", ")", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "order", "[", "1", ":", "]", "]", ")", "\n", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "ovr", "=", "inter", "/", "(", "areas", "[", "i", "]", "+", "areas", "[", "order", "[", "1", ":", "]", "]", "-", "inter", ")", "\n", "\n", "inds", "=", "np", ".", "where", "(", "ovr", "<=", "thresh", ")", "[", "0", "]", "\n", "order", "=", "order", "[", "inds", "+", "1", "]", "\n", "\n", "", "return", "np", ".", "array", "(", "keep", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.decode": [[41, 60], ["torch.cat", "torch.exp"], "function", ["None"], ["", "def", "decode", "(", "loc", ",", "priors", ",", "variances", ")", ":", "\n", "    ", "\"\"\"Decode locations from predictions using priors to undo\n    the encoding we did for offset regression at train time.\n    Args:\n        loc (tensor): location predictions for loc layers,\n            Shape: [num_priors,4]\n        priors (tensor): Prior boxes in center-offset form.\n            Shape: [num_priors,4].\n        variances: (list[float]) Variances of priorboxes\n    Return:\n        decoded bounding box predictions\n    \"\"\"", "\n", "\n", "boxes", "=", "torch", ".", "cat", "(", "(", "\n", "priors", "[", ":", ",", ":", "2", "]", "+", "loc", "[", ":", ",", ":", "2", "]", "*", "variances", "[", "0", "]", "*", "priors", "[", ":", ",", "2", ":", "]", ",", "\n", "priors", "[", ":", ",", "2", ":", "]", "*", "torch", ".", "exp", "(", "loc", "[", ":", ",", "2", ":", "]", "*", "variances", "[", "1", "]", ")", ")", ",", "1", ")", "\n", "boxes", "[", ":", ",", ":", "2", "]", "-=", "boxes", "[", ":", ",", "2", ":", "]", "/", "2", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.nms": [[62, 127], ["scores.new().zero_().long", "torch.mul", "scores.sort", "boxes.new", "boxes.new", "boxes.new", "boxes.new", "boxes.new", "boxes.new", "boxes.numel", "idx.numel", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp.resize_as_", "torch.clamp.resize_as_", "torch.clamp", "torch.clamp", "torch.index_select", "scores.new().zero_", "idx.size", "IoU.le", "scores.new", "scores.size"], "function", ["None"], ["", "def", "nms", "(", "boxes", ",", "scores", ",", "overlap", "=", "0.5", ",", "top_k", "=", "200", ")", ":", "\n", "    ", "\"\"\"Apply non-maximum suppression at test time to avoid detecting too many\n    overlapping bounding boxes for a given object.\n    Args:\n        boxes: (tensor) The location preds for the img, Shape: [num_priors,4].\n        scores: (tensor) The class predscores for the img, Shape:[num_priors].\n        overlap: (float) The overlap thresh for suppressing unnecessary boxes.\n        top_k: (int) The Maximum number of box preds to consider.\n    Return:\n        The indices of the kept boxes with respect to num_priors.\n    \"\"\"", "\n", "\n", "keep", "=", "scores", ".", "new", "(", "scores", ".", "size", "(", "0", ")", ")", ".", "zero_", "(", ")", ".", "long", "(", ")", "\n", "if", "boxes", ".", "numel", "(", ")", "==", "0", ":", "\n", "        ", "return", "keep", ",", "0", "\n", "", "x1", "=", "boxes", "[", ":", ",", "0", "]", "\n", "y1", "=", "boxes", "[", ":", ",", "1", "]", "\n", "x2", "=", "boxes", "[", ":", ",", "2", "]", "\n", "y2", "=", "boxes", "[", ":", ",", "3", "]", "\n", "area", "=", "torch", ".", "mul", "(", "x2", "-", "x1", ",", "y2", "-", "y1", ")", "\n", "v", ",", "idx", "=", "scores", ".", "sort", "(", "0", ")", "# sort in ascending order", "\n", "# I = I[v >= 0.01]", "\n", "idx", "=", "idx", "[", "-", "top_k", ":", "]", "# indices of the top-k largest vals", "\n", "xx1", "=", "boxes", ".", "new", "(", ")", "\n", "yy1", "=", "boxes", ".", "new", "(", ")", "\n", "xx2", "=", "boxes", ".", "new", "(", ")", "\n", "yy2", "=", "boxes", ".", "new", "(", ")", "\n", "w", "=", "boxes", ".", "new", "(", ")", "\n", "h", "=", "boxes", ".", "new", "(", ")", "\n", "\n", "# keep = torch.Tensor()", "\n", "count", "=", "0", "\n", "while", "idx", ".", "numel", "(", ")", ">", "0", ":", "\n", "        ", "i", "=", "idx", "[", "-", "1", "]", "# index of current largest val", "\n", "# keep.append(i)", "\n", "keep", "[", "count", "]", "=", "i", "\n", "count", "+=", "1", "\n", "if", "idx", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "idx", "=", "idx", "[", ":", "-", "1", "]", "# remove kept element from view", "\n", "# load bboxes of next highest vals", "\n", "torch", ".", "index_select", "(", "x1", ",", "0", ",", "idx", ",", "out", "=", "xx1", ")", "\n", "torch", ".", "index_select", "(", "y1", ",", "0", ",", "idx", ",", "out", "=", "yy1", ")", "\n", "torch", ".", "index_select", "(", "x2", ",", "0", ",", "idx", ",", "out", "=", "xx2", ")", "\n", "torch", ".", "index_select", "(", "y2", ",", "0", ",", "idx", ",", "out", "=", "yy2", ")", "\n", "# store element-wise max with next highest score", "\n", "xx1", "=", "torch", ".", "clamp", "(", "xx1", ",", "min", "=", "x1", "[", "i", "]", ")", "\n", "yy1", "=", "torch", ".", "clamp", "(", "yy1", ",", "min", "=", "y1", "[", "i", "]", ")", "\n", "xx2", "=", "torch", ".", "clamp", "(", "xx2", ",", "max", "=", "x2", "[", "i", "]", ")", "\n", "yy2", "=", "torch", ".", "clamp", "(", "yy2", ",", "max", "=", "y2", "[", "i", "]", ")", "\n", "w", ".", "resize_as_", "(", "xx2", ")", "\n", "h", ".", "resize_as_", "(", "yy2", ")", "\n", "w", "=", "xx2", "-", "xx1", "\n", "h", "=", "yy2", "-", "yy1", "\n", "# check sizes of xx1 and xx2.. after each iteration", "\n", "w", "=", "torch", ".", "clamp", "(", "w", ",", "min", "=", "0.0", ")", "\n", "h", "=", "torch", ".", "clamp", "(", "h", ",", "min", "=", "0.0", ")", "\n", "inter", "=", "w", "*", "h", "\n", "# IoU = i / (area(a) + area(b) - i)", "\n", "rem_areas", "=", "torch", ".", "index_select", "(", "area", ",", "0", ",", "idx", ")", "# load remaining areas)", "\n", "union", "=", "(", "rem_areas", "-", "inter", ")", "+", "area", "[", "i", "]", "\n", "IoU", "=", "inter", "/", "union", "# store result in iou", "\n", "# keep only elements with an IoU <= overlap", "\n", "idx", "=", "idx", "[", "IoU", ".", "le", "(", "overlap", ")", "]", "\n", "", "return", "keep", ",", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.__init__": [[19, 30], ["time.time", "nets.S3FDNet().to", "os.path.join", "torch.load", "__init__.S3FD.net.load_state_dict", "__init__.S3FD.net.eval", "os.getcwd", "nets.S3FDNet"], "methods", ["None"], []], "home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.__init__.S3FD.detect_faces": [[32, 67], ["numpy.empty", "torch.no_grad", "box_utils.nms_", "cv2.resize", "numpy.swapaxes", "numpy.swapaxes", "scaled_img.astype.astype.astype", "torch.from_numpy().unsqueeze().to", "__init__.S3FD.net", "torch.Tensor", "range", "detections.size", "torch.from_numpy().unsqueeze", "numpy.vstack", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.TaoRuijie_TalkNet_ASD.s3fd.box_utils.nms_"], []]}