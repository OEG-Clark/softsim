{"home.repos.pwc.inspect_result.megvii-research_protoclip.utils.RoBERTa.TextDataset.__init__": [[12, 18], ["pandas.read_csv", "print", "numpy.array", "df[].tolist"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_filename", ",", "tokenizer", ",", "caption_key", "=", "'title'", ",", "sep", "=", "\"\\t\"", ")", "->", "None", ":", "\n", "\n", "        ", "df", "=", "pd", ".", "read_csv", "(", "input_filename", ",", "sep", "=", "sep", ")", "\n", "print", "(", "df", ")", "\n", "self", ".", "captions", "=", "np", ".", "array", "(", "df", "[", "caption_key", "]", ".", "tolist", "(", ")", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.RoBERTa.TextDataset.__len__": [[19, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "captions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.RoBERTa.TextDataset.__getitem__": [[22, 28], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "RoBERTa.TextDataset.tokenizer", "str", "torch.zeros.long", "torch.zeros.long", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "tokens_full", "=", "torch", ".", "zeros", "(", "77", ")", "\n", "token", "=", "self", ".", "tokenizer", "(", "str", "(", "self", ".", "captions", "[", "idx", "]", ")", ")", "\n", "tokens_full", "[", ":", "len", "(", "token", ")", "]", "=", "token", "[", ":", "77", "]", "\n", "\n", "return", "idx", ",", "tokens_full", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.RoBERTa.PCA": [[30, 37], ["feature.astype.astype", "faiss.PCAMatrix", "faiss.PCAMatrix.train", "faiss.PCAMatrix.apply_py"], "function", ["None"], ["", "", "def", "PCA", "(", "dim", ",", "feature", ")", ":", "\n", "    ", "feature", "=", "feature", ".", "astype", "(", "np", ".", "float32", ")", "\n", "pca", "=", "faiss", ".", "PCAMatrix", "(", "feature", ".", "shape", "[", "1", "]", ",", "dim", ")", "\n", "pca", ".", "train", "(", "feature", ")", "\n", "PCAed_feature", "=", "pca", ".", "apply_py", "(", "feature", ")", "\n", "\n", "return", "PCAed_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.evaluate_checkpoints.evaluate_checkpoint": [[17, 42], ["open_clip.create_model_and_transforms", "torch.load", "model.to.load_state_dict", "logging.info", "model.to.to", "training.evaluations.evaluation.evaluate", "logging.info", "training.pretrained_transformers.get_pretrained_text_encoder_and_tokenizer", "logging.info", "[].startswith", "sd.items", "next", "len", "iter", "sd.items"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model_and_transforms", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.evaluation.evaluate", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.pretrained_transformers.get_pretrained_text_encoder_and_tokenizer"], ["def", "evaluate_checkpoint", "(", "checkpoint_path", ",", "epoch", ")", ":", "\n", "# load model", "\n", "\n", "    ", "if", "args", ".", "pretrained_text", "is", "not", "None", ":", "\n", "        ", "logging", ".", "info", "(", "f'Loading pretrained text trasformer: {args.pretrained_text}.'", ")", "\n", "pretrained_text_encoder", ",", "tokenizer", ",", "args", ".", "pretrained_text_feature_dim", "=", "get_pretrained_text_encoder_and_tokenizer", "(", "args", ".", "pretrained_text", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "f'Text encoder will be trained from scratch.'", ")", "\n", "pretrained_text_encoder", ",", "tokenizer", ",", "args", ".", "pretrained_text_feature_dim", "=", "None", ",", "None", ",", "None", "\n", "", "model", ",", "preprocess_train", ",", "preprocess_val", "=", "create_model_and_transforms", "(", "\n", "args", ".", "model", ",", "\n", "pretrained_text", "=", "pretrained_text_encoder", ",", "\n", "args", "=", "args", "\n", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "device", ")", "\n", "sd", "=", "checkpoint", "[", "\"state_dict\"", "]", "\n", "if", "not", "args", ".", "distributed", "and", "next", "(", "iter", "(", "sd", ".", "items", "(", ")", ")", ")", "[", "0", "]", ".", "startswith", "(", "'module'", ")", ":", "\n", "        ", "sd", "=", "{", "k", "[", "len", "(", "'module.'", ")", ":", "]", ":", "v", "for", "k", ",", "v", "in", "sd", ".", "items", "(", ")", "}", "\n", "", "model", ".", "load_state_dict", "(", "sd", ")", "\n", "logging", ".", "info", "(", "f\"=> Loaded checkpoint '{checkpoint_path}' (epoch {checkpoint['epoch']})\"", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "metrics", "=", "evaluate", "(", "model", ",", "epoch", ",", "preprocess_val", ",", "tokenizer", ",", "args", ",", "tb_writer", "=", "None", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.evaluate_checkpoints.load_params": [[43, 59], ["vars", "argparse.Namespace", "open", "f.readlines", "line.strip().split.strip().split", "line.strip().split.strip", "vars.keys", "type"], "function", ["None"], ["", "def", "load_params", "(", "params_file", ",", "args", ")", ":", "\n", "    ", "args", "=", "vars", "(", "args", ")", "\n", "with", "open", "(", "params_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "': '", ")", "\n", "key", ",", "value", "=", "line", "[", "0", "]", ",", "''", ".", "join", "(", "line", "[", "1", ":", "]", ")", "\n", "if", "key", "in", "args", ".", "keys", "(", ")", "and", "args", "[", "key", "]", "is", "not", "None", ":", "\n", "#print(key, value, args[key], type(args[key]))", "\n", "                ", "args", "[", "key", "]", "=", "type", "(", "args", "[", "key", "]", ")", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "args", "[", "key", "]", "=", "value", "\n", "", "if", "value", "==", "'False'", ":", "\n", "                ", "args", "[", "key", "]", "=", "False", "\n", "", "if", "value", "==", "'None'", ":", "\n", "                ", "args", "[", "key", "]", "=", "None", "\n", "", "", "", "return", "argparse", ".", "Namespace", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.plot_pairs.plot_pairs": [[7, 46], ["matplotlib.figure", "matplotlib.subplots_adjust", "matplotlib.rc", "range", "matplotlib.savefig", "matplotlib.close", "len", "len", "texts[].replace", "textwrap.fill", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.text", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.suptitle", "len", "len", "int", "len"], "function", ["None"], ["def", "plot_pairs", "(", "imgs", ",", "texts", ",", "suptitle", ",", "file_name", "=", "'test.png'", ",", "sample_per_row", "=", "32", ")", ":", "\n", "# imgs: a list of PIL-opened images", "\n", "# texts: a list of str, will be showed as title (per subplot)", "\n", "# suptitle: figure super title", "\n", "\n", "    ", "if", "len", "(", "imgs", ")", "<", "sample_per_row", ":", "\n", "        ", "row", ",", "column", "=", "1", ",", "len", "(", "imgs", ")", "\n", "", "else", ":", "\n", "        ", "row", "=", "(", "sample_per_row", "+", "len", "(", "imgs", ")", "-", "1", ")", "//", "sample_per_row", "\n", "column", "=", "sample_per_row", "\n", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "2", "*", "column", ",", "2.5", "*", "row", ")", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0.3", ",", "hspace", "=", "0.3", ")", "\n", "plt", ".", "rc", "(", "'font'", ",", "size", "=", "10", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "imgs", ")", ")", ":", "\n", "        ", "image", "=", "imgs", "[", "i", "]", "\n", "text", "=", "texts", "[", "i", "]", ".", "replace", "(", "'$'", ",", "''", ")", "\n", "if", "len", "(", "text", ")", ">", "40", ":", "\n", "            ", "text", "=", "text", "[", ":", "40", "]", "+", "'...'", "\n", "", "text", "=", "textwrap", ".", "fill", "(", "text", ",", "width", "=", "20", ")", "\n", "\n", "plt", ".", "subplot", "(", "row", ",", "column", ",", "i", "+", "1", ")", "\n", "plt", ".", "imshow", "(", "image", ")", "\n", "plt", ".", "text", "(", "\n", "x", "=", "int", "(", "image", ".", "size", "[", "0", "]", "/", "2", ")", ",", "y", "=", "image", ".", "size", "[", "1", "]", "+", "30", ",", "s", "=", "text", ",", "\n", "fontsize", "=", "11", ",", "va", "=", "'top'", ",", "ha", "=", "'center'", ",", "\n", "bbox", "=", "{", "'facecolor'", ":", "'white'", ",", "'edgecolor'", ":", "'white'", ",", "'pad'", ":", "4", ",", "}", "\n", ")", "\n", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "\n", "", "if", "suptitle", "is", "not", "None", ":", "\n", "        ", "plt", ".", "suptitle", "(", "suptitle", ",", "size", "=", "'x-large'", ")", "\n", "\n", "\n", "", "plt", ".", "savefig", "(", "file_name", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.utils.gather_cc.grab": [[12, 57], ["os.path.exists", "print", "requests.get", "PIL.Image.open", "Image.open.thumbnail", "Image.open.save", "line.split", "print", "print", "io.BytesIO", "min", "print", "PIL.Image.open", "numpy.array", "print", "print", "max", "print"], "function", ["None"], ["def", "grab", "(", "line", ")", ":", "\n", "    ", "\"\"\"\n    Download a single image from the TSV.\n    \"\"\"", "\n", "uid", ",", "split", ",", "line", "=", "line", "\n", "try", ":", "\n", "        ", "caption", ",", "url", "=", "line", ".", "split", "(", "\"\\t\"", ")", "[", ":", "2", "]", "\n", "", "except", ":", "\n", "        ", "print", "(", "\"Parse error\"", ")", "\n", "return", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "ROOT", "+", "\"/%s/%d/%d.jpg\"", "%", "(", "split", ",", "uid", "%", "1000", ",", "uid", ")", ")", ":", "\n", "        ", "print", "(", "\"Finished\"", ",", "uid", ")", "\n", "return", "uid", ",", "caption", ",", "url", "\n", "\n", "# Let's not crash if anythign weird happens", "\n", "", "try", ":", "\n", "        ", "dat", "=", "requests", ".", "get", "(", "url", ",", "timeout", "=", "20", ")", "\n", "if", "dat", ".", "status_code", "!=", "200", ":", "\n", "            ", "print", "(", "\"404 file\"", ",", "url", ")", "\n", "return", "\n", "\n", "# Try to parse this as an Image file, we'll fail out if not", "\n", "", "im", "=", "Image", ".", "open", "(", "BytesIO", "(", "dat", ".", "content", ")", ")", "\n", "im", ".", "thumbnail", "(", "(", "512", ",", "512", ")", ",", "PIL", ".", "Image", ".", "BICUBIC", ")", "\n", "if", "min", "(", "*", "im", ".", "size", ")", "<", "max", "(", "*", "im", ".", "size", ")", "/", "3", ":", "\n", "            ", "print", "(", "\"Too small\"", ",", "url", ")", "\n", "return", "\n", "\n", "", "im", ".", "save", "(", "ROOT", "+", "\"/%s/%d/%d.jpg\"", "%", "(", "split", ",", "uid", "%", "1000", ",", "uid", ")", ")", "\n", "\n", "# Another try/catch just because sometimes saving and re-loading", "\n", "# the image is different than loading it once.", "\n", "try", ":", "\n", "            ", "o", "=", "Image", ".", "open", "(", "ROOT", "+", "\"/%s/%d/%d.jpg\"", "%", "(", "split", ",", "uid", "%", "1000", ",", "uid", ")", ")", "\n", "o", "=", "np", ".", "array", "(", "o", ")", "\n", "\n", "print", "(", "\"Success\"", ",", "o", ".", "shape", ",", "uid", ",", "url", ")", "\n", "return", "uid", ",", "caption", ",", "url", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Failed\"", ",", "uid", ",", "url", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Unknown error\"", ",", "e", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.timm_model.TimmModel.__init__": [[25, 70], ["torch.Module.__init__", "to_2tuple", "timm.create_model", "timm_model.TimmModel.trunk.default_cfg.get", "collections.OrderedDict", "torch.Sequential", "RuntimeError", "timm_model.TimmModel.trunk.reset_classifier", "timm_model.TimmModel.trunk.reset_classifier", "AbsAttentionPool2d", "torch.Dropout", "torch.Linear", "dict", "RotAttentionPool2d", "Mlp"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model_name", ",", "\n", "embed_dim", ",", "\n", "image_size", "=", "224", ",", "\n", "pool", "=", "'avg'", ",", "\n", "proj", "=", "'linear'", ",", "\n", "drop", "=", "0.", ",", "\n", "pretrained", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "timm", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Please `pip install timm` to use timm models.\"", ")", "\n", "\n", "", "self", ".", "image_size", "=", "to_2tuple", "(", "image_size", ")", "\n", "self", ".", "trunk", "=", "timm", ".", "create_model", "(", "model_name", ",", "pretrained", "=", "pretrained", ")", "\n", "feat_size", "=", "self", ".", "trunk", ".", "default_cfg", ".", "get", "(", "'pool_size'", ",", "None", ")", "\n", "feature_ndim", "=", "1", "if", "not", "feat_size", "else", "2", "\n", "if", "pool", "in", "(", "'abs_attn'", ",", "'rot_attn'", ")", ":", "\n", "            ", "assert", "feature_ndim", "==", "2", "\n", "# if attn pooling used, remove both classifier and default pool", "\n", "self", ".", "trunk", ".", "reset_classifier", "(", "0", ",", "global_pool", "=", "''", ")", "\n", "", "else", ":", "\n", "# reset global pool if pool config set, otherwise leave as network default", "\n", "            ", "reset_kwargs", "=", "dict", "(", "global_pool", "=", "pool", ")", "if", "pool", "else", "{", "}", "\n", "self", ".", "trunk", ".", "reset_classifier", "(", "0", ",", "**", "reset_kwargs", ")", "\n", "", "prev_chs", "=", "self", ".", "trunk", ".", "num_features", "\n", "\n", "head_layers", "=", "OrderedDict", "(", ")", "\n", "if", "pool", "==", "'abs_attn'", ":", "\n", "            ", "head_layers", "[", "'pool'", "]", "=", "AbsAttentionPool2d", "(", "prev_chs", ",", "feat_size", "=", "feat_size", ",", "out_features", "=", "embed_dim", ")", "\n", "prev_chs", "=", "embed_dim", "\n", "", "elif", "pool", "==", "'rot_attn'", ":", "\n", "            ", "head_layers", "[", "'pool'", "]", "=", "RotAttentionPool2d", "(", "prev_chs", ",", "out_features", "=", "embed_dim", ")", "\n", "prev_chs", "=", "embed_dim", "\n", "", "else", ":", "\n", "            ", "assert", "proj", ",", "'projection layer needed if non-attention pooling is used.'", "\n", "\n", "# NOTE attention pool ends with a projection layer, so proj should usually be set to '' if such pooling is used", "\n", "", "if", "proj", "==", "'linear'", ":", "\n", "            ", "head_layers", "[", "'drop'", "]", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "head_layers", "[", "'proj'", "]", "=", "nn", ".", "Linear", "(", "prev_chs", ",", "embed_dim", ")", "\n", "", "elif", "proj", "==", "'mlp'", ":", "\n", "            ", "head_layers", "[", "'mlp'", "]", "=", "Mlp", "(", "prev_chs", ",", "2", "*", "embed_dim", ",", "embed_dim", ",", "drop", "=", "drop", ")", "\n", "\n", "", "self", ".", "head", "=", "nn", ".", "Sequential", "(", "head_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.timm_model.TimmModel.lock": [[71, 102], ["timm_model.TimmModel.trunk.parameters", "timm_model.TimmModel.trunk.group_matcher", "group_parameters", "max", "range", "utils.freeze_batch_norm_2d", "group_parameters.keys", "group_modules", "utils.freeze_batch_norm_2d", "RuntimeError", "timm_model.TimmModel.trunk.get_parameter", "group_modules.items"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.utils.freeze_batch_norm_2d", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.utils.freeze_batch_norm_2d"], ["", "def", "lock", "(", "self", ",", "unlocked_groups", "=", "0", ",", "freeze_bn_stats", "=", "False", ")", ":", "\n", "        ", "\"\"\" lock modules\n        Args:\n            unlocked_groups (int): leave last n layer groups unlocked (default: 0)\n        \"\"\"", "\n", "if", "not", "unlocked_groups", ":", "\n", "# lock full model", "\n", "            ", "for", "param", "in", "self", ".", "trunk", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "if", "freeze_bn_stats", ":", "\n", "                ", "freeze_batch_norm_2d", "(", "self", ".", "trunk", ")", "\n", "", "", "else", ":", "\n", "# NOTE: partial freeze requires latest timm (master) branch and is subject to change", "\n", "            ", "try", ":", "\n", "# FIXME import here until API stable and in an official release", "\n", "                ", "from", "timm", ".", "models", ".", "helpers", "import", "group_parameters", ",", "group_modules", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "'Please install latest timm `pip install git+https://github.com/rwightman/pytorch-image-models`'", ")", "\n", "", "matcher", "=", "self", ".", "trunk", ".", "group_matcher", "(", ")", "\n", "gparams", "=", "group_parameters", "(", "self", ".", "trunk", ",", "matcher", ")", "\n", "max_layer_id", "=", "max", "(", "gparams", ".", "keys", "(", ")", ")", "\n", "max_layer_id", "=", "max_layer_id", "-", "unlocked_groups", "\n", "for", "group_idx", "in", "range", "(", "max_layer_id", "+", "1", ")", ":", "\n", "                ", "group", "=", "gparams", "[", "group_idx", "]", "\n", "for", "param", "in", "group", ":", "\n", "                    ", "self", ".", "trunk", ".", "get_parameter", "(", "param", ")", ".", "requires_grad", "=", "False", "\n", "", "", "if", "freeze_bn_stats", ":", "\n", "                ", "gmodules", "=", "group_modules", "(", "self", ".", "trunk", ",", "matcher", ",", "reverse", "=", "True", ")", "\n", "gmodules", "=", "{", "k", "for", "k", ",", "v", "in", "gmodules", ".", "items", "(", ")", "if", "v", "<=", "max_layer_id", "}", "\n", "freeze_batch_norm_2d", "(", "self", ".", "trunk", ",", "gmodules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.timm_model.TimmModel.forward": [[103, 107], ["timm_model.TimmModel.trunk", "timm_model.TimmModel.head"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "trunk", "(", "x", ")", "\n", "x", "=", "self", ".", "head", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.list_pretrained": [[91, 96], ["_PRETRAINED.keys", "_PRETRAINED[].keys"], "function", ["None"], ["def", "list_pretrained", "(", "as_str", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\" returns list of pretrained models\n    Returns a tuple (model_name, pretrain_tag) by default or 'name:tag' if as_str == True\n    \"\"\"", "\n", "return", "[", "':'", ".", "join", "(", "[", "k", ",", "t", "]", ")", "if", "as_str", "else", "(", "k", ",", "t", ")", "for", "k", "in", "_PRETRAINED", ".", "keys", "(", ")", "for", "t", "in", "_PRETRAINED", "[", "k", "]", ".", "keys", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.list_pretrained_tag_models": [[98, 105], ["_PRETRAINED.keys", "models.append"], "function", ["None"], ["", "def", "list_pretrained_tag_models", "(", "tag", ":", "str", ")", ":", "\n", "    ", "\"\"\" return all models having the specified pretrain tag \"\"\"", "\n", "models", "=", "[", "]", "\n", "for", "k", "in", "_PRETRAINED", ".", "keys", "(", ")", ":", "\n", "        ", "if", "tag", "in", "_PRETRAINED", "[", "k", "]", ":", "\n", "            ", "models", ".", "append", "(", "k", ")", "\n", "", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.list_pretrained_model_tags": [[107, 113], ["tags.extend", "_PRETRAINED[].keys"], "function", ["None"], ["", "def", "list_pretrained_model_tags", "(", "model", ":", "str", ")", ":", "\n", "    ", "\"\"\" return all pretrain tags for the specified model architecture \"\"\"", "\n", "tags", "=", "[", "]", "\n", "if", "model", "in", "_PRETRAINED", ":", "\n", "        ", "tags", ".", "extend", "(", "_PRETRAINED", "[", "model", "]", ".", "keys", "(", ")", ")", "\n", "", "return", "tags", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.get_pretrained_url": [[115, 123], ["tag.lower.lower"], "function", ["None"], ["", "def", "get_pretrained_url", "(", "model", ":", "str", ",", "tag", ":", "str", ")", ":", "\n", "    ", "if", "model", "not", "in", "_PRETRAINED", ":", "\n", "        ", "return", "''", "\n", "", "model_pretrained", "=", "_PRETRAINED", "[", "model", "]", "\n", "tag", "=", "tag", ".", "lower", "(", ")", "\n", "if", "tag", "not", "in", "model_pretrained", ":", "\n", "        ", "return", "''", "\n", "", "return", "model_pretrained", "[", "tag", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.download_pretrained": [[125, 162], ["os.path.expanduser", "os.makedirs", "os.path.basename", "os.path.join", "os.path.isfile", "os.path.exists", "RuntimeError", "urllib.request.urlopen", "open", "RuntimeError", "url.split", "os.path.isfile", "tqdm.tqdm", "hashlib.sha256().hexdigest", "hashlib.sha256().hexdigest", "warnings.warn", "source.read", "output.write", "loop.update", "int", "len", "hashlib.sha256", "hashlib.sha256", "source.info().get", "open().read", "open().read", "source.info", "open", "open"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update"], ["", "def", "download_pretrained", "(", "url", ":", "str", ",", "root", ":", "str", "=", "os", ".", "path", ".", "expanduser", "(", "\"~/.cache/clip\"", ")", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "root", ",", "exist_ok", "=", "True", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "url", ")", "\n", "\n", "if", "'openaipublic'", "in", "url", ":", "\n", "        ", "expected_sha256", "=", "url", ".", "split", "(", "\"/\"", ")", "[", "-", "2", "]", "\n", "", "else", ":", "\n", "        ", "expected_sha256", "=", "''", "\n", "\n", "", "download_target", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "download_target", ")", "and", "not", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"{download_target} exists and is not a regular file\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "download_target", ")", ":", "\n", "        ", "if", "expected_sha256", ":", "\n", "            ", "if", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "==", "expected_sha256", ":", "\n", "                ", "return", "download_target", "\n", "", "else", ":", "\n", "                ", "warnings", ".", "warn", "(", "f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\"", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "download_target", "\n", "\n", "", "", "with", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "as", "source", ",", "open", "(", "download_target", ",", "\"wb\"", ")", "as", "output", ":", "\n", "        ", "with", "tqdm", "(", "total", "=", "int", "(", "source", ".", "info", "(", ")", ".", "get", "(", "\"Content-Length\"", ")", ")", ",", "ncols", "=", "80", ",", "unit", "=", "'iB'", ",", "unit_scale", "=", "True", ")", "as", "loop", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "buffer", "=", "source", ".", "read", "(", "8192", ")", "\n", "if", "not", "buffer", ":", "\n", "                    ", "break", "\n", "\n", "", "output", ".", "write", "(", "buffer", ")", "\n", "loop", ".", "update", "(", "len", "(", "buffer", ")", ")", "\n", "\n", "", "", "", "if", "expected_sha256", "and", "hashlib", ".", "sha256", "(", "open", "(", "download_target", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "!=", "expected_sha256", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Model has been downloaded but the SHA256 checksum does not not match\"", ")", "\n", "\n", "", "return", "download_target", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.__init__": [[69, 93], ["tokenizer.default_bpe", "tokenizer.bytes_to_unicode", "gzip.open().read().decode().split", "list", "list.extend", "dict", "dict", "regex.compile", "len", "tuple", "bytes_to_unicode().values", "list.append", "zip", "zip", "tokenizer.SimpleTokenizer.byte_encoder.items", "gzip.open().read().decode", "merge.split", "range", "tokenizer.SimpleTokenizer.encoder.items", "range", "tokenizer.bytes_to_unicode", "len", "len", "gzip.open().read", "gzip.open"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.default_bpe", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.bytes_to_unicode", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.bytes_to_unicode"], ["    ", "def", "__init__", "(", "self", ",", "bpe_path", ":", "str", "=", "default_bpe", "(", ")", ",", "special_tokens", "=", "None", ")", ":", "\n", "        ", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "merges", "=", "gzip", ".", "open", "(", "bpe_path", ")", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "'\\n'", ")", "\n", "merges", "=", "merges", "[", "1", ":", "49152", "-", "256", "-", "2", "+", "1", "]", "\n", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "vocab", "=", "list", "(", "bytes_to_unicode", "(", ")", ".", "values", "(", ")", ")", "\n", "vocab", "=", "vocab", "+", "[", "v", "+", "'</w>'", "for", "v", "in", "vocab", "]", "\n", "for", "merge", "in", "merges", ":", "\n", "            ", "vocab", ".", "append", "(", "''", ".", "join", "(", "merge", ")", ")", "\n", "", "if", "not", "special_tokens", ":", "\n", "            ", "special_tokens", "=", "[", "'<start_of_text>'", ",", "'<end_of_text>'", "]", "\n", "", "else", ":", "\n", "            ", "special_tokens", "=", "[", "'<start_of_text>'", ",", "'<end_of_text>'", "]", "+", "special_tokens", "\n", "", "vocab", ".", "extend", "(", "special_tokens", ")", "\n", "self", ".", "encoder", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "t", ":", "t", "for", "t", "in", "special_tokens", "}", "\n", "special", "=", "\"|\"", ".", "join", "(", "special_tokens", ")", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "special", "+", "r\"\"\"|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\"", ",", "re", ".", "IGNORECASE", ")", "\n", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "encoder", ")", "\n", "self", ".", "all_special_ids", "=", "[", "self", ".", "encoder", "[", "t", "]", "for", "t", "in", "special_tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.bpe": [[94, 134], ["tokenizer.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenizer.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenizer.SimpleTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.get_pairs", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "'</w>'", ",", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "'</w>'", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "'inf'", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "", "except", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "' '", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.encode": [[135, 142], ["whitespace_clean().lower", "regex.findall", "bpe_tokens.extend", "tokenizer.whitespace_clean", "tokenizer.basic_clean", "token.encode", "tokenizer.SimpleTokenizer.bpe().split", "tokenizer.SimpleTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.whitespace_clean", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.basic_clean", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.encode", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.bpe"], ["", "def", "encode", "(", "self", ",", "text", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "text", "=", "whitespace_clean", "(", "basic_clean", "(", "text", ")", ")", ".", "lower", "(", ")", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "bpe_tokens", ".", "extend", "(", "self", ".", "encoder", "[", "bpe_token", "]", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode": [[143, 147], ["bytearray().decode().replace", "bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode"], ["", "def", "decode", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "text", "=", "''", ".", "join", "(", "[", "self", ".", "decoder", "[", "token", "]", "for", "token", "in", "tokens", "]", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "'utf-8'", ",", "errors", "=", "\"replace\"", ")", ".", "replace", "(", "'</w>'", ",", "' '", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.default_bpe": [[16, 19], ["functools.lru_cache", "os.path.join", "os.path.dirname", "os.path.abspath"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "default_bpe", "(", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\"bpe_simple_vocab_16e6.txt.gz\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.bytes_to_unicode": [[21, 42], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["", "@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a corresponding list of unicode strings.\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    And avoids mapping to whitespace/control characters the bpe code barfs on.\n    \"\"\"", "\n", "bs", "=", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.get_pairs": [[44, 54], ["set", "set.add"], "function", ["None"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.basic_clean": [[56, 60], ["ftfy.fix_text", "html.unescape", "html.unescape.strip", "html.unescape"], "function", ["None"], ["", "def", "basic_clean", "(", "text", ")", ":", "\n", "    ", "text", "=", "ftfy", ".", "fix_text", "(", "text", ")", "\n", "text", "=", "html", ".", "unescape", "(", "html", ".", "unescape", "(", "text", ")", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.whitespace_clean": [[62, 66], ["regex.sub", "text.strip.strip"], "function", ["None"], ["", "def", "whitespace_clean", "(", "text", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "text", ")", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.tokenize": [[152, 181], ["isinstance", "torch.zeros", "enumerate", "len", "torch.tensor", "len", "_tokenizer.encode", "len"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.encode"], ["def", "tokenize", "(", "texts", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "context_length", ":", "int", "=", "77", ")", "->", "torch", ".", "LongTensor", ":", "\n", "    ", "\"\"\"\n    Returns the tokenized representation of given input string(s)\n\n    Parameters\n    ----------\n    texts : Union[str, List[str]]\n        An input string or a list of input strings to tokenize\n    context_length : int\n        The context length to use; all CLIP models use 77 as the context length\n\n    Returns\n    -------\n    A two-dimensional tensor containing the resulting tokens, shape = [number of input strings, context_length]\n    \"\"\"", "\n", "if", "isinstance", "(", "texts", ",", "str", ")", ":", "\n", "        ", "texts", "=", "[", "texts", "]", "\n", "\n", "", "sot_token", "=", "_tokenizer", ".", "encoder", "[", "\"<start_of_text>\"", "]", "\n", "eot_token", "=", "_tokenizer", ".", "encoder", "[", "\"<end_of_text>\"", "]", "\n", "all_tokens", "=", "[", "[", "sot_token", "]", "+", "_tokenizer", ".", "encode", "(", "text", ")", "+", "[", "eot_token", "]", "for", "text", "in", "texts", "]", "\n", "result", "=", "torch", ".", "zeros", "(", "len", "(", "all_tokens", ")", ",", "context_length", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "for", "i", ",", "tokens", "in", "enumerate", "(", "all_tokens", ")", ":", "\n", "        ", "if", "len", "(", "tokens", ")", ">", "context_length", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "context_length", "]", "# Truncate", "\n", "", "result", "[", "i", ",", ":", "len", "(", "tokens", ")", "]", "=", "torch", ".", "tensor", "(", "tokens", ")", "\n", "\n", "", "return", "result", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.loss.ClipLoss.__init__": [[60, 80], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "local_loss", "=", "False", ",", "\n", "gather_with_grad", "=", "False", ",", "\n", "cache_labels", "=", "False", ",", "\n", "rank", "=", "0", ",", "\n", "world_size", "=", "1", ",", "\n", "use_horovod", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "local_loss", "=", "local_loss", "\n", "self", ".", "gather_with_grad", "=", "gather_with_grad", "\n", "self", ".", "cache_labels", "=", "cache_labels", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "use_horovod", "=", "use_horovod", "\n", "\n", "# cache state", "\n", "self", ".", "prev_num_logits", "=", "0", "\n", "self", ".", "labels", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.loss.ClipLoss.forward": [[81, 115], ["loss.gather_features", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.gather_features"], ["", "def", "forward", "(", "self", ",", "image_features", ",", "text_features", ",", "logit_scale", ")", ":", "\n", "        ", "device", "=", "image_features", ".", "device", "\n", "if", "self", ".", "world_size", ">", "1", ":", "\n", "            ", "all_image_features", ",", "all_text_features", "=", "gather_features", "(", "\n", "image_features", ",", "text_features", ",", "\n", "self", ".", "local_loss", ",", "self", ".", "gather_with_grad", ",", "self", ".", "rank", ",", "self", ".", "world_size", ",", "self", ".", "use_horovod", ")", "\n", "\n", "if", "self", ".", "local_loss", ":", "\n", "                ", "logits_per_image", "=", "logit_scale", "*", "image_features", "@", "all_text_features", ".", "T", "\n", "logits_per_text", "=", "logit_scale", "*", "text_features", "@", "all_image_features", ".", "T", "\n", "", "else", ":", "\n", "                ", "logits_per_image", "=", "logit_scale", "*", "all_image_features", "@", "all_text_features", ".", "T", "\n", "logits_per_text", "=", "logits_per_image", ".", "T", "\n", "", "", "else", ":", "\n", "            ", "logits_per_image", "=", "logit_scale", "*", "image_features", "@", "text_features", ".", "T", "\n", "logits_per_text", "=", "logit_scale", "*", "text_features", "@", "image_features", ".", "T", "\n", "\n", "# calculated ground-truth and cache if enabled", "\n", "", "num_logits", "=", "logits_per_image", ".", "shape", "[", "0", "]", "\n", "if", "self", ".", "prev_num_logits", "!=", "num_logits", "or", "device", "not", "in", "self", ".", "labels", ":", "\n", "            ", "labels", "=", "torch", ".", "arange", "(", "num_logits", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "world_size", ">", "1", "and", "self", ".", "local_loss", ":", "\n", "                ", "labels", "=", "labels", "+", "num_logits", "*", "self", ".", "rank", "\n", "", "if", "self", ".", "cache_labels", ":", "\n", "                ", "self", ".", "labels", "[", "device", "]", "=", "labels", "\n", "self", ".", "prev_num_logits", "=", "num_logits", "\n", "", "", "else", ":", "\n", "            ", "labels", "=", "self", ".", "labels", "[", "device", "]", "\n", "\n", "", "total_loss", "=", "(", "\n", "F", ".", "cross_entropy", "(", "logits_per_image", ",", "labels", ")", "+", "\n", "F", ".", "cross_entropy", "(", "logits_per_text", ",", "labels", ")", "\n", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.loss.gather_features": [[12, 56], ["hvd.allgather", "hvd.allgather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.no_grad", "torch.no_grad", "hvd.allgather", "hvd.allgather", "list", "list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat.chunk", "torch.cat.chunk", "range", "range"], "function", ["None"], ["", "def", "gather_features", "(", "\n", "image_features", ",", "\n", "text_features", ",", "\n", "local_loss", "=", "False", ",", "\n", "gather_with_grad", "=", "False", ",", "\n", "rank", "=", "0", ",", "\n", "world_size", "=", "1", ",", "\n", "use_horovod", "=", "False", "\n", ")", ":", "\n", "    ", "if", "use_horovod", ":", "\n", "        ", "assert", "hvd", "is", "not", "None", ",", "'Please install horovod'", "\n", "if", "gather_with_grad", ":", "\n", "            ", "all_image_features", "=", "hvd", ".", "allgather", "(", "image_features", ")", "\n", "all_text_features", "=", "hvd", ".", "allgather", "(", "text_features", ")", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "all_image_features", "=", "hvd", ".", "allgather", "(", "image_features", ")", "\n", "all_text_features", "=", "hvd", ".", "allgather", "(", "text_features", ")", "\n", "", "if", "not", "local_loss", ":", "\n", "# ensure grads for local rank when all_* features don't have a gradient", "\n", "                ", "gathered_image_features", "=", "list", "(", "all_image_features", ".", "chunk", "(", "world_size", ",", "dim", "=", "0", ")", ")", "\n", "gathered_text_features", "=", "list", "(", "all_text_features", ".", "chunk", "(", "world_size", ",", "dim", "=", "0", ")", ")", "\n", "gathered_image_features", "[", "rank", "]", "=", "image_features", "\n", "gathered_text_features", "[", "rank", "]", "=", "text_features", "\n", "all_image_features", "=", "torch", ".", "cat", "(", "gathered_image_features", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "gathered_text_features", ",", "dim", "=", "0", ")", "\n", "", "", "", "else", ":", "\n", "# We gather tensors from all gpus", "\n", "        ", "if", "gather_with_grad", ":", "\n", "            ", "all_image_features", "=", "torch", ".", "cat", "(", "torch", ".", "distributed", ".", "nn", ".", "all_gather", "(", "image_features", ")", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "torch", ".", "distributed", ".", "nn", ".", "all_gather", "(", "text_features", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "gathered_image_features", "=", "[", "torch", ".", "zeros_like", "(", "image_features", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "gathered_text_features", "=", "[", "torch", ".", "zeros_like", "(", "text_features", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "gathered_image_features", ",", "image_features", ")", "\n", "dist", ".", "all_gather", "(", "gathered_text_features", ",", "text_features", ")", "\n", "if", "not", "local_loss", ":", "\n", "# ensure grads for local rank when all_* features don't have a gradient", "\n", "                ", "gathered_image_features", "[", "rank", "]", "=", "image_features", "\n", "gathered_text_features", "[", "rank", "]", "=", "text_features", "\n", "", "all_image_features", "=", "torch", ".", "cat", "(", "gathered_image_features", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "gathered_text_features", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "return", "all_image_features", ",", "all_text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory._natural_key": [[21, 23], ["s.isdigit", "int", "re.split", "string_.lower"], "function", ["None"], ["def", "_natural_key", "(", "string_", ")", ":", "\n", "    ", "return", "[", "int", "(", "s", ")", "if", "s", ".", "isdigit", "(", ")", "else", "s", "for", "s", "in", "re", ".", "split", "(", "r'(\\d+)'", ",", "string_", ".", "lower", "(", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory._rescan_model_configs": [[25, 44], ["config_path.is_file", "config_files.append", "config_path.is_dir", "open", "json.load", "all", "sorted", "_MODEL_CONFIGS.items", "config_files.extend", "config_path.glob", "factory._natural_key"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory._natural_key"], ["", "def", "_rescan_model_configs", "(", ")", ":", "\n", "    ", "global", "_MODEL_CONFIGS", "\n", "\n", "config_ext", "=", "(", "'.json'", ",", ")", "\n", "config_files", "=", "[", "]", "\n", "for", "config_path", "in", "_MODEL_CONFIG_PATHS", ":", "\n", "        ", "if", "config_path", ".", "is_file", "(", ")", "and", "config_path", ".", "suffix", "in", "config_ext", ":", "\n", "            ", "config_files", ".", "append", "(", "config_path", ")", "\n", "", "elif", "config_path", ".", "is_dir", "(", ")", ":", "\n", "            ", "for", "ext", "in", "config_ext", ":", "\n", "                ", "config_files", ".", "extend", "(", "config_path", ".", "glob", "(", "f'*{ext}'", ")", ")", "\n", "\n", "", "", "", "for", "cf", "in", "config_files", ":", "\n", "        ", "with", "open", "(", "cf", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "model_cfg", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "all", "(", "a", "in", "model_cfg", "for", "a", "in", "(", "'embed_dim'", ",", "'vision_cfg'", ",", "'text_cfg'", ")", ")", ":", "\n", "                ", "_MODEL_CONFIGS", "[", "cf", ".", "stem", "]", "=", "model_cfg", "\n", "\n", "", "", "", "_MODEL_CONFIGS", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "sorted", "(", "_MODEL_CONFIGS", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "_natural_key", "(", "x", "[", "0", "]", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict": [[49, 58], ["torch.load", "[].startswith", "isinstance", "next", "state_dict.items", "iter", "state_dict.items"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load"], ["def", "load_state_dict", "(", "checkpoint_path", ":", "str", ",", "map_location", "=", "'cpu'", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "map_location", ")", "\n", "if", "isinstance", "(", "checkpoint", ",", "dict", ")", "and", "'state_dict'", "in", "checkpoint", ":", "\n", "        ", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "", "else", ":", "\n", "        ", "state_dict", "=", "checkpoint", "\n", "", "if", "next", "(", "iter", "(", "state_dict", ".", "items", "(", ")", ")", ")", "[", "0", "]", ".", "startswith", "(", "'module'", ")", ":", "\n", "        ", "state_dict", "=", "{", "k", "[", "7", ":", "]", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model": [[60, 125], ["torch.device", "model_name.replace.replace", "pretrained.lower", "logging.info", "openai.load_openai_model", "model.CLIP", "torch.jit.script.to", "torch.jit.script.float", "logging.info", "copy.deepcopy", "logging.error", "RuntimeError", "pretrained.get_pretrained_url", "model.convert_weights_to_fp16", "torch.jit.script", "copy.deepcopy.get", "pretrained.download_pretrained", "os.path.exists", "logging.info", "torch.jit.script.load_state_dict", "logging.warning", "RuntimeError", "factory.load_state_dict", "factory.list_models"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.openai.load_openai_model", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.get_pretrained_url", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.convert_weights_to_fp16", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.download_pretrained", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.list_models"], ["", "def", "create_model", "(", "\n", "model_name", ":", "str", ",", "\n", "pretrained", ":", "str", "=", "''", ",", "\n", "precision", ":", "str", "=", "'fp32'", ",", "\n", "device", ":", "torch", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ",", "\n", "jit", ":", "bool", "=", "False", ",", "\n", "force_quick_gelu", ":", "bool", "=", "False", ",", "\n", "pretrained_image", ":", "bool", "=", "False", ",", "\n", "pretrained_text", "=", "None", ",", "\n", "args", "=", "None", "\n", ")", ":", "\n", "    ", "model_name", "=", "model_name", ".", "replace", "(", "'/'", ",", "'-'", ")", "# for callers using old naming with / in ViT names", "\n", "\n", "if", "pretrained", ".", "lower", "(", ")", "==", "'openai'", ":", "\n", "        ", "logging", ".", "info", "(", "f'Loading pretrained {model_name} from OpenAI.'", ")", "\n", "model", "=", "load_openai_model", "(", "model_name", ",", "device", "=", "device", ",", "jit", "=", "jit", ")", "\n", "# See https://discuss.pytorch.org/t/valueerror-attemting-to-unscale-fp16-gradients/81372", "\n", "if", "precision", "==", "\"amp\"", "or", "precision", "==", "\"fp32\"", ":", "\n", "            ", "model", "=", "model", ".", "float", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "model_name", "in", "_MODEL_CONFIGS", ":", "\n", "            ", "logging", ".", "info", "(", "f'Loading {model_name} model config.'", ")", "\n", "model_cfg", "=", "deepcopy", "(", "_MODEL_CONFIGS", "[", "model_name", "]", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "error", "(", "f'Model config for {model_name} not found; available models {list_models()}.'", ")", "\n", "raise", "RuntimeError", "(", "f'Model config for {model_name} not found.'", ")", "\n", "\n", "", "if", "force_quick_gelu", ":", "\n", "# override for use of QuickGELU on non-OpenAI transformer models", "\n", "            ", "model_cfg", "[", "\"quick_gelu\"", "]", "=", "True", "\n", "\n", "", "if", "pretrained_image", ":", "\n", "            ", "if", "'timm_model_name'", "in", "model_cfg", ".", "get", "(", "'vision_cfg'", ",", "{", "}", ")", ":", "\n", "# pretrained weight loading for timm models set via vision_cfg", "\n", "                ", "model_cfg", "[", "'vision_cfg'", "]", "[", "'timm_model_pretrained'", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "'pretrained image towers currently only supported for timm models'", "\n", "", "", "model_cfg", "[", "'pretrained_text'", "]", "=", "pretrained_text", "\n", "model_cfg", "[", "'args'", "]", "=", "args", "\n", "model", "=", "CLIP", "(", "**", "model_cfg", ")", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "checkpoint_path", "=", "''", "\n", "url", "=", "get_pretrained_url", "(", "model_name", ",", "pretrained", ")", "\n", "if", "url", ":", "\n", "                ", "checkpoint_path", "=", "download_pretrained", "(", "url", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "pretrained", ")", ":", "\n", "                ", "checkpoint_path", "=", "pretrained", "\n", "\n", "", "if", "checkpoint_path", ":", "\n", "                ", "logging", ".", "info", "(", "f'Loading pretrained {model_name} weights ({pretrained}).'", ")", "\n", "model", ".", "load_state_dict", "(", "load_state_dict", "(", "checkpoint_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logging", ".", "warning", "(", "f'Pretrained weights ({pretrained}) not found for model {model_name}.'", ")", "\n", "raise", "RuntimeError", "(", "f'Pretrained weights ({pretrained}) not found for model {model_name}.'", ")", "\n", "\n", "", "", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "if", "precision", "==", "\"fp16\"", ":", "\n", "            ", "assert", "device", ".", "type", "!=", "'cpu'", "\n", "convert_weights_to_fp16", "(", "model", ")", "\n", "\n", "", "if", "jit", ":", "\n", "            ", "model", "=", "torch", ".", "jit", ".", "script", "(", "model", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model_and_transforms": [[127, 147], ["torch.device", "factory.create_model", "transform.image_transform", "transform.image_transform"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.transform.image_transform", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.transform.image_transform"], ["", "def", "create_model_and_transforms", "(", "\n", "model_name", ":", "str", ",", "\n", "pretrained", ":", "str", "=", "''", ",", "\n", "precision", ":", "str", "=", "'fp32'", ",", "\n", "device", ":", "torch", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ",", "\n", "jit", ":", "bool", "=", "False", ",", "\n", "force_quick_gelu", ":", "bool", "=", "False", ",", "\n", "pretrained_image", ":", "bool", "=", "False", ",", "\n", "pretrained_text", "=", "None", ",", "\n", "args", "=", "None", "\n", ")", ":", "\n", "    ", "model", "=", "create_model", "(", "\n", "model_name", ",", "pretrained", ",", "precision", ",", "device", ",", "jit", ",", "\n", "force_quick_gelu", "=", "force_quick_gelu", ",", "\n", "pretrained_image", "=", "pretrained_image", ",", "\n", "pretrained_text", "=", "pretrained_text", ",", "\n", "args", "=", "args", ")", "\n", "preprocess_train", "=", "image_transform", "(", "model", ".", "visual", ".", "image_size", ",", "is_train", "=", "True", ",", "augmentation", "=", "args", ".", "augmentation", ")", "\n", "preprocess_val", "=", "image_transform", "(", "model", ".", "visual", ".", "image_size", ",", "is_train", "=", "False", ")", "\n", "return", "model", ",", "preprocess_train", ",", "preprocess_val", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.list_models": [[149, 152], ["list", "_MODEL_CONFIGS.keys"], "function", ["None"], ["", "def", "list_models", "(", ")", ":", "\n", "    ", "\"\"\" enumerate available model architectures based on config files \"\"\"", "\n", "return", "list", "(", "_MODEL_CONFIGS", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.add_model_config": [[154, 160], ["_MODEL_CONFIG_PATHS.append", "factory._rescan_model_configs", "isinstance", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory._rescan_model_configs"], ["", "def", "add_model_config", "(", "path", ")", ":", "\n", "    ", "\"\"\" add model config path or file and update registry \"\"\"", "\n", "if", "not", "isinstance", "(", "path", ",", "Path", ")", ":", "\n", "        ", "path", "=", "Path", "(", "path", ")", "\n", "", "_MODEL_CONFIG_PATHS", ".", "append", "(", "path", ")", "\n", "_rescan_model_configs", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.Bottleneck.__init__": [[23, 50], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Sequential", "torch.nn.Sequential", "collections.OrderedDict", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# all conv layers have stride 1. an avgpool is performed after the second convolution when stride > 1", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "stride", ")", "if", "stride", ">", "1", "else", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu3", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "\n", "self", ".", "downsample", "=", "None", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "if", "stride", ">", "1", "or", "inplanes", "!=", "planes", "*", "Bottleneck", ".", "expansion", ":", "\n", "# downsampling layer is prepended with an avgpool, and the subsequent convolution has stride 1", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"-1\"", ",", "nn", ".", "AvgPool2d", "(", "stride", ")", ")", ",", "\n", "(", "\"0\"", ",", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", "*", "self", ".", "expansion", ",", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ")", ",", "\n", "(", "\"1\"", ",", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", ")", "\n", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.Bottleneck.forward": [[52, 66], ["model.Bottleneck.relu1", "model.Bottleneck.relu2", "model.Bottleneck.avgpool", "model.Bottleneck.bn3", "model.Bottleneck.relu3", "model.Bottleneck.bn1", "model.Bottleneck.bn2", "model.Bottleneck.conv3", "model.Bottleneck.downsample", "model.Bottleneck.conv1", "model.Bottleneck.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "self", ".", "avgpool", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu3", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.AttentionPool2d.__init__": [[69, 77], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "spacial_dim", ":", "int", ",", "embed_dim", ":", "int", ",", "num_heads", ":", "int", ",", "output_dim", ":", "int", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "spacial_dim", "**", "2", "+", "1", ",", "embed_dim", ")", "/", "embed_dim", "**", "0.5", ")", "\n", "self", ".", "k_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "q_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "v_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "c_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "output_dim", "or", "embed_dim", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.AttentionPool2d.forward": [[78, 103], ["torch.cat.reshape().permute", "torch.cat.reshape().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "model.AttentionPool2d.positional_embedding[].to", "torch.cat.reshape", "torch.cat.reshape", "torch.cat.mean", "torch.cat.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", "*", "x", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# NCHW -> (HW)NC", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", ",", "x", "]", ",", "dim", "=", "0", ")", "# (HW+1)NC", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", "[", ":", ",", "None", ",", ":", "]", ".", "to", "(", "x", ".", "dtype", ")", "# (HW+1)NC", "\n", "x", ",", "_", "=", "F", ".", "multi_head_attention_forward", "(", "\n", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "\n", "embed_dim_to_check", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj", ".", "weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj", ".", "weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj", ".", "weight", ",", "\n", "in_proj_weight", "=", "None", ",", "\n", "in_proj_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "q_proj", ".", "bias", ",", "self", ".", "k_proj", ".", "bias", ",", "self", ".", "v_proj", ".", "bias", "]", ")", ",", "\n", "bias_k", "=", "None", ",", "\n", "bias_v", "=", "None", ",", "\n", "add_zero_attn", "=", "False", ",", "\n", "dropout_p", "=", "0", ",", "\n", "out_proj_weight", "=", "self", ".", "c_proj", ".", "weight", ",", "\n", "out_proj_bias", "=", "self", ".", "c_proj", ".", "bias", ",", "\n", "use_separate_proj_weight", "=", "True", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "need_weights", "=", "False", "\n", ")", "\n", "\n", "return", "x", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.__init__": [[113, 141], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.AvgPool2d", "torch.nn.AvgPool2d", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.ModifiedResNet._make_layer", "model.AttentionPool2d", "model.ModifiedResNet.init_parameters"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet._make_layer", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.init_parameters"], ["def", "__init__", "(", "self", ",", "layers", ",", "output_dim", ",", "heads", ",", "image_size", "=", "224", ",", "width", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "image_size", "=", "image_size", "\n", "\n", "# the 3-layer stem", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", "//", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "width", "//", "2", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "width", "//", "2", ",", "width", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "width", ")", "\n", "self", ".", "relu3", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "2", ")", "\n", "\n", "# residual layers", "\n", "self", ".", "_inplanes", "=", "width", "# this is a *mutable* variable used during construction", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "width", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "width", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "width", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "width", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "\n", "embed_dim", "=", "width", "*", "32", "# the ResNet feature dimension", "\n", "self", ".", "attnpool", "=", "AttentionPool2d", "(", "image_size", "//", "32", ",", "embed_dim", ",", "heads", ",", "output_dim", ")", "\n", "\n", "self", ".", "init_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet._make_layer": [[142, 150], ["range", "torch.nn.Sequential", "torch.nn.Sequential", "model.Bottleneck", "layers.append", "model.Bottleneck"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "layers", "=", "[", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ",", "stride", ")", "]", "\n", "\n", "self", ".", "_inplanes", "=", "planes", "*", "Bottleneck", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "Bottleneck", "(", "self", ".", "_inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.init_parameters": [[151, 163], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "resnet_block.named_parameters", "name.endswith", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["None"], ["", "def", "init_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "attnpool", "is", "not", "None", ":", "\n", "            ", "std", "=", "self", ".", "attnpool", ".", "c_proj", ".", "in_features", "**", "-", "0.5", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "q_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "k_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "v_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "attnpool", ".", "c_proj", ".", "weight", ",", "std", "=", "std", ")", "\n", "\n", "", "for", "resnet_block", "in", "[", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", "]", ":", "\n", "            ", "for", "name", ",", "param", "in", "resnet_block", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "name", ".", "endswith", "(", "\"bn3.weight\"", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "zeros_", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.lock": [[164, 170], ["model.ModifiedResNet.parameters", "utils.freeze_batch_norm_2d"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.utils.freeze_batch_norm_2d"], ["", "", "", "", "def", "lock", "(", "self", ",", "unlocked_groups", "=", "0", ",", "freeze_bn_stats", "=", "False", ")", ":", "\n", "        ", "assert", "unlocked_groups", "==", "0", ",", "'partial locking not currently supported for this model'", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "if", "freeze_bn_stats", ":", "\n", "            ", "freeze_batch_norm_2d", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.set_grad_checkpointing": [[171, 175], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "# FIXME support for non-transformer", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.stem": [[176, 182], ["model.ModifiedResNet.relu1", "model.ModifiedResNet.relu2", "model.ModifiedResNet.relu3", "model.ModifiedResNet.avgpool", "model.ModifiedResNet.bn1", "model.ModifiedResNet.bn2", "model.ModifiedResNet.bn3", "model.ModifiedResNet.conv1", "model.ModifiedResNet.conv2", "model.ModifiedResNet.conv3"], "methods", ["None"], ["", "def", "stem", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "relu3", "(", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.forward": [[183, 192], ["model.ModifiedResNet.stem", "model.ModifiedResNet.layer1", "model.ModifiedResNet.layer2", "model.ModifiedResNet.layer3", "model.ModifiedResNet.layer4", "model.ModifiedResNet.attnpool"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ModifiedResNet.stem"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "stem", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "attnpool", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.LayerNorm.forward": [[197, 201], ["torch.layer_norm", "torch.layer_norm", "torch.layer_norm.to"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "orig_type", "=", "x", ".", "dtype", "\n", "x", "=", "F", ".", "layer_norm", "(", "x", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "self", ".", "eps", ")", "\n", "return", "x", ".", "to", "(", "orig_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.QuickGELU.forward": [[205, 207], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "1.702", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ResidualAttentionBlock.__init__": [[210, 222], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "model.LayerNorm", "int", "torch.nn.Sequential", "torch.nn.Sequential", "model.LayerNorm", "collections.OrderedDict", "torch.nn.Linear", "torch.nn.Linear", "act_layer", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "n_head", ":", "int", ",", "mlp_ratio", ":", "float", "=", "4.0", ",", "act_layer", ":", "Callable", "=", "nn", ".", "GELU", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "n_head", ")", "\n", "self", ".", "ln_1", "=", "LayerNorm", "(", "d_model", ")", "\n", "mlp_width", "=", "int", "(", "d_model", "*", "mlp_ratio", ")", "\n", "self", ".", "mlp", "=", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "\"c_fc\"", ",", "nn", ".", "Linear", "(", "d_model", ",", "mlp_width", ")", ")", ",", "\n", "(", "\"gelu\"", ",", "act_layer", "(", ")", ")", ",", "\n", "(", "\"c_proj\"", ",", "nn", ".", "Linear", "(", "mlp_width", ",", "d_model", ")", ")", "\n", "]", ")", ")", "\n", "self", ".", "ln_2", "=", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ResidualAttentionBlock.attention": [[223, 225], ["model.ResidualAttentionBlock.attn"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "attn", "(", "x", ",", "x", ",", "x", ",", "need_weights", "=", "False", ",", "attn_mask", "=", "attn_mask", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ResidualAttentionBlock.forward": [[226, 230], ["model.ResidualAttentionBlock.attention", "model.ResidualAttentionBlock.mlp", "model.ResidualAttentionBlock.ln_1", "model.ResidualAttentionBlock.ln_2"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.ResidualAttentionBlock.attention"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "x", "=", "x", "+", "self", ".", "attention", "(", "self", ".", "ln_1", "(", "x", ")", ",", "attn_mask", "=", "attn_mask", ")", "\n", "x", "=", "x", "+", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.Transformer.__init__": [[233, 242], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "model.ResidualAttentionBlock", "range"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["    ", "def", "__init__", "(", "self", ",", "width", ":", "int", ",", "layers", ":", "int", ",", "heads", ":", "int", ",", "mlp_ratio", ":", "float", "=", "4.0", ",", "act_layer", ":", "Callable", "=", "nn", ".", "GELU", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "grad_checkpointing", "=", "False", "\n", "\n", "self", ".", "resblocks", "=", "nn", ".", "ModuleList", "(", "[", "\n", "ResidualAttentionBlock", "(", "width", ",", "heads", ",", "mlp_ratio", ",", "act_layer", "=", "act_layer", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.Transformer.forward": [[244, 251], ["torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "r", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "attn_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "for", "r", "in", "self", ".", "resblocks", ":", "\n", "            ", "if", "self", ".", "grad_checkpointing", "and", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ":", "\n", "                ", "x", "=", "checkpoint", "(", "r", ",", "x", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "r", "(", "x", ",", "attn_mask", "=", "attn_mask", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.VisualTransformer.__init__": [[254, 271], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "model.LayerNorm", "model.Transformer", "model.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "image_size", ":", "int", ",", "patch_size", ":", "int", ",", "width", ":", "int", ",", "layers", ":", "int", ",", "heads", ":", "int", ",", "mlp_ratio", ":", "float", ",", "\n", "output_dim", ":", "int", ",", "act_layer", ":", "Callable", "=", "nn", ".", "GELU", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "image_size", "=", "image_size", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "width", ",", "kernel_size", "=", "patch_size", ",", "stride", "=", "patch_size", ",", "bias", "=", "False", ")", "\n", "\n", "scale", "=", "width", "**", "-", "0.5", "\n", "self", ".", "class_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ")", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "(", "image_size", "//", "patch_size", ")", "**", "2", "+", "1", ",", "width", ")", ")", "\n", "self", ".", "ln_pre", "=", "LayerNorm", "(", "width", ")", "\n", "\n", "self", ".", "transformer", "=", "Transformer", "(", "width", ",", "layers", ",", "heads", ",", "mlp_ratio", ",", "act_layer", "=", "act_layer", ")", "\n", "\n", "self", ".", "ln_post", "=", "LayerNorm", "(", "width", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Parameter", "(", "scale", "*", "torch", ".", "randn", "(", "width", ",", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.VisualTransformer.lock": [[272, 276], ["model.VisualTransformer.parameters"], "methods", ["None"], ["", "def", "lock", "(", "self", ",", "unlocked_groups", "=", "0", ",", "freeze_bn_stats", "=", "False", ")", ":", "\n", "        ", "assert", "unlocked_groups", "==", "0", ",", "'partial locking not currently supported for this model'", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.VisualTransformer.set_grad_checkpointing": [[277, 280], ["None"], "methods", ["None"], ["", "", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.VisualTransformer.forward": [[281, 301], ["model.VisualTransformer.conv1", "model.VisualTransformer.reshape", "model.VisualTransformer.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.VisualTransformer.ln_pre", "model.VisualTransformer.permute", "model.VisualTransformer.transformer", "model.VisualTransformer.permute", "model.VisualTransformer.ln_post", "model.VisualTransformer.positional_embedding.to", "model.VisualTransformer.class_embedding.to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "# shape = [*, width, grid, grid]", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "# shape = [*, width, grid ** 2]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# shape = [*, grid ** 2, width]", "\n", "x", "=", "torch", ".", "cat", "(", "\n", "[", "self", ".", "class_embedding", ".", "to", "(", "x", ".", "dtype", ")", "+", "torch", ".", "zeros", "(", "x", ".", "shape", "[", "0", "]", ",", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ",", "\n", "x", "]", ",", "dim", "=", "1", ")", "# shape = [*, grid ** 2 + 1, width]", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", ".", "to", "(", "x", ".", "dtype", ")", "\n", "x", "=", "self", ".", "ln_pre", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "\n", "x", "=", "self", ".", "ln_post", "(", "x", "[", ":", ",", "0", ",", ":", "]", ")", "\n", "\n", "if", "self", ".", "proj", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", "@", "self", ".", "proj", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.__init__": [[327, 439], ["torch.nn.Module.__init__", "isinstance", "isinstance", "torch.nn.Parameter", "torch.nn.Parameter", "model.CLIP.init_parameters", "model.CLIPVisionCfg", "model.CLIPTextCfg", "timm_model.TimmModel", "isinstance", "model.Transformer", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.Parameter", "model.LayerNorm", "torch.nn.Parameter", "torch.nn.Parameter", "model.CLIP.register_buffer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.nn.Parameter", "torch.nn.Parameter", "copy.deepcopy", "model.ModifiedResNet", "model.VisualTransformer", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "model.CLIP.build_attention_mask", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "torch.nn.Sequential", "torch.nn.Sequential", "range", "layers.append", "torch.nn.Sequential", "torch.nn.Sequential", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "numpy.log", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "layers.extend", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.init_parameters", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.build_attention_mask"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ":", "int", ",", "\n", "vision_cfg", ":", "CLIPVisionCfg", ",", "\n", "text_cfg", ":", "CLIPTextCfg", ",", "\n", "quick_gelu", ":", "bool", "=", "False", ",", "\n", "pretrained_text", "=", "None", ",", "\n", "args", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "vision_cfg", ",", "dict", ")", ":", "\n", "            ", "vision_cfg", "=", "CLIPVisionCfg", "(", "**", "vision_cfg", ")", "\n", "", "if", "isinstance", "(", "text_cfg", ",", "dict", ")", ":", "\n", "            ", "text_cfg", "=", "CLIPTextCfg", "(", "**", "text_cfg", ")", "\n", "\n", "", "self", ".", "context_length", "=", "text_cfg", ".", "context_length", "\n", "\n", "# OpenAI models are pretrained w/ QuickGELU but native nn.GELU is both faster and more", "\n", "# memory efficient in recent PyTorch releases (>= 1.10).", "\n", "# NOTE: timm models always use native GELU regardless of quick_gelu flag.", "\n", "quick_gelu", "=", "True", "\n", "act_layer", "=", "QuickGELU", "if", "quick_gelu", "else", "nn", ".", "GELU", "\n", "\n", "if", "vision_cfg", ".", "timm_model_name", ":", "\n", "            ", "self", ".", "visual", "=", "TimmModel", "(", "\n", "vision_cfg", ".", "timm_model_name", ",", "\n", "pretrained", "=", "vision_cfg", ".", "timm_model_pretrained", ",", "\n", "pool", "=", "vision_cfg", ".", "timm_pool", ",", "\n", "proj", "=", "vision_cfg", ".", "timm_proj", ",", "\n", "embed_dim", "=", "embed_dim", ",", "\n", "image_size", "=", "vision_cfg", ".", "image_size", "\n", ")", "\n", "act_layer", "=", "nn", ".", "GELU", "# so that text transformer doesn't use QuickGELU w/ timm models", "\n", "", "elif", "isinstance", "(", "vision_cfg", ".", "layers", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "vision_heads", "=", "vision_cfg", ".", "width", "*", "32", "//", "vision_cfg", ".", "head_width", "\n", "self", ".", "visual", "=", "ModifiedResNet", "(", "\n", "layers", "=", "vision_cfg", ".", "layers", ",", "\n", "output_dim", "=", "embed_dim", ",", "\n", "heads", "=", "vision_heads", ",", "\n", "image_size", "=", "vision_cfg", ".", "image_size", ",", "\n", "width", "=", "vision_cfg", ".", "width", "\n", ")", "\n", "", "else", ":", "\n", "            ", "vision_heads", "=", "vision_cfg", ".", "width", "//", "vision_cfg", ".", "head_width", "\n", "self", ".", "visual", "=", "VisualTransformer", "(", "\n", "image_size", "=", "vision_cfg", ".", "image_size", ",", "\n", "patch_size", "=", "vision_cfg", ".", "patch_size", ",", "\n", "width", "=", "vision_cfg", ".", "width", ",", "\n", "layers", "=", "vision_cfg", ".", "layers", ",", "\n", "heads", "=", "vision_heads", ",", "\n", "mlp_ratio", "=", "vision_cfg", ".", "mlp_ratio", ",", "\n", "output_dim", "=", "embed_dim", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", ")", "\n", "\n", "", "self", ".", "pretrained_text", "=", "pretrained_text", "\n", "if", "self", ".", "pretrained_text", "is", "None", ":", "\n", "            ", "self", ".", "transformer", "=", "Transformer", "(", "\n", "width", "=", "text_cfg", ".", "width", ",", "\n", "layers", "=", "text_cfg", ".", "layers", ",", "\n", "heads", "=", "text_cfg", ".", "heads", ",", "\n", "act_layer", "=", "act_layer", ",", "\n", ")", "\n", "\n", "self", ".", "vocab_size", "=", "text_cfg", ".", "vocab_size", "\n", "self", ".", "token_embedding", "=", "nn", ".", "Embedding", "(", "text_cfg", ".", "vocab_size", ",", "text_cfg", ".", "width", ")", "\n", "self", ".", "positional_embedding", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "self", ".", "context_length", ",", "text_cfg", ".", "width", ")", ")", "\n", "self", ".", "ln_final", "=", "LayerNorm", "(", "text_cfg", ".", "width", ")", "\n", "\n", "self", ".", "text_projection", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "text_cfg", ".", "width", ",", "embed_dim", ")", ")", "\n", "self", ".", "register_buffer", "(", "'attn_mask'", ",", "self", ".", "build_attention_mask", "(", ")", ",", "persistent", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "text_projection", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "args", ".", "pretrained_text_feature_dim", ",", "embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "text_projection", ",", "std", "=", "0.01", ")", "\n", "self", ".", "text_projection", ".", "data", "[", ":", ",", ":", "args", ".", "pretrained_text_feature_dim", "]", "=", "torch", ".", "eye", "(", "args", ".", "pretrained_text_feature_dim", ")", "\n", "# TODO: add support for args.pretrained_text_feature_dim > embed_dim", "\n", "\n", "", "self", ".", "logit_scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "\n", "\n", "if", "args", "is", "not", "None", "and", "args", ".", "add_projection_head", ":", "\n", "            ", "self", ".", "add_projection_head", "=", "True", "\n", "self", ".", "logit_scale_proto", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "]", ")", "*", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "\n", "# self.image_projection_head = nn.Sequential(", "\n", "#     nn.Linear(embed_dim, 2048),", "\n", "#     nn.BatchNorm1d(2048),", "\n", "#     nn.ReLU(inplace=True),", "\n", "#     nn.Linear(2048, args.projection_dim),", "\n", "# )", "\n", "# self.text_projection_head = nn.Sequential(", "\n", "#     nn.Linear(embed_dim, 2048),", "\n", "#     nn.BatchNorm1d(2048),", "\n", "#     nn.ReLU(inplace=True),", "\n", "#     nn.Linear(2048, args.projection_dim),", "\n", "# )", "\n", "if", "args", ".", "projection_n_layers", "==", "0", ":", "\n", "                ", "self", ".", "text_projection_head", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "embed_dim", ",", "args", ".", "projection_dim", ")", ")", "\n", "", "else", ":", "\n", "                ", "layers", "=", "[", "\n", "nn", ".", "Linear", "(", "embed_dim", ",", "args", ".", "projection_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "args", ".", "projection_hidden_dim", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "projection_n_layers", "-", "1", ")", ":", "\n", "                    ", "layers", ".", "extend", "(", "[", "\n", "nn", ".", "Linear", "(", "args", ".", "projection_hidden_dim", ",", "args", ".", "projection_hidden_dim", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "args", ".", "projection_hidden_dim", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "args", ".", "projection_hidden_dim", ",", "args", ".", "projection_dim", ")", ")", "\n", "self", ".", "text_projection_head", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "", "self", ".", "image_projection_head", "=", "copy", ".", "deepcopy", "(", "self", ".", "text_projection_head", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_projection_head", "=", "False", "\n", "\n", "", "self", ".", "init_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.init_parameters": [[440, 460], ["torch.nn.init.constant_", "torch.nn.init.constant_", "hasattr", "numpy.log", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "model.CLIP.visual.init_parameters", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.init_parameters"], ["", "def", "init_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "logit_scale", ",", "np", ".", "log", "(", "1", "/", "0.07", ")", ")", "\n", "\n", "if", "self", ".", "pretrained_text", "is", "None", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "token_embedding", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "positional_embedding", ",", "std", "=", "0.01", ")", "\n", "proj_std", "=", "(", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "*", "(", "(", "2", "*", "self", ".", "transformer", ".", "layers", ")", "**", "-", "0.5", ")", "\n", "attn_std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", "\n", "fc_std", "=", "(", "2", "*", "self", ".", "transformer", ".", "width", ")", "**", "-", "0.5", "\n", "for", "block", "in", "self", ".", "transformer", ".", "resblocks", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "in_proj_weight", ",", "std", "=", "attn_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "attn", ".", "out_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_fc", ".", "weight", ",", "std", "=", "fc_std", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "block", ".", "mlp", ".", "c_proj", ".", "weight", ",", "std", "=", "proj_std", ")", "\n", "\n", "", "if", "self", ".", "text_projection", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "text_projection", ",", "std", "=", "self", ".", "transformer", ".", "width", "**", "-", "0.5", ")", "\n", "\n", "", "", "if", "hasattr", "(", "self", ".", "visual", ",", "'init_parameters'", ")", ":", "\n", "            ", "self", ".", "visual", ".", "init_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.build_attention_mask": [[461, 468], ["torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.fill_", "torch.empty.fill_", "torch.empty.triu_", "torch.empty.triu_", "float"], "methods", ["None"], ["", "", "def", "build_attention_mask", "(", "self", ")", ":", "\n", "# lazily create causal attention mask, with full attention between the vision tokens", "\n", "# pytorch uses additive attention mask; fill with -inf", "\n", "        ", "mask", "=", "torch", ".", "empty", "(", "self", ".", "context_length", ",", "self", ".", "context_length", ")", "\n", "mask", ".", "fill_", "(", "float", "(", "\"-inf\"", ")", ")", "\n", "mask", ".", "triu_", "(", "1", ")", "# zero out the lower diagonal", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.lock_image_tower": [[469, 472], ["model.CLIP.visual.lock"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.VisualTransformer.lock"], ["", "def", "lock_image_tower", "(", "self", ",", "unlocked_groups", "=", "0", ",", "freeze_bn_stats", "=", "False", ")", ":", "\n", "# lock image tower as per LiT - https://arxiv.org/abs/2111.07991", "\n", "        ", "self", ".", "visual", ".", "lock", "(", "unlocked_groups", "=", "unlocked_groups", ",", "freeze_bn_stats", "=", "freeze_bn_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.set_grad_checkpointing": [[473, 477], ["model.CLIP.visual.set_grad_checkpointing"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.set_grad_checkpointing"], ["", "@", "torch", ".", "jit", ".", "ignore", "\n", "def", "set_grad_checkpointing", "(", "self", ",", "enable", "=", "True", ")", ":", "\n", "        ", "self", ".", "visual", ".", "set_grad_checkpointing", "(", "enable", ")", "\n", "self", ".", "transformer", ".", "grad_checkpointing", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image": [[478, 480], ["model.CLIP.visual"], "methods", ["None"], ["", "def", "encode_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "self", ".", "visual", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text": [[481, 497], ["model.CLIP.encode_text_pretrained", "model.CLIP.token_embedding", "model.CLIP.permute", "model.CLIP.transformer", "model.CLIP.permute", "model.CLIP.ln_final", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "text.argmax"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text_pretrained"], ["", "def", "encode_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "pretrained_text", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "encode_text_pretrained", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "token_embedding", "(", "text", ")", "# [batch_size, n_ctx, d_model]", "\n", "\n", "x", "=", "x", "+", "self", ".", "positional_embedding", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# NLD -> LND", "\n", "x", "=", "self", ".", "transformer", "(", "x", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "x", "=", "x", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "# LND -> NLD", "\n", "x", "=", "self", ".", "ln_final", "(", "x", ")", "\n", "\n", "# x.shape = [batch_size, n_ctx, transformer.width]", "\n", "# take features from the eot embedding (eot_token is the highest number in each sequence)", "\n", "x", "=", "x", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ",", "text", ".", "argmax", "(", "dim", "=", "-", "1", ")", "]", "@", "self", ".", "text_projection", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text_pretrained": [[498, 502], ["last_hidden_states.mean", "model.CLIP.pretrained_text"], "methods", ["None"], ["", "", "def", "encode_text_pretrained", "(", "self", ",", "text", ")", ":", "\n", "        ", "last_hidden_states", "=", "self", ".", "pretrained_text", "(", "text", ")", "[", "0", "]", "# [batch_size, n_ctx, pretrained_text_feature_dim]", "\n", "text_feature", "=", "last_hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "# pooling [batch_size, pretrained_text_feature_dim]", "\n", "return", "text_feature", "@", "self", ".", "text_projection", "# [batch_size, embed_dim]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.forward": [[504, 519], ["model.CLIP.encode_image", "torch.normalize", "torch.normalize", "model.CLIP.encode_text", "torch.normalize", "torch.normalize", "model.CLIP.encode_text", "model.CLIP.forward_projection", "model.CLIP.logit_scale.exp", "model.CLIP.encode_image"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.forward_projection", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image"], ["", "def", "forward", "(", "self", ",", "image", ",", "text", ")", ":", "\n", "        ", "if", "image", "is", "None", ":", "\n", "            ", "return", "self", ".", "encode_text", "(", "text", ")", "\n", "", "elif", "text", "is", "None", ":", "\n", "            ", "return", "self", ".", "encode_image", "(", "image", ")", "\n", "", "if", "self", ".", "add_projection_head", ":", "\n", "            ", "return", "self", ".", "forward_projection", "(", "image", ",", "text", ")", "\n", "\n", "", "image_features", "=", "self", ".", "encode_image", "(", "image", ")", "\n", "image_features", "=", "F", ".", "normalize", "(", "image_features", ",", "dim", "=", "-", "1", ")", "\n", "\n", "text_features", "=", "self", ".", "encode_text", "(", "text", ")", "\n", "text_features", "=", "F", ".", "normalize", "(", "text_features", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "image_features", ",", "text_features", ",", "self", ".", "logit_scale", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.forward_projection": [[520, 532], ["model.CLIP.encode_image", "model.CLIP.image_projection_head", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "model.CLIP.encode_text", "model.CLIP.text_projection_head", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "model.CLIP.logit_scale.exp", "model.CLIP.logit_scale_proto.exp"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text"], ["", "def", "forward_projection", "(", "self", ",", "image", ",", "text", ")", ":", "\n", "        ", "image_features", "=", "self", ".", "encode_image", "(", "image", ")", "\n", "image_features_projected", "=", "self", ".", "image_projection_head", "(", "image_features", ")", "\n", "image_features", "=", "F", ".", "normalize", "(", "image_features", ",", "dim", "=", "-", "1", ")", "\n", "image_features_projected", "=", "F", ".", "normalize", "(", "image_features_projected", ",", "dim", "=", "-", "1", ")", "\n", "\n", "text_features", "=", "self", ".", "encode_text", "(", "text", ")", "\n", "text_features_projected", "=", "self", ".", "text_projection_head", "(", "text_features", ")", "\n", "text_features", "=", "F", ".", "normalize", "(", "text_features", ",", "dim", "=", "-", "1", ")", "\n", "text_features_projected", "=", "F", ".", "normalize", "(", "text_features_projected", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "image_features", ",", "text_features", ",", "image_features_projected", ",", "text_features_projected", ",", "self", ".", "logit_scale", ".", "exp", "(", ")", ",", "self", ".", "logit_scale_proto", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.convert_weights_to_fp16": [[534, 556], ["model.apply", "isinstance", "isinstance", "l.weight.data.half", "hasattr", "l.bias.data.half", "getattr", "getattr", "getattr.data.half", "getattr.data.half"], "function", ["None"], ["", "", "def", "convert_weights_to_fp16", "(", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Convert applicable model parameters to fp16\"\"\"", "\n", "\n", "def", "_convert_weights_to_fp16", "(", "l", ")", ":", "\n", "        ", "if", "isinstance", "(", "l", ",", "(", "nn", ".", "Conv1d", ",", "nn", ".", "Conv2d", ",", "nn", ".", "Linear", ")", ")", ":", "\n", "            ", "l", ".", "weight", ".", "data", "=", "l", ".", "weight", ".", "data", ".", "half", "(", ")", "\n", "if", "l", ".", "bias", "is", "not", "None", ":", "\n", "                ", "l", ".", "bias", ".", "data", "=", "l", ".", "bias", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "if", "isinstance", "(", "l", ",", "nn", ".", "MultiheadAttention", ")", ":", "\n", "            ", "for", "attr", "in", "[", "*", "[", "f\"{s}_proj_weight\"", "for", "s", "in", "[", "\"in\"", ",", "\"q\"", ",", "\"k\"", ",", "\"v\"", "]", "]", ",", "\"in_proj_bias\"", ",", "\"bias_k\"", ",", "\"bias_v\"", "]", ":", "\n", "                ", "tensor", "=", "getattr", "(", "l", ",", "attr", ")", "\n", "if", "tensor", "is", "not", "None", ":", "\n", "                    ", "tensor", ".", "data", "=", "tensor", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "", "for", "name", "in", "[", "\"text_projection\"", ",", "\"proj\"", "]", ":", "\n", "            ", "if", "hasattr", "(", "l", ",", "name", ")", ":", "\n", "                ", "attr", "=", "getattr", "(", "l", ",", "name", ")", "\n", "if", "attr", "is", "not", "None", ":", "\n", "                    ", "attr", ".", "data", "=", "attr", ".", "data", ".", "half", "(", ")", "\n", "\n", "", "", "", "", "model", ".", "apply", "(", "_convert_weights_to_fp16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.build_model_from_openai_state_dict": [[558, 611], ["len", "model.CLIPVisionCfg", "model.CLIPTextCfg", "model.CLIP", "model.convert_weights_to_fp16", "CLIP.load_state_dict", "CLIP.eval", "len", "round", "tuple", "round", "set", "state_dict.pop", "len", "set", "state_dict.keys", "k.split", "k.startswith", "k.startswith", "k.endswith", "k.split", "k.startswith"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.convert_weights_to_fp16", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict"], ["", "def", "build_model_from_openai_state_dict", "(", "state_dict", ":", "dict", ")", ":", "\n", "    ", "vit", "=", "\"visual.proj\"", "in", "state_dict", "\n", "\n", "if", "vit", ":", "\n", "        ", "vision_width", "=", "state_dict", "[", "\"visual.conv1.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "vision_layers", "=", "len", "(", "\n", "[", "k", "for", "k", "in", "state_dict", ".", "keys", "(", ")", "if", "k", ".", "startswith", "(", "\"visual.\"", ")", "and", "k", ".", "endswith", "(", "\".attn.in_proj_weight\"", ")", "]", ")", "\n", "vision_patch_size", "=", "state_dict", "[", "\"visual.conv1.weight\"", "]", ".", "shape", "[", "-", "1", "]", "\n", "grid_size", "=", "round", "(", "(", "state_dict", "[", "\"visual.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "**", "0.5", ")", "\n", "image_size", "=", "vision_patch_size", "*", "grid_size", "\n", "", "else", ":", "\n", "        ", "counts", ":", "list", "=", "[", "\n", "len", "(", "set", "(", "k", ".", "split", "(", "\".\"", ")", "[", "2", "]", "for", "k", "in", "state_dict", "if", "k", ".", "startswith", "(", "f\"visual.layer{b}\"", ")", ")", ")", "for", "b", "in", "[", "1", ",", "2", ",", "3", ",", "4", "]", "]", "\n", "vision_layers", "=", "tuple", "(", "counts", ")", "\n", "vision_width", "=", "state_dict", "[", "\"visual.layer1.0.conv1.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "output_width", "=", "round", "(", "(", "state_dict", "[", "\"visual.attnpool.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "**", "0.5", ")", "\n", "vision_patch_size", "=", "None", "\n", "assert", "output_width", "**", "2", "+", "1", "==", "state_dict", "[", "\"visual.attnpool.positional_embedding\"", "]", ".", "shape", "[", "0", "]", "\n", "image_size", "=", "output_width", "*", "32", "\n", "\n", "", "embed_dim", "=", "state_dict", "[", "\"text_projection\"", "]", ".", "shape", "[", "1", "]", "\n", "context_length", "=", "state_dict", "[", "\"positional_embedding\"", "]", ".", "shape", "[", "0", "]", "\n", "vocab_size", "=", "state_dict", "[", "\"token_embedding.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "transformer_width", "=", "state_dict", "[", "\"ln_final.weight\"", "]", ".", "shape", "[", "0", "]", "\n", "transformer_heads", "=", "transformer_width", "//", "64", "\n", "transformer_layers", "=", "len", "(", "set", "(", "k", ".", "split", "(", "\".\"", ")", "[", "2", "]", "for", "k", "in", "state_dict", "if", "k", ".", "startswith", "(", "f\"transformer.resblocks\"", ")", ")", ")", "\n", "\n", "vision_cfg", "=", "CLIPVisionCfg", "(", "\n", "layers", "=", "vision_layers", ",", "\n", "width", "=", "vision_width", ",", "\n", "patch_size", "=", "vision_patch_size", ",", "\n", "image_size", "=", "image_size", ",", "\n", ")", "\n", "text_cfg", "=", "CLIPTextCfg", "(", "\n", "context_length", "=", "context_length", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "width", "=", "transformer_width", ",", "\n", "heads", "=", "transformer_heads", ",", "\n", "layers", "=", "transformer_layers", "\n", ")", "\n", "model", "=", "CLIP", "(", "\n", "embed_dim", ",", "\n", "vision_cfg", "=", "vision_cfg", ",", "\n", "text_cfg", "=", "text_cfg", ",", "\n", "quick_gelu", "=", "True", ",", "# OpenAI models were trained with QuickGELU", "\n", ")", "\n", "\n", "for", "key", "in", "[", "\"input_resolution\"", ",", "\"context_length\"", ",", "\"vocab_size\"", "]", ":", "\n", "        ", "state_dict", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "convert_weights_to_fp16", "(", "model", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.trace_model": [[613, 627], ["torch.device", "torch.device", "torch.jit.trace_module.eval", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.jit.trace_module", "torch.jit.trace_module", "dict"], "function", ["None"], ["", "def", "trace_model", "(", "model", ",", "batch_size", "=", "256", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "image_size", "=", "model", ".", "visual", ".", "image_size", "\n", "example_images", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "3", ",", "image_size", ",", "image_size", ")", ",", "device", "=", "device", ")", "\n", "example_text", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "model", ".", "context_length", ")", ",", "dtype", "=", "torch", ".", "int", ",", "device", "=", "device", ")", "\n", "model", "=", "torch", ".", "jit", ".", "trace_module", "(", "\n", "model", ",", "\n", "inputs", "=", "dict", "(", "\n", "forward", "=", "(", "example_images", ",", "example_text", ")", ",", "\n", "encode_text", "=", "(", "example_text", ",", ")", ",", "\n", "encode_image", "=", "(", "example_images", ",", ")", "\n", ")", ")", "\n", "model", ".", "visual", ".", "image_size", "=", "image_size", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.transform._convert_to_rgb": [[9, 11], ["image.convert"], "function", ["None"], ["def", "_convert_to_rgb", "(", "image", ")", ":", "\n", "    ", "return", "image", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.transform.image_transform": [[13, 52], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.transforms.ColorJitter", "torchvision.transforms.transforms.GaussianBlur", "torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.transforms.RandomResizedCrop", "torchvision.transforms.transforms.RandomHorizontalFlip", "torchvision.transforms.transforms.RandomApply", "torchvision.transforms.transforms.RandomGrayscale", "torchvision.transforms.transforms.RandomApply", "torchvision.transforms.transforms.ToTensor"], "function", ["None"], ["", "def", "image_transform", "(", "\n", "image_size", ":", "int", ",", "\n", "is_train", ":", "bool", ",", "\n", "mean", "=", "(", "0.48145466", ",", "0.4578275", ",", "0.40821073", ")", ",", "\n", "std", "=", "(", "0.26862954", ",", "0.26130258", ",", "0.27577711", ")", ",", "\n", "augmentation", "=", "None", "\n", ")", ":", "\n", "    ", "normalize", "=", "Normalize", "(", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "if", "is_train", ":", "\n", "        ", "if", "not", "augmentation", ":", "\n", "            ", "return", "Compose", "(", "[", "\n", "RandomResizedCrop", "(", "image_size", ",", "scale", "=", "(", "0.9", ",", "1.0", ")", ",", "interpolation", "=", "InterpolationMode", ".", "BICUBIC", ")", ",", "\n", "_convert_to_rgb", ",", "\n", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n", "", "elif", "augmentation", "==", "'protoclip-light-augmentation'", ":", "\n", "            ", "s", "=", "1", "\n", "size", "=", "image_size", "\n", "color_jitter", "=", "transforms", ".", "ColorJitter", "(", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.8", "*", "s", ",", "0.2", "*", "s", ")", "\n", "gaussian_blur", "=", "transforms", ".", "GaussianBlur", "(", "kernel_size", "=", "21", ")", "\n", "return", "Compose", "(", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "size", "=", "size", ",", "scale", "=", "(", "0.5", ",", "1.0", ")", ",", "interpolation", "=", "InterpolationMode", ".", "BICUBIC", ")", ",", "\n", "_convert_to_rgb", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "color_jitter", "]", ",", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "gaussian_blur", "]", ",", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", "\n", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "return", "Compose", "(", "[", "\n", "Resize", "(", "image_size", ",", "interpolation", "=", "InterpolationMode", ".", "BICUBIC", ")", ",", "\n", "CenterCrop", "(", "image_size", ")", ",", "\n", "_convert_to_rgb", ",", "\n", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.openai.list_openai_models": [[18, 21], ["pretrained.list_pretrained_tag_models"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.list_pretrained_tag_models"], ["def", "list_openai_models", "(", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"Returns the names of available CLIP models\"\"\"", "\n", "return", "list_pretrained_tag_models", "(", "'openai'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.openai.load_openai_model": [[23, 127], ["pretrained.get_pretrained_url", "torch.jit.trace", "build_model_from_openai_state_dict().to.apply", "openai.load_openai_model.patch_device"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.pretrained.get_pretrained_url"], ["", "def", "load_openai_model", "(", "\n", "name", ":", "str", ",", "\n", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "jit", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Load a CLIP model\n\n    Parameters\n    ----------\n    name : str\n        A model name listed by `clip.available_models()`, or the path to a model checkpoint containing the state_dict\n    device : Union[str, torch.device]\n        The device to put the loaded model\n    jit : bool\n        Whether to load the optimized JIT model (default) or more hackable non-JIT model.\n\n    Returns\n    -------\n    model : torch.nn.Module\n        The CLIP model\n    preprocess : Callable[[PIL.Image], torch.Tensor]\n        A torchvision transform that converts a PIL image into a tensor that the returned model can take as its input\n    \"\"\"", "\n", "if", "get_pretrained_url", "(", "name", ",", "'openai'", ")", ":", "\n", "        ", "model_path", "=", "download_pretrained", "(", "get_pretrained_url", "(", "name", ",", "'openai'", ")", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "name", ")", ":", "\n", "        ", "model_path", "=", "name", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Model {name} not found; available models = {list_openai_models()}\"", ")", "\n", "\n", "", "try", ":", "\n", "# loading JIT archive", "\n", "        ", "model", "=", "torch", ".", "jit", ".", "load", "(", "model_path", ",", "map_location", "=", "device", "if", "jit", "else", "\"cpu\"", ")", ".", "eval", "(", ")", "\n", "state_dict", "=", "None", "\n", "", "except", "RuntimeError", ":", "\n", "# loading saved state dict", "\n", "        ", "if", "jit", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"File {model_path} is not a JIT archive. Loading as a state dict instead\"", ")", "\n", "jit", "=", "False", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "", "if", "not", "jit", ":", "\n", "        ", "try", ":", "\n", "            ", "model", "=", "build_model_from_openai_state_dict", "(", "state_dict", "or", "model", ".", "state_dict", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "sd", "=", "{", "k", "[", "7", ":", "]", ":", "v", "for", "k", ",", "v", "in", "state_dict", "[", "\"state_dict\"", "]", ".", "items", "(", ")", "}", "\n", "model", "=", "build_model_from_openai_state_dict", "(", "sd", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "if", "str", "(", "device", ")", "==", "\"cpu\"", ":", "\n", "            ", "model", ".", "float", "(", ")", "\n", "", "return", "model", "\n", "\n", "# patch the device names", "\n", "", "device_holder", "=", "torch", ".", "jit", ".", "trace", "(", "lambda", ":", "torch", ".", "ones", "(", "[", "]", ")", ".", "to", "(", "torch", ".", "device", "(", "device", ")", ")", ",", "example_inputs", "=", "[", "]", ")", "\n", "device_node", "=", "[", "n", "for", "n", "in", "device_holder", ".", "graph", ".", "findAllNodes", "(", "\"prim::Constant\"", ")", "if", "\"Device\"", "in", "repr", "(", "n", ")", "]", "[", "-", "1", "]", "\n", "\n", "def", "patch_device", "(", "module", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "graphs", "=", "[", "module", ".", "graph", "]", "if", "hasattr", "(", "module", ",", "\"graph\"", ")", "else", "[", "]", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "graphs", "=", "[", "]", "\n", "\n", "", "if", "hasattr", "(", "module", ",", "\"forward1\"", ")", ":", "\n", "            ", "graphs", ".", "append", "(", "module", ".", "forward1", ".", "graph", ")", "\n", "\n", "", "for", "graph", "in", "graphs", ":", "\n", "            ", "for", "node", "in", "graph", ".", "findAllNodes", "(", "\"prim::Constant\"", ")", ":", "\n", "                ", "if", "\"value\"", "in", "node", ".", "attributeNames", "(", ")", "and", "str", "(", "node", "[", "\"value\"", "]", ")", ".", "startswith", "(", "\"cuda\"", ")", ":", "\n", "                    ", "node", ".", "copyAttributes", "(", "device_node", ")", "\n", "\n", "", "", "", "", "model", ".", "apply", "(", "patch_device", ")", "\n", "patch_device", "(", "model", ".", "encode_image", ")", "\n", "patch_device", "(", "model", ".", "encode_text", ")", "\n", "\n", "# patch dtype to float32 on CPU", "\n", "if", "str", "(", "device", ")", "==", "\"cpu\"", ":", "\n", "        ", "float_holder", "=", "torch", ".", "jit", ".", "trace", "(", "lambda", ":", "torch", ".", "ones", "(", "[", "]", ")", ".", "float", "(", ")", ",", "example_inputs", "=", "[", "]", ")", "\n", "float_input", "=", "list", "(", "float_holder", ".", "graph", ".", "findNode", "(", "\"aten::to\"", ")", ".", "inputs", "(", ")", ")", "[", "1", "]", "\n", "float_node", "=", "float_input", ".", "node", "(", ")", "\n", "\n", "def", "patch_float", "(", "module", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "graphs", "=", "[", "module", ".", "graph", "]", "if", "hasattr", "(", "module", ",", "\"graph\"", ")", "else", "[", "]", "\n", "", "except", "RuntimeError", ":", "\n", "                ", "graphs", "=", "[", "]", "\n", "\n", "", "if", "hasattr", "(", "module", ",", "\"forward1\"", ")", ":", "\n", "                ", "graphs", ".", "append", "(", "module", ".", "forward1", ".", "graph", ")", "\n", "\n", "", "for", "graph", "in", "graphs", ":", "\n", "                ", "for", "node", "in", "graph", ".", "findAllNodes", "(", "\"aten::to\"", ")", ":", "\n", "                    ", "inputs", "=", "list", "(", "node", ".", "inputs", "(", ")", ")", "\n", "for", "i", "in", "[", "1", ",", "2", "]", ":", "# dtype can be the second or third argument to aten::to()", "\n", "                        ", "if", "inputs", "[", "i", "]", ".", "node", "(", ")", "[", "\"value\"", "]", "==", "5", ":", "\n", "                            ", "inputs", "[", "i", "]", ".", "node", "(", ")", ".", "copyAttributes", "(", "float_node", ")", "\n", "\n", "", "", "", "", "", "model", ".", "apply", "(", "patch_float", ")", "\n", "patch_float", "(", "model", ".", "encode_image", ")", "\n", "patch_float", "(", "model", ".", "encode_text", ")", "\n", "model", ".", "float", "(", ")", "\n", "\n", "# ensure image_size attr available at consistent location for both jit and non-jit", "\n", "", "model", ".", "visual", ".", "image_size", "=", "model", ".", "input_resolution", ".", "item", "(", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.utils.freeze_batch_norm_2d": [[5, 42], ["isinstance", "torchvision.ops.misc.FrozenBatchNorm2d", "module.named_children", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "utils.freeze_batch_norm_2d", "torchvision.ops.misc.FrozenBatchNorm2d.add_module", "module.weight.data.clone", "module.bias.data.clone"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.utils.freeze_batch_norm_2d"], ["def", "freeze_batch_norm_2d", "(", "module", ",", "module_match", "=", "{", "}", ",", "name", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    Converts all `BatchNorm2d` and `SyncBatchNorm` layers of provided module into `FrozenBatchNorm2d`. If `module` is\n    itself an instance of either `BatchNorm2d` or `SyncBatchNorm`, it is converted into `FrozenBatchNorm2d` and\n    returned. Otherwise, the module is walked recursively and submodules are converted in place.\n\n    Args:\n        module (torch.nn.Module): Any PyTorch module.\n        module_match (dict): Dictionary of full module names to freeze (all if empty)\n        name (str): Full module name (prefix)\n\n    Returns:\n        torch.nn.Module: Resulting module\n\n    Inspired by https://github.com/pytorch/pytorch/blob/a5895f85be0f10212791145bfedc0261d364f103/torch/nn/modules/batchnorm.py#L762\n    \"\"\"", "\n", "res", "=", "module", "\n", "is_match", "=", "True", "\n", "if", "module_match", ":", "\n", "        ", "is_match", "=", "name", "in", "module_match", "\n", "", "if", "is_match", "and", "isinstance", "(", "module", ",", "(", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm2d", ",", "nn", ".", "modules", ".", "batchnorm", ".", "SyncBatchNorm", ")", ")", ":", "\n", "        ", "res", "=", "FrozenBatchNorm2d", "(", "module", ".", "num_features", ")", "\n", "res", ".", "num_features", "=", "module", ".", "num_features", "\n", "res", ".", "affine", "=", "module", ".", "affine", "\n", "if", "module", ".", "affine", ":", "\n", "            ", "res", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "res", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "res", ".", "running_mean", ".", "data", "=", "module", ".", "running_mean", ".", "data", "\n", "res", ".", "running_var", ".", "data", "=", "module", ".", "running_var", ".", "data", "\n", "res", ".", "eps", "=", "module", ".", "eps", "\n", "", "else", ":", "\n", "        ", "for", "child_name", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "            ", "full_child_name", "=", "'.'", ".", "join", "(", "[", "name", ",", "child_name", "]", ")", "if", "name", "else", "child_name", "\n", "new_child", "=", "freeze_batch_norm_2d", "(", "child", ",", "module_match", ",", "full_child_name", ")", "\n", "if", "new_child", "is", "not", "child", ":", "\n", "                ", "res", ".", "add_module", "(", "child_name", ",", "new_child", ")", "\n", "", "", "", "return", "res", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.get_gathered_item": [[12, 23], ["torch.get_world_size", "torch.all_gather", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "range"], "function", ["None"], ["def", "get_gathered_item", "(", "item", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "distributed", ":", "\n", "        ", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "gathered_item", "=", "[", "torch", ".", "zeros_like", "(", "item", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "gathered_item", ",", "item", ")", "\n", "# all_item = torch.cat([item] + gathered_item[:rank] + gathered_item[rank + 1 :])", "\n", "all_item", "=", "torch", ".", "cat", "(", "gathered_item", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "all_item", "=", "item", "\n", "\n", "", "return", "all_item", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_global_master": [[25, 27], ["None"], "function", ["None"], ["", "def", "is_global_master", "(", "args", ")", ":", "\n", "    ", "return", "args", ".", "rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_local_master": [[29, 31], ["None"], "function", ["None"], ["", "def", "is_local_master", "(", "args", ")", ":", "\n", "    ", "return", "args", ".", "local_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master": [[33, 35], ["distributed.is_local_master", "distributed.is_global_master"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_local_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_global_master"], ["", "def", "is_master", "(", "args", ",", "local", "=", "False", ")", ":", "\n", "    ", "return", "is_local_master", "(", "args", ")", "if", "local", "else", "is_global_master", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_using_horovod": [[37, 46], ["all", "all"], "function", ["None"], ["", "def", "is_using_horovod", "(", ")", ":", "\n", "# NOTE w/ horovod run, OMPI vars should be set, but w/ SLURM PMI vars will be set", "\n", "# Differentiating between horovod and DDP use via SLURM may not be possible, so horovod arg still required...", "\n", "    ", "ompi_vars", "=", "[", "\"OMPI_COMM_WORLD_RANK\"", ",", "\"OMPI_COMM_WORLD_SIZE\"", "]", "\n", "pmi_vars", "=", "[", "\"PMI_RANK\"", ",", "\"PMI_SIZE\"", "]", "\n", "if", "all", "(", "[", "var", "in", "os", ".", "environ", "for", "var", "in", "ompi_vars", "]", ")", "or", "all", "(", "[", "var", "in", "os", ".", "environ", "for", "var", "in", "pmi_vars", "]", ")", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_using_distributed": [[48, 54], ["int", "int"], "function", ["None"], ["", "", "def", "is_using_distributed", "(", ")", ":", "\n", "    ", "if", "'WORLD_SIZE'", "in", "os", ".", "environ", ":", "\n", "        ", "return", "int", "(", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", ")", ">", "1", "\n", "", "if", "'SLURM_NTASKS'", "in", "os", ".", "environ", ":", "\n", "        ", "return", "int", "(", "os", ".", "environ", "[", "'SLURM_NTASKS'", "]", ")", ">", "1", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.world_info_from_env": [[56, 74], ["int", "int", "int"], "function", ["None"], ["", "def", "world_info_from_env", "(", ")", ":", "\n", "    ", "local_rank", "=", "0", "\n", "for", "v", "in", "(", "'SLURM_LOCALID'", ",", "'MPI_LOCALRANKID'", ",", "'OMPI_COMM_WORLD_LOCAL_RANK'", ",", "'LOCAL_RANK'", ")", ":", "\n", "        ", "if", "v", "in", "os", ".", "environ", ":", "\n", "            ", "local_rank", "=", "int", "(", "os", ".", "environ", "[", "v", "]", ")", "\n", "break", "\n", "", "", "global_rank", "=", "0", "\n", "for", "v", "in", "(", "'SLURM_PROCID'", ",", "'PMI_RANK'", ",", "'OMPI_COMM_WORLD_RANK'", ",", "'RANK'", ")", ":", "\n", "        ", "if", "v", "in", "os", ".", "environ", ":", "\n", "            ", "global_rank", "=", "int", "(", "os", ".", "environ", "[", "v", "]", ")", "\n", "break", "\n", "", "", "world_size", "=", "1", "\n", "for", "v", "in", "(", "'SLURM_NTASKS'", ",", "'PMI_SIZE'", ",", "'OMPI_COMM_WORLD_SIZE'", ",", "'WORLD_SIZE'", ")", ":", "\n", "        ", "if", "v", "in", "os", ".", "environ", ":", "\n", "            ", "world_size", "=", "int", "(", "os", ".", "environ", "[", "v", "]", ")", "\n", "break", "\n", "\n", "", "", "return", "local_rank", ",", "global_rank", ",", "world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.init_distributed_device": [[76, 128], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "hvd.init", "int", "hvd.rank", "hvd.size", "str", "str", "str", "distributed.is_using_distributed", "torch.cuda.set_device", "torch.cuda.set_device", "hvd.local_rank", "distributed.world_info_from_env", "str", "str", "str", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "distributed.world_info_from_env", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_rank", "torch.distributed.get_rank"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_using_distributed", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.world_info_from_env", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.world_info_from_env"], ["", "def", "init_distributed_device", "(", "args", ")", ":", "\n", "# Distributed training = training on more than one GPU.", "\n", "# Works in both single and multi-node scenarios.", "\n", "    ", "args", ".", "distributed", "=", "False", "\n", "args", ".", "world_size", "=", "1", "\n", "args", ".", "rank", "=", "0", "# global rank", "\n", "args", ".", "local_rank", "=", "0", "\n", "if", "args", ".", "horovod", ":", "\n", "        ", "assert", "hvd", "is", "not", "None", ",", "\"Horovod is not installed\"", "\n", "hvd", ".", "init", "(", ")", "\n", "args", ".", "local_rank", "=", "int", "(", "hvd", ".", "local_rank", "(", ")", ")", "\n", "args", ".", "rank", "=", "hvd", ".", "rank", "(", ")", "\n", "args", ".", "world_size", "=", "hvd", ".", "size", "(", ")", "\n", "args", ".", "distributed", "=", "True", "\n", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "args", ".", "rank", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "args", ".", "world_size", ")", "\n", "", "elif", "is_using_distributed", "(", ")", ":", "\n", "        ", "if", "'SLURM_PROCID'", "in", "os", ".", "environ", ":", "\n", "# DDP via SLURM", "\n", "            ", "args", ".", "local_rank", ",", "args", ".", "rank", ",", "args", ".", "world_size", "=", "world_info_from_env", "(", ")", "\n", "# SLURM var -> torch.distributed vars in case needed", "\n", "os", ".", "environ", "[", "'LOCAL_RANK'", "]", "=", "str", "(", "args", ".", "local_rank", ")", "\n", "os", ".", "environ", "[", "'RANK'", "]", "=", "str", "(", "args", ".", "rank", ")", "\n", "os", ".", "environ", "[", "'WORLD_SIZE'", "]", "=", "str", "(", "args", ".", "world_size", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "dist_backend", ",", "\n", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", ")", "\n", "", "else", ":", "\n", "# DDP via torchrun, torch.distributed.launch", "\n", "            ", "args", ".", "local_rank", ",", "_", ",", "_", "=", "world_info_from_env", "(", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "dist_backend", ",", "\n", "init_method", "=", "args", ".", "dist_url", ")", "\n", "args", ".", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "args", ".", "rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "", "args", ".", "distributed", "=", "True", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "if", "args", ".", "distributed", "and", "not", "args", ".", "no_set_device_rank", ":", "\n", "            ", "device", "=", "'cuda:%d'", "%", "args", ".", "local_rank", "\n", "", "else", ":", "\n", "            ", "device", "=", "'cuda:0'", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "'cpu'", "\n", "", "args", ".", "device", "=", "device", "\n", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "return", "device", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.main.random_seed": [[40, 45], ["torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "random.seed"], "function", ["None"], ["def", "random_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.main.main": [[47, 482], ["training.params.parse_args", "main.random_seed", "training.params.parse_args.model.replace", "training.distributed.world_info_from_env", "training.distributed.is_master", "training.logger.setup_logging", "training.distributed.init_distributed_device", "os.path.join", "os.path.join", "training.distributed.is_master", "open_clip.create_model_and_transforms", "training.distributed.is_master", "training.distributed.is_master", "training.data.get_data", "training.clustering.Clustering", "range", "os.path.join", "os.makedirs", "os.path.join", "os.path.exists", "os.path.join", "training.distributed.is_master", "main.copy_codebase", "logging.warning", "logging.info", "logging.info", "training.pretrained_transformers.get_pretrained_text_encoder_and_tokenizer", "logging.info", "logging.info", "open_clip.trace_model", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.lock_image_tower", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.set_grad_checkpointing", "logging.info", "os.path.join", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "training.distributed.is_master", "torch.optim.AdamW", "os.path.isfile", "torch.arange().share_memory_", "torch.arange().share_memory_", "training.distributed.is_master", "training.distributed.is_master", "len", "training.scheduler.protoclip_cosine_lr", "training.distributed.is_master", "training.distributed.is_master", "tensorboard.SummaryWriter", "training.distributed.is_master", "logging.debug", "wandb.init", "logging.debug", "training.evaluations.evaluation.evaluate", "training.distributed.is_master", "time.time", "training.train.train_one_epoch", "training.distributed.is_master", "training.evaluations.evaluation.evaluate", "training.distributed.is_master", "wandb.finish", "print", "os.path.join", "logging.info", "logging.info", "str", "open", "sorted", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "logging.info", "logging.info", "hvd.DistributedOptimizer", "hvd.broadcast_parameters", "hvd.broadcast_optimizer_state", "torch.cuda.amp.GradScaler", "torch.load", "torch.load", "logging.info", "logging.info", "logging.info", "logging.info", "training.params.parse_args.logs.lower", "wandb.watch", "logging.info", "time.time", "torch.from_numpy", "torch.from_numpy", "training.distributed.is_master", "logging.info", "logging.info", "profiling.items", "datetime.datetime.now().strftime", "os.makedirs", "vars", "getattr", "logging.info", "f.write", "bool", "visual", "exclude", "list", "visual", "list", "non_visual", "logging.info", "logging.info", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.state_dict", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.load_state_dict", "logging.info", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.load_state_dict", "logging.info", "torch.arange", "torch.arange", "logging.info", "logging.info", "vars", "numpy.random.choice", "logging.info", "training.clustering.Clustering.reset", "time.time", "training.train.feature_extraction_one_epoch", "training.distributed.is_master", "training.distributed.is_master", "training.clustering.Clustering.sync_prototypes", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.state_dict", "hvd.DistributedOptimizer.state_dict", "scaler.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.named_parameters", "exclude", "include", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.named_parameters", "exclude", "include", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.named_parameters", "[].startswith", "hvd.DistributedOptimizer.load_state_dict", "scaler.load_state_dict", "logging.info", "time.time", "training.clustering.Clustering.generate_labels", "training.clustering.Clustering.log_kmeans_error", "training.clustering.Clustering.log_kmeans_error", "logging.info", "time.time", "torch.barrier", "time.time", "time.time", "tensorboard.SummaryWriter.add_scalar", "wandb.log", "os.path.join", "os.path.join", "datetime.datetime.now", "time.time", "training.clustering.Clustering.show_samples", "training.clustering.Clustering.show_samples", "training.clustering.Clustering.show_tsne", "logging.info", "logging.warning", "training.clustering.Clustering.PBT", "training.clustering.Clustering.PBT", "logging.info", "sd.items", "time.time", "time.time", "numpy.load", "logging.info", "training.clustering.Clustering.generate_labels_from_external_teacher", "training.clustering.Clustering.PBT", "training.clustering.Clustering.PBT", "next", "len", "os.path.join", "os.path.join", "os.path.join", "time.time", "iter", "sd.items", "time.time"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.params.parse_args", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.main.random_seed", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.world_info_from_env", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.logger.setup_logging", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.init_distributed_device", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.create_model_and_transforms", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.get_data", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.main.copy_codebase", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.pretrained_transformers.get_pretrained_text_encoder_and_tokenizer", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.trace_model", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.lock_image_tower", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.set_grad_checkpointing", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.protoclip_cosine_lr", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.evaluation.evaluate", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.train_one_epoch", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.evaluation.evaluate", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.feature_extraction_one_epoch", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.sync_prototypes", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.factory.load_state_dict", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.generate_labels", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.log_kmeans_error", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.log_kmeans_error", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.show_samples", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.show_samples", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.show_tsne", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.PBT", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.PBT", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.generate_labels_from_external_teacher", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.PBT", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.PBT"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parse_args", "(", ")", "\n", "random_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# sanitize model name for filesystem / uri use, easier if we don't use / in name as a rule?", "\n", "args", ".", "model", "=", "args", ".", "model", ".", "replace", "(", "'/'", ",", "'-'", ")", "\n", "\n", "# get the name of the experiments", "\n", "if", "args", ".", "name", "is", "None", ":", "\n", "        ", "args", ".", "name", "=", "'-'", ".", "join", "(", "[", "\n", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y_%m_%d-%H_%M\"", ")", ",", "# disabled since it might make different process to have different names", "\n", "f\"model_{args.model}\"", ",", "\n", "f\"lr_{args.lr}\"", ",", "\n", "f\"b_{args.batch_size}\"", ",", "\n", "f\"j_{args.workers}\"", ",", "\n", "f\"p_{args.precision}\"", ",", "\n", "]", ")", "\n", "\n", "# discover initial world args early so we can log properly", "\n", "", "args", ".", "distributed", "=", "False", "\n", "args", ".", "local_rank", ",", "args", ".", "rank", ",", "args", ".", "world_size", "=", "world_info_from_env", "(", ")", "\n", "\n", "args", ".", "log_path", "=", "None", "\n", "if", "is_master", "(", "args", ",", "local", "=", "args", ".", "log_local", ")", ":", "\n", "        ", "log_base_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ")", "\n", "os", ".", "makedirs", "(", "log_base_path", ",", "exist_ok", "=", "True", ")", "\n", "log_filename", "=", "f'out-{args.rank}'", "if", "args", ".", "log_local", "else", "'out.log'", "\n", "args", ".", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_base_path", ",", "log_filename", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "log_path", ")", ":", "\n", "            ", "print", "(", "\n", "\"Error. Experiment already exists. Use --name {} to specify a new experiment.\"", "\n", ")", "\n", "return", "-", "1", "\n", "\n", "# Set logger", "\n", "", "", "args", ".", "log_level", "=", "logging", ".", "DEBUG", "if", "args", ".", "debug", "else", "logging", ".", "INFO", "\n", "setup_logging", "(", "args", ".", "log_path", ",", "args", ".", "log_level", ")", "\n", "\n", "# fully initialize distributed device environment", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "False", "\n", "device", "=", "init_distributed_device", "(", "args", ")", "\n", "\n", "args", ".", "wandb", "=", "'wandb'", "in", "args", ".", "report_to", "or", "'all'", "in", "args", ".", "report_to", "\n", "args", ".", "tensorboard", "=", "'tensorboard'", "in", "args", ".", "report_to", "or", "'all'", "in", "args", ".", "report_to", "\n", "\n", "# NCCL does not support CPU tensor communication. Set up manual multiprocessing communication.", "\n", "args", ".", "cache_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"cache\"", ")", "\n", "args", ".", "visualization_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"visualization\"", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "        ", "args", ".", "tensorboard_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"tensorboard\"", ")", "if", "args", ".", "tensorboard", "else", "''", "\n", "args", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"checkpoints\"", ")", "\n", "for", "dirname", "in", "[", "args", ".", "tensorboard_path", ",", "args", ".", "checkpoint_path", ",", "args", ".", "cache_path", ",", "args", ".", "visualization_path", "]", ":", "\n", "            ", "if", "dirname", ":", "\n", "                ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "", "", "", "else", ":", "\n", "        ", "args", ".", "tensorboard_path", "=", "''", "\n", "args", ".", "checkpoint_path", "=", "''", "\n", "\n", "", "if", "args", ".", "copy_codebase", "and", "is_master", "(", "args", ")", ":", "\n", "        ", "copy_codebase", "(", "args", ")", "\n", "\n", "", "assert", "args", ".", "precision", "in", "[", "'amp'", ",", "'fp16'", ",", "'fp32'", "]", "\n", "if", "args", ".", "precision", "==", "'fp16'", ":", "\n", "        ", "logging", ".", "warning", "(", "\n", "'It is recommended to use AMP mixed-precision instead of FP16. '", "\n", "'FP16 support needs further verification and tuning, especially for train.'", ")", "\n", "\n", "", "if", "args", ".", "horovod", ":", "\n", "        ", "logging", ".", "info", "(", "\n", "f'Running in horovod mode with multiple processes / nodes. Device: {args.device}.'", "\n", "f'Process (global: {args.rank}, local {args.local_rank}), total {args.world_size}.'", ")", "\n", "", "elif", "args", ".", "distributed", ":", "\n", "        ", "logging", ".", "info", "(", "\n", "f'Running in distributed mode with multiple processes. Device: {args.device}.'", "\n", "f'Process (global: {args.rank}, local {args.local_rank}), total {args.world_size}.'", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "f'Running with a single process. Device {args.device}.'", ")", "\n", "\n", "", "if", "args", ".", "pretrained_text", "is", "not", "None", ":", "\n", "        ", "logging", ".", "info", "(", "f'Loading pretrained text transformer structure: {args.pretrained_text}.'", ")", "\n", "pretrained_text_encoder", ",", "tokenizer", ",", "args", ".", "pretrained_text_feature_dim", "=", "get_pretrained_text_encoder_and_tokenizer", "(", "args", ".", "pretrained_text", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "f'Using CLIP default text transformer structure.'", ")", "\n", "pretrained_text_encoder", ",", "tokenizer", ",", "args", ".", "pretrained_text_feature_dim", "=", "None", ",", "None", ",", "None", "\n", "\n", "", "model", ",", "preprocess_train", ",", "preprocess_val", "=", "create_model_and_transforms", "(", "\n", "args", ".", "model", ",", "\n", "args", ".", "pretrained", ",", "\n", "precision", "=", "args", ".", "precision", ",", "\n", "device", "=", "device", ",", "\n", "jit", "=", "args", ".", "torchscript", ",", "\n", "force_quick_gelu", "=", "args", ".", "force_quick_gelu", ",", "\n", "pretrained_image", "=", "args", ".", "pretrained_image", ",", "\n", "pretrained_text", "=", "pretrained_text_encoder", ",", "\n", "args", "=", "args", "\n", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "        ", "logging", ".", "info", "(", "str", "(", "model", ")", ")", "\n", "", "if", "args", ".", "trace", ":", "\n", "        ", "model", "=", "trace_model", "(", "model", ",", "batch_size", "=", "args", ".", "batch_size", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "args", ".", "lock_image", ":", "\n", "# lock image tower as per LiT - https://arxiv.org/abs/2111.07991", "\n", "        ", "model", ".", "lock_image_tower", "(", "\n", "unlocked_groups", "=", "args", ".", "lock_image_unlocked_groups", ",", "\n", "freeze_bn_stats", "=", "args", ".", "lock_image_freeze_bn_stats", ")", "\n", "\n", "", "if", "args", ".", "grad_checkpointing", ":", "\n", "        ", "model", ".", "set_grad_checkpointing", "(", ")", "\n", "\n", "", "if", "is_master", "(", "args", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Params:\"", ")", "\n", "params_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"params.txt\"", ")", "\n", "with", "open", "(", "params_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "name", "in", "sorted", "(", "vars", "(", "args", ")", ")", ":", "\n", "                ", "val", "=", "getattr", "(", "args", ",", "name", ")", "\n", "logging", ".", "info", "(", "f\"  {name}: {val}\"", ")", "\n", "f", ".", "write", "(", "f\"{name}: {val}\\n\"", ")", "\n", "\n", "", "", "", "if", "args", ".", "distributed", "and", "not", "args", ".", "horovod", ":", "\n", "        ", "if", "args", ".", "use_bn_sync", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "model", ")", "\n", "", "ddp_args", "=", "{", "}", "\n", "if", "args", ".", "ddp_static_graph", ":", "\n", "# this doesn't exist in older PyTorch, arg only added if enabled", "\n", "            ", "ddp_args", "[", "'static_graph'", "]", "=", "True", "\n", "", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "device", "]", ",", "**", "ddp_args", ",", "\n", "find_unused_parameters", "=", "bool", "(", "pretrained_text_encoder", "is", "not", "None", ")", "# TODO: find which parameter is unused", "\n", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# create optimizer and scaler", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "", "optimizer", "=", "None", "\n", "scaler", "=", "None", "\n", "if", "args", ".", "train_data", ":", "\n", "        ", "assert", "not", "args", ".", "trace", ",", "'Cannot train with traced model'", "\n", "\n", "visual", "=", "lambda", "n", ",", "p", ":", "'visual'", "in", "n", "\n", "non_visual", "=", "lambda", "n", ",", "p", ":", "not", "visual", "(", "n", ",", "p", ")", "\n", "\n", "exclude", "=", "lambda", "n", ",", "p", ":", "p", ".", "ndim", "<", "2", "or", "\"bn\"", "in", "n", "or", "\"ln\"", "in", "n", "or", "\"bias\"", "in", "n", "or", "'logit_scale'", "in", "n", "or", "'projection_head'", "in", "n", "\n", "include", "=", "lambda", "n", ",", "p", ":", "not", "exclude", "(", "n", ",", "p", ")", "\n", "\n", "# named_parameters = list(model.named_parameters())", "\n", "# gain_or_bias_params = [p for n, p in named_parameters if exclude(n, p) and p.requires_grad]", "\n", "# rest_params = [p for n, p in named_parameters if include(n, p) and p.requires_grad]", "\n", "\n", "visual_named_parameters", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "if", "visual", "(", "n", ",", "p", ")", "]", "\n", "visual_gain_or_bias_params", "=", "[", "p", "for", "n", ",", "p", "in", "visual_named_parameters", "if", "exclude", "(", "n", ",", "p", ")", "and", "p", ".", "requires_grad", "]", "\n", "visual_rest_params", "=", "[", "p", "for", "n", ",", "p", "in", "visual_named_parameters", "if", "include", "(", "n", ",", "p", ")", "and", "p", ".", "requires_grad", "]", "\n", "\n", "non_visual_named_parameters", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "if", "non_visual", "(", "n", ",", "p", ")", "]", "\n", "non_visual_gain_or_bias_params", "=", "[", "p", "for", "n", ",", "p", "in", "non_visual_named_parameters", "if", "exclude", "(", "n", ",", "p", ")", "and", "p", ".", "requires_grad", "]", "\n", "non_visual_rest_params", "=", "[", "p", "for", "n", ",", "p", "in", "non_visual_named_parameters", "if", "include", "(", "n", ",", "p", ")", "and", "p", ".", "requires_grad", "]", "\n", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f\"visual_named_parameters:\"", ")", "\n", "for", "n", ",", "p", "in", "visual_named_parameters", ":", "\n", "                ", "logging", ".", "info", "(", "f'\\t{n}'", ")", "\n", "", "logging", ".", "info", "(", "f\"non_visual_named_parameters:\"", ")", "\n", "for", "n", ",", "p", "in", "non_visual_named_parameters", ":", "\n", "                ", "logging", ".", "info", "(", "f'\\t{n}'", ")", "\n", "\n", "\n", "", "", "optimizer", "=", "optim", ".", "AdamW", "(", "\n", "[", "\n", "{", "\"params\"", ":", "visual_gain_or_bias_params", ",", "\"weight_decay\"", ":", "0.", "}", ",", "\n", "{", "\"params\"", ":", "visual_rest_params", ",", "\"weight_decay\"", ":", "args", ".", "wd", "}", ",", "\n", "{", "\"params\"", ":", "non_visual_gain_or_bias_params", ",", "\"weight_decay\"", ":", "0.", "}", ",", "\n", "{", "\"params\"", ":", "non_visual_rest_params", ",", "\"weight_decay\"", ":", "args", ".", "wd", "}", ",", "\n", "]", ",", "\n", "lr", "=", "args", ".", "lr", ",", "\n", "betas", "=", "(", "args", ".", "beta1", ",", "args", ".", "beta2", ")", ",", "\n", "eps", "=", "args", ".", "eps", ",", "\n", ")", "\n", "if", "args", ".", "horovod", ":", "\n", "            ", "optimizer", "=", "hvd", ".", "DistributedOptimizer", "(", "optimizer", ",", "named_parameters", "=", "model", ".", "named_parameters", "(", ")", ")", "\n", "hvd", ".", "broadcast_parameters", "(", "model", ".", "state_dict", "(", ")", ",", "root_rank", "=", "0", ")", "\n", "hvd", ".", "broadcast_optimizer_state", "(", "optimizer", ",", "root_rank", "=", "0", ")", "\n", "\n", "", "scaler", "=", "GradScaler", "(", ")", "if", "args", ".", "precision", "==", "\"amp\"", "else", "None", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# optionally resume from a checkpoint", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "", "start_epoch", "=", "0", "\n", "if", "args", ".", "resume", "is", "not", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ",", "map_location", "=", "device", ")", "\n", "if", "'epoch'", "in", "checkpoint", ":", "\n", "# resuming a train checkpoint w/ epoch and optimizer state", "\n", "                ", "start_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "\n", "sd", "=", "checkpoint", "[", "\"state_dict\"", "]", "\n", "if", "not", "args", ".", "distributed", "and", "next", "(", "iter", "(", "sd", ".", "items", "(", ")", ")", ")", "[", "0", "]", ".", "startswith", "(", "'module'", ")", ":", "\n", "                    ", "sd", "=", "{", "k", "[", "len", "(", "'module.'", ")", ":", "]", ":", "v", "for", "k", ",", "v", "in", "sd", ".", "items", "(", ")", "}", "\n", "", "model", ".", "load_state_dict", "(", "sd", ")", "\n", "if", "optimizer", "is", "not", "None", ":", "\n", "                    ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "", "if", "scaler", "is", "not", "None", "and", "'scaler'", "in", "checkpoint", ":", "\n", "                    ", "scaler", ".", "load_state_dict", "(", "checkpoint", "[", "'scaler'", "]", ")", "\n", "", "logging", ".", "info", "(", "f\"=> resuming checkpoint '{args.resume}' (epoch {start_epoch})\"", ")", "\n", "", "else", ":", "\n", "# loading a bare (model only) checkpoint for fine-tune or evaluation", "\n", "                ", "model", ".", "load_state_dict", "(", "checkpoint", ")", "\n", "logging", ".", "info", "(", "f\"=> loaded checkpoint '{args.resume}' (epoch {start_epoch})\"", ")", "\n", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# initialize datasets", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "", "", "if", "args", ".", "episode_size", "!=", "0", ":", "\n", "        ", "args", ".", "episodic_training", "=", "True", "\n", "index_mapping", "=", "torch", ".", "arange", "(", "args", ".", "episode_size", ")", ".", "share_memory_", "(", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Model will be trained with episodic training strategy (episodic size={args.episode_size}).\"", ")", "\n", "", "", "else", ":", "\n", "        ", "args", ".", "episodic_training", "=", "False", "\n", "index_mapping", "=", "None", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Model will be trained with epoch-wise training strategy.\"", ")", "\n", "\n", "", "", "data", "=", "get_data", "(", "args", ",", "(", "preprocess_train", ",", "preprocess_val", ")", ",", "index_mapping", "=", "index_mapping", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "if", "args", ".", "train_data", "is", "not", "None", "and", "args", ".", "dataset_size", "is", "None", ":", "\n", "        ", "args", ".", "dataset_size", "=", "len", "(", "data", "[", "'train'", "]", ".", "dataset", ".", "captions", ")", "\n", "", "if", "not", "args", ".", "episodic_training", ":", "\n", "        ", "args", ".", "episode_size", "=", "args", ".", "dataset_size", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# create scheduler if train", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "", "scheduler", "=", "None", "\n", "if", "'train'", "in", "data", "and", "optimizer", "is", "not", "None", ":", "\n", "        ", "total_steps", "=", "data", "[", "\"train\"", "]", ".", "dataloader", ".", "num_batches", "*", "args", ".", "epochs", "\n", "if", "args", ".", "lit_start_epoch", "<", "0", ":", "# No LiT", "\n", "            ", "visual_steps", "=", "total_steps", "\n", "", "else", ":", "\n", "            ", "visual_steps", "=", "data", "[", "\"train\"", "]", ".", "dataloader", ".", "num_batches", "*", "(", "args", ".", "lit_start_epoch", "-", "1", ")", "\n", "\n", "\n", "", "text_start_step", "=", "data", "[", "\"train\"", "]", ".", "dataloader", ".", "num_batches", "*", "args", ".", "text_start_epoch", "\n", "if", "args", ".", "text_end_epoch", "<", "0", ":", "\n", "            ", "args", ".", "text_end_epoch", "=", "args", ".", "epochs", "\n", "", "text_end_step", "=", "data", "[", "\"train\"", "]", ".", "dataloader", ".", "num_batches", "*", "args", ".", "text_end_epoch", "\n", "\n", "if", "args", ".", "lr_text", "<", "0", ":", "\n", "            ", "args", ".", "lr_text", "=", "args", ".", "lr", "\n", "", "scheduler", "=", "protoclip_cosine_lr", "(", "optimizer", ",", "args", ".", "lr", ",", "args", ".", "lr_text", ",", "args", ".", "warmup", ",", "total_steps", ",", "visual_steps", ",", "text_start_step", ",", "text_end_step", ")", "\n", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Using cosine lr scheduler. Total steps: {total_steps} ({args.epochs} epochs, {data['train'].dataloader.num_batches} steps per epoch)\"", ")", "\n", "if", "visual_steps", "!=", "total_steps", ":", "\n", "                ", "logging", ".", "info", "(", "f\"\\tTotal steps for visual backbone:  {visual_steps}\"", ")", "\n", "", "if", "text_start_step", "!=", "0", ":", "\n", "                ", "logging", ".", "info", "(", "f\"\\tRest parameters are frozen until: {text_start_step}\"", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# determine if this worker should save logs and checkpoints. only do so if it is rank == 0", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "", "", "", "args", ".", "save_logs", "=", "args", ".", "logs", "and", "args", ".", "logs", ".", "lower", "(", ")", "!=", "'none'", "and", "is_master", "(", "args", ")", "\n", "writer", "=", "None", "\n", "if", "args", ".", "save_logs", "and", "args", ".", "tensorboard", ":", "\n", "        ", "assert", "tensorboard", "is", "not", "None", ",", "\"Please install tensorboard.\"", "\n", "writer", "=", "tensorboard", ".", "SummaryWriter", "(", "args", ".", "tensorboard_path", ")", "\n", "\n", "", "if", "args", ".", "wandb", "and", "is_master", "(", "args", ")", ":", "\n", "        ", "assert", "wandb", "is", "not", "None", ",", "'Please install wandb.'", "\n", "logging", ".", "debug", "(", "'Starting wandb.'", ")", "\n", "args", ".", "train_sz", "=", "data", "[", "\"train\"", "]", ".", "dataloader", ".", "num_samples", "\n", "# you will have to configure this for your project!", "\n", "wandb", ".", "init", "(", "\n", "project", "=", "\"TrainProtoCLIP\"", ",", "\n", "notes", "=", "args", ".", "name", ",", "\n", "tags", "=", "[", "]", ",", "\n", "config", "=", "vars", "(", "args", ")", ",", "\n", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "wandb", ".", "watch", "(", "model", ",", "log", "=", "'all'", ")", "\n", "#wandb.save(params_file)", "\n", "", "logging", ".", "debug", "(", "'Finished loading wandb.'", ")", "\n", "\n", "", "if", "'train'", "not", "in", "data", ":", "\n", "        ", "evaluate", "(", "model", ",", "start_epoch", ",", "preprocess_val", ",", "tokenizer", ",", "args", ",", "writer", ")", "\n", "return", "\n", "\n", "\n", "", "clustering", "=", "Clustering", "(", "args", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Start training loop", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "\n", "profiling", "=", "{", "\n", "\"epsidoe feature extraction time (m)\"", ":", "0", ",", "\n", "\"epsidoe kmeans time (m)\"", ":", "0", ",", "\n", "\"epsidoe model training time (m)\"", ":", "0", ",", "\n", "\"epsidoe total time (m)\"", ":", "0", ",", "\n", "}", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f'Start epoch {epoch}'", ")", "\n", "epoch_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "if", "args", ".", "episodic_training", ":", "\n", "# Random episode sampling      ", "\n", "            ", "index_mapping", "[", ":", "]", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "choice", "(", "args", ".", "dataset_size", ",", "args", ".", "episode_size", ",", "replace", "=", "True", ")", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "                ", "logging", ".", "info", "(", "f\"Randomly select {args.episode_size} samples from full dataset {args.dataset_size} as current episode.\"", ")", "\n", "\n", "", "if", "args", ".", "clustering_frequency", "!=", "-", "1", "and", "epoch", "%", "args", ".", "clustering_frequency", "==", "0", ":", "\n", "                ", "clustering", ".", "reset", "(", "args", ".", "k", ")", "\n", "# --- Episodic Training Step 1: Feature Extraction --- # ", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "feature_extraction_one_epoch", "(", "model", ",", "data", ",", "epoch", ",", "optimizer", ",", "scaler", ",", "scheduler", ",", "clustering", ",", "args", ",", "writer", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "                    ", "duration", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", "\n", "profiling", "[", "'epsidoe feature extraction time (m)'", "]", "=", "duration", "\n", "logging", ".", "info", "(", "f'[Profiling] Feature extraction finished in {duration:.2f} minute.'", ")", "\n", "\n", "# --- Episodic Training Step 2: Prototype Construction --- #", "\n", "", "if", "is_master", "(", "args", ")", ":", "\n", "                    ", "start", "=", "time", ".", "time", "(", ")", "\n", "img_iteration_stats", ",", "text_iteration_stats", "=", "clustering", ".", "generate_labels", "(", "args", ".", "k", ",", "args", ")", "\n", "clustering", ".", "log_kmeans_error", "(", "img_iteration_stats", ",", "epoch", ",", "writer", ",", "args", ",", "'image'", ")", "\n", "clustering", ".", "log_kmeans_error", "(", "text_iteration_stats", ",", "epoch", ",", "writer", ",", "args", ",", "'text'", ")", "\n", "\n", "duration", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", "\n", "profiling", "[", "'epsidoe kmeans time (m)'", "]", "=", "duration", "\n", "logging", ".", "info", "(", "f'[Profiling] K-Means clustering finished in {duration:.2f} minute.'", ")", "\n", "\n", "# metrics = clustering.analyze_labels()", "\n", "# for name, val in metrics.items():", "\n", "#     if writer is not None:", "\n", "#         writer.add_scalar('clustering/' + name, val, epoch)", "\n", "#     if args.wandb:", "\n", "#         wandb.log({'clustering/' + name: val, 'step': epoch})", "\n", "\n", "if", "args", ".", "visualize_frequency", "!=", "-", "1", "and", "epoch", "%", "args", ".", "visualize_frequency", "==", "0", ":", "\n", "                        ", "visualize_start", "=", "time", ".", "time", "(", ")", "\n", "clustering", ".", "show_samples", "(", "dataset", "=", "data", "[", "'train'", "]", ".", "dataset", ",", "modality", "=", "'image'", ",", "file_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualization_path", ",", "f'samples_image_label@epoch{epoch+1}'", ")", ")", "\n", "clustering", ".", "show_samples", "(", "dataset", "=", "data", "[", "'train'", "]", ".", "dataset", ",", "modality", "=", "'text'", ",", "file_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualization_path", ",", "f'samples_text_label@epoch{epoch+1}'", ")", ")", "\n", "clustering", ".", "show_tsne", "(", "file_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "visualization_path", ",", "f'TSNE@epoch{epoch+1}'", ")", ",", "truncate", "=", "20000", ",", "title", "=", "f\"Epoch {epoch+1}\"", ")", "\n", "logging", ".", "info", "(", "f'[Profiling] Cluster visualization finished in {(time.time()-visualize_start)/60:.2f} minute.'", ")", "\n", "\n", "", "if", "not", "args", ".", "PBT", "and", "args", ".", "external_teacher", "is", "not", "None", ":", "\n", "                        ", "logging", ".", "warning", "(", "'External teacher supervision can not be applied without PBT. Skip external prototype construction.'", ")", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "if", "args", ".", "PBT", ":", "\n", "                        ", "clustering", ".", "img_centroids_translated_from_text_prototypes", "=", "clustering", ".", "PBT", "(", "\n", "k", "=", "args", ".", "k", ",", "\n", "teacher_labels", "=", "clustering", ".", "text_labels", ",", "\n", "student_features", "=", "clustering", ".", "img_feature", "\n", ")", "\n", "clustering", ".", "text_centroids_translated_from_image_prototypes", "=", "clustering", ".", "PBT", "(", "\n", "k", "=", "args", ".", "k", ",", "\n", "teacher_labels", "=", "clustering", ".", "img_labels", ",", "\n", "student_features", "=", "clustering", ".", "text_feature", "\n", ")", "\n", "if", "args", ".", "external_teacher", "is", "not", "None", ":", "\n", "                            ", "external_teacher", "=", "np", ".", "load", "(", "args", ".", "external_teacher", ")", "\n", "logging", ".", "info", "(", "f'Loaded external teacher ({external_teacher.shape}) from file \"{args.external_teacher}\".'", ")", "\n", "clustering", ".", "generate_labels_from_external_teacher", "(", "external_teacher", "[", "index_mapping", "]", ",", "args", ".", "k", ",", "args", ")", "\n", "clustering", ".", "img_centroids_translated_from_external_prototypes", "=", "clustering", ".", "PBT", "(", "\n", "k", "=", "args", ".", "k", ",", "\n", "teacher_labels", "=", "clustering", ".", "external_labels", ",", "\n", "student_features", "=", "clustering", ".", "img_feature", "\n", ")", "\n", "clustering", ".", "text_centroids_translated_from_external_prototypes", "=", "clustering", ".", "PBT", "(", "\n", "k", "=", "args", ".", "k", ",", "\n", "teacher_labels", "=", "clustering", ".", "external_labels", ",", "\n", "student_features", "=", "clustering", ".", "text_feature", "\n", ")", "\n", "", "duration", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", "\n", "profiling", "[", "'epsidoe PBT time (m)'", "]", "=", "duration", "\n", "logging", ".", "info", "(", "f'[Profiling] PBT finished in {duration:.2f} minute.'", ")", "\n", "\n", "", "", "if", "args", ".", "distributed", ":", "\n", "                    ", "dist", ".", "barrier", "(", ")", "\n", "", "clustering", ".", "sync_prototypes", "(", "args", ")", "\n", "\n", "# --- Episodic Training Step 3: Model Training --- #", "\n", "", "", "start", "=", "time", ".", "time", "(", ")", "\n", "train_one_epoch", "(", "model", ",", "data", ",", "epoch", ",", "optimizer", ",", "scaler", ",", "scheduler", ",", "clustering", ",", "args", ",", "writer", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "duration", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", "\n", "profiling", "[", "'epsidoe model training time (m)'", "]", "=", "duration", "\n", "logging", ".", "info", "(", "f'[Profiling] Model training finished in {duration:.2f} minute.'", ")", "\n", "duration", "=", "(", "time", ".", "time", "(", ")", "-", "epoch_start", ")", "/", "60", "\n", "profiling", "[", "'epsidoe total time (m)'", "]", "=", "duration", "\n", "logging", ".", "info", "(", "f'[Profiling] Entire epoch/episode takes {duration:.1f} minute.'", ")", "\n", "\n", "for", "name", ",", "val", "in", "profiling", ".", "items", "(", ")", ":", "\n", "                ", "name", "=", "\"profiling/\"", "+", "name", "\n", "if", "writer", "is", "not", "None", ":", "\n", "                    ", "writer", ".", "add_scalar", "(", "name", ",", "val", ",", "epoch", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "                    ", "assert", "wandb", "is", "not", "None", ",", "'Please install wandb.'", "\n", "wandb", ".", "log", "(", "{", "name", ":", "val", ",", "'step'", ":", "epoch", "}", ")", "\n", "\n", "", "", "", "completed_epoch", "=", "epoch", "+", "1", "\n", "\n", "# Saving checkpoints.", "\n", "if", "args", ".", "save_logs", ":", "\n", "            ", "checkpoint_dict", "=", "{", "\n", "\"epoch\"", ":", "completed_epoch", ",", "\n", "\"name\"", ":", "args", ".", "name", ",", "\n", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "if", "scaler", "is", "not", "None", ":", "\n", "                ", "checkpoint_dict", "[", "\"scaler\"", "]", "=", "scaler", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "completed_epoch", "==", "args", ".", "epochs", "or", "(", "\n", "args", ".", "save_frequency", ">", "0", "and", "(", "completed_epoch", "%", "args", ".", "save_frequency", ")", "==", "0", "\n", ")", ":", "\n", "                ", "torch", ".", "save", "(", "\n", "checkpoint_dict", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "f\"epoch_{completed_epoch}.pt\"", ")", ",", "\n", ")", "\n", "", "if", "args", ".", "save_most_recent", ":", "\n", "                ", "torch", ".", "save", "(", "\n", "checkpoint_dict", ",", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "f\"epoch_latest.pt\"", ")", ",", "\n", ")", "\n", "\n", "", "", "evaluate", "(", "model", ",", "completed_epoch", ",", "preprocess_val", ",", "tokenizer", ",", "args", ",", "writer", ")", "\n", "\n", "", "if", "args", ".", "wandb", "and", "is_master", "(", "args", ")", ":", "\n", "        ", "wandb", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.main.copy_codebase": [[484, 499], ["os.path.join", "os.path.exists", "print", "os.path.realpath", "range", "copytree", "print", "print", "os.path.dirname", "ignore_patterns"], "function", ["None"], ["", "", "def", "copy_codebase", "(", "args", ")", ":", "\n", "    ", "from", "shutil", "import", "copytree", ",", "ignore_patterns", "\n", "new_code_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"code\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "new_code_path", ")", ":", "\n", "        ", "print", "(", "\n", "f\"Error. Experiment already exists at {new_code_path}. Use --name to specify a new experiment.\"", "\n", ")", "\n", "return", "-", "1", "\n", "", "print", "(", "f\"Copying codebase to {new_code_path}\"", ")", "\n", "current_code_path", "=", "os", ".", "path", ".", "realpath", "(", "__file__", ")", "\n", "for", "_", "in", "range", "(", "3", ")", ":", "\n", "        ", "current_code_path", "=", "os", ".", "path", ".", "dirname", "(", "current_code_path", ")", "\n", "", "copytree", "(", "current_code_path", ",", "new_code_path", ",", "ignore", "=", "ignore_patterns", "(", "'log'", ",", "'logs'", ",", "'wandb'", ",", "'cache'", ",", "'features'", ")", ")", "\n", "print", "(", "\"Done copying code.\"", ")", "\n", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.__init__": [[26, 30], ["clustering.Clustering.reset"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "episode_size", "=", "args", ".", "episode_size", "\n", "self", ".", "feature_dim", "=", "args", ".", "projection_dim", "\n", "self", ".", "reset", "(", "args", ".", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.reset": [[31, 47], ["torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros().share_memory_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "k", ")", ":", "\n", "        ", "self", ".", "img_feature", "=", "torch", ".", "zeros", "(", "size", "=", "(", "self", ".", "episode_size", ",", "self", ".", "feature_dim", ")", ")", ".", "share_memory_", "(", ")", "\n", "self", ".", "text_feature", "=", "torch", ".", "zeros", "(", "size", "=", "(", "self", ".", "episode_size", ",", "self", ".", "feature_dim", ")", ")", ".", "share_memory_", "(", ")", "\n", "\n", "self", ".", "img_labels", "=", "torch", ".", "zeros", "(", "self", ".", "episode_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "text_labels", "=", "torch", ".", "zeros", "(", "self", ".", "episode_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "external_labels", "=", "torch", ".", "zeros", "(", "self", ".", "episode_size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "self", ".", "img_centroids", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "self", ".", "text_centroids", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "self", ".", "external_centroids", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "\n", "self", ".", "img_centroids_translated_from_text_prototypes", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "self", ".", "text_centroids_translated_from_image_prototypes", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "self", ".", "img_centroids_translated_from_external_prototypes", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "self", ".", "text_centroids_translated_from_external_prototypes", "=", "torch", ".", "zeros", "(", "[", "k", ",", "self", ".", "feature_dim", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load_batch": [[49, 52], ["img_features.detach().cpu().type", "text_features.detach().cpu().type", "img_features.detach().cpu", "text_features.detach().cpu", "img_features.detach", "text_features.detach"], "methods", ["None"], ["", "def", "load_batch", "(", "self", ",", "index", ",", "img_features", ",", "text_features", ")", ":", "\n", "        ", "self", ".", "img_feature", "[", "index", "]", "=", "img_features", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "type", "(", "torch", ".", "float32", ")", "\n", "self", ".", "text_feature", "[", "index", "]", "=", "text_features", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "type", "(", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump": [[54, 58], ["open", "_pickle.dump", "open.close"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump"], ["", "def", "dump", "(", "self", ",", "file", ",", "item", ")", ":", "\n", "        ", "f", "=", "open", "(", "file", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "item", ",", "f", ",", "protocol", "=", "4", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load": [[59, 64], ["open", "_pickle.load", "open.close"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load"], ["", "def", "load", "(", "self", ",", "file", ")", ":", "\n", "        ", "f", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "item", "=", "pickle", ".", "load", "(", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.sync_prototypes": [[65, 103], ["training.distributed.is_master", "training.distributed.is_master", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "torch.barrier", "torch.barrier", "training.distributed.is_master", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "torch.barrier", "torch.barrier", "logging.info", "os.listdir", "logging.info", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "clustering.Clustering.dump", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "clustering.Clustering.load", "os.remove", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.dump", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load"], ["", "def", "sync_prototypes", "(", "self", ",", "args", ")", ":", "\n", "        ", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_labels.pkl'", ")", ",", "self", ".", "img_labels", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids.pkl'", ")", ",", "self", ".", "img_centroids", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_labels.pkl'", ")", ",", "self", ".", "text_labels", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids.pkl'", ")", ",", "self", ".", "text_centroids", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'external_labels.pkl'", ")", ",", "self", ".", "external_labels", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'external_centroids.pkl'", ")", ",", "self", ".", "external_centroids", ")", "\n", "if", "args", ".", "PBT", ":", "\n", "                ", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids_translated_from_text_prototypes.pkl'", ")", ",", "self", ".", "img_centroids_translated_from_text_prototypes", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids_translated_from_image_prototypes.pkl'", ")", ",", "self", ".", "text_centroids_translated_from_image_prototypes", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids_translated_from_external_prototypes.pkl'", ")", ",", "self", ".", "img_centroids_translated_from_external_prototypes", ")", "\n", "self", ".", "dump", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids_translated_from_external_prototypes.pkl'", ")", ",", "self", ".", "text_centroids_translated_from_external_prototypes", ")", "\n", "\n", "", "", "if", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "not", "is_master", "(", "args", ")", ":", "\n", "            ", "self", ".", "img_labels", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_labels.pkl'", ")", ")", "\n", "self", ".", "img_centroids", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids.pkl'", ")", ")", "\n", "self", ".", "text_labels", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_labels.pkl'", ")", ")", "\n", "self", ".", "text_centroids", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids.pkl'", ")", ")", "\n", "self", ".", "external_labels", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'external_labels.pkl'", ")", ")", "\n", "self", ".", "external_centroids", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'external_centroids.pkl'", ")", ")", "\n", "if", "args", ".", "PBT", ":", "\n", "                ", "self", ".", "img_centroids_translated_from_text_prototypes", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids_translated_from_text_prototypes.pkl'", ")", ")", "\n", "self", ".", "text_centroids_translated_from_image_prototypes", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids_translated_from_image_prototypes.pkl'", ")", ")", "\n", "self", ".", "img_centroids_translated_from_external_prototypes", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'img_centroids_translated_from_external_prototypes.pkl'", ")", ")", "\n", "self", ".", "text_centroids_translated_from_external_prototypes", "=", "self", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "f'text_centroids_translated_from_external_prototypes.pkl'", ")", ")", "\n", "\n", "", "", "if", "args", ".", "distributed", ":", "\n", "            ", "dist", ".", "barrier", "(", ")", "\n", "\n", "", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f'Constructed prototypes are synchronized'", ")", "\n", "for", "file", "in", "os", ".", "listdir", "(", "args", ".", "cache_path", ")", ":", "\n", "                ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "args", ".", "cache_path", ",", "file", ")", ")", "\n", "", "logging", ".", "info", "(", "f'Cache path {args.cache_path} has been cleared'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.generate_labels": [[105, 116], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "logging.info", "clustering.Clustering.kmeans", "logging.info", "clustering.Clustering.kmeans", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.kmeans", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.kmeans"], ["", "", "def", "generate_labels", "(", "self", ",", "k", ",", "args", ")", ":", "\n", "# remove possible NaN", "\n", "        ", "self", ".", "img_feature", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "self", ".", "img_feature", ")", ",", "torch", ".", "full_like", "(", "self", ".", "img_feature", ",", "0", ")", ",", "self", ".", "img_feature", ")", "\n", "self", ".", "text_feature", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "self", ".", "text_feature", ")", ",", "torch", ".", "full_like", "(", "self", ".", "text_feature", ",", "0", ")", ",", "self", ".", "text_feature", ")", "\n", "\n", "self", ".", "k", "=", "k", "\n", "logging", ".", "info", "(", "f'Constructing image prototypes with K-Means'", ")", "\n", "self", ".", "img_labels", ",", "self", ".", "img_centroids", ",", "img_error_log", ",", "self", ".", "img_distance", "=", "self", ".", "kmeans", "(", "self", ".", "img_feature", ",", "k", ",", "args", ")", "\n", "logging", ".", "info", "(", "f'Constructing text prototypes with K-Means'", ")", "\n", "self", ".", "text_labels", ",", "self", ".", "text_centroids", ",", "text_error_log", ",", "self", ".", "text_distance", "=", "self", ".", "kmeans", "(", "self", ".", "text_feature", ",", "k", ",", "args", ")", "\n", "return", "img_error_log", ",", "text_error_log", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.generate_labels_from_external_teacher": [[117, 121], ["logging.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "clustering.Clustering.kmeans", "torch.from_numpy.astype", "torch.from_numpy.astype"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.kmeans"], ["", "def", "generate_labels_from_external_teacher", "(", "self", ",", "external_teacher", ",", "k", ",", "args", ")", ":", "\n", "        ", "logging", ".", "info", "(", "f'Constructing external teacher prototypes with K-Means'", ")", "\n", "external_teacher", "=", "torch", ".", "from_numpy", "(", "external_teacher", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "self", ".", "external_labels", ",", "self", ".", "external_centroids", ",", "external_error_log", ",", "external_distance", "=", "self", ".", "kmeans", "(", "external_teacher", ",", "k", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.kmeans": [[123, 144], ["feature.cpu().numpy.cpu().numpy.cpu().numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "faiss.Kmeans", "faiss.Kmeans.train", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "faiss.Kmeans.index.search", "numpy.array", "numpy.reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "distance.flatten", "feature.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "kmeans", "(", "self", ",", "feature", ",", "k", ",", "args", ")", ":", "\n", "        ", "feature", "=", "feature", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "centroids", "=", "torch", ".", "zeros", "(", "[", "k", ",", "feature", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "kmeans", "=", "faiss", ".", "Kmeans", "(", "\n", "d", "=", "feature", ".", "shape", "[", "1", "]", ",", "\n", "k", "=", "k", ",", "\n", "niter", "=", "args", ".", "kmeans_max_iter", ",", "\n", "nredo", "=", "args", ".", "kmeans_nredo", ",", "\n", "verbose", "=", "True", ",", "\n", "gpu", "=", "True", ")", "\n", "kmeans", ".", "train", "(", "feature", ")", "\n", "\n", "# in case of derived centroid is less than args.k", "\n", "centroids", "[", ":", ",", ":", "kmeans", ".", "centroids", ".", "shape", "[", "1", "]", "]", "=", "torch", ".", "from_numpy", "(", "kmeans", ".", "centroids", ")", "\n", "distance", ",", "labels", "=", "kmeans", ".", "index", ".", "search", "(", "feature", ",", "1", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "labels", "=", "np", ".", "reshape", "(", "labels", ",", "labels", ".", "shape", "[", "0", "]", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "labels", ")", ",", "centroids", ",", "kmeans", ".", "iteration_stats", ",", "distance", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.log_kmeans_error": [[145, 151], ["range", "len", "writer.add_scalar", "wandb.log"], "methods", ["None"], ["", "def", "log_kmeans_error", "(", "self", ",", "iteration_stats", ",", "epoch", ",", "writer", ",", "args", ",", "name", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "iteration_stats", ")", ")", ":", "\n", "            ", "if", "writer", "is", "not", "None", ":", "\n", "                ", "writer", ".", "add_scalar", "(", "f'clustering/kmeans_error_log_{name}'", ",", "iteration_stats", "[", "i", "]", "[", "'obj'", "]", ",", "epoch", "*", "args", ".", "kmeans_max_iter", "+", "i", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "f'clustering/kmeans_error_log_{name}'", ":", "iteration_stats", "[", "i", "]", "[", "'obj'", "]", ",", "'step'", ":", "epoch", "*", "args", ".", "kmeans_max_iter", "+", "i", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.PBT": [[153, 166], ["student_features.size", "numpy.unique", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "numpy.where"], "methods", ["None"], ["", "", "", "def", "PBT", "(", "self", ",", "k", ",", "teacher_labels", ",", "student_features", ")", ":", "\n", "# teacher_centroids: (n_class, feature_dim)", "\n", "        ", "n_sample", ",", "feature_dim", "=", "student_features", ".", "size", "(", ")", "\n", "teacher_labels", "=", "teacher_labels", "[", ":", "n_sample", "]", "\n", "cluster_indexs", "=", "np", ".", "unique", "(", "teacher_labels", ")", "\n", "centorids", "=", "torch", ".", "zeros", "(", "k", ",", "feature_dim", ")", "\n", "\n", "for", "k", "in", "cluster_indexs", ":", "\n", "            ", "cluster_samples", "=", "np", ".", "where", "(", "teacher_labels", "==", "k", ")", "[", "0", "]", "\n", "centroid", "=", "torch", ".", "mean", "(", "student_features", "[", "cluster_samples", "]", ",", "dim", "=", "0", ")", "\n", "centorids", "[", "k", "]", "=", "centroid", "\n", "\n", "", "return", "centorids", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.analyze_labels": [[167, 186], ["logging.info", "logging.info", "numpy.unique", "len", "sklearn.metrics.silhouette_score", "sklearn.metrics.davies_bouldin_score", "sklearn.metrics.calinski_harabasz_score", "clustering.Clustering.img_feature.numpy", "clustering.Clustering.text_feature.numpy", "metrics.items"], "methods", ["None"], ["", "def", "analyze_labels", "(", "self", ")", ":", "\n", "        ", "metrics", "=", "{", "}", "\n", "logging", ".", "info", "(", "\"Analyzing pseudo labels.\"", ")", "\n", "for", "modality", "in", "[", "'image'", ",", "'text'", "]", ":", "\n", "            ", "if", "modality", "==", "'image'", ":", "\n", "                ", "label", "=", "self", ".", "img_labels", "\n", "feature", "=", "self", ".", "img_feature", ".", "numpy", "(", ")", "\n", "", "if", "modality", "==", "'text'", ":", "\n", "                ", "label", "=", "self", ".", "text_labels", "\n", "feature", "=", "self", ".", "text_feature", ".", "numpy", "(", ")", "\n", "\n", "", "unique_labels", ",", "n_samples", "=", "np", ".", "unique", "(", "label", ",", "return_counts", "=", "True", ")", "\n", "metrics", "[", "f'{modality}-n_cluster'", "]", "=", "len", "(", "unique_labels", ")", "\n", "metrics", "[", "f'{modality}-Silhouette Coefficient'", "]", "=", "silhouette_score", "(", "feature", ",", "label", ",", "sample_size", "=", "5000", ")", "\n", "metrics", "[", "f'{modality}-Davies-Bouldin Index'", "]", "=", "davies_bouldin_score", "(", "feature", ",", "label", ")", "\n", "metrics", "[", "f'{modality}-Calinski and Harabasz score'", "]", "=", "calinski_harabasz_score", "(", "feature", ",", "label", ")", "\n", "\n", "", "logging", ".", "info", "(", "\"Pseudo labels metrics:\\n\"", "+", "f\"\\n\"", ".", "join", "(", "[", "f\"\\t{k}\\t{v}\"", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "]", ")", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.show_tsne": [[187, 214], ["logging.info", "openTSNE.TSNE().fit", "openTSNE.TSNE().fit", "matplotlib.figure", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "matplotlib.subplots_adjust", "matplotlib.subplots_adjust", "matplotlib.subplot", "matplotlib.subplot", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.title", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.subplot", "matplotlib.subplot", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.title", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.suptitle", "matplotlib.suptitle", "matplotlib.savefig", "matplotlib.savefig", "logging.info", "openTSNE.TSNE", "openTSNE.TSNE"], "methods", ["None"], ["", "def", "show_tsne", "(", "self", ",", "file_name", ",", "truncate", ",", "title", ")", ":", "\n", "\n", "        ", "logging", ".", "info", "(", "'Fitting T-SNE'", ")", "\n", "\n", "tsne_img", "=", "TSNE", "(", "verbose", "=", "True", ",", "n_jobs", "=", "64", ",", "n_iter", "=", "1000", ")", ".", "fit", "(", "self", ".", "img_feature", "[", ":", "truncate", "]", ")", "\n", "tsne_text", "=", "TSNE", "(", "verbose", "=", "True", ",", "n_jobs", "=", "64", ",", "n_iter", "=", "1000", ")", ".", "fit", "(", "self", ".", "text_feature", "[", ":", "truncate", "]", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "30", ",", "15", ")", ")", "\n", "plt", ".", "rc", "(", "'font'", ",", "size", "=", "20", ")", "\n", "plt", ".", "subplots_adjust", "(", "top", "=", "0.9", ",", "wspace", "=", "0.05", ",", "hspace", "=", "0.05", ")", "\n", "\n", "plt", ".", "subplot", "(", "121", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "title", "(", "'image features'", ")", "\n", "plt", ".", "scatter", "(", "tsne_img", "[", ":", ",", "0", "]", ",", "tsne_img", "[", ":", ",", "1", "]", ",", "s", "=", "1.5", ",", "c", "=", "self", ".", "img_labels", "[", ":", "truncate", "]", ",", "cmap", "=", "'tab10'", ",", "alpha", "=", "0.8", ")", "\n", "\n", "plt", ".", "subplot", "(", "122", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "title", "(", "'text features'", ")", "\n", "plt", ".", "scatter", "(", "tsne_text", "[", ":", ",", "0", "]", ",", "tsne_text", "[", ":", ",", "1", "]", ",", "s", "=", "1.5", ",", "c", "=", "self", ".", "text_labels", "[", ":", "truncate", "]", ",", "cmap", "=", "'tab10'", ",", "alpha", "=", "0.8", ")", "\n", "\n", "plt", ".", "suptitle", "(", "title", ")", "\n", "plt", ".", "savefig", "(", "file_name", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n", "logging", ".", "info", "(", "f'T-SNE visuallization saved to: {file_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.show_samples": [[215, 248], ["logging.info", "numpy.unique", "utils.plot_pairs.plot_pairs", "logging.info", "numpy.squeeze", "range", "numpy.argwhere", "len", "images.append", "texts.append", "dataset.get_data", "images.append", "texts.append", "PIL.Image.new", "int", "torchvision.transforms.ToPILImage"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.utils.plot_pairs.plot_pairs", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.get_data"], ["", "def", "show_samples", "(", "self", ",", "dataset", ",", "modality", ",", "file_name", ",", "sample_per_class", "=", "16", ",", "max_rows", "=", "16", ")", ":", "\n", "        ", "images", "=", "[", "]", "\n", "texts", "=", "[", "]", "\n", "if", "modality", "==", "'image'", ":", "\n", "            ", "label", "=", "self", ".", "img_labels", "\n", "", "elif", "modality", "==", "'text'", ":", "\n", "            ", "label", "=", "self", ".", "text_labels", "\n", "\n", "", "logging", ".", "info", "(", "f'Visuallizing {modality} clustering results'", ")", "\n", "unique_labels", ",", "n_samples", "=", "np", ".", "unique", "(", "label", ",", "return_counts", "=", "True", ")", "\n", "\n", "for", "k", "in", "unique_labels", "[", ":", "max_rows", "]", ":", "\n", "            ", "cluster_dataset_index", "=", "np", ".", "squeeze", "(", "np", ".", "argwhere", "(", "label", "==", "k", ")", ")", "\n", "if", "cluster_dataset_index", ".", "shape", "==", "(", ")", ":", "\n", "                ", "continue", "# empty cluster", "\n", "# show [sample_per_class] samples for each class", "\n", "", "for", "i", "in", "range", "(", "sample_per_class", ")", ":", "\n", "# sometimes there are not much sample in this cluster", "\n", "                ", "if", "i", ">=", "len", "(", "cluster_dataset_index", ")", ":", "\n", "                    ", "images", ".", "append", "(", "Image", ".", "new", "(", "'RGB'", ",", "(", "256", ",", "256", ")", ",", "(", "255", ",", "255", ",", "255", ")", ")", ")", "\n", "texts", ".", "append", "(", "' '", ")", "\n", "", "else", ":", "\n", "                    ", "image", ",", "text", "=", "dataset", ".", "get_data", "(", "int", "(", "cluster_dataset_index", "[", "i", "]", ")", ")", "\n", "image", "=", "ToPILImage", "(", ")", "(", "image", ")", "\n", "images", ".", "append", "(", "image", ")", "\n", "texts", ".", "append", "(", "text", ")", "\n", "\n", "", "", "", "plot_pairs", "(", "\n", "images", "[", ":", "100", "*", "sample_per_class", "]", ",", "texts", "[", ":", "100", "*", "sample_per_class", "]", ",", "\n", "suptitle", "=", "file_name", ",", "file_name", "=", "file_name", "+", "'.png'", ",", "\n", "sample_per_row", "=", "sample_per_class", "\n", ")", "\n", "logging", ".", "info", "(", "f'Sample visuallization saved to: {file_name}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.logger.setup_logging": [[4, 26], ["logging.root.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.root.addHandler", "socket.gethostname", "logging.Formatter", "logging.Formatter", "logging.getLogger", "logger.setLevel", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.root.addHandler"], "function", ["None"], ["def", "setup_logging", "(", "log_file", ",", "level", ",", "include_host", "=", "False", ")", ":", "\n", "    ", "if", "include_host", ":", "\n", "        ", "import", "socket", "\n", "hostname", "=", "socket", ".", "gethostname", "(", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\n", "f'%(asctime)s |  {hostname} | %(levelname)s | %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d,%H:%M:%S'", ")", "\n", "", "else", ":", "\n", "        ", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s | %(levelname)s | %(message)s'", ",", "datefmt", "=", "'%Y-%m-%d,%H:%M:%S'", ")", "\n", "\n", "", "logging", ".", "root", ".", "setLevel", "(", "level", ")", "\n", "loggers", "=", "[", "logging", ".", "getLogger", "(", "name", ")", "for", "name", "in", "logging", ".", "root", ".", "manager", ".", "loggerDict", "]", "\n", "for", "logger", "in", "loggers", ":", "\n", "        ", "logger", ".", "setLevel", "(", "level", ")", "\n", "\n", "", "stream_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "stream_handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logging", ".", "root", ".", "addHandler", "(", "stream_handler", ")", "\n", "\n", "if", "log_file", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "filename", "=", "log_file", ")", "\n", "file_handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logging", ".", "root", ".", "addHandler", "(", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.__init__": [[26, 28], ["train.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset": [[29, 34], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update": [[35, 40], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.unwrap_model": [[42, 47], ["hasattr"], "function", ["None"], ["", "", "def", "unwrap_model", "(", "model", ")", ":", "\n", "    ", "if", "hasattr", "(", "model", ",", "'module'", ")", ":", "\n", "        ", "return", "model", ".", "module", "\n", "", "else", ":", "\n", "        ", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.train_one_epoch": [[49, 286], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "model.train", "training.loss.ClipLoss", "training.loss.ProtoLoss", "clustering.img_centroids.cuda", "clustering.text_centroids.cuda", "clustering.external_centroids.cuda", "math.ceil", "train.AverageMeter", "train.AverageMeter", "time.time", "enumerate", "distributed.is_master", "distributed.is_master", "clustering.img_centroids_translated_from_text_prototypes.cuda", "clustering.text_centroids_translated_from_image_prototypes.cuda", "clustering.img_centroids_translated_from_external_prototypes.cuda", "clustering.text_centroids_translated_from_external_prototypes.cuda", "sampler.set_epoch", "math.log", "scheduler", "distributed.get_gathered_item", "images.to.to", "texts.to.to", "clustering.img_labels[].to", "clustering.text_labels[].to", "clustering.external_labels[].to", "train.AverageMeter.update", "optimizer.zero_grad", "train.AverageMeter.update", "time.time", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "logging.info", "logging.info", "len", "index.cuda", "autocast", "scaler.scale().backward", "scaler.unscale_", "torch.utils.clip_grad_norm_", "scaler.update", "total_loss.backward", "torch.utils.clip_grad_norm_", "optimizer.step", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "unwrap_model().logit_scale.clamp_", "distributed.is_master", "len", "logging.info", "log_data.items", "log_data_protoclip.items", "profiling.items", "train.AverageMeter.reset", "train.AverageMeter.reset", "time.time", "model", "training.loss.ClipLoss.", "model", "training.loss.ClipLoss.", "training.loss.ProtoLoss.", "training.loss.ProtoLoss.", "model.parameters", "optimizer.synchronize", "scaler.unscale_", "scaler.step", "model.parameters", "math.log", "unwrap_model().logit_scale_proto.clamp_", "time.time", "clip_loss.item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean().item", "training.evaluations.analyze_features.get_modality_gap", "L_proto.item", "L_proto_external.item", "training.loss.gather_features", "training.loss.gather_features", "training.loss.gather_features", "training.loss.ProtoLoss.", "training.loss.ProtoLoss.", "scaler.scale", "optimizer.skip_synchronize", "scaler.step", "math.log", "logit_scale.item", "logit_scale_proto.item", "tb_writer.add_scalar", "wandb.log", "tb_writer.add_scalar", "wandb.log", "tb_writer.add_scalar", "wandb.log", "train.unwrap_model", "total_loss.item", "torch.std().mean", "torch.std().mean", "torch.std().mean", "torch.std().mean", "torch.std().mean", "torch.std().mean", "torch.std().mean", "torch.std().mean", "train.unwrap_model", "logit_scale.item", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.get_gathered_item", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.get_modality_gap", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.gather_features", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.gather_features", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.gather_features", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.unwrap_model", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.unwrap_model"], ["", "", "def", "train_one_epoch", "(", "model", ",", "data", ",", "epoch", ",", "optimizer", ",", "scaler", ",", "scheduler", ",", "clustering", ",", "args", ",", "tb_writer", "=", "None", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "ZERO", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "#autocast = torch.cuda.amp.autocast if args.precision == 'amp' else suppress", "\n", "autocast", "=", "torch", ".", "cuda", ".", "amp", ".", "autocast", "\n", "\n", "model", ".", "train", "(", ")", "\n", "clip_loss", "=", "ClipLoss", "(", "\n", "local_loss", "=", "args", ".", "local_loss", ",", "\n", "gather_with_grad", "=", "args", ".", "gather_with_grad", ",", "\n", "cache_labels", "=", "True", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "\n", "use_horovod", "=", "args", ".", "horovod", ")", "\n", "\n", "proto_loss", "=", "ProtoLoss", "(", ")", "\n", "\n", "w_clip", "=", "args", ".", "w_clip", "\n", "w_proto", "=", "args", ".", "w_proto", "\n", "w_proto_external", "=", "args", ".", "w_proto_external", "\n", "\n", "# optionally entering and LiT epoch", "\n", "if", "args", ".", "lit_start_epoch", ">", "0", "and", "epoch", ">=", "args", ".", "lit_start_epoch", "-", "1", ":", "\n", "        ", "w_clip", "=", "1", "\n", "w_proto", "=", "0", "\n", "w_proto_external", "=", "0", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Setting up Locked-image Finetuning (LiT)'", ")", "\n", "\n", "# optionally warm-up the model with InfoNCE only following PCL", "\n", "", "", "if", "epoch", "<", "args", ".", "infonce_warmup_epoch", ":", "\n", "        ", "w_clip", "=", "1", "\n", "w_proto", "=", "0", "\n", "w_proto_external", "=", "0", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'Setting up InfoNCE-only warmup'", ")", "\n", "\n", "\n", "", "", "clustering", ".", "img_centroids", "=", "clustering", ".", "img_centroids", ".", "cuda", "(", ")", "\n", "clustering", ".", "text_centroids", "=", "clustering", ".", "text_centroids", ".", "cuda", "(", ")", "\n", "clustering", ".", "external_centroids", "=", "clustering", ".", "external_centroids", ".", "cuda", "(", ")", "\n", "if", "args", ".", "PBT", ":", "\n", "        ", "clustering", ".", "img_centroids_translated_from_text_prototypes", "=", "clustering", ".", "img_centroids_translated_from_text_prototypes", ".", "cuda", "(", ")", "\n", "clustering", ".", "text_centroids_translated_from_image_prototypes", "=", "clustering", ".", "text_centroids_translated_from_image_prototypes", ".", "cuda", "(", ")", "\n", "clustering", ".", "img_centroids_translated_from_external_prototypes", "=", "clustering", ".", "img_centroids_translated_from_external_prototypes", ".", "cuda", "(", ")", "\n", "clustering", ".", "text_centroids_translated_from_external_prototypes", "=", "clustering", ".", "text_centroids_translated_from_external_prototypes", ".", "cuda", "(", ")", "\n", "\n", "\n", "", "dataloader", ",", "sampler", "=", "data", "[", "'train'", "]", ".", "dataloader", ",", "data", "[", "'train'", "]", ".", "sampler", "\n", "if", "args", ".", "distributed", "and", "sampler", "is", "not", "None", ":", "\n", "        ", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "num_batches_per_epoch", "=", "dataloader", ".", "num_batches", "\n", "sample_digits", "=", "math", ".", "ceil", "(", "math", ".", "log", "(", "dataloader", ".", "num_samples", "+", "1", ",", "10", ")", ")", "\n", "\n", "batch_time_m", "=", "AverageMeter", "(", ")", "\n", "data_time_m", "=", "AverageMeter", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "step", "=", "num_batches_per_epoch", "*", "epoch", "+", "i", "\n", "scheduler", "(", "step", ")", "\n", "index", ",", "images", ",", "texts", "=", "batch", "\n", "if", "len", "(", "index", ")", "!=", "args", ".", "batch_size", ":", "# drop last incomplete small batch", "\n", "            ", "continue", "\n", "", "all_index", "=", "get_gathered_item", "(", "index", ".", "cuda", "(", ")", ",", "args", ")", "\n", "images", "=", "images", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "texts", "=", "texts", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "img_labels", "=", "clustering", ".", "img_labels", "[", "all_index", "]", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "text_labels", "=", "clustering", ".", "text_labels", "[", "all_index", "]", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "external_labels", "=", "clustering", ".", "external_labels", "[", "all_index", "]", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "data_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "with", "autocast", "(", ")", ":", "\n", "# original CLIP", "\n", "            ", "if", "not", "args", ".", "add_projection_head", ":", "\n", "                ", "image_features", ",", "text_features", ",", "logit_scale", "=", "model", "(", "images", ",", "texts", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "                    ", "all_image_features", ",", "all_text_features", "=", "gather_features", "(", "image_features", ",", "text_features", ",", "\n", "args", ".", "local_loss", ",", "args", ".", "gather_with_grad", ",", "args", ".", "rank", ",", "args", ".", "world_size", ",", "args", ".", "horovod", ")", "\n", "", "else", ":", "\n", "                    ", "all_image_features", ",", "all_text_features", "=", "image_features", ",", "text_features", "\n", "\n", "", "L_clip", "=", "clip_loss", "(", "all_image_features", ",", "all_text_features", ",", "logit_scale", ")", "\n", "total_loss", "=", "L_clip", "\n", "# ProtoCLIP", "\n", "", "else", ":", "\n", "                ", "image_features", ",", "text_features", ",", "image_features_projected", ",", "text_features_projected", ",", "logit_scale", ",", "logit_scale_proto", "=", "model", "(", "images", ",", "texts", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "                    ", "all_image_features", ",", "all_text_features", "=", "gather_features", "(", "image_features", ",", "text_features", ",", "\n", "args", ".", "local_loss", ",", "args", ".", "gather_with_grad", ",", "args", ".", "rank", ",", "args", ".", "world_size", ",", "args", ".", "horovod", ")", "\n", "all_image_features_projected", ",", "all_text_features_projected", "=", "gather_features", "(", "image_features_projected", ",", "text_features_projected", ",", "\n", "args", ".", "local_loss", ",", "args", ".", "gather_with_grad", ",", "args", ".", "rank", ",", "args", ".", "world_size", ",", "args", ".", "horovod", ")", "\n", "", "else", ":", "\n", "                    ", "all_image_features", ",", "all_text_features", "=", "image_features", ",", "text_features", "\n", "all_image_features_projected", ",", "all_text_features_projected", "=", "image_features_projected", ",", "text_features_projected", "\n", "\n", "", "L_clip", "=", "clip_loss", "(", "all_image_features", ",", "all_text_features", ",", "logit_scale", ")", "\n", "\n", "if", "args", ".", "PBT", ":", "\n", "                    ", "img_target", "=", "clustering", ".", "img_centroids_translated_from_text_prototypes", "\n", "text_target", "=", "clustering", ".", "text_centroids_translated_from_image_prototypes", "\n", "img_target_external", "=", "clustering", ".", "img_centroids_translated_from_external_prototypes", "\n", "text_target_external", "=", "clustering", ".", "text_centroids_translated_from_external_prototypes", "\n", "", "else", ":", "\n", "                    ", "img_target", "=", "clustering", ".", "text_centroids", "\n", "text_target", "=", "clustering", ".", "img_centroids", "\n", "img_target_external", "=", "clustering", ".", "img_centroids_translated_from_external_prototypes", "\n", "text_target_external", "=", "clustering", ".", "text_centroids_translated_from_external_prototypes", "\n", "\n", "", "L_proto_img2text", ",", "acc_img2text", "=", "proto_loss", "(", "\n", "student_features", "=", "all_image_features_projected", ",", "student_centroids", "=", "img_target", ",", "teacher_centroids", "=", "clustering", ".", "text_centroids", ",", "\n", "logit_scale_student", "=", "logit_scale_proto", ",", "teacher_temperature", "=", "args", ".", "target_temperature", ",", "labels", "=", "text_labels", "\n", ")", "\n", "L_proto_text2img", ",", "acc_text2img", "=", "proto_loss", "(", "\n", "student_features", "=", "all_text_features_projected", ",", "student_centroids", "=", "text_target", ",", "teacher_centroids", "=", "clustering", ".", "img_centroids", ",", "\n", "logit_scale_student", "=", "logit_scale_proto", ",", "teacher_temperature", "=", "args", ".", "target_temperature", ",", "labels", "=", "img_labels", "\n", ")", "\n", "\n", "if", "args", ".", "external_teacher", "is", "not", "None", ":", "\n", "                    ", "L_proto_img2external", ",", "acc_img2external", "=", "proto_loss", "(", "\n", "student_features", "=", "all_image_features_projected", ",", "student_centroids", "=", "img_target_external", ",", "teacher_centroids", "=", "clustering", ".", "external_centroids", ",", "\n", "logit_scale_student", "=", "logit_scale_proto", ",", "teacher_temperature", "=", "-", "1", ",", "labels", "=", "external_labels", "\n", ")", "\n", "L_proto_text2external", ",", "acc_text2external", "=", "proto_loss", "(", "\n", "student_features", "=", "all_text_features_projected", ",", "student_centroids", "=", "text_target_external", ",", "teacher_centroids", "=", "clustering", ".", "external_centroids", ",", "\n", "logit_scale_student", "=", "logit_scale_proto", ",", "teacher_temperature", "=", "-", "1", ",", "labels", "=", "external_labels", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "L_proto_img2external", ",", "acc_img2external", "=", "ZERO", ",", "ZERO", "\n", "L_proto_text2external", ",", "acc_text2external", "=", "ZERO", ",", "ZERO", "\n", "\n", "", "L_proto", "=", "0.5", "*", "(", "L_proto_img2text", "+", "L_proto_text2img", ")", "\n", "L_proto_external", "=", "0.5", "*", "(", "L_proto_img2external", "+", "L_proto_text2external", ")", "\n", "total_loss", "=", "w_clip", "*", "L_clip", "+", "w_proto", "*", "L_proto", "+", "w_proto_external", "*", "L_proto_external", "\n", "\n", "", "", "if", "scaler", "is", "not", "None", ":", "\n", "            ", "scaler", ".", "scale", "(", "total_loss", ")", ".", "backward", "(", ")", "\n", "scaler", ".", "unscale_", "(", "optimizer", ")", "\n", "norm", "=", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "max_norm", "=", "args", ".", "max_grad_norm", ")", "\n", "if", "args", ".", "horovod", ":", "\n", "                ", "optimizer", ".", "synchronize", "(", ")", "\n", "scaler", ".", "unscale_", "(", "optimizer", ")", "\n", "with", "optimizer", ".", "skip_synchronize", "(", ")", ":", "\n", "                    ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "", "", "else", ":", "\n", "                ", "scaler", ".", "step", "(", "optimizer", ")", "\n", "", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "            ", "total_loss", ".", "backward", "(", ")", "\n", "norm", "=", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "max_norm", "=", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Note: we clamp to 4.6052 = ln(100), as in the original paper.", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "unwrap_model", "(", "model", ")", ".", "logit_scale", ".", "clamp_", "(", "0", ",", "math", ".", "log", "(", "100", ")", ")", "\n", "if", "args", ".", "add_projection_head", ":", "\n", "                ", "unwrap_model", "(", "model", ")", ".", "logit_scale_proto", ".", "clamp_", "(", "0", ",", "math", ".", "log", "(", "100", ")", ")", "\n", "\n", "", "", "batch_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "batch_count", "=", "i", "+", "1", "\n", "if", "is_master", "(", "args", ")", "and", "(", "i", "%", "10", "==", "0", "or", "batch_count", "==", "num_batches_per_epoch", ")", ":", "\n", "            ", "batch_size", "=", "len", "(", "images", ")", "\n", "num_samples", "=", "batch_count", "*", "batch_size", "*", "args", ".", "world_size", "\n", "samples_per_epoch", "=", "dataloader", ".", "num_samples", "\n", "percent_complete", "=", "100.0", "*", "batch_count", "/", "num_batches_per_epoch", "\n", "\n", "# NOTE loss is coarsely sampled, just master node and per log update", "\n", "logging", ".", "info", "(", "\n", "f\"Train Epoch: {epoch+1}/{args.epochs} [{num_samples:>{sample_digits}}/{samples_per_epoch} ({percent_complete:.0f}%)] \"", "\n", "f\"Loss: {total_loss.item():.5f} \"", "\n", "f\"Data (t): {data_time_m.avg:.3f} \"", "\n", "f\"Batch (t): {batch_time_m.avg:.3f} \"", "\n", "f\"Temperature: {1 / logit_scale.item():.4f} \"", "\n", "f\"LR (visual/rest): {optimizer.param_groups[0]['lr']:3f}/{optimizer.param_groups[2]['lr']:3f} \"", "\n", "f\"grad: {norm:1f} \"", "\n", ")", "\n", "\n", "# Save train loss / etc. Using non avg meter values as loggers have their own smoothing", "\n", "log_data", "=", "{", "\n", "\"loss_clip\"", ":", "L_clip", ".", "item", "(", ")", ",", "\n", "\"temperature\"", ":", "1", "/", "logit_scale", ".", "item", "(", ")", ",", "\n", "\"lr_visual\"", ":", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "\n", "\"lr_rest\"", ":", "optimizer", ".", "param_groups", "[", "2", "]", "[", "\"lr\"", "]", ",", "\n", "\"gradient-norm\"", ":", "norm", ",", "\n", "\n", "\"feature_std_image\"", ":", "torch", ".", "std", "(", "image_features", ",", "dim", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "\"feature_std_text\"", ":", "torch", ".", "std", "(", "text_features", ",", "dim", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "\"feature_modality_gap\"", ":", "get_modality_gap", "(", "image_features", ",", "text_features", ")", ",", "\n", "}", "\n", "profiling", "=", "{", "\n", "\"batch data time (s)\"", ":", "data_time_m", ".", "val", ",", "\n", "\"bathc total time (s)\"", ":", "batch_time_m", ".", "val", ",", "\n", "}", "\n", "\n", "log_data_protoclip", "=", "{", "}", "\n", "if", "args", ".", "add_projection_head", ":", "\n", "                ", "log_data_protoclip", "[", "'loss_proto'", "]", "=", "L_proto", ".", "item", "(", ")", "\n", "log_data_protoclip", "[", "'loss_proto_external'", "]", "=", "L_proto_external", ".", "item", "(", ")", "\n", "log_data_protoclip", "[", "'acc_img2text'", "]", "=", "acc_img2text", "\n", "log_data_protoclip", "[", "'acc_text2img'", "]", "=", "acc_text2img", "\n", "log_data_protoclip", "[", "'acc_img2external'", "]", "=", "acc_img2external", "\n", "log_data_protoclip", "[", "'acc_text2external'", "]", "=", "acc_text2external", "\n", "log_data_protoclip", "[", "'temperature_proto'", "]", "=", "1", "/", "logit_scale_proto", ".", "item", "(", ")", "\n", "\n", "\n", "", "for", "name", ",", "val", "in", "log_data", ".", "items", "(", ")", ":", "\n", "                ", "name", "=", "\"training/\"", "+", "name", "\n", "if", "tb_writer", "is", "not", "None", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "name", ",", "val", ",", "step", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "                    ", "assert", "wandb", "is", "not", "None", ",", "'Please install wandb.'", "\n", "wandb", ".", "log", "(", "{", "name", ":", "val", ",", "'step'", ":", "step", "}", ")", "\n", "\n", "", "", "for", "name", ",", "val", "in", "log_data_protoclip", ".", "items", "(", ")", ":", "\n", "                ", "name", "=", "\"training_protoclip/\"", "+", "name", "\n", "if", "tb_writer", "is", "not", "None", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "name", ",", "val", ",", "step", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "                    ", "assert", "wandb", "is", "not", "None", ",", "'Please install wandb.'", "\n", "wandb", ".", "log", "(", "{", "name", ":", "val", ",", "'step'", ":", "step", "}", ")", "\n", "\n", "", "", "for", "name", ",", "val", "in", "profiling", ".", "items", "(", ")", ":", "\n", "                ", "name", "=", "\"profiling/\"", "+", "name", "\n", "if", "tb_writer", "is", "not", "None", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "name", ",", "val", ",", "step", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "                    ", "assert", "wandb", "is", "not", "None", ",", "'Please install wandb.'", "\n", "wandb", ".", "log", "(", "{", "name", ":", "val", ",", "'step'", ":", "step", "}", ")", "\n", "\n", "# resetting batch / data time meters per log window", "\n", "", "", "batch_time_m", ".", "reset", "(", ")", "\n", "data_time_m", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.feature_extraction_one_epoch": [[288, 342], ["torch.device", "torch.device", "torch.device", "torch.device", "model.eval", "math.ceil", "train.AverageMeter", "train.AverageMeter", "time.time", "enumerate", "sampler.set_epoch", "math.log", "distributed.get_gathered_item.to", "images.to.to", "texts.to.to", "train.AverageMeter.update", "distributed.get_gathered_item", "distributed.get_gathered_item", "distributed.get_gathered_item", "distributed.is_master", "train.AverageMeter.update", "time.time", "autocast", "clustering.load_batch", "distributed.is_master", "len", "logging.info", "train.AverageMeter.reset", "train.AverageMeter.reset", "time.time", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "time.time"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.get_gathered_item", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.get_gathered_item", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.get_gathered_item", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.clustering.Clustering.load_batch", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.reset"], ["", "", "", "def", "feature_extraction_one_epoch", "(", "model", ",", "data", ",", "epoch", ",", "optimizer", ",", "scaler", ",", "scheduler", ",", "clustering", ",", "args", ",", "tb_writer", "=", "None", ")", ":", "\n", "    ", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "autocast", "=", "torch", ".", "cuda", ".", "amp", ".", "autocast", "if", "args", ".", "precision", "==", "'amp'", "else", "suppress", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "dataloader", ",", "sampler", "=", "data", "[", "'train'", "]", ".", "dataloader", ",", "data", "[", "'train'", "]", ".", "sampler", "\n", "if", "args", ".", "distributed", "and", "sampler", "is", "not", "None", ":", "\n", "        ", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "num_batches_per_epoch", "=", "dataloader", ".", "num_batches", "\n", "sample_digits", "=", "math", ".", "ceil", "(", "math", ".", "log", "(", "dataloader", ".", "num_samples", "+", "1", ",", "10", ")", ")", "\n", "\n", "batch_time_m", "=", "AverageMeter", "(", ")", "\n", "data_time_m", "=", "AverageMeter", "(", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "\n", "        ", "indexs", ",", "images", ",", "texts", "=", "batch", "\n", "indexs", "=", "indexs", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "images", "=", "images", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "texts", "=", "texts", ".", "to", "(", "device", "=", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "data_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "# forward propagation", "\n", "with", "autocast", "(", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "image_features", ",", "text_features", ",", "image_features_projected", ",", "text_features_projected", ",", "logit_scale", ",", "logit_scale_proto", "=", "model", "(", "images", ",", "texts", ")", "\n", "\n", "# cache features", "\n", "", "", "indexs", "=", "get_gathered_item", "(", "indexs", ",", "args", ")", "\n", "image_features_projected", "=", "get_gathered_item", "(", "image_features_projected", ",", "args", ")", "\n", "text_features_projected", "=", "get_gathered_item", "(", "text_features_projected", ",", "args", ")", "\n", "if", "is_master", "(", "args", ")", ":", "\n", "            ", "clustering", ".", "load_batch", "(", "indexs", ",", "image_features_projected", ",", "text_features_projected", ")", "\n", "\n", "", "batch_time_m", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "batch_count", "=", "i", "+", "1", "\n", "if", "is_master", "(", "args", ")", "and", "(", "i", "%", "100", "==", "0", "or", "batch_count", "==", "num_batches_per_epoch", ")", ":", "\n", "            ", "batch_size", "=", "len", "(", "images", ")", "\n", "num_samples", "=", "batch_count", "*", "batch_size", "*", "args", ".", "world_size", "\n", "samples_per_epoch", "=", "dataloader", ".", "num_samples", "\n", "percent_complete", "=", "100.0", "*", "batch_count", "/", "num_batches_per_epoch", "\n", "\n", "logging", ".", "info", "(", "\n", "f\"Feature extraction: {epoch+1}/{args.epochs} [{num_samples:>{sample_digits}}/{samples_per_epoch} ({percent_complete:.0f}%)] \"", "\n", "f\"Data (t): {data_time_m.avg:.3f} \"", "\n", "f\"Batch (t): {batch_time_m.avg:.3f} \"", "\n", ")", "\n", "\n", "# resetting batch / data time meters per log window", "\n", "batch_time_m", ".", "reset", "(", ")", "\n", "data_time_m", ".", "reset", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.CsvDataset.__init__": [[25, 62], ["logging.debug", "pandas.read_csv", "df[].tolist", "df[].tolist", "torchvision.transforms.Compose", "numpy.array().astype", "numpy.array", "range", "data.CsvDataset.captions.astype", "logging.debug", "df[].tolist", "len", "data.CsvDataset.captions[].encode", "torch.arange", "torchvision.transforms.Normalize", "torchvision.transforms.Normalize", "numpy.array", "len", "df[].tolist"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.encode"], ["    ", "def", "__init__", "(", "self", ",", "input_filename", ",", "transforms", ",", "img_key", ",", "caption_key", ",", "sep", "=", "\"\\t\"", ",", "dataset_size", "=", "None", ",", "index_mapping", "=", "None", ",", "tokenizer", "=", "None", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "f'Loading csv data from {input_filename}.'", ")", "\n", "\n", "df", "=", "pd", ".", "read_csv", "(", "input_filename", ",", "sep", "=", "sep", ")", "\n", "\n", "self", ".", "images", "=", "df", "[", "img_key", "]", ".", "tolist", "(", ")", "\n", "self", ".", "captions", "=", "df", "[", "caption_key", "]", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "self", ".", "inversed_normalize", "=", "Compose", "(", "[", "\n", "Normalize", "(", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "(", "1", "/", "0.26862954", ",", "1", "/", "0.26130258", ",", "1", "/", "0.27577711", ")", ")", ",", "\n", "Normalize", "(", "(", "-", "0.48145466", ",", "-", "0.4578275", ",", "-", "0.40821073", ")", ",", "(", "1.0", ",", "1.0", ",", "1.0", ")", ")", ",", "\n", "]", ")", "\n", "\n", "# Faster data loading. see https://github.com/pytorch/pytorch/issues/13246#issuecomment-905703662", "\n", "self", ".", "images", "=", "np", ".", "array", "(", "df", "[", "img_key", "]", ".", "tolist", "(", ")", ")", ".", "astype", "(", "np", ".", "string_", ")", "\n", "self", ".", "captions", "=", "np", ".", "array", "(", "df", "[", "caption_key", "]", ".", "tolist", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "captions", ")", ")", ":", "\n", "            ", "self", ".", "captions", "[", "i", "]", "=", "self", ".", "captions", "[", "i", "]", ".", "encode", "(", "'ascii'", ",", "errors", "=", "'ignore'", ")", "\n", "", "self", ".", "captions", "=", "self", ".", "captions", ".", "astype", "(", "np", ".", "string_", ")", "\n", "\n", "# use a subset of given dataset", "\n", "if", "dataset_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "images", "=", "self", ".", "images", "[", ":", "dataset_size", "]", "\n", "self", ".", "captions", "=", "self", ".", "captions", "[", ":", "dataset_size", "]", "\n", "\n", "", "if", "index_mapping", "is", "None", ":", "\n", "            ", "self", ".", "index_mapping", "=", "torch", ".", "arange", "(", "len", "(", "self", ".", "captions", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "index_mapping", "=", "index_mapping", "\n", "\n", "", "if", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "tokenizer", "=", "clip_tokenizer", "\n", "", "else", ":", "\n", "# using the tokenizer of pretrained NLP model", "\n", "            ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "\n", "", "logging", ".", "debug", "(", "'Done loading data.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.CsvDataset.__len__": [[63, 65], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "index_mapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.CsvDataset.__getitem__": [[66, 72], ["PIL.Image.open", "data.CsvDataset.transforms", "data.CsvDataset.tokenizer", "str", "str", "data.CsvDataset.images[].decode", "data.CsvDataset.captions[].decode"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode"], ["", "def", "__getitem__", "(", "self", ",", "episodic_index", ")", ":", "\n", "        ", "index", "=", "self", ".", "index_mapping", "[", "episodic_index", "]", "\n", "image", "=", "Image", ".", "open", "(", "str", "(", "self", ".", "images", "[", "index", "]", ".", "decode", "(", "'utf-8'", ")", ")", ")", "\n", "image", "=", "self", ".", "transforms", "(", "image", ")", "\n", "texts", "=", "self", ".", "tokenizer", "(", "str", "(", "self", ".", "captions", "[", "index", "]", ".", "decode", "(", "'utf-8'", ")", ")", ")", "\n", "return", "episodic_index", ",", "image", ",", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.CsvDataset.get_data": [[73, 80], ["PIL.Image.open", "data.CsvDataset.inversed_normalize", "data.CsvDataset.captions[].decode", "str", "data.CsvDataset.transforms", "data.CsvDataset.images[].decode"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.decode"], ["", "def", "get_data", "(", "self", ",", "episode_index", ")", ":", "\n", "        ", "idx", "=", "self", ".", "index_mapping", "[", "episode_index", "]", "\n", "pic", "=", "Image", ".", "open", "(", "str", "(", "self", ".", "images", "[", "idx", "]", ".", "decode", "(", "'utf-8'", ")", ")", ")", "\n", "image", "=", "self", ".", "inversed_normalize", "(", "self", ".", "transforms", "(", "pic", ")", ")", "\n", "texts", "=", "self", ".", "captions", "[", "idx", "]", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "return", "image", ",", "texts", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.clip_tokenizer": [[21, 23], ["open_clip.tokenize"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.tokenize"], ["def", "clip_tokenizer", "(", "str", ")", ":", "\n", "    ", "return", "tokenize", "(", "[", "str", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.get_csv_dataset": [[89, 119], ["data.CsvDataset", "len", "torch.utils.data.DataLoader", "len", "data.DataInfo", "torch.utils.data.distributed.DistributedSampler"], "function", ["None"], ["", "def", "get_csv_dataset", "(", "args", ",", "preprocess_fn", ",", "is_train", ",", "index_mapping", ",", "tokenizer", ")", ":", "\n", "    ", "input_filename", "=", "args", ".", "train_data", "if", "is_train", "else", "args", ".", "val_data", "\n", "assert", "input_filename", "\n", "dataset", "=", "CsvDataset", "(", "\n", "input_filename", ",", "\n", "preprocess_fn", ",", "\n", "img_key", "=", "args", ".", "csv_img_key", ",", "\n", "caption_key", "=", "args", ".", "csv_caption_key", ",", "\n", "sep", "=", "args", ".", "csv_separator", ",", "\n", "dataset_size", "=", "args", ".", "dataset_size", ",", "\n", "index_mapping", "=", "index_mapping", ",", "\n", "tokenizer", "=", "tokenizer", ")", "\n", "num_samples", "=", "len", "(", "dataset", ")", "\n", "sampler", "=", "DistributedSampler", "(", "dataset", ")", "if", "args", ".", "distributed", "and", "is_train", "else", "None", "\n", "shuffle", "=", "is_train", "and", "sampler", "is", "None", "\n", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "sampler", ",", "\n", "drop_last", "=", "False", ",", "\n", "persistent_workers", "=", "True", "\n", ")", "\n", "dataloader", ".", "num_samples", "=", "num_samples", "\n", "dataloader", ".", "num_batches", "=", "len", "(", "dataloader", ")", "\n", "\n", "return", "DataInfo", "(", "dataset", ",", "dataloader", ",", "sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.get_data": [[121, 129], ["data.get_csv_dataset"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.data.get_csv_dataset"], ["", "def", "get_data", "(", "args", ",", "preprocess_fns", ",", "index_mapping", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "preprocess_train", ",", "preprocess_val", "=", "preprocess_fns", "\n", "data", "=", "{", "}", "\n", "\n", "if", "args", ".", "train_data", ":", "\n", "        ", "data", "[", "\"train\"", "]", "=", "get_csv_dataset", "(", "args", ",", "preprocess_train", ",", "is_train", "=", "True", ",", "index_mapping", "=", "index_mapping", ",", "tokenizer", "=", "tokenizer", ")", "\n", "\n", "", "return", "data", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.assign_learning_rate": [[4, 7], ["None"], "function", ["None"], ["def", "assign_learning_rate", "(", "optimizer", ",", "new_lr", ")", ":", "\n", "    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "\"lr\"", "]", "=", "new_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler._warmup_lr": [[9, 11], ["None"], "function", ["None"], ["", "", "def", "_warmup_lr", "(", "base_lr", ",", "warmup_length", ",", "step", ")", ":", "\n", "    ", "return", "base_lr", "*", "(", "step", "+", "1", ")", "/", "warmup_length", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.cosine_lr": [[13, 24], ["scheduler.assign_learning_rate", "scheduler._warmup_lr", "numpy.cos"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.assign_learning_rate", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler._warmup_lr"], ["", "def", "cosine_lr", "(", "optimizer", ",", "base_lr", ",", "warmup_length", ",", "steps", ")", ":", "\n", "    ", "def", "_lr_adjuster", "(", "step", ")", ":", "\n", "        ", "if", "step", "<", "warmup_length", ":", "\n", "            ", "lr", "=", "_warmup_lr", "(", "base_lr", ",", "warmup_length", ",", "step", ")", "\n", "", "else", ":", "\n", "            ", "e", "=", "step", "-", "warmup_length", "\n", "es", "=", "steps", "-", "warmup_length", "\n", "lr", "=", "0.5", "*", "(", "1", "+", "np", ".", "cos", "(", "np", ".", "pi", "*", "e", "/", "es", ")", ")", "*", "base_lr", "\n", "", "assign_learning_rate", "(", "optimizer", ",", "lr", ")", "\n", "return", "lr", "\n", "", "return", "_lr_adjuster", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.assign_learning_rate_seperately": [[29, 34], ["None"], "function", ["None"], ["", "def", "assign_learning_rate_seperately", "(", "optimizer", ",", "lr_visual", ",", "lr_non_visual", ")", ":", "\n", "    ", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "=", "lr_visual", "\n", "optimizer", ".", "param_groups", "[", "1", "]", "[", "\"lr\"", "]", "=", "lr_visual", "\n", "optimizer", ".", "param_groups", "[", "2", "]", "[", "\"lr\"", "]", "=", "lr_non_visual", "\n", "optimizer", ".", "param_groups", "[", "3", "]", "[", "\"lr\"", "]", "=", "lr_non_visual", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.protoclip_cosine_lr": [[35, 65], ["scheduler.assign_learning_rate_seperately", "scheduler._warmup_lr", "scheduler._warmup_lr", "numpy.cos", "numpy.cos"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler.assign_learning_rate_seperately", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler._warmup_lr", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.scheduler._warmup_lr"], ["", "def", "protoclip_cosine_lr", "(", "optimizer", ",", "visual_base_lr", ",", "text_base_lr", ",", "warmup_length", ",", "total_steps", ",", "visual_steps", ",", "text_start_step", ",", "text_end_step", ")", ":", "\n", "    ", "def", "_lr_adjuster", "(", "step", ")", ":", "\n", "\n", "# get lr_visual for visual backbone", "\n", "        ", "if", "step", "<", "warmup_length", ":", "\n", "            ", "lr_visual", "=", "_warmup_lr", "(", "visual_base_lr", ",", "warmup_length", ",", "step", ")", "\n", "", "else", ":", "\n", "            ", "e_visual", "=", "step", "-", "warmup_length", "\n", "es_visual", "=", "visual_steps", "-", "warmup_length", "\n", "lr_visual", "=", "0.5", "*", "(", "1", "+", "np", ".", "cos", "(", "np", ".", "pi", "*", "e_visual", "/", "es_visual", ")", ")", "*", "visual_base_lr", "\n", "if", "step", ">", "visual_steps", ":", "\n", "                ", "lr_visual", "=", "0", "\n", "\n", "# get lr_non_visual for rest parameters", "\n", "", "", "if", "step", "<", "text_start_step", ":", "\n", "            ", "lr_non_visual", "=", "0", "\n", "", "else", ":", "\n", "            ", "step", "-=", "text_start_step", "\n", "if", "step", "<", "warmup_length", ":", "\n", "                ", "lr_non_visual", "=", "_warmup_lr", "(", "text_base_lr", ",", "warmup_length", ",", "step", ")", "\n", "", "else", ":", "\n", "                ", "e_non_visual", "=", "step", "-", "warmup_length", "\n", "es_non_visual", "=", "text_end_step", "-", "text_start_step", "-", "warmup_length", "\n", "lr_non_visual", "=", "0.5", "*", "(", "1", "+", "np", ".", "cos", "(", "np", ".", "pi", "*", "e_non_visual", "/", "es_non_visual", ")", ")", "*", "text_base_lr", "\n", "if", "step", ">", "text_end_step", ":", "\n", "                    ", "lr_non_visual", "=", "0", "\n", "\n", "", "", "", "assign_learning_rate_seperately", "(", "optimizer", ",", "lr_visual", ",", "lr_non_visual", ")", "\n", "return", "[", "lr_visual", ",", "lr_non_visual", "]", "\n", "", "return", "_lr_adjuster", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.ClipLoss.__init__": [[63, 83], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["gather_with_grad", "=", "False", ",", "\n", "cache_labels", "=", "False", ",", "\n", "rank", "=", "0", ",", "\n", "world_size", "=", "1", ",", "\n", "use_horovod", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "local_loss", "=", "local_loss", "\n", "self", ".", "gather_with_grad", "=", "gather_with_grad", "\n", "self", ".", "cache_labels", "=", "cache_labels", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "use_horovod", "=", "use_horovod", "\n", "\n", "# cache state", "\n", "self", ".", "prev_num_logits", "=", "0", "\n", "self", ".", "labels", "=", "{", "}", "\n", "\n", "", "def", "forward", "(", "self", ",", "image_features", ",", "text_features", ",", "logit_scale", ")", ":", "\n", "        ", "device", "=", "image_features", ".", "device", "\n", "if", "self", ".", "world_size", ">", "1", ":", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.ClipLoss.forward": [[84, 106], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy"], "methods", ["None"], ["            ", "all_image_features", ",", "all_text_features", "=", "gather_features", "(", "\n", "image_features", ",", "text_features", ",", "\n", "self", ".", "local_loss", ",", "self", ".", "gather_with_grad", ",", "self", ".", "rank", ",", "self", ".", "world_size", ",", "self", ".", "use_horovod", ")", "\n", "\n", "if", "self", ".", "local_loss", ":", "\n", "                ", "logits_per_image", "=", "logit_scale", "*", "image_features", "@", "all_text_features", ".", "T", "\n", "logits_per_text", "=", "logit_scale", "*", "text_features", "@", "all_image_features", ".", "T", "\n", "", "else", ":", "\n", "                ", "logits_per_image", "=", "logit_scale", "*", "all_image_features", "@", "all_text_features", ".", "T", "\n", "logits_per_text", "=", "logits_per_image", ".", "T", "\n", "", "", "else", ":", "\n", "            ", "logits_per_image", "=", "logit_scale", "*", "image_features", "@", "text_features", ".", "T", "\n", "logits_per_text", "=", "logit_scale", "*", "text_features", "@", "image_features", ".", "T", "\n", "\n", "# calculated ground-truth and cache if enabled", "\n", "", "num_logits", "=", "logits_per_image", ".", "shape", "[", "0", "]", "\n", "if", "self", ".", "prev_num_logits", "!=", "num_logits", "or", "device", "not", "in", "self", ".", "labels", ":", "\n", "            ", "labels", "=", "torch", ".", "arange", "(", "num_logits", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "world_size", ">", "1", "and", "self", ".", "local_loss", ":", "\n", "                ", "labels", "=", "labels", "+", "num_logits", "*", "self", ".", "rank", "\n", "", "if", "self", ".", "cache_labels", ":", "\n", "                ", "self", ".", "labels", "[", "device", "]", "=", "labels", "\n", "self", ".", "prev_num_logits", "=", "num_logits", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.ProtoLoss.__init__": [[111, 113], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__"], ["F", ".", "cross_entropy", "(", "logits_per_image", ",", "labels", ")", "+", "\n", "F", ".", "cross_entropy", "(", "logits_per_text", ",", "labels", ")", "\n", ")", "/", "2", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.ProtoLoss.forward": [[114, 135], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "teacher_scores.softmax.softmax.softmax", "CrossEntropy", "CrossEntropy", "student_scores.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "labels.size"], "methods", ["None"], ["return", "total_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.loss.gather_features": [[15, 59], ["hvd.allgather", "hvd.allgather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hvd.allgather", "hvd.allgather", "list", "list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.distributed.nn.all_gather", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.cat.chunk", "torch.cat.chunk", "range", "range"], "function", ["None"], ["local_loss", "=", "False", ",", "\n", "gather_with_grad", "=", "False", ",", "\n", "rank", "=", "0", ",", "\n", "world_size", "=", "1", ",", "\n", "use_horovod", "=", "False", "\n", ")", ":", "\n", "    ", "if", "use_horovod", ":", "\n", "        ", "assert", "hvd", "is", "not", "None", ",", "'Please install horovod'", "\n", "if", "gather_with_grad", ":", "\n", "            ", "all_image_features", "=", "hvd", ".", "allgather", "(", "image_features", ")", "\n", "all_text_features", "=", "hvd", ".", "allgather", "(", "text_features", ")", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "all_image_features", "=", "hvd", ".", "allgather", "(", "image_features", ")", "\n", "all_text_features", "=", "hvd", ".", "allgather", "(", "text_features", ")", "\n", "", "if", "not", "local_loss", ":", "\n", "# ensure grads for local rank when all_* features don't have a gradient", "\n", "                ", "gathered_image_features", "=", "list", "(", "all_image_features", ".", "chunk", "(", "world_size", ",", "dim", "=", "0", ")", ")", "\n", "gathered_text_features", "=", "list", "(", "all_text_features", ".", "chunk", "(", "world_size", ",", "dim", "=", "0", ")", ")", "\n", "gathered_image_features", "[", "rank", "]", "=", "image_features", "\n", "gathered_text_features", "[", "rank", "]", "=", "text_features", "\n", "all_image_features", "=", "torch", ".", "cat", "(", "gathered_image_features", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "gathered_text_features", ",", "dim", "=", "0", ")", "\n", "", "", "", "else", ":", "\n", "# We gather tensors from all gpus", "\n", "        ", "if", "gather_with_grad", ":", "\n", "            ", "all_image_features", "=", "torch", ".", "cat", "(", "torch", ".", "distributed", ".", "nn", ".", "all_gather", "(", "image_features", ")", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "torch", ".", "distributed", ".", "nn", ".", "all_gather", "(", "text_features", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "gathered_image_features", "=", "[", "torch", ".", "zeros_like", "(", "image_features", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "gathered_text_features", "=", "[", "torch", ".", "zeros_like", "(", "text_features", ")", "for", "_", "in", "range", "(", "world_size", ")", "]", "\n", "dist", ".", "all_gather", "(", "gathered_image_features", ",", "image_features", ")", "\n", "dist", ".", "all_gather", "(", "gathered_text_features", ",", "text_features", ")", "\n", "if", "not", "local_loss", ":", "\n", "# ensure grads for local rank when all_* features don't have a gradient", "\n", "                ", "gathered_image_features", "[", "rank", "]", "=", "image_features", "\n", "gathered_text_features", "[", "rank", "]", "=", "text_features", "\n", "", "all_image_features", "=", "torch", ".", "cat", "(", "gathered_image_features", ",", "dim", "=", "0", ")", "\n", "all_text_features", "=", "torch", ".", "cat", "(", "gathered_text_features", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "return", "all_image_features", ",", "all_text_features", "\n", "\n", "\n", "", "class", "ClipLoss", "(", "nn", ".", "Module", ")", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.params.get_default_params": [[4, 11], ["model_name.lower.lower"], "function", ["None"], ["def", "get_default_params", "(", "model_name", ")", ":", "\n", "# Params from paper (https://arxiv.org/pdf/2103.00020.pdf)", "\n", "    ", "model_name", "=", "model_name", ".", "lower", "(", ")", "\n", "if", "\"vit\"", "in", "model_name", ":", "\n", "        ", "return", "{", "\"lr\"", ":", "5.0e-4", ",", "\"beta1\"", ":", "0.9", ",", "\"beta2\"", ":", "0.98", ",", "\"eps\"", ":", "1.0e-6", "}", "\n", "", "else", ":", "\n", "        ", "return", "{", "\"lr\"", ":", "5.0e-4", ",", "\"beta1\"", ":", "0.9", ",", "\"beta2\"", ":", "0.999", ",", "\"eps\"", ":", "1.0e-8", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.params.parse_args": [[13, 411], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "params.get_default_params", "get_default_params.items", "getattr", "setattr"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.training.params.parse_args", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.params.get_default_params"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Data and Episodic training", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train-data\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Path to csv filewith training data\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--augmentation\"", ",", "\n", "choices", "=", "[", "None", ",", "\"protoclip-light-augmentation\"", "]", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Use lighter augmentation for implicit contrast. Choices: [None, protoclip-light-augmentation]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval-data-dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Path to datasets for evaluation\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset-size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Trunck the number of samples in dataset.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--csv-separator\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\\t\"", ",", "\n", "help", "=", "\"For csv-like datasets, which separator to use.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--csv-img-key\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"filepath\"", ",", "\n", "help", "=", "\"For csv-like datasets, the name of the key for the image paths.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--csv-caption-key\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"title\"", ",", "\n", "help", "=", "\"For csv-like datasets, the name of the key for the captions.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--workers\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Number of workers per GPU.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--episode-size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"Set episode_size to 0 to disable episodic training\"", ",", "\n", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Prototypical contrast", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\n", "\"--external-teacher\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Saved numpy array with shape (dataset_size, feature_dim) as external teacher. leave it as None to disable the external teacher.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add-projection-head\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"add two projection heads and leanable temperatures to CLIP\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--PBT\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"enable Prototype Back Translation\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--projection-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "128", ",", "\n", "help", "=", "\"dimension of projected representations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--projection-hidden-dim\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2048", ",", "\n", "help", "=", "\"dimension of projected representations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--projection-n-layers\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"dimension of projected representations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--target-temperature\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "-", "1.0", ",", "\n", "help", "=", "\"target temperature to calculate teacher scroes in proto loss\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--clustering-frequency\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"update prototypes, set to -1 for non ProtoCLIP models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--k\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20000", ",", "\n", "help", "=", "\"dimension of projected representations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--kmeans-max-iter\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20", ",", "\n", "help", "=", "\"maximum iterations of K-Means optimization\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--kmeans-nredo\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"random re-initialize and do K-Means for how many times\"", ",", "\n", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Logging and checkpointing", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\n", "\"--logs\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"./logs/\"", ",", "\n", "help", "=", "\"Where to store tensorboard logs. Use None to avoid storing logs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log-local\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"log files on local master, otherwise global master only.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--name\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Optional identifier for the experiment when storing logs. Otherwise use current time.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-frequency\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"How often to save checkpoints.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save-most-recent\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "True", ",", "\n", "help", "=", "\"Always save the most recent model trained to epoch_latest.pt.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--resume\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"path to latest checkpoint (default: none)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pretrained\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Use a pretrained CLIP model weights with the specified tag or file path.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pretrained-image\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Load imagenet pretrained weights for image tower backbone if available.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pretrained-text\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Load pretrained language model as text tower via pytorch-transformers.\"", ",", "\n", ")", "\n", "\n", "# MODELS = [(BertModel,       BertTokenizer,      'bert-base-uncased'),", "\n", "#           (OpenAIGPTModel,  OpenAIGPTTokenizer, 'openai-gpt'),", "\n", "#           (GPT2Model,       GPT2Tokenizer,      'gpt2'),", "\n", "#           (TransfoXLModel,  TransfoXLTokenizer, 'transfo-xl-wt103'),", "\n", "#           (XLNetModel,      XLNetTokenizer,     'xlnet-base-cased'),", "\n", "#           (XLMModel,        XLMTokenizer,       'xlm-mlm-enfr-1024'),", "\n", "#           (RobertaModel,    RobertaTokenizer,   'roberta-base')]", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Loss functions", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "\n", "parser", ".", "add_argument", "(", "\"--w-clip\"", ",", "type", "=", "float", ",", "default", "=", "1.", ",", "help", "=", "\"Loss weight.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--w-proto\"", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "\"Loss weight.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--w-proto-external\"", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "\"Loss weight.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--infonce-warmup-epoch\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"InfoNCE-only warmup.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lit-start-epoch\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Enable ProtoCLIP asymetric learning rate scheduler. Leave it as negative to skip LiT.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--text-start-epoch\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Freeze text encoder at the begining of training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--text-end-epoch\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"TODO\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lock-image\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Lock full image tower by disabling gradients.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lock-image-unlocked-groups\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "\n", "help", "=", "\"Leave last n image tower layer groups unlocked.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lock-image-freeze-bn-stats\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Freeze BatchNorm running stats in image tower for any locked layers.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--report-to\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Options are ['wandb', 'tensorboard', 'wandb,tensorboard']\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--wandb-notes\"", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Notes if logging with wandb\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, more information is logged.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--copy-codebase\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, we copy the entire base on the log diretory, and execute from there.\"", "\n", ")", "\n", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Optimization", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"Batch size per GPU.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "\"Number of epochs to train for.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"Learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr-text\"", ",", "type", "=", "float", ",", "default", "=", "-", "1.", ",", "help", "=", "\"Seperate learning rate despite visual backbone. Leave it as -1 to use default unified learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--beta1\"", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"Adam beta 1.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--beta2\"", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"Adam beta 2.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eps\"", ",", "type", "=", "float", ",", "default", "=", "None", ",", "help", "=", "\"Adam epsilon.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wd\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Weight decay.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "\"Number of steps to warmup for.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use-bn-sync\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use batch norm sync.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--skip-scheduler\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Use this flag to skip the learning rate decay.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--precision\"", ",", "\n", "choices", "=", "[", "\"amp\"", ",", "\"fp16\"", ",", "\"fp32\"", "]", ",", "\n", "default", "=", "\"amp\"", ",", "\n", "help", "=", "\"Floating point precision.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--grad-checkpointing\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Enable gradient checkpointing.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max-grad-norm\"", ",", "\n", "default", "=", "1e16", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Enable gradient clipping.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--local-loss\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"calculate loss w/ local features @ global (instead of realizing full global @ global matrix)\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gather-with-grad\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"enable full distributed gradient for feature gather\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--force-quick-gelu\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Force use of QuickGELU activation for non-OpenAI transformer models.\"", ",", "\n", ")", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Evaluation", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\"--zeroshot-frequency\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"How often to run zero shot.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--retrieval-frequency\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"How often to run coco retrieval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--linear-frequency\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"How often to run linear eval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--visualize-frequency\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"How often to run linear eval.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--C\"", ",", "type", "=", "float", ",", "default", "=", "3.16", ",", "help", "=", "\"inverse regularizer for logistic reg (sklearn implementation).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--linear-prob-mode\"", ",", "\n", "choices", "=", "[", "\"pytorch\"", ",", "\"sklearn\"", "]", ",", "\n", "default", "=", "\"pytorch\"", ",", "\n", "help", "=", "\"Use witch implementation for linear evaluaion\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"RN50\"", ",", "\n", "help", "=", "\"Name of the vision backbone to use.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--torchscript\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"torch.jit.script the model, also uses jit version of OpenAI models if pretrained=='openai'\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--trace\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"torch.jit.trace the model for inference / eval only\"", ",", "\n", ")", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "# Distributed training", "\n", "# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # ", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dist-url\"", ",", "\n", "default", "=", "\"env://\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"url used to set up distributed training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dist-backend\"", ",", "default", "=", "\"nccl\"", ",", "type", "=", "str", ",", "help", "=", "\"distributed backend\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--horovod\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use horovod for distributed training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ddp-static-graph\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Enable static graph optimization for DDP in PyTorch >= 1.11.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-set-device-rank\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Don't set device index from local rank (when CUDA_VISIBLE_DEVICES restricted to one per proc).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Default random seed.\"", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# If some params are not passed, we use the default values based on model name.", "\n", "default_params", "=", "get_default_params", "(", "args", ".", "model", ")", "\n", "for", "name", ",", "val", "in", "default_params", ".", "items", "(", ")", ":", "\n", "        ", "if", "getattr", "(", "args", ",", "name", ")", "is", "None", ":", "\n", "            ", "setattr", "(", "args", ",", "name", ",", "val", ")", "\n", "\n", "", "", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.training.pretrained_transformers.get_pretrained_text_encoder_and_tokenizer": [[4, 28], ["tokenizer_class.from_pretrained", "model_class.from_pretrained", "torch.zeros", "torch.zeros.long", "torch.tensor", "tokenizer_class.from_pretrained.encode", "len"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.SimpleTokenizer.encode"], ["def", "get_pretrained_text_encoder_and_tokenizer", "(", "name", ")", ":", "\n", "# TODO: get the width of other models", "\n", "    ", "MODELS", "=", "[", "\n", "# (BertModel,       BertTokenizer,      'bert-base-uncased', ?),", "\n", "# (OpenAIGPTModel,  OpenAIGPTTokenizer, 'openai-gpt', ?),", "\n", "# (GPT2Model,       GPT2Tokenizer,      'gpt2', ?),", "\n", "# (TransfoXLModel,  TransfoXLTokenizer, 'transfo-xl-wt103', ?),", "\n", "# (XLNetModel,      XLNetTokenizer,     'xlnet-base-cased', ?),", "\n", "# (XLMModel,        XLMTokenizer,       'xlm-mlm-enfr-1024', ?),", "\n", "(", "RobertaModel", ",", "RobertaTokenizer", ",", "'roberta-base'", ",", "768", ")", "\n", "]", "\n", "\n", "for", "model_class", ",", "tokenizer_class", ",", "pretrained_weights", ",", "feature_dim", "in", "MODELS", ":", "\n", "        ", "if", "pretrained_weights", "==", "name", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "pretrained_weights", ",", "max_len", "=", "75", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "pretrained_weights", ")", "\n", "\n", "def", "tokenize", "(", "text", ")", ":", "\n", "                ", "result", "=", "torch", ".", "zeros", "(", "77", ")", "\n", "token", "=", "torch", ".", "tensor", "(", "tokenizer", ".", "encode", "(", "text", ",", "add_special_tokens", "=", "True", ")", ")", "[", ":", "77", "]", "\n", "result", "[", ":", "len", "(", "token", ")", "]", "=", "token", "\n", "return", "result", ".", "long", "(", ")", "\n", "\n", "", "return", "model", ",", "tokenize", ",", "feature_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoDataset.__init__": [[15, 43], ["range", "torch.cat", "len", "coco_dataset.coco.getAnnIds", "coco_dataset.coco.loadAnns", "os.path.join", "coco_retrieval.CocoDataset.image.append", "enumerate", "coco_retrieval.CocoDataset.img2txt[].append", "coco_dataset.coco.loadImgs", "coco_retrieval.CocoDataset.text.append", "coco_retrieval.CocoDataset.text.append", "open_clip.tokenize", "torch.stack", "tokenizer"], "methods", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "coco_dataset", ",", "coco_val_root", ",", "transform", ",", "tokenizer", ")", ":", "\n", "        ", "self", ".", "text", "=", "[", "]", "\n", "self", ".", "image", "=", "[", "]", "\n", "self", ".", "txt2img", "=", "{", "}", "\n", "self", ".", "img2txt", "=", "{", "}", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "txt_id", "=", "0", "\n", "for", "index", "in", "range", "(", "len", "(", "coco_dataset", ")", ")", ":", "\n", "            ", "ann_ids", "=", "coco_dataset", ".", "coco", ".", "getAnnIds", "(", "imgIds", "=", "coco_dataset", ".", "ids", "[", "index", "]", ")", "\n", "anns", "=", "coco_dataset", ".", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "target", "=", "[", "ann", "[", "'caption'", "]", "for", "ann", "in", "anns", "]", "\n", "\n", "path", "=", "coco_dataset", ".", "coco", ".", "loadImgs", "(", "coco_dataset", ".", "ids", "[", "index", "]", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "coco_val_root", ",", "path", ")", "\n", "\n", "self", ".", "image", ".", "append", "(", "path", ")", "\n", "self", ".", "img2txt", "[", "index", "]", "=", "[", "]", "\n", "\n", "for", "i", ",", "caption", "in", "enumerate", "(", "target", ")", ":", "\n", "                ", "if", "tokenizer", "is", "None", ":", "\n", "                    ", "self", ".", "text", ".", "append", "(", "clip_tokenizer", "(", "caption", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "text", ".", "append", "(", "torch", ".", "stack", "(", "[", "tokenizer", "(", "caption", ")", "]", ")", ")", "\n", "", "self", ".", "img2txt", "[", "index", "]", ".", "append", "(", "txt_id", ")", "\n", "self", ".", "txt2img", "[", "txt_id", "]", "=", "index", "\n", "txt_id", "+=", "1", "\n", "", "", "self", ".", "text", "=", "torch", ".", "cat", "(", "self", ".", "text", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoDataset.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoDataset.__getitem__": [[47, 52], ["PIL.Image.open().convert", "coco_retrieval.CocoDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "image_path", "=", "self", ".", "image", "[", "index", "]", "\n", "image", "=", "Image", ".", "open", "(", "image_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "return", "image", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__init__": [[55, 57], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "coco_dataset", ")", ":", "\n", "        ", "self", ".", "coco_dataset", "=", "coco_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__len__": [[58, 60], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "coco_dataset", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.CocoTexts.__getitem__": [[61, 63], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "coco_dataset", ".", "text", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.coco_retrieval_evaluation": [[65, 133], ["os.path.join", "os.path.join", "torchvision.datasets.coco.CocoCaptions", "coco_retrieval.CocoDataset", "torch.utils.data.DataLoader", "coco_retrieval.CocoTexts", "torch.utils.data.DataLoader", "coco_retrieval.get_retrieval_metrics", "logging.info", "torch.zeros_like", "range", "torch.no_grad", "logging.info", "tqdm.tqdm", "torch.cat", "logging.info", "tqdm.tqdm", "torch.cat", "scores_img2text.t().detach", "scores_img2text.cpu().numpy", "scores_img2text.t().detach.cpu().numpy", "len", "texts.to.to", "torch.cat.append", "images.to.to", "torch.cat.append", "torch.cat.norm", "torch.cat.norm", "str", "model.module.encode_text().detach().cpu", "model.encode_text().detach().cpu", "model.module.encode_image().detach().cpu", "model.encode_image().detach().cpu", "scores_img2text.t", "scores_img2text.cpu", "scores_img2text.t().detach.cpu", "torch.cat.t", "model.module.encode_text().detach", "model.encode_text().detach", "model.module.encode_image().detach", "model.encode_image().detach", "model.module.encode_text", "model.encode_text", "model.module.encode_image", "model.encode_image"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.get_retrieval_metrics", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image"], ["", "", "def", "coco_retrieval_evaluation", "(", "model", ",", "epoch", ",", "preprocess", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "if", "args", ".", "retrieval_frequency", "==", "0", ":", "\n", "        ", "return", "{", "}", ",", "None", ",", "None", "\n", "", "if", "(", "epoch", "%", "args", ".", "retrieval_frequency", ")", "!=", "0", "and", "epoch", "!=", "args", ".", "epochs", ":", "\n", "        ", "return", "{", "}", ",", "None", ",", "None", "\n", "\n", "", "coco_val_root", "=", "os", ".", "path", ".", "join", "(", "args", ".", "eval_data_dir", ",", "'coco2017/val2017'", ")", "\n", "coco_val_json", "=", "os", ".", "path", ".", "join", "(", "args", ".", "eval_data_dir", ",", "'coco2017/annotations/captions_val2017.json'", ")", "\n", "\n", "coco_dataset", "=", "CocoCaptions", "(", "root", "=", "coco_val_root", ",", "annFile", "=", "coco_val_json", ",", "transform", "=", "preprocess", ")", "\n", "coco_dataset", "=", "CocoDataset", "(", "coco_dataset", ",", "coco_val_root", "=", "coco_val_root", ",", "transform", "=", "preprocess", ",", "tokenizer", "=", "tokenizer", ")", "\n", "coco_retrieval_dataloader", "=", "DataLoader", "(", "\n", "coco_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ",", "\n", ")", "\n", "coco_dataset_text", "=", "CocoTexts", "(", "coco_dataset", ")", "\n", "coco_retrieval_text_dataloader", "=", "DataLoader", "(", "\n", "coco_dataset_text", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ",", "\n", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'extracting COCO text features...'", ")", "\n", "all_text_features", "=", "[", "]", "\n", "for", "texts", "in", "tqdm", ".", "tqdm", "(", "coco_retrieval_text_dataloader", ")", ":", "\n", "            ", "texts", "=", "texts", ".", "to", "(", "args", ".", "device", ")", "\n", "if", "args", ".", "distributed", "and", "not", "args", ".", "horovod", ":", "\n", "                ", "text_features", "=", "model", ".", "module", ".", "encode_text", "(", "texts", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "text_features", "=", "model", ".", "encode_text", "(", "texts", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "all_text_features", ".", "append", "(", "text_features", ")", "\n", "", "all_text_features", "=", "torch", ".", "cat", "(", "all_text_features", ",", "dim", "=", "0", ")", "\n", "\n", "logging", ".", "info", "(", "'extracting COCO image features...'", ")", "\n", "all_image_features", "=", "[", "]", "\n", "for", "images", ",", "img_id", "in", "tqdm", ".", "tqdm", "(", "coco_retrieval_dataloader", ")", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "distributed", "and", "not", "args", ".", "horovod", ":", "\n", "                ", "image_features", "=", "model", ".", "module", ".", "encode_image", "(", "images", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "image_features", "=", "model", ".", "encode_image", "(", "images", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "", "all_image_features", ".", "append", "(", "image_features", ")", "\n", "", "all_image_features", "=", "torch", ".", "cat", "(", "all_image_features", ",", "dim", "=", "0", ")", "\n", "\n", "# normalization, this step is important", "\n", "all_image_features", "=", "all_image_features", "/", "all_image_features", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "all_text_features", "=", "all_text_features", "/", "all_text_features", ".", "norm", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "scores_img2text", "=", "(", "all_image_features", "@", "all_text_features", ".", "t", "(", ")", ")", ".", "detach", "(", ")", "\n", "scores_text2img", "=", "scores_img2text", ".", "t", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "retrieval_metrics", "=", "get_retrieval_metrics", "(", "\n", "scores_img2text", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "scores_text2img", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "coco_retrieval_dataloader", ".", "dataset", ".", "img2txt", ",", "\n", "coco_retrieval_dataloader", ".", "dataset", ".", "txt2img", "\n", ")", "\n", "logging", ".", "info", "(", "'COCO retrieval evaluation: '", "+", "str", "(", "retrieval_metrics", ")", ")", "\n", "\n", "deduplicated_text_features", "=", "torch", ".", "zeros_like", "(", "all_image_features", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "coco_retrieval_dataloader", ".", "dataset", ".", "img2txt", ")", ")", ":", "\n", "        ", "deduplicated_text_features", "[", "i", "]", "=", "all_text_features", "[", "coco_retrieval_dataloader", ".", "dataset", ".", "img2txt", "[", "i", "]", "[", "0", "]", "]", "\n", "\n", "", "return", "retrieval_metrics", ",", "all_image_features", ",", "deduplicated_text_features", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.get_retrieval_metrics": [[136, 182], ["numpy.zeros", "enumerate", "numpy.zeros", "enumerate", "eval_result.items", "len", "len", "len", "len", "len", "len", "float", "numpy.argsort", "len", "len", "len", "numpy.argsort", "len", "len", "len", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "get_retrieval_metrics", "(", "scores_img2text", ",", "scores_text2img", ",", "gt_img2text", ",", "gt_text2img", ")", ":", "\n", "\n", "#Images->Text ", "\n", "    ", "ranks", "=", "np", ".", "zeros", "(", "scores_img2text", ".", "shape", "[", "0", "]", ")", "\n", "for", "index", ",", "score", "in", "enumerate", "(", "scores_img2text", ")", ":", "\n", "        ", "inds", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "gt_img2text", "[", "index", "]", ":", "\n", "            ", "tmp", "=", "np", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "\n", "", "img2text_recall_at_1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "img2text_recall_at_5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "img2text_recall_at_10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "\n", "#Text->Images ", "\n", "ranks", "=", "np", ".", "zeros", "(", "scores_text2img", ".", "shape", "[", "0", "]", ")", "\n", "for", "index", ",", "score", "in", "enumerate", "(", "scores_text2img", ")", ":", "\n", "        ", "inds", "=", "np", ".", "argsort", "(", "score", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "index", "]", "=", "np", ".", "where", "(", "inds", "==", "gt_text2img", "[", "index", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "", "text2img_recall_at_1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "text2img_recall_at_5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "text2img_recall_at_10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "\n", "tr_mean", "=", "(", "img2text_recall_at_1", "+", "img2text_recall_at_5", "+", "img2text_recall_at_10", ")", "/", "3", "\n", "ir_mean", "=", "(", "text2img_recall_at_1", "+", "text2img_recall_at_5", "+", "text2img_recall_at_10", ")", "/", "3", "\n", "r_mean", "=", "(", "tr_mean", "+", "ir_mean", ")", "/", "2", "\n", "\n", "eval_result", "=", "{", "\n", "'image2text-R@1'", ":", "img2text_recall_at_1", ",", "\n", "'image2text-R@5'", ":", "img2text_recall_at_5", ",", "\n", "'image2text-R@10'", ":", "img2text_recall_at_10", ",", "\n", "#'image2text-R-mean': tr_mean,", "\n", "'text2image-R@1'", ":", "text2img_recall_at_1", ",", "\n", "'text2image-R@5'", ":", "text2img_recall_at_5", ",", "\n", "'text2image-R@10'", ":", "text2img_recall_at_10", ",", "\n", "#'text2image-R-mean': ir_mean,", "\n", "'mean-recall'", ":", "r_mean", "\n", "}", "\n", "\n", "for", "key", ",", "item", "in", "eval_result", ".", "items", "(", ")", ":", "\n", "        ", "eval_result", "[", "key", "]", "=", "float", "(", "item", ")", "\n", "", "return", "eval_result", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.zero_shot_classifier": [[17, 36], ["torch.no_grad", "torch.no_grad", "torch.stack", "torch.stack", "torch.normalize().mean", "F.normalize().mean.norm", "torch.stack.append", "template", "open_clip.tokenize.to", "torch.stack().to", "torch.stack().to", "model.module.encode_text", "model.encode_text", "F.normalize().mean.cpu", "torch.normalize", "open_clip.tokenize", "torch.stack", "torch.stack", "tokenizer"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_text", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.tokenizer.tokenize"], ["def", "zero_shot_classifier", "(", "model", ",", "classnames", ",", "templates", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "zeroshot_weights", "=", "[", "]", "\n", "for", "classname", "in", "classnames", ":", "\n", "            ", "texts", "=", "[", "template", "(", "classname", ")", "for", "template", "in", "templates", "]", "\n", "if", "tokenizer", "is", "None", ":", "\n", "                ", "texts", "=", "clip_tokenizer", "(", "texts", ")", ".", "to", "(", "args", ".", "device", ")", "#tokenize", "\n", "", "else", ":", "\n", "                ", "texts", "=", "torch", ".", "stack", "(", "[", "tokenizer", "(", "text", ")", "for", "text", "in", "texts", "]", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "", "if", "args", ".", "distributed", "and", "not", "args", ".", "horovod", ":", "\n", "                ", "class_embeddings", "=", "model", ".", "module", ".", "encode_text", "(", "texts", ")", "\n", "", "else", ":", "\n", "                ", "class_embeddings", "=", "model", ".", "encode_text", "(", "texts", ")", "\n", "", "class_embedding", "=", "F", ".", "normalize", "(", "class_embeddings", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "class_embedding", "/=", "class_embedding", ".", "norm", "(", ")", "\n", "zeroshot_weights", ".", "append", "(", "class_embedding", ".", "cpu", "(", ")", ")", "\n", "", "zeroshot_weights", "=", "torch", ".", "stack", "(", "zeroshot_weights", ",", "dim", "=", "1", ")", "#.to(args.device)", "\n", "", "return", "zeroshot_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.accuracy": [[38, 42], ["[].t", "[].t.eq", "target.view().expand_as", "float", "correct[].reshape().float().sum().cpu().numpy", "output.topk", "target.view", "max", "correct[].reshape().float().sum().cpu", "correct[].reshape().float().sum", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "pred", "=", "output", ".", "topk", "(", "max", "(", "topk", ")", ",", "1", ",", "True", ",", "True", ")", "[", "1", "]", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "return", "[", "float", "(", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "for", "k", "in", "topk", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.run": [[44, 78], ["torch.cat", "torch.cat", "torch.cat().numpy", "torch.cat().numpy", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "images.to.to", "torch.normalize", "model.encode_image.detach().cpu", "torch.cat.append", "torch.cat().numpy.append", "zero_shot.accuracy", "images.to.size", "torch.cat", "torch.cat", "model.module.encode_image", "model.encode_image", "model.encode_image.detach"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.accuracy", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image", "home.repos.pwc.inspect_result.megvii-research_protoclip.open_clip.model.CLIP.encode_image"], ["", "def", "run", "(", "model", ",", "classifier", ",", "dataloader", ",", "args", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "top1", ",", "top5", ",", "n", "=", "0.", ",", "0.", ",", "0.", "\n", "all_image_features", "=", "[", "]", "\n", "all_labels", "=", "[", "]", "\n", "for", "images", ",", "target", "in", "tqdm", ".", "tqdm", "(", "dataloader", ",", "unit_scale", "=", "args", ".", "batch_size", ")", ":", "\n", "            ", "images", "=", "images", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "distributed", "and", "not", "args", ".", "horovod", ":", "\n", "                ", "image_features", "=", "model", ".", "module", ".", "encode_image", "(", "images", ")", "\n", "", "else", ":", "\n", "                ", "image_features", "=", "model", ".", "encode_image", "(", "images", ")", "\n", "\n", "", "image_features", "=", "F", ".", "normalize", "(", "image_features", ",", "dim", "=", "-", "1", ")", "\n", "image_features", "=", "image_features", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "all_image_features", ".", "append", "(", "image_features", ")", "\n", "all_labels", ".", "append", "(", "target", ")", "\n", "\n", "logits", "=", "100.", "*", "image_features", "@", "classifier", "\n", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "logits", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "top1", "+=", "acc1", "\n", "top5", "+=", "acc5", "\n", "n", "+=", "images", ".", "size", "(", "0", ")", "\n", "\n", "", "", "top1", "=", "100.0", "*", "(", "top1", "/", "n", ")", "\n", "top5", "=", "100.0", "*", "(", "top5", "/", "n", ")", "\n", "\n", "all_image_features", "=", "torch", ".", "cat", "(", "all_image_features", ")", "\n", "all_labels", "=", "torch", ".", "cat", "(", "all_labels", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "return", "top1", ",", "top5", ",", "all_image_features", ",", "all_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.clustering_evaluation": [[79, 99], ["features.numpy().astype.numpy().astype", "faiss.Kmeans", "faiss.Kmeans.train", "faiss.Kmeans.index.search", "numpy.array", "numpy.reshape", "sklearn.metrics.cluster.adjusted_rand_score", "sklearn.metrics.adjusted_mutual_info_score", "features.numpy().astype.numpy", "int", "max"], "function", ["None"], ["", "def", "clustering_evaluation", "(", "features", ",", "labels", ")", ":", "\n", "\n", "    ", "features", "=", "features", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "kmeans", "=", "faiss", ".", "Kmeans", "(", "\n", "d", "=", "features", ".", "shape", "[", "1", "]", ",", "\n", "k", "=", "int", "(", "max", "(", "labels", ")", "+", "1", ")", ",", "\n", "niter", "=", "100", ",", "\n", "nredo", "=", "5", ",", "\n", "verbose", "=", "False", ",", "\n", "gpu", "=", "True", ")", "\n", "kmeans", ".", "train", "(", "features", ")", "\n", "\n", "distance", ",", "img_plabels", "=", "kmeans", ".", "index", ".", "search", "(", "features", ",", "1", ")", "\n", "img_plabels", "=", "np", ".", "array", "(", "img_plabels", ")", "\n", "img_plabels", "=", "np", ".", "reshape", "(", "img_plabels", ",", "img_plabels", ".", "shape", "[", "0", "]", ")", "\n", "\n", "ari", "=", "adjusted_rand_score", "(", "img_plabels", ",", "labels", ")", "\n", "ami", "=", "adjusted_mutual_info_score", "(", "img_plabels", ",", "labels", ")", "\n", "\n", "return", "ari", ",", "ami", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.zero_shot_eval": [[101, 156], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logging.info", "copy.deepcopy", "zero_shot.zero_shot_classifier", "logging.info", "zero_shot.run", "zero_shot.clustering_evaluation", "logging.info", "logging.info", "results.items", "torchvision.datasets.CIFAR10", "float", "torchvision.datasets.CIFAR100", "torchvision.datasets.STL10", "logging.info", "torchvision.datasets.ImageFolder"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.zero_shot_classifier", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.run", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.clustering_evaluation"], ["", "def", "zero_shot_eval", "(", "model", ",", "zeroshot_dataset", ",", "epoch", ",", "preprocess", ",", "tokenizer", ",", "args", ")", ":", "\n", "\n", "    ", "if", "args", ".", "zeroshot_frequency", "==", "0", ":", "\n", "        ", "return", "{", "}", "\n", "", "if", "(", "epoch", "%", "args", ".", "zeroshot_frequency", ")", "!=", "0", "and", "epoch", "!=", "args", ".", "epochs", ":", "\n", "        ", "return", "{", "}", "\n", "", "if", "zeroshot_dataset", "==", "'cifar10'", ":", "\n", "        ", "dataset", "=", "CIFAR10", "(", "root", "=", "args", ".", "eval_data_dir", ",", "download", "=", "True", ",", "train", "=", "False", ",", "transform", "=", "preprocess", ")", "\n", "", "elif", "zeroshot_dataset", "==", "'cifar100'", ":", "\n", "        ", "dataset", "=", "CIFAR100", "(", "root", "=", "args", ".", "eval_data_dir", ",", "download", "=", "True", ",", "train", "=", "False", ",", "transform", "=", "preprocess", ")", "\n", "", "elif", "zeroshot_dataset", "==", "'stl10'", ":", "\n", "        ", "dataset", "=", "STL10", "(", "root", "=", "args", ".", "eval_data_dir", ",", "download", "=", "True", ",", "split", "=", "'test'", ",", "transform", "=", "preprocess", ")", "\n", "", "else", ":", "\n", "# for ['birdsnap', 'country211', 'flowers102', 'gtsrb', 'stanford_cars', 'ucf101']", "\n", "        ", "data_path", "=", "f'{args.eval_data_dir}/{zeroshot_dataset}/test'", "\n", "if", "zeroshot_dataset", "==", "'ucf101'", ":", "\n", "            ", "data_path", "+=", "'list01'", "\n", "", "logging", ".", "info", "(", "f'Loading data from  {data_path}'", ")", "\n", "\n", "dataset", "=", "torchvision", ".", "datasets", ".", "ImageFolder", "(", "data_path", ",", "transform", "=", "preprocess", ")", "\n", "\n", "", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "\n", "logging", ".", "info", "(", "f'Calculating text classifier for {zeroshot_dataset}'", ")", "\n", "classnames", ",", "prompt_templates", "=", "get_class_names_and_templets", "[", "zeroshot_dataset", "]", "\n", "import", "copy", "\n", "classnames", "=", "copy", ".", "deepcopy", "(", "classnames", ")", "\n", "if", "zeroshot_dataset", "==", "'birdsnap'", ":", "\n", "# https://github.com/ml-jku/cloob/issues/10", "\n", "# FileNotFoundError: Found no valid file for the classes 046, 066, 123, 299, 302, 351, 403, 436, 465", "\n", "# these empty folders are removed", "\n", "        ", "empty_indexs", "=", "[", "46", ",", "66", ",", "123", ",", "299", ",", "302", ",", "351", ",", "403", ",", "436", ",", "465", "]", "\n", "for", "empty_index", "in", "empty_indexs", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "del", "classnames", "[", "empty_index", "]", "\n", "", "", "classifier", "=", "zero_shot_classifier", "(", "model", ",", "classnames", ",", "prompt_templates", ",", "tokenizer", ",", "args", ")", "\n", "\n", "logging", ".", "info", "(", "f'Calculating image features for {zeroshot_dataset}'", ")", "\n", "results", "=", "{", "}", "\n", "top1", ",", "top5", ",", "features", ",", "labels", "=", "run", "(", "model", ",", "classifier", ",", "dataloader", ",", "args", ")", "\n", "ari", ",", "ami", "=", "clustering_evaluation", "(", "features", ",", "labels", ")", "\n", "logging", ".", "info", "(", "f'{zeroshot_dataset} zero-shot accuracy: {top1:.2f}% (top5: {top5:.2f}%)'", ")", "\n", "logging", ".", "info", "(", "f'{zeroshot_dataset} clustering evaluation: ARI: {ari:.4f}, AMI:{ami:.4f}'", ")", "\n", "\n", "\n", "results", "[", "f'{zeroshot_dataset}-zeroshot-accuracy-top1'", "]", "=", "top1", "\n", "results", "[", "f'{zeroshot_dataset}-zeroshot-accuracy-top5'", "]", "=", "top5", "\n", "results", "[", "f'{zeroshot_dataset}-adjusted-rand-index'", "]", "=", "ari", "\n", "results", "[", "f'{zeroshot_dataset}-adjusted-mutual-info'", "]", "=", "ami", "\n", "\n", "\n", "for", "key", ",", "item", "in", "results", ".", "items", "(", ")", ":", "\n", "        ", "results", "[", "key", "]", "=", "float", "(", "item", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.analyze_features": [[5, 22], ["analyze_features..", "analyze_features..", "analyze_features.get_modality_gap", "float", "float", "torch.std().mean().item", "torch.std().mean().item", "torch.std().mean", "torch.std().mean", "torch.std", "torch.std"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.get_modality_gap"], ["def", "analyze_features", "(", "all_image_features", ",", "all_text_features", ",", "args", ")", ":", "\n", "    ", "if", "all_image_features", "is", "None", "or", "all_text_features", "is", "None", ":", "\n", "        ", "return", "{", "}", "\n", "\n", "", "image_avg_sim", "=", "get_self_cosine_similarity", "(", "all_image_features", ")", "\n", "text_avg_sim", "=", "get_self_cosine_similarity", "(", "all_text_features", ")", "\n", "modality_gap", "=", "get_modality_gap", "(", "all_image_features", ",", "all_text_features", ")", "\n", "\n", "results", "=", "{", "\n", "'image_avg_self_similarity'", ":", "image_avg_sim", ",", "\n", "'text_avg_self_similarity'", ":", "text_avg_sim", ",", "\n", "'modality_gap'", ":", "modality_gap", ",", "\n", "'image_feature_std'", ":", "float", "(", "torch", ".", "std", "(", "all_image_features", ",", "dim", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", ",", "\n", "'text_feature_std'", ":", "float", "(", "torch", ".", "std", "(", "all_text_features", ",", "dim", "=", "0", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", ",", "\n", "}", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.get_self_cosine_similarity": [[24, 31], ["features.numpy.numpy", "sklearn.metrics.pairwise.cosine_similarity().flatten", "float", "numpy.average", "sklearn.metrics.pairwise.cosine_similarity"], "function", ["None"], ["", "def", "get_self_cosine_similarity", "(", "features", ")", ":", "\n", "# reimplement Figure 2(a) in https://arxiv.org/abs/2203.02053v1 ", "\n", "    ", "features", "=", "features", ".", "numpy", "(", ")", "\n", "similarities", "=", "cosine_similarity", "(", "features", ",", "features", ")", ".", "flatten", "(", ")", "\n", "similarities", "=", "similarities", "[", "similarities", ">", "0", "]", "\n", "\n", "return", "float", "(", "np", ".", "average", "(", "similarities", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.get_modality_gap": [[33, 40], ["torch.mean", "torch.mean", "float", "delta_gap.norm().item", "delta_gap.norm"], "function", ["None"], ["", "def", "get_modality_gap", "(", "all_image_features", ",", "all_text_features", ")", ":", "\n", "# reimplement the \"modaility gap\" in Section 4.2 of https://arxiv.org/abs/2203.02053v1 ", "\n", "    ", "mean_image_feature", "=", "torch", ".", "mean", "(", "all_image_features", ",", "dim", "=", "0", ")", "\n", "mean_text_feature", "=", "torch", ".", "mean", "(", "all_text_features", ",", "dim", "=", "0", ")", "\n", "delta_gap", "=", "mean_image_feature", "-", "mean_text_feature", "\n", "\n", "return", "float", "(", "delta_gap", ".", "norm", "(", ")", ".", "item", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.evaluation.evaluate": [[15, 79], ["logging.info", "model.eval", "metrics.items", "coco_retrieval.coco_retrieval_evaluation", "metrics.update", "all_metrics.update", "metrics.items", "analyze_features.analyze_features", "all_metrics.update", "analyze_features.analyze_features.items", "logging.info", "metrics.items", "training.distributed.is_master", "zero_shot.zero_shot_eval", "metrics.update", "all_metrics.update", "linear_eval.linear_eval", "metrics.update", "all_metrics.update", "tb_writer.add_scalar", "wandb.log", "tb_writer.add_scalar", "wandb.log", "tb_writer.add_scalar", "wandb.log", "tb_writer.add_scalar", "wandb.log", "open", "f.write", "f.write", "os.path.join", "json.dumps", "all_metrics.items"], "function", ["home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.coco_retrieval.coco_retrieval_evaluation", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.analyze_features.analyze_features", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.distributed.is_master", "home.repos.pwc.inspect_result.megvii-research_protoclip.evaluations.zero_shot.zero_shot_eval", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update", "home.repos.pwc.inspect_result.megvii-research_protoclip.training.train.AverageMeter.update"], ["", "def", "evaluate", "(", "model", ",", "epoch", ",", "preprocess", ",", "tokenizer", ",", "args", ",", "tb_writer", "=", "None", ")", ":", "\n", "    ", "if", "not", "is_master", "(", "args", ")", ":", "\n", "        ", "return", "\n", "", "logging", ".", "info", "(", "f\"Starting evaluation of [{args.name}] at epoch {epoch}\"", ")", "\n", "\n", "linear_eval_datasets", "=", "[", "'imagenet'", ",", "'cifar10'", ",", "'cifar100'", ",", "'stl10'", "]", "\n", "zeroshot_datasets", "=", "[", "'imagenet'", ",", "'cifar10'", ",", "'cifar100'", ",", "'stl10'", ",", "'birdsnap'", ",", "'country211'", ",", "'flowers102'", ",", "'gtsrb'", ",", "'ucf101'", ",", "'stanford_cars'", "]", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "all_metrics", "=", "{", "}", "\n", "\n", "# zeroshot classification", "\n", "metrics", "=", "{", "}", "\n", "for", "zeroshot_dataset", "in", "zeroshot_datasets", ":", "\n", "        ", "zeroshot_metrics", "=", "zero_shot_eval", "(", "model", ",", "zeroshot_dataset", ",", "epoch", ",", "preprocess", ",", "tokenizer", ",", "args", ")", "\n", "metrics", ".", "update", "(", "zeroshot_metrics", ")", "\n", "all_metrics", ".", "update", "(", "zeroshot_metrics", ")", "\n", "", "for", "name", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "if", "tb_writer", "is", "not", "None", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "f\"eval_zero_shot/{name}\"", ",", "val", ",", "epoch", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "            ", "wandb", ".", "log", "(", "{", "f\"eval_zero_shot/{name}\"", ":", "val", ",", "'epoch'", ":", "epoch", "}", ")", "\n", "\n", "# MS-COCO retrieval", "\n", "", "", "metrics", "=", "{", "}", "\n", "retrieval_metrics", ",", "all_image_features", ",", "all_text_features", "=", "coco_retrieval_evaluation", "(", "model", ",", "epoch", ",", "preprocess", ",", "tokenizer", ",", "args", ")", "\n", "metrics", ".", "update", "(", "retrieval_metrics", ")", "\n", "all_metrics", ".", "update", "(", "retrieval_metrics", ")", "\n", "for", "name", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "if", "tb_writer", "is", "not", "None", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "f\"eval_retrieval/{name}\"", ",", "val", ",", "epoch", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "            ", "wandb", ".", "log", "(", "{", "f\"eval_retrieval/{name}\"", ":", "val", ",", "'epoch'", ":", "epoch", "}", ")", "\n", "\n", "# Analyse COCO features", "\n", "", "", "feature_metrics", "=", "analyze_features", "(", "all_image_features", ",", "all_text_features", ",", "args", ")", "\n", "all_metrics", ".", "update", "(", "feature_metrics", ")", "\n", "for", "name", ",", "val", "in", "feature_metrics", ".", "items", "(", ")", ":", "\n", "        ", "if", "tb_writer", "is", "not", "None", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "f\"eval_analyze_features/{name}\"", ",", "val", ",", "epoch", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "            ", "wandb", ".", "log", "(", "{", "f\"eval_analyze_features/{name}\"", ":", "val", ",", "'epoch'", ":", "epoch", "}", ")", "\n", "\n", "# linear evaluation", "\n", "", "", "metrics", "=", "{", "}", "\n", "if", "linear_eval_datasets", ":", "\n", "        ", "linear_metrics", "=", "linear_eval", "(", "model", ",", "linear_eval_datasets", ",", "epoch", ",", "preprocess", ",", "args", ")", "\n", "metrics", ".", "update", "(", "linear_metrics", ")", "\n", "all_metrics", ".", "update", "(", "linear_metrics", ")", "\n", "\n", "", "logging", ".", "info", "(", "f\"Finished evaluation of [{args.name}] at epoch {epoch}\\n\"", "+", "\"\\n\"", ".", "join", "(", "[", "f\"\\t{k}\\t{v}\"", "for", "k", ",", "v", "in", "all_metrics", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "for", "name", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "if", "tb_writer", "is", "not", "None", ":", "\n", "            ", "tb_writer", ".", "add_scalar", "(", "f\"eval_linear_prob/{name}\"", ",", "val", ",", "epoch", ")", "\n", "", "if", "args", ".", "wandb", ":", "\n", "            ", "wandb", ".", "log", "(", "{", "f\"eval_linear_prob/{name}\"", ":", "val", ",", "'epoch'", ":", "epoch", "}", ")", "\n", "\n", "", "", "if", "args", ".", "save_logs", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "logs", ",", "args", ".", "name", ",", "\"results.jsonl\"", ")", ",", "\"a+\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "all_metrics", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_metrics", "\n", "", ""]]}