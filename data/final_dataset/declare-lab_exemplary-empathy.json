{"home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGMainModel.__init__": [[11, 37], ["torch.nn.Module.__init__", "models.ERGModel", "models.T5EncoderClassifier", "models.ERGMainModel.empathy_classifier_model1.load_state_dict", "models.T5EncoderClassifier", "models.ERGMainModel.empathy_classifier_model2.load_state_dict", "models.T5EncoderClassifier", "models.ERGMainModel.empathy_classifier_model3.load_state_dict", "models.T5EncoderRegressor", "models.ERGMainModel.sentiment_regression_model.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "models.ERGMainModel.empathy_classifier_model1.parameters", "models.ERGMainModel.empathy_classifier_model2.parameters", "models.ERGMainModel.empathy_classifier_model3.parameters", "models.ERGMainModel.sentiment_regression_model.parameters"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_model_name", ",", "max_source_length", ",", "max_target_length", ",", "strategy", ",", "exemplars", "=", "False", ",", "max_exemplars", "=", "None", ",", "fixed", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "erg_model", "=", "ERGModel", "(", "base_model_name", ",", "max_source_length", ",", "max_target_length", ",", "exemplars", ",", "max_exemplars", ")", "\n", "\n", "self", ".", "empathy_classifier_model1", "=", "T5EncoderClassifier", "(", "\"base\"", ",", "2", ",", "strategy", ")", "\n", "self", ".", "empathy_classifier_model1", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"saved/empathy/1619600015/model.pt\"", ")", ")", "\n", "\n", "self", ".", "empathy_classifier_model2", "=", "T5EncoderClassifier", "(", "\"base\"", ",", "2", ",", "strategy", ")", "\n", "self", ".", "empathy_classifier_model2", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"saved/empathy/1619600805/model.pt\"", ")", ")", "\n", "\n", "self", ".", "empathy_classifier_model3", "=", "T5EncoderClassifier", "(", "\"base\"", ",", "2", ",", "strategy", ")", "\n", "self", ".", "empathy_classifier_model3", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"saved/empathy/1619601340/model.pt\"", ")", ")", "\n", "\n", "self", ".", "sentiment_regression_model", "=", "T5EncoderRegressor", "(", "\"base\"", ",", "strategy", ")", "\n", "self", ".", "sentiment_regression_model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"saved/sentiment/1620236944/model.pt\"", ")", ")", "\n", "\n", "self", ".", "fixed", "=", "fixed", "\n", "if", "self", ".", "fixed", ":", "\n", "            ", "for", "param", "in", "self", ".", "empathy_classifier_model1", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "empathy_classifier_model2", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "empathy_classifier_model3", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "for", "param", "in", "self", ".", "sentiment_regression_model", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGMainModel.forward": [[38, 55], ["models.ERGMainModel.erg_model", "models.ERGMainModel.empathy_classifier_model1.output_from_logits", "models.ERGMainModel.empathy_classifier_model2.output_from_logits", "models.ERGMainModel.empathy_classifier_model3.output_from_logits", "models.ERGMainModel.sentiment_regression_model.output_from_logits", "models.ERGMainModel.empathy_classifier_model1.eval", "models.ERGMainModel.empathy_classifier_model2.eval", "models.ERGMainModel.empathy_classifier_model3.eval", "models.ERGMainModel.sentiment_regression_model.eval"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.output_from_logits", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.output_from_logits", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.output_from_logits", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.output_from_logits"], ["", "", "", "def", "forward", "(", "self", ",", "context", ",", "response", ",", "exemplars", ",", "padding", "=", "True", ",", "ignore_pad_token_for_loss", "=", "True", ")", ":", "\n", "        ", "output", ",", "tokenized_response", "=", "self", ".", "erg_model", "(", "context", ",", "response", ",", "exemplars", ",", "padding", ",", "ignore_pad_token_for_loss", ")", "\n", "logits", "=", "output", "[", "\"logits\"", "]", "\n", "response_mask", "=", "tokenized_response", "[", "\"attention_mask\"", "]", "\n", "merged_context", "=", "[", "\" \"", ".", "join", "(", "conv", ")", "for", "conv", "in", "context", "]", "\n", "\n", "if", "self", ".", "fixed", ":", "\n", "            ", "self", ".", "empathy_classifier_model1", ".", "eval", "(", ")", "\n", "self", ".", "empathy_classifier_model2", ".", "eval", "(", ")", "\n", "self", ".", "empathy_classifier_model3", ".", "eval", "(", ")", "\n", "self", ".", "sentiment_regression_model", ".", "eval", "(", ")", "\n", "\n", "", "empathy1_preds", "=", "self", ".", "empathy_classifier_model1", ".", "output_from_logits", "(", "merged_context", ",", "logits", ",", "response_mask", ")", "\n", "empathy2_preds", "=", "self", ".", "empathy_classifier_model2", ".", "output_from_logits", "(", "merged_context", ",", "logits", ",", "response_mask", ")", "\n", "empathy3_preds", "=", "self", ".", "empathy_classifier_model3", ".", "output_from_logits", "(", "merged_context", ",", "logits", ",", "response_mask", ")", "\n", "sentiment_preds", "=", "self", ".", "sentiment_regression_model", ".", "output_from_logits", "(", "logits", ",", "response_mask", ")", "\n", "return", "output", ",", "empathy1_preds", ",", "empathy2_preds", ",", "empathy3_preds", ",", "sentiment_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.__init__": [[58, 84], ["torch.nn.Module.__init__", "transformers.T5Tokenizer.from_pretrained", "models.ERGModel.base_model.state_dict", "torch.nn.Embedding", "torch.nn.Embedding", "open", "transformers.T5ForConditionalGeneration", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "torch.nn.Linear", "torch.nn.Linear", "models.ERGModel.exemplar_model.parameters", "transformers.T5Config", "len", "json.load", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "model_weights[].size"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_model_name", ",", "max_source_length", ",", "max_target_length", ",", "\n", "exemplars", "=", "False", ",", "max_exemplars", "=", "None", ")", ":", "\n", "        ", "super", "(", "ERGModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "max_source_length", ",", "self", ".", "max_target_length", "=", "max_source_length", ",", "max_target_length", "\n", "assert", "\"t5\"", "in", "base_model_name", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "base_model_name", ")", "\n", "\n", "# self.base_model = T5ForConditionalGeneration.from_pretrained(base_model_name)", "\n", "\n", "with", "open", "(", "\"t5-config/\"", "+", "base_model_name", "+", "\".json\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "base_model", "=", "T5ForConditionalGeneration", "(", "T5Config", "(", "**", "json", ".", "load", "(", "f", ")", ")", ")", "\n", "", "model_weights", "=", "self", ".", "base_model", ".", "state_dict", "(", ")", "\n", "for", "key", "in", "model_weights", ":", "\n", "            ", "if", "len", "(", "model_weights", "[", "key", "]", ".", "shape", ")", ">=", "2", ":", "\n", "                ", "model_weights", "[", "key", "]", "=", "2", "*", "torch", ".", "rand", "(", "model_weights", "[", "key", "]", ".", "size", "(", ")", ")", "-", "1", "\n", "\n", "", "", "self", ".", "speaker_embedding", "=", "nn", ".", "Embedding", "(", "3", ",", "self", ".", "base_model", ".", "encoder", ".", "embed_tokens", ".", "embedding_dim", ",", "\n", "padding_idx", "=", "0", ")", "\n", "self", ".", "speaker_embedding", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "exemplars", ":", "\n", "            ", "self", ".", "exemplar_tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\"Vamsi/T5_Paraphrase_Paws\"", ")", "\n", "self", ".", "exemplar_model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\"Vamsi/T5_Paraphrase_Paws\"", ")", "\n", "self", ".", "transform_to_t5_decoder", "=", "nn", ".", "Linear", "(", "self", ".", "base_model", ".", "encoder", ".", "embed_tokens", ".", "embedding_dim", "+", "self", ".", "exemplar_model", ".", "encoder", ".", "embed_tokens", ".", "embedding_dim", ",", "self", ".", "base_model", ".", "encoder", ".", "embed_tokens", ".", "embedding_dim", ")", "\n", "self", ".", "max_exemplars", "=", "999", "if", "max_exemplars", "is", "None", "else", "max_exemplars", "\n", "for", "param", "in", "self", ".", "exemplar_model", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._get_speaker_mask": [[85, 99], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "speaker_mask.append", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["", "", "", "def", "_get_speaker_mask", "(", "self", ",", "speaker_span_lens", ",", "mask_length", ")", ":", "\n", "        ", "speaker_mask", "=", "[", "]", "\n", "for", "diag", "in", "speaker_span_lens", ":", "\n", "            ", "diag_mask", "=", "[", "]", "\n", "speaker", "=", "0", "\n", "for", "utt_len", "in", "diag", ":", "\n", "                ", "diag_mask", "+=", "[", "speaker", "+", "1", "]", "*", "utt_len", "\n", "speaker", "=", "(", "speaker", "+", "1", ")", "%", "2", "\n", "", "if", "mask_length", ">=", "len", "(", "diag_mask", ")", ":", "\n", "                ", "diag_mask", "+=", "[", "0", "]", "*", "(", "mask_length", "-", "len", "(", "diag_mask", ")", ")", "\n", "", "else", ":", "\n", "                ", "diag_mask", "=", "diag_mask", "[", ":", "mask_length", "]", "\n", "", "speaker_mask", ".", "append", "(", "diag_mask", ")", "\n", "", "return", "torch", ".", "tensor", "(", "speaker_mask", ")", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._tokenize_input": [[100, 114], ["models.ERGModel.tokenizer", "inputs[].to", "inputs[].to", "models.ERGModel._get_speaker_mask", "models.ERGModel.tokenizer", "speaker_span_lens.append", "len"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._get_speaker_mask"], ["", "def", "_tokenize_input", "(", "self", ",", "context", ",", "max_length", ",", "padding", "=", "True", ",", "truncation", "=", "True", ")", ":", "\n", "# Append prefix", "\n", "# context = [prefix + inp for inp in context]", "\n", "        ", "cat_context", "=", "[", "\" \"", ".", "join", "(", "inp", ")", "for", "inp", "in", "context", "]", "\n", "speaker_span_lens", "=", "[", "]", "\n", "for", "diag", "in", "context", ":", "\n", "            ", "tokenized", "=", "self", ".", "tokenizer", "(", "diag", ")", "\n", "speaker_span_lens", ".", "append", "(", "[", "len", "(", "utt", ")", "-", "1", "for", "utt", "in", "tokenized", "[", "\"input_ids\"", "]", "]", ")", "\n", "# Setup the tokenizer for source", "\n", "", "inputs", "=", "self", ".", "tokenizer", "(", "cat_context", ",", "max_length", "=", "self", ".", "max_source_length", ",", "padding", "=", "padding", ",", "truncation", "=", "truncation", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "inputs", "[", "\"input_ids\"", "]", "=", "inputs", "[", "\"input_ids\"", "]", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", "\n", "inputs", "[", "\"attention_mask\"", "]", "=", "inputs", "[", "\"attention_mask\"", "]", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", "\n", "inputs", "[", "\"speaker_mask\"", "]", "=", "self", ".", "_get_speaker_mask", "(", "speaker_span_lens", ",", "inputs", "[", "\"attention_mask\"", "]", ".", "shape", "[", "1", "]", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._preprocess": [[115, 131], ["models.ERGModel._tokenize_input", "models.ERGModel.tokenizer.as_target_tokenizer", "models.ERGModel.tokenizer", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._tokenize_input"], ["", "def", "_preprocess", "(", "self", ",", "context", ",", "response", "=", "None", ",", "padding", "=", "True", ",", "ignore_pad_token_for_loss", "=", "True", ")", ":", "\n", "        ", "\"Preprocess data\"", "\n", "\n", "inputs", "=", "self", ".", "_tokenize_input", "(", "context", ",", "max_length", "=", "self", ".", "max_source_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "# Setup the tokenizer for targets", "\n", "with", "self", ".", "tokenizer", ".", "as_target_tokenizer", "(", ")", ":", "\n", "            ", "labels", "=", "self", ".", "tokenizer", "(", "response", ",", "max_length", "=", "self", ".", "max_target_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore", "\n", "# padding in the loss.", "\n", "", "if", "padding", "and", "ignore_pad_token_for_loss", ":", "\n", "            ", "labels", "[", "\"input_ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "\n", "[", "(", "l", "if", "l", "!=", "self", ".", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "l", "in", "label", "]", "for", "label", "in", "labels", "[", "\"input_ids\"", "]", "\n", "]", ")", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", "\n", "\n", "", "return", "inputs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._exemplar_mean_pool_representation": [[132, 147], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "models.ERGModel.exemplar_tokenizer", "models.ERGModel.exemplar_model.encoder", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "exemplar_representations.append", "exemplars_inputs[].to", "exemplars_inputs[].to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "_exemplar_mean_pool_representation", "(", "self", ",", "exemplars", ")", ":", "\n", "        ", "exemplar_representations", "=", "[", "]", "\n", "for", "samples", "in", "exemplars", ":", "\n", "            ", "samples", "=", "[", "f\"paraphrase: {x}\"", "for", "x", "in", "samples", "[", ":", "self", ".", "max_exemplars", "]", "]", "\n", "exemplars_inputs", "=", "self", ".", "exemplar_tokenizer", "(", "samples", ",", "max_length", "=", "self", ".", "max_source_length", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "exemplar_input_ids", ",", "exemplar_attention_masks", "=", "exemplars_inputs", "[", "\"input_ids\"", "]", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", ",", "exemplars_inputs", "[", "\"attention_mask\"", "]", ".", "to", "(", "self", ".", "speaker_embedding", ".", "weight", ".", "device", ")", "\n", "encoder_output", "=", "self", ".", "exemplar_model", ".", "encoder", "(", "\n", "input_ids", "=", "exemplar_input_ids", ",", "\n", "attention_mask", "=", "exemplar_attention_masks", "\n", ")", "\n", "hidden_states", "=", "encoder_output", "[", "0", "]", "*", "exemplar_attention_masks", "[", ":", ",", ":", ",", "None", "]", "\n", "hidden_states", "=", "torch", ".", "sum", "(", "hidden_states", ",", "dim", "=", "1", ")", "/", "torch", ".", "sum", "(", "exemplar_attention_masks", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "hidden_states", "=", "torch", ".", "mean", "(", "hidden_states", ",", "dim", "=", "0", ")", "\n", "exemplar_representations", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "torch", ".", "stack", "(", "exemplar_representations", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.forward": [[148, 177], ["models.ERGModel._preprocess", "models.ERGModel.exemplar_model.eval", "models.ERGModel.base_model.encoder.embed_tokens", "models.ERGModel.speaker_embedding", "models.ERGModel.base_model", "models.ERGModel.base_model.encoder", "models.ERGModel._exemplar_mean_pool_representation", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.ERGModel.transform_to_t5_decoder", "models.ERGModel.base_model", "hasattr", "hasattr", "models.ERGModel.unsqueeze().expand", "models.ERGModel.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._preprocess", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._exemplar_mean_pool_representation"], ["", "def", "forward", "(", "self", ",", "context", ",", "response", ",", "exemplars", "=", "None", ",", "padding", "=", "True", ",", "ignore_pad_token_for_loss", "=", "True", ")", ":", "\n", "# assert exemplars is None or (hasattr(self, \"exemplar_tokenizer\") and hasattr(self, \"exemplar_model\"))", "\n", "        ", "inputs", ",", "labels", "=", "self", ".", "_preprocess", "(", "context", ",", "response", ",", "padding", ",", "ignore_pad_token_for_loss", ")", "\n", "self", ".", "exemplar_model", ".", "eval", "(", ")", "\n", "inputs_embeds", "=", "self", ".", "base_model", ".", "encoder", ".", "embed_tokens", "(", "inputs", "[", "\"input_ids\"", "]", ")", "+", "self", ".", "speaker_embedding", "(", "inputs", "[", "\"speaker_mask\"", "]", ")", "\n", "if", "not", "(", "hasattr", "(", "self", ",", "\"exemplar_tokenizer\"", ")", "and", "hasattr", "(", "self", ",", "\"exemplar_model\"", ")", ")", ":", "\n", "            ", "out", "=", "self", ".", "base_model", "(", "\n", "# input_ids=inputs[\"input_ids\"],", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "labels", "=", "labels", "[", "\"input_ids\"", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "encoder_output", "=", "self", ".", "base_model", ".", "encoder", "(", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", "\n", ")", "\n", "hidden_states", "=", "encoder_output", "[", "0", "]", "\n", "exemplar_representations", "=", "self", ".", "_exemplar_mean_pool_representation", "(", "exemplars", ")", "\n", "hidden_states", "=", "torch", ".", "cat", "(", "[", "hidden_states", ",", "\n", "exemplar_representations", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "hidden_states", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "]", ",", "\n", "dim", "=", "2", ")", "\n", "decoder_input", "=", "self", ".", "transform_to_t5_decoder", "(", "hidden_states", ")", "\n", "out", "=", "self", ".", "base_model", "(", "\n", "encoder_outputs", "=", "[", "decoder_input", "]", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "labels", "=", "labels", "[", "\"input_ids\"", "]", "\n", ")", "\n", "", "return", "out", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate": [[178, 243], ["models.ERGModel._tokenize_input", "models.ERGModel.base_model.encoder.embed_tokens", "models.ERGModel.speaker_embedding", "models.ERGModel.base_model.encoder", "models.ERGModel._exemplar_mean_pool_representation", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.ERGModel.transform_to_t5_decoder", "models.ERGModel.tokenizer.decode", "hasattr", "hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.ERGModel.base_model.generate", "models.ERGModel.unsqueeze().expand", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.ERGModel.base_model.generate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.ERGModel.base_model.generate", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.ERGModel.base_model.generate", "models.ERGModel.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._tokenize_input", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel._exemplar_mean_pool_representation", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate"], ["", "def", "generate", "(", "self", ",", "context", ",", "exemplars", "=", "None", ",", "mode", "=", "\"topk\"", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_tokenize_input", "(", "context", ",", "max_length", "=", "self", ".", "max_source_length", ",", "padding", "=", "True", ",", "truncation", "=", "True", ")", "\n", "inputs_embeds", "=", "self", ".", "base_model", ".", "encoder", ".", "embed_tokens", "(", "inputs", "[", "\"input_ids\"", "]", ")", "+", "self", ".", "speaker_embedding", "(", "inputs", "[", "\"speaker_mask\"", "]", ")", "\n", "if", "not", "(", "hasattr", "(", "self", ",", "\"exemplar_tokenizer\"", ")", "and", "hasattr", "(", "self", ",", "\"exemplar_model\"", ")", ")", ":", "\n", "            ", "if", "mode", "==", "\"topk\"", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "generated", "=", "self", ".", "base_model", ".", "generate", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "max_length", "=", "20", ",", "\n", "do_sample", "=", "True", ",", "\n", "top_k", "=", "20", ",", "\n", "temperature", "=", "0.9", ",", "\n", "early_stopping", "=", "True", ",", "\n", "num_return_sequences", "=", "1", ")", "\n", "", "", "elif", "mode", "==", "\"beam\"", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "generated", "=", "self", ".", "base_model", ".", "generate", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "max_length", "=", "20", ",", "\n", "num_beams", "=", "8", ",", "\n", "early_stopping", "=", "True", ",", "\n", "num_return_sequences", "=", "1", ")", "\n", "", "", "", "else", ":", "\n", "            ", "encoder_output", "=", "self", ".", "base_model", ".", "encoder", "(", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", "\n", ")", "\n", "hidden_states", "=", "encoder_output", "[", "0", "]", "\n", "exemplar_representations", "=", "self", ".", "_exemplar_mean_pool_representation", "(", "exemplars", ")", "\n", "hidden_states", "=", "torch", ".", "cat", "(", "[", "hidden_states", ",", "\n", "exemplar_representations", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "hidden_states", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "]", ",", "\n", "dim", "=", "2", ")", "\n", "decoder_input", "=", "self", ".", "transform_to_t5_decoder", "(", "hidden_states", ")", "\n", "encoder_output", "[", "\"last_hidden_state\"", "]", "=", "decoder_input", "\n", "if", "mode", "==", "\"topk\"", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "generated", "=", "self", ".", "base_model", ".", "generate", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "encoder_outputs", "=", "encoder_output", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "max_length", "=", "20", ",", "\n", "do_sample", "=", "True", ",", "\n", "top_k", "=", "20", ",", "\n", "temperature", "=", "0.9", ",", "\n", "early_stopping", "=", "True", ",", "\n", "num_return_sequences", "=", "1", ")", "\n", "", "", "elif", "mode", "==", "\"beam\"", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "generated", "=", "self", ".", "base_model", ".", "generate", "(", "\n", "input_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "encoder_outputs", "=", "encoder_output", ",", "\n", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "\n", "max_length", "=", "20", ",", "\n", "num_beams", "=", "8", ",", "\n", "early_stopping", "=", "True", ",", "\n", "num_return_sequences", "=", "1", ")", "\n", "\n", "\n", "", "", "", "hyp", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "g", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "for", "g", "in", "generated", "]", "\n", "return", "hyp", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderClassifier.__init__": [[246, 258], ["torch.nn.Module.__init__", "transformers.T5Tokenizer.from_pretrained", "transformers.T5EncoderModel.from_pretrained", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "num_labels", "=", "2", ",", "strategy", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "size", "==", "\"base\"", ":", "\n", "            ", "in_features", "=", "768", "\n", "", "elif", "size", "==", "\"large\"", ":", "\n", "            ", "in_features", "=", "1024", "\n", "\n", "", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "\"t5-\"", "+", "size", ")", "\n", "self", ".", "model", "=", "T5EncoderModel", ".", "from_pretrained", "(", "\"t5-\"", "+", "size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "in_features", ",", "num_labels", ")", "\n", "self", ".", "strategy", "=", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderClassifier.forward": [[259, 267], ["models.T5EncoderClassifier.tokenizer", "models.T5EncoderClassifier.model", "models.T5EncoderClassifier.classifier", "zip", "batch[].cuda", "batch[].cuda"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "context", ",", "response", ")", ":", "\n", "        ", "max_len", "=", "768", "\n", "data", "=", "[", "[", "x", ",", "y", "]", "for", "x", ",", "y", "in", "zip", "(", "context", ",", "response", ")", "]", "\n", "batch", "=", "self", ".", "tokenizer", "(", "data", ",", "max_length", "=", "max_len", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "cuda", "(", ")", ",", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "cuda", "(", ")", ")", "\n", "sequence_output", "=", "outputs", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderClassifier.convert_to_probabilities": [[268, 276], ["torch.softmax", "torch.softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax"], "methods", ["None"], ["", "def", "convert_to_probabilities", "(", "self", ",", "logits", ")", ":", "\n", "        ", "if", "self", ".", "strategy", "==", "0", ":", "\n", "            ", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "1", ")", "\n", "", "elif", "self", ".", "strategy", "==", "1", ":", "\n", "            ", "probs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "False", ")", "\n", "", "elif", "self", ".", "strategy", "==", "2", ":", "\n", "            ", "probs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "True", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderClassifier.output_from_logits": [[277, 304], ["models.T5EncoderClassifier.tokenizer", "batch[].cuda", "batch[].cuda", "models.T5EncoderClassifier.model.encoder.embed_tokens", "models.T5EncoderClassifier.convert_to_probabilities", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.T5EncoderClassifier.model", "models.T5EncoderClassifier.classifier", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.convert_to_probabilities"], ["", "def", "output_from_logits", "(", "self", ",", "context", ",", "decoded_logits", ",", "response_mask", ")", ":", "\n", "        ", "'''\n        b: batch_size, l: length of sequence, v: vocabulary size, d: embedding dim\n        decoded_probabilities -> (b, l, v)\n        attention_mask -> (b, l)\n        embedding_weights -> (v, d)\n        output -> (b, num_labels)\n        '''", "\n", "# encode context #", "\n", "max_len", "=", "768", "\n", "batch", "=", "self", ".", "tokenizer", "(", "context", ",", "max_length", "=", "max_len", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "context_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "cuda", "(", ")", "\n", "context_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "cuda", "(", ")", "\n", "context_embeddings", "=", "self", ".", "model", ".", "encoder", ".", "embed_tokens", "(", "context_ids", ")", "\n", "\n", "# encode response #", "\n", "decoded_probabilities", "=", "self", ".", "convert_to_probabilities", "(", "decoded_logits", ")", "\n", "embedding_weights", "=", "self", ".", "model", ".", "encoder", ".", "embed_tokens", ".", "weight", "\n", "response_embeddings", "=", "torch", ".", "einsum", "(", "\"blv, vd->bld\"", ",", "decoded_probabilities", ",", "embedding_weights", ")", "\n", "\n", "# concatenate #", "\n", "merged_embeddings", "=", "torch", ".", "cat", "(", "[", "context_embeddings", ",", "response_embeddings", "]", ",", "1", ")", "\n", "merged_mask", "=", "torch", ".", "cat", "(", "[", "context_mask", ",", "torch", ".", "tensor", "(", "response_mask", ")", ".", "cuda", "(", ")", "]", ",", "1", ")", "\n", "outputs", "=", "self", ".", "model", "(", "inputs_embeds", "=", "merged_embeddings", ",", "attention_mask", "=", "merged_mask", ")", "\n", "sequence_output", "=", "outputs", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.__init__": [[306, 318], ["torch.nn.Module.__init__", "transformers.T5Tokenizer.from_pretrained", "transformers.T5EncoderModel.from_pretrained", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "strategy", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "size", "==", "\"base\"", ":", "\n", "            ", "in_features", "=", "768", "\n", "", "elif", "size", "==", "\"large\"", ":", "\n", "            ", "in_features", "=", "1024", "\n", "\n", "", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "\"t5-\"", "+", "size", ")", "\n", "self", ".", "model", "=", "T5EncoderModel", ".", "from_pretrained", "(", "\"t5-\"", "+", "size", ")", "\n", "self", ".", "scorer", "=", "nn", ".", "Linear", "(", "in_features", ",", "1", ")", "\n", "self", ".", "strategy", "=", "strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.forward": [[319, 326], ["models.T5EncoderRegressor.tokenizer", "models.T5EncoderRegressor.model", "torch.tanh().flatten", "torch.tanh().flatten", "torch.tanh().flatten", "torch.tanh().flatten", "batch[].cuda", "batch[].cuda", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "models.T5EncoderRegressor.scorer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "response", ")", ":", "\n", "        ", "max_len", "=", "512", "\n", "batch", "=", "self", ".", "tokenizer", "(", "response", ",", "max_length", "=", "max_len", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "cuda", "(", ")", ",", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "cuda", "(", ")", ")", "\n", "sequence_output", "=", "outputs", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "scores", "=", "torch", ".", "tanh", "(", "self", ".", "scorer", "(", "sequence_output", ")", ")", ".", "flatten", "(", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.convert_to_probabilities": [[327, 335], ["torch.softmax", "torch.softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax"], "methods", ["None"], ["", "def", "convert_to_probabilities", "(", "self", ",", "logits", ")", ":", "\n", "        ", "if", "self", ".", "strategy", "==", "0", ":", "\n", "            ", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "1", ")", "\n", "", "elif", "self", ".", "strategy", "==", "1", ":", "\n", "            ", "probs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "False", ")", "\n", "", "elif", "self", ".", "strategy", "==", "2", ":", "\n", "            ", "probs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "tau", "=", "1", ",", "hard", "=", "True", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.output_from_logits": [[336, 351], ["models.T5EncoderRegressor.convert_to_probabilities", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "models.T5EncoderRegressor.model", "torch.tanh().flatten", "torch.tanh().flatten", "torch.tanh().flatten", "torch.tanh().flatten", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "models.T5EncoderRegressor.scorer", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.T5EncoderRegressor.convert_to_probabilities"], ["", "def", "output_from_logits", "(", "self", ",", "decoded_logits", ",", "attention_mask", ")", ":", "\n", "        ", "'''\n        b: batch_size, l: length of sequence, v: vocabulary size, d: embedding dim\n        decoded_probabilities -> (b, l, v)\n        attention_mask -> (b, l)\n        embedding_weights -> (v, d)\n        output -> (b)\n        '''", "\n", "decoded_probabilities", "=", "self", ".", "convert_to_probabilities", "(", "decoded_logits", ")", "\n", "embedding_weights", "=", "self", ".", "model", ".", "encoder", ".", "embed_tokens", ".", "weight", "\n", "soft_embeddings", "=", "torch", ".", "einsum", "(", "\"blv, vd->bld\"", ",", "decoded_probabilities", ",", "embedding_weights", ")", "\n", "outputs", "=", "self", ".", "model", "(", "inputs_embeds", "=", "soft_embeddings", ",", "attention_mask", "=", "torch", ".", "tensor", "(", "attention_mask", ")", ".", "cuda", "(", ")", ")", "\n", "sequence_output", "=", "outputs", "[", "\"last_hidden_state\"", "]", "[", ":", ",", "0", ",", ":", "]", "\n", "scores", "=", "torch", ".", "tanh", "(", "self", ".", "scorer", "(", "sequence_output", ")", ")", ".", "flatten", "(", ")", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dpr_exempler_retriever.preprocess": [[8, 10], ["text.replace"], "function", ["None"], ["def", "preprocess", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "replace", "(", "\"_comma_\"", ",", "\",\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dpr_exempler_retriever.load_df": [[11, 21], ["pandas.read_csv().drop", "data[].apply", "list", "tqdm.tqdm", "dict.fromkeys", "pandas.read_csv", "dpr_exempler_retriever.preprocess", "range", "len"], "function", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dpr_exempler_retriever.preprocess"], ["", "def", "load_df", "(", "split", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "\"data/empathetic_dialogues/original/\"", "+", "split", "+", "\".csv\"", ",", "quoting", "=", "3", ")", ".", "drop", "(", "columns", "=", "[", "\"junk\"", "]", ")", "\n", "data", "[", "\"utterance\"", "]", "=", "data", "[", "\"utterance\"", "]", ".", "apply", "(", "lambda", "x", ":", "preprocess", "(", "x", ")", ")", "\n", "history", "=", "[", "]", "\n", "conv_ids", "=", "list", "(", "dict", ".", "fromkeys", "(", "data", "[", "\"conv_id\"", "]", ")", ")", "\n", "for", "ids", "in", "tqdm", "(", "conv_ids", ")", ":", "\n", "        ", "conv_utts", "=", "data", "[", "data", "[", "\"conv_id\"", "]", "==", "ids", "]", "[", "\"utterance\"", "]", "\n", "history", "+=", "[", "\" \"", ".", "join", "(", "conv_utts", "[", ":", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "conv_utts", ")", ")", "]", "\n", "", "data", "[", "\"history\"", "]", "=", "history", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dpr_exempler_retriever.embeddings_from_sentences": [[22, 33], ["tqdm.tqdm", "torch.cat", "range", "tokenizer", "batch[].cuda", "batch[].cuda", "embeddings.append", "len", "torch.no_grad", "model"], "function", ["None"], ["", "def", "embeddings_from_sentences", "(", "tokenizer", ",", "model", ",", "sentences", ")", ":", "\n", "    ", "batch_size", "=", "32", "\n", "embeddings", "=", "[", "]", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "batch_size", ")", ")", ":", "\n", "        ", "batch", "=", "tokenizer", "(", "sentences", "[", "j", ":", "j", "+", "batch_size", "]", ",", "padding", "=", "True", ",", "max_length", "=", "512", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", ".", "cuda", "(", ")", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "model", "(", "input_ids", ",", "attention_mask", ")", "\n", "", "embeddings", ".", "append", "(", "output", ".", "pooler_output", ")", "\n", "", "return", "torch", ".", "cat", "(", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dpr_exempler_retriever.compute_exemplers": [[34, 62], ["gpu_index_flat.search", "list", "tqdm.tqdm", "range", "set", "df_exemplers_indices.append", "df_exemplers.append", "len", "I[].cpu().numpy", "matches.append", "len", "I[].cpu", "str"], "function", ["None"], ["", "def", "compute_exemplers", "(", "query_df", ",", "query_tensor", ")", ":", "\n", "    ", "k", "=", "2048", "\n", "D", ",", "I", "=", "gpu_index_flat", ".", "search", "(", "query_tensor", ",", "k", ")", "\n", "exemplers", "=", "list", "(", "train", "[", "\"utterance\"", "]", ")", "\n", "df_exemplers", ",", "df_exemplers_indices", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "j", "in", "tqdm", "(", "range", "(", "len", "(", "query_df", ")", ")", ")", ":", "\n", "        ", "row", "=", "query_df", ".", "iloc", "[", "j", "]", "\n", "emotion", ",", "conv_id", "=", "row", "[", "\"context\"", "]", ",", "row", "[", "\"conv_id\"", "]", "\n", "candidate_indices", "=", "set", "(", "train", "[", "\n", "(", "train", "[", "\"context\"", "]", "==", "emotion", ")", "# dialogs having same emotion", "\n", "&", "(", "train", "[", "\"conv_id\"", "]", "!=", "conv_id", ")", "# different dialog (only required when computing train set exemplers)", "\n", "&", "(", "train", "[", "\"utterance_idx\"", "]", "%", "2", "==", "0", ")", "# user 2 utterances", "\n", "]", ".", "index", ")", "\n", "\n", "retrieved", ",", "matches", "=", "I", "[", "j", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "]", "\n", "for", "item", "in", "retrieved", ":", "\n", "            ", "if", "item", "in", "candidate_indices", ":", "\n", "                ", "matches", ".", "append", "(", "item", ")", "\n", "", "if", "len", "(", "matches", ")", "==", "10", ":", "\n", "                ", "break", "\n", "\n", "", "", "df_exemplers_indices", ".", "append", "(", "\" \u00e6\u00e6 \"", ".", "join", "(", "[", "str", "(", "ind", ")", "for", "ind", "in", "matches", "]", ")", ")", "\n", "df_exemplers", ".", "append", "(", "\" \u00e6\u00e6 \"", ".", "join", "(", "[", "exemplers", "[", "ind", "]", "for", "ind", "in", "matches", "]", ")", ")", "\n", "\n", "", "query_df", "[", "\"exemplers\"", "]", "=", "df_exemplers", "\n", "query_df", "[", "\"exemplers_index\"", "]", "=", "df_exemplers_indices", "\n", "return", "query_df", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train.configure_dataloaders": [[15, 21], ["dataloader.MainDataLoader", "dataloader.MainDataLoader", "dataloader.MainDataLoader"], "function", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.MainDataLoader", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.MainDataLoader", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.MainDataLoader"], ["def", "configure_dataloaders", "(", "batch_size", ")", ":", "\n", "    ", "\"Prepare dataloaders\"", "\n", "train_loader", "=", "MainDataLoader", "(", "\"data/empathetic_dialogues/valid_dpr.csv\"", ",", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "valid_loader", "=", "MainDataLoader", "(", "\"data/empathetic_dialogues/valid_dpr.csv\"", ",", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_loader", "=", "MainDataLoader", "(", "\"data/empathetic_dialogues/test_dpr.csv\"", ",", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "train_loader", ",", "valid_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train.configure_optimizer": [[22, 43], ["transformers.trainer_pt_utils.get_parameter_names", "transformers.optimization.AdamW", "model.named_parameters", "model.named_parameters"], "function", ["None"], ["", "def", "configure_optimizer", "(", "model", ",", "args", ")", ":", "\n", "    ", "\"Prepare optimizer\"", "\n", "decay_parameters", "=", "get_parameter_names", "(", "model", ",", "[", "torch", ".", "nn", ".", "LayerNorm", "]", ")", "\n", "decay_parameters", "=", "[", "name", "for", "name", "in", "decay_parameters", "if", "\"bias\"", "not", "in", "name", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "not", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer_kwargs", "=", "{", "\n", "\"betas\"", ":", "(", "args", ".", "adam_beta1", ",", "args", ".", "adam_beta2", ")", ",", "\n", "\"eps\"", ":", "args", ".", "adam_epsilon", ",", "\n", "\"lr\"", ":", "args", ".", "lr", "\n", "}", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "**", "optimizer_kwargs", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train.configure_scheduler": [[44, 58], ["transformers.optimization.get_scheduler", "math.ceil"], "function", ["None"], ["", "def", "configure_scheduler", "(", "optimizer", ",", "num_training_steps", ",", "args", ")", ":", "\n", "    ", "\"Prepare scheduler\"", "\n", "warmup_steps", "=", "(", "\n", "args", ".", "warmup_steps", "\n", "if", "args", ".", "warmup_steps", ">", "0", "\n", "else", "math", ".", "ceil", "(", "num_training_steps", "*", "args", ".", "warmup_ratio", ")", "\n", ")", "\n", "lr_scheduler", "=", "get_scheduler", "(", "\n", "args", ".", "lr_scheduler_type", ",", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "\n", ")", "\n", "return", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train.train_or_eval_model": [[59, 100], ["tqdm.tqdm", "round", "model.train", "model.eval", "model", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "empathy_loss_function", "empathy_loss_function", "empathy_loss_function", "sentiment_loss_function", "losses.append", "numpy.mean", "optimizer.zero_grad", "total_loss.backward", "optimizer.step", "loss.item", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "train_or_eval_model", "(", "model", ",", "dataloader", ",", "optimizer", "=", "None", ",", "train", "=", "False", ",", "main_loss_w", "=", "1", ",", "empathy_loss_w", "=", "1", ",", "sentiment_loss_w", "=", "1", ")", ":", "\n", "    ", "losses", "=", "[", "]", "\n", "assert", "not", "train", "or", "optimizer", "!=", "None", "\n", "\n", "if", "train", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "for", "conv_id", ",", "emotion", ",", "context", ",", "response", ",", "exemplars", ",", "empathy1_labels", ",", "empathy2_labels", ",", "empathy3_labels", ",", "sentiment", "in", "tqdm", "(", "dataloader", ",", "leave", "=", "False", ")", ":", "\n", "\n", "        ", "if", "train", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "out", ",", "empathy1_preds", ",", "empathy2_preds", ",", "empathy3_preds", ",", "sentiment_preds", "=", "model", "(", "context", ",", "response", ",", "exemplars", "=", "exemplars", ")", "\n", "\n", "empathy1_labels", "=", "torch", ".", "tensor", "(", "empathy1_labels", ")", ".", "cuda", "(", ")", "\n", "empathy2_labels", "=", "torch", ".", "tensor", "(", "empathy2_labels", ")", ".", "cuda", "(", ")", "\n", "empathy3_labels", "=", "torch", ".", "tensor", "(", "empathy3_labels", ")", ".", "cuda", "(", ")", "\n", "sentiment_labels", "=", "torch", ".", "tensor", "(", "sentiment", ")", ".", "cuda", "(", ")", "\n", "\n", "loss", "=", "out", ".", "loss", "\n", "\n", "empathy1_loss", "=", "empathy_loss_function", "(", "empathy1_preds", ",", "empathy1_labels", ")", "\n", "empathy2_loss", "=", "empathy_loss_function", "(", "empathy2_preds", ",", "empathy2_labels", ")", "\n", "empathy3_loss", "=", "empathy_loss_function", "(", "empathy3_preds", ",", "empathy3_labels", ")", "\n", "total_empathy_loss", "=", "empathy1_loss", "+", "empathy2_loss", "+", "empathy3_loss", "\n", "\n", "sentiment_loss", "=", "sentiment_loss_function", "(", "sentiment_preds", ",", "sentiment_labels", ")", "\n", "\n", "total_loss", "=", "main_loss_w", "*", "loss", "+", "empathy_loss_w", "*", "total_empathy_loss", "+", "sentiment_loss_w", "*", "sentiment_loss", "\n", "\n", "if", "train", ":", "\n", "            ", "total_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# losses.append(total_loss.item())", "\n", "", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "# Return the generative seq2seq loss.", "\n", "\n", "", "avg_loss", "=", "round", "(", "np", ".", "mean", "(", "losses", ")", ",", "4", ")", "\n", "return", "avg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train.test_model": [[101, 117], ["tqdm.tqdm", "nlgevaluation.compute_bleu", "round", "round", "model.erg_model.generate", "zip", "len"], "function", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation.compute_bleu", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.models.ERGModel.generate"], ["", "def", "test_model", "(", "model", ",", "dataloader", ",", "mode", ")", ":", "\n", "    ", "references", ",", "hypothesis", ",", "utt_ids", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "conv_id", ",", "emotion", ",", "context", ",", "response", ",", "exemplars", ",", "empathy1_labels", ",", "empathy2_labels", ",", "empathy3_labels", ",", "sentiment", "in", "tqdm", "(", "dataloader", ",", "leave", "=", "False", ")", ":", "\n", "\n", "        ", "ref", "=", "[", "[", "item", "]", "for", "item", "in", "response", "]", "\n", "hyp", "=", "model", ".", "erg_model", ".", "generate", "(", "context", ",", "exemplars", "=", "exemplars", ",", "mode", "=", "mode", ")", "\n", "\n", "references", "+=", "ref", "\n", "hypothesis", "+=", "hyp", "\n", "utt_ids", "+=", "[", "[", "conv", ",", "len", "(", "con", ")", "+", "1", ",", "\"\\n\"", ".", "join", "(", "con", ")", "]", "for", "conv", ",", "con", "in", "zip", "(", "conv_id", ",", "context", ")", "]", "\n", "\n", "", "scores", "=", "compute_bleu", "(", "references", ",", "hypothesis", ")", "\n", "bleu1", "=", "round", "(", "scores", "[", "\"Bleu_1\"", "]", ",", "4", ")", "\n", "bleu2", "=", "round", "(", "scores", "[", "\"Bleu_2\"", "]", ",", "4", ")", "\n", "\n", "return", "bleu1", ",", "bleu2", ",", "references", ",", "hypothesis", ",", "utt_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_empathy_classifier.configure_dataloaders": [[19, 24], ["dataloader.ClassificationLoader", "dataloader.ClassificationLoader"], "function", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationLoader", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationLoader"], ["def", "configure_dataloaders", "(", "dimension", ",", "batch_size", ")", ":", "\n", "    ", "\"Prepare dataloaders\"", "\n", "train_loader", "=", "ClassificationLoader", "(", "\"data/empathy_mental_health/\"", "+", "dimension", "+", "\"_train.csv\"", ",", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "valid_loader", "=", "ClassificationLoader", "(", "\"data/empathy_mental_health/\"", "+", "dimension", "+", "\"_valid.csv\"", ",", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_empathy_classifier.configure_transformer_optimizer": [[25, 47], ["transformers.trainer_pt_utils.get_parameter_names", "transformers.optimization.AdamW", "model.named_parameters", "model.named_parameters"], "function", ["None"], ["", "def", "configure_transformer_optimizer", "(", "model", ",", "args", ")", ":", "\n", "    ", "\"Prepare AdamW optimizer for transformer encoders\"", "\n", "decay_parameters", "=", "get_parameter_names", "(", "model", ",", "[", "torch", ".", "nn", ".", "LayerNorm", "]", ")", "\n", "# decay_parameters = [name for name in decay_parameters if \"bias\" not in name]", "\n", "decay_parameters", "=", "[", "name", "for", "name", "in", "decay_parameters", "if", "\"bias\"", "not", "in", "name", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "wd", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "not", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer_kwargs", "=", "{", "\n", "\"betas\"", ":", "(", "args", ".", "adam_beta1", ",", "args", ".", "adam_beta2", ")", ",", "\n", "\"eps\"", ":", "args", ".", "adam_epsilon", ",", "\n", "\"lr\"", ":", "args", ".", "lr", "\n", "}", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "**", "optimizer_kwargs", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_empathy_classifier.configure_scheduler": [[48, 62], ["transformers.optimization.get_scheduler", "math.ceil"], "function", ["None"], ["", "def", "configure_scheduler", "(", "optimizer", ",", "num_training_steps", ",", "args", ")", ":", "\n", "    ", "\"Prepare scheduler\"", "\n", "warmup_steps", "=", "(", "\n", "args", ".", "warmup_steps", "\n", "if", "args", ".", "warmup_steps", ">", "0", "\n", "else", "math", ".", "ceil", "(", "num_training_steps", "*", "args", ".", "warmup_ratio", ")", "\n", ")", "\n", "lr_scheduler", "=", "get_scheduler", "(", "\n", "args", ".", "lr_scheduler_type", ",", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "\n", ")", "\n", "return", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_empathy_classifier.train_or_eval_model": [[64, 96], ["tqdm.tqdm", "round", "numpy.concatenate", "numpy.concatenate", "round", "round", "model.train", "model.eval", "model", "loss_function", "losses.append", "np.concatenate.append", "np.concatenate.append", "numpy.mean", "optimizer.zero_grad", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "loss_function.backward", "optimizer.step", "loss_function.item", "torch.argmax().data.cpu().numpy", "torch.argmax().data.cpu().numpy", "torch.argmax().data.cpu().numpy", "numpy.array", "sklearn.metrics.accuracy_score", "sklearn.metrics.f1_score", "torch.tensor", "torch.tensor", "torch.tensor", "torch.argmax().data.cpu", "torch.argmax().data.cpu", "torch.argmax().data.cpu", "torch.argmax", "torch.argmax", "torch.argmax"], "function", ["None"], ["", "def", "train_or_eval_model", "(", "model", ",", "dataloader", ",", "optimizer", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "    ", "losses", ",", "preds", ",", "labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "assert", "not", "train", "or", "optimizer", "!=", "None", "\n", "\n", "if", "train", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "for", "context", ",", "response", ",", "emp_labels", "in", "tqdm", "(", "dataloader", ",", "leave", "=", "False", ")", ":", "\n", "        ", "if", "train", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "logits", "=", "model", "(", "context", ",", "response", ")", "\n", "loss", "=", "loss_function", "(", "logits", ",", "torch", ".", "tensor", "(", "emp_labels", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "preds", ".", "append", "(", "torch", ".", "argmax", "(", "logits", ",", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "np", ".", "array", "(", "emp_labels", ")", ")", "\n", "\n", "", "avg_loss", "=", "round", "(", "np", ".", "mean", "(", "losses", ")", ",", "4", ")", "\n", "\n", "preds", "=", "np", ".", "concatenate", "(", "preds", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ")", "\n", "accuracy", "=", "round", "(", "accuracy_score", "(", "labels", ",", "preds", ")", "*", "100", ",", "2", ")", "\n", "fscore", "=", "round", "(", "f1_score", "(", "labels", ",", "preds", ",", "average", "=", "\"weighted\"", ")", "*", "100", ",", "2", ")", "\n", "\n", "return", "avg_loss", ",", "accuracy", ",", "fscore", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionDataset.__init__": [[10, 15], ["pandas.read_csv", "list", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "x", "=", "pd", ".", "read_csv", "(", "filename", ")", "\n", "self", ".", "text", "=", "list", "(", "x", "[", "\"utterance\"", "]", ")", "\n", "self", ".", "labels", "=", "list", "(", "x", "[", "\"sentiment\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionDataset.__len__": [[16, 18], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionDataset.__getitem__": [[19, 21], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "text", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionDataset.collate_fn": [[22, 25], ["pandas.DataFrame", "dat[].tolist"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "data", ")", ":", "\n", "        ", "dat", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "return", "[", "dat", "[", "i", "]", ".", "tolist", "(", ")", "for", "i", "in", "dat", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationDataset.__init__": [[32, 38], ["pandas.read_csv", "list", "list", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "x", "=", "pd", ".", "read_csv", "(", "filename", ")", "\n", "self", ".", "context", "=", "list", "(", "x", "[", "\"seeker_post\"", "]", ")", "\n", "self", ".", "response", "=", "list", "(", "x", "[", "\"response_post\"", "]", ")", "\n", "self", ".", "labels", "=", "list", "(", "x", "[", "\"label\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationDataset.__len__": [[39, 41], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationDataset.__getitem__": [[42, 44], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "context", "[", "index", "]", ",", "self", ".", "response", "[", "index", "]", ",", "self", ".", "labels", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationDataset.collate_fn": [[45, 48], ["pandas.DataFrame", "dat[].tolist"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "data", ")", ":", "\n", "        ", "dat", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "return", "[", "dat", "[", "i", "]", ".", "tolist", "(", ")", "for", "i", "in", "dat", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__init__": [[55, 92], ["pandas.read_csv().drop", "data[].unique().tolist", "print", "tqdm.tqdm.tqdm", "hashlib.md5().hexdigest", "os.path.isfile", "pandas.read_csv().drop.query().sort_values", "enumerate", "print", "pandas.read_csv", "data[].unique", "pd.read_csv().drop.query().sort_values.iterrows", "utterance[].replace", "context.append", "os.path.isdir", "os.mkdir", "open", "pickle.dump", "hashlib.md5", "open", "pickle.load", "pandas.read_csv().drop.query", "dataloader.EmpatheticDialogues.data.append", "open().read", "utterance[].split", "int", "int", "int", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "cache", "=", "\"./.cache\"", ")", ":", "\n", "        ", "if", "cache", ":", "\n", "            ", "cs", "=", "hashlib", ".", "md5", "(", "open", "(", "filename", ",", "\"rb\"", ")", ".", "read", "(", ")", ")", ".", "hexdigest", "(", ")", "\n", "cache_file", "=", "f\"{cache}/{cs}\"", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cache_file", ")", ":", "\n", "                ", "with", "open", "(", "cache_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                    ", "self", ".", "data", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "print", "(", "f\"Loaded data from {filename} cache\"", ")", "\n", "return", "\n", "", "", "data", "=", "pd", ".", "read_csv", "(", "filename", ",", "quoting", "=", "0", ")", ".", "drop", "(", "columns", "=", "[", "\"history\"", "]", ")", "\n", "conversations", "=", "data", "[", "\"conv_id\"", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "data", "=", "[", "]", "\n", "print", "(", "f\"Loading data from {filename}\"", ")", "\n", "for", "conv_id", "in", "tqdm", "(", "conversations", ")", ":", "\n", "            ", "conv", "=", "data", ".", "query", "(", "f'conv_id == \"{conv_id}\"'", ")", ".", "sort_values", "(", "\"utterance_idx\"", ")", "\n", "context", "=", "[", "]", "\n", "for", "idx", ",", "utterance", "in", "enumerate", "(", "conv", ".", "iterrows", "(", ")", ")", ":", "\n", "                ", "utterance", "=", "utterance", "[", "1", "]", "\n", "curr_utterance", "=", "utterance", "[", "\"utterance\"", "]", ".", "replace", "(", "\"_comma_\"", ",", "\",\"", ")", "\n", "if", "idx", "%", "2", "==", "1", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "{", "\n", "\"conv_id\"", ":", "conv_id", ",", "\n", "\"emotion\"", ":", "utterance", "[", "\"context\"", "]", ",", "\n", "\"context\"", ":", "context", "[", ":", "idx", "+", "1", "]", ",", "\n", "\"response\"", ":", "curr_utterance", ",", "\n", "\"exemplars\"", ":", "utterance", "[", "\"exemplars_empd_reddit\"", "]", ".", "split", "(", "\"\u00e6\u00e6\"", ")", ",", "\n", "\"empathy1_labels\"", ":", "int", "(", "utterance", "[", "\"empathy_labels\"", "]", ")", ",", "\n", "\"empathy2_labels\"", ":", "int", "(", "utterance", "[", "\"empathy2_labels\"", "]", ")", ",", "\n", "\"empathy3_labels\"", ":", "int", "(", "utterance", "[", "\"empathy3_labels\"", "]", ")", ",", "\n", "\"sentiment\"", ":", "utterance", "[", "\"sentiment\"", "]", "\n", "}", ")", "\n", "", "context", ".", "append", "(", "curr_utterance", ")", "\n", "", "", "if", "cache", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "cache", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "cache", ")", "\n", "", "with", "open", "(", "cache_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__len__": [[93, 95], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.__getitem__": [[96, 98], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.EmpatheticDialogues.collate_fn": [[99, 102], ["pandas.DataFrame", "dat[].tolist"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "data", ")", ":", "\n", "        ", "dat", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "return", "[", "dat", "[", "i", "]", ".", "tolist", "(", ")", "for", "i", "in", "dat", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionLoader": [[26, 30], ["dataloader.RegressionDataset", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "def", "RegressionLoader", "(", "filename", ",", "batch_size", ",", "shuffle", ")", ":", "\n", "    ", "dataset", "=", "RegressionDataset", "(", "filename", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "shuffle", "=", "shuffle", ",", "batch_size", "=", "batch_size", ",", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.ClassificationLoader": [[49, 53], ["dataloader.ClassificationDataset", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "def", "ClassificationLoader", "(", "filename", ",", "batch_size", ",", "shuffle", ")", ":", "\n", "    ", "dataset", "=", "ClassificationDataset", "(", "filename", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "shuffle", "=", "shuffle", ",", "batch_size", "=", "batch_size", ",", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.MainDataLoader": [[103, 107], ["dataloader.EmpatheticDialogues", "torch.utils.data.DataLoader"], "function", ["None"], ["", "", "def", "MainDataLoader", "(", "filename", ",", "batch_size", ",", "shuffle", ",", "cache", "=", "\"./.cache\"", ")", ":", "\n", "    ", "dataset", "=", "EmpatheticDialogues", "(", "filename", ",", "cache", "=", "cache", ")", "\n", "loader", "=", "DataLoader", "(", "dataset", ",", "shuffle", "=", "shuffle", ",", "batch_size", "=", "batch_size", ",", "collate_fn", "=", "dataset", ".", "collate_fn", ")", "\n", "return", "loader", "\n", "", ""]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_sentiment_regressor.configure_dataloaders": [[16, 22], ["dataloader.RegressionLoader", "dataloader.RegressionLoader", "dataloader.RegressionLoader"], "function", ["home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionLoader", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionLoader", "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.dataloader.RegressionLoader"], ["def", "configure_dataloaders", "(", "batch_size", ")", ":", "\n", "    ", "\"Prepare dataloaders\"", "\n", "train_loader", "=", "RegressionLoader", "(", "\"data/empathetic_dialogues/train_vader.csv\"", ",", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "valid_loader", "=", "RegressionLoader", "(", "\"data/empathetic_dialogues/valid_vader.csv\"", ",", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "test_loader", "=", "RegressionLoader", "(", "\"data/empathetic_dialogues/test_vader.csv\"", ",", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "train_loader", ",", "valid_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_sentiment_regressor.configure_transformer_optimizer": [[23, 45], ["transformers.trainer_pt_utils.get_parameter_names", "transformers.optimization.AdamW", "model.named_parameters", "model.named_parameters"], "function", ["None"], ["", "def", "configure_transformer_optimizer", "(", "model", ",", "args", ")", ":", "\n", "    ", "\"Prepare AdamW optimizer for transformer encoders\"", "\n", "decay_parameters", "=", "get_parameter_names", "(", "model", ",", "[", "torch", ".", "nn", ".", "LayerNorm", "]", ")", "\n", "# decay_parameters = [name for name in decay_parameters if \"bias\" not in name]", "\n", "decay_parameters", "=", "[", "name", "for", "name", "in", "decay_parameters", "if", "\"bias\"", "not", "in", "name", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "wd", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "n", "not", "in", "decay_parameters", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer_kwargs", "=", "{", "\n", "\"betas\"", ":", "(", "args", ".", "adam_beta1", ",", "args", ".", "adam_beta2", ")", ",", "\n", "\"eps\"", ":", "args", ".", "adam_epsilon", ",", "\n", "\"lr\"", ":", "args", ".", "lr", "\n", "}", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "**", "optimizer_kwargs", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_sentiment_regressor.configure_scheduler": [[46, 60], ["transformers.optimization.get_scheduler", "math.ceil"], "function", ["None"], ["", "def", "configure_scheduler", "(", "optimizer", ",", "num_training_steps", ",", "args", ")", ":", "\n", "    ", "\"Prepare scheduler\"", "\n", "warmup_steps", "=", "(", "\n", "args", ".", "warmup_steps", "\n", "if", "args", ".", "warmup_steps", ">", "0", "\n", "else", "math", ".", "ceil", "(", "num_training_steps", "*", "args", ".", "warmup_ratio", ")", "\n", ")", "\n", "lr_scheduler", "=", "get_scheduler", "(", "\n", "args", ".", "lr_scheduler_type", ",", "\n", "optimizer", ",", "\n", "num_warmup_steps", "=", "warmup_steps", ",", "\n", "num_training_steps", "=", "num_training_steps", ",", "\n", ")", "\n", "return", "lr_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.train_sentiment_regressor.train_or_eval_model": [[62, 86], ["tqdm.tqdm", "round", "model.train", "model.eval", "model", "loss_function", "losses.append", "numpy.mean", "optimizer.zero_grad", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "loss_function.backward", "optimizer.step", "loss_function.item", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "train_or_eval_model", "(", "model", ",", "dataloader", ",", "optimizer", "=", "None", ",", "train", "=", "False", ")", ":", "\n", "    ", "losses", "=", "[", "]", "\n", "assert", "not", "train", "or", "optimizer", "!=", "None", "\n", "\n", "if", "train", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "", "for", "utterances", ",", "gold_scores", "in", "tqdm", "(", "dataloader", ",", "leave", "=", "False", ")", ":", "\n", "        ", "if", "train", ":", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "scores", "=", "model", "(", "utterances", ")", "\n", "loss", "=", "loss_function", "(", "scores", ",", "torch", ".", "tensor", "(", "gold_scores", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "avg_loss", "=", "round", "(", "np", ".", "mean", "(", "losses", ")", ",", "4", ")", "\n", "return", "avg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation._strip": [[15, 17], ["s.strip"], "function", ["None"], ["def", "_strip", "(", "s", ")", ":", "\n", "    ", "return", "s", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation.compute_metrics": [[19, 84], ["enumerate", "open", "f.readlines", "list", "len", "len", "skipthoughts.load_model", "skipthoughts.Encoder", "skipthoughts.Encoder.encode", "np.array().T.tolist", "six.moves.map", "list", "np.max().mean", "print", "np.array().T.tolist", "six.moves.map", "eval_emb_metrics", "print", "scores.split.split", "open", "ref_list.append", "six.moves.map", "zip", "enumerate", "lines.strip", "enumerate", "scorer.compute_score", "isinstance", "isinstance", "six.moves.map", "h.strip", "score.split", "float", "f.readlines", "nlgeval.pycocoevalcap.bleu.bleu.Bleu", "nlgeval.pycocoevalcap.meteor.meteor.Meteor", "nlgeval.pycocoevalcap.rouge.rouge.Rouge", "nlgeval.pycocoevalcap.cider.cider.Cider", "zip", "print", "scorer.close", "h.strip", "skipthoughts.Encoder.encode", "np.max", "float.strip", "print", "np.array", "np.max().mean.diagonal", "np.array", "r.strip", "r.strip", "np.max().mean."], "function", ["None"], ["", "def", "compute_metrics", "(", "hypothesis", ",", "references", ",", "no_overlap", "=", "False", ",", "no_skipthoughts", "=", "False", ",", "no_glove", "=", "False", ")", ":", "\n", "    ", "with", "open", "(", "hypothesis", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "hyp_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "ref_list", "=", "[", "]", "\n", "for", "iidx", ",", "reference", "in", "enumerate", "(", "references", ")", ":", "\n", "        ", "with", "open", "(", "reference", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ref_list", ".", "append", "(", "f", ".", "readlines", "(", ")", ")", "\n", "", "", "ref_list", "=", "[", "list", "(", "map", "(", "_strip", ",", "refs", ")", ")", "for", "refs", "in", "zip", "(", "*", "ref_list", ")", "]", "\n", "refs", "=", "{", "idx", ":", "strippedlines", "for", "(", "idx", ",", "strippedlines", ")", "in", "enumerate", "(", "ref_list", ")", "}", "\n", "hyps", "=", "{", "idx", ":", "[", "lines", ".", "strip", "(", ")", "]", "for", "(", "idx", ",", "lines", ")", "in", "enumerate", "(", "hyp_list", ")", "}", "\n", "assert", "len", "(", "refs", ")", "==", "len", "(", "hyps", ")", "\n", "\n", "ret_scores", "=", "{", "}", "\n", "if", "not", "no_overlap", ":", "\n", "        ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "(", "Meteor", "(", ")", ",", "\"METEOR\"", ")", ",", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", "\n", "]", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "refs", ",", "hyps", ")", "\n", "if", "isinstance", "(", "method", ",", "list", ")", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "print", "(", "\"%s: %0.6f\"", "%", "(", "m", ",", "sc", ")", ")", "\n", "ret_scores", "[", "m", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"%s: %0.6f\"", "%", "(", "method", ",", "score", ")", ")", "\n", "ret_scores", "[", "method", "]", "=", "score", "\n", "", "if", "isinstance", "(", "scorer", ",", "Meteor", ")", ":", "\n", "                ", "scorer", ".", "close", "(", ")", "\n", "", "", "del", "scorers", "\n", "\n", "", "if", "not", "no_skipthoughts", ":", "\n", "        ", "from", "nlgeval", ".", "skipthoughts", "import", "skipthoughts", "\n", "import", "numpy", "as", "np", "\n", "from", "sklearn", ".", "metrics", ".", "pairwise", "import", "cosine_similarity", "\n", "\n", "model", "=", "skipthoughts", ".", "load_model", "(", ")", "\n", "encoder", "=", "skipthoughts", ".", "Encoder", "(", "model", ")", "\n", "vector_hyps", "=", "encoder", ".", "encode", "(", "[", "h", ".", "strip", "(", ")", "for", "h", "in", "hyp_list", "]", ",", "verbose", "=", "False", ")", "\n", "ref_list_T", "=", "np", ".", "array", "(", "ref_list", ")", ".", "T", ".", "tolist", "(", ")", "\n", "vector_refs", "=", "map", "(", "lambda", "refl", ":", "encoder", ".", "encode", "(", "[", "r", ".", "strip", "(", ")", "for", "r", "in", "refl", "]", ",", "verbose", "=", "False", ")", ",", "ref_list_T", ")", "\n", "cosine_similarity", "=", "list", "(", "map", "(", "lambda", "refv", ":", "cosine_similarity", "(", "refv", ",", "vector_hyps", ")", ".", "diagonal", "(", ")", ",", "vector_refs", ")", ")", "\n", "cosine_similarity", "=", "np", ".", "max", "(", "cosine_similarity", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "\n", "print", "(", "\"SkipThoughtsCosineSimilarity: %0.6f\"", "%", "(", "cosine_similarity", ")", ")", "\n", "ret_scores", "[", "'SkipThoughtCS'", "]", "=", "cosine_similarity", "\n", "del", "model", "\n", "\n", "", "if", "not", "no_glove", ":", "\n", "        ", "from", "nlgeval", ".", "word2vec", ".", "evaluate", "import", "eval_emb_metrics", "\n", "import", "numpy", "as", "np", "\n", "\n", "glove_hyps", "=", "[", "h", ".", "strip", "(", ")", "for", "h", "in", "hyp_list", "]", "\n", "ref_list_T", "=", "np", ".", "array", "(", "ref_list", ")", ".", "T", ".", "tolist", "(", ")", "\n", "glove_refs", "=", "map", "(", "lambda", "refl", ":", "[", "r", ".", "strip", "(", ")", "for", "r", "in", "refl", "]", ",", "ref_list_T", ")", "\n", "scores", "=", "eval_emb_metrics", "(", "glove_hyps", ",", "glove_refs", ")", "\n", "print", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "split", "(", "'\\n'", ")", "\n", "for", "score", "in", "scores", ":", "\n", "            ", "name", ",", "value", "=", "score", ".", "split", "(", "':'", ")", "\n", "value", "=", "float", "(", "value", ".", "strip", "(", ")", ")", "\n", "ret_scores", "[", "name", "]", "=", "value", "\n", "\n", "", "", "return", "ret_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation.compute_bleu": [[86, 110], ["enumerate", "lines.strip", "enumerate", "scorer.compute_score", "isinstance", "isinstance", "nlgeval.pycocoevalcap.bleu.bleu.Bleu", "zip", "print", "scorer.close", "print"], "function", ["None"], ["", "def", "compute_bleu", "(", "ref_list", ",", "hyp_list", ",", "no_overlap", "=", "False", ")", ":", "\n", "    ", "ret_scores", "=", "{", "}", "\n", "\n", "refs", "=", "{", "idx", ":", "strippedlines", "for", "(", "idx", ",", "strippedlines", ")", "in", "enumerate", "(", "ref_list", ")", "}", "\n", "hyps", "=", "{", "idx", ":", "[", "lines", ".", "strip", "(", ")", "]", "for", "(", "idx", ",", "lines", ")", "in", "enumerate", "(", "hyp_list", ")", "}", "\n", "\n", "if", "not", "no_overlap", ":", "\n", "        ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", "\n", "]", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "refs", ",", "hyps", ")", "\n", "if", "isinstance", "(", "method", ",", "list", ")", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "print", "(", "\"%s: %0.6f\"", "%", "(", "m", ",", "sc", ")", ")", "\n", "ret_scores", "[", "m", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"%s: %0.6f\"", "%", "(", "method", ",", "score", ")", ")", "\n", "ret_scores", "[", "method", "]", "=", "score", "\n", "", "if", "isinstance", "(", "scorer", ",", "Meteor", ")", ":", "\n", "                ", "scorer", ".", "close", "(", ")", "\n", "", "", "del", "scorers", "\n", "\n", "", "return", "ret_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation.compute_individual_metrics": [[111, 171], ["isinstance", "isinstance", "ref.split.split", "a.strip", "skipthoughts.load_model", "skipthoughts.Encoder", "skipthoughts.Encoder.encode", "np.array().T.tolist", "six.moves.map", "list", "np.max().mean", "np.array().T.tolist", "six.moves.map", "eval_emb_metrics", "scores.split.split", "hyp.strip", "scorer.compute_score", "isinstance", "isinstance", "six.moves.map", "h.strip", "score.split", "float", "nlgeval.pycocoevalcap.bleu.bleu.Bleu", "nlgeval.pycocoevalcap.meteor.meteor.Meteor", "nlgeval.pycocoevalcap.rouge.rouge.Rouge", "nlgeval.pycocoevalcap.cider.cider.Cider", "zip", "scorer.close", "h.strip", "skipthoughts.Encoder.encode", "np.max", "float.strip", "np.array", "np.max().mean.diagonal", "np.array", "r.strip", "r.strip", "np.max().mean."], "function", ["None"], ["", "def", "compute_individual_metrics", "(", "ref", ",", "hyp", ",", "no_overlap", "=", "False", ",", "no_skipthoughts", "=", "True", ",", "no_glove", "=", "True", ")", ":", "\n", "    ", "assert", "isinstance", "(", "hyp", ",", "six", ".", "string_types", ")", "\n", "\n", "if", "isinstance", "(", "ref", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "ref", "=", "ref", ".", "split", "(", "'||<|>||'", ")", "# special delimiter for backward compatibility", "\n", "", "ref", "=", "[", "a", ".", "strip", "(", ")", "for", "a", "in", "ref", "]", "\n", "refs", "=", "{", "0", ":", "ref", "}", "\n", "ref_list", "=", "[", "ref", "]", "\n", "\n", "hyps", "=", "{", "0", ":", "[", "hyp", ".", "strip", "(", ")", "]", "}", "\n", "hyp_list", "=", "[", "hyp", "]", "\n", "\n", "ret_scores", "=", "{", "}", "\n", "if", "not", "no_overlap", ":", "\n", "        ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "(", "Meteor", "(", ")", ",", "\"METEOR\"", ")", ",", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", "\n", "]", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "refs", ",", "hyps", ")", "\n", "if", "isinstance", "(", "method", ",", "list", ")", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "ret_scores", "[", "m", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                ", "ret_scores", "[", "method", "]", "=", "score", "\n", "", "if", "isinstance", "(", "scorer", ",", "Meteor", ")", ":", "\n", "                ", "scorer", ".", "close", "(", ")", "\n", "", "", "del", "scorers", "\n", "\n", "", "if", "not", "no_skipthoughts", ":", "\n", "        ", "from", "nlgeval", ".", "skipthoughts", "import", "skipthoughts", "\n", "import", "numpy", "as", "np", "\n", "from", "sklearn", ".", "metrics", ".", "pairwise", "import", "cosine_similarity", "\n", "\n", "model", "=", "skipthoughts", ".", "load_model", "(", ")", "\n", "encoder", "=", "skipthoughts", ".", "Encoder", "(", "model", ")", "\n", "vector_hyps", "=", "encoder", ".", "encode", "(", "[", "h", ".", "strip", "(", ")", "for", "h", "in", "hyp_list", "]", ",", "verbose", "=", "False", ")", "\n", "ref_list_T", "=", "np", ".", "array", "(", "ref_list", ")", ".", "T", ".", "tolist", "(", ")", "\n", "vector_refs", "=", "map", "(", "lambda", "refl", ":", "encoder", ".", "encode", "(", "[", "r", ".", "strip", "(", ")", "for", "r", "in", "refl", "]", ",", "verbose", "=", "False", ")", ",", "ref_list_T", ")", "\n", "cosine_similarity", "=", "list", "(", "map", "(", "lambda", "refv", ":", "cosine_similarity", "(", "refv", ",", "vector_hyps", ")", ".", "diagonal", "(", ")", ",", "vector_refs", ")", ")", "\n", "cosine_similarity", "=", "np", ".", "max", "(", "cosine_similarity", ",", "axis", "=", "0", ")", ".", "mean", "(", ")", "\n", "ret_scores", "[", "'SkipThoughtCS'", "]", "=", "cosine_similarity", "\n", "\n", "", "if", "not", "no_glove", ":", "\n", "        ", "from", "nlgeval", ".", "word2vec", ".", "evaluate", "import", "eval_emb_metrics", "\n", "import", "numpy", "as", "np", "\n", "\n", "glove_hyps", "=", "[", "h", ".", "strip", "(", ")", "for", "h", "in", "hyp_list", "]", "\n", "ref_list_T", "=", "np", ".", "array", "(", "ref_list", ")", ".", "T", ".", "tolist", "(", ")", "\n", "glove_refs", "=", "map", "(", "lambda", "refl", ":", "[", "r", ".", "strip", "(", ")", "for", "r", "in", "refl", "]", ",", "ref_list_T", ")", "\n", "scores", "=", "eval_emb_metrics", "(", "glove_hyps", ",", "glove_refs", ")", "\n", "scores", "=", "scores", ".", "split", "(", "'\\n'", ")", "\n", "for", "score", "in", "scores", ":", "\n", "            ", "name", ",", "value", "=", "score", ".", "split", "(", "':'", ")", "\n", "value", "=", "float", "(", "value", ".", "strip", "(", ")", ")", "\n", "ret_scores", "[", "name", "]", "=", "value", "\n", "\n", "", "", "return", "ret_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.declare-lab_exemplary-empathy.None.nlgevaluation.compute_individual_bleu": [[172, 201], ["isinstance", "isinstance", "ref.split.split", "a.strip", "hyp.strip", "scorer.compute_score", "isinstance", "isinstance", "nlgeval.pycocoevalcap.bleu.bleu.Bleu", "zip", "scorer.close"], "function", ["None"], ["", "def", "compute_individual_bleu", "(", "ref", ",", "hyp", ",", "no_overlap", "=", "False", ")", ":", "\n", "    ", "assert", "isinstance", "(", "hyp", ",", "six", ".", "string_types", ")", "\n", "\n", "if", "isinstance", "(", "ref", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "ref", "=", "ref", ".", "split", "(", "'||<|>||'", ")", "# special delimiter for backward compatibility", "\n", "", "ref", "=", "[", "a", ".", "strip", "(", ")", "for", "a", "in", "ref", "]", "\n", "refs", "=", "{", "0", ":", "ref", "}", "\n", "ref_list", "=", "[", "ref", "]", "\n", "\n", "hyps", "=", "{", "0", ":", "[", "hyp", ".", "strip", "(", ")", "]", "}", "\n", "hyp_list", "=", "[", "hyp", "]", "\n", "\n", "ret_scores", "=", "{", "}", "\n", "if", "not", "no_overlap", ":", "\n", "        ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "]", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "            ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "refs", ",", "hyps", ")", "\n", "if", "isinstance", "(", "method", ",", "list", ")", ":", "\n", "                ", "for", "sc", ",", "scs", ",", "m", "in", "zip", "(", "score", ",", "scores", ",", "method", ")", ":", "\n", "                    ", "ret_scores", "[", "m", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                ", "ret_scores", "[", "method", "]", "=", "score", "\n", "", "if", "isinstance", "(", "scorer", ",", "Meteor", ")", ":", "\n", "                ", "scorer", ".", "close", "(", ")", "\n", "", "", "del", "scorers", "\n", "\n", "", "return", "ret_scores", "", "", ""]]}