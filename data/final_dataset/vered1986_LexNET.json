{"home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.main": [[8, 54], ["docopt.docopt", "spacy.en.English", "codecs.open", "set", "codecs.open", "codecs.open", "line.strip", "paragraph.strip.strip", "spacy.en.English.", "len", "unicode", "parse_wikipedia.parse_sentence", "len", "parse_sentence.iteritems"], "function", ["home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.parse_sentence"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\"\n    Creates a \"knowledge resource\" from triplets file\n    \"\"\"", "\n", "\n", "# Get the arguments", "\n", "args", "=", "docopt", "(", "\"\"\"Parse the Wikipedia dump and create a triplets file, each line is formatted as follows: X\\t\\Y\\tpath\n\n    Usage:\n        parse_wikipedia.py <wiki_file> <vocabulary_file> <out_file>\n\n        <wiki_file> = the Wikipedia dump file\n        <vocabulary_file> = a file containing the words to include\n        <out_file> = the output file\n    \"\"\"", ")", "\n", "\n", "nlp", "=", "English", "(", ")", "\n", "\n", "wiki_file", "=", "args", "[", "'<wiki_file>'", "]", "\n", "vocabulary_file", "=", "args", "[", "'<vocabulary_file>'", "]", "\n", "out_file", "=", "args", "[", "'<out_file>'", "]", "\n", "\n", "# Load the phrase pair files", "\n", "with", "codecs", ".", "open", "(", "vocabulary_file", ",", "'r'", ",", "'utf-8'", ")", "as", "f_in", ":", "\n", "        ", "vocabulary", "=", "set", "(", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f_in", "]", ")", "\n", "\n", "", "with", "codecs", ".", "open", "(", "wiki_file", ",", "'r'", ",", "'utf-8'", ")", "as", "f_in", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "out_file", ",", "'w'", ",", "'utf-8'", ")", "as", "f_out", ":", "\n", "\n", "# Read the next paragraph", "\n", "            ", "for", "paragraph", "in", "f_in", ":", "\n", "\n", "# Skip empty lines", "\n", "                ", "paragraph", "=", "paragraph", ".", "strip", "(", ")", "\n", "if", "len", "(", "paragraph", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "parsed_par", "=", "nlp", "(", "unicode", "(", "paragraph", ")", ")", "\n", "\n", "# Parse each sentence separately", "\n", "for", "sent", "in", "parsed_par", ".", "sents", ":", "\n", "                    ", "dependency_paths", "=", "parse_sentence", "(", "sent", ",", "vocabulary", ")", "\n", "if", "len", "(", "dependency_paths", ")", ">", "0", ":", "\n", "                        ", "for", "(", "x", ",", "y", ")", ",", "paths", "in", "dependency_paths", ".", "iteritems", "(", ")", ":", "\n", "                            ", "for", "path", "in", "paths", ":", "\n", "                                ", "print", ">>", "f_out", ",", "'\\t'", ".", "join", "(", "[", "x", ",", "y", ",", "path", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.parse_sentence": [[56, 90], ["indices.extend", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "paths[].append", "satellites[].extend", "filtered_paths[].extend", "enumerate", "parse_wikipedia.shortest_path", "collections.defaultdict.keys", "filter", "collections.defaultdict.keys", "len", "parse_wikipedia.get_satellite_links", "parse_wikipedia.pretty_print"], "function", ["home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.shortest_path", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.get_satellite_links", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.pretty_print"], ["", "", "", "", "", "", "", "", "def", "parse_sentence", "(", "sent", ",", "vocabulary", ")", ":", "\n", "    ", "\"\"\"\n    Get all the dependency paths between nouns in the sentence\n    :param sent: the sentence to parse\n    :param vocabulary: the words to search paths for\n    :return: the list of entities and paths\n    \"\"\"", "\n", "\n", "# Get all term indices", "\n", "indices", "=", "[", "(", "token", ".", "lemma_", ",", "sent", "[", "i", ":", "i", "+", "1", "]", ",", "i", ",", "i", ")", "for", "i", ",", "token", "in", "enumerate", "(", "sent", ")", "\n", "if", "len", "(", "token", ".", "orth_", ")", ">", "2", "and", "token", ".", "lemma_", "in", "vocabulary", "and", "token", ".", "pos_", "in", "[", "'NOUN'", ",", "'VERB'", ",", "'ADJ'", "]", "]", "\n", "\n", "# Add noun chunks for the current sentence", "\n", "# Don't include noun chunks with only one word - these are nouns already included", "\n", "indices", ".", "extend", "(", "[", "(", "np", ".", "orth_", ",", "np", ",", "np", ".", "start", ",", "np", ".", "end", ")", "for", "np", "in", "sent", ".", "doc", ".", "noun_chunks", "\n", "if", "sent", ".", "start", "<=", "np", ".", "start", "<", "np", ".", "end", "-", "1", "<", "sent", ".", "end", "and", "np", ".", "orth_", "in", "vocabulary", "]", ")", "\n", "\n", "tokens", "=", "[", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "y", "[", "0", "]", ",", "y", "[", "1", "]", ")", "for", "x", "in", "indices", "for", "y", "in", "indices", "if", "x", "[", "3", "]", "<", "y", "[", "2", "]", "]", "\n", "\n", "# Get all dependency paths between words, up to length 4", "\n", "paths", "=", "defaultdict", "(", "list", ")", "\n", "[", "paths", "[", "(", "x", ",", "y", ")", "]", ".", "append", "(", "shortest_path", "(", "(", "x_tokens", ",", "y_tokens", ")", ")", ")", "for", "(", "x", ",", "x_tokens", ",", "y", ",", "y_tokens", ")", "in", "tokens", "]", "\n", "\n", "satellites", "=", "defaultdict", "(", "list", ")", "\n", "[", "satellites", "[", "(", "x", ",", "y", ")", "]", ".", "extend", "(", "[", "sat_path", "for", "path", "in", "paths", "[", "(", "x", ",", "y", ")", "]", "for", "sat_path", "in", "get_satellite_links", "(", "path", ")", "\n", "if", "sat_path", "is", "not", "None", "]", ")", "for", "(", "x", ",", "y", ")", "in", "paths", ".", "keys", "(", ")", "]", "\n", "\n", "filtered_paths", "=", "defaultdict", "(", "list", ")", "\n", "[", "filtered_paths", "[", "(", "x", ",", "y", ")", "]", ".", "extend", "(", "filter", "(", "None", ",", "[", "pretty_print", "(", "set_x_l", ",", "x", ",", "set_x_r", ",", "hx", ",", "lch", ",", "hy", ",", "set_y_l", ",", "y", ",", "set_y_r", ")", "\n", "for", "(", "set_x_l", ",", "x", ",", "set_x_r", ",", "hx", ",", "lch", ",", "hy", ",", "set_y_l", ",", "y", ",", "set_y_r", ")", "\n", "in", "satellites", "[", "(", "x", ",", "y", ")", "]", "]", ")", ")", "\n", "for", "(", "x", ",", "y", ")", "in", "satellites", ".", "keys", "(", ")", "]", "\n", "\n", "return", "filtered_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.shortest_path": [[92, 169], ["parse_wikipedia.heads", "parse_wikipedia.heads", "parse_wikipedia.check_direction", "parse_wikipedia.check_direction", "heads.index", "heads.index", "len", "len", "xrange", "min", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.heads", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.heads", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.check_direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.check_direction"], ["", "def", "shortest_path", "(", "path", ")", ":", "\n", "    ", "\"\"\" Returns the shortest dependency path from x to y\n    :param x: x token\n    :param y: y token\n    :return: the shortest dependency path from x to y\n    \"\"\"", "\n", "\n", "# Get the root token and work on it", "\n", "if", "path", "is", "None", ":", "\n", "        ", "return", "None", "\n", "\n", "", "x_tokens", ",", "y_tokens", "=", "path", "\n", "x_token", "=", "x_tokens", ".", "root", "\n", "y_token", "=", "y_tokens", ".", "root", "\n", "\n", "# Get the path from the root to each of the tokens", "\n", "hx", "=", "heads", "(", "x_token", ")", "\n", "hy", "=", "heads", "(", "y_token", ")", "\n", "\n", "# Get the lowest common head", "\n", "\n", "# There could be several cases. For example, for x = parrot, y = bird:", "\n", "\n", "# 1. x is the head of y: \"[parrot] and other [birds]\"", "\n", "if", "x_token", "in", "hy", ":", "\n", "        ", "hy", "=", "hy", "[", "hy", ".", "index", "(", "x_token", ")", "+", "1", ":", "]", "\n", "hx", "=", "[", "]", "\n", "lch", "=", "x_token", "\n", "\n", "# 2. y is the head of x: \"[birds] such as [parrots]\"", "\n", "", "elif", "y_token", "in", "hx", ":", "\n", "        ", "hx", "=", "hx", "[", ":", "hx", ".", "index", "(", "y_token", ")", "]", "\n", "hy", "=", "[", "]", "\n", "lch", "=", "y_token", "\n", "\n", "", "elif", "len", "(", "hx", ")", "==", "0", "or", "len", "(", "hy", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "# 3. x and y have no common head - the first head in each list should be the sentence root, so", "\n", "# this is possibly a parse error?", "\n", "", "elif", "hy", "[", "0", "]", "!=", "hx", "[", "0", "]", ":", "\n", "        ", "return", "None", "\n", "\n", "# 4. x and y are connected via a direct parent or have the exact same path to the root, as in \"[parrot] is a [bird]\"", "\n", "", "elif", "hx", "==", "hy", ":", "\n", "        ", "lch", "=", "hx", "[", "-", "1", "]", "\n", "hx", "=", "hy", "=", "[", "]", "\n", "\n", "# 5. x and y have a different parent which is non-direct, as in \"[parrot] is a member of the [bird] family\".", "\n", "# The head is the last item in the common sequence of both head lists.", "\n", "", "else", ":", "\n", "        ", "for", "i", "in", "xrange", "(", "min", "(", "len", "(", "hx", ")", ",", "len", "(", "hy", ")", ")", ")", ":", "\n", "# Now we've found the common ancestor in i-1", "\n", "            ", "if", "hx", "[", "i", "]", "is", "not", "hy", "[", "i", "]", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "len", "(", "hx", ")", ">", "i", ":", "\n", "            ", "lch", "=", "hx", "[", "i", "-", "1", "]", "\n", "", "elif", "len", "(", "hy", ")", ">", "i", ":", "\n", "            ", "lch", "=", "hy", "[", "i", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n", "# The path from x to the lowest common head", "\n", "", "hx", "=", "hx", "[", "i", "+", "1", ":", "]", "\n", "\n", "# The path from the lowest common head to y", "\n", "hy", "=", "hy", "[", "i", "+", "1", ":", "]", "\n", "\n", "", "if", "lch", "and", "check_direction", "(", "lch", ",", "hx", ",", "lambda", "h", ":", "h", ".", "lefts", ")", ":", "\n", "        ", "return", "None", "\n", "", "hx", "=", "hx", "[", ":", ":", "-", "1", "]", "\n", "\n", "if", "lch", "and", "check_direction", "(", "lch", ",", "hy", ",", "lambda", "h", ":", "h", ".", "rights", ")", ":", "\n", "        ", "return", "None", "\n", "\n", "", "return", "(", "x_token", ",", "hx", ",", "lch", ",", "hy", ",", "y_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.heads": [[171, 183], ["hs.append"], "function", ["None"], ["", "def", "heads", "(", "token", ")", ":", "\n", "    ", "\"\"\"\n    Return the heads of a token, from the root down to immediate head\n    :param token:\n    :return:\n    \"\"\"", "\n", "t", "=", "token", "\n", "hs", "=", "[", "]", "\n", "while", "t", "is", "not", "t", ".", "head", ":", "\n", "        ", "t", "=", "t", ".", "head", "\n", "hs", ".", "append", "(", "t", ")", "\n", "", "return", "hs", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.check_direction": [[185, 194], ["any", "f_dir", "zip"], "function", ["None"], ["", "def", "check_direction", "(", "lch", ",", "hs", ",", "f_dir", ")", ":", "\n", "    ", "\"\"\"\n    Make sure that the path between the term and the lowest common head is in a certain direction\n    :param lch: the lowest common head\n    :param hs: the path from the lowest common head to the term\n    :param f_dir: function of direction\n    :return:\n    \"\"\"", "\n", "return", "any", "(", "modifier", "not", "in", "f_dir", "(", "head", ")", "for", "head", ",", "modifier", "in", "zip", "(", "[", "lch", "]", "+", "hs", "[", ":", "-", "1", "]", ",", "hs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.get_satellite_links": [[196, 235], ["set", "len", "paths.append", "paths.append", "len", "paths.append", "paths.append", "child.string.strip", "child.string.strip"], "function", ["None"], ["", "def", "get_satellite_links", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Add the \"satellites\" - single links not already contained in the dependency path added on either side of each noun\n    :param x: the X token\n    :param y: the Y token\n    :param hx: X's head tokens\n    :param hy: Y's head tokens\n    :param lch: the lowest common ancestor of X and Y\n    :return: more paths, with satellite links\n    \"\"\"", "\n", "if", "path", "is", "None", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "x_tokens", ",", "hx", ",", "lch", ",", "hy", ",", "y_tokens", "=", "path", "\n", "paths", "=", "[", "(", "None", ",", "x_tokens", ",", "None", ",", "hx", ",", "lch", ",", "hy", ",", "None", ",", "y_tokens", ",", "None", ")", "]", "\n", "tokens_on_path", "=", "set", "(", "[", "x_tokens", "]", "+", "hx", "+", "[", "lch", "]", "+", "hy", "+", "[", "y_tokens", "]", ")", "\n", "\n", "# Get daughters of x not in the path", "\n", "set_xs", "=", "[", "(", "child", ",", "child", ".", "idx", ")", "for", "child", "in", "x_tokens", ".", "children", "if", "child", "not", "in", "tokens_on_path", "]", "\n", "set_ys", "=", "[", "(", "child", ",", "child", ".", "idx", ")", "for", "child", "in", "y_tokens", ".", "children", "if", "child", "not", "in", "tokens_on_path", "]", "\n", "\n", "x_index", "=", "x_tokens", ".", "idx", "\n", "y_index", "=", "y_tokens", ".", "idx", "\n", "\n", "for", "child", ",", "idx", "in", "set_xs", ":", "\n", "        ", "if", "child", ".", "tag_", "!=", "'PUNCT'", "and", "len", "(", "child", ".", "string", ".", "strip", "(", ")", ")", ">", "1", ":", "\n", "            ", "if", "idx", "<", "x_index", ":", "\n", "                ", "paths", ".", "append", "(", "(", "child", ",", "x_tokens", ",", "None", ",", "hx", ",", "lch", ",", "hy", ",", "None", ",", "y_tokens", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "                ", "paths", ".", "append", "(", "(", "None", ",", "x_tokens", ",", "child", ",", "hx", ",", "lch", ",", "hy", ",", "None", ",", "y_tokens", ",", "None", ")", ")", "\n", "\n", "", "", "", "for", "child", ",", "idx", "in", "set_ys", ":", "\n", "        ", "if", "child", ".", "tag_", "!=", "'PUNCT'", "and", "len", "(", "child", ".", "string", ".", "strip", "(", ")", ")", ">", "1", ":", "\n", "            ", "if", "idx", "<", "y_index", ":", "\n", "                ", "paths", ".", "append", "(", "(", "None", ",", "x_tokens", ",", "None", ",", "hx", ",", "lch", ",", "hy", ",", "child", ",", "y_tokens", ",", "None", ")", ")", "\n", "", "else", ":", "\n", "                ", "paths", ".", "append", "(", "(", "None", ",", "x_tokens", ",", "None", ",", "hx", ",", "lch", ",", "hy", ",", "None", ",", "y_tokens", ",", "child", ")", ")", "\n", "\n", "", "", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string": [[237, 244], ["t.lemma_.strip().lower", "t.lemma_.strip"], "function", ["None"], ["", "def", "edge_to_string", "(", "t", ",", "is_head", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Converts the token to an edge string representation\n    :param token: the token\n    :return: the edge string\n    \"\"\"", "\n", "return", "'/'", ".", "join", "(", "[", "t", ".", "lemma_", ".", "strip", "(", ")", ".", "lower", "(", ")", ",", "t", ".", "pos_", ",", "t", ".", "dep_", "if", "t", ".", "dep_", "!=", "''", "and", "not", "is_head", "else", "'ROOT'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.argument_to_string": [[246, 254], ["None"], "function", ["None"], ["", "def", "argument_to_string", "(", "token", ",", "edge_name", ")", ":", "\n", "    ", "\"\"\"\n    Converts the argument token (X or Y) to an edge string representation\n    :param token: the X or Y token\n    :param edge_name: 'X' or 'Y'\n    :return:\n    \"\"\"", "\n", "return", "'/'", ".", "join", "(", "[", "edge_name", ",", "token", ".", "pos_", ",", "token", ".", "dep_", "if", "token", ".", "dep_", "!=", "''", "else", "'ROOT'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction": [[256, 272], ["None"], "function", ["None"], ["", "def", "direction", "(", "dir", ")", ":", "\n", "    ", "\"\"\"\n    Print the direction of the edge\n    :param dir: the direction\n    :return: a string representation of the direction\n    \"\"\"", "\n", "# Up to the head", "\n", "if", "dir", "==", "UP", ":", "\n", "        ", "return", "'>'", "\n", "# Down from the head", "\n", "", "elif", "dir", "==", "DOWN", ":", "\n", "        ", "return", "'<'", "\n", "", "elif", "dir", "==", "SAT", ":", "\n", "        ", "return", "'V'", "\n", "", "else", ":", "\n", "        ", "return", "'^'", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.pretty_print": [[274, 320], ["parse_wikipedia.direction", "parse_wikipedia.direction", "len", "parse_wikipedia.direction", "parse_wikipedia.direction", "parse_wikipedia.direction", "parse_wikipedia.direction", "len", "parse_wikipedia.direction", "parse_wikipedia.direction", "parse_wikipedia.direction", "parse_wikipedia.direction", "len", "parse_wikipedia.edge_to_string", "parse_wikipedia.edge_to_string", "parse_wikipedia.edge_to_string", "parse_wikipedia.edge_to_string", "len", "parse_wikipedia.direction", "len", "parse_wikipedia.edge_to_string", "len", "len", "parse_wikipedia.argument_to_string", "parse_wikipedia.direction", "parse_wikipedia.edge_to_string", "parse_wikipedia.direction", "parse_wikipedia.edge_to_string", "parse_wikipedia.argument_to_string"], "function", ["home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.argument_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.direction", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.edge_to_string", "home.repos.pwc.inspect_result.vered1986_LexNET.corpus.parse_wikipedia.argument_to_string"], ["", "", "def", "pretty_print", "(", "set_x_l", ",", "x", ",", "set_x_r", ",", "hx", ",", "lch", ",", "hy", ",", "set_y_l", ",", "y", ",", "set_y_r", ")", ":", "\n", "    ", "\"\"\"\n    Filter out long paths and pretty print the short ones\n    :return: the string representation of the path\n    \"\"\"", "\n", "set_path_x_l", "=", "[", "]", "\n", "set_path_x_r", "=", "[", "]", "\n", "set_path_y_r", "=", "[", "]", "\n", "set_path_y_l", "=", "[", "]", "\n", "lch_lst", "=", "[", "]", "\n", "\n", "if", "set_x_l", ":", "\n", "        ", "set_path_x_l", "=", "[", "edge_to_string", "(", "set_x_l", ")", "+", "'/'", "+", "direction", "(", "SAT", ")", "]", "\n", "", "if", "set_x_r", ":", "\n", "        ", "set_path_x_r", "=", "[", "edge_to_string", "(", "set_x_r", ")", "+", "'/'", "+", "direction", "(", "SAT", ")", "]", "\n", "", "if", "set_y_l", ":", "\n", "        ", "set_path_y_l", "=", "[", "edge_to_string", "(", "set_y_l", ")", "+", "'/'", "+", "direction", "(", "SAT", ")", "]", "\n", "", "if", "set_y_r", ":", "\n", "        ", "set_path_y_r", "=", "[", "edge_to_string", "(", "set_y_r", ")", "+", "'/'", "+", "direction", "(", "SAT", ")", "]", "\n", "\n", "# X is the head", "\n", "", "if", "lch", "==", "x", ":", "\n", "        ", "dir_x", "=", "direction", "(", "ROOT", ")", "\n", "dir_y", "=", "direction", "(", "DOWN", ")", "\n", "# Y is the head", "\n", "", "elif", "lch", "==", "y", ":", "\n", "        ", "dir_x", "=", "direction", "(", "UP", ")", "\n", "dir_y", "=", "direction", "(", "ROOT", ")", "\n", "# X and Y are not heads", "\n", "", "else", ":", "\n", "        ", "lch_lst", "=", "[", "edge_to_string", "(", "lch", ",", "is_head", "=", "True", ")", "+", "'/'", "+", "direction", "(", "ROOT", ")", "]", "if", "lch", "else", "[", "]", "\n", "dir_x", "=", "direction", "(", "UP", ")", "\n", "dir_y", "=", "direction", "(", "DOWN", ")", "\n", "\n", "", "len_path", "=", "len", "(", "hx", ")", "+", "len", "(", "hy", ")", "+", "len", "(", "set_path_x_r", ")", "+", "len", "(", "set_path_x_l", ")", "+", "len", "(", "set_path_y_r", ")", "+", "len", "(", "set_path_y_l", ")", "+", "len", "(", "lch_lst", ")", "\n", "\n", "if", "len_path", "<=", "MAX_PATH_LEN", ":", "\n", "        ", "cleaned_path", "=", "'_'", ".", "join", "(", "set_path_x_l", "+", "[", "argument_to_string", "(", "x", ",", "'X'", ")", "+", "'/'", "+", "dir_x", "]", "+", "set_path_x_r", "+", "\n", "[", "edge_to_string", "(", "token", ")", "+", "'/'", "+", "direction", "(", "UP", ")", "for", "token", "in", "hx", "]", "+", "\n", "lch_lst", "+", "\n", "[", "edge_to_string", "(", "token", ")", "+", "'/'", "+", "direction", "(", "DOWN", ")", "for", "token", "in", "hy", "]", "+", "\n", "set_path_y_l", "+", "[", "argument_to_string", "(", "y", ",", "'Y'", ")", "+", "'/'", "+", "dir_y", "]", "+", "set_path_y_r", ")", "\n", "return", "cleaned_path", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.__init__": [[8, 18], ["bsddb.btopen", "bsddb.btopen", "bsddb.btopen", "bsddb.btopen", "bsddb.btopen"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "resource_prefix", ")", ":", "\n", "        ", "\"\"\"\n        Init the knowledge resource\n        :param resource_prefix - the resource directory and file prefix\n        \"\"\"", "\n", "self", ".", "term_to_id", "=", "bsddb", ".", "btopen", "(", "resource_prefix", "+", "'_term_to_id.db'", ",", "'r'", ")", "\n", "self", ".", "id_to_term", "=", "bsddb", ".", "btopen", "(", "resource_prefix", "+", "'_id_to_term.db'", ",", "'r'", ")", "\n", "self", ".", "path_to_id", "=", "bsddb", ".", "btopen", "(", "resource_prefix", "+", "'_path_to_id.db'", ",", "'r'", ")", "\n", "self", ".", "id_to_path", "=", "bsddb", ".", "btopen", "(", "resource_prefix", "+", "'_id_to_path.db'", ",", "'r'", ")", "\n", "self", ".", "l2r_edges", "=", "bsddb", ".", "btopen", "(", "resource_prefix", "+", "'_l2r.db'", ",", "'r'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.get_term_by_id": [[19, 21], ["str"], "methods", ["None"], ["", "def", "get_term_by_id", "(", "self", ",", "id", ")", ":", "\n", "        ", "return", "self", ".", "id_to_term", "[", "str", "(", "id", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.get_path_by_id": [[22, 24], ["str"], "methods", ["None"], ["", "def", "get_path_by_id", "(", "self", ",", "id", ")", ":", "\n", "        ", "return", "self", ".", "id_to_path", "[", "str", "(", "id", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.get_id_by_term": [[25, 27], ["knowledge_resource.KnowledgeResource.term_to_id.has_key", "int"], "methods", ["None"], ["", "def", "get_id_by_term", "(", "self", ",", "term", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "term_to_id", "[", "term", "]", ")", "if", "self", ".", "term_to_id", ".", "has_key", "(", "term", ")", "else", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.get_id_by_path": [[28, 30], ["knowledge_resource.KnowledgeResource.path_to_id.has_key", "int"], "methods", ["None"], ["", "def", "get_id_by_path", "(", "self", ",", "path", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "path_to_id", "[", "path", "]", ")", "if", "self", ".", "path_to_id", ".", "has_key", "(", "path", ")", "else", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.vered1986_LexNET.common.knowledge_resource.KnowledgeResource.get_relations": [[31, 44], ["str", "knowledge_resource.KnowledgeResource.l2r_edges.has_key", "len", "str", "tuple", "map", "path_str.split", "p.split"], "methods", ["None"], ["", "def", "get_relations", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Returns the relations from x to y\n        \"\"\"", "\n", "path_dict", "=", "{", "}", "\n", "key", "=", "str", "(", "x", ")", "+", "'###'", "+", "str", "(", "y", ")", "\n", "path_str", "=", "self", ".", "l2r_edges", "[", "key", "]", "if", "self", ".", "l2r_edges", ".", "has_key", "(", "key", ")", "else", "''", "\n", "\n", "if", "len", "(", "path_str", ")", ">", "0", ":", "\n", "            ", "paths", "=", "[", "tuple", "(", "map", "(", "int", ",", "p", ".", "split", "(", "':'", ")", ")", ")", "for", "p", "in", "path_str", ".", "split", "(", "','", ")", "]", "\n", "path_dict", "=", "{", "path", ":", "count", "for", "(", "path", ",", "count", ")", "in", "paths", "}", "\n", "\n", "", "return", "path_dict", "\n", "", "", ""]]}