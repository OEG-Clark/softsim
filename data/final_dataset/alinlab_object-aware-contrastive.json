{"home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.cli_main": [[17, 82], ["argparse.ArgumentParser", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "model_class.add_model_specific_args.add_argument", "pytorch_lightning.Trainer.add_argparse_args", "model_class.add_model_specific_args.parse_args", "pytorch_lightning.seed_everything", "print", "models.get_model_class", "models.get_model_class.add_model_specific_args", "sys.path.insert", "os.path.join", "os.path.join", "models.get_model_class.load_from_checkpoint", "inference.lineval", "utils.GradCAM", "models.load_redo_model", "ValueError", "inference.seg", "model_class.add_model_specific_args.parse_known_args", "inference.save_box", "model_class.add_model_specific_args.parse_known_args", "inference.save_mask", "ValueError"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.__init__.get_model_class", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.lineval", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.__init__.load_redo_model", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.seg", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.save_box", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.save_mask"], ["def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_dir\"", ",", "default", "=", "\"logs\"", ",", "type", "=", "str", ",", "help", "=", "\"log directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--ckpt_name'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "'name of checkpoint directory'", ")", "\n", "parser", ".", "add_argument", "(", "\"--ckpt_version\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"checkpoint version\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ckpt_epoch\"", ",", "default", "=", "'last'", ",", "type", "=", "str", ",", "help", "=", "\"checkpoint epoch\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "\"random seed\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "default", "=", "'lineval'", ",", "type", "=", "str", ",", "help", "=", "\"inference mode\"", ")", "\n", "parser", ".", "add_argument", "(", "'--clf_type'", ",", "default", "=", "'lbfgs'", ",", "type", "=", "str", ",", "help", "=", "\"classifier type\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"save boxes/masks in the path\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cam_score'", ",", "default", "=", "'con'", ",", "type", "=", "str", ",", "help", "=", "\"CAM score function\"", ")", "\n", "parser", ".", "add_argument", "(", "'--expand_res'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"expand resolution for CAM\"", ")", "\n", "parser", ".", "add_argument", "(", "'--cam_iters'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"CAM # of iterative refinements\"", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_crf'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"apply CRF for segmentation masks\"", ")", "\n", "parser", ".", "add_argument", "(", "'--box_margin'", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "help", "=", "\"margin for bounding boxes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--box_threshold'", ",", "default", "=", "None", ",", "type", "=", "float", ",", "help", "=", "\"threshold for bounding boxes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--largest_box_only'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"store only the largest box\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "default", "=", "\"moco\"", ",", "type", "=", "str", ",", "help", "=", "\"pre-training model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--normalize\"", ",", "default", "=", "\"coco\"", ",", "type", "=", "str", ",", "help", "=", "\"mean/std of pre-trained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"coco\"", ",", "type", "=", "str", ",", "help", "=", "\"dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "help", "=", "\"batch size per gpu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"num of workers per GPU\"", ")", "\n", "\n", "if", "parser", ".", "parse_known_args", "(", ")", "[", "0", "]", ".", "model", "!=", "'redo'", ":", "\n", "        ", "model_class", "=", "get_model_class", "(", "parser", ".", "parse_known_args", "(", ")", "[", "0", "]", ".", "model", ")", "# model class", "\n", "parser", "=", "model_class", ".", "add_model_specific_args", "(", "parser", ")", "# model-specific arguments", "\n", "\n", "", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "# trainer arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "pl", ".", "seed_everything", "(", "1234", ")", "\n", "\n", "# load model", "\n", "if", "args", ".", "model", "in", "[", "'moco'", ",", "'byol'", "]", ":", "\n", "# compatible with pretrained models", "\n", "        ", "import", "sys", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "'./data'", ")", "\n", "\n", "args", ".", "ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "ckpt_name", ",", "'version_{}'", ".", "format", "(", "args", ".", "ckpt_version", ")", ")", "\n", "args", ".", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "ckpt_dir", ",", "'checkpoints'", ",", "'{}.ckpt'", ".", "format", "(", "args", ".", "ckpt_epoch", ")", ")", "\n", "model", "=", "model_class", ".", "load_from_checkpoint", "(", "args", ".", "ckpt_path", ")", "\n", "\n", "if", "args", ".", "mode", "in", "[", "'seg'", ",", "'save_box'", ",", "'save_mask'", "]", ":", "# use CAM model", "\n", "            ", "model", "=", "GradCAM", "(", "model", ".", "encoder", ",", "projector", "=", "model", ".", "projector", ",", "expand_res", "=", "args", ".", "expand_res", ")", "\n", "\n", "", "", "elif", "args", ".", "model", "==", "'redo'", ":", "\n", "        ", "args", ".", "image_size", "=", "128", "\n", "args", ".", "normalize", "=", "'redo'", "\n", "model", "=", "load_redo_model", "(", "args", ".", "dataset", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'No matching model class'", ")", "\n", "\n", "", "print", "(", "'Model: {}  Dataset: {}  Mode: {}'", ".", "format", "(", "args", ".", "model", ",", "args", ".", "dataset", ",", "args", ".", "mode", ")", ")", "\n", "if", "args", ".", "mode", "==", "'lineval'", ":", "\n", "        ", "lineval", "(", "args", ",", "model", ")", "\n", "", "elif", "args", ".", "mode", "==", "'seg'", ":", "\n", "        ", "seg", "(", "args", ",", "model", ")", "\n", "", "elif", "args", ".", "mode", "==", "'save_box'", ":", "\n", "        ", "save_box", "(", "args", ",", "model", ")", "\n", "", "elif", "args", ".", "mode", "==", "'save_mask'", ":", "\n", "        ", "save_mask", "(", "args", ",", "model", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'No matching inference mode'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.lineval": [[84, 146], ["model.to.to", "model.to.eval", "data.transforms.get_normalization", "data.transforms.FinetuneTransform", "data.load_finetune_datamodule", "print", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "utils.collect_outputs", "utils.collect_outputs", "utils.collect_outputs", "open", "f.write", "data.load_finetune_datamodule.train_dataloader", "data.load_finetune_datamodule.val_dataloader", "data.load_finetune_datamodule.test_dataloader", "torch.Linear().to", "torch.init.normal_", "torch.init.normal_", "torch.optim.LBFGS", "torch.optim.LBFGS", "torch.optim.LBFGS", "torch.logspace().tolist", "torch.logspace().tolist", "torch.logspace().tolist", "utils.accuracy", "print", "os.path.join", "X_train.to", "Y_train.to", "X_val.to", "Y_val.to", "X_test.to", "Y_test.to", "nn.Linear().to.parameters", "torch.optim.LBFGS.step", "utils.accuracy", "utils.accuracy", "utils.accuracy", "print", "torch.optim.LBFGS.zero_grad", "torch.cross_entropy", "nn.Linear().to.parameters", "F.cross_entropy.backward", "torch.Linear", "torch.logspace", "torch.logspace", "torch.logspace", "inference.lineval.build_step"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_finetune_datamodule", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.collect_outputs", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.collect_outputs", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.collect_outputs", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.train_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.val_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.test_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.accuracy", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.accuracy", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.accuracy", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.accuracy"], ["", "", "def", "lineval", "(", "args", ",", "model", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "normalize", "=", "get_normalization", "(", "args", ".", "normalize", ")", "\n", "t_norm", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ",", "crop", "=", "'center'", ")", "\n", "\n", "dm", "=", "load_finetune_datamodule", "(", "args", ".", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "train_transform", "=", "t_norm", ",", "test_transform", "=", "t_norm", ")", "\n", "\n", "print", "(", "'Computing features...'", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "X_train", ",", "Y_train", "=", "collect_outputs", "(", "model", ",", "dm", ".", "train_dataloader", "(", ")", ")", "\n", "X_val", ",", "Y_val", "=", "collect_outputs", "(", "model", ",", "dm", ".", "val_dataloader", "(", ")", ")", "\n", "X_test", ",", "Y_test", "=", "collect_outputs", "(", "model", ",", "dm", ".", "test_dataloader", "(", ")", ")", "\n", "\n", "# train and evaluate linear classifier", "\n", "", "print", "(", "'Evaluating classifier...'", ")", "\n", "if", "args", ".", "clf_type", "==", "'sgd'", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "elif", "args", ".", "clf_type", "==", "'lbfgs'", ":", "\n", "        ", "def", "build_step", "(", "X", ",", "Y", ",", "classifier", ",", "optimizer", ",", "weight", ")", ":", "\n", "            ", "def", "step", "(", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "classifier", "(", "X", ")", ",", "Y", ")", "\n", "for", "p", "in", "classifier", ".", "parameters", "(", ")", ":", "\n", "                    ", "loss", "=", "loss", "+", "p", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", ".", "mul", "(", "0.5", "*", "weight", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "return", "loss", "\n", "", "return", "step", "\n", "\n", "", "X_train", ",", "Y_train", "=", "X_train", ".", "to", "(", "device", ")", ",", "Y_train", ".", "to", "(", "device", ")", "\n", "X_val", ",", "Y_val", "=", "X_val", ".", "to", "(", "device", ")", ",", "Y_val", ".", "to", "(", "device", ")", "\n", "X_test", ",", "Y_test", "=", "X_test", ".", "to", "(", "device", ")", ",", "Y_test", ".", "to", "(", "device", ")", "\n", "\n", "classifier", "=", "nn", ".", "Linear", "(", "model", ".", "encoder", ".", "feat_dim", ",", "dm", ".", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "classifier", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "classifier", ".", "bias", ",", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "LBFGS", "(", "classifier", ".", "parameters", "(", ")", ",", "max_iter", "=", "1000", ")", "\n", "\n", "best_acc", "=", "0", "\n", "best_classifier", "=", "None", "\n", "for", "w", "in", "torch", ".", "logspace", "(", "-", "6", ",", "5", ",", "steps", "=", "45", ")", ".", "tolist", "(", ")", ":", "\n", "            ", "optimizer", ".", "step", "(", "build_step", "(", "X_train", ",", "Y_train", ",", "classifier", ",", "optimizer", ",", "w", ")", ")", "\n", "train_acc", "=", "accuracy", "(", "X_train", ",", "Y_train", ",", "classifier", ")", "\n", "val_acc", "=", "accuracy", "(", "X_val", ",", "Y_val", ",", "classifier", ")", "\n", "test_acc", "=", "accuracy", "(", "X_test", ",", "Y_test", ",", "classifier", ")", "\n", "print", "(", "'w: {:13.6f}  Train acc.: {:.2f}  Val acc.:{:.2f}  Test acc.:{:.2f}'", ".", "format", "(", "\n", "w", ",", "train_acc", "*", "100", ",", "val_acc", "*", "100", ",", "test_acc", "*", "100", ")", ")", "\n", "\n", "if", "val_acc", ">", "best_acc", ":", "\n", "                ", "best_acc", "=", "val_acc", "\n", "best_classifier", "=", "deepcopy", "(", "classifier", ")", "\n", "\n", "", "", "test_acc", "=", "accuracy", "(", "X_test", ",", "Y_test", ",", "best_classifier", ")", "\n", "print", "(", "'Test acc.:{:.2f}'", ".", "format", "(", "test_acc", "*", "100", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "ckpt_dir", ",", "'lineval.txt'", ")", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'{}\\t{}\\te{}\\t{:.2f}\\n'", ".", "format", "(", "args", ".", "dataset", ",", "args", ".", "clf_type", ",", "args", ".", "ckpt_epoch", ",", "test_acc", "*", "100", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.seg": [[148, 173], ["model.to.to", "model.to.eval", "data.transforms.get_normalization", "data.transforms.FinetuneTransform", "data.transforms.FinetuneTransform", "print", "data.load_segment_datamodule", "data.load_segment_datamodule.test_dataloader", "inference.compute_masks", "utils.clean_mask", "print", "utils.compute_mask_miou", "print", "torch.cat", "torch.cat", "torch.cat", "utils.apply_crf"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_segment_datamodule", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.test_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.compute_masks", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.clean_mask", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.compute_mask_miou", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.apply_crf"], ["", "", "def", "seg", "(", "args", ",", "model", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "normalize", "=", "get_normalization", "(", "args", ".", "normalize", ")", "\n", "t_norm", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ",", "crop", "=", "'none'", ")", "\n", "t_orig", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "crop", "=", "'none'", ")", "\n", "\n", "print", "(", "'Computing masks...'", ")", "\n", "dm", "=", "load_segment_datamodule", "(", "args", ".", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "transform", "=", "t_norm", ",", "target_transform", "=", "t_orig", ")", "\n", "loader", "=", "dm", ".", "test_dataloader", "(", ")", "# test loader", "\n", "\n", "pred_masks", ",", "gt_masks", "=", "compute_masks", "(", "args", ",", "model", ",", "loader", ")", "\n", "\n", "if", "args", ".", "apply_crf", ":", "\n", "        ", "loader", ".", "dataset", ".", "transform", "=", "t_orig", "# original images", "\n", "images", "=", "torch", ".", "cat", "(", "[", "x", "for", "x", ",", "_", "in", "loader", "]", ")", "\n", "pred_masks", "=", "box_utils", ".", "apply_crf", "(", "images", ",", "pred_masks", ")", "\n", "\n", "", "pred_masks", "=", "box_utils", ".", "clean_mask", "(", "pred_masks", ")", "\n", "\n", "print", "(", "'Evaluating segmentation...'", ")", "\n", "miou", "=", "box_utils", ".", "compute_mask_miou", "(", "gt_masks", ",", "pred_masks", ")", "\n", "print", "(", "'Mask mIoU: {:.4f}'", ".", "format", "(", "miou", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.save_box": [[175, 201], ["model.to.to", "model.to.eval", "data.transforms.get_normalization", "data.transforms.FinetuneTransform", "data.transforms.FinetuneTransform", "print", "data.load_pretrain_datamodule", "data.load_pretrain_datamodule.train_dataloader", "data.get_image_ids", "inference.compute_masks", "utils.clean_mask", "utils.extract_boxes", "utils.save_boxes", "torch.cat", "torch.cat", "torch.cat", "utils.apply_crf", "zip"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_pretrain_datamodule", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.train_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.get_image_ids", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.compute_masks", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.clean_mask", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.extract_boxes", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.save_boxes", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.apply_crf"], ["", "def", "save_box", "(", "args", ",", "model", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "normalize", "=", "get_normalization", "(", "args", ".", "normalize", ")", "\n", "t_norm", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ",", "crop", "=", "'none'", ")", "\n", "t_orig", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "crop", "=", "'none'", ")", "\n", "\n", "print", "(", "'Computing masks...'", ")", "\n", "dm", "=", "load_pretrain_datamodule", "(", "args", ".", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "train_transform", "=", "t_norm", ",", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "loader", "=", "dm", ".", "train_dataloader", "(", ")", "# train loader", "\n", "\n", "image_ids", "=", "get_image_ids", "(", "loader", ".", "dataset", ")", "\n", "pred_masks", ",", "_", "=", "compute_masks", "(", "args", ",", "model", ",", "loader", ")", "\n", "\n", "if", "args", ".", "apply_crf", ":", "\n", "        ", "loader", ".", "dataset", ".", "transform", "=", "t_orig", "# original images", "\n", "images", "=", "torch", ".", "cat", "(", "[", "x", "for", "x", ",", "_", "in", "loader", "]", ")", "\n", "pred_masks", "=", "box_utils", ".", "apply_crf", "(", "images", ",", "pred_masks", ")", "\n", "\n", "", "pred_masks", "=", "box_utils", ".", "clean_mask", "(", "pred_masks", ",", "single", "=", "args", ".", "single_instance", ",", "min_obj_scale", "=", "0.01", ")", "\n", "pred_boxes", "=", "box_utils", ".", "extract_boxes", "(", "pred_masks", ",", "image_size", "=", "args", ".", "image_size", ",", "margin", "=", "args", ".", "box_margin", ")", "\n", "\n", "pred_boxes", "=", "{", "img_id", ":", "boxes", "for", "img_id", ",", "boxes", "in", "zip", "(", "image_ids", ",", "pred_boxes", ")", "}", "\n", "box_utils", ".", "save_boxes", "(", "pred_boxes", ",", "args", ".", "save_box_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.save_mask": [[203, 221], ["model.to.to", "model.to.eval", "data.transforms.get_normalization", "data.transforms.FinetuneTransform", "data.transforms.FinetuneTransform", "print", "data.load_pretrain_datamodule", "data.load_pretrain_datamodule.train_dataloader", "data.get_image_ids", "inference.compute_masks", "utils.save_masks", "zip"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_pretrain_datamodule", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.train_dataloader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.get_image_ids", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.compute_masks", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.save_masks"], ["", "def", "save_mask", "(", "args", ",", "model", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "normalize", "=", "get_normalization", "(", "args", ".", "normalize", ")", "\n", "t_norm", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ",", "crop", "=", "'none'", ")", "\n", "t_orig", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "crop", "=", "'none'", ")", "\n", "\n", "print", "(", "'Computing masks...'", ")", "\n", "dm", "=", "load_pretrain_datamodule", "(", "args", ".", "dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "train_transform", "=", "t_norm", ",", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "loader", "=", "dm", ".", "train_dataloader", "(", ")", "# train loader", "\n", "\n", "image_ids", "=", "get_image_ids", "(", "loader", ".", "dataset", ")", "\n", "pred_masks", ",", "_", "=", "compute_masks", "(", "args", ",", "model", ",", "loader", ")", "\n", "\n", "pred_masks", "=", "{", "img_id", ":", "mask", "for", "img_id", ",", "mask", "in", "zip", "(", "image_ids", ",", "pred_masks", ")", "}", "\n", "box_utils", ".", "save_masks", "(", "pred_masks", ",", "args", ".", "save_path", ",", "loader", ".", "dataset", ".", "root", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.inference.compute_masks": [[223, 232], ["isinstance", "utils.collect_outputs"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.collect_outputs"], ["", "def", "compute_masks", "(", "args", ",", "model", ",", "loader", ")", ":", "\n", "    ", "forward_kwargs", "=", "{", "}", "\n", "if", "isinstance", "(", "model", ",", "GradCAM", ")", ":", "\n", "        ", "forward_kwargs", "[", "'score_type'", "]", "=", "args", ".", "cam_score", "\n", "if", "args", ".", "cam_score", "==", "'con'", ":", "\n", "            ", "forward_kwargs", "[", "'n_iters'", "]", "=", "args", ".", "cam_iters", "\n", "\n", "", "", "x", ",", "y", "=", "collect_outputs", "(", "model", ",", "loader", ",", "**", "forward_kwargs", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.None.pretrain.cli_main": [[13, 81], ["argparse.ArgumentParser", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "pl.Trainer.add_argparse_args.add_argument", "models.get_model_class", "models.get_model_class.add_model_specific_args", "pytorch_lightning.Trainer.add_argparse_args", "pl.Trainer.add_argparse_args.parse_args", "pytorch_lightning.seed_everything", "data.transforms.get_normalization", "data.transforms.PretrainTransform", "data.transforms.FinetuneTransform", "data.transforms.KorniaTransform", "data.load_pretrain_datamodule", "models.get_model_class.", "utils.SSLOnlineEvaluator", "utils.ModelCheckpoint", "pytorch_lightning.Trainer.from_argparse_args", "pl.Trainer.from_argparse_args.fit", "isinstance", "torch.cuda.device_count", "pytorch_lightning.loggers.TensorBoardLogger", "pl.Trainer.add_argparse_args.parse_known_args", "parser.parse_args.arch.replace"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.__init__.get_model_class", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_pretrain_datamodule"], ["def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_dir\"", ",", "default", "=", "\"logs\"", ",", "type", "=", "str", ",", "help", "=", "\"log directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"experiment name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--suffix\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"suffix for experiment name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--version\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"version (same as random seed)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "default", "=", "\"moco\"", ",", "type", "=", "str", ",", "help", "=", "\"pre-training model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"coco\"", ",", "type", "=", "str", ",", "help", "=", "\"dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ft_datasets\"", ",", "default", "=", "[", "\"coco\"", "]", ",", "nargs", "=", "'*'", ",", "type", "=", "str", ",", "help", "=", "\"datasets for fine-tuning\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "help", "=", "\"batch size per gpu\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"num of workers per GPU\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_freq\"", ",", "default", "=", "25", ",", "type", "=", "int", ",", "help", "=", "\"save frequency of model\"", ")", "\n", "\n", "model_class", "=", "get_model_class", "(", "parser", ".", "parse_known_args", "(", ")", "[", "0", "]", ".", "model", ")", "# model class", "\n", "\n", "parser", "=", "model_class", ".", "add_model_specific_args", "(", "parser", ")", "# model-specific arguments", "\n", "parser", "=", "pl", ".", "Trainer", ".", "add_argparse_args", "(", "parser", ")", "# trainer arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "pl", ".", "seed_everything", "(", "args", ".", "version", ")", "# fix random seed", "\n", "\n", "# set default arguments", "\n", "if", "not", "isinstance", "(", "args", ".", "gpus", ",", "int", ")", ":", "\n", "        ", "args", ".", "gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "args", ".", "benchmark", "=", "True", "\n", "\n", "args", ".", "check_val_every_n_epoch", "=", "25", "\n", "args", ".", "save_freq", "=", "25", "\n", "args", ".", "num_sanity_val_steps", "=", "0", "\n", "\n", "args", ".", "global_batch_size", "=", "args", ".", "num_nodes", "*", "args", ".", "gpus", "*", "args", ".", "batch_size", "\n", "\n", "if", "args", ".", "name", "is", "None", ":", "# default log name", "\n", "        ", "args", ".", "name", "=", "'_'", ".", "join", "(", "[", "args", ".", "dataset", ",", "args", ".", "model", ",", "args", ".", "arch", ".", "replace", "(", "'esnet'", ",", "''", ")", ",", "f'b{args.global_batch_size}'", "]", ")", "\n", "", "if", "args", ".", "suffix", "is", "not", "None", ":", "\n", "        ", "args", ".", "name", "+=", "'_{}'", ".", "format", "(", "args", ".", "suffix", ")", "\n", "\n", "# define datamodule and model", "\n", "", "normalize", "=", "get_normalization", "(", "args", ".", "dataset", ")", "\n", "crop_scale", "=", "(", "args", ".", "min_crop_scale", ",", "args", ".", "max_crop_scale", ")", "\n", "\n", "train_transform", "=", "PretrainTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "crop_scale", "=", "crop_scale", ",", "use_mask", "=", "(", "'mask'", "in", "args", ".", "dataset", ")", ")", "\n", "test_transform", "=", "FinetuneTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ")", "\n", "\n", "args", ".", "diff_transform", "=", "KorniaTransform", "(", "image_size", "=", "args", ".", "image_size", ",", "normalize", "=", "normalize", ",", "\n", "jitter_strength", "=", "args", ".", "jitter_strength", ",", "\n", "gaussian_blur", "=", "args", ".", "gaussian_blur", ")", "\n", "\n", "dm", "=", "load_pretrain_datamodule", "(", "args", ".", "dataset", ",", "ft_datasets", "=", "args", ".", "ft_datasets", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "\n", "train_transform", "=", "train_transform", ",", "test_transform", "=", "test_transform", ")", "\n", "\n", "model", "=", "model_class", "(", "**", "args", ".", "__dict__", ")", "\n", "\n", "# run experiments", "\n", "online_evaluator", "=", "SSLOnlineEvaluator", "(", "in_features", "=", "model", ".", "encoder", ".", "feat_dim", ",", "ft_datasets", "=", "args", ".", "ft_datasets", ")", "\n", "model_checkpoint", "=", "ModelCheckpoint", "(", "save_freq", "=", "args", ".", "save_freq", ")", "\n", "callbacks", "=", "[", "online_evaluator", ",", "model_checkpoint", "]", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "logger", "=", "TensorBoardLogger", "(", "args", ".", "log_dir", ",", "args", ".", "name", ",", "args", ".", "version", ")", ",", "\n", "accelerator", "=", "'ddp'", "if", "args", ".", "gpus", ">", "1", "else", "None", ",", "\n", "sync_batchnorm", "=", "True", "if", "args", ".", "gpus", ">", "1", "else", "False", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", ")", "\n", "\n", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.model_checkpoint.ModelCheckpoint.__init__": [[8, 12], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "save_freq", "=", "1", ",", "save_weights_only", "=", "False", ")", ":", "\n", "        ", "self", ".", "ckpt_dir", "=", "None", "\n", "self", ".", "save_freq", "=", "save_freq", "\n", "self", ".", "save_weights_only", "=", "save_weights_only", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.model_checkpoint.ModelCheckpoint.on_pretrain_routine_start": [[13, 17], ["os.path.join", "os.makedirs"], "methods", ["None"], ["", "def", "on_pretrain_routine_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "self", ".", "ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "trainer", ".", "logger", ".", "log_dir", ",", "\"checkpoints\"", ")", "\n", "if", "not", "trainer", ".", "fast_dev_run", "and", "trainer", ".", "is_global_zero", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "ckpt_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.model_checkpoint.ModelCheckpoint.on_train_epoch_end": [[18, 26], ["os.path.join", "trainer.save_checkpoint", "os.path.join", "trainer.save_checkpoint"], "methods", ["None"], ["", "", "def", "on_train_epoch_end", "(", "self", ",", "trainer", ",", "pl_module", ",", "outputs", ")", ":", "\n", "        ", "epoch", "=", "trainer", ".", "current_epoch", "+", "1", "# start from 1", "\n", "if", "epoch", "%", "self", ".", "save_freq", "==", "0", ":", "\n", "            ", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "ckpt_dir", ",", "'{}.ckpt'", ".", "format", "(", "epoch", ")", ")", "\n", "trainer", ".", "save_checkpoint", "(", "ckpt_path", ",", "self", ".", "save_weights_only", ")", "\n", "", "if", "epoch", "==", "trainer", ".", "max_epochs", ":", "\n", "            ", "ckpt_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "ckpt_dir", ",", "'last.ckpt'", ")", "\n", "trainer", ".", "save_checkpoint", "(", "ckpt_path", ",", "self", ".", "save_weights_only", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator.__init__": [[9, 16], ["pytorch_lightning.Callback.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "ft_datasets", ",", "n_splits", "=", "100", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "ft_datasets", "=", "ft_datasets", "if", "isinstance", "(", "ft_datasets", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "ft_datasets", "]", "\n", "self", ".", "n_splits", "=", "n_splits", "\n", "self", ".", "features", "=", "None", "\n", "self", ".", "labels", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator.on_validation_start": [[17, 21], ["range", "range", "len", "len"], "methods", ["None"], ["", "def", "on_validation_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "# save train/test features and labels for each fine-tuning datasets", "\n", "        ", "self", ".", "features", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", "*", "len", "(", "self", ".", "ft_datasets", ")", ")", "]", "\n", "self", ".", "labels", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", "*", "len", "(", "self", ".", "ft_datasets", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator.on_validation_batch_end": [[22, 35], ["batch[].to", "batch[].to", "ssl_online.SSLOnlineEvaluator.features[].append", "ssl_online.SSLOnlineEvaluator.labels[].append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pl_module", "pl_module.all_gather().view", "pl_module.all_gather().view", "pl_module.all_gather().view.size", "pl_module.all_gather", "pl_module.all_gather"], "methods", ["None"], ["", "def", "on_validation_batch_end", "(", "self", ",", "trainer", ",", "pl_module", ",", "outputs", ",", "batch", ",", "batch_idx", ",", "dataloader_idx", ")", ":", "\n", "        ", "x", "=", "batch", "[", "0", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "y", "=", "batch", "[", "1", "]", ".", "to", "(", "pl_module", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "z", "=", "pl_module", "(", "x", ")", "\n", "\n", "", "if", "trainer", ".", "distributed_backend", "in", "(", "'ddp'", ",", "'ddp_spawn'", ",", "'ddp2'", ")", ":", "\n", "            ", "z", "=", "pl_module", ".", "all_gather", "(", "z", ")", ".", "view", "(", "-", "1", ",", "z", ".", "size", "(", "-", "1", ")", ")", "\n", "y", "=", "pl_module", ".", "all_gather", "(", "y", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "", "self", ".", "features", "[", "dataloader_idx", "]", ".", "append", "(", "z", ")", "\n", "self", ".", "labels", "[", "dataloader_idx", "]", ".", "append", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator.on_validation_epoch_end": [[36, 45], ["enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ssl_online.SSLOnlineEvaluator._compute_accuracy", "pl_module.log"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator._compute_accuracy"], ["", "def", "on_validation_epoch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "for", "i", ",", "name", "in", "enumerate", "(", "self", ".", "ft_datasets", ")", ":", "\n", "            ", "X_train", "=", "torch", ".", "cat", "(", "self", ".", "features", "[", "2", "*", "i", "]", ")", "\n", "Y_train", "=", "torch", ".", "cat", "(", "self", ".", "labels", "[", "2", "*", "i", "]", ")", "\n", "X_test", "=", "torch", ".", "cat", "(", "self", ".", "features", "[", "2", "*", "i", "+", "1", "]", ")", "\n", "Y_test", "=", "torch", ".", "cat", "(", "self", ".", "labels", "[", "2", "*", "i", "+", "1", "]", ")", "\n", "\n", "test_acc", "=", "self", ".", "_compute_accuracy", "(", "X_train", ",", "Y_train", ",", "X_test", ",", "Y_test", ")", "\n", "pl_module", ".", "log", "(", "'test_acc_{}'", ".", "format", "(", "name", ")", ",", "test_acc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.ssl_online.SSLOnlineEvaluator._compute_accuracy": [[46, 59], ["torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "zip", "torch.normalize.size", "torch.normalize.split", "Y_test.split", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.normalize.size", "torch.einsum.argmax", "torch.einsum.argmax"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize"], ["", "", "def", "_compute_accuracy", "(", "self", ",", "X_train", ",", "Y_train", ",", "X_test", ",", "Y_test", ")", ":", "\n", "        ", "X_train", "=", "F", ".", "normalize", "(", "X_train", ")", "\n", "X_test", "=", "F", ".", "normalize", "(", "X_test", ")", "\n", "\n", "n_splits", "=", "X_train", ".", "size", "(", "0", ")", "if", "self", ".", "n_splits", "==", "-", "1", "else", "self", ".", "n_splits", "# GPU memory may be limited", "\n", "\n", "corrects", "=", "0", "\n", "for", "X", ",", "Y", "in", "zip", "(", "X_test", ".", "split", "(", "n_splits", ")", ",", "Y_test", ".", "split", "(", "n_splits", ")", ")", ":", "\n", "            ", "scores", "=", "torch", ".", "einsum", "(", "'ik, jk -> ij'", ",", "X", ",", "X_train", ")", "# cosine distance", "\n", "preds", "=", "Y_train", "[", "scores", ".", "argmax", "(", "1", ")", "]", "\n", "corrects", "+=", "(", "preds", "==", "Y", ")", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "test_acc", "=", "corrects", "/", "X_test", ".", "size", "(", "0", ")", "\n", "return", "test_acc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.upscale_box": [[12, 18], ["box_utils.get_image_size"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.get_image_size"], ["def", "upscale_box", "(", "box", ",", "image_size", ")", ":", "\n", "    ", "\"\"\"Convert box to img_size scale\"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "W", ",", "H", "=", "get_image_size", "(", "image_size", ")", "\n", "box", "=", "(", "x1", "*", "W", ",", "y1", "*", "H", ",", "x2", "*", "W", ",", "y2", "*", "H", ")", "\n", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.downscale_box": [[20, 26], ["box_utils.get_image_size"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.get_image_size"], ["", "def", "downscale_box", "(", "box", ",", "image_size", ")", ":", "\n", "    ", "\"\"\"Convert box to img_size scale\"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "W", ",", "H", "=", "get_image_size", "(", "image_size", ")", "\n", "box", "=", "(", "x1", "/", "W", ",", "y1", "/", "H", ",", "x2", "/", "W", ",", "y2", "/", "H", ")", "\n", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.expand_box": [[28, 41], ["box_utils.get_image_size", "max", "max", "min", "min"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.get_image_size"], ["", "def", "expand_box", "(", "box", ",", "image_size", "=", "(", "1", ",", "1", ")", ",", "margin", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"Expand box with margin and downscale\"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "W", ",", "H", "=", "get_image_size", "(", "image_size", ")", "\n", "\n", "w", ",", "h", "=", "x2", "-", "x1", ",", "y2", "-", "y1", "\n", "x1", "=", "max", "(", "0", ",", "x1", "-", "w", "*", "margin", ")", "/", "W", "\n", "y1", "=", "max", "(", "0", ",", "y1", "-", "h", "*", "margin", ")", "/", "H", "\n", "x2", "=", "min", "(", "W", ",", "x2", "+", "w", "*", "margin", ")", "/", "W", "\n", "y2", "=", "min", "(", "H", ",", "y2", "+", "h", "*", "margin", ")", "/", "H", "\n", "\n", "box", "=", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", "\n", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.get_image_size": [[43, 50], ["isinstance"], "function", ["None"], ["", "def", "get_image_size", "(", "image_size", ")", ":", "\n", "    ", "\"\"\"Convert image_size to (H,W) format\"\"\"", "\n", "if", "isinstance", "(", "image_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "W", ",", "H", "=", "image_size", "\n", "", "else", ":", "\n", "        ", "W", "=", "H", "=", "image_size", "\n", "", "return", "W", ",", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.xywh_to_xyxy": [[52, 58], ["None"], "function", ["None"], ["", "def", "xywh_to_xyxy", "(", "box", ")", ":", "\n", "    ", "\"\"\"Convert box from xywh to xyxy format\"\"\"", "\n", "x1", ",", "y1", ",", "w", ",", "h", "=", "box", "\n", "x2", ",", "y2", "=", "x1", "+", "w", ",", "y1", "+", "h", "\n", "box", "=", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", "\n", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.xyxy_to_xywh": [[60, 66], ["None"], "function", ["None"], ["", "def", "xyxy_to_xywh", "(", "box", ")", ":", "\n", "    ", "\"\"\"Convert box from xyxy to xywh format\"\"\"", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "w", ",", "h", "=", "x2", "-", "x1", ",", "y2", "-", "y1", "\n", "box", "=", "(", "x1", ",", "y1", ",", "w", ",", "h", ")", "\n", "return", "box", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.extract_boxes": [[68, 86], ["box_utils._extract_box", "enumerate", "all_boxes.append", "box_utils.xywh_to_xyxy", "box_utils.expand_box", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils._extract_box", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.xywh_to_xyxy", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.expand_box"], ["", "def", "extract_boxes", "(", "masks", ",", "image_size", "=", "224", ",", "threshold", "=", "0.5", ",", "margin", "=", "0", ",", "largest_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"Extract all boxes from masks\"\"\"", "\n", "all_boxes", "=", "[", "]", "\n", "for", "mask", "in", "masks", ":", "\n", "        ", "boxes", "=", "_extract_box", "(", "mask", ",", "threshold", "=", "threshold", ")", "\n", "\n", "if", "largest_only", ":", "\n", "            ", "areas", "=", "[", "box", "[", "2", "]", "*", "box", "[", "3", "]", "for", "box", "in", "boxes", "]", "\n", "boxes", "=", "[", "boxes", "[", "np", ".", "argmax", "(", "areas", ")", "]", "]", "\n", "\n", "", "for", "i", ",", "box", "in", "enumerate", "(", "boxes", ")", ":", "\n", "            ", "box", "=", "xywh_to_xyxy", "(", "box", ")", "\n", "box", "=", "expand_box", "(", "box", ",", "image_size", ",", "margin", "=", "margin", ")", "\n", "boxes", "[", "i", "]", "=", "box", "\n", "\n", "", "all_boxes", ".", "append", "(", "boxes", ")", "\n", "\n", "", "return", "all_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils._extract_box": [[88, 107], ["np.array.size", "np.array.detach().cpu", "np.array.view().quantile", "numpy.array", "cv2.findContours", "cv2.boundingRect", "np.array.detach", "np.array.view", "torchvision.ToPILImage", "boxes.append"], "function", ["None"], ["", "def", "_extract_box", "(", "mask", ",", "min_obj_scale", "=", "0.01", ",", "threshold", "=", "0.5", ",", "quantile", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Extract boxes from mask\"\"\"", "\n", "_", ",", "h", ",", "w", "=", "mask", ".", "size", "(", ")", "\n", "mask", "=", "mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "threshold", "*=", "mask", ".", "view", "(", "1", ",", "-", "1", ")", ".", "quantile", "(", "q", "=", "quantile", ",", "dim", "=", "1", ")", "\n", "\n", "mask", "=", "(", "mask", ">", "threshold", ")", ".", "float", "(", ")", "\n", "mask", "=", "np", ".", "array", "(", "T", ".", "ToPILImage", "(", ")", "(", "mask", ")", ")", "\n", "\n", "contours", ",", "hierarchy", "=", "cv2", ".", "findContours", "(", "mask", ",", "cv2", ".", "RETR_TREE", ",", "cv2", ".", "CHAIN_APPROX_SIMPLE", ")", "\n", "\n", "boxes", "=", "[", "]", "\n", "for", "cnt", "in", "contours", ":", "\n", "        ", "box", "=", "cv2", ".", "boundingRect", "(", "cnt", ")", "\n", "min_obj_size", "=", "h", "*", "w", "*", "min_obj_scale", "\n", "if", "box", "[", "2", "]", "*", "box", "[", "3", "]", ">", "min_obj_size", ":", "\n", "            ", "boxes", ".", "append", "(", "box", ")", "\n", "", "", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.apply_crf": [[109, 133], ["images.detach().cpu.size", "images.detach().cpu.detach().cpu", "masks.detach().cpu.detach().cpu", "tqdm.tqdm", "torch.stack", "range", "numpy.array", "numpy.array", "numpy.concatenate().reshape", "dcrf.DenseCRF2D", "dcrf.DenseCRF2D.setUnaryEnergy", "dcrf.DenseCRF2D.addPairwiseGaussian", "dcrf.DenseCRF2D.addPairwiseBilateral", "dcrf.DenseCRF2D.inference", "numpy.array().reshape", "torch.tensor().unsqueeze", "outs.append", "images.detach().cpu.detach", "masks.detach().cpu.detach", "torchvision.ToPILImage", "numpy.concatenate", "numpy.log", "numpy.array", "torch.tensor"], "function", ["None"], ["", "def", "apply_crf", "(", "images", ",", "masks", ",", "n_iters", "=", "5", ")", ":", "\n", "    ", "\"\"\"Apply CRF post-processing\"\"\"", "\n", "import", "pydensecrf", ".", "densecrf", "as", "dcrf", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "images", ".", "size", "(", ")", "\n", "images", "=", "images", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "masks", "=", "masks", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "b", ")", ",", "desc", "=", "'Applying CRF...'", ")", ":", "\n", "        ", "image", "=", "np", ".", "array", "(", "T", ".", "ToPILImage", "(", ")", "(", "images", "[", "i", "]", ")", ")", "\n", "mask", "=", "np", ".", "array", "(", "masks", "[", "i", "]", ")", "\n", "mask", "=", "np", ".", "concatenate", "(", "[", "mask", ",", "1", "-", "mask", "]", ",", "axis", "=", "0", ")", ".", "reshape", "(", "(", "2", ",", "-", "1", ")", ")", "\n", "\n", "d", "=", "dcrf", ".", "DenseCRF2D", "(", "h", ",", "w", ",", "2", ")", "\n", "d", ".", "setUnaryEnergy", "(", "-", "np", ".", "log", "(", "mask", "+", "1e-20", ")", ")", "\n", "d", ".", "addPairwiseGaussian", "(", "sxy", "=", "3", ",", "compat", "=", "3", ")", "\n", "d", ".", "addPairwiseBilateral", "(", "sxy", "=", "80", ",", "srgb", "=", "13", ",", "rgbim", "=", "image", ",", "compat", "=", "10", ")", "\n", "\n", "Q", "=", "d", ".", "inference", "(", "n_iters", ")", "\n", "out", "=", "np", ".", "array", "(", "Q", ")", ".", "reshape", "(", "(", "2", ",", "h", ",", "w", ")", ")", "\n", "out", "=", "torch", ".", "tensor", "(", "out", "[", "0", "]", ")", ".", "unsqueeze", "(", "0", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "outs", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.clean_mask": [[135, 157], ["masks.detach().cpu.size", "masks.detach().cpu.detach().cpu", "tqdm.tqdm", "torch.stack", "numpy.array", "cv2.connectedComponentsWithStats", "torch.zeros", "outs.append", "masks.detach().cpu.detach", "torch.zeros.view", "torchvision.ToPILImage", "len", "stats[].argmax"], "function", ["None"], ["", "def", "clean_mask", "(", "masks", ",", "single", "=", "False", ",", "min_obj_scale", "=", "0.001", ")", ":", "\n", "    ", "\"\"\"Clean small noisy segmentations\"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "masks", ".", "size", "(", ")", "\n", "masks", "=", "masks", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "mask", "in", "tqdm", "(", "masks", ",", "desc", "=", "'Cleaning masks...'", ")", ":", "\n", "        ", "mask", "=", "np", ".", "array", "(", "T", ".", "ToPILImage", "(", ")", "(", "mask", ")", ")", "\n", "nb_components", ",", "output", ",", "stats", ",", "centroids", "=", "cv2", ".", "connectedComponentsWithStats", "(", "mask", ",", "connectivity", "=", "4", ")", "\n", "\n", "if", "single", ":", "\n", "            ", "idxs", "=", "[", "stats", "[", "1", ":", ",", "-", "1", "]", ".", "argmax", "(", ")", "+", "1", "]", "if", "len", "(", "stats", ")", ">", "1", "else", "[", "]", "\n", "", "else", ":", "\n", "            ", "min_obj_size", "=", "h", "*", "w", "*", "min_obj_scale", "\n", "idxs", "=", "(", "stats", "[", ":", ",", "-", "1", "]", ">", "min_obj_size", ")", ".", "nonzero", "(", ")", "[", "0", "]", "[", "1", ":", "]", "\n", "\n", "", "out", "=", "torch", ".", "zeros", "(", "output", ".", "shape", ")", "\n", "for", "idx", "in", "idxs", ":", "\n", "            ", "out", "[", "output", "==", "idx", "]", "=", "1", "\n", "", "outs", ".", "append", "(", "out", ".", "view", "(", "1", ",", "h", ",", "w", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "outs", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.compute_box_ious": [[159, 167], ["zip", "box_utils._compute_box_iou", "ious.append"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils._compute_box_iou"], ["", "def", "compute_box_ious", "(", "gt_boxes", ",", "pred_boxes", ")", ":", "\n", "    ", "\"\"\"Compute box mIoUs for all boxes\"\"\"", "\n", "ious", "=", "[", "]", "\n", "for", "gt_box", ",", "pred_box", "in", "zip", "(", "gt_boxes", ",", "pred_boxes", ")", ":", "\n", "        ", "iou", "=", "_compute_box_iou", "(", "gt_box", ",", "pred_box", ")", "\n", "if", "iou", "is", "not", "None", ":", "\n", "            ", "ious", ".", "append", "(", "iou", ")", "\n", "", "", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils._compute_box_iou": [[169, 182], ["len", "len", "torch.tensor", "torch.tensor", "torchvision.ops.boxes.box_iou().max", "ious.mean().item", "torchvision.ops.boxes.box_iou", "ious.mean"], "function", ["None"], ["", "def", "_compute_box_iou", "(", "gt_box", ",", "pred_box", ")", ":", "\n", "    ", "\"\"\"Compute box mIoU\"\"\"", "\n", "if", "len", "(", "gt_box", ")", ">", "0", ":", "\n", "        ", "if", "len", "(", "pred_box", ")", ">", "0", ":", "\n", "            ", "gt_box", "=", "torch", ".", "tensor", "(", "gt_box", ")", "\n", "pred_box", "=", "torch", ".", "tensor", "(", "pred_box", ")", "\n", "ious", ",", "_", "=", "box_iou", "(", "gt_box", ",", "pred_box", ")", ".", "max", "(", "dim", "=", "1", ")", "# best for each GT box", "\n", "iou", "=", "ious", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "iou", "=", "0", "\n", "", "", "else", ":", "\n", "        ", "iou", "=", "None", "\n", "", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.compute_mask_miou": [[184, 197], ["torch.min().sum", "torch.max().sum", "ious.mean().item", "gt_masks.size", "pred_masks.size", "torch.min", "torch.max", "ious.isnan", "ious.mean"], "function", ["None"], ["", "def", "compute_mask_miou", "(", "gt_masks", ",", "pred_masks", ")", ":", "\n", "    ", "\"\"\"Compute mask mIoUs for all masks\"\"\"", "\n", "assert", "gt_masks", ".", "size", "(", ")", "==", "pred_masks", ".", "size", "(", ")", "\n", "gt_masks", "=", "(", "gt_masks", ">", "0.5", ")", ".", "float", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "pred_masks", "=", "(", "pred_masks", ">", "0.5", ")", ".", "float", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "\n", "inter", "=", "torch", ".", "min", "(", "gt_masks", ",", "pred_masks", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "union", "=", "torch", ".", "max", "(", "gt_masks", ",", "pred_masks", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "ious", "=", "inter", "/", "union", "\n", "ious", "[", "ious", ".", "isnan", "(", ")", "]", "=", "1", "# both GT and pred are empty", "\n", "\n", "miou", "=", "ious", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "return", "miou", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.load_boxes": [[199, 211], ["dict", "open", "f.readlines", "line.strip().split", "list", "boxes[].append", "line.strip", "map", "tok.split"], "function", ["None"], ["", "def", "load_boxes", "(", "path", ")", ":", "\n", "    ", "\"\"\"Load boxes from path\"\"\"", "\n", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "boxes", "=", "dict", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "toks", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "boxes", "[", "toks", "[", "0", "]", "]", "=", "[", "]", "\n", "for", "tok", "in", "toks", "[", "1", ":", "]", ":", "\n", "            ", "box", "=", "list", "(", "map", "(", "float", ",", "tok", ".", "split", "(", "\",\"", ")", ")", ")", "\n", "boxes", "[", "toks", "[", "0", "]", "]", ".", "append", "(", "box", ")", "\n", "", "", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.save_boxes": [[213, 221], ["open", "d.items", "f.write", "line.append", "map"], "function", ["None"], ["", "def", "save_boxes", "(", "d", ",", "path", ")", ":", "\n", "    ", "\"\"\"Save boxes from dictionary\"\"\"", "\n", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "img_id", ",", "boxes", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "line", "=", "[", "img_id", "]", "\n", "for", "box", "in", "boxes", ":", "\n", "                ", "line", ".", "append", "(", "\",\"", ".", "join", "(", "map", "(", "\"{:.6f}\"", ".", "format", ",", "box", ")", ")", ")", "\n", "", "f", ".", "write", "(", "\" \"", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.save_masks": [[223, 241], ["tqdm.tqdm", "d.items", "mask.size", "numpy.asarray", "numpy.uint8", "numpy.squeeze", "PIL.Image.fromarray", "os.path.join", "Image.fromarray.save", "PIL.Image.open", "torchvision.Resize", "os.path.exists", "os.makedirs", "os.path.join", "Image.fromarray.cpu", "os.path.dirname", "os.path.dirname"], "function", ["None"], ["", "", "", "def", "save_masks", "(", "d", ",", "path", ",", "root_path", ")", ":", "\n", "    ", "\"\"\"Save boxes from dictionary\"\"\"", "\n", "for", "img_id", ",", "mask", "in", "tqdm", "(", "d", ".", "items", "(", ")", ")", ":", "\n", "        ", "_", ",", "h", ",", "w", "=", "mask", ".", "size", "(", ")", "\n", "\n", "original_img", "=", "np", ".", "asarray", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "img_id", ")", ")", ")", "\n", "h_original", ",", "w_original", ",", "_", "=", "original_img", ".", "shape", "\n", "\n", "resized_mask", "=", "T", ".", "Resize", "(", "(", "h_original", ",", "w_original", ")", ")", "(", "mask", ")", "\n", "resized_mask", "=", "np", ".", "uint8", "(", "resized_mask", ".", "cpu", "(", ")", "*", "255", ")", "\n", "resized_mask", "=", "np", ".", "squeeze", "(", "resized_mask", ")", "\n", "resized_mask", "=", "Image", ".", "fromarray", "(", "resized_mask", ")", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "img_id", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", ")", "\n", "\n", "", "resized_mask", ".", "save", "(", "save_path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.backup_code.BackupCode.__init__": [[9, 12], ["pytorch_lightning.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "excludes", "=", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "excludes", "=", "excludes", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.backup_code.BackupCode.setup": [[13, 25], ["os.path.join", "os.path.exists", "os.makedirs", "os.listdir", "os.getcwd", "copy_func", "os.path.isdir", "os.path.join"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "setup", "(", "self", ",", "trainer", ",", "pl_module", ",", "stage", ":", "str", ")", ":", "\n", "        ", "log_dir", "=", "trainer", ".", "logger", ".", "log_dir", "\n", "\n", "# save current code except excluded files", "\n", "code_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'code'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "code_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "code_dir", ",", "exist_ok", "=", "True", ")", "\n", "for", "fn", "in", "os", ".", "listdir", "(", "os", ".", "getcwd", "(", ")", ")", ":", "\n", "                ", "if", "not", "(", "fn", "[", "0", "]", "in", "(", "'.'", ",", "'_'", ")", "or", "fn", "in", "self", ".", "excludes", ")", ":", "\n", "                    ", "copy_func", "=", "shutil", ".", "copytree", "if", "os", ".", "path", ".", "isdir", "(", "fn", ")", "else", "shutil", ".", "copy", "\n", "copy_func", "(", "fn", ",", "os", ".", "path", ".", "join", "(", "code_dir", ",", "fn", ")", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.collect_outputs": [[5, 14], ["tqdm.tqdm", "torch.cat", "torch.cat", "model().cpu", "torch.cat.append", "torch.cat.append", "model", "x.to"], "function", ["None"], ["def", "collect_outputs", "(", "model", ",", "loader", ",", "device", "=", "'cuda'", ",", "**", "kwargs", ")", ":", "\n", "    ", "outs", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "for", "x", ",", "y", "in", "tqdm", "(", "loader", ")", ":", "\n", "        ", "out", "=", "model", "(", "x", ".", "to", "(", "device", ")", ",", "**", "kwargs", ")", ".", "cpu", "(", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "labels", ".", "append", "(", "y", ")", "\n", "", "outs", "=", "torch", ".", "cat", "(", "outs", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "labels", ")", "\n", "return", "outs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.utils.accuracy": [[16, 21], ["torch.no_grad", "classifier().argmax", "classifier"], "function", ["None"], ["", "def", "accuracy", "(", "X", ",", "Y", ",", "classifier", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "preds", "=", "classifier", "(", "X", ")", ".", "argmax", "(", "1", ")", "\n", "", "acc", "=", "(", "preds", "==", "Y", ")", ".", "float", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "return", "acc", "\n", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.__init__": [[9, 15], ["torch.Module.__init__", "gradcam.GradCAM._expand_res", "gradcam.GradCAM.eval"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._expand_res"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "classifier", "=", "None", ",", "projector", "=", "None", ",", "expand_res", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "self", ".", "_expand_res", "(", "encoder", ",", "expand_res", "=", "expand_res", ")", "\n", "self", ".", "classifier", "=", "classifier", "\n", "self", ".", "projector", "=", "projector", "\n", "self", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._expand_res": [[16, 31], ["module.modules", "gradcam.GradCAM._expand_res._reduce_stride"], "methods", ["None"], ["", "def", "_expand_res", "(", "self", ",", "encoder", ",", "expand_res", "=", "1", ")", ":", "\n", "        ", "\"\"\"Expand resolution of penultimate feature\"\"\"", "\n", "assert", "expand_res", "in", "[", "1", ",", "2", ",", "4", "]", "\n", "\n", "def", "_reduce_stride", "(", "module", ")", ":", "\n", "            ", "for", "m", "in", "module", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "m", ".", "stride", "=", "(", "1", ",", "1", ")", "\n", "\n", "", "", "", "if", "expand_res", ">=", "2", ":", "\n", "            ", "_reduce_stride", "(", "encoder", ".", "layer4", "[", "0", "]", ")", "\n", "", "if", "expand_res", ">=", "4", ":", "\n", "            ", "_reduce_stride", "(", "encoder", ".", "layer3", "[", "0", "]", ")", "\n", "\n", "", "return", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_features": [[32, 43], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gradcam.GradCAM.encoder.conv1", "gradcam.GradCAM.encoder.bn1", "gradcam.GradCAM.encoder.relu", "gradcam.GradCAM.encoder.maxpool", "gradcam.GradCAM.encoder.layer1", "gradcam.GradCAM.encoder.layer2", "gradcam.GradCAM.encoder.layer3", "gradcam.GradCAM.encoder.layer4"], "methods", ["None"], ["", "def", "get_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "x", "=", "self", ".", "encoder", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "maxpool", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "encoder", ".", "layer4", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_output": [[44, 49], ["gradcam.GradCAM.encoder.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "gradcam.GradCAM.classifier"], "methods", ["None"], ["", "def", "get_output", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "encoder", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_projection": [[50, 55], ["gradcam.GradCAM.encoder.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "gradcam.GradCAM.projector"], "methods", ["None"], ["", "def", "get_projection", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "encoder", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "projector", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.forward": [[56, 64], ["gradcam.GradCAM.get_supervised_cam", "gradcam.GradCAM.get_contrastive_cam"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_supervised_cam", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_contrastive_cam"], ["", "def", "forward", "(", "self", ",", "image", ",", "score_type", "=", "'con'", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "score_type", "==", "'sup'", ":", "\n", "            ", "cam", "=", "self", ".", "get_supervised_cam", "(", "image", ",", "**", "kwargs", ")", "\n", "", "elif", "score_type", "==", "'con'", ":", "\n", "            ", "cam", "=", "self", ".", "get_contrastive_cam", "(", "image", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "return", "cam", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_supervised_cam": [[65, 79], ["image.size", "gradcam.GradCAM.get_features", "gradcam.GradCAM.get_projection", "gradcam.GradCAM._compute_cam", "gradcam.GradCAM.max", "range", "gradcam.GradCAM.size"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_features", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_projection", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._compute_cam"], ["", "def", "get_supervised_cam", "(", "self", ",", "image", ",", "label", "=", "None", ")", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "image", ".", "size", "(", ")", "\n", "\n", "feature", "=", "self", ".", "get_features", "(", "image", ")", "\n", "feature", ".", "requires_grad", "=", "True", "\n", "output", "=", "self", ".", "get_projection", "(", "feature", ")", "\n", "\n", "if", "label", "is", "None", ":", "\n", "            ", "label", "=", "output", ".", "max", "(", "dim", "=", "1", ")", "[", "1", "]", "\n", "\n", "", "score", "=", "output", "[", "range", "(", "output", ".", "size", "(", "0", ")", ")", ",", "label", "]", "\n", "cam", "=", "self", ".", "_compute_cam", "(", "feature", ",", "score", ",", "size", "=", "(", "h", ",", "w", ")", ")", "\n", "\n", "return", "cam", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_contrastive_cam": [[80, 109], ["image.size", "image.mean", "range", "gradcam.GradCAM.get_features", "gradcam.GradCAM.get_projection", "queues.append", "gradcam.GradCAM._contrastive_score", "gradcam.GradCAM._compute_cam", "_masks.append", "_masked_images.append", "gradcam.GradCAM.detach", "gradcam.GradCAM.detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_features", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.get_projection", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._contrastive_score", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._compute_cam"], ["", "def", "get_contrastive_cam", "(", "self", ",", "image", ",", "n_iters", "=", "1", ",", "return_intermediate", "=", "False", ")", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", "=", "image", ".", "size", "(", ")", "\n", "image_original", "=", "image", "\n", "mask_color", "=", "image", ".", "mean", "(", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n", "key", ",", "queues", "=", "None", ",", "[", "]", "\n", "_masks", ",", "_masked_images", "=", "[", "]", ",", "[", "]", "\n", "for", "it", "in", "range", "(", "n_iters", ")", ":", "\n", "            ", "feature", "=", "self", ".", "get_features", "(", "image", ")", "\n", "feature", ".", "requires_grad", "=", "True", "\n", "output", "=", "self", ".", "get_projection", "(", "feature", ")", "\n", "\n", "if", "it", "==", "0", ":", "\n", "               ", "key", "=", "output", ".", "detach", "(", ")", "# original images", "\n", "", "queues", ".", "append", "(", "output", ".", "detach", "(", ")", ")", "# masked images", "\n", "\n", "score", "=", "self", ".", "_contrastive_score", "(", "output", ",", "key", ",", "queues", ")", "\n", "cam", "=", "self", ".", "_compute_cam", "(", "feature", ",", "score", ",", "size", "=", "(", "h", ",", "w", ")", ",", "clamp_negative_weights", "=", "True", ")", "\n", "\n", "mask", "=", "torch", ".", "max", "(", "mask", ",", "cam", ")", "if", "it", ">", "0", "else", "cam", "# union over iterations", "\n", "image", "=", "image_original", "*", "(", "1", "-", "mask", ")", "+", "mask_color", "*", "mask", "\n", "\n", "_masks", ".", "append", "(", "cam", ")", "\n", "_masked_images", ".", "append", "(", "image", ")", "\n", "\n", "", "if", "return_intermediate", ":", "\n", "            ", "return", "mask", ",", "(", "_masks", ",", "_masked_images", ")", "\n", "", "else", ":", "\n", "            ", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._contrastive_score": [[110, 116], ["torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.eye().type_as", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "query.size", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum().unsqueeze.exp().sum", "torch.einsum().unsqueeze.exp().sum", "torch.einsum().unsqueeze.exp().sum", "torch.cat.exp().sum", "torch.cat.exp().sum", "torch.cat.exp().sum", "torch.einsum().unsqueeze.exp", "torch.einsum().unsqueeze.exp", "torch.einsum().unsqueeze.exp", "torch.cat.exp", "torch.cat.exp", "torch.cat.exp"], "methods", ["None"], ["", "", "def", "_contrastive_score", "(", "self", ",", "query", ",", "key", ",", "queues", ")", ":", "\n", "        ", "eye", "=", "torch", ".", "eye", "(", "query", ".", "size", "(", "0", ")", ")", ".", "type_as", "(", "query", ")", "\n", "pos", "=", "torch", ".", "einsum", "(", "'nc,nc->n'", ",", "[", "query", ",", "key", "]", ")", ".", "unsqueeze", "(", "0", ")", "\n", "neg", "=", "torch", ".", "cat", "(", "[", "torch", ".", "einsum", "(", "'nc,kc->nk'", ",", "[", "query", ",", "queue", "]", ")", "*", "(", "1", "-", "eye", ")", "for", "queue", "in", "queues", "]", ",", "dim", "=", "1", ")", "\n", "score", "=", "(", "pos", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "/", "neg", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ")", ".", "log", "(", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM._compute_cam": [[117, 131], ["torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.sum().detach", "torch.relu", "torch.relu", "torch.relu", "torch.interpolate", "torch.interpolate", "torch.interpolate", "gradcam.GradCAM.normalize", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "weight.clamp_min.clamp_min.clamp_min", "score.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize"], ["", "def", "_compute_cam", "(", "self", ",", "feature", ",", "score", ",", "size", "=", "(", "224", ",", "224", ")", ",", "clamp_negative_weights", "=", "True", ")", ":", "\n", "        ", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "score", ".", "sum", "(", ")", ",", "feature", ")", "[", "0", "]", "\n", "\n", "weight", "=", "F", ".", "adaptive_avg_pool2d", "(", "grad", ",", "output_size", "=", "(", "1", ",", "1", ")", ")", "\n", "if", "clamp_negative_weights", ":", "# positive weights only", "\n", "            ", "weight", "=", "weight", ".", "clamp_min", "(", "0", ")", "\n", "\n", "", "cam", "=", "torch", ".", "sum", "(", "weight", "*", "feature", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "detach", "(", ")", "\n", "\n", "cam", "=", "F", ".", "relu", "(", "cam", ")", "# positive values only (follow Grad-CAM)", "\n", "cam", "=", "F", ".", "interpolate", "(", "cam", ",", "size", "=", "size", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "cam", "=", "GradCAM", ".", "normalize", "(", "cam", ")", "\n", "\n", "return", "cam", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize": [[132, 139], ["cam.clone.clone.clone", "range", "cam.clone.clone.size", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "normalize", "(", "cam", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "cam", "=", "cam", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "cam", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "cam", "[", "i", "]", "-=", "torch", ".", "min", "(", "cam", "[", "i", "]", ")", "\n", "cam", "[", "i", "]", "/=", "(", "torch", ".", "max", "(", "cam", "[", "i", "]", ")", "+", "eps", ")", "\n", "", "return", "cam", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.show_cam_on_image": [[140, 161], ["images.detach().cpu.detach().cpu.detach().cpu", "masks.detach().cpu.detach().cpu.detach().cpu", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "image.permute.permute.permute", "mask.squeeze.squeeze.squeeze", "cv2.applyColorMap", "numpy.uint8", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "torch.tensor().permute", "outs.append", "images.detach().cpu.detach().cpu.detach", "masks.detach().cpu.detach().cpu.detach", "numpy.uint8", "numpy.float32", "numpy.float32", "numpy.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "show_cam_on_image", "(", "images", ",", "masks", ")", ":", "\n", "        ", "images", "=", "images", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "masks", "=", "masks", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "outs", "=", "[", "]", "\n", "for", "image", ",", "mask", "in", "zip", "(", "images", ",", "masks", ")", ":", "\n", "            ", "image", "=", "image", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", "\n", "\n", "heatmap", "=", "cv2", ".", "applyColorMap", "(", "np", ".", "uint8", "(", "255", "*", "mask", ")", ",", "cv2", ".", "COLORMAP_JET", ")", "\n", "heatmap", "=", "np", ".", "float32", "(", "heatmap", ")", "/", "255", "\n", "heatmap", "=", "heatmap", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "# BGR2RGB", "\n", "out", "=", "heatmap", "+", "np", ".", "float32", "(", "image", ")", "\n", "out", "=", "out", "/", "np", ".", "max", "(", "out", ")", "\n", "out", "=", "np", ".", "uint8", "(", "255", "*", "out", ")", "\n", "\n", "out", "=", "torch", ".", "tensor", "(", "out", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "outs", ".", "append", "(", "out", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "outs", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.Res5ROIHeadsExtraNorm._build_res5_block": [[20, 26], ["super()._build_res5_block", "detectron2.layers.get_norm", "seq.add_module"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.Res5ROIHeadsExtraNorm._build_res5_block"], ["def", "_build_res5_block", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "seq", ",", "out_channels", "=", "super", "(", ")", ".", "_build_res5_block", "(", "cfg", ")", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "RESNETS", ".", "NORM", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", "\n", "seq", ".", "add_module", "(", "\"norm\"", ",", "norm", ")", "\n", "return", "seq", ",", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.Trainer.build_evaluator": [[29, 38], ["os.path.join", "detectron2.evaluation.COCOEvaluator", "detectron2.evaluation.PascalVOCDetectionEvaluator"], "methods", ["None"], ["    ", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "if", "\"coco\"", "in", "dataset_name", ":", "\n", "            ", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "", "else", ":", "\n", "            ", "assert", "\"voc\"", "in", "dataset_name", "\n", "return", "PascalVOCDetectionEvaluator", "(", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.setup": [[40, 47], ["detectron2.config.get_cfg", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["None"], ["", "", "", "def", "setup", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "get_cfg", "(", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "default_setup", "(", "cfg", ",", "args", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.main": [[49, 63], ["train_net.setup", "train_net.Trainer", "Trainer.resume_or_load", "Trainer.train", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "detectron2.checkpoint.DetectionCheckpointer"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.setup"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "\n", "if", "args", ".", "eval_only", ":", "\n", "        ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "model", ")", "\n", "return", "res", "\n", "\n", "", "trainer", "=", "Trainer", "(", "cfg", ")", "\n", "trainer", ".", "resume_or_load", "(", "resume", "=", "args", ".", "resume", ")", "\n", "return", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.__init__": [[13, 24], ["torch.Identity", "torch.Identity", "pytorch_lightning.LightningModule.__init__", "base.BaseModel.save_hyperparameters", "base.load_backbone"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_backbone"], ["def", "__init__", "(", "\n", "self", ",", "\n", "arch", ":", "str", "=", "'resnet18'", ",", "\n", "image_size", ":", "int", "=", "224", ",", "\n", "diff_transform", ":", "nn", ".", "Module", "=", "nn", ".", "Identity", "(", ")", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "self", ".", "encoder", "=", "load_backbone", "(", "arch", ",", "image_size", ")", "\n", "self", ".", "diff_transform", "=", "diff_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.forward": [[25, 27], ["base.BaseModel.encoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.process_batch": [[28, 32], ["base.BaseModel.diff_transform"], "methods", ["None"], ["", "def", "process_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "inputs", ",", "target", "=", "batch", "\n", "inputs", "=", "[", "self", ".", "diff_transform", "(", "img", ")", "for", "img", "in", "inputs", "]", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.training_step": [[33, 35], ["None"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.validation_step": [[36, 38], ["None"], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "# no validation error", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.BaseModel.add_model_specific_args": [[39, 45], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--arch\"", ",", "default", "=", "\"resnet18\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--image_size\"", ",", "default", "=", "224", ",", "type", "=", "int", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.Lambda.__init__": [[88, 91], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "func", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "func", "=", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.Lambda.forward": [[92, 94], ["base.Lambda.func"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "func", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_backbone": [[47, 57], ["torch.Identity", "base.reset_parameters", "torch.Conv2d", "torch.Identity"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.reset_parameters"], ["", "", "def", "load_backbone", "(", "arch", ",", "image_size", ")", ":", "\n", "    ", "assert", "image_size", "in", "[", "32", ",", "224", "]", "\n", "backbone", "=", "models", ".", "__dict__", "[", "arch", "]", "(", "zero_init_residual", "=", "True", ")", "\n", "if", "image_size", "==", "32", ":", "\n", "        ", "backbone", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "backbone", ".", "maxpool", "=", "nn", ".", "Identity", "(", ")", "\n", "", "backbone", ".", "feat_dim", "=", "backbone", ".", "fc", ".", "weight", ".", "shape", "[", "1", "]", "\n", "backbone", ".", "fc", "=", "nn", ".", "Identity", "(", ")", "\n", "reset_parameters", "(", "backbone", ")", "\n", "return", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_projection": [[59, 73], ["range", "layers.append", "layers.append", "torch.Sequential", "base.reset_parameters", "layers.append", "layers.append", "layers.append", "torch.Linear", "layers.append", "base.Lambda", "torch.Linear", "torch.BatchNorm1d", "torch.ReLU", "torch.BatchNorm1d"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.reset_parameters"], ["", "def", "load_projection", "(", "n_in", ",", "n_hidden", ",", "n_out", ",", "num_layers", "=", "2", ",", "last_bn", "=", "False", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_layers", "-", "1", ")", ":", "\n", "        ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_in", ",", "n_hidden", ",", "bias", "=", "False", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "n_hidden", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "n_in", "=", "n_hidden", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_hidden", ",", "n_out", ",", "bias", "=", "not", "last_bn", ")", ")", "\n", "if", "last_bn", ":", "\n", "        ", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "n_out", ")", ")", "\n", "", "layers", ".", "append", "(", "Lambda", "(", "F", ".", "normalize", ")", ")", "# normalize projection", "\n", "projection", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "reset_parameters", "(", "projection", ")", "\n", "return", "projection", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.reset_parameters": [[75, 85], ["model.modules", "isinstance", "isinstance", "m.reset_parameters", "torch.init._calculate_fan_in_and_fan_out", "torch.init.uniform_", "math.sqrt", "torch.init.uniform_"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.reset_parameters"], ["", "def", "reset_parameters", "(", "model", ")", ":", "\n", "    ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "m", ".", "reset_parameters", "(", ")", "\n", "", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "fan_in", ",", "_", "=", "nn", ".", "init", ".", "_calculate_fan_in_and_fan_out", "(", "m", ".", "weight", ")", "\n", "bound", "=", "1", "/", "math", ".", "sqrt", "(", "fan_in", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "m", ".", "weight", ",", "-", "bound", ",", "bound", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "uniform_", "(", "m", ".", "bias", ",", "-", "bound", ",", "bound", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_bgmix.MoCoBGMix.__init__": [[13, 16], ["models.moco.MoCo.__init__", "models.bg_mixup.BGMixupModule"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "bg_mixup_module", "=", "BGMixupModule", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_bgmix.MoCoBGMix.process_batch": [[17, 24], ["inputs.append", "moco_bgmix.MoCoBGMix.diff_transform"], "methods", ["None"], ["", "def", "process_batch", "(", "self", ",", "batch", ")", ":", "\n", "# batch is a collection of (img1, img2, foreground mask of img1)", "\n", "        ", "masks", "=", "batch", "[", "-", "1", "]", "\n", "inputs", "=", "batch", "[", ":", "-", "1", "]", "\n", "inputs", "=", "[", "self", ".", "diff_transform", "(", "img", ")", "for", "img", "in", "inputs", "]", "\n", "inputs", ".", "append", "(", "masks", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_bgmix.MoCoBGMix.training_step": [[25, 31], ["moco_bgmix.MoCoBGMix.process_batch", "moco_bgmix.MoCoBGMix.bg_mixup_module.generate_bg_mixed_img", "moco_bgmix.MoCoBGMix.training_step_after_process_batch"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.process_batch", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.generate_bg_mixed_img", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step_after_process_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "img1", ",", "img2", ",", "masks1", "=", "self", ".", "process_batch", "(", "batch", ")", "\n", "img1", ",", "bg_only_img1", "=", "self", ".", "bg_mixup_module", ".", "generate_bg_mixed_img", "(", "\n", "img1", ",", "masks1", ",", "self", ".", "hparams", ".", "cam_thres", ",", "self", ".", "hparams", ".", "aug_prob", ")", "\n", "\n", "return", "self", ".", "training_step_after_process_batch", "(", "img1", ",", "img2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_bgmix.MoCoBGMix.add_model_specific_args": [[32, 42], ["models.moco.MoCo.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "MoCo", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--aug_prob\"", ",", "default", "=", "0.4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--cam_thres\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ")", "\n", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_mixup.BYOLMixup.__init__": [[11, 13], ["models.byol.BYOL.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_mixup.BYOLMixup.training_step_after_process_batch": [[14, 33], ["models.mixup.mixup", "torch.arange().cuda", "byol_mixup.BYOLMixup._momentum_update_key_encoder", "byol_mixup.BYOLMixup.predictor", "byol_mixup.BYOLMixup.predictor", "byol_mixup.BYOLMixup.log_dict", "byol_mixup.BYOLMixup.projector", "byol_mixup.BYOLMixup.projector", "torch.no_grad", "byol_mixup.BYOLMixup._projector", "byol_mixup.BYOLMixup._projector", "torch.arange", "byol_mixup.BYOLMixup.encoder", "byol_mixup.BYOLMixup.encoder", "byol_mixup.BYOLMixup._encoder", "byol_mixup.BYOLMixup._encoder", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "byol_mixup.BYOLMixup.detach", "y2[].detach", "byol_mixup.BYOLMixup.detach", "byol_mixup.BYOLMixup.detach"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.mixup.mixup", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "img1", ",", "target_aux", ",", "lam", "=", "mixup", "(", "img1", ",", "alpha", "=", "1.", ")", "\n", "target", "=", "torch", ".", "arange", "(", "img1", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "p1", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", ")", "\n", "p2", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img2", ")", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "y1", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img1", ")", ")", "\n", "y2", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "", "loss1", "=", "(", "F", ".", "cosine_similarity", "(", "p1", ",", "y2", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "lam", "+", "F", ".", "cosine_similarity", "(", "p1", ",", "y2", "[", "target_aux", ",", ":", "]", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "(", "1", "-", "lam", ")", ")", ".", "mean", "(", ")", "\n", "loss2", "=", "(", "F", ".", "cosine_similarity", "(", "p2", ",", "y1", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "lam", "+", "F", ".", "cosine_similarity", "(", "p2", "[", "target_aux", ",", ":", "]", ",", "y1", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "(", "1", "-", "lam", ")", ")", ".", "mean", "(", ")", "\n", "loss", "=", "-", "(", "loss1", "+", "loss2", ")", "*", "2", "# l2 loss", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_mixup.BYOLMixup.add_model_specific_args": [[34, 42], ["models.byol.BYOL.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "BYOL", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_mixup.MoCoMixup.__init__": [[12, 14], ["models.moco.MoCo.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_mixup.MoCoMixup.training_step_after_process_batch": [[15, 36], ["models.mixup.mixup", "torch.arange().cuda", "moco_mixup.MoCoMixup._momentum_update_key_encoder", "moco_mixup.MoCoMixup.projector", "torch.cat", "pl_bolts.metrics.precision_at_k", "moco_mixup.MoCoMixup._dequeue_and_enqueue", "moco_mixup.MoCoMixup.log_dict", "moco_mixup.MoCoMixup.encoder", "torch.no_grad", "moco_mixup.MoCoMixup._projector", "torch.mm", "torch.arange", "moco_mixup.MoCoMixup._encoder", "moco_mixup.MoCoMixup.queue.clone().detach", "torch.cat.t", "moco_mixup.MoCoMixup.queue.clone", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.mixup.mixup", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo._dequeue_and_enqueue"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "img1", ",", "target_aux", ",", "lam", "=", "mixup", "(", "img1", ",", "alpha", "=", "self", ".", "hparams", ".", "alpha", ")", "\n", "target", "=", "torch", ".", "arange", "(", "img1", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "q", "=", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "# compute loss", "\n", "", "contrast", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "queue", ".", "clone", "(", ")", ".", "detach", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "logits", "=", "torch", ".", "mm", "(", "q", ",", "contrast", ".", "t", "(", ")", ")", "/", "self", ".", "hparams", ".", "temperature", "\n", "loss", "=", "(", "lam", "*", "F", ".", "cross_entropy", "(", "logits", ",", "target", ")", "+", "(", "1.", "-", "lam", ")", "*", "F", ".", "cross_entropy", "(", "logits", ",", "target_aux", ")", ")", ".", "mean", "(", ")", "\n", "acc1", ",", "acc5", "=", "precision_at_k", "(", "logits", ",", "target", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "self", ".", "_dequeue_and_enqueue", "(", "k", ")", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", ",", "'acc1'", ":", "acc1", ",", "'acc5'", ":", "acc5", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_mixup.MoCoMixup.add_model_specific_args": [[37, 45], ["models.moco.MoCo.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "MoCo", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_cutmix.BYOLCutMix.__init__": [[11, 13], ["models.byol.BYOL.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_cutmix.BYOLCutMix.training_step_after_process_batch": [[14, 32], ["models.cutmix.cutmix", "byol_cutmix.BYOLCutMix._momentum_update_key_encoder", "byol_cutmix.BYOLCutMix.predictor", "byol_cutmix.BYOLCutMix.predictor", "byol_cutmix.BYOLCutMix.log_dict", "byol_cutmix.BYOLCutMix.projector", "byol_cutmix.BYOLCutMix.projector", "torch.no_grad", "byol_cutmix.BYOLCutMix._projector", "byol_cutmix.BYOLCutMix._projector", "byol_cutmix.BYOLCutMix.encoder", "byol_cutmix.BYOLCutMix.encoder", "byol_cutmix.BYOLCutMix._encoder", "byol_cutmix.BYOLCutMix._encoder", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cosine_similarity", "byol_cutmix.BYOLCutMix.detach", "y2[].detach", "byol_cutmix.BYOLCutMix.detach", "byol_cutmix.BYOLCutMix.detach"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.cutmix.cutmix", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "img1", ",", "target_aux", ",", "lam", "=", "cutmix", "(", "img1", ",", "alpha", "=", "self", ".", "hparams", ".", "alpha", ")", "\n", "\n", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "p1", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", ")", "\n", "p2", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img2", ")", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "y1", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img1", ")", ")", "\n", "y2", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "", "loss1", "=", "(", "F", ".", "cosine_similarity", "(", "p1", ",", "y2", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "lam", "+", "F", ".", "cosine_similarity", "(", "p1", ",", "y2", "[", "target_aux", ",", ":", "]", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "(", "1", "-", "lam", ")", ")", ".", "mean", "(", ")", "\n", "loss2", "=", "(", "F", ".", "cosine_similarity", "(", "p2", ",", "y1", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "lam", "+", "F", ".", "cosine_similarity", "(", "p2", "[", "target_aux", ",", ":", "]", ",", "y1", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", "*", "(", "1", "-", "lam", ")", ")", ".", "mean", "(", ")", "\n", "loss", "=", "-", "(", "loss1", "+", "loss2", ")", "*", "2", "# l2 loss", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_cutmix.BYOLCutMix.add_model_specific_args": [[33, 41], ["models.byol.BYOL.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "BYOL", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.mixup.mixup": [[4, 12], ["torch.distributions.beta.Beta", "torch.randperm", "torch.distributions.beta.Beta.sample().to", "torch.max", "torch.max.view", "torch.distributions.beta.Beta.sample", "input.dim"], "function", ["None"], ["def", "mixup", "(", "input", ",", "alpha", ")", ":", "\n", "    ", "beta", "=", "torch", ".", "distributions", ".", "beta", ".", "Beta", "(", "alpha", ",", "alpha", ")", "\n", "randind", "=", "torch", ".", "randperm", "(", "input", ".", "shape", "[", "0", "]", ",", "device", "=", "input", ".", "device", ")", "\n", "lam", "=", "beta", ".", "sample", "(", "[", "input", ".", "shape", "[", "0", "]", "]", ")", ".", "to", "(", "device", "=", "input", ".", "device", ")", "\n", "lam", "=", "torch", ".", "max", "(", "lam", ",", "1.", "-", "lam", ")", "\n", "lam_expanded", "=", "lam", ".", "view", "(", "[", "-", "1", "]", "+", "[", "1", "]", "*", "(", "input", ".", "dim", "(", ")", "-", "1", ")", ")", "\n", "output", "=", "lam_expanded", "*", "input", "+", "(", "1.", "-", "lam_expanded", ")", "*", "input", "[", "randind", "]", "\n", "return", "output", ",", "randind", ",", "lam", "\n", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.__init__": [[8, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "max_len", "=", "50", ")", ":", "\n", "        ", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "memory", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.push": [[12, 16], ["bg_mixup.Queue.memory.append", "len", "bg_mixup.Queue.memory.pop"], "methods", ["None"], ["", "def", "push", "(", "self", ",", "elem", ")", ":", "\n", "        ", "self", ".", "memory", ".", "append", "(", "elem", ")", "\n", "while", "len", "(", "self", ".", "memory", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "self", ".", "memory", ".", "pop", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.get": [[17, 19], ["random.choice"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "choice", "(", "self", ".", "memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.__len__": [[20, 22], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.__init__": [[25, 27], ["bg_mixup.Queue"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "bg_queue", "=", "Queue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.get_minimum_rectangle_including_mask": [[28, 52], ["mask.dim", "non_zero[].min", "non_zero[].max", "non_zero[].min", "non_zero[].max", "mask.dim", "non_zero[].min", "non_zero[].max", "non_zero[].min", "non_zero[].max", "mask.dim", "non_zero[].min", "non_zero[].max", "non_zero[].min", "non_zero[].max", "non_zero.size", "non_zero.size", "mask.size", "mask.size"], "methods", ["None"], ["", "def", "get_minimum_rectangle_including_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "if", "mask", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "non_zero", "=", "(", "mask", ">", "0.1", ")", ".", "nonzero", "(", ")", "\n", "h_min", "=", "non_zero", "[", ":", ",", "2", "]", ".", "min", "(", ")", "\n", "h_max", "=", "non_zero", "[", ":", ",", "2", "]", ".", "max", "(", ")", "\n", "w_min", "=", "non_zero", "[", ":", ",", "3", "]", ".", "min", "(", ")", "\n", "w_max", "=", "non_zero", "[", ":", ",", "3", "]", ".", "max", "(", ")", "\n", "", "elif", "mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "non_zero", "=", "(", "mask", ">", "0.1", ")", ".", "nonzero", "(", ")", "\n", "h_min", "=", "non_zero", "[", ":", ",", "1", "]", ".", "min", "(", ")", "\n", "h_max", "=", "non_zero", "[", ":", ",", "1", "]", ".", "max", "(", ")", "\n", "w_min", "=", "non_zero", "[", ":", ",", "2", "]", ".", "min", "(", ")", "\n", "w_max", "=", "non_zero", "[", ":", ",", "2", "]", ".", "max", "(", ")", "\n", "", "elif", "mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "non_zero", "=", "(", "mask", ">", "0.1", ")", ".", "nonzero", "(", ")", "\n", "if", "non_zero", ".", "size", "(", "0", ")", "==", "0", "or", "non_zero", ".", "size", "(", "1", ")", "==", "0", ":", "\n", "                ", "return", "0", ",", "mask", ".", "size", "(", "0", ")", "-", "1", ",", "0", ",", "mask", ".", "size", "(", "1", ")", "-", "1", "\n", "", "h_min", "=", "non_zero", "[", ":", ",", "0", "]", ".", "min", "(", ")", "\n", "h_max", "=", "non_zero", "[", ":", ",", "0", "]", ".", "max", "(", ")", "\n", "w_min", "=", "non_zero", "[", ":", ",", "1", "]", ".", "min", "(", ")", "\n", "w_max", "=", "non_zero", "[", ":", ",", "1", "]", ".", "max", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "return", "h_min", ",", "h_max", ",", "w_min", ",", "w_max", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.generate_bg_only_img": [[53, 91], ["img.size", "random.random", "candidate_list.index", "torch.zeros_like", "torch.zeros_like", "torch.where", "max", "int", "torch.tile", "int", "torch.tile", "int", "torch.tile", "int", "torch.tile"], "methods", ["None"], ["", "def", "generate_bg_only_img", "(", "self", ",", "img", ",", "mask", ",", "h_min", ",", "h_max", ",", "w_min", ",", "w_max", ",", "aug_prob", ")", ":", "\n", "        ", "c", ",", "height", ",", "width", "=", "img", ".", "size", "(", ")", "\n", "if", "h_max", "-", "h_min", "==", "(", "height", "-", "1", ")", "and", "w_max", "-", "w_min", "==", "(", "width", "-", "1", ")", ":", "\n", "            ", "return", "img", ",", "False", "\n", "", "else", ":", "\n", "            ", "current_prob", "=", "random", ".", "random", "(", ")", "\n", "if", "aug_prob", "<", "current_prob", ":", "\n", "                ", "return", "img", ",", "False", "\n", "\n", "", "candidate_list", "=", "[", "(", "h_min", "-", "0", ")", "*", "width", ",", "(", "w_min", "-", "0", ")", "*", "height", ",", "(", "width", "-", "w_max", "-", "1", ")", "*", "height", ",", "(", "height", "-", "h_max", "-", "1", ")", "*", "width", "]", "\n", "max_idx", "=", "candidate_list", ".", "index", "(", "max", "(", "candidate_list", ")", ")", "\n", "\n", "bg_only_img", "=", "torch", ".", "zeros_like", "(", "img", ")", "\n", "if", "candidate_list", "[", "max_idx", "]", "<=", "0", ":", "\n", "                ", "raise", "ValueError", "\n", "", "elif", "max_idx", "==", "0", ":", "\n", "                ", "nb_y", "=", "int", "(", "height", "/", "h_min", ")", "\n", "bg_only_img", "[", ":", ",", "0", ":", "h_min", "*", "nb_y", ",", ":", "]", "=", "torch", ".", "tile", "(", "img", "[", ":", ",", "0", ":", "h_min", ",", ":", "]", ",", "(", "1", ",", "nb_y", ",", "1", ")", ")", "\n", "bg_only_img", "[", ":", ",", "h_min", "*", "nb_y", ":", "height", ",", ":", "]", "=", "img", "[", ":", ",", "0", ":", "(", "height", "-", "h_min", "*", "nb_y", ")", ",", ":", "]", "\n", "", "elif", "max_idx", "==", "1", ":", "\n", "                ", "nb_x", "=", "int", "(", "width", "/", "w_min", ")", "\n", "bg_only_img", "[", ":", ",", ":", ",", "0", ":", "w_min", "*", "nb_x", "]", "=", "torch", ".", "tile", "(", "img", "[", ":", ",", ":", ",", "0", ":", "w_min", "]", ",", "(", "1", ",", "1", ",", "nb_x", ")", ")", "\n", "bg_only_img", "[", ":", ",", ":", ",", "w_min", "*", "nb_x", ":", "width", "]", "=", "img", "[", ":", ",", ":", ",", "0", ":", "(", "width", "-", "w_min", "*", "nb_x", ")", "]", "\n", "", "elif", "max_idx", "==", "2", ":", "\n", "                ", "nb_x", "=", "int", "(", "width", "/", "(", "width", "-", "w_max", ")", ")", "\n", "bg_only_img", "[", ":", ",", ":", ",", "0", ":", "(", "width", "-", "w_max", ")", "*", "nb_x", "]", "=", "torch", ".", "tile", "(", "img", "[", ":", ",", ":", ",", "w_max", ":", "width", "]", ",", "(", "1", ",", "1", ",", "nb_x", ")", ")", "\n", "bg_only_img", "[", ":", ",", ":", ",", "(", "width", "-", "w_max", ")", "*", "nb_x", ":", "width", "]", "=", "img", "[", ":", ",", ":", ",", "w_max", ":", "w_max", "+", "width", "-", "(", "width", "-", "w_max", ")", "*", "nb_x", "]", "\n", "", "else", ":", "\n", "                ", "nb_y", "=", "int", "(", "height", "/", "(", "height", "-", "h_max", ")", ")", "\n", "bg_only_img", "[", ":", ",", "0", ":", "(", "height", "-", "h_max", ")", "*", "nb_y", ",", ":", "]", "=", "torch", ".", "tile", "(", "img", "[", ":", ",", "h_max", ":", "height", ",", ":", "]", ",", "(", "1", ",", "nb_y", ",", "1", ")", ")", "\n", "bg_only_img", "[", ":", ",", "(", "height", "-", "h_max", ")", "*", "nb_y", ":", "height", ",", ":", "]", "=", "img", "[", ":", ",", "h_max", ":", "h_max", "+", "height", "-", "(", "height", "-", "h_max", ")", "*", "nb_y", ",", ":", "]", "\n", "\n", "", "rectangle_mask", "=", "torch", ".", "zeros_like", "(", "mask", ")", "\n", "rectangle_mask", "[", "h_min", ":", "h_max", ",", "w_min", ":", "w_max", "]", "=", "1", "\n", "bg_only_img", "=", "torch", ".", "where", "(", "\n", "rectangle_mask", ">", "0", ",", "\n", "bg_only_img", ",", "img", ")", "\n", "return", "bg_only_img", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.bg_mixup": [[92, 95], ["None"], "methods", ["None"], ["", "", "def", "bg_mixup", "(", "self", ",", "img1", ",", "img2", ",", "mask1", ")", ":", "\n", "        ", "bg_mixup_img", "=", "mask1", "*", "img1", "+", "(", "1.", "-", "mask1", ")", "*", "img2", "\n", "return", "bg_mixup_img", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.generate_bg_mixed_img": [[96, 134], ["torch.zeros_like", "img.size", "torch.randperm().cuda", "range", "range", "bg_mixup.BGMixupModule.get_minimum_rectangle_including_mask", "bg_mixup.BGMixupModule.generate_bg_only_img", "bg_only_imgs.append", "does_bg_exist.append", "torch.stack", "torch.stack", "torch.randperm", "bg_only_img.cuda", "bg_mixed_imgs.append", "bg_mixup.BGMixupModule.bg_queue.push", "bg_mixup.BGMixupModule.bg_mixup", "bg_mixed_imgs.append", "len", "bg_mixed_imgs.append", "bg_mixup.BGMixupModule.bg_queue.get", "bg_mixup.BGMixupModule.bg_mixup", "bg_mixed_imgs.append"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.get_minimum_rectangle_including_mask", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.generate_bg_only_img", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.push", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.bg_mixup", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.get", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.bg_mixup"], ["", "def", "generate_bg_mixed_img", "(", "self", ",", "img", ",", "masks1", ",", "cam_thres", ",", "aug_prob", ")", ":", "\n", "        ", "hard_masks1", "=", "torch", ".", "zeros_like", "(", "masks1", ")", "\n", "hard_masks1", "[", "masks1", ">=", "cam_thres", "]", "=", "1.", "\n", "\n", "b", ",", "c", ",", "img_h", ",", "img_w", "=", "img", ".", "size", "(", ")", "\n", "rand_index", "=", "torch", ".", "randperm", "(", "b", ")", ".", "cuda", "(", ")", "\n", "\n", "bg_only_imgs", "=", "[", "]", "\n", "does_bg_exist", "=", "[", "]", "# check whether the minimum rectangle inlcuding maskment is whole img or not", "\n", "for", "i", "in", "range", "(", "b", ")", ":", "\n", "            ", "h_min", ",", "h_max", ",", "w_min", ",", "w_max", "=", "self", ".", "get_minimum_rectangle_including_mask", "(", "hard_masks1", "[", "i", "]", ")", "\n", "bg_only_img", ",", "bg_existance", "=", "self", ".", "generate_bg_only_img", "(", "img", "[", "i", "]", ",", "hard_masks1", "[", "i", "]", ",", "h_min", ",", "h_max", ",", "w_min", ",", "w_max", ",", "aug_prob", ")", "\n", "bg_only_imgs", ".", "append", "(", "bg_only_img", ".", "cuda", "(", ")", ")", "\n", "does_bg_exist", ".", "append", "(", "bg_existance", ")", "\n", "\n", "", "bg_mixed_imgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "b", ")", ":", "\n", "            ", "if", "not", "does_bg_exist", "[", "i", "]", ":", "\n", "# if the background does not exist, just use original image", "\n", "                ", "bg_mixed_imgs", ".", "append", "(", "img", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "if", "not", "does_bg_exist", "[", "rand_index", "[", "i", "]", "]", ":", "\n", "                    ", "if", "len", "(", "self", ".", "bg_queue", ")", "==", "0", ":", "\n", "                        ", "bg_mixed_imgs", ".", "append", "(", "img", "[", "i", "]", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "target_img", "=", "self", ".", "bg_queue", ".", "get", "(", ")", "\n", "bg_mixed_img", "=", "self", ".", "bg_mixup", "(", "img", "[", "i", "]", ",", "target_img", ",", "masks1", "[", "i", "]", ")", "\n", "bg_mixed_imgs", ".", "append", "(", "bg_mixed_img", ")", "\n", "", "", "else", ":", "\n", "                    ", "target_img", "=", "bg_only_imgs", "[", "rand_index", "[", "i", "]", "]", "\n", "bg_mixed_img", "=", "self", ".", "bg_mixup", "(", "img", "[", "i", "]", ",", "target_img", ",", "masks1", "[", "i", "]", ")", "\n", "bg_mixed_imgs", ".", "append", "(", "bg_mixed_img", ")", "\n", "\n", "", "", "if", "does_bg_exist", "[", "i", "]", ":", "\n", "                ", "self", ".", "bg_queue", ".", "push", "(", "bg_only_imgs", "[", "i", "]", ")", "\n", "\n", "", "", "return", "torch", ".", "stack", "(", "bg_mixed_imgs", ")", ",", "torch", ".", "stack", "(", "bg_only_imgs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.__init__": [[13, 16], ["models.byol.BYOL.__init__", "models.bg_mixup.BGMixupModule"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "bg_mixup_module", "=", "BGMixupModule", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.process_batch": [[17, 24], ["inputs.append", "byol_bgmix.BYOLBGMix.diff_transform"], "methods", ["None"], ["", "def", "process_batch", "(", "self", ",", "batch", ")", ":", "\n", "# batch is a collection of (img1, img2, foreground mask of img1)", "\n", "        ", "masks", "=", "batch", "[", "-", "1", "]", "\n", "inputs", "=", "batch", "[", ":", "-", "1", "]", "\n", "inputs", "=", "[", "self", ".", "diff_transform", "(", "img", ")", "for", "img", "in", "inputs", "]", "\n", "inputs", ".", "append", "(", "masks", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.training_step": [[25, 31], ["byol_bgmix.BYOLBGMix.process_batch", "byol_bgmix.BYOLBGMix.bg_mixup_module.generate_bg_mixed_img", "byol_bgmix.BYOLBGMix.training_step_after_process_batch"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.process_batch", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.BGMixupModule.generate_bg_mixed_img", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step_after_process_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "img1", ",", "img2", ",", "masks1", "=", "self", ".", "process_batch", "(", "batch", ")", "\n", "img1", ",", "bg_only_img1", "=", "self", ".", "bg_mixup_module", ".", "generate_bg_mixed_img", "(", "\n", "img1", ",", "masks1", ",", "self", ".", "hparams", ".", "cam_thres", ",", "self", ".", "hparams", ".", "aug_prob", ")", "\n", "\n", "return", "self", ".", "training_step_after_process_batch", "(", "img1", ",", "img2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.add_model_specific_args": [[32, 42], ["models.byol.BYOL.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "BYOL", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--aug_prob\"", ",", "default", "=", "0.4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--cam_thres\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ")", "\n", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_cutmix.MoCoCutMix.__init__": [[13, 15], ["models.moco.MoCo.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_cutmix.MoCoCutMix.training_step_after_process_batch": [[16, 40], ["torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "models.cutmix.cutmix", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "moco_cutmix.MoCoCutMix._momentum_update_key_encoder", "moco_cutmix.MoCoCutMix.projector", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pl_bolts.metrics.precision_at_k", "moco_cutmix.MoCoCutMix._dequeue_and_enqueue", "moco_cutmix.MoCoCutMix.log_dict", "moco_cutmix.MoCoCutMix.encoder", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "moco_cutmix.MoCoCutMix._projector", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "moco_cutmix.MoCoCutMix._encoder", "moco_cutmix.MoCoCutMix.queue.clone().detach", "torch.cat.t", "torch.cat.t", "moco_cutmix.MoCoCutMix.queue.clone", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss."], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.cutmix.cutmix", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo._dequeue_and_enqueue"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "img1", ",", "target_aux", ",", "lam", "=", "cutmix", "(", "img1", ",", "alpha", "=", "self", ".", "hparams", ".", "alpha", ")", "\n", "target", "=", "torch", ".", "arange", "(", "img1", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "q", "=", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "# compute loss", "\n", "", "contrast", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "queue", ".", "clone", "(", ")", ".", "detach", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "logits", "=", "torch", ".", "mm", "(", "q", ",", "contrast", ".", "t", "(", ")", ")", "/", "self", ".", "hparams", ".", "temperature", "\n", "\n", "loss", "=", "(", "lam", "*", "criterion", "(", "logits", ",", "target", ")", "+", "(", "1.", "-", "lam", ")", "*", "criterion", "(", "logits", ",", "target_aux", ")", ")", ".", "mean", "(", ")", "\n", "acc1", ",", "acc5", "=", "precision_at_k", "(", "logits", ",", "target", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "self", ".", "_dequeue_and_enqueue", "(", "k", ")", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", ",", "'acc1'", ":", "acc1", ",", "'acc5'", ":", "acc5", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco_cutmix.MoCoCutMix.add_model_specific_args": [[41, 49], ["models.moco.MoCo.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "MoCo", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.__init__": [[15, 37], ["models.base.BaseModel.__init__", "models.base.load_projection", "copy.deepcopy", "copy.deepcopy", "torch.nn.functional.normalize", "moco.MoCo.register_buffer", "list", "list", "torch.randn", "moco.MoCo.init_lr_schedule", "moco.MoCo._encoder.parameters", "moco.MoCo._projector.parameters"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_projection", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.gradcam.GradCAM.normalize", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.init_lr_schedule"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "feat_dim", "=", "self", ".", "encoder", ".", "feat_dim", "\n", "proj_dim", "=", "self", ".", "hparams", ".", "proj_dim", "\n", "\n", "self", ".", "projector", "=", "load_projection", "(", "feat_dim", ",", "feat_dim", ",", "proj_dim", ",", "num_layers", "=", "2", ",", "last_bn", "=", "False", ")", "\n", "\n", "self", ".", "_encoder", "=", "deepcopy", "(", "self", ".", "encoder", ")", "\n", "self", ".", "_projector", "=", "deepcopy", "(", "self", ".", "projector", ")", "\n", "\n", "for", "p", "in", "list", "(", "self", ".", "_encoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "_projector", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# create negative queue", "\n", "", "num_negatives", "=", "self", ".", "hparams", ".", "num_negatives", "\n", "queue", "=", "F", ".", "normalize", "(", "torch", ".", "randn", "(", "num_negatives", ",", "proj_dim", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"queue\"", ",", "queue", ")", "\n", "self", ".", "queue_ptr", "=", "0", "\n", "\n", "if", "self", ".", "hparams", ".", "global_batch_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_schedule", "=", "self", ".", "init_lr_schedule", "(", ")", "# custom lr schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.init_lr_schedule": [[38, 48], ["torch.tensor", "torch.arange", "math.cos"], "methods", ["None"], ["", "", "def", "init_lr_schedule", "(", "self", ")", ":", "\n", "        ", "base_lr", "=", "self", ".", "hparams", ".", "base_lr", "*", "self", ".", "hparams", ".", "global_batch_size", "/", "256", "# linear lr scaling rule", "\n", "final_lr", "=", "self", ".", "hparams", ".", "final_lr", "\n", "max_epochs", "=", "self", ".", "hparams", ".", "max_epochs", "\n", "\n", "lr_schedule", "=", "torch", ".", "tensor", "(", "[", "\n", "final_lr", "+", "0.5", "*", "(", "base_lr", "-", "final_lr", ")", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "t", "/", "max_epochs", ")", ")", "\n", "for", "t", "in", "torch", ".", "arange", "(", "max_epochs", ")", "\n", "]", ")", "\n", "return", "lr_schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.on_train_epoch_start": [[49, 56], ["moco.MoCo.optimizers", "moco.MoCo.log"], "methods", ["None"], ["", "def", "on_train_epoch_start", "(", "self", ")", ":", "\n", "# manually update learning rates", "\n", "        ", "optimizer", "=", "self", ".", "optimizers", "(", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "self", ".", "lr_schedule", "[", "self", ".", "current_epoch", "]", "\n", "\n", "", "self", ".", "log", "(", "'lr'", ",", "self", ".", "lr_schedule", "[", "self", ".", "current_epoch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.training_step": [[57, 60], ["moco.MoCo.process_batch", "moco.MoCo.training_step_after_process_batch"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.process_batch", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step_after_process_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "img1", ",", "img2", "=", "self", ".", "process_batch", "(", "batch", ")", "\n", "return", "self", ".", "training_step_after_process_batch", "(", "img1", ",", "img2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.training_step_after_process_batch": [[61, 81], ["moco.MoCo._momentum_update_key_encoder", "moco.MoCo.projector", "torch.einsum().unsqueeze", "torch.einsum", "torch.zeros().type_as().long", "torch.nn.functional.cross_entropy", "pl_bolts.metrics.precision_at_k", "moco.MoCo._dequeue_and_enqueue", "moco.MoCo.log_dict", "moco.MoCo.encoder", "torch.no_grad", "moco.MoCo._projector", "torch.cat", "moco.MoCo._encoder", "torch.einsum", "moco.MoCo.queue.clone", "torch.zeros().type_as", "torch.zeros", "logits.size"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo._dequeue_and_enqueue"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "q", "=", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "# compute loss", "\n", "", "l_pos", "=", "torch", ".", "einsum", "(", "'nc,nc->n'", ",", "[", "q", ",", "k", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "# positive logits: Nx1", "\n", "l_neg", "=", "torch", ".", "einsum", "(", "'nc,kc->nk'", ",", "[", "q", ",", "self", ".", "queue", ".", "clone", "(", ")", "]", ")", "# negative logits: NxK", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "l_pos", ",", "l_neg", "]", ",", "dim", "=", "1", ")", "/", "self", ".", "hparams", ".", "temperature", "# logits: Nx(1+K)", "\n", "labels", "=", "torch", ".", "zeros", "(", "logits", ".", "size", "(", "0", ")", ")", ".", "type_as", "(", "logits", ")", ".", "long", "(", ")", "# labels: positive key indicators", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "labels", ")", "\n", "acc1", ",", "acc5", "=", "precision_at_k", "(", "logits", ",", "labels", ",", "top_k", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "self", ".", "_dequeue_and_enqueue", "(", "k", ")", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", ",", "'acc1'", ":", "acc1", ",", "'acc5'", ":", "acc5", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo._momentum_update_key_encoder": [[82, 88], ["torch.no_grad", "zip", "online.parameters", "target.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_momentum_update_key_encoder", "(", "self", ")", ":", "\n", "        ", "em", "=", "self", ".", "hparams", ".", "encoder_momentum", "\n", "for", "online", ",", "target", "in", "[", "(", "self", ".", "encoder", ",", "self", ".", "_encoder", ")", ",", "(", "self", ".", "projector", ",", "self", ".", "_projector", ")", "]", ":", "\n", "            ", "for", "p1", ",", "p2", "in", "zip", "(", "online", ".", "parameters", "(", ")", ",", "target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "p2", ".", "data", "=", "p2", ".", "data", "*", "em", "+", "p1", ".", "data", "*", "(", "1", "-", "em", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo._dequeue_and_enqueue": [[89, 98], ["torch.no_grad", "torch.cat", "moco.MoCo.all_gather().unbind", "torch.cat.size", "torch.cat.size", "moco.MoCo.all_gather"], "methods", ["None"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_dequeue_and_enqueue", "(", "self", ",", "keys", ")", ":", "\n", "# gather keys before updating queue", "\n", "        ", "if", "self", ".", "trainer", ".", "distributed_backend", "in", "(", "'ddp'", ",", "'ddp_spawn'", ",", "'ddp2'", ")", ":", "\n", "            ", "keys", "=", "torch", ".", "cat", "(", "self", ".", "all_gather", "(", "keys", ")", ".", "unbind", "(", ")", ")", "\n", "\n", "", "ptr", "=", "self", ".", "queue_ptr", "\n", "self", ".", "queue", "[", "ptr", ":", "ptr", "+", "keys", ".", "size", "(", "0", ")", "]", "=", "keys", "\n", "self", ".", "queue_ptr", "=", "(", "ptr", "+", "keys", ".", "size", "(", "0", ")", ")", "%", "self", ".", "hparams", ".", "num_negatives", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.configure_optimizers": [[99, 103], ["torch.optim.SGD", "moco.MoCo.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "lr", "=", "self", ".", "hparams", ".", "base_lr", "*", "self", ".", "hparams", ".", "global_batch_size", "/", "256", "# linear lr scaling rule", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "0.0001", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.moco.MoCo.add_model_specific_args": [[104, 125], ["models.base.BaseModel.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--base_lr\"", ",", "default", "=", "0.03", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--final_lr\"", ",", "default", "=", "1e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--global_batch_size'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "# default: inference mode", "\n", "parser", ".", "add_argument", "(", "'--num_negatives'", ",", "default", "=", "65536", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--encoder_momentum'", ",", "default", "=", "0.999", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--temperature\"", ",", "default", "=", "0.2", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_dim\"", ",", "default", "=", "128", ",", "type", "=", "int", ")", "\n", "\n", "# transform params", "\n", "parser", ".", "add_argument", "(", "\"--jitter_strength\"", ",", "default", "=", "0.5", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--gaussian_blur\"", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_crop_scale\"", ",", "default", "=", "0.08", ",", "type", "=", "float", ")", "# stronger augmentation", "\n", "parser", ".", "add_argument", "(", "\"--max_crop_scale\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.__init__.get_model_class": [[14, 41], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.__init__": [[14, 32], ["models.base.BaseModel.__init__", "models.base.load_projection", "models.base.load_projection", "copy.deepcopy", "copy.deepcopy", "list", "list", "byol.BYOL.init_lr_schedule", "byol.BYOL._encoder.parameters", "byol.BYOL._projector.parameters"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_projection", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.base.load_projection", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.init_lr_schedule"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "feat_dim", "=", "self", ".", "encoder", ".", "feat_dim", "\n", "proj_dim", "=", "self", ".", "hparams", ".", "proj_dim", "\n", "hidden_dim", "=", "self", ".", "hparams", ".", "hidden_dim", "\n", "\n", "self", ".", "projector", "=", "load_projection", "(", "feat_dim", ",", "hidden_dim", ",", "proj_dim", ",", "num_layers", "=", "2", ",", "last_bn", "=", "False", ")", "\n", "self", ".", "predictor", "=", "load_projection", "(", "proj_dim", ",", "hidden_dim", ",", "proj_dim", ",", "num_layers", "=", "2", ",", "last_bn", "=", "False", ")", "\n", "\n", "self", ".", "_encoder", "=", "deepcopy", "(", "self", ".", "encoder", ")", "\n", "self", ".", "_projector", "=", "deepcopy", "(", "self", ".", "projector", ")", "\n", "\n", "for", "p", "in", "list", "(", "self", ".", "_encoder", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "_projector", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "if", "self", ".", "hparams", ".", "global_batch_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_schedule", "=", "self", ".", "init_lr_schedule", "(", ")", "# custom lr schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.init_lr_schedule": [[33, 43], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.cos"], "methods", ["None"], ["", "", "def", "init_lr_schedule", "(", "self", ")", ":", "\n", "        ", "base_lr", "=", "self", ".", "hparams", ".", "base_lr", "*", "self", ".", "hparams", ".", "global_batch_size", "/", "256", "# linear lr scaling rule", "\n", "final_lr", "=", "self", ".", "hparams", ".", "final_lr", "\n", "max_epochs", "=", "self", ".", "hparams", ".", "max_epochs", "\n", "\n", "lr_schedule", "=", "torch", ".", "tensor", "(", "[", "\n", "final_lr", "+", "0.5", "*", "(", "base_lr", "-", "final_lr", ")", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "t", "/", "max_epochs", ")", ")", "\n", "for", "t", "in", "torch", ".", "arange", "(", "max_epochs", ")", "\n", "]", ")", "\n", "return", "lr_schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.on_train_epoch_start": [[44, 51], ["byol.BYOL.optimizers", "byol.BYOL.log"], "methods", ["None"], ["", "def", "on_train_epoch_start", "(", "self", ")", ":", "\n", "# manually update learning rates", "\n", "        ", "optimizer", "=", "self", ".", "optimizers", "(", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "self", ".", "lr_schedule", "[", "self", ".", "current_epoch", "]", "\n", "\n", "", "self", ".", "log", "(", "'lr'", ",", "self", ".", "lr_schedule", "[", "self", ".", "current_epoch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step": [[52, 55], ["byol.BYOL.process_batch", "byol.BYOL.training_step_after_process_batch"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol_bgmix.BYOLBGMix.process_batch", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step_after_process_batch"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "img1", ",", "img2", "=", "self", ".", "process_batch", "(", "batch", ")", "\n", "return", "self", ".", "training_step_after_process_batch", "(", "img1", ",", "img2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.training_step_after_process_batch": [[56, 73], ["byol.BYOL._momentum_update_key_encoder", "byol.BYOL.predictor", "byol.BYOL.predictor", "torch.cosine_similarity().mean", "torch.cosine_similarity().mean", "torch.cosine_similarity().mean", "torch.cosine_similarity().mean", "byol.BYOL.log_dict", "byol.BYOL.projector", "byol.BYOL.projector", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "byol.BYOL._projector", "byol.BYOL._projector", "byol.BYOL.encoder", "byol.BYOL.encoder", "byol.BYOL._encoder", "byol.BYOL._encoder", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "torch.cosine_similarity", "byol.BYOL.detach", "byol.BYOL.detach"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder"], ["", "def", "training_step_after_process_batch", "(", "self", ",", "img1", ",", "img2", ")", ":", "\n", "        ", "self", ".", "_momentum_update_key_encoder", "(", ")", "\n", "\n", "# forward", "\n", "p1", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img1", ")", ")", ")", "\n", "p2", "=", "self", ".", "predictor", "(", "self", ".", "projector", "(", "self", ".", "encoder", "(", "img2", ")", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "y1", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img1", ")", ")", "\n", "y2", "=", "self", ".", "_projector", "(", "self", ".", "_encoder", "(", "img2", ")", ")", "\n", "\n", "# compute loss", "\n", "", "loss1", "=", "F", ".", "cosine_similarity", "(", "p1", ",", "y2", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "loss2", "=", "F", ".", "cosine_similarity", "(", "p2", ",", "y1", ".", "detach", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "mean", "(", ")", "\n", "loss", "=", "-", "(", "loss1", "+", "loss2", ")", "*", "2", "# l2 loss", "\n", "\n", "self", ".", "log_dict", "(", "{", "'loss'", ":", "loss", "}", ",", "prog_bar", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL._momentum_update_key_encoder": [[74, 80], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "online.parameters", "target.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_momentum_update_key_encoder", "(", "self", ")", ":", "\n", "        ", "em", "=", "self", ".", "hparams", ".", "encoder_momentum", "\n", "for", "online", ",", "target", "in", "[", "(", "self", ".", "encoder", ",", "self", ".", "_encoder", ")", ",", "(", "self", ".", "projector", ",", "self", ".", "_projector", ")", "]", ":", "\n", "            ", "for", "p1", ",", "p2", "in", "zip", "(", "online", ".", "parameters", "(", ")", ",", "target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "p2", ".", "data", "=", "p2", ".", "data", "*", "em", "+", "p1", ".", "data", "*", "(", "1", "-", "em", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.configure_optimizers": [[81, 86], ["torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "byol.BYOL.parameters"], "methods", ["None"], ["", "", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "lr", "=", "self", ".", "hparams", ".", "base_lr", "*", "self", ".", "hparams", ".", "global_batch_size", "/", "256", "# linear lr scaling rule", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "0.0001", ")", "\n", "# do not use LARS optimizer (follow MoCo LR scheme)", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args": [[87, 107], ["models.base.BaseModel.add_model_specific_args", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.byol.BYOL.add_model_specific_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parent_parser", ")", ":", "\n", "        ", "parent_parser", "=", "BaseModel", ".", "add_model_specific_args", "(", "parent_parser", ")", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ")", "\n", "\n", "# training params", "\n", "parser", ".", "add_argument", "(", "\"--base_lr\"", ",", "default", "=", "0.03", ",", "type", "=", "float", ")", "# follow MoCo LR scheme", "\n", "parser", ".", "add_argument", "(", "\"--final_lr\"", ",", "default", "=", "1e-3", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--global_batch_size'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "# default: inference mode", "\n", "parser", ".", "add_argument", "(", "'--encoder_momentum'", ",", "default", "=", "0.996", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--hidden_dim\"", ",", "default", "=", "4096", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--proj_dim\"", ",", "default", "=", "256", ",", "type", "=", "int", ")", "\n", "\n", "# transform params", "\n", "parser", ".", "add_argument", "(", "\"--jitter_strength\"", ",", "default", "=", "0.5", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\"--gaussian_blur\"", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_crop_scale\"", ",", "default", "=", "0.08", ",", "type", "=", "float", ")", "# stronger augmentation", "\n", "parser", ".", "add_argument", "(", "\"--max_crop_scale\"", ",", "default", "=", "1.", ",", "type", "=", "float", ")", "\n", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.cutmix.rand_bbox": [[4, 21], ["torch.zeros_like().random_", "torch.zeros_like().random_", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["def", "rand_bbox", "(", "size", ",", "lam", ")", ":", "\n", "    ", "W", ",", "H", "=", "size", "\n", "cut_rat", "=", "(", "1.", "-", "lam", ")", ".", "sqrt", "(", ")", "\n", "cut_w", "=", "(", "W", "*", "cut_rat", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "cut_h", "=", "(", "H", "*", "cut_rat", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "\n", "cx", "=", "torch", ".", "zeros_like", "(", "cut_w", ",", "dtype", "=", "cut_w", ".", "dtype", ")", ".", "random_", "(", "0", ",", "W", ")", "\n", "cy", "=", "torch", ".", "zeros_like", "(", "cut_h", ",", "dtype", "=", "cut_h", ".", "dtype", ")", ".", "random_", "(", "0", ",", "H", ")", "\n", "\n", "bbx1", "=", "(", "cx", "-", "cut_w", "//", "2", ")", ".", "clamp", "(", "0", ",", "W", ")", "\n", "bby1", "=", "(", "cy", "-", "cut_h", "//", "2", ")", ".", "clamp", "(", "0", ",", "H", ")", "\n", "bbx2", "=", "(", "cx", "+", "cut_w", "//", "2", ")", ".", "clamp", "(", "0", ",", "W", ")", "\n", "bby2", "=", "(", "cy", "+", "cut_h", "//", "2", ")", ".", "clamp", "(", "0", ",", "H", ")", "\n", "\n", "new_lam", "=", "1.", "-", "(", "bbx2", "-", "bbx1", ")", ".", "to", "(", "lam", ".", "dtype", ")", "*", "(", "bby2", "-", "bby1", ")", ".", "to", "(", "lam", ".", "dtype", ")", "/", "(", "W", "*", "H", ")", "\n", "\n", "return", "(", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", ")", ",", "new_lam", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.cutmix.cutmix": [[23, 32], ["torch.distributions.beta.Beta", "torch.randperm", "torch.distributions.beta.Beta.sample().to", "torch.max", "cutmix.rand_bbox", "input.clone", "torch.distributions.beta.Beta.sample"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.cutmix.rand_bbox"], ["", "def", "cutmix", "(", "input", ",", "alpha", ")", ":", "\n", "    ", "beta", "=", "torch", ".", "distributions", ".", "beta", ".", "Beta", "(", "alpha", ",", "alpha", ")", "\n", "randind", "=", "torch", ".", "randperm", "(", "input", ".", "shape", "[", "0", "]", ",", "device", "=", "input", ".", "device", ")", "\n", "lam", "=", "beta", ".", "sample", "(", ")", ".", "to", "(", "device", "=", "input", ".", "device", ")", "\n", "lam", "=", "torch", ".", "max", "(", "lam", ",", "1.", "-", "lam", ")", "\n", "(", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", ")", ",", "lam", "=", "rand_bbox", "(", "input", ".", "shape", "[", "-", "2", ":", "]", ",", "lam", ")", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "output", "[", "...", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "=", "output", "[", "randind", "]", "[", "...", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "\n", "return", "output", ",", "randind", ",", "lam", "\n", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._downConv.__init__": [[7, 23], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nIn", "=", "3", ",", "nf", "=", "128", ",", "spectralNorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "_downConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mods", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nIn", ",", "nf", "//", "4", ",", "7", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nIn", ",", "nf", "//", "4", ",", "7", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", "//", "4", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", "//", "4", ",", "nf", "//", "2", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", "//", "4", ",", "nf", "//", "2", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", "//", "2", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", "//", "2", ",", "nf", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", "//", "2", ",", "nf", ",", "3", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._downConv.forward": [[25, 27], ["model._downConv.mods"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mods", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._resBloc.__init__": [[30, 43], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", "=", "128", ",", "spectralNorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "_resBloc", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "blocs", "=", "nn", ".", "Sequential", "(", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", ",", "nf", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", ",", "nf", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", ",", "nf", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "True", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", ",", "nf", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "True", ")", ",", "\n", ")", "\n", "self", ".", "activationF", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._resBloc.forward": [[45, 47], ["model._resBloc.activationF", "model._resBloc.blocs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "activationF", "(", "self", ".", "blocs", "(", "x", ")", "+", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._upConv.__init__": [[50, 66], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Upsample", "torch.Upsample", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.Upsample", "torch.Upsample", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReflectionPad2d", "torch.ReflectionPad2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.nn.utils.spectral_norm", "torch.nn.utils.spectral_norm", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nOut", "=", "3", ",", "nf", "=", "128", ",", "spectralNorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "_upConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mods", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", ",", "nf", "//", "2", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", ",", "nf", "//", "2", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", "//", "2", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", "//", "2", ",", "nf", "//", "4", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", "//", "2", ",", "nf", "//", "4", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "nf", "//", "4", ",", "affine", "=", "True", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "ReflectionPad2d", "(", "3", ")", ",", "\n", "spectral_norm", "(", "nn", ".", "Conv2d", "(", "nf", "//", "4", ",", "nOut", ",", "7", ",", "bias", "=", "True", ")", ")", "if", "spectralNorm", "\n", "else", "nn", ".", "Conv2d", "(", "nf", "//", "4", ",", "nOut", ",", "7", ",", "bias", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model._upConv.forward": [[68, 70], ["model._upConv.mods"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mods", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model.ReDO.__init__": [[73, 93], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "model._upConv", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Upsample", "torch.Upsample", "model._downConv", "model._resBloc", "range"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sizex", "=", "128", ",", "nIn", "=", "3", ",", "nMasks", "=", "2", ",", "nRes", "=", "3", ",", "nf", "=", "64", ",", "temperature", "=", "1", ")", ":", "\n", "        ", "super", "(", "ReDO", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nMasks", "=", "nMasks", "\n", "sizex", "=", "sizex", "//", "4", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "*", "(", "[", "_downConv", "(", "nIn", ",", "nf", ")", "]", "+", "\n", "[", "_resBloc", "(", "nf", "=", "nf", ")", "for", "i", "in", "range", "(", "nRes", ")", "]", ")", ")", "\n", "self", ".", "psp", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Sequential", "(", "nn", ".", "AvgPool2d", "(", "sizex", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nf", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Upsample", "(", "size", "=", "sizex", ",", "mode", "=", "'bilinear'", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "AvgPool2d", "(", "sizex", "//", "2", ",", "sizex", "//", "2", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nf", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Upsample", "(", "size", "=", "sizex", ",", "mode", "=", "'bilinear'", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "AvgPool2d", "(", "sizex", "//", "3", ",", "sizex", "//", "3", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nf", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Upsample", "(", "size", "=", "sizex", ",", "mode", "=", "'bilinear'", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "nn", ".", "AvgPool2d", "(", "sizex", "//", "6", ",", "sizex", "//", "6", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nf", ",", "1", ",", "1", ")", ",", "\n", "nn", ".", "Upsample", "(", "size", "=", "sizex", ",", "mode", "=", "'bilinear'", ")", ")", "]", ")", "\n", "self", ".", "out", "=", "_upConv", "(", "1", "if", "nMasks", "==", "2", "else", "nMasks", ",", "nf", "+", "4", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.model.ReDO.forward": [[94, 99], ["model.ReDO.cnn", "model.ReDO.out", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "f", "=", "self", ".", "cnn", "(", "x", ")", "\n", "m", "=", "self", ".", "out", "(", "torch", ".", "cat", "(", "[", "f", "]", "+", "[", "pnet", "(", "f", ")", "for", "pnet", "in", "self", ".", "psp", "]", ",", "1", ")", ")", "\n", "m", "=", "torch", ".", "sigmoid", "(", "m", "/", "self", ".", "temperature", ")", "\n", "return", "m", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.redo.__init__.load_redo_model": [[5, 16], ["model.ReDO", "model.ReDO.parameters", "model.ReDO.load_state_dict", "torch.load"], "function", ["None"], ["from", ".", "utils", "import", "collect_outputs", ",", "accuracy", "\n", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.PretrainTransformBase.__init__": [[19, 34], ["torchvision.Compose", "torchvision.Compose", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.Resize", "transform.append", "transform_orig.append", "torchvision.ToTensor", "torchvision.ToTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "image_size", "=", "224", ",", "crop_scale", "=", "(", "0.08", ",", "1.", ")", ",", "view", "=", "2", ",", "use_mask", "=", "False", ")", ":", "\n", "        ", "self", ".", "view", "=", "view", "\n", "transform", "=", "[", "\n", "T", ".", "RandomResizedCrop", "(", "image_size", ",", "scale", "=", "crop_scale", ")", ",", "\n", "T", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", ",", "\n", "]", "\n", "transform_orig", "=", "[", "\n", "T", ".", "Resize", "(", "(", "image_size", ",", "image_size", ")", ")", ",", "\n", "]", "\n", "\n", "if", "not", "use_mask", ":", "\n", "            ", "transform", ".", "append", "(", "T", ".", "ToTensor", "(", ")", ")", "\n", "transform_orig", ".", "append", "(", "T", ".", "ToTensor", "(", ")", ")", "\n", "", "self", ".", "transform", "=", "T", ".", "Compose", "(", "transform", ")", "\n", "self", ".", "transform_orig", "=", "T", ".", "Compose", "(", "transform_orig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.PretrainTransform.__call__": [[38, 58], ["range", "range", "out.append", "out.append", "torchvision.ToTensor", "torchvision.ToTensor", "transforms.PretrainTransform.transform", "transforms.PretrainTransform.transform", "out.append", "out.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transforms.PretrainTransform.transform"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "sample", ",", "mask", "=", "None", ")", ":", "\n", "        ", "if", "mask", "is", "None", ":", "\n", "            ", "out", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "view", ")", ":", "\n", "                ", "out", ".", "append", "(", "self", ".", "transform", "(", "sample", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "sample", "=", "T", ".", "ToTensor", "(", ")", "(", "sample", ")", "\n", "mask", "=", "T", ".", "ToTensor", "(", ")", "(", "mask", ")", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "view", ")", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "combined", "=", "self", ".", "transform", "(", "torch", ".", "cat", "(", "[", "sample", ",", "mask", "]", ")", ")", "\n", "first_sample", "=", "combined", "[", ":", "3", ",", ":", ",", ":", "]", "\n", "mask", "=", "combined", "[", "-", "1", ",", ":", ",", ":", "]", "\n", "out", ".", "append", "(", "first_sample", ")", "\n", "", "else", ":", "\n", "                    ", "out", ".", "append", "(", "self", ".", "transform", "(", "sample", ")", ")", "\n", "", "", "out", ".", "append", "(", "mask", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.FinetuneTransform.__init__": [[62, 89], ["torchvision.Compose", "transforms.append", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.CenterCrop", "torchvision.ToTensor", "torchvision.Resize", "torchvision.ToTensor", "torchvision.Resize", "torchvision.Resize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "image_size", "=", "224", ",", "crop", "=", "'center'", ",", "normalize", "=", "None", ")", ":", "\n", "        ", "assert", "crop", "in", "[", "'random'", ",", "'center'", ",", "'none'", "]", "\n", "\n", "transforms", "=", "[", "]", "\n", "\n", "if", "crop", "==", "'random'", ":", "\n", "            ", "transforms", "+=", "[", "\n", "T", ".", "RandomResizedCrop", "(", "image_size", ")", ",", "\n", "T", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "T", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", "", "elif", "crop", "==", "'center'", ":", "\n", "            ", "transforms", "+=", "[", "\n", "T", ".", "Resize", "(", "image_size", ")", "if", "image_size", "!=", "224", "else", "T", ".", "Resize", "(", "256", ")", ",", "\n", "T", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "T", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "transforms", "+=", "[", "\n", "T", ".", "Resize", "(", "(", "image_size", ",", "image_size", ")", ")", ",", "\n", "T", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", "\n", "", "if", "normalize", "is", "not", "None", ":", "\n", "            ", "transforms", ".", "append", "(", "normalize", ")", "\n", "\n", "", "self", ".", "transform", "=", "T", ".", "Compose", "(", "transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.FinetuneTransform.__call__": [[90, 92], ["transforms.FinetuneTransform.transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "return", "self", ".", "transform", "(", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.KorniaTransform.__init__": [[96, 118], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "transforms.ColorJitter", "kornia.RandomGrayscale", "kornia.RandomGrayscale", "int", "transforms.append", "transforms.KorniaTransform.to_kornia_normalize", "transforms.append", "transforms.GaussianBlur"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.KorniaTransform.to_kornia_normalize"], ["def", "__init__", "(", "self", ",", "image_size", "=", "224", ",", "normalize", "=", "None", ",", "jitter_strength", "=", "1.", ",", "gaussian_blur", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "transforms", "=", "[", "\n", "ColorJitter", "(", "0.8", "*", "jitter_strength", ",", "\n", "0.8", "*", "jitter_strength", ",", "\n", "0.8", "*", "jitter_strength", ",", "\n", "0.2", "*", "jitter_strength", ",", "p", "=", "0.8", ")", ",", "\n", "K", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "]", "\n", "\n", "if", "gaussian_blur", ":", "\n", "            ", "kernel_size", "=", "int", "(", "0.1", "*", "image_size", ")", "\n", "if", "kernel_size", "%", "2", "==", "0", ":", "\n", "                ", "kernel_size", "+=", "1", "\n", "", "transforms", ".", "append", "(", "GaussianBlur", "(", "kernel_size", ",", "(", "0.1", ",", "2.0", ")", ")", ")", "\n", "\n", "", "if", "normalize", "is", "not", "None", ":", "\n", "            ", "normalize", "=", "self", ".", "to_kornia_normalize", "(", "normalize", ")", "\n", "transforms", ".", "append", "(", "normalize", ")", "\n", "\n", "", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "*", "transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.KorniaTransform.to_kornia_normalize": [[119, 123], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "kornia.Normalize", "kornia.Normalize"], "methods", ["None"], ["", "def", "to_kornia_normalize", "(", "self", ",", "normalization", ")", ":", "\n", "        ", "mean", "=", "torch", ".", "tensor", "(", "normalization", ".", "mean", ")", "\n", "std", "=", "torch", ".", "tensor", "(", "normalization", ".", "std", ")", "\n", "return", "K", ".", "Normalize", "(", "mean", ",", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.KorniaTransform.forward": [[124, 126], ["transforms.KorniaTransform.transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "transform", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.ColorJitter.apply_transform": [[142, 155], ["params[].tolist", "t", "transforms.apply_adjust_brightness", "transforms.apply_adjust_contrast", "kornia.apply_adjust_saturation", "kornia.apply_adjust_saturation", "kornia.apply_adjust_hue", "kornia.apply_adjust_hue"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.apply_adjust_brightness", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.apply_adjust_contrast"], ["    ", "def", "apply_transform", "(", "self", ",", "x", ",", "params", ")", ":", "\n", "        ", "transforms", "=", "[", "\n", "lambda", "img", ":", "apply_adjust_brightness", "(", "img", ",", "params", ")", ",", "\n", "lambda", "img", ":", "apply_adjust_contrast", "(", "img", ",", "params", ")", ",", "\n", "lambda", "img", ":", "KF", ".", "apply_adjust_saturation", "(", "img", ",", "params", ")", ",", "\n", "lambda", "img", ":", "KF", ".", "apply_adjust_hue", "(", "img", ",", "params", ")", "\n", "]", "\n", "\n", "for", "idx", "in", "params", "[", "'order'", "]", ".", "tolist", "(", ")", ":", "\n", "            ", "t", "=", "transforms", "[", "idx", "]", "\n", "x", "=", "t", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.GaussianBlur.__init__": [[158, 165], ["kornia.AugmentationBase2D.__init__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "sigma", ",", "border_type", "=", "'reflect'", ",", "\n", "return_transform", "=", "False", ",", "same_on_batch", "=", "False", ",", "p", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "p", "=", "p", ",", "return_transform", "=", "return_transform", ",", "same_on_batch", "=", "same_on_batch", ",", "p_batch", "=", "1.", ")", "\n", "assert", "kernel_size", "%", "2", "==", "1", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "border_type", "=", "border_type", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.GaussianBlur.__repr__": [[166, 168], ["kornia.AugmentationBase2D.__repr__"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.GaussianBlur.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "f\"({super().__repr__()})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.GaussianBlur.generate_parameters": [[169, 171], ["dict", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "generate_parameters", "(", "self", ",", "batch_shape", ")", ":", "\n", "        ", "return", "dict", "(", "sigma", "=", "torch", ".", "zeros", "(", "batch_shape", "[", "0", "]", ")", ".", "uniform_", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.GaussianBlur.apply_transform": [[172, 183], ["params[].to", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.pad", "torch.pad", "torch.pad", "torch.conv2d().transpose", "torch.conv2d().transpose", "torch.conv2d().transpose", "torch.conv2d().transpose.type", "torch.exp.sum", "torch.exp.sum", "torch.exp.sum", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d().transpose.transpose"], "methods", ["None"], ["", "def", "apply_transform", "(", "self", ",", "input", ",", "params", ")", ":", "\n", "        ", "dtype", "=", "input", ".", "dtype", "# function may change the original dtype", "\n", "sigma", "=", "params", "[", "'sigma'", "]", ".", "to", "(", "input", ".", "device", ")", "\n", "k_half", "=", "self", ".", "kernel_size", "//", "2", "\n", "x", "=", "torch", ".", "linspace", "(", "-", "k_half", ",", "k_half", ",", "steps", "=", "self", ".", "kernel_size", ",", "dtype", "=", "input", ".", "dtype", ",", "device", "=", "input", ".", "device", ")", "\n", "pdf", "=", "torch", ".", "exp", "(", "-", "0.5", "*", "(", "x", "[", "None", ",", ":", "]", "/", "sigma", "[", ":", ",", "None", "]", ")", ".", "pow", "(", "2", ")", ")", "\n", "kernel1d", "=", "pdf", "/", "pdf", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "kernel2d", "=", "torch", ".", "bmm", "(", "kernel1d", "[", ":", ",", ":", ",", "None", "]", ",", "kernel1d", "[", ":", ",", "None", ",", ":", "]", ")", "\n", "input", "=", "F", ".", "pad", "(", "input", ",", "(", "k_half", ",", "k_half", ",", "k_half", ",", "k_half", ")", ",", "mode", "=", "self", ".", "border_type", ")", "\n", "input", "=", "F", ".", "conv2d", "(", "input", ".", "transpose", "(", "0", ",", "1", ")", ",", "kernel2d", "[", ":", ",", "None", "]", ",", "groups", "=", "input", ".", "shape", "[", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "input", ".", "type", "(", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.get_normalization": [[9, 15], ["torchvision.Normalize", "torchvision.Normalize"], "function", ["None"], ["def", "get_normalization", "(", "normalize", ")", ":", "\n", "    ", "\"\"\"Get normalization values for dataset\"\"\"", "\n", "if", "normalize", "==", "'redo'", ":", "\n", "        ", "return", "T", ".", "Normalize", "(", "mean", "=", "0.5", ",", "std", "=", "0.5", ")", "\n", "", "else", ":", "# default: ImageNet", "\n", "        ", "return", "T", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.apply_adjust_brightness": [[128, 132], ["[].to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["", "", "def", "apply_adjust_brightness", "(", "img1", ",", "params", ")", ":", "\n", "    ", "ratio", "=", "params", "[", "'brightness_factor'", "]", "[", ":", ",", "None", ",", "None", ",", "None", "]", ".", "to", "(", "img1", ".", "device", ")", "\n", "img2", "=", "torch", ".", "zeros_like", "(", "img1", ")", "\n", "return", "(", "ratio", "*", "img1", "+", "(", "1.0", "-", "ratio", ")", "*", "img2", ")", ".", "clamp", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.transforms.apply_adjust_contrast": [[134, 139], ["[].to", "torch.mean", "torch.mean", "torch.mean"], "function", ["None"], ["", "def", "apply_adjust_contrast", "(", "img1", ",", "params", ")", ":", "\n", "    ", "ratio", "=", "params", "[", "'contrast_factor'", "]", "[", ":", ",", "None", ",", "None", ",", "None", "]", ".", "to", "(", "img1", ".", "device", ")", "\n", "img2", "=", "0.2989", "*", "img1", "[", ":", ",", "0", ":", "1", "]", "+", "0.587", "*", "img1", "[", ":", ",", "1", ":", "2", "]", "+", "0.114", "*", "img1", "[", ":", ",", "2", ":", "3", "]", "\n", "img2", "=", "torch", ".", "mean", "(", "img2", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ",", "keepdim", "=", "True", ")", "\n", "return", "(", "ratio", "*", "img1", "+", "(", "1.0", "-", "ratio", ")", "*", "img2", ")", ".", "clamp", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset.__init__": [[13, 23], ["torch.utils.data.Dataset.__init__", "segmentation.SegmentationDataset._split_images", "numpy.random.RandomState().shuffle", "numpy.random.RandomState"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._split_images"], ["def", "__init__", "(", "self", ",", "root", ",", "split", ",", "split_root", "=", "None", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "seed", "=", "42", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "split_root", "=", "split_root", "\n", "self", ".", "ids", "=", "self", ".", "_split_images", "(", "split", "=", "split", ")", "\n", "np", ".", "random", ".", "RandomState", "(", "seed", ")", ".", "shuffle", "(", "self", ".", "ids", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset._split_images": [[24, 26], ["None"], "methods", ["None"], ["", "def", "_split_images", "(", "self", ",", "split", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset.__len__": [[27, 29], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset.__getitem__": [[30, 42], ["segmentation.SegmentationDataset._load_img", "segmentation.SegmentationDataset._load_seg", "segmentation.SegmentationDataset.transform", "segmentation.SegmentationDataset.target_transform", "segmentation.SegmentationDataset._post_process"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._load_img", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._load_seg", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._post_process"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img", "=", "self", ".", "_load_img", "(", "item", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "seg", "=", "self", ".", "_load_seg", "(", "item", ")", "\n", "# assume fixed geometric transformation", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "seg", "=", "self", ".", "target_transform", "(", "seg", ")", "\n", "seg", "=", "self", ".", "_post_process", "(", "seg", ")", "\n", "\n", "", "return", "img", ",", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset._load_img": [[43, 45], ["None"], "methods", ["None"], ["", "def", "_load_img", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset._load_seg": [[46, 48], ["None"], "methods", ["None"], ["", "def", "_load_seg", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.SegmentationDataset._post_process": [[49, 52], ["None"], "methods", ["None"], ["", "def", "_post_process", "(", "self", ",", "seg", ")", ":", "\n", "        ", "seg", "=", "(", "seg", ">", "0.5", ")", ".", "float", "(", ")", "# binary mask", "\n", "return", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.CUBSegmentation._split_images": [[57, 63], ["numpy.loadtxt", "os.path.join", "numpy.loadtxt", "os.path.join"], "methods", ["None"], ["def", "_split_images", "(", "self", ",", "split", ")", ":", "\n", "        ", "split_id", "=", "{", "'train'", ":", "0", ",", "'val'", ":", "1", ",", "'test'", ":", "2", "}", "[", "split", "]", "\n", "splits", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "self", ".", "split_root", ",", "\"cub.txt\"", ")", ",", "int", ")", "\n", "ids", "=", "np", ".", "loadtxt", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"CUB_200_2011\"", ",", "\"images.txt\"", ")", ",", "str", ")", "[", ":", ",", "1", "]", "\n", "ids", "=", "ids", "[", "splits", "[", ":", ",", "1", "]", "==", "split_id", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.CUBSegmentation._load_img": [[64, 68], ["PIL.Image.open().convert", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "def", "_load_img", "(", "self", ",", "item", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"CUB_200_2011\"", ",", "\"images\"", ",", "\n", "self", ".", "ids", "[", "item", "]", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.CUBSegmentation._load_seg": [[69, 73], ["PIL.Image.open().convert", "PIL.Image.open", "os.path.join", "segmentation.CUBSegmentation.ids[].replace"], "methods", ["None"], ["", "def", "_load_seg", "(", "self", ",", "item", ")", ":", "\n", "        ", "seg", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"CUB_200_2011\"", ",", "\"segmentations\"", ",", "\n", "self", ".", "ids", "[", "item", "]", ".", "replace", "(", "'jpg'", ",", "'png'", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "return", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.FlowersSegmentation._split_images": [[78, 83], ["list", "scipy.io.loadmat().get", "map", "scipy.io.loadmat", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.models.bg_mixup.Queue.get"], ["def", "_split_images", "(", "self", ",", "split", ")", ":", "\n", "        ", "split_id", "=", "{", "'train'", ":", "'tstid'", ",", "'val'", ":", "'valid'", ",", "'test'", ":", "'trnid'", "}", "[", "split", "]", "\n", "ids", "=", "loadmat", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"flowers102\"", ",", "\"setid.mat\"", ")", ")", ".", "get", "(", "split_id", ")", "[", "0", "]", "\n", "ids", "=", "list", "(", "map", "(", "'{:05d}'", ".", "format", ",", "ids", ")", ")", "# convert to string", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.FlowersSegmentation._load_img": [[84, 88], ["PIL.Image.open().convert", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "def", "_load_img", "(", "self", ",", "item", ")", ":", "\n", "        ", "imgname", "=", "\"image_{}.jpg\"", ".", "format", "(", "self", ".", "ids", "[", "item", "]", ")", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"flowers102\"", ",", "\"jpg\"", ",", "imgname", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.FlowersSegmentation._load_seg": [[89, 95], ["numpy.array", "PIL.Image.fromarray().convert", "PIL.Image.open", "os.path.join", "PIL.Image.fromarray"], "methods", ["None"], ["", "def", "_load_seg", "(", "self", ",", "item", ")", ":", "\n", "        ", "segname", "=", "\"segmim_{}.jpg\"", ".", "format", "(", "self", ".", "ids", "[", "item", "]", ")", "\n", "seg", "=", "np", ".", "array", "(", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"flowers102\"", ",", "\"segmim\"", ",", "segname", ")", ")", ")", "\n", "seg", "=", "1", "-", "(", "(", "seg", "[", ":", ",", ":", ",", "0", "]", "==", "0", ")", "+", "(", "seg", "[", ":", ",", ":", ",", "1", "]", "==", "0", ")", "+", "(", "seg", "[", ":", ",", ":", ",", "2", "]", "==", "254", ")", ")", "\n", "seg", "=", "Image", ".", "fromarray", "(", "(", "seg", "*", "255", ")", ".", "astype", "(", "'uint8'", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "return", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.COCOSegmentation._split_images": [[100, 105], ["COCO", "list", "os.path.join", "sorted", "segmentation.COCOSegmentation.coco.imgs.keys"], "methods", ["None"], ["def", "_split_images", "(", "self", ",", "split", ")", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "self", ".", "coco", "=", "COCO", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'COCO/annotations/instances_{}2017.json'", ".", "format", "(", "split", ")", ")", ")", "\n", "ids", "=", "list", "(", "sorted", "(", "self", ".", "coco", ".", "imgs", ".", "keys", "(", ")", ")", ")", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.COCOSegmentation._load_img": [[106, 111], ["PIL.Image.open().convert", "segmentation.COCOSegmentation.coco.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "def", "_load_img", "(", "self", ",", "item", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "item", "]", "\n", "path", "=", "self", ".", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'COCO/{}2017'", ".", "format", "(", "self", ".", "split", ")", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.COCOSegmentation._load_seg": [[112, 124], ["numpy.zeros", "segmentation.COCOSegmentation.coco.loadAnns", "PIL.Image.fromarray().convert", "segmentation.COCOSegmentation.coco.getAnnIds", "segmentation.COCOSegmentation.coco.annToMask", "PIL.Image.fromarray", "PIL.Image.fromarray().convert.clip"], "methods", ["None"], ["", "def", "_load_seg", "(", "self", ",", "item", ",", "min_obj_scale", "=", "0", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "item", "]", "\n", "img_size", "=", "(", "self", ".", "coco", ".", "imgs", "[", "img_id", "]", "[", "'width'", "]", ",", "self", ".", "coco", ".", "imgs", "[", "img_id", "]", "[", "'height'", "]", ")", "\n", "min_obj_size", "=", "img_size", "[", "0", "]", "*", "img_size", "[", "1", "]", "*", "min_obj_scale", "\n", "\n", "seg", "=", "np", ".", "zeros", "(", "[", "img_size", "[", "1", "]", ",", "img_size", "[", "0", "]", "]", ")", "# (H, W)", "\n", "for", "ann", "in", "self", ".", "coco", ".", "loadAnns", "(", "self", ".", "coco", ".", "getAnnIds", "(", "imgIds", "=", "img_id", ")", ")", ":", "\n", "            ", "if", "ann", "[", "'area'", "]", ">", "min_obj_size", ":", "\n", "                ", "seg", "+=", "self", ".", "coco", ".", "annToMask", "(", "ann", ")", "\n", "\n", "", "", "seg", "=", "Image", ".", "fromarray", "(", "(", "seg", ".", "clip", "(", "0", ",", "1", ")", "*", "255", ")", ".", "astype", "(", "'uint8'", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "return", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._split_images": [[129, 136], ["os.path.join", "os.path.join", "torchvision.datasets.ImageFolder"], "methods", ["None"], ["def", "_split_images", "(", "self", ",", "split", ")", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'imagenet9/original/train'", ")", "\n", "", "else", ":", "\n", "            ", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'imagenet9/bg_challenge/original/val'", ")", "\n", "", "ids", "=", "[", "img", "[", "0", "]", "for", "img", "in", "ImageFolder", "(", "img_dir", ")", ".", "imgs", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._load_img": [[137, 139], ["PIL.Image.open().convert", "PIL.Image.open"], "methods", ["None"], ["", "def", "_load_img", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "Image", ".", "open", "(", "self", ".", "ids", "[", "item", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._load_seg": [[140, 143], ["PIL.Image.open().convert", "PIL.Image.open", "segmentation.IN9Segmentation.ids[].replace"], "methods", ["None"], ["", "def", "_load_seg", "(", "self", ",", "item", ")", ":", "\n", "        ", "seg", "=", "Image", ".", "open", "(", "self", ".", "ids", "[", "item", "]", ".", "replace", "(", "'original'", ",", "'only_fg'", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "return", "seg", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.segmentation.IN9Segmentation._post_process": [[144, 148], ["seg.sum"], "methods", ["None"], ["", "def", "_post_process", "(", "self", ",", "seg", ")", ":", "\n", "        ", "seg", "[", "seg", ">", "0", "]", "=", "1", "\n", "seg", "=", "(", "seg", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "==", "3", ")", ".", "float", "(", ")", "\n", "return", "seg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.create_coco-objects.cli_main": [[9, 55], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "os.listdir", "os.path.join", "os.path.join", "torchvision.datasets.CocoDetection", "os.path.join", "enumerate", "os.path.join", "os.path.join", "os.path.exists", "os.makedirs", "tqdm.tqdm", "range", "os.path.exists", "os.makedirs", "len", "len", "create_coco-objects.expand_bbox", "torchvision.resized_crop", "str", "os.path.join", "TF.resized_crop.convert().save", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "TF.resized_crop.convert"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.create_coco-objects.expand_bbox"], ["def", "cli_main", "(", ")", ":", "\n", "    ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_root'", ",", "type", "=", "str", ",", "default", "=", "'/data'", ")", "\n", "parser", ".", "add_argument", "(", "'--img_size'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--min_size'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'minimum size (ratio) of cropped instance'", ")", "\n", "parser", ".", "add_argument", "(", "'--margin'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'expand bbox to contain some background'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_root", ",", "'COCO'", ")", "\n", "\n", "for", "split", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "img_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'{}2017'", ".", "format", "(", "split", ")", ")", "\n", "ann_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'annotations/instances_{}2017.json'", ".", "format", "(", "split", ")", ")", "\n", "dataset", "=", "CocoDetection", "(", "img_dir", ",", "ann_path", ")", "\n", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'objects'", ",", "split", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "\n", "", "for", "img_idx", ",", "(", "img", ",", "anns", ")", "in", "enumerate", "(", "tqdm", "(", "dataset", ")", ")", ":", "\n", "            ", "if", "len", "(", "anns", ")", "==", "0", ":", "# objects not exist", "\n", "                ", "continue", "\n", "\n", "", "min_size", "=", "img", ".", "size", "[", "0", "]", "*", "img", ".", "size", "[", "1", "]", "*", "args", ".", "min_size", "\n", "for", "ann_idx", "in", "range", "(", "len", "(", "anns", ")", ")", ":", "\n", "                ", "if", "anns", "[", "ann_idx", "]", "[", "'area'", "]", "<", "min_size", ":", "# skip small objects", "\n", "                    ", "continue", "\n", "\n", "", "j", ",", "i", ",", "w", ",", "h", "=", "anns", "[", "ann_idx", "]", "[", "'bbox'", "]", "\n", "bbox", "=", "(", "i", ",", "j", ",", "h", ",", "w", ")", "# convert to pytorch format", "\n", "bbox_expand", "=", "expand_bbox", "(", "*", "bbox", ",", "*", "img", ".", "size", ",", "margin", "=", "args", ".", "margin", ")", "\n", "img_cropped", "=", "TF", ".", "resized_crop", "(", "img", ",", "*", "bbox_expand", ",", "args", ".", "img_size", ")", "\n", "\n", "image_id", "=", "dataset", ".", "ids", "[", "img_idx", "]", "\n", "category_id", "=", "str", "(", "anns", "[", "ann_idx", "]", "[", "'category_id'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "category_id", ")", ")", ":", "\n", "                    ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "category_id", ")", ")", "\n", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "category_id", ",", "'{:012d}_{}.jpg'", ".", "format", "(", "image_id", ",", "ann_idx", ")", ")", "\n", "img_cropped", ".", "convert", "(", "'RGB'", ")", ".", "save", "(", "save_path", ")", "\n", "\n", "# create empty directories in training but not in validation dataset", "\n", "", "", "", "for", "category_id", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'objects/train'", ")", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'objects/val'", ",", "category_id", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.create_coco-objects.expand_bbox": [[57, 67], ["max", "max", "min", "min"], "function", ["None"], ["", "", "", "def", "expand_bbox", "(", "i", ",", "j", ",", "h", ",", "w", ",", "W", ",", "H", ",", "margin", "=", "0.2", ")", ":", "\n", "    ", "I", ",", "J", "=", "i", "+", "h", ",", "j", "+", "w", "\n", "i", "=", "max", "(", "0", ",", "i", "-", "h", "*", "margin", ")", "\n", "j", "=", "max", "(", "0", ",", "j", "-", "w", "*", "margin", ")", "\n", "I", "=", "min", "(", "H", ",", "I", "+", "h", "*", "margin", ")", "\n", "J", "=", "min", "(", "W", ",", "J", "+", "w", "*", "margin", ")", "\n", "h", ",", "w", "=", "I", "-", "i", ",", "J", "-", "j", "\n", "\n", "bbox", "=", "(", "i", ",", "j", ",", "h", ",", "w", ")", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCO.__init__": [[15, 21], ["os.path.join", "datasets.COCO", "list", "os.path.join", "sorted", "datasets.COCO.coco.imgs.keys"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "split", "=", "'train'", ",", "transform", "=", "None", ")", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "self", ".", "root", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'COCO/{}2017'", ".", "format", "(", "split", ")", ")", "\n", "self", ".", "coco", "=", "COCO", "(", "os", ".", "path", ".", "join", "(", "data_root", ",", "'COCO/annotations/instances_{}2017.json'", ".", "format", "(", "split", ")", ")", ")", "\n", "self", ".", "ids", "=", "list", "(", "sorted", "(", "self", ".", "coco", ".", "imgs", ".", "keys", "(", ")", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCO.__len__": [[22, 24], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCO.__getitem__": [[25, 35], ["PIL.Image.open().convert", "datasets.COCO.transform", "datasets.COCO.coco.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "item", "]", "\n", "\n", "path", "=", "self", ".", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "img_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCOBox.__init__": [[38, 41], ["datasets.COCO.__init__", "utils.load_boxes"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.load_boxes"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "split", "=", "'train'", ",", "box_path", "=", "None", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "data_root", ",", "split", "=", "split", ",", "transform", "=", "transform", ")", "\n", "self", ".", "boxes", "=", "box_utils", ".", "load_boxes", "(", "box_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCOBox.__getitem__": [[42, 58], ["PIL.Image.open().convert", "len", "random.choice", "utils.upscale_box", "datasets.COCOBox.crop", "datasets.COCOBox.transform", "str", "datasets.COCOBox.coco.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.upscale_box"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "img_id", "=", "self", ".", "ids", "[", "item", "]", "\n", "boxes", "=", "self", ".", "boxes", "[", "str", "(", "img_id", ")", "]", "\n", "\n", "path", "=", "self", ".", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "len", "(", "boxes", ")", ">", "0", ":", "\n", "            ", "box", "=", "random", ".", "choice", "(", "boxes", ")", "\n", "box", "=", "box_utils", ".", "upscale_box", "(", "box", ",", "img", ".", "size", ")", "\n", "img", "=", "img", ".", "crop", "(", "box", ")", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "return", "img", ",", "img_id", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.COCOBox.get_gt_box": [[59, 80], ["datasets.COCO", "list", "tqdm.tqdm.tqdm", "os.path.join", "sorted", "COCO.loadAnns", "COCO.imgs.keys", "COCO.getAnnIds", "utils.xywh_to_xyxy", "utils.expand_box", "boxes.append", "str"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.xywh_to_xyxy", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.utils.box_utils.expand_box"], ["", "@", "staticmethod", "\n", "def", "get_gt_box", "(", "data_root", ",", "split", "=", "'train'", ",", "min_obj_scale", "=", "0.01", ",", "box_margin", "=", "0.2", ")", ":", "\n", "        ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "coco", "=", "COCO", "(", "os", ".", "path", ".", "join", "(", "data_root", ",", "'COCO/annotations/instances_{}2017.json'", ".", "format", "(", "split", ")", ")", ")", "\n", "ids", "=", "list", "(", "sorted", "(", "coco", ".", "imgs", ".", "keys", "(", ")", ")", ")", "\n", "\n", "all_boxes", "=", "{", "}", "\n", "for", "img_id", "in", "tqdm", "(", "ids", ")", ":", "\n", "            ", "img_size", "=", "(", "coco", ".", "imgs", "[", "img_id", "]", "[", "'width'", "]", ",", "coco", ".", "imgs", "[", "img_id", "]", "[", "'height'", "]", ")", "\n", "min_obj_size", "=", "img_size", "[", "0", "]", "*", "img_size", "[", "1", "]", "*", "min_obj_scale", "\n", "\n", "boxes", "=", "[", "]", "\n", "for", "ann", "in", "coco", ".", "loadAnns", "(", "coco", ".", "getAnnIds", "(", "imgIds", "=", "img_id", ")", ")", ":", "\n", "                ", "if", "ann", "[", "'area'", "]", ">", "min_obj_size", ":", "\n", "                    ", "box", "=", "box_utils", ".", "xywh_to_xyxy", "(", "ann", "[", "'bbox'", "]", ")", "\n", "box", "=", "box_utils", ".", "expand_box", "(", "box", ",", "img_size", ",", "margin", "=", "box_margin", ")", "\n", "boxes", ".", "append", "(", "box", ")", "\n", "\n", "", "", "all_boxes", "[", "str", "(", "img_id", ")", "]", "=", "boxes", "\n", "\n", "", "return", "all_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.BaseDataset.__init__": [[83, 86], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "samples", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "samples", "=", "samples", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.BaseDataset.__getitem__": [[87, 93], ["PIL.Image.open().convert", "datasets.BaseDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "path", ",", "label", "=", "self", ".", "samples", "[", "idx", "]", "\n", "img", "=", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.BaseDataset.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.Food101.__init__": [[99, 113], ["os.path.join", "enumerate", "datasets.BaseDataset.__init__", "open", "open", "json.load", "os.path.join", "line.strip", "os.path.join", "samples.append", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "split", ",", "transform", "=", "None", ")", ":", "\n", "        ", "root", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'food-101'", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'meta'", ",", "'classes.txt'", ")", ")", "as", "f", ":", "\n", "            ", "classes", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'meta'", ",", "f'{split}.json'", ")", ")", "as", "f", ":", "\n", "            ", "annotations", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "samples", "=", "[", "]", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "classes", ")", ":", "\n", "            ", "for", "path", "in", "annotations", "[", "cls", "]", ":", "\n", "                ", "samples", ".", "append", "(", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "f'{path}.jpg'", ")", ",", "i", ")", ")", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "samples", ",", "transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.Pets.__init__": [[116, 129], ["os.path.join", "datasets.BaseDataset.__init__", "open", "os.path.join", "samples.append", "os.path.join", "line.split", "int"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "split", ",", "transform", "=", "None", ")", ":", "\n", "        ", "root", "=", "os", ".", "path", ".", "join", "(", "data_root", ",", "'Pets'", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "'annotations'", ",", "f'{split}.txt'", ")", ")", "as", "f", ":", "\n", "            ", "annotations", "=", "[", "line", ".", "split", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "", "samples", "=", "[", "]", "\n", "for", "sample", "in", "annotations", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "sample", "[", "0", "]", "+", "'.jpg'", ")", "\n", "label", "=", "int", "(", "sample", "[", "1", "]", ")", "-", "1", "\n", "samples", ".", "append", "(", "(", "path", ",", "label", ")", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "samples", ",", "transform", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.IN9WithMask.__init__": [[132, 138], ["torch.utils.data.Dataset.__init__", "datasets.IN9WithMask.get_file_names_list"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.IN9WithMask.get_file_names_list"], ["    ", "def", "__init__", "(", "self", ",", "sample_dataset", ",", "mask_dataset", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sample_dataset", "=", "sample_dataset", "\n", "self", ".", "mask_dataset", "=", "mask_dataset", "\n", "self", ".", "data_file_names_list", ",", "self", ".", "mask_file_names_list", "=", "self", ".", "get_file_names_list", "(", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.IN9WithMask.get_file_names_list": [[139, 147], ["None"], "methods", ["None"], ["", "def", "get_file_names_list", "(", "self", ")", ":", "\n", "        ", "imgs", "=", "self", ".", "sample_dataset", ".", "imgs", "\n", "data_file_names_list", "=", "[", "img", "[", "0", "]", "for", "img", "in", "imgs", "]", "\n", "\n", "masks", "=", "self", ".", "mask_dataset", ".", "imgs", "\n", "mask_file_names_list", "=", "[", "mask", "[", "0", "]", "for", "mask", "in", "masks", "]", "\n", "\n", "return", "data_file_names_list", ",", "mask_file_names_list", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.IN9WithMask.__len__": [[148, 150], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_file_names_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.IN9WithMask.__getitem__": [[151, 161], ["PIL.Image.open().convert", "PIL.Image.open().convert", "datasets.IN9WithMask.transform", "PIL.Image.open", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "data_file_name", "=", "self", ".", "data_file_names_list", "[", "idx", "]", "\n", "mask_file_name", "=", "self", ".", "mask_file_names_list", "[", "idx", "]", "\n", "\n", "img", "=", "Image", ".", "open", "(", "data_file_name", ")", ".", "convert", "(", "'RGB'", ")", "\n", "mask", "=", "Image", ".", "open", "(", "mask_file_name", ")", ".", "convert", "(", "'L'", ")", "\n", "\n", "combined", "=", "self", ".", "transform", "(", "img", ",", "mask", ")", "\n", "\n", "return", "combined", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.NineDataset.__init__": [[164, 183], ["torch.utils.data.Dataset.__init__", "datasets.NineDataset.get_files_list"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.NineDataset.get_files_list"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "in_info_path", "=", "'./data/imagenet_info'", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "dog", "=", "'n02084071'", "\n", "bird", "=", "'n01503061'", "\n", "vehicle", "=", "'n04576211'", "\n", "reptile", "=", "'n01661091'", "\n", "carnivore", "=", "'n02075296'", "\n", "insect", "=", "'n02159955'", "\n", "instrument", "=", "'n03800933'", "\n", "primate", "=", "'n02469914'", "\n", "fish", "=", "'n02512053'", "\n", "\n", "self", ".", "imagenet_id_list", "=", "[", "dog", ",", "bird", ",", "vehicle", ",", "reptile", ",", "carnivore", ",", "insect", ",", "instrument", ",", "primate", ",", "fish", "]", "\n", "self", ".", "imagenet_names", "=", "[", "'dog'", ",", "'bird'", ",", "'vehicle'", ",", "'reptile'", ",", "'carnivore'", ",", "'insect'", ",", "'instrunment'", ",", "'primate'", ",", "'fish'", "]", "\n", "self", ".", "file_names_list", "=", "self", ".", "get_files_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.NineDataset.get_files_list": [[184, 206], ["dict", "enumerate", "robustness.tools.imagenet_helpers.ImageNetHierarchy", "os.system", "os.system", "robustness.tools.imagenet_helpers.ImageNetHierarchy", "robustness.tools.imagenet_helpers.ImageNetHierarchy.get_superclasses", "len", "os.listdir", "os.path.join", "data_list.append", "os.path.join"], "methods", ["None"], ["", "def", "get_files_list", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "in_hier", "=", "ImageNetHierarchy", "(", "self", ".", "root", ",", "self", ".", "in_info_path", ")", "\n", "", "except", ":", "\n", "            ", "os", ".", "system", "(", "f'ln -s {self.root} {self.root}/train'", ")", "\n", "os", ".", "system", "(", "f'ln -s {self.root} {self.root}/val'", ")", "\n", "in_hier", "=", "ImageNetHierarchy", "(", "self", ".", "root", ",", "self", ".", "in_info_path", ")", "\n", "\n", "", "data_list", "=", "[", "]", "\n", "class_names_class_dict", "=", "dict", "(", ")", "\n", "for", "idx", ",", "class_name", "in", "enumerate", "(", "self", ".", "imagenet_id_list", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "superclass_wnid", "=", "in_hier", ".", "tree", "[", "class_name", "]", ".", "descendants_all", "\n", "superclass_wnid", ",", "class_ranges", ",", "label_map", "=", "in_hier", ".", "get_superclasses", "(", "\n", "len", "(", "in_hier", ".", "tree", "[", "class_name", "]", ".", "descendants_all", ")", ",", "ancestor_wnid", "=", "class_name", ")", "\n", "for", "sub_class", "in", "superclass_wnid", ":", "\n", "                    ", "file_names", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "sub_class", ")", ")", "\n", "for", "file_name", "in", "file_names", ":", "\n", "                        ", "data_list", ".", "append", "(", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'val'", ",", "sub_class", ",", "file_name", ")", ",", "idx", ")", ")", "\n", "", "", "", "except", ":", "\n", "                ", "continue", "\n", "", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.NineDataset.__len__": [[207, 209], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "file_names_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datasets.NineDataset.__getitem__": [[210, 216], ["PIL.Image.open().convert", "datasets.NineDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "file_name", ",", "label", "=", "self", ".", "file_names_list", "[", "idx", "]", "\n", "img", "=", "Image", ".", "open", "(", "file_name", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "img", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__": [[278, 304], ["pytorch_lightning.LightningDataModule.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "train_dataset", "=", "None", ",", "\n", "val_dataset", "=", "None", ",", "\n", "test_dataset", "=", "None", ",", "\n", "num_classes", "=", "None", ",", "\n", "num_workers", ":", "int", "=", "16", ",", "\n", "batch_size", ":", "int", "=", "32", ",", "\n", "pin_memory", ":", "bool", "=", "True", ",", "\n", "shuffle", ":", "bool", "=", "False", ",", "\n", "drop_last", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "train_dataset", "=", "train_dataset", "\n", "self", ".", "val_dataset", "=", "val_dataset", "\n", "self", ".", "test_dataset", "=", "test_dataset", "\n", "if", "self", ".", "train_dataset", "is", "not", "None", ":", "\n", "            ", "self", ".", "num_samples", "=", "len", "(", "self", ".", "train_dataset", ")", "\n", "", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "num_workers", "=", "num_workers", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "pin_memory", "=", "pin_memory", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.train_dataloader": [[305, 307], ["datamodules.BaseDataModule._data_loader"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader"], ["", "def", "train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "return", "self", ".", "_data_loader", "(", "self", ".", "train_dataset", ",", "shuffle", "=", "self", ".", "shuffle", ",", "drop_last", "=", "self", ".", "drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.val_dataloader": [[308, 315], ["isinstance", "datamodules.BaseDataModule._data_loader", "datamodules.BaseDataModule._data_loader"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader"], ["", "def", "val_dataloader", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "val_dataset", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "[", "self", ".", "_data_loader", "(", "dataset", ")", "for", "dataset", "in", "self", ".", "val_dataset", "]", "\n", "", "elif", "self", ".", "val_dataset", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_data_loader", "(", "self", ".", "val_dataset", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule.test_dataloader": [[316, 323], ["isinstance", "datamodules.BaseDataModule._data_loader", "datamodules.BaseDataModule._data_loader"], "methods", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader"], ["", "", "def", "test_dataloader", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "test_dataset", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "return", "[", "self", ".", "_data_loader", "(", "dataset", ")", "for", "dataset", "in", "self", ".", "test_dataset", "]", "\n", "", "elif", "self", ".", "test_dataset", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_data_loader", "(", "self", ".", "test_dataset", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.BaseDataModule._data_loader": [[324, 332], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "", "def", "_data_loader", "(", "self", ",", "dataset", ",", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", ":", "\n", "        ", "return", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", "pin_memory", "=", "self", ".", "pin_memory", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.CIFAR100DataModule.num_classes": [[342, 345], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "num_classes", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "100", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_pretrain_datamodule": [[17, 69], ["datamodules._load_online_finetune_datasets", "print", "enumerate", "datamodules.BaseDataModule", "print", "print", "segmentation.CUBSegmentation", "segmentation.FlowersSegmentation", "datasets.COCO", "len", "os.path.join", "datasets.COCOBox", "len", "len", "os.path.join", "torchvision.datasets.ImageFolder", "os.path.join", "os.path.join", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "datasets.IN9WithMask"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules._load_online_finetune_datasets"], ["def", "load_pretrain_datamodule", "(", "dataset", ",", "ft_datasets", "=", "(", ")", ",", "\n", "batch_size", "=", "64", ",", "num_workers", "=", "8", ",", "shuffle", "=", "True", ",", "drop_last", "=", "True", ",", "\n", "train_transform", "=", "None", ",", "test_transform", "=", "None", ")", ":", "\n", "\n", "    ", "if", "dataset", "in", "[", "'cub'", ",", "'flowers'", "]", ":", "\n", "# segmentation datasets", "\n", "        ", "if", "dataset", "==", "'cub'", ":", "\n", "            ", "train", "=", "CUBSegmentation", "(", "DATA_ROOT", ",", "split_root", "=", "SPLIT_ROOT", ",", "split", "=", "'train'", ",", "transform", "=", "train_transform", ")", "\n", "", "else", ":", "\n", "            ", "train", "=", "FlowersSegmentation", "(", "DATA_ROOT", ",", "split", "=", "'train'", ",", "transform", "=", "train_transform", ")", "\n", "\n", "# COCO datasets", "\n", "", "", "elif", "dataset", "==", "'coco'", ":", "\n", "        ", "train", "=", "COCO", "(", "DATA_ROOT", ",", "split", "=", "'train'", ",", "transform", "=", "train_transform", ")", "\n", "\n", "", "elif", "'coco-box'", "in", "dataset", ":", "\n", "        ", "box_path", "=", "os", ".", "path", ".", "join", "(", "BOX_ROOT", ",", "'coco_{}.txt'", ".", "format", "(", "dataset", "[", "9", ":", "]", ")", ")", "# 'coco-box-{box_name}'", "\n", "train", "=", "COCOBox", "(", "DATA_ROOT", ",", "split", "=", "'train'", ",", "box_path", "=", "box_path", ",", "transform", "=", "train_transform", ")", "\n", "\n", "# IN9 datasets", "\n", "", "elif", "dataset", "==", "'in9'", ":", "\n", "        ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/train'", ")", "\n", "train", "=", "ImageFolder", "(", "data_dir", ",", "transform", "=", "train_transform", ")", "\n", "\n", "", "elif", "'in9-mask'", "in", "dataset", ":", "\n", "        ", "data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/train'", ")", "\n", "mask_dir", "=", "os", ".", "path", ".", "join", "(", "MASK_ROOT", ",", "f'in9_{dataset[9:]}'", ")", "# 'in9-mask-{mask_name}'", "\n", "sample_dataset", "=", "ImageFolder", "(", "data_dir", ")", "\n", "mask_dataset", "=", "ImageFolder", "(", "mask_dir", ")", "\n", "train", "=", "IN9WithMask", "(", "sample_dataset", ",", "mask_dataset", ",", "transform", "=", "train_transform", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "finetune", "=", "_load_online_finetune_datasets", "(", "ft_datasets", ",", "transform", "=", "test_transform", ")", "\n", "\n", "print", "(", "'Pre-train dataset: {}'", ".", "format", "(", "len", "(", "train", ")", ")", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "ft_datasets", ")", ":", "\n", "        ", "print", "(", "'FT-train dataset ({}): {}'", ".", "format", "(", "name", ",", "len", "(", "finetune", "[", "2", "*", "i", "]", ")", ")", ")", "\n", "print", "(", "'FT-test dataset ({}): {}'", ".", "format", "(", "name", ",", "len", "(", "finetune", "[", "2", "*", "i", "+", "1", "]", ")", ")", ")", "\n", "\n", "# create datamodule", "\n", "", "dm", "=", "BaseDataModule", "(", "\n", "train_dataset", "=", "train", ",", "\n", "val_dataset", "=", "finetune", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", ")", "\n", "\n", "return", "dm", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules._load_online_finetune_datasets": [[71, 122], ["isinstance", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "datamodules.random_subset", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "datasets.Food101", "datasets.Food101", "datasets.Pets", "datasets.Pets", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.random_subset"], ["", "def", "_load_online_finetune_datasets", "(", "ft_datasets", "=", "(", ")", ",", "transform", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load fine-tuning datasets for online evaluation\"\"\"", "\n", "if", "not", "isinstance", "(", "ft_datasets", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "ft_datasets", "=", "[", "ft_datasets", "]", "\n", "\n", "", "finetune", "=", "[", "]", "\n", "for", "ft_dataset", "in", "ft_datasets", ":", "\n", "        ", "if", "ft_dataset", "==", "'cifar10'", ":", "\n", "# num_classes: 10", "\n", "            ", "ft_train", "=", "CIFAR10", "(", "DATA_ROOT", ",", "train", "=", "True", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "CIFAR10", "(", "DATA_ROOT", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'coco'", ":", "\n", "# num_classes: 80", "\n", "            ", "ft_train", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'COCO/objects/train'", ")", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'COCO/objects/val'", ")", ",", "transform", "=", "transform", ")", "\n", "ft_train", "=", "random_subset", "(", "ft_train", ",", "len", "(", "ft_train", ")", "//", "5", ")", "# use 20% of samples", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'in9'", ":", "\n", "# num_classes: 9", "\n", "            ", "ft_train", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/train'", ")", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/val'", ")", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'cub'", ":", "\n", "# num_classes: 200", "\n", "            ", "ft_train", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'CUB_200_2011/train'", ")", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'CUB_200_2011/test'", ")", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'food'", ":", "\n", "# num_classes: 101", "\n", "            ", "ft_train", "=", "Food101", "(", "DATA_ROOT", ",", "split", "=", "'train'", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "Food101", "(", "DATA_ROOT", ",", "split", "=", "'test'", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'pets'", ":", "\n", "# num_classes: 37", "\n", "            ", "ft_train", "=", "Pets", "(", "DATA_ROOT", ",", "split", "=", "'trainval'", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "Pets", "(", "DATA_ROOT", ",", "split", "=", "'test'", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "if", "ft_dataset", "==", "'flowers'", ":", "\n", "# num_classes: 102", "\n", "            ", "ft_train", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'flowers102/trn'", ")", ",", "transform", "=", "transform", ")", "\n", "ft_test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'flowers102/tst'", ")", ",", "transform", "=", "transform", ")", "\n", "finetune", "+=", "[", "ft_train", ",", "ft_test", "]", "\n", "\n", "", "", "return", "finetune", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_finetune_datamodule": [[124, 224], ["torch.Generator().manual_seed", "BaseDataModule.prepare_data", "BaseDataModule.setup", "print", "print", "print", "datamodules.apply_transform", "datamodules.apply_transform", "datamodules.apply_transform", "pl_bolts.datamodules.CIFAR10DataModule", "torch.Generator", "datamodules.CIFAR100DataModule", "len", "len", "len", "os.path.join", "torchvision.datasets.ImageFolder", "len", "torch.utils.data.random_split", "os.path.join", "torchvision.datasets.ImageFolder", "datamodules.load_finetune_datamodule.apply_all_transforms"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.detection.train_net.setup", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.apply_transform", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.apply_transform", "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.apply_transform"], ["", "def", "load_finetune_datamodule", "(", "dataset", ",", "batch_size", "=", "64", ",", "num_workers", "=", "8", ",", "\n", "train_transform", "=", "None", ",", "test_transform", "=", "None", ")", ":", "\n", "    ", "loader_kwargs", "=", "{", "\n", "'train_transforms'", ":", "train_transform", ",", "'val_transforms'", ":", "test_transform", ",", "'test_transforms'", ":", "test_transform", ",", "\n", "'batch_size'", ":", "batch_size", ",", "'num_workers'", ":", "num_workers", ",", "'drop_last'", ":", "False", ",", "'pin_memory'", ":", "True", ",", "\n", "}", "\n", "\n", "generator", "=", "torch", ".", "Generator", "(", ")", ".", "manual_seed", "(", "42", ")", "\n", "\n", "def", "apply_all_transforms", "(", "train", "=", "None", ",", "val", "=", "None", ",", "test", "=", "None", ")", ":", "\n", "        ", "apply_transform", "(", "train", ",", "train_transform", ")", "\n", "apply_transform", "(", "val", ",", "test_transform", ")", "\n", "apply_transform", "(", "test", ",", "test_transform", ")", "\n", "\n", "# create fine-tuning dataset", "\n", "", "if", "dataset", "==", "'cifar10'", ":", "\n", "        ", "dm", "=", "CIFAR10DataModule", "(", "DATA_ROOT", ",", "**", "loader_kwargs", ")", "\n", "\n", "", "elif", "dataset", "==", "'cifar100'", ":", "\n", "        ", "dm", "=", "CIFAR100DataModule", "(", "DATA_ROOT", ",", "**", "loader_kwargs", ")", "\n", "\n", "", "elif", "'in9'", "in", "dataset", ":", "\n", "# in9-{ mixed_rand / mixed_same / fg_only / ... }", "\n", "        ", "train_data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/train'", ")", "\n", "trainval", "=", "ImageFolder", "(", "train_data_dir", ",", "transform", "=", "train_transform", ")", "\n", "len_trainval", "=", "len", "(", "trainval", ")", "\n", "train", ",", "val", "=", "random_split", "(", "trainval", ",", "[", "int", "(", "len_trainval", "*", "0.95", ")", ",", "len_trainval", "-", "int", "(", "len_trainval", "*", "0.95", ")", "]", ",", "generator", "=", "generator", ")", "\n", "\n", "dataset_type", "=", "dataset", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "test_data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "f'bg_challenge/bg_challenge/{dataset_type}/val'", ")", "\n", "test", "=", "ImageFolder", "(", "test_data_dir", ")", "\n", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "9", "\n", "\n", "", "else", ":", "# custom datamodules", "\n", "        ", "if", "dataset", "==", "'cub'", ":", "\n", "            ", "trainval", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'CUB_200_2011/train'", ")", ")", "\n", "test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'CUB_200_2011/test'", ")", ")", "\n", "train", ",", "val", "=", "random_split", "(", "trainval", ",", "[", "4994", ",", "1000", "]", ",", "generator", "=", "generator", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "200", "\n", "\n", "", "elif", "dataset", "==", "'flowers'", ":", "\n", "            ", "train", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'flowers102/trn'", ")", ")", "\n", "val", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'flowers102/val'", ")", ")", "\n", "test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'flowers102/tst'", ")", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "102", "\n", "\n", "", "elif", "dataset", "==", "'food'", ":", "\n", "            ", "trainval", "=", "Food101", "(", "DATA_ROOT", ",", "split", "=", "'train'", ")", "\n", "test", "=", "Food101", "(", "DATA_ROOT", ",", "split", "=", "'test'", ")", "\n", "train", ",", "val", "=", "random_split", "(", "trainval", ",", "[", "68175", ",", "7575", "]", ",", "generator", "=", "generator", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "101", "\n", "\n", "", "elif", "dataset", "==", "'pets'", ":", "\n", "            ", "trainval", "=", "Pets", "(", "DATA_ROOT", ",", "split", "=", "'trainval'", ")", "\n", "test", "=", "Pets", "(", "DATA_ROOT", ",", "split", "=", "'test'", ")", "\n", "train", ",", "val", "=", "random_split", "(", "trainval", ",", "[", "2940", ",", "740", "]", ",", "generator", "=", "generator", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "37", "\n", "\n", "", "elif", "dataset", "==", "'coco'", ":", "\n", "            ", "trainval", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'COCO/objects/train'", ")", ")", "\n", "test", "=", "ImageFolder", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'COCO/objects/val'", ")", ")", "\n", "train", ",", "val", "=", "random_split", "(", "trainval", ",", "[", "len", "(", "trainval", ")", "-", "10000", ",", "10000", "]", ",", "generator", "=", "generator", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "80", "\n", "\n", "", "elif", "dataset", "==", "'imagenet-r-9'", ":", "\n", "            ", "train_data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/original/train'", ")", "\n", "train", "=", "ImageFolder", "(", "train_data_dir", ")", "\n", "val_data_dir", "=", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'bg_challenge/bg_challenge/original/val'", ")", "\n", "val", "=", "ImageFolder", "(", "val_data_dir", ")", "\n", "\n", "test", "=", "NineDataset", "(", "os", ".", "path", ".", "join", "(", "DATA_ROOT", ",", "'imagenet-r'", ")", ")", "\n", "apply_all_transforms", "(", "train", ",", "val", ",", "test", ")", "\n", "num_classes", "=", "9", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "dm", "=", "BaseDataModule", "(", "\n", "train_dataset", "=", "train", ",", "\n", "val_dataset", "=", "val", ",", "\n", "test_dataset", "=", "test", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "**", "loader_kwargs", ",", "\n", ")", "\n", "\n", "", "dm", ".", "prepare_data", "(", ")", "\n", "dm", ".", "setup", "(", ")", "\n", "\n", "print", "(", "'Train dataset: {}'", ".", "format", "(", "len", "(", "dm", ".", "train_dataloader", "(", ")", ".", "dataset", ")", ")", ")", "\n", "print", "(", "'Val dataset: {}'", ".", "format", "(", "len", "(", "dm", ".", "val_dataloader", "(", ")", ".", "dataset", ")", ")", ")", "\n", "print", "(", "'Test dataset: {}'", ".", "format", "(", "len", "(", "dm", ".", "test_dataloader", "(", ")", ".", "dataset", ")", ")", ")", "\n", "\n", "return", "dm", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.load_segment_datamodule": [[226, 249], ["datamodules.BaseDataModule", "segmentation.CUBSegmentation", "segmentation.FlowersSegmentation", "segmentation.COCOSegmentation", "segmentation.IN9Segmentation"], "function", ["None"], ["", "def", "load_segment_datamodule", "(", "dataset", ",", "batch_size", "=", "64", ",", "num_workers", "=", "8", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_kwargs", "=", "{", "'seed'", ":", "42", ",", "'transform'", ":", "transform", ",", "'target_transform'", ":", "target_transform", "}", "\n", "loader_kwargs", "=", "{", "'batch_size'", ":", "batch_size", ",", "'num_workers'", ":", "num_workers", ",", "'drop_last'", ":", "False", ",", "'pin_memory'", ":", "True", "}", "\n", "\n", "if", "dataset", "==", "'cub'", ":", "\n", "        ", "test", "=", "CUBSegmentation", "(", "DATA_ROOT", ",", "split_root", "=", "SPLIT_ROOT", ",", "split", "=", "'test'", ",", "**", "dataset_kwargs", ")", "\n", "", "elif", "dataset", "==", "'flowers'", ":", "\n", "        ", "test", "=", "FlowersSegmentation", "(", "DATA_ROOT", ",", "split", "=", "'test'", ",", "**", "dataset_kwargs", ")", "\n", "", "elif", "dataset", "==", "'coco'", ":", "\n", "        ", "test", "=", "COCOSegmentation", "(", "DATA_ROOT", ",", "split", "=", "'val'", ",", "**", "dataset_kwargs", ")", "\n", "", "elif", "dataset", "==", "'in9'", ":", "\n", "        ", "test", "=", "IN9Segmentation", "(", "DATA_ROOT", ",", "split", "=", "'test'", ",", "**", "dataset_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "", "dm", "=", "BaseDataModule", "(", "\n", "test_dataset", "=", "test", ",", "\n", "**", "loader_kwargs", ",", "\n", ")", "\n", "\n", "return", "dm", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.get_image_ids": [[251, 261], ["isinstance", "map", "isinstance", "isinstance", "path[].replace"], "function", ["None"], ["", "def", "get_image_ids", "(", "dataset", ")", ":", "\n", "    ", "if", "isinstance", "(", "dataset", ",", "COCO", ")", ":", "\n", "        ", "ids", "=", "map", "(", "str", ",", "dataset", ".", "ids", ")", "\n", "", "elif", "isinstance", "(", "dataset", ",", "SegmentationDataset", ")", ":", "\n", "        ", "ids", "=", "dataset", ".", "ids", "\n", "", "elif", "isinstance", "(", "dataset", ",", "ImageFolder", ")", ":", "\n", "        ", "ids", "=", "[", "path", "[", "0", "]", ".", "replace", "(", "dataset", ".", "root", "+", "'/'", ",", "''", ")", "for", "path", "in", "dataset", ".", "imgs", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.random_subset": [[263, 266], ["torch.utils.data.random_split", "len"], "function", ["None"], ["", "def", "random_subset", "(", "dataset", ",", "num_samples", ",", "generator", "=", "torch", ".", "default_generator", ")", ":", "\n", "    ", "dataset", ",", "_", "=", "random_split", "(", "dataset", ",", "[", "num_samples", ",", "len", "(", "dataset", ")", "-", "num_samples", "]", ",", "generator", "=", "generator", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.apply_transform": [[268, 273], ["isinstance", "datamodules.apply_transform", "isinstance"], "function", ["home.repos.pwc.inspect_result.alinlab_object-aware-contrastive.data.datamodules.apply_transform"], ["", "def", "apply_transform", "(", "dataset", ",", "transform", ")", ":", "\n", "    ", "if", "isinstance", "(", "dataset", ",", "Subset", ")", ":", "\n", "        ", "apply_transform", "(", "dataset", ".", "dataset", ",", "transform", ")", "\n", "", "elif", "isinstance", "(", "dataset", ",", "Dataset", ")", ":", "\n", "        ", "dataset", ".", "transform", "=", "transform", "\n", "\n"]]}