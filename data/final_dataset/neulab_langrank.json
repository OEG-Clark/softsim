{"home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task": [[39, 42], ["Exception"], "function", ["None"], ["def", "check_task", "(", "task", ")", ":", "\n", "\t", "if", "task", "not", "in", "TASKS", ":", "\n", "\t\t", "raise", "Exception", "(", "\"Unknown task \"", "+", "task", "+", "\". Only 'MT', 'DEP', 'EL', 'POS' are supported.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task_model": [[43, 49], ["langrank.check_task", "langrank.map_task_to_models", "Exception"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_models"], ["", "", "def", "check_task_model", "(", "task", ",", "model", ")", ":", "\n", "\t", "check_task", "(", "task", ")", "\n", "avail_models", "=", "map_task_to_models", "(", "task", ")", "\n", "if", "model", "not", "in", "avail_models", ":", "\n", "\t\t", "ll", "=", "', '", ".", "join", "(", "[", "key", "for", "key", "in", "avail_models", "]", ")", "\n", "raise", "Exception", "(", "\"Unknown model \"", "+", "model", "+", "\". Only \"", "+", "ll", "+", "\" are provided.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task_model_data": [[50, 56], ["langrank.check_task_model", "langrank.map_task_to_data", "Exception"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task_model", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_data"], ["", "", "def", "check_task_model_data", "(", "task", ",", "model", ",", "data", ")", ":", "\n", "\t", "check_task_model", "(", "task", ",", "model", ")", "\n", "avail_data", "=", "map_task_to_data", "(", "task", ")", "\n", "if", "data", "not", "in", "avail_data", ":", "\n", "\t\t", "ll", "=", "', '", ".", "join", "(", "[", "key", "for", "key", "in", "avail_data", "]", ")", "\n", "raise", "Exception", "(", "\"Unknown dataset \"", "+", "data", "+", "\". Only \"", "+", "ll", "+", "\" are provided.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_data": [[59, 70], ["Exception"], "function", ["None"], ["", "", "def", "map_task_to_data", "(", "task", ")", ":", "\n", "\t", "if", "task", "==", "\"MT\"", ":", "\n", "\t\t", "return", "MT_DATASETS", "\n", "", "elif", "task", "==", "\"POS\"", ":", "\n", "\t\t", "return", "POS_DATASETS", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t", "return", "EL_DATASETS", "\n", "", "elif", "task", "==", "\"DEP\"", ":", "\n", "\t\t", "return", "DEP_DATASETS", "\n", "", "else", ":", "\n", "\t\t", "raise", "Exception", "(", "\"Unknown task\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_models": [[71, 82], ["Exception"], "function", ["None"], ["", "", "def", "map_task_to_models", "(", "task", ")", ":", "\n", "\t", "if", "task", "==", "\"MT\"", ":", "\n", "\t\t", "return", "MT_MODELS", "\n", "", "elif", "task", "==", "\"POS\"", ":", "\n", "\t\t", "return", "POS_MODELS", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t", "return", "EL_MODELS", "\n", "", "elif", "task", "==", "\"DEP\"", ":", "\n", "\t\t", "return", "DEP_MODELS", "\n", "", "else", ":", "\n", "\t\t", "raise", "Exception", "(", "\"Unknown task\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.read_vocab_file": [[83, 94], ["open", "inp.readlines", "l.strip().split.strip().split", "len", "c.append", "v.append", "l.strip().split.strip", "int"], "function", ["None"], ["", "", "def", "read_vocab_file", "(", "fn", ")", ":", "\n", "\t", "with", "open", "(", "fn", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "c", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "\t\t\t", "c", ".", "append", "(", "int", "(", "l", "[", "1", "]", ")", ")", "\n", "v", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "", "", "return", "v", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.get_candidates": [[97, 126], ["langrank.map_task_to_data", "Exception", "pkg_resources.resource_filename", "numpy.load().item", "isinstance", "os.path.join", "len", "numpy.load", "len", "add_languages.append", "sub_languages.append"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_data"], ["", "def", "get_candidates", "(", "task", ",", "languages", "=", "None", ")", ":", "\n", "\t", "if", "languages", "is", "not", "None", "and", "not", "isinstance", "(", "languages", ",", "list", ")", ":", "\n", "\t\t", "raise", "Exception", "(", "\"languages should be a list of ISO-3 codes\"", ")", "\n", "\n", "", "datasets_dict", "=", "map_task_to_data", "(", "task", ")", "\n", "cands", "=", "[", "]", "\n", "for", "dt", "in", "datasets_dict", ":", "\n", "\t\t", "fn", "=", "pkg_resources", ".", "resource_filename", "(", "__name__", ",", "os", ".", "path", ".", "join", "(", "'indexed'", ",", "task", ",", "datasets_dict", "[", "dt", "]", ")", ")", "\n", "d", "=", "np", ".", "load", "(", "fn", ",", "encoding", "=", "'latin1'", ",", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "cands", "+=", "[", "(", "key", ",", "d", "[", "key", "]", ")", "for", "key", "in", "d", "if", "key", "!=", "\"eng\"", "]", "\n", "# Possibly restrict to a subset of candidate languages", "\n", "", "if", "languages", "is", "not", "None", "and", "task", "==", "\"MT\"", ":", "\n", "\t\t", "add_languages", "=", "[", "]", "\n", "sub_languages", "=", "[", "]", "\n", "for", "l", "in", "languages", ":", "\n", "\t\t\t", "if", "len", "(", "l", ")", "==", "3", ":", "\n", "\t\t\t\t", "add_languages", ".", "append", "(", "l", ")", "\n", "", "else", ":", "\n", "# starts with -", "\n", "\t\t\t\t", "sub_languages", ".", "append", "(", "l", "[", "1", ":", "]", ")", "\n", "# Keep a candidate if it matches the languages", "\n", "# -aze indicates all except aze", "\n", "", "", "if", "len", "(", "add_languages", ")", ">", "0", ":", "\n", "\t\t\t", "new_cands", "=", "[", "c", "for", "c", "in", "cands", "if", "c", "[", "0", "]", "[", "-", "3", ":", "]", "in", "add_languages", "and", "c", "[", "0", "]", "[", "-", "3", "]", "not", "in", "sub_languages", "]", "\n", "", "else", ":", "\n", "\t\t\t", "new_cands", "=", "[", "c", "for", "c", "in", "cands", "if", "c", "[", "0", "]", "[", "-", "3", ":", "]", "not", "in", "sub_languages", "]", "\n", "", "return", "new_cands", "\n", "\n", "", "return", "cands", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.prepare_new_dataset": [[128, 197], ["isinstance", "print", "isinstance", "isinstance", "print", "open", "inp.readlines", "Exception", "len", "len", "set", "len", "isinstance", "len", "len", "set", "len", "print", "float", "len", "set", "open", "inp.readlines", "float", "s.strip().split", "Exception", "s.strip().split", "s.strip().split", "s.strip", "s.strip", "s.strip"], "function", ["None"], ["", "def", "prepare_new_dataset", "(", "lang", ",", "task", "=", "\"MT\"", ",", "dataset_source", "=", "None", ",", "dataset_target", "=", "None", ",", "dataset_subword_source", "=", "None", ",", "dataset_subword_target", "=", "None", ")", ":", "\n", "\t", "features", "=", "{", "}", "\n", "features", "[", "\"lang\"", "]", "=", "lang", "\n", "\n", "# Get dataset features", "\n", "if", "dataset_source", "is", "None", "and", "dataset_target", "is", "None", "and", "dataset_subword_source", "is", "None", "and", "dataset_subword_target", "is", "None", ":", "\n", "\t\t", "print", "(", "\"NOTE: no dataset provided. You can still use the ranker using language typological features.\"", ")", "\n", "return", "features", "\n", "", "elif", "dataset_source", "is", "None", ":", "# and dataset_target is None:", "\n", "\t\t", "print", "(", "\"NOTE: no word-level dataset provided, will only extract subword-level features.\"", ")", "\n", "", "elif", "dataset_subword_source", "is", "None", ":", "# and dataset_subword_target is None:", "\n", "\t\t", "print", "(", "\"NOTE: no subword-level dataset provided, will only extract word-level features.\"", ")", "\n", "\n", "\n", "", "source_lines", "=", "[", "]", "\n", "if", "isinstance", "(", "dataset_source", ",", "str", ")", ":", "\n", "\t\t", "with", "open", "(", "dataset_source", ")", "as", "inp", ":", "\n", "\t\t\t", "source_lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "", "elif", "isinstance", "(", "dataset_source", ",", "list", ")", ":", "\n", "\t\t", "source_lines", "=", "dataset_source", "\n", "", "else", ":", "\n", "\t\t", "raise", "Exception", "(", "\"dataset_source should either be a filnename (str) or a list of sentences.\"", ")", "\n", "", "'''\n\tif isinstance(dataset_target, str):\n\t\twith open(dataset_target) as inp:\n\t\t\ttarget_lines = inp.readlines()\n\telif isinstance(dataset_target, list):\n\t\tsource_lines = dataset_target\n\telse:\n\t\traise Exception(\"dataset_target should either be a filnename (str) or a list of sentences.\")\n\t'''", "\n", "if", "source_lines", ":", "\n", "\t\t", "if", "task", "!=", "\"EL\"", ":", "\n", "\t\t\t", "features", "[", "\"dataset_size\"", "]", "=", "len", "(", "source_lines", ")", "\n", "tokens", "=", "[", "w", "for", "s", "in", "source_lines", "for", "w", "in", "s", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "features", "[", "\"token_number\"", "]", "=", "len", "(", "tokens", ")", "\n", "types", "=", "set", "(", "tokens", ")", "\n", "features", "[", "\"type_number\"", "]", "=", "len", "(", "types", ")", "\n", "features", "[", "\"word_vocab\"", "]", "=", "types", "\n", "features", "[", "\"type_token_ratio\"", "]", "=", "features", "[", "\"type_number\"", "]", "/", "float", "(", "features", "[", "\"token_number\"", "]", ")", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t\t", "features", "[", "\"dataset_size\"", "]", "=", "len", "(", "source_lines", ")", "\n", "tokens", "=", "[", "w", "for", "s", "in", "source_lines", "for", "w", "in", "s", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "types", "=", "set", "(", "tokens", ")", "\n", "features", "[", "\"word_vocab\"", "]", "=", "types", "\n", "\n", "", "", "if", "task", "==", "\"MT\"", ":", "\n", "# Only use subword overlap features for the MT task", "\n", "\t\t", "if", "isinstance", "(", "dataset_subword_source", ",", "str", ")", ":", "\n", "\t\t\t", "with", "open", "(", "dataset_subword_source", ")", "as", "inp", ":", "\n", "\t\t\t\t", "source_lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "", "elif", "isinstance", "(", "dataset_subword_source", ",", "list", ")", ":", "\n", "\t\t\t", "source_lines", "=", "dataset_subword_source", "\n", "", "elif", "dataset_subword_source", "is", "None", ":", "\n", "\t\t\t", "pass", "\n", "# Use the word-level info, just in case. TODO(this is only for MT)", "\n", "# source_lines = []", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "\"dataset_subword_source should either be a filnename (str) or a list of sentences.\"", ")", "\n", "", "if", "source_lines", ":", "\n", "\t\t\t", "features", "[", "\"dataset_size\"", "]", "=", "len", "(", "source_lines", ")", "# This should be be the same as above", "\n", "tokens", "=", "[", "w", "for", "s", "in", "source_lines", "for", "w", "in", "s", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "features", "[", "\"subword_token_number\"", "]", "=", "len", "(", "tokens", ")", "\n", "types", "=", "set", "(", "tokens", ")", "\n", "features", "[", "\"subword_type_number\"", "]", "=", "len", "(", "types", ")", "\n", "features", "[", "\"subword_vocab\"", "]", "=", "types", "\n", "features", "[", "\"subword_type_token_ratio\"", "]", "=", "features", "[", "\"subword_type_number\"", "]", "/", "float", "(", "features", "[", "\"subword_token_number\"", "]", ")", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.uriel_distance_vec": [[198, 213], ["print", "lang2vec.geographic_distance", "print", "lang2vec.genetic_distance", "print", "lang2vec.inventory_distance", "print", "lang2vec.syntactic_distance", "print", "lang2vec.phonological_distance", "print", "lang2vec.featural_distance"], "function", ["None"], ["", "def", "uriel_distance_vec", "(", "languages", ")", ":", "\n", "\t", "print", "(", "'...geographic'", ")", "\n", "geographic", "=", "l2v", ".", "geographic_distance", "(", "languages", ")", "\n", "print", "(", "'...genetic'", ")", "\n", "genetic", "=", "l2v", ".", "genetic_distance", "(", "languages", ")", "\n", "print", "(", "'...inventory'", ")", "\n", "inventory", "=", "l2v", ".", "inventory_distance", "(", "languages", ")", "\n", "print", "(", "'...syntactic'", ")", "\n", "syntactic", "=", "l2v", ".", "syntactic_distance", "(", "languages", ")", "\n", "print", "(", "'...phonological'", ")", "\n", "phonological", "=", "l2v", ".", "phonological_distance", "(", "languages", ")", "\n", "print", "(", "'...featural'", ")", "\n", "featural", "=", "l2v", ".", "featural_distance", "(", "languages", ")", "\n", "uriel_features", "=", "[", "genetic", ",", "syntactic", ",", "featural", ",", "phonological", ",", "inventory", ",", "geographic", "]", "\n", "return", "uriel_features", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.distance_vec": [[216, 245], ["numpy.array", "float", "float", "float", "float", "len", "len", "len", "set().intersection", "set().intersection", "set().intersection", "set", "set", "set", "set", "set", "set"], "function", ["None"], ["", "def", "distance_vec", "(", "test", ",", "transfer", ",", "uriel_features", ",", "task", ")", ":", "\n", "\t", "output", "=", "[", "]", "\n", "# Dataset specific ", "\n", "# Dataset Size", "\n", "transfer_dataset_size", "=", "transfer", "[", "\"dataset_size\"", "]", "\n", "task_data_size", "=", "test", "[", "\"dataset_size\"", "]", "\n", "ratio_dataset_size", "=", "float", "(", "transfer_dataset_size", ")", "/", "task_data_size", "\n", "# TTR", "\n", "if", "task", "!=", "\"EL\"", ":", "\n", "\t\t", "transfer_ttr", "=", "transfer", "[", "\"type_token_ratio\"", "]", "\n", "task_ttr", "=", "test", "[", "\"type_token_ratio\"", "]", "\n", "distance_ttr", "=", "(", "1", "-", "transfer_ttr", "/", "task_ttr", ")", "**", "2", "\n", "# Word overlap", "\n", "", "if", "task", "!=", "\"EL\"", ":", "\n", "\t\t", "word_overlap", "=", "float", "(", "len", "(", "set", "(", "transfer", "[", "\"word_vocab\"", "]", ")", ".", "intersection", "(", "set", "(", "test", "[", "\"word_vocab\"", "]", ")", ")", ")", ")", "/", "(", "transfer", "[", "\"type_number\"", "]", "+", "test", "[", "\"type_number\"", "]", ")", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t", "word_overlap", "=", "float", "(", "len", "(", "set", "(", "transfer", "[", "\"word_vocab\"", "]", ")", ".", "intersection", "(", "set", "(", "test", "[", "\"word_vocab\"", "]", ")", ")", ")", ")", "\n", "# Subword overlap", "\n", "", "if", "task", "==", "\"MT\"", ":", "\n", "\t\t", "subword_overlap", "=", "float", "(", "len", "(", "set", "(", "transfer", "[", "\"subword_vocab\"", "]", ")", ".", "intersection", "(", "set", "(", "test", "[", "\"subword_vocab\"", "]", ")", ")", ")", ")", "/", "(", "transfer", "[", "\"subword_type_number\"", "]", "+", "test", "[", "\"subword_type_number\"", "]", ")", "\n", "\n", "", "if", "task", "==", "\"MT\"", ":", "\n", "\t\t", "data_specific_features", "=", "[", "word_overlap", ",", "subword_overlap", ",", "transfer_dataset_size", ",", "task_data_size", ",", "ratio_dataset_size", ",", "transfer_ttr", ",", "task_ttr", ",", "distance_ttr", "]", "\n", "", "elif", "task", "==", "\"POS\"", "or", "task", "==", "\"DEP\"", ":", "\n", "\t\t", "data_specific_features", "=", "[", "word_overlap", ",", "transfer_dataset_size", ",", "task_data_size", ",", "ratio_dataset_size", ",", "transfer_ttr", ",", "task_ttr", ",", "distance_ttr", "]", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t", "data_specific_features", "=", "[", "word_overlap", ",", "transfer_dataset_size", ",", "task_data_size", ",", "ratio_dataset_size", "]", "\n", "\n", "", "return", "np", ".", "array", "(", "data_specific_features", "+", "uriel_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.lgbm_rel_exp": [[246, 251], ["isinstance", "numpy.where"], "function", ["None"], ["", "def", "lgbm_rel_exp", "(", "BLEU_level", ",", "cutoff", ")", ":", "\n", "\t", "if", "isinstance", "(", "BLEU_level", ",", "np", ".", "ndarray", ")", ":", "\n", "\t\t", "return", "np", ".", "where", "(", "BLEU_level", ">=", "cutoff", ",", "BLEU_level", "-", "cutoff", "+", "1", ",", "0", ")", "\n", "", "else", ":", "\n", "\t\t", "return", "BLEU_level", "-", "cutoff", "+", "1", "if", "BLEU_level", ">=", "cutoff", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.prepare_train_file": [[254, 300], ["len", "langrank.lgbm_rel_exp", "enumerate", "langrank.uriel_distance_vec", "os.path.join", "open", "os.path.join", "open", "enumerate", "open.close", "open.close", "print", "print", "isinstance", "numpy.array", "len", "zip", "langrank.prepare_new_dataset", "os.path.exists", "os.mkdir", "enumerate", "open.write", "open", "ds_f.readlines", "open", "sds_f.readlines", "langrank.distance_vec", "open.write", "enumerate", "str"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.lgbm_rel_exp", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.uriel_distance_vec", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.prepare_new_dataset", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.distance_vec"], ["", "", "def", "prepare_train_file", "(", "datasets", ",", "langs", ",", "rank", ",", "segmented_datasets", "=", "None", ",", "task", "=", "\"MT\"", ",", "tmp_dir", "=", "\"tmp\"", ")", ":", "\n", "\t", "\"\"\"\n\tdataset: [ted_aze, ted_tur, ted_ben]\n\tlang: [aze, tur, ben]\n\trank: [[0, 1, 2], [1, 0, 2], [1, 2, 0]]\n\t\"\"\"", "\n", "num_langs", "=", "len", "(", "langs", ")", "\n", "REL_EXP_CUTOFF", "=", "num_langs", "-", "1", "-", "9", "\n", "\n", "if", "not", "isinstance", "(", "rank", ",", "np", ".", "ndarray", ")", ":", "\n", "\t\t", "rank", "=", "np", ".", "array", "(", "rank", ")", "\n", "", "BLEU_level", "=", "-", "rank", "+", "len", "(", "langs", ")", "\n", "rel_BLEU_level", "=", "lgbm_rel_exp", "(", "BLEU_level", ",", "REL_EXP_CUTOFF", ")", "\n", "\n", "features", "=", "{", "}", "\n", "for", "i", ",", "(", "ds", ",", "lang", ")", "in", "enumerate", "(", "zip", "(", "datasets", ",", "langs", ")", ")", ":", "\n", "\t\t", "with", "open", "(", "ds", ",", "\"r\"", ")", "as", "ds_f", ":", "\n", "\t\t\t", "lines", "=", "ds_f", ".", "readlines", "(", ")", "\n", "", "seg_lines", "=", "None", "\n", "if", "segmented_datasets", "is", "not", "None", ":", "\n", "\t\t\t", "sds", "=", "segmented_datasets", "[", "i", "]", "\n", "with", "open", "(", "sds", ",", "\"r\"", ")", "as", "sds_f", ":", "\n", "\t\t\t\t", "seg_lines", "=", "sds_f", ".", "readlines", "(", ")", "\n", "", "", "features", "[", "lang", "]", "=", "prepare_new_dataset", "(", "lang", "=", "lang", ",", "dataset_source", "=", "lines", ",", "dataset_subword_source", "=", "seg_lines", ")", "\n", "", "uriel", "=", "uriel_distance_vec", "(", "langs", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "tmp_dir", ")", ":", "\n", "\t\t", "os", ".", "mkdir", "(", "tmp_dir", ")", "\n", "\n", "", "train_file", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"train_mt.csv\"", ")", "\n", "train_file_f", "=", "open", "(", "train_file", ",", "\"w\"", ")", "\n", "train_size", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"train_mt_size.csv\"", ")", "\n", "train_size_f", "=", "open", "(", "train_size", ",", "\"w\"", ")", "\n", "for", "i", ",", "lang1", "in", "enumerate", "(", "langs", ")", ":", "\n", "\t\t", "for", "j", ",", "lang2", "in", "enumerate", "(", "langs", ")", ":", "\n", "\t\t\t", "if", "i", "!=", "j", ":", "\n", "\t\t\t\t", "uriel_features", "=", "[", "u", "[", "i", ",", "j", "]", "for", "u", "in", "uriel", "]", "\n", "distance_vector", "=", "distance_vec", "(", "features", "[", "lang1", "]", ",", "features", "[", "lang2", "]", ",", "uriel_features", ",", "task", ")", "\n", "distance_vector", "=", "[", "\"{}:{}\"", ".", "format", "(", "i", ",", "d", ")", "for", "i", ",", "d", "in", "enumerate", "(", "distance_vector", ")", "]", "\n", "line", "=", "\" \"", ".", "join", "(", "[", "str", "(", "rel_BLEU_level", "[", "i", ",", "j", "]", ")", "]", "+", "distance_vector", ")", "\n", "train_file_f", ".", "write", "(", "line", "+", "\"\\n\"", ")", "\n", "", "", "train_size_f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "num_langs", "-", "1", ")", ")", "\n", "", "train_file_f", ".", "close", "(", ")", "\n", "train_size_f", ".", "close", "(", ")", "\n", "print", "(", "\"Dump train file to {} ...\"", ".", "format", "(", "train_file_f", ")", ")", "\n", "print", "(", "\"Dump train size file to {} ...\"", ".", "format", "(", "train_size_f", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.train": [[301, 310], ["os.path.join", "os.path.join", "sklearn.datasets.load_svmlight_file", "lightgbm.LGBMRanker", "lgb.LGBMRanker.fit", "lgb.LGBMRanker.booster_.save_model", "numpy.loadtxt"], "function", ["None"], ["", "def", "train", "(", "tmp_dir", ",", "output_model", ")", ":", "\n", "\t", "train_file", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"train_mt.csv\"", ")", "\n", "train_size", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"train_mt_size.csv\"", ")", "\n", "X_train", ",", "y_train", "=", "load_svmlight_file", "(", "train_file", ")", "\n", "model", "=", "lgb", ".", "LGBMRanker", "(", "boosting_type", "=", "'gbdt'", ",", "num_leaves", "=", "16", ",", "\n", "max_depth", "=", "-", "1", ",", "learning_rate", "=", "0.1", ",", "n_estimators", "=", "100", ",", "\n", "min_child_samples", "=", "5", ")", "\n", "model", ".", "fit", "(", "X_train", ",", "y_train", ",", "group", "=", "np", ".", "loadtxt", "(", "train_size", ")", ")", "\n", "model", ".", "booster_", ".", "save_model", "(", "output_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.rank": [[311, 400], ["langrank.check_task_model", "print", "print", "langrank.uriel_distance_vec", "print", "enumerate", "print", "langrank.map_task_to_models", "pkg_resources.resource_filename", "lightgbm.Booster", "print", "lgb.Booster.predict", "bst.predict.sum", "print", "min", "numpy.array", "range", "list", "print", "enumerate", "langrank.get_candidates", "langrank.get_candidates", "langrank.distance_vec", "np.array.append", "os.path.join", "len", "len", "numpy.argsort", "print", "print", "print", "numpy.argsort", "range", "list", "print", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.check_task_model", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.uriel_distance_vec", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.map_task_to_models", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.get_candidates", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.get_candidates", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.distance_vec"], ["", "def", "rank", "(", "test_dataset_features", ",", "task", "=", "\"MT\"", ",", "candidates", "=", "\"all\"", ",", "model", "=", "\"best\"", ",", "print_topK", "=", "3", ")", ":", "\n", "\t", "'''\n\ttest_dataset_features : the output of prepare_new_dataset(). Basically a dictionary with the necessary dataset features.\n\t'''", "\n", "# Checks", "\n", "check_task_model", "(", "task", ",", "model", ")", "\n", "\n", "# Get candidates to be compared against", "\n", "print", "(", "\"Preparing candidate list...\"", ")", "\n", "if", "candidates", "==", "'all'", ":", "\n", "\t\t", "candidate_list", "=", "get_candidates", "(", "task", ")", "\n", "", "else", ":", "\n", "# Restricts to a specific set of languages", "\n", "\t\t", "candidate_list", "=", "get_candidates", "(", "task", ",", "candidates", ")", "\n", "\n", "", "print", "(", "\"Collecting URIEL distance vectors...\"", ")", "\n", "\n", "languages", "=", "[", "test_dataset_features", "[", "\"lang\"", "]", "]", "+", "[", "c", "[", "1", "]", "[", "\"lang\"", "]", "for", "c", "in", "candidate_list", "]", "\n", "# TODO: This takes forever...", "\n", "uriel", "=", "uriel_distance_vec", "(", "languages", ")", "\n", "\n", "\n", "print", "(", "\"Collecting dataset distance vectors...\"", ")", "\n", "test_inputs", "=", "[", "]", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "candidate_list", ")", ":", "\n", "\t\t", "key", "=", "c", "[", "0", "]", "\n", "cand_dict", "=", "c", "[", "1", "]", "\n", "candidate_language", "=", "key", "[", "-", "3", ":", "]", "\n", "uriel_j", "=", "[", "u", "[", "0", ",", "i", "+", "1", "]", "for", "u", "in", "uriel", "]", "\n", "distance_vector", "=", "distance_vec", "(", "test_dataset_features", ",", "cand_dict", ",", "uriel_j", ",", "task", ")", "\n", "test_inputs", ".", "append", "(", "distance_vector", ")", "\n", "\n", "# load model", "\n", "", "print", "(", "\"Loading model...\"", ")", "\n", "model_dict", "=", "map_task_to_models", "(", "task", ")", "# this loads the dict that will give us the name of the pretrained model", "\n", "model_fname", "=", "model_dict", "[", "model", "]", "# this gives us the filename (needs to be joined, see below)", "\n", "modelfilename", "=", "pkg_resources", ".", "resource_filename", "(", "__name__", ",", "os", ".", "path", ".", "join", "(", "'pretrained'", ",", "task", ",", "model_fname", ")", ")", "\n", "\n", "# rank", "\n", "bst", "=", "lgb", ".", "Booster", "(", "model_file", "=", "modelfilename", ")", "\n", "\n", "print", "(", "\"predicting...\"", ")", "\n", "predict_contribs", "=", "bst", ".", "predict", "(", "test_inputs", ",", "pred_contrib", "=", "True", ")", "\n", "predict_scores", "=", "predict_contribs", ".", "sum", "(", "-", "1", ")", "\n", "\n", "\n", "print", "(", "\"Ranking with single features:\"", ")", "\n", "TOP_K", "=", "min", "(", "3", ",", "len", "(", "candidate_list", ")", ")", "\n", "\n", "# 0 means we ignore this feature (don't compute single-feature result of it)", "\n", "if", "task", "==", "\"MT\"", ":", "\n", "\t\t", "sort_sign_list", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "0", ",", "-", "1", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "feature_name", "=", "[", "\"Overlap word-level\"", ",", "\"Overlap subword-level\"", ",", "\"Transfer lang dataset size\"", ",", "\n", "\"Target lang dataset size\"", ",", "\"Transfer over target size ratio\"", ",", "\"Transfer lang TTR\"", ",", "\n", "\"Target lang TTR\"", ",", "\"Transfer target TTR distance\"", ",", "\"GENETIC\"", ",", "\n", "\"SYNTACTIC\"", ",", "\"FEATURAL\"", ",", "\"PHONOLOGICAL\"", ",", "\"INVENTORY\"", ",", "\"GEOGRAPHIC\"", "]", "\n", "", "elif", "task", "==", "\"POS\"", "or", "task", "==", "\"DEP\"", ":", "\n", "\t\t", "sort_sign_list", "=", "[", "-", "1", ",", "0", ",", "-", "1", ",", "0", ",", "-", "1", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "feature_name", "=", "[", "\"Overlap word-level\"", ",", "\"Transfer lang dataset size\"", ",", "\"Target lang dataset size\"", ",", "\n", "\"Transfer over target size ratio\"", ",", "\"Transfer lang TTR\"", ",", "\"Target lang TTR\"", ",", "\n", "\"Transfer target TTR distance\"", ",", "\"GENETIC\"", ",", "\"SYNTACTIC\"", ",", "\"FEATURAL\"", ",", "\n", "\"PHONOLOGICAL\"", ",", "\"INVENTORY\"", ",", "\"GEOGRAPHIC\"", "]", "\n", "", "elif", "task", "==", "\"EL\"", ":", "\n", "\t\t", "sort_sign_list", "=", "[", "-", "1", ",", "-", "1", ",", "0", ",", "-", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "feature_name", "=", "[", "\"Entity overlap\"", ",", "\"Transfer lang dataset size\"", ",", "\"Target lang dataset size\"", ",", "\n", "\"Transfer over target size ratio\"", ",", "\"GENETIC\"", ",", "\"SYNTACTIC\"", ",", "\"FEATURAL\"", ",", "\"PHONOLOGICAL\"", ",", "\n", "\"INVENTORY\"", ",", "\"GEOGRAPHIC\"", "]", "\n", "\n", "", "test_inputs", "=", "np", ".", "array", "(", "test_inputs", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "feature_name", ")", ")", ":", "\n", "\t\t", "if", "sort_sign_list", "[", "j", "]", "!=", "0", ":", "\n", "\t\t\t", "print", "(", "feature_name", "[", "j", "]", ")", "\n", "values", "=", "test_inputs", "[", ":", ",", "j", "]", "*", "sort_sign_list", "[", "j", "]", "\n", "best_feat_index", "=", "np", ".", "argsort", "(", "values", ")", "\n", "for", "i", "in", "range", "(", "TOP_K", ")", ":", "\n", "\t\t\t\t", "index", "=", "best_feat_index", "[", "i", "]", "\n", "print", "(", "\"%d. %s : score=%.2f\"", "%", "(", "i", ",", "candidate_list", "[", "index", "]", "[", "0", "]", ",", "test_inputs", "[", "index", "]", "[", "j", "]", ")", ")", "\n", "\n", "", "", "", "ind", "=", "list", "(", "np", ".", "argsort", "(", "-", "predict_scores", ")", ")", "\n", "print", "(", "\"Ranking (top {}):\"", ".", "format", "(", "print_topK", ")", ")", "\n", "for", "j", ",", "i", "in", "enumerate", "(", "ind", "[", ":", "print_topK", "]", ")", ":", "\n", "\t\t", "print", "(", "\"%d. %s : score=%.2f\"", "%", "(", "j", "+", "1", ",", "candidate_list", "[", "i", "]", "[", "0", "]", ",", "predict_scores", "[", "i", "]", ")", ")", "\n", "contrib_scores", "=", "predict_contribs", "[", "i", "]", "[", ":", "-", "1", "]", "\n", "contrib_ind", "=", "list", "(", "np", ".", "argsort", "(", "contrib_scores", ")", ")", "[", ":", ":", "-", "1", "]", "\n", "print", "(", "\"\\t1. %s : score=%.2f; \\n\\t2. %s : score=%.2f; \\n\\t3. %s : score=%.2f\"", "%", "\n", "(", "feature_name", "[", "contrib_ind", "[", "0", "]", "]", ",", "contrib_scores", "[", "contrib_ind", "[", "0", "]", "]", ",", "\n", "feature_name", "[", "contrib_ind", "[", "1", "]", "]", ",", "contrib_scores", "[", "contrib_ind", "[", "1", "]", "]", ",", "\n", "feature_name", "[", "contrib_ind", "[", "2", "]", "]", ",", "contrib_scores", "[", "contrib_ind", "[", "2", "]", "]", ")", ")", "\n", "", "return", "ind", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_ted_datasets.read_data": [[6, 17], ["open", "inp.readlines", "l.strip().split.strip().split", "len", "c.append", "v.append", "l.strip().split.strip", "int"], "function", ["None"], ["def", "read_data", "(", "fn", ")", ":", "\n", "\t", "with", "open", "(", "fn", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "c", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "\t\t\t", "c", ".", "append", "(", "int", "(", "l", "[", "1", "]", ")", ")", "\n", "v", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "", "", "return", "v", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_pos_datasets.read_data": [[7, 18], ["open", "inp.readlines", "l.strip().split.strip().split", "len", "c.append", "v.append", "l.strip().split.strip", "int"], "function", ["None"], ["def", "read_data", "(", "fn", ")", ":", "\n", "\t", "with", "open", "(", "fn", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "c", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "\t\t\t", "c", ".", "append", "(", "int", "(", "l", "[", "1", "]", ")", ")", "\n", "v", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "", "", "return", "v", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_pos_datasets.get_vocab": [[31, 36], ["open", "inp.readlines", "l.strip().split", "l.strip"], "function", ["None"], ["def", "get_vocab", "(", "filename", ")", ":", "\n", "\t", "with", "open", "(", "filename", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "all_words", "=", "[", "w", "for", "l", "in", "lines", "for", "w", "in", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "return", "all_words", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_el_datasets.read_data": [[7, 18], ["open", "inp.readlines", "l.strip().split.strip().split", "len", "c.append", "v.append", "l.strip().split.strip", "int"], "function", ["None"], ["def", "read_data", "(", "fn", ")", ":", "\n", "\t", "with", "open", "(", "fn", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "c", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "\t\t\t", "c", ".", "append", "(", "int", "(", "l", "[", "1", "]", ")", ")", "\n", "v", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "", "", "return", "v", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_el_datasets.get_vocab": [[31, 40], ["open", "inp.readlines", "l.strip().split.strip().split", "all_words.append", "l.strip().split.strip"], "function", ["None"], ["def", "get_vocab", "(", "filename", ")", ":", "\n", "\t", "with", "open", "(", "filename", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "all_words", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", "\" ||| \"", ")", "\n", "all_words", ".", "append", "(", "l", "[", "2", "]", ")", "\n", "#all_words = [w for l in lines for w in l.strip().split()]", "\n", "", "return", "all_words", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_parsing_datasets.read_data": [[7, 18], ["open", "inp.readlines", "l.strip().split.strip().split", "len", "c.append", "v.append", "l.strip().split.strip", "int"], "function", ["None"], ["def", "read_data", "(", "fn", ")", ":", "\n", "\t", "with", "open", "(", "fn", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "c", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t", "l", "=", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "len", "(", "l", ")", "==", "2", ":", "\n", "\t\t\t", "c", ".", "append", "(", "int", "(", "l", "[", "1", "]", ")", ")", "\n", "v", ".", "append", "(", "l", "[", "0", "]", ")", "\n", "", "", "return", "v", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.None.index_parsing_datasets.get_vocab": [[31, 36], ["open", "inp.readlines", "l.strip().split", "l.strip"], "function", ["None"], ["def", "get_vocab", "(", "filename", ")", ":", "\n", "\t", "with", "open", "(", "filename", ")", "as", "inp", ":", "\n", "\t\t", "lines", "=", "inp", ".", "readlines", "(", ")", "\n", "", "all_words", "=", "[", "w", "for", "l", "in", "lines", "for", "w", "in", "l", ".", "strip", "(", ")", ".", "split", "(", ")", "]", "\n", "return", "all_words", "\n", "\n"]], "home.repos.pwc.inspect_result.neulab_langrank.tests.test_train_file.test_train": [[8, 19], ["langrank.prepare_train_file", "langrank.train", "os.path.isfile", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.neulab_langrank.None.langrank.prepare_train_file", "home.repos.pwc.inspect_result.neulab_langrank.None.langrank.train"], ["def", "test_train", "(", ")", ":", "\n", "    ", "langs", "=", "[", "\"aze\"", ",", "\"ben\"", ",", "\"fin\"", "]", "\n", "datasets", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "\"sample-data\"", ",", "\"ted-train.orig.{}\"", ".", "format", "(", "l", ")", ")", "for", "l", "in", "langs", "]", "\n", "seg_datasets", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "\"sample-data\"", ",", "\"ted-train.orig.spm8000.{}\"", ".", "format", "(", "l", ")", ")", "for", "l", "in", "langs", "]", "\n", "rank", "=", "[", "[", "0", ",", "1", ",", "2", "]", ",", "[", "1", ",", "0", ",", "2", "]", ",", "[", "2", ",", "1", ",", "0", "]", "]", "# random", "\n", "tmp_dir", "=", "\"tmp\"", "\n", "prepare_train_file", "(", "datasets", "=", "datasets", ",", "segmented_datasets", "=", "seg_datasets", ",", "\n", "langs", "=", "langs", ",", "rank", "=", "rank", ",", "tmp_dir", "=", "tmp_dir", ",", "task", "=", "\"MT\"", ")", "\n", "output_model", "=", "\"{}/model.txt\"", ".", "format", "(", "tmp_dir", ")", "\n", "train", "(", "tmp_dir", "=", "tmp_dir", ",", "output_model", "=", "output_model", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "output_model", ")", "\n", "", ""]]}