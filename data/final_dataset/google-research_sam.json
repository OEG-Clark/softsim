{"home.repos.pwc.inspect_result.google-research_sam.autoaugment.policies.policy_imagenet": [[20, 57], ["None"], "function", ["None"], ["def", "policy_imagenet", "(", ")", "->", "List", "[", "List", "[", "Tuple", "[", "str", ",", "float", ",", "int", "]", "]", "]", ":", "\n", "  ", "\"\"\"Returns the autoaugment policy that was used in AutoAugment Paper.\n\n  A policy is composed of two augmentations applied sequentially to the image.\n  Each augmentation is described as a tuple where the first element is the\n  type of transformation to apply, the second is the probability with which the\n  augmentation should be applied, and the third element is the strength of the\n  transformation.\n  \"\"\"", "\n", "policy", "=", "[", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "1", ")", ",", "(", "'ShearY'", ",", "0.8", ",", "4", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.4", ",", "9", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "3", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.4", ",", "1", ")", ",", "(", "'Rotate'", ",", "0.6", ",", "8", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.8", ",", "3", ")", ",", "(", "'Equalize'", ",", "0.4", ",", "7", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "2", ")", ",", "(", "'Solarize'", ",", "0.6", ",", "2", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.2", ",", "0", ")", ",", "(", "'Equalize'", ",", "0.8", ",", "8", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.4", ",", "8", ")", ",", "(", "'SolarizeAdd'", ",", "0.8", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.2", ",", "9", ")", ",", "(", "'Rotate'", ",", "0.6", ",", "8", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.6", ",", "1", ")", ",", "(", "'Equalize'", ",", "1.0", ",", "2", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.4", ",", "9", ")", ",", "(", "'Rotate'", ",", "0.6", ",", "0", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "1.0", ",", "9", ")", ",", "(", "'ShearY'", ",", "0.6", ",", "3", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.4", ",", "7", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "0", ")", "]", ",", "\n", "[", "(", "'Posterize'", ",", "0.4", ",", "6", ")", ",", "(", "'AutoContrast'", ",", "0.4", ",", "7", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.6", ",", "8", ")", ",", "(", "'Color'", ",", "0.6", ",", "9", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "4", ")", ",", "(", "'Rotate'", ",", "0.8", ",", "9", ")", "]", ",", "\n", "[", "(", "'Rotate'", ",", "1.0", ",", "7", ")", ",", "(", "'TranslateY'", ",", "0.8", ",", "9", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.0", ",", "0", ")", ",", "(", "'Solarize'", ",", "0.8", ",", "4", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.8", ",", "0", ")", ",", "(", "'Color'", ",", "0.6", ",", "4", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "1.0", ",", "0", ")", ",", "(", "'Rotate'", ",", "0.6", ",", "2", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.0", ",", "8", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "1.0", ",", "4", ")", ",", "(", "'AutoContrast'", ",", "0.6", ",", "2", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.4", ",", "7", ")", ",", "(", "'SolarizeAdd'", ",", "0.6", ",", "7", ")", "]", ",", "\n", "[", "(", "'Posterize'", ",", "0.8", ",", "2", ")", ",", "(", "'Solarize'", ",", "0.6", ",", "10", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.6", ",", "8", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "1", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.8", ",", "6", ")", ",", "(", "'Rotate'", ",", "0.4", ",", "5", ")", "]", ",", "\n", "]", "\n", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.policies.policy_cifar": [[59, 186], ["None"], "function", ["None"], ["", "def", "policy_cifar", "(", ")", "->", "List", "[", "List", "[", "Tuple", "[", "str", ",", "float", ",", "int", "]", "]", "]", ":", "\n", "  ", "\"\"\"Returns the AutoAugment policies found on Cifar.\n\n  A policy is composed of two augmentations applied sequentially to the image.\n  Each augmentation is described as a tuple where the first element is the\n  type of transformation to apply, the second is the probability with which the\n  augmentation should be applied, and the third element is the strength of the\n  transformation.\n  \"\"\"", "\n", "exp0_0", "=", "[", "\n", "[", "(", "'Invert'", ",", "0.1", ",", "7", ")", ",", "(", "'Contrast'", ",", "0.2", ",", "6", ")", "]", ",", "\n", "[", "(", "'Rotate'", ",", "0.7", ",", "2", ")", ",", "(", "'TranslateX'", ",", "0.3", ",", "9", ")", "]", ",", "\n", "[", "(", "'Sharpness'", ",", "0.8", ",", "1", ")", ",", "(", "'Sharpness'", ",", "0.9", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.5", ",", "8", ")", ",", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.5", ",", "8", ")", ",", "(", "'Equalize'", ",", "0.9", ",", "2", ")", "]", "]", "\n", "exp0_1", "=", "[", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "3", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.9", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.9", ",", "2", ")", ",", "(", "'Solarize'", ",", "0.8", ",", "3", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "8", ")", ",", "(", "'Invert'", ",", "0.1", ",", "3", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "1", ")", "]", "]", "\n", "exp0_2", "=", "[", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.0", ",", "2", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.9", ",", "0", ")", ",", "(", "'Solarize'", ",", "0.4", ",", "3", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.7", ",", "5", ")", ",", "(", "'Invert'", ",", "0.1", ",", "3", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", "]", "]", "\n", "exp0_3", "=", "[", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "1", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.8", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.9", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.8", ",", "0", ")", ",", "(", "'TranslateY'", ",", "0.7", ",", "9", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.2", ",", "7", ")", ",", "(", "'Color'", ",", "0.9", ",", "6", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.7", ",", "6", ")", ",", "(", "'Color'", ",", "0.4", ",", "9", ")", "]", "]", "\n", "exp1_0", "=", "[", "\n", "[", "(", "'ShearY'", ",", "0.2", ",", "7", ")", ",", "(", "'Posterize'", ",", "0.3", ",", "7", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.4", ",", "3", ")", ",", "(", "'Brightness'", ",", "0.6", ",", "7", ")", "]", ",", "\n", "[", "(", "'Sharpness'", ",", "0.3", ",", "9", ")", ",", "(", "'Brightness'", ",", "0.7", ",", "9", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "5", ")", ",", "(", "'Equalize'", ",", "0.5", ",", "1", ")", "]", ",", "\n", "[", "(", "'Contrast'", ",", "0.6", ",", "7", ")", ",", "(", "'Sharpness'", ",", "0.6", ",", "5", ")", "]", "]", "\n", "exp1_1", "=", "[", "\n", "[", "(", "'Brightness'", ",", "0.3", ",", "7", ")", ",", "(", "'AutoContrast'", ",", "0.5", ",", "8", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.9", ",", "4", ")", ",", "(", "'AutoContrast'", ",", "0.5", ",", "6", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.3", ",", "5", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "5", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.2", ",", "4", ")", ",", "(", "'Sharpness'", ",", "0.3", ",", "3", ")", "]", ",", "\n", "[", "(", "'Brightness'", ",", "0.0", ",", "8", ")", ",", "(", "'Color'", ",", "0.8", ",", "8", ")", "]", "]", "\n", "exp1_2", "=", "[", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "6", ")", ",", "(", "'Color'", ",", "0.8", ",", "6", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "6", ")", ",", "(", "'AutoContrast'", ",", "0.8", ",", "1", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "1", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "5", ")", "]", ",", "\n", "[", "(", "'Brightness'", ",", "0.0", ",", "0", ")", ",", "(", "'Solarize'", ",", "0.5", ",", "2", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.9", ",", "5", ")", ",", "(", "'Brightness'", ",", "0.5", ",", "3", ")", "]", "]", "\n", "exp1_3", "=", "[", "\n", "[", "(", "'Contrast'", ",", "0.7", ",", "5", ")", ",", "(", "'Brightness'", ",", "0.0", ",", "2", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "8", ")", ",", "(", "'Solarize'", ",", "0.1", ",", "5", ")", "]", ",", "\n", "[", "(", "'Contrast'", ",", "0.5", ",", "1", ")", ",", "(", "'TranslateY'", ",", "0.2", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.6", ",", "5", ")", ",", "(", "'TranslateY'", ",", "0.0", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.9", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.8", ",", "4", ")", "]", "]", "\n", "exp1_4", "=", "[", "\n", "[", "(", "'Brightness'", ",", "0.0", ",", "7", ")", ",", "(", "'Equalize'", ",", "0.4", ",", "7", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "5", ")", ",", "(", "'Equalize'", ",", "0.7", ",", "5", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "8", ")", ",", "(", "'Color'", ",", "0.6", ",", "2", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.3", ",", "7", ")", ",", "(", "'Color'", ",", "0.2", ",", "4", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.5", ",", "2", ")", ",", "(", "'Solarize'", ",", "0.7", ",", "2", ")", "]", "]", "\n", "exp1_5", "=", "[", "\n", "[", "(", "'AutoContrast'", ",", "0.2", ",", "0", ")", ",", "(", "'Equalize'", ",", "0.1", ",", "0", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.6", ",", "5", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "5", ")", "]", ",", "\n", "[", "(", "'Brightness'", ",", "0.9", ",", "3", ")", ",", "(", "'AutoContrast'", ",", "0.4", ",", "1", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "8", ")", ",", "(", "'Equalize'", ",", "0.7", ",", "7", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.7", ",", "7", ")", ",", "(", "'Solarize'", ",", "0.5", ",", "0", ")", "]", "]", "\n", "exp1_6", "=", "[", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "4", ")", ",", "(", "'TranslateY'", ",", "0.8", ",", "9", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.8", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.6", ",", "9", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.9", ",", "0", ")", ",", "(", "'TranslateY'", ",", "0.5", ",", "9", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.5", ",", "3", ")", ",", "(", "'Solarize'", ",", "0.3", ",", "4", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.5", ",", "3", ")", ",", "(", "'Equalize'", ",", "0.4", ",", "4", ")", "]", "]", "\n", "exp2_0", "=", "[", "\n", "[", "(", "'Color'", ",", "0.7", ",", "7", ")", ",", "(", "'TranslateX'", ",", "0.5", ",", "8", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.3", ",", "7", ")", ",", "(", "'AutoContrast'", ",", "0.4", ",", "8", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.4", ",", "3", ")", ",", "(", "'Sharpness'", ",", "0.2", ",", "6", ")", "]", ",", "\n", "[", "(", "'Brightness'", ",", "0.9", ",", "6", ")", ",", "(", "'Color'", ",", "0.2", ",", "8", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.5", ",", "2", ")", ",", "(", "'Invert'", ",", "0.0", ",", "3", ")", "]", "]", "\n", "exp2_1", "=", "[", "\n", "[", "(", "'AutoContrast'", ",", "0.1", ",", "5", ")", ",", "(", "'Brightness'", ",", "0.0", ",", "0", ")", "]", ",", "\n", "[", "(", "'Cutout'", ",", "0.2", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.1", ",", "1", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.7", ",", "7", ")", ",", "(", "'AutoContrast'", ",", "0.6", ",", "4", ")", "]", ",", "\n", "[", "(", "'Color'", ",", "0.1", ",", "8", ")", ",", "(", "'ShearY'", ",", "0.2", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.4", ",", "2", ")", ",", "(", "'Rotate'", ",", "0.7", ",", "0", ")", "]", "]", "\n", "exp2_2", "=", "[", "\n", "[", "(", "'ShearY'", ",", "0.1", ",", "3", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "5", ")", "]", ",", "\n", "[", "(", "'TranslateY'", ",", "0.3", ",", "6", ")", ",", "(", "'Cutout'", ",", "0.3", ",", "3", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.5", ",", "0", ")", ",", "(", "'Solarize'", ",", "0.6", ",", "6", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.3", ",", "5", ")", ",", "(", "'Rotate'", ",", "0.2", ",", "7", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "2", ")", ",", "(", "'Invert'", ",", "0.4", ",", "0", ")", "]", "]", "\n", "exp2_3", "=", "[", "\n", "[", "(", "'Equalize'", ",", "0.9", ",", "5", ")", ",", "(", "'Color'", ",", "0.7", ",", "0", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.1", ",", "1", ")", ",", "(", "'ShearY'", ",", "0.1", ",", "3", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.7", ",", "3", ")", ",", "(", "'Equalize'", ",", "0.7", ",", "0", ")", "]", ",", "\n", "[", "(", "'Brightness'", ",", "0.5", ",", "1", ")", ",", "(", "'Contrast'", ",", "0.1", ",", "7", ")", "]", ",", "\n", "[", "(", "'Contrast'", ",", "0.1", ",", "4", ")", ",", "(", "'Solarize'", ",", "0.6", ",", "5", ")", "]", "]", "\n", "exp2_4", "=", "[", "\n", "[", "(", "'Solarize'", ",", "0.2", ",", "3", ")", ",", "(", "'ShearX'", ",", "0.0", ",", "0", ")", "]", ",", "\n", "[", "(", "'TranslateX'", ",", "0.3", ",", "0", ")", ",", "(", "'TranslateX'", ",", "0.6", ",", "0", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.5", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.6", ",", "7", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.1", ",", "0", ")", ",", "(", "'Sharpness'", ",", "0.5", ",", "1", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "6", ")", ",", "(", "'Invert'", ",", "0.3", ",", "6", ")", "]", "]", "\n", "exp2_5", "=", "[", "\n", "[", "(", "'AutoContrast'", ",", "0.3", ",", "9", ")", ",", "(", "'Cutout'", ",", "0.5", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.4", ",", "4", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "2", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.0", ",", "3", ")", ",", "(", "'Posterize'", ",", "0.0", ",", "3", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.4", ",", "3", ")", ",", "(", "'Color'", ",", "0.2", ",", "4", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.1", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.7", ",", "6", ")", "]", "]", "\n", "exp2_6", "=", "[", "\n", "[", "(", "'Equalize'", ",", "0.3", ",", "8", ")", ",", "(", "'AutoContrast'", ",", "0.4", ",", "3", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.6", ",", "4", ")", ",", "(", "'AutoContrast'", ",", "0.7", ",", "6", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.2", ",", "9", ")", ",", "(", "'Brightness'", ",", "0.4", ",", "8", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.1", ",", "0", ")", ",", "(", "'Equalize'", ",", "0.0", ",", "6", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.8", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.0", ",", "4", ")", "]", "]", "\n", "exp2_7", "=", "[", "\n", "[", "(", "'Equalize'", ",", "0.5", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.1", ",", "2", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.5", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.9", ",", "5", ")", "]", ",", "\n", "[", "(", "'AutoContrast'", ",", "0.6", ",", "1", ")", ",", "(", "'AutoContrast'", ",", "0.7", ",", "8", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.2", ",", "0", ")", ",", "(", "'AutoContrast'", ",", "0.1", ",", "2", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "9", ")", ",", "(", "'Equalize'", ",", "0.4", ",", "4", ")", "]", "]", "\n", "exp0s", "=", "exp0_0", "+", "exp0_1", "+", "exp0_2", "+", "exp0_3", "\n", "exp1s", "=", "exp1_0", "+", "exp1_1", "+", "exp1_2", "+", "exp1_3", "+", "exp1_4", "+", "exp1_5", "+", "exp1_6", "\n", "exp2s", "=", "exp2_0", "+", "exp2_1", "+", "exp2_2", "+", "exp2_3", "+", "exp2_4", "+", "exp2_5", "+", "exp2_6", "+", "exp2_7", "\n", "return", "exp0s", "+", "exp1s", "+", "exp2s", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.policies.policy_svhn": [[188, 222], ["None"], "function", ["None"], ["", "def", "policy_svhn", "(", ")", "->", "List", "[", "List", "[", "Tuple", "[", "str", ",", "float", ",", "int", "]", "]", "]", ":", "\n", "  ", "\"\"\"Returns the AutoAugment policies found on SVHN.\n\n  A policy is composed of two augmentations applied sequentially to the image.\n  Each augmentation is described as a tuple where the first element is the\n  type of transformation to apply, the second is the probability with which the\n  augmentation should be applied, and the third element is the strength of the\n  transformation.\n  \"\"\"", "\n", "return", "[", "[", "(", "'ShearX'", ",", "0.9", ",", "4", ")", ",", "(", "'Invert'", ",", "0.2", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.9", ",", "8", ")", ",", "(", "'Invert'", ",", "0.7", ",", "5", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "5", ")", ",", "(", "'Solarize'", ",", "0.6", ",", "6", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.9", ",", "3", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "3", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "1", ")", ",", "(", "'Rotate'", ",", "0.9", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.9", ",", "4", ")", ",", "(", "'AutoContrast'", ",", "0.8", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.9", ",", "8", ")", ",", "(", "'Invert'", ",", "0.4", ",", "5", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.9", ",", "5", ")", ",", "(", "'Solarize'", ",", "0.2", ",", "6", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.9", ",", "6", ")", ",", "(", "'AutoContrast'", ",", "0.8", ",", "1", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.6", ",", "3", ")", ",", "(", "'Rotate'", ",", "0.9", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.9", ",", "4", ")", ",", "(", "'Solarize'", ",", "0.3", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.8", ",", "8", ")", ",", "(", "'Invert'", ",", "0.7", ",", "4", ")", "]", ",", "\n", "[", "(", "'Equalize'", ",", "0.9", ",", "5", ")", ",", "(", "'TranslateY'", ",", "0.6", ",", "6", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.9", ",", "4", ")", ",", "(", "'Equalize'", ",", "0.6", ",", "7", ")", "]", ",", "\n", "[", "(", "'Contrast'", ",", "0.3", ",", "3", ")", ",", "(", "'Rotate'", ",", "0.8", ",", "4", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.8", ",", "5", ")", ",", "(", "'TranslateY'", ",", "0.0", ",", "2", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.7", ",", "6", ")", ",", "(", "'Solarize'", ",", "0.4", ",", "8", ")", "]", ",", "\n", "[", "(", "'Invert'", ",", "0.6", ",", "4", ")", ",", "(", "'Rotate'", ",", "0.8", ",", "4", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.3", ",", "7", ")", ",", "(", "'TranslateX'", ",", "0.9", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.1", ",", "6", ")", ",", "(", "'Invert'", ",", "0.6", ",", "5", ")", "]", ",", "\n", "[", "(", "'Solarize'", ",", "0.7", ",", "2", ")", ",", "(", "'TranslateY'", ",", "0.6", ",", "7", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.8", ",", "4", ")", ",", "(", "'Invert'", ",", "0.8", ",", "8", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.7", ",", "9", ")", ",", "(", "'TranslateY'", ",", "0.8", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearY'", ",", "0.8", ",", "5", ")", ",", "(", "'AutoContrast'", ",", "0.7", ",", "3", ")", "]", ",", "\n", "[", "(", "'ShearX'", ",", "0.7", ",", "2", ")", ",", "(", "'Invert'", ",", "0.1", ",", "5", ")", "]", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.blend": [[45, 86], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.cast", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.to_float", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["", "def", "blend", "(", "image1", ",", "image2", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Blend image1 and image2 using 'factor'.\n\n  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n  A value of 1.0 means only image2 is used.  A value between 0.0 and\n  1.0 means we linearly interpolate the pixel values between the two\n  images.  A value greater than 1.0 \"extrapolates\" the difference\n  between the two pixel values, and we clip the results to values\n  between 0 and 255.\n\n  Args:\n    image1: An image Tensor of type uint8.\n    image2: An image Tensor of type uint8.\n    factor: A floating point value above 0.0.\n\n  Returns:\n    A blended image Tensor of type uint8.\n  \"\"\"", "\n", "if", "factor", "==", "0.0", ":", "\n", "    ", "return", "tf", ".", "convert_to_tensor", "(", "image1", ")", "\n", "", "if", "factor", "==", "1.0", ":", "\n", "    ", "return", "tf", ".", "convert_to_tensor", "(", "image2", ")", "\n", "\n", "", "image1", "=", "tf", ".", "to_float", "(", "image1", ")", "\n", "image2", "=", "tf", ".", "to_float", "(", "image2", ")", "\n", "\n", "difference", "=", "image2", "-", "image1", "\n", "scaled", "=", "factor", "*", "difference", "\n", "\n", "# Do addition in float.", "\n", "temp", "=", "tf", ".", "to_float", "(", "image1", ")", "+", "scaled", "\n", "\n", "# Interpolate", "\n", "if", "factor", ">", "0.0", "and", "factor", "<", "1.0", ":", "\n", "# Interpolation means we always stay within 0 and 255.", "\n", "    ", "return", "tf", ".", "cast", "(", "temp", ",", "tf", ".", "uint8", ")", "\n", "\n", "# Extrapolate:", "\n", "#", "\n", "# We need to clip and then cast.", "\n", "", "return", "tf", ".", "cast", "(", "tf", ".", "clip_by_value", "(", "temp", ",", "0.0", ",", "255.0", ")", ",", "tf", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.cutout": [[88, 137], ["tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.pad", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.where", "tensorflow.shape", "tensorflow.shape", "tensorflow.zeros", "tensorflow.equal", "tensorflow.ones_like"], "function", ["None"], ["", "def", "cutout", "(", "image", ",", "pad_size", ",", "replace", "=", "0", ")", ":", "\n", "  ", "\"\"\"Apply cutout (https://arxiv.org/abs/1708.04552) to image.\n\n  This operation applies a (2*pad_size x 2*pad_size) mask of zeros to\n  a random location within `img`. The pixel values filled in will be of the\n  value `replace`. The located where the mask will be applied is randomly\n  chosen uniformly over the whole image.\n\n  Args:\n    image: An image Tensor of type uint8.\n    pad_size: Specifies how big the zero mask that will be generated is that\n      is applied to the image. The mask will be of size\n      (2*pad_size x 2*pad_size).\n    replace: What pixel value to fill in the image in the area that has\n      the cutout mask applied to it.\n\n  Returns:\n    An image Tensor that is of type uint8.\n  \"\"\"", "\n", "image_height", "=", "tf", ".", "shape", "(", "image", ")", "[", "0", "]", "\n", "image_width", "=", "tf", ".", "shape", "(", "image", ")", "[", "1", "]", "\n", "\n", "# Sample the center location in the image where the zero mask will be applied.", "\n", "cutout_center_height", "=", "tf", ".", "random_uniform", "(", "\n", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_height", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "cutout_center_width", "=", "tf", ".", "random_uniform", "(", "\n", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_width", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "lower_pad", "=", "tf", ".", "maximum", "(", "0", ",", "cutout_center_height", "-", "pad_size", ")", "\n", "upper_pad", "=", "tf", ".", "maximum", "(", "0", ",", "image_height", "-", "cutout_center_height", "-", "pad_size", ")", "\n", "left_pad", "=", "tf", ".", "maximum", "(", "0", ",", "cutout_center_width", "-", "pad_size", ")", "\n", "right_pad", "=", "tf", ".", "maximum", "(", "0", ",", "image_width", "-", "cutout_center_width", "-", "pad_size", ")", "\n", "\n", "cutout_shape", "=", "[", "image_height", "-", "(", "lower_pad", "+", "upper_pad", ")", ",", "\n", "image_width", "-", "(", "left_pad", "+", "right_pad", ")", "]", "\n", "padding_dims", "=", "[", "[", "lower_pad", ",", "upper_pad", "]", ",", "[", "left_pad", ",", "right_pad", "]", "]", "\n", "mask", "=", "tf", ".", "pad", "(", "\n", "tf", ".", "zeros", "(", "cutout_shape", ",", "dtype", "=", "image", ".", "dtype", ")", ",", "\n", "padding_dims", ",", "constant_values", "=", "1", ")", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "mask", "=", "tf", ".", "tile", "(", "mask", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "where", "(", "\n", "tf", ".", "equal", "(", "mask", ",", "0", ")", ",", "\n", "tf", ".", "ones_like", "(", "image", ",", "dtype", "=", "image", ".", "dtype", ")", "*", "replace", ",", "\n", "image", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.solarize": [[139, 144], ["tensorflow.where"], "function", ["None"], ["", "def", "solarize", "(", "image", ",", "threshold", "=", "128", ")", ":", "\n", "# For each pixel in the image, select the pixel", "\n", "# if the value is less than the threshold.", "\n", "# Otherwise, subtract 255 from the pixel.", "\n", "  ", "return", "tf", ".", "where", "(", "image", "<", "threshold", ",", "image", ",", "255", "-", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.solarize_add": [[146, 154], ["tensorflow.cast", "tensorflow.where", "tensorflow.cast", "tensorflow.clip_by_value"], "function", ["None"], ["", "def", "solarize_add", "(", "image", ",", "addition", "=", "0", ",", "threshold", "=", "128", ")", ":", "\n", "# For each pixel in the image less than threshold", "\n", "# we add 'addition' amount to it and then clip the", "\n", "# pixel value to be between 0 and 255. The value", "\n", "# of 'addition' is between -128 and 128.", "\n", "  ", "added_image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "int64", ")", "+", "addition", "\n", "added_image", "=", "tf", ".", "cast", "(", "tf", ".", "clip_by_value", "(", "added_image", ",", "0", ",", "255", ")", ",", "tf", ".", "uint8", ")", "\n", "return", "tf", ".", "where", "(", "image", "<", "threshold", ",", "added_image", ",", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.color": [[156, 160], ["tensorflow.image.grayscale_to_rgb", "autoaugment.blend", "tensorflow.image.rgb_to_grayscale"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.blend"], ["", "def", "color", "(", "image", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Color.\"\"\"", "\n", "degenerate", "=", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "tf", ".", "image", ".", "rgb_to_grayscale", "(", "image", ")", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.contrast": [[162, 177], ["tensorflow.image.rgb_to_grayscale", "tensorflow.cast", "tensorflow.histogram_fixed_width", "tensorflow.clip_by_value", "tensorflow.image.grayscale_to_rgb", "autoaugment.blend", "tensorflow.reduce_sum", "tensorflow.ones_like", "tensorflow.cast", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.blend"], ["", "def", "contrast", "(", "image", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Contrast.\"\"\"", "\n", "degenerate", "=", "tf", ".", "image", ".", "rgb_to_grayscale", "(", "image", ")", "\n", "# Cast before calling tf.histogram.", "\n", "degenerate", "=", "tf", ".", "cast", "(", "degenerate", ",", "tf", ".", "int32", ")", "\n", "\n", "# Compute the grayscale histogram, then compute the mean pixel value,", "\n", "# and create a constant image size of that value.  Use that as the", "\n", "# blending degenerate target of the original image.", "\n", "hist", "=", "tf", ".", "histogram_fixed_width", "(", "degenerate", ",", "[", "0", ",", "255", "]", ",", "nbins", "=", "256", ")", "\n", "mean", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "hist", ",", "tf", ".", "float32", ")", ")", "/", "256.0", "\n", "degenerate", "=", "tf", ".", "ones_like", "(", "degenerate", ",", "dtype", "=", "tf", ".", "float32", ")", "*", "mean", "\n", "degenerate", "=", "tf", ".", "clip_by_value", "(", "degenerate", ",", "0.0", ",", "255.0", ")", "\n", "degenerate", "=", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "tf", ".", "cast", "(", "degenerate", ",", "tf", ".", "uint8", ")", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.brightness": [[179, 183], ["tensorflow.zeros_like", "autoaugment.blend"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.blend"], ["", "def", "brightness", "(", "image", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Brightness.\"\"\"", "\n", "degenerate", "=", "tf", ".", "zeros_like", "(", "image", ")", "\n", "return", "blend", "(", "degenerate", ",", "image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.posterize": [[185, 189], ["tensorflow.bitwise.left_shift", "tensorflow.bitwise.right_shift"], "function", ["None"], ["", "def", "posterize", "(", "image", ",", "bits", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Posterize.\"\"\"", "\n", "shift", "=", "8", "-", "bits", "\n", "return", "tf", ".", "bitwise", ".", "left_shift", "(", "tf", ".", "bitwise", ".", "right_shift", "(", "image", ",", "shift", ")", ",", "shift", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.rotate": [[191, 214], ["tensorflow_addons.image.rotate", "autoaugment.unwrap", "autoaugment.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.rotate", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap"], ["", "def", "rotate", "(", "image", ",", "degrees", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n\n  Args:\n    image: An image Tensor of type uint8.\n    degrees: Float, a scalar angle in degrees to rotate all images by. If\n      degrees is positive the image will be rotated clockwise otherwise it will\n      be rotated counterclockwise.\n    replace: A one or three value 1D tensor to fill empty pixels caused by\n      the rotate operation.\n\n  Returns:\n    The rotated version of image.\n  \"\"\"", "\n", "# Convert from degrees to radians.", "\n", "degrees_to_radians", "=", "math", ".", "pi", "/", "180.0", "\n", "radians", "=", "degrees", "*", "degrees_to_radians", "\n", "\n", "# In practice, we should randomize the rotation degrees by flipping", "\n", "# it negatively half the time, but that's done on 'degrees' outside", "\n", "# of the function.", "\n", "image", "=", "contrib_image", ".", "rotate", "(", "wrap", "(", "image", ")", ",", "radians", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.translate_x": [[216, 220], ["tensorflow_addons.image.translate", "autoaugment.unwrap", "autoaugment.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap"], ["", "def", "translate_x", "(", "image", ",", "pixels", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Translate in X dimension.\"\"\"", "\n", "image", "=", "contrib_image", ".", "translate", "(", "wrap", "(", "image", ")", ",", "[", "-", "pixels", ",", "0", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.translate_y": [[222, 226], ["tensorflow_addons.image.translate", "autoaugment.unwrap", "autoaugment.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap"], ["", "def", "translate_y", "(", "image", ",", "pixels", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"", "\n", "image", "=", "contrib_image", ".", "translate", "(", "wrap", "(", "image", ")", ",", "[", "0", ",", "-", "pixels", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.shear_x": [[228, 237], ["tensorflow_addons.image.transform", "autoaugment.unwrap", "autoaugment.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap"], ["", "def", "shear_x", "(", "image", ",", "level", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"", "\n", "# Shear parallel to x axis is a projective transform", "\n", "# with a matrix form of:", "\n", "# [1  level", "\n", "#  0  1].", "\n", "image", "=", "contrib_image", ".", "transform", "(", "\n", "wrap", "(", "image", ")", ",", "[", "1.", ",", "level", ",", "0.", ",", "0.", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.shear_y": [[239, 248], ["tensorflow_addons.image.transform", "autoaugment.unwrap", "autoaugment.wrap"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap"], ["", "def", "shear_y", "(", "image", ",", "level", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"", "\n", "# Shear parallel to y axis is a projective transform", "\n", "# with a matrix form of:", "\n", "# [1  0", "\n", "#  level  1].", "\n", "image", "=", "contrib_image", ".", "transform", "(", "\n", "wrap", "(", "image", ")", ",", "[", "1.", ",", "0.", ",", "0.", ",", "level", ",", "1.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "return", "unwrap", "(", "image", ",", "replace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.autocontrast": [[250, 287], ["autoaugment.autocontrast.scale_channel"], "function", ["None"], ["", "def", "autocontrast", "(", "image", ")", ":", "\n", "  ", "\"\"\"Implements Autocontrast function from PIL using TF ops.\n\n  Args:\n    image: A 3D uint8 tensor.\n\n  Returns:\n    The image after it has had autocontrast applied to it and will be of type\n    uint8.\n  \"\"\"", "\n", "\n", "def", "scale_channel", "(", "image", ")", ":", "\n", "    ", "\"\"\"Scale the 2D image using the autocontrast rule.\"\"\"", "\n", "# A possibly cheaper version can be done using cumsum/unique_with_counts", "\n", "# over the histogram values, rather than iterating over the entire image.", "\n", "# to compute mins and maxes.", "\n", "lo", "=", "tf", ".", "to_float", "(", "tf", ".", "reduce_min", "(", "image", ")", ")", "\n", "hi", "=", "tf", ".", "to_float", "(", "tf", ".", "reduce_max", "(", "image", ")", ")", "\n", "\n", "# Scale the image, making the lowest value 0 and the highest value 255.", "\n", "def", "scale_values", "(", "im", ")", ":", "\n", "      ", "scale", "=", "255.0", "/", "(", "hi", "-", "lo", ")", "\n", "offset", "=", "-", "lo", "*", "scale", "\n", "im", "=", "tf", ".", "to_float", "(", "im", ")", "*", "scale", "+", "offset", "\n", "im", "=", "tf", ".", "clip_by_value", "(", "im", ",", "0.0", ",", "255.0", ")", "\n", "return", "tf", ".", "cast", "(", "im", ",", "tf", ".", "uint8", ")", "\n", "\n", "", "result", "=", "tf", ".", "cond", "(", "hi", ">", "lo", ",", "lambda", ":", "scale_values", "(", "image", ")", ",", "lambda", ":", "image", ")", "\n", "return", "result", "\n", "\n", "# Assumes RGB for now.  Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "s2", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "1", "]", ")", "\n", "s3", "=", "scale_channel", "(", "image", "[", ":", ",", ":", ",", "2", "]", ")", "\n", "image", "=", "tf", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "2", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.sharpness": [[289, 316], ["tensorflow.cast", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.nn.depthwise_conv2d", "tensorflow.clip_by_value", "tensorflow.squeeze", "tensorflow.ones_like", "tensorflow.pad", "tensorflow.pad", "tensorflow.where", "autoaugment.blend", "tensorflow.constant", "tensorflow.cast", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.blend"], ["", "def", "sharpness", "(", "image", ",", "factor", ")", ":", "\n", "  ", "\"\"\"Implements Sharpness function from PIL using TF ops.\"\"\"", "\n", "orig_image", "=", "image", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "# Make image 4D for conv operation.", "\n", "image", "=", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "# SMOOTH PIL Kernel.", "\n", "kernel", "=", "tf", ".", "constant", "(", "\n", "[", "[", "1", ",", "1", ",", "1", "]", ",", "[", "1", ",", "5", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", "]", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "/", "13.", "\n", "# Tile across channel dimension.", "\n", "kernel", "=", "tf", ".", "tile", "(", "kernel", ",", "[", "1", ",", "1", ",", "3", ",", "1", "]", ")", "\n", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "degenerate", "=", "tf", ".", "nn", ".", "depthwise_conv2d", "(", "\n", "image", ",", "kernel", ",", "strides", ",", "padding", "=", "'VALID'", ",", "rate", "=", "[", "1", ",", "1", "]", ")", "\n", "degenerate", "=", "tf", ".", "clip_by_value", "(", "degenerate", ",", "0.0", ",", "255.0", ")", "\n", "degenerate", "=", "tf", ".", "squeeze", "(", "tf", ".", "cast", "(", "degenerate", ",", "tf", ".", "uint8", ")", ",", "[", "0", "]", ")", "\n", "\n", "# For the borders of the resulting image, fill in the values of the", "\n", "# original image.", "\n", "mask", "=", "tf", ".", "ones_like", "(", "degenerate", ")", "\n", "padded_mask", "=", "tf", ".", "pad", "(", "mask", ",", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "padded_degenerate", "=", "tf", ".", "pad", "(", "degenerate", ",", "[", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "result", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "padded_mask", ",", "1", ")", ",", "padded_degenerate", ",", "orig_image", ")", "\n", "\n", "# Blend the final result.", "\n", "return", "blend", "(", "result", ",", "orig_image", ",", "factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.equalize": [[318, 356], ["autoaugment.autocontrast.scale_channel"], "function", ["None"], ["", "def", "equalize", "(", "image", ")", ":", "\n", "  ", "\"\"\"Implements Equalize function from PIL using TF ops.\"\"\"", "\n", "def", "scale_channel", "(", "im", ",", "c", ")", ":", "\n", "    ", "\"\"\"Scale the data in the channel to implement equalize.\"\"\"", "\n", "im", "=", "tf", ".", "cast", "(", "im", "[", ":", ",", ":", ",", "c", "]", ",", "tf", ".", "int32", ")", "\n", "# Compute the histogram of the image channel.", "\n", "histo", "=", "tf", ".", "histogram_fixed_width", "(", "im", ",", "[", "0", ",", "255", "]", ",", "nbins", "=", "256", ")", "\n", "\n", "# For the purposes of computing the step, filter out the nonzeros.", "\n", "nonzero", "=", "tf", ".", "where", "(", "tf", ".", "not_equal", "(", "histo", ",", "0", ")", ")", "\n", "nonzero_histo", "=", "tf", ".", "reshape", "(", "tf", ".", "gather", "(", "histo", ",", "nonzero", ")", ",", "[", "-", "1", "]", ")", "\n", "step", "=", "(", "tf", ".", "reduce_sum", "(", "nonzero_histo", ")", "-", "nonzero_histo", "[", "-", "1", "]", ")", "//", "255", "\n", "\n", "def", "build_lut", "(", "histo", ",", "step", ")", ":", "\n", "# Compute the cumulative sum, shifting by step // 2", "\n", "# and then normalization by step.", "\n", "      ", "lut", "=", "(", "tf", ".", "cumsum", "(", "histo", ")", "+", "(", "step", "//", "2", ")", ")", "//", "step", "\n", "# Shift lut, prepending with 0.", "\n", "lut", "=", "tf", ".", "concat", "(", "[", "[", "0", "]", ",", "lut", "[", ":", "-", "1", "]", "]", ",", "0", ")", "\n", "# Clip the counts to be in range.  This is done", "\n", "# in the C code for image.point.", "\n", "return", "tf", ".", "clip_by_value", "(", "lut", ",", "0", ",", "255", ")", "\n", "\n", "# If step is zero, return the original image.  Otherwise, build", "\n", "# lut from the full histogram and step and then index from it.", "\n", "", "result", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "step", ",", "0", ")", ",", "\n", "lambda", ":", "im", ",", "\n", "lambda", ":", "tf", ".", "gather", "(", "build_lut", "(", "histo", ",", "step", ")", ",", "im", ")", ")", "\n", "\n", "return", "tf", ".", "cast", "(", "result", ",", "tf", ".", "uint8", ")", "\n", "\n", "# Assumes RGB for now.  Scales each channel independently", "\n", "# and then stacks the result.", "\n", "", "s1", "=", "scale_channel", "(", "image", ",", "0", ")", "\n", "s2", "=", "scale_channel", "(", "image", ",", "1", ")", "\n", "s3", "=", "scale_channel", "(", "image", ",", "2", ")", "\n", "image", "=", "tf", ".", "stack", "(", "[", "s1", ",", "s2", ",", "s3", "]", ",", "2", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.invert": [[358, 362], ["tensorflow.convert_to_tensor"], "function", ["None"], ["", "def", "invert", "(", "image", ")", ":", "\n", "  ", "\"\"\"Inverts the image pixels.\"\"\"", "\n", "image", "=", "tf", ".", "convert_to_tensor", "(", "image", ")", "\n", "return", "255", "-", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.wrap": [[364, 370], ["tensorflow.shape", "tensorflow.ones", "tensorflow.concat", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["", "def", "wrap", "(", "image", ")", ":", "\n", "  ", "\"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"", "\n", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "extended_channel", "=", "tf", ".", "ones", "(", "[", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "1", "]", ",", "image", ".", "dtype", ")", "\n", "extended", "=", "tf", ".", "concat", "(", "[", "image", ",", "extended_channel", "]", ",", "2", ")", "\n", "return", "extended", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.unwrap": [[372, 408], ["tensorflow.shape", "tensorflow.reshape", "tensorflow.concat", "tensorflow.where", "tensorflow.reshape", "tensorflow.slice", "tensorflow.equal", "tensorflow.ones", "tensorflow.ones_like", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image", "tensorflow_addons.image"], "function", ["None"], ["", "def", "unwrap", "(", "image", ",", "replace", ")", ":", "\n", "  ", "\"\"\"Unwraps an image produced by wrap.\n\n  Where there is a 0 in the last channel for every spatial position,\n  the rest of the three channels in that spatial dimension are grayed\n  (set to 128).  Operations like translate and shear on a wrapped\n  Tensor will leave 0s in empty locations.  Some transformations look\n  at the intensity of values to do preprocessing, and we want these\n  empty pixels to assume the 'average' value, rather than pure black.\n\n\n  Args:\n    image: A 3D Image Tensor with 4 channels.\n    replace: A one or three value 1D tensor to fill empty pixels.\n\n  Returns:\n    image: A 3D image Tensor with 3 channels.\n  \"\"\"", "\n", "image_shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "# Flatten the spatial dimensions.", "\n", "flattened_image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "-", "1", ",", "image_shape", "[", "2", "]", "]", ")", "\n", "\n", "# Find all pixels where the last channel is zero.", "\n", "alpha_channel", "=", "flattened_image", "[", ":", ",", "3", "]", "\n", "\n", "replace", "=", "tf", ".", "concat", "(", "[", "replace", ",", "tf", ".", "ones", "(", "[", "1", "]", ",", "image", ".", "dtype", ")", "]", ",", "0", ")", "\n", "\n", "# Where they are zero, fill them in with 'replace'.", "\n", "flattened_image", "=", "tf", ".", "where", "(", "\n", "tf", ".", "equal", "(", "alpha_channel", ",", "0", ")", ",", "\n", "tf", ".", "ones_like", "(", "flattened_image", ",", "dtype", "=", "image", ".", "dtype", ")", "*", "replace", ",", "\n", "flattened_image", ")", "\n", "\n", "image", "=", "tf", ".", "reshape", "(", "flattened_image", ",", "image_shape", ")", "\n", "image", "=", "tf", ".", "slice", "(", "image", ",", "[", "0", ",", "0", ",", "0", "]", ",", "[", "image_shape", "[", "0", "]", ",", "image_shape", "[", "1", "]", ",", "3", "]", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._randomly_negate_tensor": [[430, 435], ["tensorflow.cast", "tensorflow.cond", "tensorflow.floor", "tensorflow.random_uniform"], "function", ["None"], ["def", "_randomly_negate_tensor", "(", "tensor", ")", ":", "\n", "  ", "\"\"\"With 50% prob turn the tensor negative.\"\"\"", "\n", "should_flip", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "]", ")", "+", "0.5", ")", ",", "tf", ".", "bool", ")", "\n", "final_tensor", "=", "tf", ".", "cond", "(", "should_flip", ",", "lambda", ":", "tensor", ",", "lambda", ":", "-", "tensor", ")", "\n", "return", "final_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._rotate_level_to_arg": [[437, 441], ["autoaugment._randomly_negate_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._randomly_negate_tensor"], ["", "def", "_rotate_level_to_arg", "(", "level", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "30.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._shrink_level_to_arg": [[443, 450], ["None"], "function", ["None"], ["", "def", "_shrink_level_to_arg", "(", "level", ")", ":", "\n", "  ", "\"\"\"Converts level to ratio by which we shrink the image content.\"\"\"", "\n", "if", "level", "==", "0", ":", "\n", "    ", "return", "(", "1.0", ",", ")", "# if level is zero, do not shrink the image", "\n", "# Maximum shrinking ratio is 2.9.", "\n", "", "level", "=", "2.", "/", "(", "_MAX_LEVEL", "/", "level", ")", "+", "0.9", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._enhance_level_to_arg": [[452, 454], ["None"], "function", ["None"], ["", "def", "_enhance_level_to_arg", "(", "level", ")", ":", "\n", "  ", "return", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "1.8", "+", "0.1", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._shear_level_to_arg": [[456, 461], ["autoaugment._randomly_negate_tensor"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._randomly_negate_tensor"], ["", "def", "_shear_level_to_arg", "(", "level", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "0.3", "\n", "# Flip level to negative with 50% chance.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._translate_level_to_arg": [[463, 468], ["autoaugment._randomly_negate_tensor", "float"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._randomly_negate_tensor"], ["", "def", "_translate_level_to_arg", "(", "level", ",", "translate_const", ")", ":", "\n", "  ", "level", "=", "(", "level", "/", "_MAX_LEVEL", ")", "*", "float", "(", "translate_const", ")", "\n", "# Flip level to negative with 50% chance.", "\n", "level", "=", "_randomly_negate_tensor", "(", "level", ")", "\n", "return", "(", "level", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.level_to_arg": [[470, 491], ["autoaugment._translate_level_to_arg", "autoaugment._translate_level_to_arg", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._translate_level_to_arg", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._translate_level_to_arg"], ["", "def", "level_to_arg", "(", "hparams", ")", ":", "\n", "  ", "return", "{", "\n", "'AutoContrast'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Equalize'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Invert'", ":", "lambda", "level", ":", "(", ")", ",", "\n", "'Rotate'", ":", "_rotate_level_to_arg", ",", "\n", "'Posterize'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "4", ")", ",", ")", ",", "\n", "'Solarize'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "256", ")", ",", ")", ",", "\n", "'SolarizeAdd'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "110", ")", ",", ")", ",", "\n", "'Color'", ":", "_enhance_level_to_arg", ",", "\n", "'Contrast'", ":", "_enhance_level_to_arg", ",", "\n", "'Brightness'", ":", "_enhance_level_to_arg", ",", "\n", "'Sharpness'", ":", "_enhance_level_to_arg", ",", "\n", "'ShearX'", ":", "_shear_level_to_arg", ",", "\n", "'ShearY'", ":", "_shear_level_to_arg", ",", "\n", "'Cutout'", ":", "lambda", "level", ":", "(", "int", "(", "(", "level", "/", "_MAX_LEVEL", ")", "*", "hparams", ".", "cutout_const", ")", ",", ")", ",", "\n", "# pylint:disable=g-long-lambda", "\n", "'TranslateX'", ":", "lambda", "level", ":", "_translate_level_to_arg", "(", "\n", "level", ",", "hparams", ".", "translate_const", ")", ",", "\n", "'TranslateY'", ":", "lambda", "level", ":", "_translate_level_to_arg", "(", "\n", "level", ",", "hparams", ".", "translate_const", ")", ",", "\n", "# pylint:enable=g-long-lambda", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._parse_policy_info": [[495, 516], ["tuple", "tuple", "autoaugment.level_to_arg", "inspect.getfullargspec", "inspect.getfullargspec", "list", "list", "inspect.getfullargspec"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.level_to_arg"], ["", "def", "_parse_policy_info", "(", "name", ",", "prob", ",", "level", ",", "replace_value", ",", "augmentation_hparams", ")", ":", "\n", "  ", "\"\"\"Return the function that corresponds to `name` and update `level` param.\"\"\"", "\n", "func", "=", "NAME_TO_FUNC", "[", "name", "]", "\n", "args", "=", "level_to_arg", "(", "augmentation_hparams", ")", "[", "name", "]", "(", "level", ")", "\n", "\n", "# Check to see if prob is passed into function. This is used for operations", "\n", "# where we alter bboxes independently.", "\n", "# pytype:disable=wrong-arg-types", "\n", "if", "'prob'", "in", "inspect", ".", "getfullargspec", "(", "func", ")", "[", "0", "]", ":", "\n", "    ", "args", "=", "tuple", "(", "[", "prob", "]", "+", "list", "(", "args", ")", ")", "\n", "# pytype:enable=wrong-arg-types", "\n", "\n", "# Add in replace arg if it is required for the function that is being called.", "\n", "# pytype:disable=wrong-arg-types", "\n", "", "if", "'replace'", "in", "inspect", ".", "getfullargspec", "(", "func", ")", "[", "0", "]", ":", "\n", "# Make sure replace is the final argument", "\n", "    ", "assert", "'replace'", "==", "inspect", ".", "getfullargspec", "(", "func", ")", "[", "0", "]", "[", "-", "1", "]", "\n", "args", "=", "tuple", "(", "list", "(", "args", ")", "+", "[", "replace_value", "]", ")", "\n", "# pytype:enable=wrong-arg-types", "\n", "\n", "", "return", "(", "func", ",", "prob", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._apply_func_with_prob": [[518, 537], ["isinstance", "tensorflow.cast", "tensorflow.cond", "tensorflow.floor", "inspect.getfullargspec", "func", "tensorflow.random_uniform"], "function", ["None"], ["", "def", "_apply_func_with_prob", "(", "func", ",", "image", ",", "args", ",", "prob", ")", ":", "\n", "  ", "\"\"\"Apply `func` to image w/ `args` as input with probability `prob`.\"\"\"", "\n", "assert", "isinstance", "(", "args", ",", "tuple", ")", "\n", "\n", "# If prob is a function argument, then this randomness is being handled", "\n", "# inside the function, so make sure it is always called.", "\n", "# pytype:disable=wrong-arg-types", "\n", "if", "'prob'", "in", "inspect", ".", "getfullargspec", "(", "func", ")", "[", "0", "]", ":", "\n", "    ", "prob", "=", "1.0", "\n", "# pytype:enable=wrong-arg-types", "\n", "\n", "# Apply the function with probability `prob`.", "\n", "", "should_apply_op", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "+", "prob", ")", ",", "tf", ".", "bool", ")", "\n", "augmented_image", "=", "tf", ".", "cond", "(", "\n", "should_apply_op", ",", "\n", "lambda", ":", "func", "(", "image", ",", "*", "args", ")", ",", "\n", "lambda", ":", "image", ")", "\n", "return", "augmented_image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.select_and_apply_random_policy": [[539, 550], ["tensorflow.random_uniform", "enumerate", "tensorflow.cond", "len", "tensorflow.equal", "selected_policy", "tensorflow_addons.image"], "function", ["None"], ["", "def", "select_and_apply_random_policy", "(", "policies", ",", "image", ")", ":", "\n", "  ", "\"\"\"Select a random policy from `policies` and apply it to `image`.\"\"\"", "\n", "policy_to_select", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "maxval", "=", "len", "(", "policies", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "# Note that using tf.case instead of tf.conds would result in significantly", "\n", "# larger graphs and would even break export for some larger policies.", "\n", "for", "(", "i", ",", "policy", ")", "in", "enumerate", "(", "policies", ")", ":", "\n", "    ", "image", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "i", ",", "policy_to_select", ")", ",", "\n", "lambda", "selected_policy", "=", "policy", ":", "selected_policy", "(", "image", ")", ",", "\n", "lambda", ":", "image", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.build_and_apply_nas_policy": [[552, 599], ["autoaugment.select_and_apply_random_policy", "tf_policies.append", "tf_policy.append", "autoaugment.build_and_apply_nas_policy.make_final_policy", "tensorflow_addons.image"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.select_and_apply_random_policy"], ["", "def", "build_and_apply_nas_policy", "(", "policies", ",", "image", ",", "\n", "augmentation_hparams", ")", ":", "\n", "  ", "\"\"\"Build a policy from the given policies passed in and apply to image.\n\n  Args:\n    policies: list of lists of tuples in the form `(func, prob, level)`, `func`\n      is a string name of the augmentation function, `prob` is the probability\n      of applying the `func` operation, `level` is the input argument for\n      `func`.\n    image: tf.Tensor that the resulting policy will be applied to.\n    augmentation_hparams: Hparams associated with the NAS learned policy.\n\n  Returns:\n    A version of image that now has data augmentation applied to it based on\n    the `policies` pass into the function.\n  \"\"\"", "\n", "replace_value", "=", "[", "128", ",", "128", ",", "128", "]", "\n", "\n", "# func is the string name of the augmentation function, prob is the", "\n", "# probability of applying the operation and level is the parameter associated", "\n", "# with the tf op.", "\n", "\n", "# tf_policies are functions that take in an image and return an augmented", "\n", "# image.", "\n", "tf_policies", "=", "[", "]", "\n", "for", "policy", "in", "policies", ":", "\n", "    ", "tf_policy", "=", "[", "]", "\n", "# Link string name to the correct python function and make sure the correct", "\n", "# argument is passed into that function.", "\n", "for", "policy_info", "in", "policy", ":", "\n", "      ", "policy_info", "=", "list", "(", "policy_info", ")", "+", "[", "replace_value", ",", "augmentation_hparams", "]", "\n", "\n", "tf_policy", ".", "append", "(", "_parse_policy_info", "(", "*", "policy_info", ")", ")", "\n", "# Now build the tf policy that will apply the augmentation procedue", "\n", "# on image.", "\n", "", "def", "make_final_policy", "(", "tf_policy_", ")", ":", "\n", "      ", "def", "final_policy", "(", "image_", ")", ":", "\n", "        ", "for", "func", ",", "prob", ",", "args", "in", "tf_policy_", ":", "\n", "          ", "image_", "=", "_apply_func_with_prob", "(", "\n", "func", ",", "image_", ",", "args", ",", "prob", ")", "\n", "", "return", "image_", "\n", "", "return", "final_policy", "\n", "", "tf_policies", ".", "append", "(", "make_final_policy", "(", "tf_policy", ")", ")", "\n", "\n", "", "augmented_image", "=", "select_and_apply_random_policy", "(", "\n", "tf_policies", ",", "image", ")", "\n", "return", "augmented_image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.distort_image_with_autoaugment": [[601, 624], ["autoaugment.HParams", "autoaugment.build_and_apply_nas_policy", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.build_and_apply_nas_policy"], ["", "def", "distort_image_with_autoaugment", "(", "image", ",", "augmentation_name", ")", ":", "\n", "  ", "\"\"\"Applies the AutoAugment policy to `image`.\n\n  AutoAugment is from the paper: https://arxiv.org/abs/1805.09501.\n\n  Args:\n    image: `Tensor` of shape [height, width, 3] representing an image.\n    augmentation_name: The name of the AutoAugment policy to use.\n\n  Returns:\n    A tuple containing the augmented versions of `image`.\n  \"\"\"", "\n", "available_policies", "=", "{", "'imagenet'", ":", "optimal_policies", ".", "policy_imagenet", ",", "\n", "'cifar'", ":", "optimal_policies", ".", "policy_cifar", ",", "\n", "'svhn'", ":", "optimal_policies", ".", "policy_svhn", "}", "\n", "if", "augmentation_name", "not", "in", "available_policies", ":", "\n", "    ", "raise", "ValueError", "(", "'Invalid augmentation_name: {}'", ".", "format", "(", "augmentation_name", ")", ")", "\n", "\n", "", "policy", "=", "available_policies", "[", "augmentation_name", "]", "(", ")", "\n", "# Hparams that will be used for AutoAugment.", "\n", "augmentation_hparams", "=", "HParams", "(", "cutout_const", "=", "100", ",", "translate_const", "=", "250", ")", "\n", "\n", "return", "build_and_apply_nas_policy", "(", "policy", ",", "image", ",", "augmentation_hparams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.distort_image_with_randaugment": [[626, 668], ["tensorflow.logging.info", "autoaugment.HParams", "range", "tensorflow.random_uniform", "float", "tensorflow.name_scope", "enumerate", "len", "tensorflow.random_uniform", "autoaugment._parse_policy_info", "tensorflow.cond", "tensorflow.equal", "selected_func"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._parse_policy_info"], ["", "def", "distort_image_with_randaugment", "(", "image", ",", "num_layers", ",", "magnitude", ")", ":", "\n", "  ", "\"\"\"Applies the RandAugment policy to `image`.\n\n  RandAugment is from the paper https://arxiv.org/abs/1909.13719,\n\n  Args:\n    image: `Tensor` of shape [height, width, 3] representing an image.\n    num_layers: Integer, the number of augmentation transformations to apply\n      sequentially to an image. Represented as (N) in the paper. Usually best\n      values will be in the range [1, 3].\n    magnitude: Integer, shared magnitude across all augmentation operations.\n      Represented as (M) in the paper. Usually best values are in the range\n      [5, 30].\n\n  Returns:\n    The augmented version of `image`.\n  \"\"\"", "\n", "replace_value", "=", "[", "128", "]", "*", "3", "\n", "tf", ".", "logging", ".", "info", "(", "'Using RandAug.'", ")", "\n", "augmentation_hparams", "=", "HParams", "(", "cutout_const", "=", "40", ",", "translate_const", "=", "100", ")", "\n", "available_ops", "=", "[", "\n", "'AutoContrast'", ",", "'Equalize'", ",", "'Invert'", ",", "'Rotate'", ",", "'Posterize'", ",", "\n", "'Solarize'", ",", "'Color'", ",", "'Contrast'", ",", "'Brightness'", ",", "'Sharpness'", ",", "\n", "'ShearX'", ",", "'ShearY'", ",", "'TranslateX'", ",", "'TranslateY'", ",", "'Cutout'", ",", "'SolarizeAdd'", "]", "\n", "\n", "for", "layer_num", "in", "range", "(", "num_layers", ")", ":", "\n", "    ", "op_to_select", "=", "tf", ".", "random_uniform", "(", "\n", "[", "]", ",", "maxval", "=", "len", "(", "available_ops", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "random_magnitude", "=", "float", "(", "magnitude", ")", "\n", "with", "tf", ".", "name_scope", "(", "'randaug_layer_{}'", ".", "format", "(", "layer_num", ")", ")", ":", "\n", "      ", "for", "(", "i", ",", "op_name", ")", "in", "enumerate", "(", "available_ops", ")", ":", "\n", "        ", "prob", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "minval", "=", "0.2", ",", "maxval", "=", "0.8", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "func", ",", "_", ",", "args", "=", "_parse_policy_info", "(", "op_name", ",", "prob", ",", "random_magnitude", ",", "\n", "replace_value", ",", "augmentation_hparams", ")", "\n", "image", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "i", ",", "op_to_select", ")", ",", "\n", "# pylint:disable=g-long-lambda", "\n", "lambda", "selected_func", "=", "func", ",", "selected_args", "=", "args", ":", "selected_func", "(", "\n", "image", ",", "*", "selected_args", ")", ",", "\n", "# pylint:enable=g-long-lambda", "\n", "lambda", ":", "image", ")", "\n", "", "", "", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment_test.AutoAugmentTest.test_image_processing_function": [[25, 51], ["absl.testing.parameterized.named_parameters", "sam.autoaugment.autoaugment.HParams", "sam.autoaugment.autoaugment._parse_policy_info", "tensorflow.zeros", "function", "autoaugment_test.AutoAugmentTest.assertEqual", "autoaugment_test.AutoAugmentTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment._parse_policy_info"], ["  ", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'ShearX'", ",", "'ShearX'", ")", ",", "\n", "(", "'ShearY'", ",", "'ShearY'", ")", ",", "\n", "(", "'Cutout'", ",", "'Cutout'", ")", ",", "\n", "(", "'TranslateX'", ",", "'TranslateX'", ")", ",", "\n", "(", "'TranslateY'", ",", "'TranslateY'", ")", ",", "\n", "(", "'Rotate'", ",", "'Rotate'", ")", ",", "\n", "(", "'AutoContrast'", ",", "'AutoContrast'", ")", ",", "\n", "(", "'Invert'", ",", "'Invert'", ")", ",", "\n", "(", "'Equalize'", ",", "'Equalize'", ")", ",", "\n", "(", "'Solarize'", ",", "'Solarize'", ")", ",", "\n", "(", "'Posterize'", ",", "'Posterize'", ")", ",", "\n", "(", "'Contrast'", ",", "'Contrast'", ")", ",", "\n", "(", "'Color'", ",", "'Color'", ")", ",", "\n", "(", "'Brightness'", ",", "'Brightness'", ")", ",", "\n", "(", "'Sharpness'", ",", "'Sharpness'", ")", ")", "\n", "def", "test_image_processing_function", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "    ", "hparams", "=", "autoaugment", ".", "HParams", "(", "cutout_const", "=", "10", ",", "translate_const", "=", "25", ")", "\n", "replace_value", "=", "[", "128", ",", "128", ",", "128", "]", "\n", "function", ",", "_", ",", "args", "=", "autoaugment", ".", "_parse_policy_info", "(", "\n", "name", ",", "1.0", ",", "10", ",", "replace_value", ",", "hparams", ")", "\n", "cifar_image_shape", "=", "[", "32", ",", "32", ",", "3", "]", "\n", "image", "=", "tf", ".", "zeros", "(", "cifar_image_shape", ",", "tf", ".", "uint8", ")", "\n", "augmented_image", "=", "function", "(", "image", ",", "*", "args", ")", "\n", "self", ".", "assertEqual", "(", "augmented_image", ".", "shape", ",", "cifar_image_shape", ")", "\n", "self", ".", "assertEqual", "(", "augmented_image", ".", "dtype", ",", "tf", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment_test.AutoAugmentTest.test_autoaugment_function": [[52, 62], ["absl.testing.parameterized.named_parameters", "tensorflow.zeros", "autoaugment_fn", "autoaugment_test.AutoAugmentTest.assertEqual", "autoaugment_test.AutoAugmentTest.assertEqual", "sam.autoaugment.autoaugment.distort_image_with_autoaugment"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.distort_image_with_autoaugment"], ["", "@", "parameterized", ".", "named_parameters", "(", "(", "'cifar'", ",", "'cifar'", ")", ",", "(", "'svhn'", ",", "'svhn'", ")", ",", "\n", "(", "'imagenet'", ",", "'imagenet'", ")", ")", "\n", "def", "test_autoaugment_function", "(", "self", ",", "dataset_name", ")", ":", "\n", "    ", "autoaugment_fn", "=", "lambda", "image", ":", "autoaugment", ".", "distort_image_with_autoaugment", "(", "# pylint:disable=g-long-lambda", "\n", "image", ",", "dataset_name", ")", "\n", "image_shape", "=", "[", "224", ",", "224", ",", "3", "]", "if", "dataset_name", "==", "'imagenet'", "else", "[", "32", ",", "32", ",", "3", "]", "\n", "image", "=", "tf", ".", "zeros", "(", "image_shape", ",", "tf", ".", "uint8", ")", "\n", "augmented_image", "=", "autoaugment_fn", "(", "image", ")", "\n", "self", ".", "assertEqual", "(", "augmented_image", ".", "shape", ",", "image_shape", ")", "\n", "self", ".", "assertEqual", "(", "augmented_image", ".", "dtype", ",", "tf", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.sam_jax.train.main": [[70, 173], ["tensorflow.enable_v2_behavior", "tensorflow.config.experimental.set_visible_devices", "train.main.set_hardware_bernoulli"], "function", ["None"], ["def", "main", "(", "_", ")", ":", "\n", "\n", "  ", "tf", ".", "enable_v2_behavior", "(", ")", "\n", "# make sure tf does not allocate gpu memory", "\n", "tf", ".", "config", ".", "experimental", ".", "set_visible_devices", "(", "[", "]", ",", "'GPU'", ")", "\n", "\n", "# Performance gains on TPU by switching to hardware bernoulli.", "\n", "def", "hardware_bernoulli", "(", "rng_key", ",", "p", "=", "jax", ".", "numpy", ".", "float32", "(", "0.5", ")", ",", "shape", "=", "None", ")", ":", "\n", "    ", "lax_key", "=", "jax", ".", "lax", ".", "tie_in", "(", "rng_key", ",", "0.0", ")", "\n", "return", "jax", ".", "lax", ".", "rng_uniform", "(", "lax_key", ",", "1.0", ",", "shape", ")", "<", "p", "\n", "\n", "", "def", "set_hardware_bernoulli", "(", ")", ":", "\n", "    ", "jax", ".", "random", ".", "bernoulli", "=", "hardware_bernoulli", "\n", "\n", "", "set_hardware_bernoulli", "(", ")", "\n", "\n", "# As we gridsearch the weight decay and the learning rate, we add them to the", "\n", "# output directory path so that each model has its own directory to save the", "\n", "# results in. We also add the `run_seed` which is \"gridsearched\" on to", "\n", "# replicate an experiment several times.", "\n", "output_dir_suffix", "=", "os", ".", "path", ".", "join", "(", "\n", "'lr_'", "+", "str", "(", "FLAGS", ".", "learning_rate", ")", ",", "\n", "'wd_'", "+", "str", "(", "FLAGS", ".", "weight_decay", ")", ",", "\n", "'rho_'", "+", "str", "(", "FLAGS", ".", "sam_rho", ")", ",", "\n", "'seed_'", "+", "str", "(", "FLAGS", ".", "run_seed", ")", ")", "\n", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "output_dir", ",", "output_dir_suffix", ")", "\n", "\n", "if", "not", "gfile", ".", "exists", "(", "output_dir", ")", ":", "\n", "    ", "gfile", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "num_devices", "=", "jax", ".", "local_device_count", "(", ")", "*", "jax", ".", "host_count", "(", ")", "\n", "assert", "FLAGS", ".", "batch_size", "%", "num_devices", "==", "0", "\n", "local_batch_size", "=", "FLAGS", ".", "batch_size", "//", "num_devices", "\n", "info", "=", "'Total batch size: {} ({} x {} replicas)'", ".", "format", "(", "\n", "FLAGS", ".", "batch_size", ",", "local_batch_size", ",", "num_devices", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "\n", "if", "FLAGS", ".", "dataset", "==", "'cifar10'", ":", "\n", "    ", "if", "FLAGS", ".", "from_pretrained_checkpoint", ":", "\n", "      ", "image_size", "=", "efficientnet", ".", "name_to_image_size", "(", "FLAGS", ".", "model_name", ")", "\n", "", "else", ":", "\n", "      ", "image_size", "=", "None", "\n", "", "dataset_source", "=", "dataset_source_lib", ".", "Cifar10", "(", "\n", "FLAGS", ".", "batch_size", "//", "jax", ".", "host_count", "(", ")", ",", "\n", "FLAGS", ".", "image_level_augmentations", ",", "\n", "FLAGS", ".", "batch_level_augmentations", ",", "\n", "image_size", "=", "image_size", ")", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'cifar100'", ":", "\n", "    ", "if", "FLAGS", ".", "from_pretrained_checkpoint", ":", "\n", "      ", "image_size", "=", "efficientnet", ".", "name_to_image_size", "(", "FLAGS", ".", "model_name", ")", "\n", "", "else", ":", "\n", "      ", "image_size", "=", "None", "\n", "", "dataset_source", "=", "dataset_source_lib", ".", "Cifar100", "(", "\n", "FLAGS", ".", "batch_size", "//", "jax", ".", "host_count", "(", ")", ",", "FLAGS", ".", "image_level_augmentations", ",", "\n", "FLAGS", ".", "batch_level_augmentations", ",", "image_size", "=", "image_size", ")", "\n", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'fashion_mnist'", ":", "\n", "    ", "dataset_source", "=", "dataset_source_lib", ".", "FashionMnist", "(", "\n", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "image_level_augmentations", ",", "\n", "FLAGS", ".", "batch_level_augmentations", ")", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'svhn'", ":", "\n", "    ", "dataset_source", "=", "dataset_source_lib", ".", "SVHN", "(", "\n", "FLAGS", ".", "batch_size", ",", "FLAGS", ".", "image_level_augmentations", ",", "\n", "FLAGS", ".", "batch_level_augmentations", ")", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'imagenet'", ":", "\n", "    ", "imagenet_image_size", "=", "efficientnet", ".", "name_to_image_size", "(", "FLAGS", ".", "model_name", ")", "\n", "dataset_source", "=", "dataset_source_imagenet", ".", "Imagenet", "(", "\n", "FLAGS", ".", "batch_size", "//", "jax", ".", "host_count", "(", ")", ",", "imagenet_image_size", ",", "\n", "FLAGS", ".", "image_level_augmentations", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Dataset not recognized.'", ")", "\n", "\n", "", "if", "'cifar'", "in", "FLAGS", ".", "dataset", "or", "'svhn'", "in", "FLAGS", ".", "dataset", ":", "\n", "    ", "if", "image_size", "is", "None", "or", "'svhn'", "in", "FLAGS", ".", "dataset", ":", "\n", "      ", "image_size", "=", "32", "\n", "", "num_channels", "=", "3", "\n", "num_classes", "=", "100", "if", "FLAGS", ".", "dataset", "==", "'cifar100'", "else", "10", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'fashion_mnist'", ":", "\n", "    ", "image_size", "=", "28", "# For Fashion Mnist", "\n", "num_channels", "=", "1", "\n", "num_classes", "=", "10", "\n", "", "elif", "FLAGS", ".", "dataset", "==", "'imagenet'", ":", "\n", "    ", "image_size", "=", "imagenet_image_size", "\n", "num_channels", "=", "3", "\n", "num_classes", "=", "1000", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Dataset not recognized.'", ")", "\n", "\n", "", "try", ":", "\n", "    ", "model", ",", "state", "=", "load_imagenet_model", ".", "get_model", "(", "FLAGS", ".", "model_name", ",", "\n", "local_batch_size", ",", "image_size", ",", "\n", "num_classes", ")", "\n", "", "except", "load_imagenet_model", ".", "ModelNameError", ":", "\n", "    ", "model", ",", "state", "=", "load_model", ".", "get_model", "(", "FLAGS", ".", "model_name", ",", "\n", "local_batch_size", ",", "image_size", ",", "\n", "num_classes", ",", "num_channels", ")", "\n", "\n", "# Learning rate will be overwritten by the lr schedule, we set it to zero.", "\n", "", "optimizer", "=", "flax_training", ".", "create_optimizer", "(", "model", ",", "0.0", ")", "\n", "\n", "flax_training", ".", "train", "(", "optimizer", ",", "state", ",", "dataset_source", ",", "output_dir", ",", "\n", "FLAGS", ".", "num_epochs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.DepthwiseConv.apply": [[77, 152], ["flax.nn.initializers.lecun_normal", "jax.numpy.asarray", "efficientnet.DepthwiseConv.param", "jax.numpy.asarray", "jax.numpy.transpose", "flax.nn.linear._conv_dimension_numbers", "jax.lax.conv_general_dilated", "efficientnet.DepthwiseConv.param", "jax.numpy.asarray"], "methods", ["None"], ["def", "apply", "(", "self", ",", "\n", "inputs", ":", "jnp", ".", "ndarray", ",", "\n", "features", ":", "int", ",", "\n", "kernel_size", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "strides", ":", "bool", "=", "None", ",", "\n", "padding", ":", "str", "=", "'SAME'", ",", "\n", "input_dilation", ":", "int", "=", "None", ",", "\n", "kernel_dilation", ":", "int", "=", "None", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "dtype", ":", "jnp", ".", "dtype", "=", "jnp", ".", "float32", ",", "\n", "precision", "=", "None", ",", "\n", "kernel_init", "=", "flax", ".", "nn", ".", "initializers", ".", "lecun_normal", "(", ")", ",", "\n", "bias_init", "=", "flax", ".", "nn", ".", "initializers", ".", "zeros", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Applies a convolution to the inputs.\n\n    Args:\n      inputs: Input data with dimensions (batch, spatial_dims..., features).\n      features: Number of convolution filters.\n      kernel_size: Shape of the convolutional kernel.\n      strides: A sequence of `n` integers, representing the inter-window\n        strides.\n      padding: Either the string `'SAME'`, the string `'VALID'`, or a sequence\n        of `n` `(low, high)` integer pairs that give the padding to apply before\n        and after each spatial dimension.\n      input_dilation: `None`, or a sequence of `n` integers, giving the\n        dilation factor to apply in each spatial dimension of `inputs`.\n        Convolution with input dilation `d` is equivalent to transposed\n        convolution with stride `d`.\n      kernel_dilation: `None`, or a sequence of `n` integers, giving the\n        dilation factor to apply in each spatial dimension of the convolution\n        kernel. Convolution with kernel dilation is also known as 'atrous\n        convolution'.\n      bias: Whether to add a bias to the output (default: True).\n      dtype: The dtype of the computation (default: float32).\n      precision: Numerical precision of the computation see `jax.lax.Precision`\n        for details.\n      kernel_init: Initializer for the convolutional kernel.\n      bias_init: Initializer for the bias.\n\n    Returns:\n      The convolved data.\n    \"\"\"", "\n", "\n", "inputs", "=", "jnp", ".", "asarray", "(", "inputs", ",", "dtype", ")", "\n", "in_features", "=", "inputs", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "strides", "is", "None", ":", "\n", "      ", "strides", "=", "(", "1", ",", ")", "*", "(", "inputs", ".", "ndim", "-", "2", ")", "\n", "\n", "", "kernel_shape", "=", "kernel_size", "+", "(", "features", ",", "1", ")", "\n", "# Naming convention follows tensorflow.", "\n", "kernel", "=", "self", ".", "param", "(", "'depthwise_kernel'", ",", "kernel_shape", ",", "kernel_init", ")", "\n", "kernel", "=", "jnp", ".", "asarray", "(", "kernel", ",", "dtype", ")", "\n", "\n", "# Need to transpose to convert tensorflow-shaped kernel to lax-shaped kernel", "\n", "kernel", "=", "jnp", ".", "transpose", "(", "kernel", ",", "[", "0", ",", "1", ",", "3", ",", "2", "]", ")", "\n", "\n", "dimension_numbers", "=", "flax", ".", "nn", ".", "linear", ".", "_conv_dimension_numbers", "(", "inputs", ".", "shape", ")", "# pylint:disable=protected-access", "\n", "\n", "y", "=", "jax", ".", "lax", ".", "conv_general_dilated", "(", "\n", "inputs", ",", "\n", "kernel", ",", "\n", "strides", ",", "\n", "padding", ",", "\n", "lhs_dilation", "=", "input_dilation", ",", "\n", "rhs_dilation", "=", "kernel_dilation", ",", "\n", "dimension_numbers", "=", "dimension_numbers", ",", "\n", "feature_group_count", "=", "in_features", ",", "\n", "precision", "=", "precision", ")", "\n", "\n", "if", "bias", ":", "\n", "      ", "bias", "=", "self", ".", "param", "(", "'bias'", ",", "(", "features", ",", ")", ",", "bias_init", ")", "\n", "bias", "=", "jnp", ".", "asarray", "(", "bias", ",", "dtype", ")", "\n", "y", "=", "y", "+", "bias", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.BlockConfig.__init__": [[159, 172], ["locals().items", "setattr", "locals"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_filters", ":", "int", "=", "0", ",", "\n", "output_filters", ":", "int", "=", "0", ",", "\n", "kernel_size", ":", "int", "=", "3", ",", "\n", "num_repeat", ":", "int", "=", "1", ",", "\n", "expand_ratio", ":", "int", "=", "1", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "se_ratio", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "id_skip", ":", "bool", "=", "True", ",", "\n", "fused_conv", ":", "bool", "=", "False", ",", "\n", "conv_type", ":", "str", "=", "'depthwise'", ")", ":", "\n", "    ", "for", "arg", "in", "locals", "(", ")", ".", "items", "(", ")", ":", "\n", "      ", "setattr", "(", "self", ",", "*", "arg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.ModelConfig.__init__": [[177, 217], ["locals().items", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "efficientnet.BlockConfig", "setattr", "locals"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "width_coefficient", ":", "float", "=", "1.0", ",", "\n", "depth_coefficient", ":", "float", "=", "1.0", ",", "\n", "resolution", ":", "int", "=", "224", ",", "\n", "dropout_rate", ":", "float", "=", "0.2", ",", "\n", "blocks", ":", "Tuple", "[", "BlockConfig", ",", "...", "]", "=", "(", "\n", "# (input_filters, output_filters, kernel_size, num_repeat,", "\n", "#  expand_ratio, strides, se_ratio)", "\n", "# pylint: disable=bad-whitespace", "\n", "BlockConfig", "(", "32", ",", "16", ",", "3", ",", "1", ",", "1", ",", "(", "1", ",", "1", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "16", ",", "24", ",", "3", ",", "2", ",", "6", ",", "(", "2", ",", "2", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "24", ",", "40", ",", "5", ",", "2", ",", "6", ",", "(", "2", ",", "2", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "40", ",", "80", ",", "3", ",", "3", ",", "6", ",", "(", "2", ",", "2", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "80", ",", "112", ",", "5", ",", "3", ",", "6", ",", "(", "1", ",", "1", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "112", ",", "192", ",", "5", ",", "4", ",", "6", ",", "(", "2", ",", "2", ")", ",", "0.25", ")", ",", "\n", "BlockConfig", "(", "192", ",", "320", ",", "3", ",", "1", ",", "6", ",", "(", "1", ",", "1", ")", ",", "0.25", ")", ",", "\n", "# pylint: enable=bad-whitespace", "\n", ")", ",", "\n", "stem_base_filters", ":", "int", "=", "32", ",", "\n", "top_base_filters", ":", "int", "=", "1280", ",", "\n", "activation", ":", "str", "=", "'swish'", ",", "\n", "batch_norm", ":", "str", "=", "'default'", ",", "\n", "bn_momentum", ":", "float", "=", "0.99", ",", "\n", "bn_epsilon", ":", "float", "=", "1e-3", ",", "\n", "# While the original implementation used a weight decay of 1e-5,", "\n", "# tf.nn.l2_loss divides it by 2, so we halve this to compensate in Keras", "\n", "weight_decay", ":", "float", "=", "5e-6", ",", "\n", "drop_connect_rate", ":", "float", "=", "0.2", ",", "\n", "depth_divisor", ":", "int", "=", "8", ",", "\n", "min_depth", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_se", ":", "bool", "=", "True", ",", "\n", "input_channels", ":", "int", "=", "3", ",", "\n", "model_name", ":", "str", "=", "'efficientnet'", ",", "\n", "rescale_input", ":", "bool", "=", "True", ",", "\n", "data_format", ":", "str", "=", "'channels_last'", ",", "\n", "dtype", ":", "str", "=", "'float32'", ")", ":", "\n", "    ", "\"\"\"Default Config for Efficientnet-B0.\"\"\"", "\n", "for", "arg", "in", "locals", "(", ")", ".", "items", "(", ")", ":", "\n", "      ", "setattr", "(", "self", ",", "*", "arg", ")", "\n", "# pylint:enable=unused-argument", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.SqueezeExcite.apply": [[356, 401], ["max", "flax.nn.avg_pool", "efficientnet.conv2d", "efficientnet.conv2d", "int", "str", "str"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "filters", ":", "int", ",", "\n", "block", ":", "BlockConfig", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "train", ":", "bool", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Applies a convolution to the inputs.\n\n    Args:\n      x: Input data with dimensions (batch, spatial_dims..., features).\n      filters: Number of convolution filters.\n      block: Configuration for this block.\n      config: Configuration for the model.\n      train: Whether the model is in training or inference mode.\n\n    Returns:\n      The output of the squeeze excite block.\n    \"\"\"", "\n", "conv_index", "=", "0", "\n", "num_reduced_filters", "=", "max", "(", "1", ",", "int", "(", "block", ".", "input_filters", "*", "block", ".", "se_ratio", ")", ")", "\n", "\n", "se", "=", "flax", ".", "nn", ".", "avg_pool", "(", "x", ",", "x", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "se", "=", "conv2d", "(", "\n", "se", ",", "\n", "num_reduced_filters", ",", "\n", "config", ",", "\n", "use_bias", "=", "True", ",", "\n", "use_batch_norm", "=", "False", ",", "\n", "activation", "=", "config", ".", "activation", ",", "\n", "conv_name", "=", "'reduce_conv2d_'", "+", "str", "(", "conv_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "conv_index", "+=", "1", "\n", "\n", "se", "=", "conv2d", "(", "\n", "se", ",", "\n", "filters", ",", "\n", "config", ",", "\n", "use_bias", "=", "True", ",", "\n", "use_batch_norm", "=", "False", ",", "\n", "activation", "=", "'sigmoid'", ",", "\n", "conv_name", "=", "'expand_conv2d_'", "+", "str", "(", "conv_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "conv_index", "+=", "1", "\n", "x", "=", "x", "*", "se", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.MBConvBlock.apply": [[406, 501], ["efficientnet.conv2d", "efficientnet.conv2d", "efficientnet.SqueezeExcite", "all", "efficientnet.conv2d", "efficientnet.conv2d", "efficientnet.stochastic_depth", "str", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.stochastic_depth"], ["def", "apply", "(", "self", ",", "\n", "inputs", ":", "jnp", ".", "ndarray", ",", "\n", "block", ":", "BlockConfig", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "train", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Mobile Inverted Residual Bottleneck.\n\n    Args:\n      inputs: Input to the block.\n      block: BlockConfig, arguments to create a Block.\n      config: ModelConfig, a set of model parameters.\n      train: Whether we are training or predicting.\n\n    Returns:\n      The output of the block.\n    \"\"\"", "\n", "use_se", "=", "config", ".", "use_se", "\n", "activation", "=", "config", ".", "activation", "\n", "drop_connect_rate", "=", "config", ".", "drop_connect_rate", "\n", "use_depthwise", "=", "block", ".", "conv_type", "!=", "'no_depthwise'", "\n", "\n", "filters", "=", "block", ".", "input_filters", "*", "block", ".", "expand_ratio", "\n", "\n", "x", "=", "inputs", "\n", "bn_index", "=", "0", "\n", "conv_index", "=", "0", "\n", "\n", "if", "block", ".", "fused_conv", ":", "\n", "# If we use fused mbconv, skip expansion and use regular conv.", "\n", "      ", "x", "=", "conv2d", "(", "\n", "x", ",", "\n", "filters", ",", "\n", "config", ",", "\n", "kernel_size", "=", "block", ".", "kernel_size", ",", "\n", "strides", "=", "block", ".", "strides", ",", "\n", "activation", "=", "activation", ",", "\n", "conv_name", "=", "'fused_conv2d_'", "+", "str", "(", "conv_index", ")", ",", "\n", "bn_name", "=", "'batch_normalization_'", "+", "str", "(", "bn_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "bn_index", "+=", "1", "\n", "conv_index", "+=", "1", "\n", "", "else", ":", "\n", "      ", "if", "block", ".", "expand_ratio", "!=", "1", ":", "\n", "# Expansion phase", "\n", "        ", "kernel_size", "=", "(", "1", ",", "1", ")", "if", "use_depthwise", "else", "(", "3", ",", "3", ")", "\n", "x", "=", "conv2d", "(", "\n", "x", ",", "\n", "filters", ",", "\n", "config", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "activation", "=", "activation", ",", "\n", "conv_name", "=", "'expand_conv2d_'", "+", "str", "(", "conv_index", ")", ",", "\n", "bn_name", "=", "'batch_normalization_'", "+", "str", "(", "bn_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "bn_index", "+=", "1", "\n", "conv_index", "+=", "1", "\n", "# Depthwise Convolution", "\n", "", "if", "use_depthwise", ":", "\n", "        ", "x", "=", "conv2d", "(", "x", ",", "\n", "conv_filters", "=", "x", ".", "shape", "[", "-", "1", "]", ",", "# Depthwise conv", "\n", "config", "=", "config", ",", "\n", "kernel_size", "=", "block", ".", "kernel_size", ",", "\n", "strides", "=", "block", ".", "strides", ",", "\n", "activation", "=", "activation", ",", "\n", "depthwise", "=", "True", ",", "\n", "conv_name", "=", "'depthwise_conv2d'", ",", "\n", "bn_name", "=", "'batch_normalization_'", "+", "str", "(", "bn_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "bn_index", "+=", "1", "\n", "\n", "# Squeeze and Excitation phase", "\n", "", "", "if", "use_se", ":", "\n", "      ", "assert", "block", ".", "se_ratio", "is", "not", "None", "\n", "assert", "0", "<", "block", ".", "se_ratio", "<=", "1", "\n", "x", "=", "SqueezeExcite", "(", "x", ",", "filters", ",", "block", ",", "config", ",", "train", "=", "train", ")", "\n", "\n", "# Output phase", "\n", "", "x", "=", "conv2d", "(", "\n", "x", ",", "\n", "block", ".", "output_filters", ",", "\n", "config", ",", "\n", "activation", "=", "None", ",", "\n", "conv_name", "=", "'project_conv2d_'", "+", "str", "(", "conv_index", ")", ",", "\n", "bn_name", "=", "'batch_normalization_'", "+", "str", "(", "bn_index", ")", ",", "\n", "train", "=", "train", ")", "\n", "conv_index", "+=", "1", "\n", "\n", "if", "(", "block", ".", "id_skip", "and", "all", "(", "s", "==", "1", "for", "s", "in", "block", ".", "strides", ")", "and", "\n", "block", ".", "input_filters", "==", "block", ".", "output_filters", ")", ":", "\n", "      ", "if", "drop_connect_rate", "and", "drop_connect_rate", ">", "0", ":", "\n", "        ", "survival_probability", "=", "1", "-", "drop_connect_rate", "\n", "x", "=", "stochastic_depth", "(", "x", ",", "survival_probability", ",", "deterministic", "=", "not", "train", ")", "\n", "", "x", "=", "x", "+", "inputs", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.Stem.apply": [[506, 533], ["efficientnet.conv2d", "ValueError", "efficientnet.round_filters"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_filters"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Returns the output of the stem block.\n\n    Args:\n      x: The input to the block.\n      config: ModelConfig, a set of model parameters.\n      train: Whether we are training or predicting.\n    \"\"\"", "\n", "resolution", "=", "config", ".", "resolution", "\n", "if", "x", ".", "shape", "[", "1", ":", "3", "]", "!=", "(", "resolution", ",", "resolution", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Wrong input size. Model was expecting '", "+", "\n", "'resolution {} '", ".", "format", "(", "(", "resolution", ",", "resolution", ")", ")", "+", "\n", "'but got input of resolution {}'", ".", "format", "(", "x", ".", "shape", "[", "1", ":", "3", "]", ")", ")", "\n", "\n", "# Build stem", "\n", "", "x", "=", "conv2d", "(", "\n", "x", ",", "\n", "round_filters", "(", "config", ".", "stem_base_filters", ",", "config", ")", ",", "\n", "config", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "activation", "=", "config", ".", "activation", ",", "\n", "train", "=", "train", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.Head.apply": [[538, 567], ["efficientnet.conv2d", "flax.nn.avg_pool", "flax.nn.Dense", "flax.nn.dropout.reshape", "efficientnet.round_filters", "flax.nn.dropout"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_filters"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "num_classes", ":", "int", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Returns the output of the head block.\n\n    Args:\n      x: The input to the block.\n      config: A set of model parameters.\n      num_classes: Dimension of the output of the model.\n      train: Whether we are training or predicting.\n    \"\"\"", "\n", "# Build top", "\n", "x", "=", "conv2d", "(", "\n", "x", ",", "\n", "round_filters", "(", "config", ".", "top_base_filters", ",", "config", ")", ",", "\n", "config", ",", "\n", "activation", "=", "config", ".", "activation", ",", "\n", "train", "=", "train", ")", "\n", "\n", "# Build classifier", "\n", "x", "=", "flax", ".", "nn", ".", "avg_pool", "(", "x", ",", "x", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "if", "config", ".", "dropout_rate", "and", "config", ".", "dropout_rate", ">", "0", ":", "\n", "      ", "x", "=", "flax", ".", "nn", ".", "dropout", "(", "x", ",", "config", ".", "dropout_rate", ",", "deterministic", "=", "not", "train", ")", "\n", "", "x", "=", "flax", ".", "nn", ".", "Dense", "(", "\n", "x", ",", "num_classes", ",", "kernel_init", "=", "dense_kernel_init_fn", ",", "name", "=", "'dense'", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "x", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.EfficientNet.apply": [[572, 633], ["copy.deepcopy", "efficientnet.Stem", "sum", "efficientnet.Head", "ValueError", "efficientnet.round_filters", "efficientnet.round_filters", "efficientnet.round_repeats", "efficientnet.MBConvBlock", "efficientnet.round_repeats", "range", "float", "efficientnet.MBConvBlock", "float"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_filters", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_filters", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_repeats", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_repeats"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Returns the output of the EfficientNet model.\n\n    Args:\n      x: The input batch of images.\n      config: The model config.\n      num_classes: Dimension of the output layer.\n      train: Whether we are in training or inference.\n\n    Returns:\n      The output of efficientnet\n    \"\"\"", "\n", "config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "depth_coefficient", "=", "config", ".", "depth_coefficient", "\n", "blocks", "=", "config", ".", "blocks", "\n", "drop_connect_rate", "=", "config", ".", "drop_connect_rate", "\n", "\n", "resolution", "=", "config", ".", "resolution", "\n", "if", "x", ".", "shape", "[", "1", ":", "3", "]", "!=", "(", "resolution", ",", "resolution", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Wrong input size. Model was expecting '", "+", "\n", "'resolution {} '", ".", "format", "(", "(", "resolution", ",", "resolution", ")", ")", "+", "\n", "'but got input of resolution {}'", ".", "format", "(", "x", ".", "shape", "[", "1", ":", "3", "]", ")", ")", "\n", "\n", "# Build stem", "\n", "", "x", "=", "Stem", "(", "x", ",", "config", ",", "train", "=", "train", ")", "\n", "\n", "# Build blocks", "\n", "num_blocks_total", "=", "sum", "(", "\n", "round_repeats", "(", "block", ".", "num_repeat", ",", "depth_coefficient", ")", "for", "block", "in", "blocks", ")", "\n", "block_num", "=", "0", "\n", "\n", "for", "block", "in", "blocks", ":", "\n", "      ", "assert", "block", ".", "num_repeat", ">", "0", "\n", "# Update block input and output filters based on depth multiplier", "\n", "block", ".", "input_filters", "=", "round_filters", "(", "block", ".", "input_filters", ",", "config", ")", "\n", "block", ".", "output_filters", "=", "round_filters", "(", "block", ".", "output_filters", ",", "config", ")", "\n", "block", ".", "num_repeat", "=", "round_repeats", "(", "block", ".", "num_repeat", ",", "depth_coefficient", ")", "\n", "\n", "# The first block needs to take care of stride and filter size increase", "\n", "drop_rate", "=", "drop_connect_rate", "*", "float", "(", "block_num", ")", "/", "num_blocks_total", "\n", "config", ".", "drop_connect_rate", "=", "drop_rate", "\n", "x", "=", "MBConvBlock", "(", "x", ",", "block", ",", "config", ",", "train", "=", "train", ")", "\n", "block_num", "+=", "1", "\n", "if", "block", ".", "num_repeat", ">", "1", ":", "\n", "        ", "block", ".", "input_filters", "=", "block", ".", "output_filters", "\n", "block", ".", "strides", "=", "[", "1", ",", "1", "]", "\n", "\n", "for", "_", "in", "range", "(", "block", ".", "num_repeat", "-", "1", ")", ":", "\n", "          ", "drop_rate", "=", "drop_connect_rate", "*", "float", "(", "block_num", ")", "/", "num_blocks_total", "\n", "config", ".", "drop_connect_rate", "=", "drop_rate", "\n", "x", "=", "MBConvBlock", "(", "x", ",", "block", ",", "config", ",", "train", "=", "train", ")", "\n", "block_num", "+=", "1", "\n", "\n", "# Build top", "\n", "", "", "", "x", "=", "Head", "(", "x", ",", "config", ",", "num_classes", ",", "train", "=", "train", ")", "\n", "\n", "return", "x", "\n", "# pytype: enable=attribute-error", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.name_to_image_size": [[33, 56], ["image_sizes.get"], "function", ["None"], ["def", "name_to_image_size", "(", "name", ":", "str", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns the expected image size for a given model.\n\n  If the model is not a recognized efficientnet model, will default to the\n  standard resolution of 224 (for Resnet, etc...).\n\n  Args:\n    name: Name of the efficientnet model (ex: efficientnet-b0).\n  \"\"\"", "\n", "image_sizes", "=", "{", "\n", "'efficientnet-b0'", ":", "224", ",", "\n", "'efficientnet-b1'", ":", "240", ",", "\n", "'efficientnet-b2'", ":", "260", ",", "\n", "'efficientnet-b3'", ":", "300", ",", "\n", "'efficientnet-b4'", ":", "380", ",", "\n", "'efficientnet-b5'", ":", "456", ",", "\n", "'efficientnet-b6'", ":", "528", ",", "\n", "'efficientnet-b7'", ":", "600", ",", "\n", "'efficientnet-b8'", ":", "672", ",", "\n", "'efficientnet-l2'", ":", "800", ",", "\n", "'efficientnet-l2-475'", ":", "475", ",", "\n", "}", "\n", "return", "image_sizes", ".", "get", "(", "name", ",", "224", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_filters": [[236, 255], ["max", "absl.logging.info", "int", "int"], "function", ["None"], ["def", "round_filters", "(", "filters", ":", "int", ",", "\n", "config", ":", "ModelConfig", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns rounded number of filters based on width coefficient.\"\"\"", "\n", "width_coefficient", "=", "config", ".", "width_coefficient", "\n", "min_depth", "=", "config", ".", "min_depth", "\n", "divisor", "=", "config", ".", "depth_divisor", "\n", "orig_filters", "=", "filters", "\n", "\n", "if", "not", "width_coefficient", ":", "\n", "    ", "return", "filters", "\n", "\n", "", "filters", "*=", "width_coefficient", "\n", "min_depth", "=", "min_depth", "or", "divisor", "\n", "new_filters", "=", "max", "(", "min_depth", ",", "int", "(", "filters", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than 10%.", "\n", "if", "new_filters", "<", "0.9", "*", "filters", ":", "\n", "    ", "new_filters", "+=", "divisor", "\n", "", "logging", ".", "info", "(", "'round_filter input=%s output=%s'", ",", "orig_filters", ",", "new_filters", ")", "\n", "return", "int", "(", "new_filters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.round_repeats": [[257, 260], ["int", "math.ceil"], "function", ["None"], ["", "def", "round_repeats", "(", "repeats", ":", "int", ",", "depth_coefficient", ":", "float", ")", "->", "int", ":", "\n", "  ", "\"\"\"Returns rounded number of repeats based on depth coefficient.\"\"\"", "\n", "return", "int", "(", "math", ".", "ceil", "(", "depth_coefficient", "*", "repeats", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.conv2d": [[262, 321], ["conv_fn", "isinstance", "tuple", "tuple", "flax.nn.BatchNorm", "getattr", "activation.lower"], "function", ["None"], ["", "def", "conv2d", "(", "inputs", ":", "tf", ".", "Tensor", ",", "\n", "conv_filters", ":", "Optional", "[", "int", "]", ",", "\n", "config", ":", "ModelConfig", ",", "\n", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "use_batch_norm", ":", "bool", "=", "True", ",", "\n", "use_bias", ":", "bool", "=", "False", ",", "\n", "activation", ":", "Any", "=", "None", ",", "\n", "depthwise", ":", "bool", "=", "False", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "conv_name", ":", "str", "=", "None", ",", "\n", "bn_name", ":", "str", "=", "None", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Convolutional layer with possibly batch norm and activation.\n\n  Args:\n    inputs: Input data with dimensions (batch, spatial_dims..., features).\n    conv_filters: Number of convolution filters.\n    config: Configuration for the model.\n    kernel_size: Size of the kernel, as a tuple of int.\n    strides: Strides for the convolution, as a tuple of int.\n    use_batch_norm: Whether batch norm should be applied to the output.\n    use_bias: Whether we should add bias to the output of the first convolution.\n    activation: Name of the activation function to use.\n    depthwise: If true, will use depthwise convolutions.\n    train: Whether the model should behave in training or inference mode.\n    conv_name: Name to give to the convolution layer.\n    bn_name: Name to give to the batch norm layer.\n\n  Returns:\n    The output of the convolutional layer.\n  \"\"\"", "\n", "conv_fn", "=", "DepthwiseConv", "if", "depthwise", "else", "flax", ".", "nn", ".", "Conv", "\n", "kernel_size", "=", "(", "(", "kernel_size", ",", "kernel_size", ")", "\n", "if", "isinstance", "(", "kernel_size", ",", "int", ")", "else", "tuple", "(", "kernel_size", ")", ")", "\n", "conv_name", "=", "conv_name", "if", "conv_name", "else", "'conv2d'", "\n", "bn_name", "=", "bn_name", "if", "bn_name", "else", "'batch_normalization'", "\n", "\n", "x", "=", "conv_fn", "(", "\n", "inputs", ",", "\n", "conv_filters", ",", "\n", "kernel_size", ",", "\n", "tuple", "(", "strides", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "use_bias", ",", "\n", "kernel_init", "=", "conv_kernel_init_fn", ",", "\n", "name", "=", "conv_name", ")", "\n", "\n", "if", "use_batch_norm", ":", "\n", "    ", "x", "=", "nn", ".", "BatchNorm", "(", "\n", "x", ",", "\n", "use_running_average", "=", "not", "train", "or", "FLAGS", ".", "from_pretrained_checkpoint", ",", "\n", "momentum", "=", "config", ".", "bn_momentum", ",", "\n", "epsilon", "=", "config", ".", "bn_epsilon", ",", "\n", "name", "=", "bn_name", ",", "\n", "axis_name", "=", "'batch'", ")", "\n", "\n", "", "if", "activation", "is", "not", "None", ":", "\n", "    ", "x", "=", "getattr", "(", "flax", ".", "nn", ".", "activation", ",", "activation", ".", "lower", "(", ")", ")", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.stochastic_depth": [[323, 351], ["jax.random.bernoulli", "jax.numpy.tile", "jax.lax.select", "flax.nn.make_rng", "jax.numpy.zeros_like", "list"], "function", ["None"], ["", "def", "stochastic_depth", "(", "inputs", ":", "jnp", ".", "ndarray", ",", "\n", "survival_probability", ":", "float", ",", "\n", "deterministic", ":", "bool", "=", "False", ",", "\n", "rng", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Applies stochastic depth.\n\n  Args:\n    inputs: The inputs that should be randomly masked.\n    survival_probability: 1 - the probablity of masking out a value.\n    deterministic: If false the inputs are scaled by `1 / (1 - rate)` and\n      masked, whereas if true, no mask is applied and the inputs are returned as\n      is.\n    rng: An optional `jax.random.PRNGKey`. By default `nn.make_rng()` will\n      be used.\n\n  Returns:\n    The masked inputs.\n  \"\"\"", "\n", "if", "survival_probability", "==", "1.0", "or", "deterministic", ":", "\n", "    ", "return", "inputs", "\n", "\n", "", "if", "rng", "is", "None", ":", "\n", "    ", "rng", "=", "flax", ".", "nn", ".", "make_rng", "(", ")", "\n", "", "mask_shape", "=", "[", "inputs", ".", "shape", "[", "0", "]", "]", "+", "[", "1", "for", "_", "in", "inputs", ".", "shape", "[", "1", ":", "]", "]", "\n", "mask", "=", "jax", ".", "random", ".", "bernoulli", "(", "rng", ",", "p", "=", "survival_probability", ",", "shape", "=", "mask_shape", ")", "\n", "mask", "=", "jnp", ".", "tile", "(", "mask", ",", "[", "1", "]", "+", "list", "(", "inputs", ".", "shape", "[", "1", ":", "]", ")", ")", "\n", "return", "jax", ".", "lax", ".", "select", "(", "mask", ",", "inputs", "/", "survival_probability", ",", "\n", "jnp", ".", "zeros_like", "(", "inputs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.get_efficientnet_module": [[636, 647], ["EfficientNet.partial"], "function", ["None"], ["", "", "def", "get_efficientnet_module", "(", "model_name", ":", "str", ",", "\n", "num_classes", ":", "int", "=", "1000", ")", "->", "EfficientNet", ":", "\n", "  ", "\"\"\"Returns an EfficientNet module for a given architecture.\n\n  Args:\n    model_name: Name of the Efficientnet architecture to use (example:\n      efficientnet-b0).\n    num_classes: Dimension of the output layer.\n  \"\"\"", "\n", "return", "EfficientNet", ".", "partial", "(", "config", "=", "MODEL_CONFIGS", "[", "model_name", "]", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim_test.OptimTest.test_RMSProp": [[30, 59], ["numpy.random.seed", "numpy.random.normal", "sam.sam_jax.efficientnet.optim.RMSProp", "sam.sam_jax.efficientnet.optim.RMSProp.create", "range", "zip", "tensorflow.Session", "tensorflow.Variable", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.RMSPropOptimizer.minimize", "sess.run", "range", "ref_opt.apply_gradient.apply_gradient.apply_gradient", "flax_updated_weights.append", "optim_test.OptimTest.assertAllClose", "tensorflow.global_variables_initializer", "sess.run", "tf1_updated_weights.append", "sess.run"], "methods", ["None"], ["  ", "def", "test_RMSProp", "(", "self", ")", ":", "\n", "    ", "\"\"\"Updates should match Tensorflow1 behavior.\"\"\"", "\n", "lr", ",", "mom", ",", "rho", "=", "0.5", ",", "0.7", ",", "0.8", "\n", "onp", ".", "random", ".", "seed", "(", "0", ")", "\n", "w0", "=", "onp", ".", "random", ".", "normal", "(", "size", "=", "[", "17", ",", "13", ",", "1", "]", ")", "\n", "num_steps", "=", "10", "\n", "# First compute weights updates for TF1 version.", "\n", "tf1_updated_weights", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "      ", "var0", "=", "tf", ".", "Variable", "(", "w0", ",", "trainable", "=", "True", ")", "\n", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "\n", "learning_rate", "=", "lr", ",", "decay", "=", "rho", ",", "momentum", "=", "mom", ",", "epsilon", "=", "0.001", ")", "\n", "loss", "=", "lambda", ":", "(", "var0", "**", "2", ")", "/", "2.0", "\n", "step", "=", "opt", ".", "minimize", "(", "loss", ",", "var_list", "=", "[", "var0", "]", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "sess", ".", "run", "(", "step", ")", "\n", "tf1_updated_weights", ".", "append", "(", "sess", ".", "run", "(", "var0", ")", ")", "\n", "# Now compute the updates for FLAX version.", "\n", "", "", "flax_updated_weights", "=", "[", "]", "\n", "optimizer_def", "=", "optim", ".", "RMSProp", "(", "\n", "learning_rate", "=", "lr", ",", "beta", "=", "mom", ",", "beta2", "=", "rho", ",", "eps", "=", "0.001", ")", "\n", "ref_opt", "=", "optimizer_def", ".", "create", "(", "w0", ")", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "      ", "gradient", "=", "ref_opt", ".", "target", "\n", "ref_opt", "=", "ref_opt", ".", "apply_gradient", "(", "gradient", ")", "\n", "flax_updated_weights", ".", "append", "(", "ref_opt", ".", "target", ")", "\n", "", "for", "a", ",", "b", "in", "zip", "(", "tf1_updated_weights", ",", "flax_updated_weights", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim_test.OptimTest.test_RMSPropWithEMA": [[60, 96], ["numpy.random.seed", "numpy.array", "sam.sam_jax.efficientnet.optim.RMSProp", "sam.sam_jax.efficientnet.optim.RMSProp.create", "sam.sam_jax.efficientnet.optim.ExponentialMovingAverage", "range", "zip", "tensorflow.Session", "tensorflow.train.get_or_create_global_step", "tensorflow.train.ExponentialMovingAverage", "tensorflow.Variable", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.RMSPropOptimizer.minimize", "sess.run", "range", "ref_opt.apply_gradient.apply_gradient.apply_gradient", "ema.update_moving_average.update_moving_average.update_moving_average", "flax_updated_weights.append", "optim_test.OptimTest.assertAllClose", "tensorflow.control_dependencies", "ema.update_moving_average.update_moving_average.apply", "tensorflow.global_variables_initializer", "sess.run", "tf1_updated_weights.append", "sess.run", "ema.update_moving_average.update_moving_average.average"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.ExponentialMovingAverage.update_moving_average", "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet.WideResnet.apply"], ["", "", "def", "test_RMSPropWithEMA", "(", "self", ")", ":", "\n", "    ", "\"\"\"Updates should match Tensorflow1 behavior.\"\"\"", "\n", "lr", ",", "mom", ",", "rho", ",", "ema_decay", "=", "0.05", ",", "0.4", ",", "0.8", ",", "1.0", "\n", "onp", ".", "random", ".", "seed", "(", "0", ")", "\n", "w0", "=", "onp", ".", "array", "(", "[", "1.0", "]", ")", "\n", "num_steps", "=", "10", "\n", "# First compute weights updates for TF1 version.", "\n", "tf1_updated_weights", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "      ", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "decay", "=", "ema_decay", ",", "num_updates", "=", "global_step", ")", "\n", "var0", "=", "tf", ".", "Variable", "(", "w0", ",", "trainable", "=", "True", ")", "\n", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "\n", "learning_rate", "=", "lr", ",", "decay", "=", "rho", ",", "momentum", "=", "mom", ",", "epsilon", "=", "0.000", ")", "\n", "loss", "=", "lambda", ":", "(", "var0", "**", "2", ")", "/", "2.0", "\n", "step", "=", "opt", ".", "minimize", "(", "loss", ",", "var_list", "=", "[", "var0", "]", ",", "global_step", "=", "global_step", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "step", "]", ")", ":", "\n", "        ", "step", "=", "ema", ".", "apply", "(", "[", "var0", "]", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "sess", ".", "run", "(", "step", ")", "\n", "tf1_updated_weights", ".", "append", "(", "sess", ".", "run", "(", "ema", ".", "average", "(", "var0", ")", ")", ")", "\n", "# Now computes the updates for FLAX version.", "\n", "", "", "flax_updated_weights", "=", "[", "]", "\n", "optimizer_def", "=", "optim", ".", "RMSProp", "(", "\n", "learning_rate", "=", "lr", ",", "beta", "=", "mom", ",", "beta2", "=", "rho", ",", "eps", "=", "0.000", ")", "\n", "ref_opt", "=", "optimizer_def", ".", "create", "(", "w0", ")", "\n", "ema", "=", "optim", ".", "ExponentialMovingAverage", "(", "w0", ",", "ema_decay", ",", "0", ")", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "      ", "gradient", "=", "ref_opt", ".", "target", "\n", "ref_opt", "=", "ref_opt", ".", "apply_gradient", "(", "gradient", ")", "\n", "ema", "=", "ema", ".", "update_moving_average", "(", "ref_opt", ".", "target", ",", "ref_opt", ".", "state", ".", "step", ")", "\n", "flax_updated_weights", ".", "append", "(", "ema", ".", "param_ema", ")", "\n", "", "for", "a", ",", "b", "in", "zip", "(", "tf1_updated_weights", ",", "flax_updated_weights", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params": [[26, 35], ["sam.sam_jax.efficientnet.efficientnet.get_efficientnet_module", "sam.sam_jax.imagenet_models.load_model.create_image_model", "sum", "efficientnet_test.EfficientnetTest.assertEqual", "jax.random.PRNGKey", "numpy.prod", "jax.tree_leaves"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.get_efficientnet_module", "home.repos.pwc.inspect_result.google-research_sam.models.load_model.create_image_model"], ["  ", "def", "_test_model_params", "(", "\n", "self", ",", "model_name", ":", "str", ",", "image_size", ":", "int", ",", "expected_params", ":", "int", ")", ":", "\n", "    ", "module", "=", "efficientnet", ".", "get_efficientnet_module", "(", "model_name", ")", "\n", "model", ",", "_", "=", "load_model", ".", "create_image_model", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ",", "\n", "batch_size", "=", "1", ",", "\n", "image_size", "=", "image_size", ",", "\n", "module", "=", "module", ")", "\n", "num_params", "=", "sum", "(", "np", ".", "prod", "(", "e", ".", "shape", ")", "for", "e", "in", "jax", ".", "tree_leaves", "(", "model", ")", ")", "\n", "self", ".", "assertEqual", "(", "num_params", ",", "expected_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b0": [[36, 38], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b0", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b0'", ",", "224", ",", "expected_params", "=", "5288548", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b1": [[39, 41], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b1", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b1'", ",", "240", ",", "expected_params", "=", "7794184", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b2": [[42, 44], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b2", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b2'", ",", "260", ",", "expected_params", "=", "9109994", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b3": [[45, 47], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b3", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b3'", ",", "300", ",", "expected_params", "=", "12233232", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b4": [[48, 50], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b4", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b4'", ",", "380", ",", "expected_params", "=", "19341616", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b5": [[51, 53], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b5", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b5'", ",", "456", ",", "expected_params", "=", "30389784", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b6": [[54, 56], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b6", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b6'", ",", "528", ",", "expected_params", "=", "43040704", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest.test_efficientnet_b7": [[57, 59], ["efficientnet_test.EfficientnetTest._test_model_params"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet_test.EfficientnetTest._test_model_params"], ["", "def", "test_efficientnet_b7", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_model_params", "(", "'efficientnet-b7'", ",", "600", ",", "expected_params", "=", "66347960", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.RMSProp.__init__": [[54, 68], ["optim._RMSPropHyperParams", "flax.optim.base.OptimizerDef.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.__init__"], ["def", "__init__", "(", "self", ",", "learning_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "beta", ":", "float", "=", "0.0", ",", "\n", "beta2", ":", "float", "=", "0.9", ",", "eps", ":", "float", "=", "1e-8", ")", ":", "\n", "    ", "\"\"\"Instantiates the RMSProp optimizer.\n\n    Args:\n      learning_rate: The step size used to update the parameters.\n      beta: Momentum.\n      beta2: The coefficient used for the moving average of the\n        gradient magnitude (default: 0.9).\n      eps: The term added to the gradient magnitude estimate for\n        numerical stability.\n    \"\"\"", "\n", "hyper_params", "=", "_RMSPropHyperParams", "(", "learning_rate", ",", "beta", ",", "beta2", ",", "eps", ")", "\n", "super", "(", ")", ".", "__init__", "(", "hyper_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.RMSProp.init_param_state": [[69, 73], ["optim._RMSPropParamState", "jax.ones_like", "jax.ones_like", "jax.zeros_like", "jax.zeros_like"], "methods", ["None"], ["", "def", "init_param_state", "(", "self", ",", "param", ":", "jnp", ".", "ndarray", ")", "->", "_RMSPropParamState", ":", "\n", "    ", "\"\"\"Initializes parameter state. See base class.\"\"\"", "\n", "return", "_RMSPropParamState", "(", "\n", "jnp", ".", "ones_like", "(", "param", ")", ",", "jnp", ".", "zeros_like", "(", "param", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.RMSProp.apply_param_gradient": [[74, 90], ["optim._RMSPropParamState", "jax.sqrt", "jax.sqrt", "jax.square", "jax.square"], "methods", ["None"], ["", "def", "apply_param_gradient", "(", "\n", "self", ",", "step", ":", "jnp", ".", "ndarray", ",", "\n", "hyper_params", ":", "_RMSPropHyperParams", ",", "\n", "param", ":", "jnp", ".", "ndarray", ",", "\n", "state", ":", "_RMSPropParamState", ",", "\n", "grad", ":", "jnp", ".", "ndarray", ")", "->", "Tuple", "[", "jnp", ".", "ndarray", ",", "_RMSPropParamState", "]", ":", "\n", "    ", "\"\"\"Applies per-parameter gradients. See base class.\"\"\"", "\n", "assert", "hyper_params", ".", "learning_rate", "is", "not", "None", ",", "'no learning rate provided.'", "\n", "new_v", "=", "hyper_params", ".", "beta2", "*", "state", ".", "v", "+", "(", "\n", "1.0", "-", "hyper_params", ".", "beta2", ")", "*", "jnp", ".", "square", "(", "grad", ")", "\n", "grad", "=", "grad", "/", "jnp", ".", "sqrt", "(", "new_v", "+", "hyper_params", ".", "eps", ")", "\n", "new_momentum", "=", "hyper_params", ".", "beta", "*", "state", ".", "momentum", "+", "grad", "\n", "new_param", "=", "param", "-", "hyper_params", ".", "learning_rate", "*", "new_momentum", "\n", "new_state", "=", "_RMSPropParamState", "(", "new_v", ",", "new_momentum", ")", "\n", "\n", "return", "new_param", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.ExponentialMovingAverage.update_moving_average": [[106, 125], ["jax.float32", "jax.float32", "jax.minimum", "jax.minimum", "jax.tree_multimap", "jax.tree_multimap", "jax.tree_multimap", "jax.tree_multimap", "optim.ExponentialMovingAverage.replace"], "methods", ["None"], ["def", "update_moving_average", "(", "self", ",", "new_target", ":", "Any", ",", "\n", "step", ":", "jnp", ".", "ndarray", ")", "->", "Any", ":", "\n", "    ", "\"\"\"Updates the moving average of the target.\n\n    Args:\n      new_target: New values of the target (example: weights of a network\n        after gradient step).\n      step: Current step (used only for warmup).\n\n    Returns:\n      The updated ExponentialMovingAverage.\n    \"\"\"", "\n", "factor", "=", "jnp", ".", "float32", "(", "step", ">=", "self", ".", "warmup_steps", ")", "\n", "delta", "=", "step", "-", "self", ".", "warmup_steps", "\n", "decay", "=", "jnp", ".", "minimum", "(", "self", ".", "decay", ",", "(", "1.", "+", "delta", ")", "/", "(", "10.", "+", "delta", ")", ")", "\n", "decay", "*=", "factor", "\n", "weight_ema", "=", "jax", ".", "tree_multimap", "(", "\n", "lambda", "a", ",", "b", ":", "(", "1", "-", "decay", ")", "*", "a", "+", "decay", "*", "b", ",", "new_target", ",", "self", ".", "param_ema", ")", "\n", "return", "self", ".", "replace", "(", "param_ema", "=", "weight_ema", ")", "\n", "# pytype:enable=attribute-error", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet_test.DatasetSourceImagenetTest.test_LoadImagenet": [[23, 29], ["sam.sam_jax.datasets.dataset_source_imagenet.Imagenet", "next", "dataset_source_imagenet_test.DatasetSourceImagenetTest.assertEqual", "dataset_source_imagenet_test.DatasetSourceImagenetTest.assertEqual", "iter", "sam.sam_jax.datasets.dataset_source_imagenet.Imagenet.get_train"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train"], ["  ", "def", "test_LoadImagenet", "(", "self", ")", ":", "\n", "    ", "dataset", "=", "dataset_source_imagenet", ".", "Imagenet", "(", "\n", "batch_size", "=", "16", ",", "image_size", "=", "127", ",", "image_level_augmentations", "=", "'autoaugment'", ")", "\n", "batch", "=", "next", "(", "iter", "(", "dataset", ".", "get_train", "(", "use_augmentations", "=", "True", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "16", ",", "127", ",", "127", ",", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "16", ",", "1000", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.DatasetSource.get_train": [[46, 58], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "get_train", "(", "self", ",", "use_augmentations", ":", "bool", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the training set.\n\n    The training set will be batched, and the remainder of the batch will be\n    dropped (except if use_augmentation is False, in which case we don't drop\n    the remainder as we are most likely computing the accuracy on the train set.\n\n    Args:\n      use_augmentations: Whether we should apply data augmentation (and possibly\n        cutout) or not.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.DatasetSource.get_test": [[59, 62], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_test", "(", "self", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns test set.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.TFDSDatasetSource._apply_image_augmentations": [[87, 94], ["sam.sam_jax.datasets.augmentation.auto_augmentation", "sam.sam_jax.datasets.augmentation.weak_image_augmentation"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.auto_augmentation", "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.weak_image_augmentation"], ["def", "_apply_image_augmentations", "(", "\n", "self", ",", "example", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "    ", "if", "self", ".", "_augmentation", "in", "[", "'autoaugment'", ",", "'aa-only'", "]", ":", "\n", "      ", "example", "=", "augmentation", ".", "auto_augmentation", "(", "example", ",", "self", ".", "_dataset_name", ")", "\n", "", "if", "self", ".", "_augmentation", "in", "[", "'basic'", ",", "'autoaugment'", "]", ":", "\n", "      ", "example", "=", "augmentation", ".", "weak_image_augmentation", "(", "example", ")", "\n", "", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.TFDSDatasetSource._preprocess_batch": [[95, 103], ["tensorflow.one_hot", "tensorflow.cast"], "methods", ["None"], ["", "def", "_preprocess_batch", "(", "self", ",", "\n", "examples", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "    ", "image", ",", "label", "=", "examples", "[", "'image'", "]", ",", "examples", "[", "'label'", "]", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "/", "255.0", "\n", "image", "=", "(", "image", "-", "self", ".", "_image_mean", ")", "/", "self", ".", "_image_std", "\n", "label", "=", "tf", ".", "one_hot", "(", "\n", "label", ",", "depth", "=", "self", ".", "_num_classes", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.TFDSDatasetSource.get_train": [[104, 133], ["dataset_source.TFDSDatasetSource._train_ds.shuffle", "ds.map.map.batch", "ds.map.map.map", "ds.map.map.map", "ds.map.map.map", "ds.map.map.map", "dataset_source._resize"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._resize"], ["", "def", "get_train", "(", "self", ",", "use_augmentations", ":", "bool", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the training set.\n\n    The training set will be batched, and the remainder of the batch will be\n    dropped (except if use_augmentations is False, in which case we don't drop\n    the remainder as we are most likely computing the accuracy on the train\n    set).\n\n    Args:\n      use_augmentations: Whether we should apply data augmentation (and possibly\n        cutout) or not.\n    \"\"\"", "\n", "ds", "=", "self", ".", "_train_ds", ".", "shuffle", "(", "50000", ")", "\n", "if", "use_augmentations", ":", "\n", "      ", "ds", "=", "ds", ".", "map", "(", "self", ".", "_apply_image_augmentations", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "# Don't drop remainder if we don't use augmentation, as we are evaluating.", "\n", "", "ds", "=", "ds", ".", "batch", "(", "self", ".", "batch_size", ",", "drop_remainder", "=", "use_augmentations", ")", "\n", "ds", "=", "ds", ".", "map", "(", "self", ".", "_preprocess_batch", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "if", "self", ".", "_batch_level_augmentations", "and", "use_augmentations", ":", "\n", "      ", "ds", "=", "ds", ".", "map", "(", "self", ".", "_batch_level_augmentations", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "if", "self", ".", "_image_size", ":", "\n", "      ", "def", "resize", "(", "batch", ")", ":", "\n", "        ", "image", "=", "_resize", "(", "batch", "[", "'image'", "]", ",", "self", ".", "_image_size", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "batch", "[", "'label'", "]", "}", "\n", "", "ds", "=", "ds", ".", "map", "(", "resize", ")", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.TFDSDatasetSource.get_test": [[134, 146], ["min", "dataset_source.TFDSDatasetSource._test_ds.batch().map", "ds.map.map.map", "dataset_source.TFDSDatasetSource._test_ds.batch", "dataset_source._resize"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._resize"], ["", "def", "get_test", "(", "self", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the batched test set.\"\"\"", "\n", "eval_batch_size", "=", "min", "(", "32", ",", "self", ".", "batch_size", ")", "\n", "ds", "=", "self", ".", "_test_ds", ".", "batch", "(", "eval_batch_size", ")", ".", "map", "(", "\n", "self", ".", "_preprocess_batch", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "if", "self", ".", "_image_size", ":", "\n", "      ", "def", "resize", "(", "batch", ")", ":", "\n", "        ", "image", "=", "_resize", "(", "batch", "[", "'image'", "]", ",", "self", ".", "_image_size", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "batch", "[", "'label'", "]", "}", "\n", "", "ds", "=", "ds", ".", "map", "(", "resize", ")", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.CifarDatasetSource.__init__": [[155, 216], ["tensorflow_datasets.load().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow_datasets.load().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "jax.host_count", "jax.host_id", "jax.host_count", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load", "sam.sam_jax.datasets.augmentation.cutout", "sam.sam_jax.datasets.augmentation.mixup"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.cutout", "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.mixup"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "name", ":", "str", ",", "image_level_augmentations", ":", "str", ",", "\n", "batch_level_augmentations", ":", "str", ",", "\n", "image_size", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"Instantiates the DatasetSource.\n\n    Args:\n      batch_size: Batch size to use for training and evaluation.\n      name: Name of the Tensorflow Dataset to use. Should be cifar10 or\n        cifar100.\n      image_level_augmentations: Augmentations to apply to the images. Should be\n        one of:\n        * none: No augmentations are applied.\n        * basic: Applies random crops and horizontal translations.\n        * autoaugment: Applies the best found policy for Cifar from the\n          AutoAugment paper.\n      batch_level_augmentations: Augmentations to apply at the batch level. Only\n        cutout is needed to get SOTA results. The following are implemented:\n        * none: No augmentations are applied.\n        * cutout: Applies cutout (https://arxiv.org/abs/1708.04552).\n        * mixup: Applies mixup (https://arxiv.org/pdf/1710.09412.pdf).\n        * mixcut: Applies mixup and cutout.\n      image_size: Size to which the image should be rescaled. If None, the\n        standard size is used (32x32).\n    \"\"\"", "\n", "assert", "name", "in", "[", "'cifar10'", ",", "'cifar100'", "]", "\n", "assert", "image_level_augmentations", "in", "[", "'none'", ",", "'basic'", ",", "'autoaugment'", "]", "\n", "assert", "batch_level_augmentations", "in", "[", "'none'", ",", "'cutout'", "]", "\n", "self", ".", "_image_size", "=", "image_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "if", "FLAGS", ".", "use_test_set", ":", "\n", "      ", "self", ".", "num_training_obs", "=", "50000", "\n", "train_split_size", "=", "self", ".", "num_training_obs", "//", "jax", ".", "host_count", "(", ")", "\n", "start", "=", "jax", ".", "host_id", "(", ")", "*", "train_split_size", "\n", "train_split", "=", "'train[{}:{}]'", ".", "format", "(", "start", ",", "start", "+", "train_split_size", ")", "\n", "self", ".", "_train_ds", "=", "tfds", ".", "load", "(", "name", ",", "split", "=", "train_split", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "name", ",", "split", "=", "'test'", ")", ".", "cache", "(", ")", "\n", "logging", ".", "info", "(", "'Used test set instead of validation set.'", ")", "\n", "", "else", ":", "\n", "# Validation split not implemented for multi-host training.", "\n", "      ", "assert", "jax", ".", "host_count", "(", ")", "==", "1", "\n", "self", ".", "_train_ds", "=", "tfds", ".", "load", "(", "name", ",", "split", "=", "'train[:45000]'", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "name", ",", "split", "=", "'train[45000:]'", ")", ".", "cache", "(", ")", "\n", "self", ".", "num_training_obs", "=", "45000", "\n", "logging", ".", "info", "(", "'Used validation set instead of test set.'", ")", "\n", "", "self", ".", "_augmentation", "=", "image_level_augmentations", "\n", "if", "batch_level_augmentations", "==", "'cutout'", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "augmentation", ".", "cutout", "\n", "", "elif", "batch_level_augmentations", "==", "'mixup'", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "augmentation", ".", "mixup", "\n", "", "elif", "batch_level_augmentations", "==", "'mixcut'", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "(", "\n", "lambda", "x", ":", "augmentation", ".", "cutout", "(", "augmentation", ".", "mixup", "(", "x", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "None", "\n", "", "if", "name", "==", "'cifar10'", ":", "\n", "      ", "self", ".", "_image_mean", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.49139968", ",", "0.48215841", ",", "0.44653091", "]", "]", "]", ")", "\n", "self", ".", "_image_std", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.24703223", ",", "0.24348513", ",", "0.26158784", "]", "]", "]", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_image_mean", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.50707516", ",", "0.48654887", ",", "0.44091784", "]", "]", "]", ")", "\n", "self", ".", "_image_std", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.26733429", ",", "0.25643846", ",", "0.27615047", "]", "]", "]", ")", "\n", "", "self", ".", "_num_classes", "=", "None", "# To define in child classes", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.Cifar10.__init__": [[221, 228], ["dataset_source.CifarDatasetSource.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "image_level_augmentations", ":", "str", ",", "\n", "batch_level_augmentations", ":", "str", ",", "image_size", ":", "int", "=", "None", ")", ":", "\n", "    ", "\"\"\"See parent class for more information.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "batch_size", ",", "'cifar10'", ",", "image_level_augmentations", ",", "\n", "batch_level_augmentations", ",", "image_size", ")", "\n", "self", ".", "_num_classes", "=", "10", "\n", "self", ".", "_dataset_name", "=", "'cifar10'", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.Cifar100.__init__": [[233, 240], ["dataset_source.CifarDatasetSource.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "image_level_augmentations", ":", "str", ",", "\n", "batch_level_augmentations", ":", "str", ",", "image_size", ":", "int", "=", "None", ")", ":", "\n", "    ", "\"\"\"See parent class for more information.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "batch_size", ",", "'cifar100'", ",", "image_level_augmentations", ",", "\n", "batch_level_augmentations", ",", "image_size", ")", "\n", "self", ".", "_num_classes", "=", "100", "\n", "self", ".", "_dataset_name", "=", "'cifar100'", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.FashionMnist.__init__": [[245, 282], ["tensorflow.constant", "tensorflow.constant", "tensorflow_datasets.load().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow_datasets.load().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "image_level_augmentations", ":", "str", ",", "\n", "batch_level_augmentations", ":", "str", ")", ":", "\n", "    ", "\"\"\"Instantiates the DatasetSource.\n\n    Args:\n      batch_size: Batch size to use for training and evaluation.\n      image_level_augmentations: Augmentations to apply to the images. Should be\n        one of:\n        * none: No augmentations are applied.\n        * basic: Applies random crops and horizontal translations.\n      batch_level_augmentations: Augmentations to apply at the batch level.\n        * none: No augmentations are applied.\n        * cutout: Applies cutout (https://arxiv.org/abs/1708.04552).\n    \"\"\"", "\n", "assert", "image_level_augmentations", "in", "[", "'none'", ",", "'basic'", "]", "\n", "assert", "batch_level_augmentations", "in", "[", "'none'", ",", "'cutout'", "]", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_image_size", "=", "None", "\n", "if", "FLAGS", ".", "use_test_set", ":", "\n", "      ", "self", ".", "_train_ds", "=", "tfds", ".", "load", "(", "'fashion_mnist'", ",", "split", "=", "'train'", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "'fashion_mnist'", ",", "split", "=", "'test'", ")", ".", "cache", "(", ")", "\n", "logging", ".", "info", "(", "'Used test set instead of validation set.'", ")", "\n", "self", ".", "num_training_obs", "=", "60000", "\n", "", "else", ":", "\n", "      ", "self", ".", "_train_ds", "=", "tfds", ".", "load", "(", "'fashion_mnist'", ",", "split", "=", "'train[:54000]'", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "'fashion_mnist'", ",", "split", "=", "'train[54000:]'", ")", ".", "cache", "(", ")", "\n", "self", ".", "num_training_obs", "=", "54000", "\n", "logging", ".", "info", "(", "'Used validation set instead of test set.'", ")", "\n", "", "self", ".", "_augmentation", "=", "image_level_augmentations", "\n", "if", "batch_level_augmentations", "==", "'cutout'", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "augmentation", ".", "cutout", "\n", "", "else", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "None", "\n", "", "self", ".", "_image_mean", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.1307", "]", "]", "]", ")", "\n", "self", ".", "_image_std", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.3081", "]", "]", "]", ")", "\n", "self", ".", "_num_classes", "=", "10", "\n", "self", ".", "_dataset_name", "=", "'fashion_mnist'", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source.SVHN.__init__": [[287, 333], ["tensorflow.constant", "tensorflow.constant", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load.concatenate().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow_datasets.load", "tensorflow_datasets.load", "tensorflow_datasets.load.concatenate().cache", "tensorflow_datasets.load().cache", "absl.logging.info", "tensorflow_datasets.load.concatenate", "tensorflow_datasets.load", "tensorflow_datasets.load.concatenate", "tensorflow_datasets.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "image_level_augmentations", ":", "str", ",", "\n", "batch_level_augmentations", ":", "str", ")", ":", "\n", "    ", "\"\"\"Instantiates the DatasetSource.\n\n    Args:\n      batch_size: Batch size to use for training and evaluation.\n      image_level_augmentations: Augmentations to apply to the images. Should be\n        one of:\n        * none: No augmentations are applied.\n        * basic: Applies random crops and horizontal translations.\n        * autoaugment: Applies the best found policy for SVHN from the\n          AutoAugment paper. Also applies the basic augmentations on top of it.\n        * aa-only: Same as autoaugment but doesn't apply the basic\n          augmentations. Should be preferred for SVHN.\n      batch_level_augmentations: Augmentations to apply at the batch level.\n        * none: No augmentations are applied.\n        * cutout: Applies cutout (https://arxiv.org/abs/1708.04552).\n    \"\"\"", "\n", "assert", "image_level_augmentations", "in", "[", "\n", "'none'", ",", "'basic'", ",", "'autoaugment'", ",", "'aa-only'", "]", "\n", "assert", "batch_level_augmentations", "in", "[", "'none'", ",", "'cutout'", "]", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_image_size", "=", "None", "\n", "if", "FLAGS", ".", "use_test_set", ":", "\n", "      ", "ds_base", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'train'", ")", "\n", "ds_extra", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'extra'", ")", "\n", "self", ".", "_train_ds", "=", "ds_base", ".", "concatenate", "(", "ds_extra", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'test'", ")", ".", "cache", "(", ")", "\n", "logging", ".", "info", "(", "'Used test set instead of validation set.'", ")", "\n", "self", ".", "num_training_obs", "=", "73257", "+", "531131", "\n", "", "else", ":", "\n", "      ", "ds_base", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'train[:65929]'", ")", "\n", "ds_extra", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'extra'", ")", "\n", "self", ".", "_train_ds", "=", "ds_base", ".", "concatenate", "(", "ds_extra", ")", ".", "cache", "(", ")", "\n", "self", ".", "_test_ds", "=", "tfds", ".", "load", "(", "'svhn_cropped'", ",", "split", "=", "'train[65929:]'", ")", ".", "cache", "(", ")", "\n", "self", ".", "num_training_obs", "=", "65929", "+", "531131", "\n", "logging", ".", "info", "(", "'Used validation set instead of test set.'", ")", "\n", "", "self", ".", "_augmentation", "=", "image_level_augmentations", "\n", "if", "batch_level_augmentations", "==", "'cutout'", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "augmentation", ".", "cutout", "\n", "", "else", ":", "\n", "      ", "self", ".", "_batch_level_augmentations", "=", "None", "\n", "", "self", ".", "_image_mean", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.43090966", ",", "0.4302428", ",", "0.44634357", "]", "]", "]", ")", "\n", "self", ".", "_image_std", "=", "tf", ".", "constant", "(", "[", "[", "[", "0.19759192", ",", "0.20029082", ",", "0.19811132", "]", "]", "]", ")", "\n", "self", ".", "_num_classes", "=", "10", "\n", "self", ".", "_dataset_name", "=", "'svhn'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source._resize": [[64, 68], ["tensorflow.compat.v1.image.resize_bicubic", "tensorflow.image.resize"], "function", ["None"], ["", "", "def", "_resize", "(", "image", ":", "tf", ".", "Tensor", ",", "image_size", ":", "int", ",", "method", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "  ", "if", "method", "is", "not", "None", ":", "\n", "    ", "return", "tf", ".", "image", ".", "resize", "(", "image", ",", "[", "image_size", ",", "image_size", "]", ",", "method", ")", "\n", "", "return", "tf", ".", "compat", ".", "v1", ".", "image", ".", "resize_bicubic", "(", "image", ",", "[", "image_size", ",", "image_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.__init__": [[282, 300], ["dataset_source_imagenet.load_split", "dataset_source_imagenet.load_split"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.load_split", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.load_split"], ["def", "__init__", "(", "self", ",", "batch_size", ":", "int", ",", "image_size", ":", "int", ",", "\n", "image_level_augmentations", ":", "str", "=", "'none'", ")", ":", "\n", "    ", "\"\"\"Instantiates the Imagenet dataset source.\n\n    Args:\n      batch_size: Global batch size used to train the model.\n      image_size: Size to which the images should be resized (in number of\n        pixels).\n      image_level_augmentations: If set to 'autoaugment', will apply\n        RandAugment to the training set.\n    \"\"\"", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "image_size", "=", "image_size", "\n", "self", ".", "num_training_obs", "=", "TRAIN_IMAGES", "\n", "self", ".", "_train_ds", "=", "load_split", "(", "train", "=", "True", ",", "cache", "=", "True", ")", "\n", "self", ".", "_test_ds", "=", "load_split", "(", "train", "=", "False", ",", "cache", "=", "True", ")", "\n", "self", ".", "_num_classes", "=", "1000", "\n", "self", ".", "_image_level_augmentations", "=", "image_level_augmentations", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.get_train": [[301, 323], ["dataset_source_imagenet.Imagenet._train_ds.shuffle", "ds.map.map.map", "ds.map.map.batch", "batched.map.map.map", "dataset_source_imagenet.Imagenet.decode_example", "dataset_source_imagenet.mixup"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.decode_example", "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.mixup"], ["", "def", "get_train", "(", "self", ",", "use_augmentations", ":", "bool", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the training set.\n\n    The training set will be batched, and the remainder of the batch will be\n    dropped (except if use_augmentation is False, in which case we don't drop\n    the remainder as we are most likely computing the accuracy on the train\n    set).\n\n    Args:\n      use_augmentations: Whether we should apply data augmentation (and possibly\n        cutout) or not.\n    \"\"\"", "\n", "ds", "=", "self", ".", "_train_ds", ".", "shuffle", "(", "16", "*", "self", ".", "batch_size", ")", "\n", "ds", "=", "ds", ".", "map", "(", "lambda", "d", ":", "self", ".", "decode_example", "(", "# pylint:disable=g-long-lambda", "\n", "d", ",", "use_augmentations", "=", "use_augmentations", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "batched", "=", "ds", ".", "batch", "(", "self", ".", "batch_size", ",", "drop_remainder", "=", "use_augmentations", ")", "\n", "if", "use_augmentations", "and", "FLAGS", ".", "imagenet_mixup_alpha", ">", "0.0", ":", "\n", "      ", "batched", "=", "batched", ".", "map", "(", "lambda", "b", ":", "mixup", "(", "b", ",", "FLAGS", ".", "imagenet_mixup_alpha", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "", "return", "batched", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.get_test": [[324, 331], ["dataset_source_imagenet.Imagenet._test_ds.map", "dataset_source_imagenet.Imagenet.batch", "dataset_source_imagenet.Imagenet.decode_example"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.decode_example"], ["", "def", "get_test", "(", "self", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns test set.\"\"\"", "\n", "ds", "=", "self", ".", "_test_ds", ".", "map", "(", "\n", "lambda", "d", ":", "self", ".", "decode_example", "(", "# pylint:disable=g-long-lambda", "\n", "d", ",", "use_augmentations", "=", "False", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "return", "ds", ".", "batch", "(", "self", ".", "batch_size", ",", "drop_remainder", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.Imagenet.decode_example": [[332, 353], ["tensorflow.one_hot", "dataset_source_imagenet.preprocess_for_train", "dataset_source_imagenet.preprocess_for_eval"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.preprocess_for_train", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.preprocess_for_eval"], ["", "def", "decode_example", "(", "self", ",", "example", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ",", "\n", "use_augmentations", ":", "bool", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Decodes the raw examples from the imagenet tensorflow dataset.\n\n    Args:\n      example: A feature dict as returned by the tensorflow imagenet dataset.\n      use_augmentations: Whether to use train time data augmentation or not.\n\n    Returns:\n      A dictionnary with an 'image' tensor and a one hot encoded 'label' tensor.\n    \"\"\"", "\n", "if", "use_augmentations", ":", "\n", "      ", "image", "=", "preprocess_for_train", "(", "\n", "example", "[", "'image'", "]", ",", "\n", "image_size", "=", "self", ".", "image_size", ",", "\n", "use_autoaugment", "=", "self", ".", "_image_level_augmentations", "==", "'autoaugment'", ")", "\n", "", "else", ":", "\n", "      ", "image", "=", "preprocess_for_eval", "(", "example", "[", "'image'", "]", ",", "image_size", "=", "self", ".", "image_size", ")", "\n", "", "label", "=", "tf", ".", "one_hot", "(", "\n", "example", "[", "'label'", "]", ",", "depth", "=", "self", ".", "_num_classes", ",", "on_value", "=", "1.0", ",", "off_value", "=", "0.0", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "label", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._distorted_bounding_box_crop": [[54, 103], ["tensorflow.image.extract_jpeg_shape", "tensorflow.image.sample_distorted_bounding_box", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.stack", "tensorflow.image.decode_and_crop_jpeg"], "function", ["None"], ["def", "_distorted_bounding_box_crop", "(", "image_bytes", ":", "tf", ".", "Tensor", ",", "\n", "bbox", ":", "tf", ".", "Tensor", ",", "\n", "min_object_covered", ":", "float", "=", "0.1", ",", "\n", "aspect_ratio_range", ":", "Tuple", "[", "float", ",", "\n", "float", "]", "=", "(", "0.75", ",", "\n", "1.33", ")", ",", "\n", "area_range", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "0.05", ",", "1.0", ")", ",", "\n", "max_attempts", ":", "int", "=", "100", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n\n  See `tf.image.sample_distorted_bounding_box` for more documentation.\n\n  Args:\n    image_bytes: `Tensor` of binary image data.\n    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n        where each coordinate is [0, 1) and the coordinates are arranged\n        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n        image.\n    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n        area of the image must contain at least this fraction of any bounding\n        box supplied.\n    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n        image must have an aspect ratio = width / height within this range.\n    area_range: An optional list of `float`s. The cropped area of the image\n        must contain a fraction of the supplied image within in this range.\n    max_attempts: An optional `int`. Number of attempts at generating a cropped\n        region of the image of the specified constraints. After `max_attempts`\n        failures, return the entire image.\n  Returns:\n    cropped image `Tensor`\n  \"\"\"", "\n", "shape", "=", "tf", ".", "image", ".", "extract_jpeg_shape", "(", "image_bytes", ")", "\n", "sample_distorted_bounding_box", "=", "tf", ".", "image", ".", "sample_distorted_bounding_box", "(", "\n", "shape", ",", "\n", "bounding_boxes", "=", "bbox", ",", "\n", "min_object_covered", "=", "min_object_covered", ",", "\n", "aspect_ratio_range", "=", "aspect_ratio_range", ",", "\n", "area_range", "=", "area_range", ",", "\n", "max_attempts", "=", "max_attempts", ",", "\n", "use_image_if_no_bounding_boxes", "=", "True", ")", "\n", "bbox_begin", ",", "bbox_size", ",", "_", "=", "sample_distorted_bounding_box", "\n", "\n", "# Crop the image to the specified bounding box.", "\n", "offset_y", ",", "offset_x", ",", "_", "=", "tf", ".", "unstack", "(", "bbox_begin", ")", "\n", "target_height", ",", "target_width", ",", "_", "=", "tf", ".", "unstack", "(", "bbox_size", ")", "\n", "crop_window", "=", "tf", ".", "stack", "(", "[", "offset_y", ",", "offset_x", ",", "target_height", ",", "target_width", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_and_crop_jpeg", "(", "image_bytes", ",", "crop_window", ",", "channels", "=", "3", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._resize": [[105, 108], ["tensorflow.compat.v1.image.resize_bicubic"], "function", ["None"], ["", "def", "_resize", "(", "image", ":", "tf", ".", "Tensor", ",", "image_size", ":", "int", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Returns the resized image.\"\"\"", "\n", "return", "tf", ".", "compat", ".", "v1", ".", "image", ".", "resize_bicubic", "(", "[", "image", "]", ",", "[", "image_size", ",", "image_size", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._at_least_x_are_equal": [[110, 116], ["tensorflow.equal", "tensorflow.cast", "tensorflow.greater_equal", "tensorflow.reduce_sum"], "function", ["None"], ["", "def", "_at_least_x_are_equal", "(", "a", ":", "tf", ".", "Tensor", ",", "b", ":", "tf", ".", "Tensor", ",", "\n", "x", ":", "int", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"At least `x` of `a` and `b` `Tensors` are equal.\"\"\"", "\n", "match", "=", "tf", ".", "equal", "(", "a", ",", "b", ")", "\n", "match", "=", "tf", ".", "cast", "(", "match", ",", "tf", ".", "int32", ")", "\n", "return", "tf", ".", "greater_equal", "(", "tf", ".", "reduce_sum", "(", "match", ")", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._decode_and_random_crop": [[118, 136], ["tensorflow.constant", "dataset_source_imagenet._distorted_bounding_box_crop", "tensorflow.image.extract_jpeg_shape", "dataset_source_imagenet._at_least_x_are_equal", "tensorflow.cond", "tensorflow.shape", "dataset_source_imagenet._decode_and_center_crop", "dataset_source_imagenet._resize"], "function", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._distorted_bounding_box_crop", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._at_least_x_are_equal", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._decode_and_center_crop", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._resize"], ["", "def", "_decode_and_random_crop", "(", "image_bytes", ":", "tf", ".", "Tensor", ",", "\n", "image_size", ":", "int", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Make a random crop of image_size.\"\"\"", "\n", "bbox", "=", "tf", ".", "constant", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "1", ",", "1", ",", "4", "]", ")", "\n", "image", "=", "_distorted_bounding_box_crop", "(", "\n", "image_bytes", ",", "\n", "bbox", ",", "\n", "min_object_covered", "=", "0.1", ",", "\n", "aspect_ratio_range", "=", "(", "3.", "/", "4", ",", "4.", "/", "3.", ")", ",", "\n", "area_range", "=", "(", "0.08", ",", "1.0", ")", ",", "\n", "max_attempts", "=", "10", ")", "\n", "original_shape", "=", "tf", ".", "image", ".", "extract_jpeg_shape", "(", "image_bytes", ")", "\n", "bad", "=", "_at_least_x_are_equal", "(", "original_shape", ",", "tf", ".", "shape", "(", "image", ")", ",", "3", ")", "\n", "\n", "image", "=", "tf", ".", "cond", "(", "bad", ",", "lambda", ":", "_decode_and_center_crop", "(", "image_bytes", ",", "image_size", ")", ",", "\n", "lambda", ":", "_resize", "(", "image", ",", "image_size", ")", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._decode_and_center_crop": [[138, 158], ["tensorflow.image.extract_jpeg_shape", "tensorflow.cast", "tensorflow.stack", "tensorflow.image.decode_and_crop_jpeg", "dataset_source_imagenet._resize", "tensorflow.cast", "tensorflow.minimum"], "function", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._resize"], ["", "def", "_decode_and_center_crop", "(", "image_bytes", ":", "tf", ".", "Tensor", ",", "\n", "image_size", ":", "int", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Crops to center of image with padding then scales image_size.\"\"\"", "\n", "shape", "=", "tf", ".", "image", ".", "extract_jpeg_shape", "(", "image_bytes", ")", "\n", "image_height", "=", "shape", "[", "0", "]", "\n", "image_width", "=", "shape", "[", "1", "]", "\n", "\n", "padded_center_crop_size", "=", "tf", ".", "cast", "(", "\n", "(", "(", "image_size", "/", "(", "image_size", "+", "CROP_PADDING", ")", ")", "*", "\n", "tf", ".", "cast", "(", "tf", ".", "minimum", "(", "image_height", ",", "image_width", ")", ",", "tf", ".", "float32", ")", ")", ",", "\n", "tf", ".", "int32", ")", "\n", "\n", "offset_height", "=", "(", "(", "image_height", "-", "padded_center_crop_size", ")", "+", "1", ")", "//", "2", "\n", "offset_width", "=", "(", "(", "image_width", "-", "padded_center_crop_size", ")", "+", "1", ")", "//", "2", "\n", "crop_window", "=", "tf", ".", "stack", "(", "[", "offset_height", ",", "offset_width", ",", "\n", "padded_center_crop_size", ",", "padded_center_crop_size", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_and_crop_jpeg", "(", "image_bytes", ",", "crop_window", ",", "channels", "=", "3", ")", "\n", "image", "=", "_resize", "(", "image", ",", "image_size", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.normalize_image": [[160, 172], ["tensorflow.constant", "tensorflow.constant"], "function", ["None"], ["", "def", "normalize_image", "(", "image", ":", "tf", ".", "Tensor", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Returns the normalized image.\n\n  Image is normalized so that the mean and variance of each channel over the\n  dataset is 0 and 1.\n\n  Args:\n    image: An image from the Imagenet dataset to normalize.\n  \"\"\"", "\n", "image", "-=", "tf", ".", "constant", "(", "MEAN_RGB", ",", "shape", "=", "[", "1", ",", "1", ",", "3", "]", ",", "dtype", "=", "image", ".", "dtype", ")", "\n", "image", "/=", "tf", ".", "constant", "(", "STDDEV_RGB", ",", "shape", "=", "[", "1", ",", "1", ",", "3", "]", ",", "dtype", "=", "image", ".", "dtype", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.preprocess_for_train": [[174, 202], ["dataset_source_imagenet._decode_and_random_crop", "tensorflow.reshape", "tensorflow.image.random_flip_left_right", "dataset_source_imagenet.normalize_image", "tensorflow.image.convert_image_dtype", "absl.logging.info", "tensorflow.cast", "sam.autoaugment.autoaugment.distort_image_with_randaugment", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._decode_and_random_crop", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.normalize_image", "home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.distort_image_with_randaugment"], ["", "def", "preprocess_for_train", "(", "image_bytes", ":", "tf", ".", "Tensor", ",", "\n", "dtype", ":", "tf", ".", "DType", "=", "tf", ".", "float32", ",", "\n", "image_size", ":", "int", "=", "IMAGE_SIZE", ",", "\n", "use_autoaugment", ":", "bool", "=", "False", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Preprocesses the given image for training.\n\n  Args:\n    image_bytes: `Tensor` representing an image binary of arbitrary size.\n    dtype: Data type of the returned image.\n    image_size: Size of the returned image.\n    use_autoaugment: If True, will apply autoaugment to the inputs.\n\n  Returns:\n    A preprocessed image `Tensor`.\n  \"\"\"", "\n", "image", "=", "_decode_and_random_crop", "(", "image_bytes", ",", "image_size", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "if", "use_autoaugment", ":", "\n", "    ", "logging", ".", "info", "(", "'Using autoaugment.'", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "uint8", ")", "\n", "image", "=", "autoaugment", ".", "distort_image_with_randaugment", "(", "image", ",", "\n", "FLAGS", ".", "randaug_num_layers", ",", "\n", "FLAGS", ".", "randaug_magnitude", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "image", "=", "normalize_image", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "dtype", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.preprocess_for_eval": [[204, 222], ["dataset_source_imagenet._decode_and_center_crop", "tensorflow.reshape", "dataset_source_imagenet.normalize_image", "tensorflow.image.convert_image_dtype"], "function", ["home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet._decode_and_center_crop", "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.normalize_image"], ["", "def", "preprocess_for_eval", "(", "image_bytes", ":", "tf", ".", "Tensor", ",", "\n", "dtype", ":", "tf", ".", "DType", "=", "tf", ".", "float32", ",", "\n", "image_size", ":", "int", "=", "IMAGE_SIZE", ")", "->", "tf", ".", "Tensor", ":", "\n", "  ", "\"\"\"Preprocesses the given image for evaluation.\n\n  Args:\n    image_bytes: `Tensor` representing an image binary of arbitrary size.\n    dtype: Data type of the returned image.\n    image_size: Size of the returned image.\n\n  Returns:\n    A preprocessed image `Tensor`.\n  \"\"\"", "\n", "image", "=", "_decode_and_center_crop", "(", "image_bytes", ",", "image_size", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "image", "=", "normalize_image", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "dtype", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.load_split": [[224, 256], ["tensorflow_datasets.load", "ds.cache.cache", "jax.host_count", "jax.host_id", "ds.cache.options", "ds.cache.options", "tensorflow_datasets.decode.SkipDecoding"], "function", ["None"], ["", "def", "load_split", "(", "train", ":", "bool", ",", "\n", "cache", ":", "bool", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "  ", "\"\"\"Creates a split from the ImageNet dataset using TensorFlow Datasets.\n\n  Args:\n    train: Whether to load the train or evaluation split.\n    cache: Whether to cache the dataset.\n  Returns:\n    A `tf.data.Dataset`.\n  \"\"\"", "\n", "if", "train", ":", "\n", "    ", "split_size", "=", "TRAIN_IMAGES", "//", "jax", ".", "host_count", "(", ")", "\n", "start", "=", "jax", ".", "host_id", "(", ")", "*", "split_size", "\n", "split", "=", "'train[{}:{}]'", ".", "format", "(", "start", ",", "start", "+", "split_size", ")", "\n", "", "else", ":", "\n", "# For validation, we load up the dataset on each host. This will have the", "\n", "# effect of evaluating on the whole dataset num_host times, but will", "\n", "# prevent size issues. This makes the performance slightly worse when", "\n", "# evaluating often, but spares us the need to pad the datasets and mask the", "\n", "# loss accordingly.", "\n", "    ", "split", "=", "'validation'", "\n", "\n", "", "ds", "=", "tfds", ".", "load", "(", "'imagenet2012:5.*.*'", ",", "split", "=", "split", ",", "decoders", "=", "{", "\n", "'image'", ":", "tfds", ".", "decode", ".", "SkipDecoding", "(", ")", ",", "\n", "}", ")", "\n", "ds", ".", "options", "(", ")", ".", "experimental_threading", ".", "private_threadpool_size", "=", "48", "\n", "ds", ".", "options", "(", ")", ".", "experimental_threading", ".", "max_intra_op_parallelism", "=", "1", "\n", "\n", "if", "cache", ":", "\n", "    ", "ds", "=", "ds", ".", "cache", "(", ")", "\n", "\n", "", "return", "ds", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_imagenet.mixup": [[258, 277], ["tensorflow_probability.distributions.Beta().sample", "tensorflow.maximum", "tensorflow.reshape", "tensorflow_probability.distributions.Beta"], "function", ["None"], ["", "def", "mixup", "(", "batch", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ",", "alpha", ":", "float", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "  ", "\"\"\"Generates augmented images using Mixup.\n\n  Arguments:\n    batch: Feature dict containing the images and the labels.\n    alpha: Float that controls the strength of Mixup regularization.\n\n  Returns:\n    A feature dict containing the mix-uped images.\n  \"\"\"", "\n", "images", ",", "labels", "=", "batch", "[", "'image'", "]", ",", "batch", "[", "'label'", "]", "\n", "batch_size", "=", "1", "# Unique mixing parameter for all samples", "\n", "mix_weight", "=", "tfp", ".", "distributions", ".", "Beta", "(", "alpha", ",", "alpha", ")", ".", "sample", "(", "[", "batch_size", ",", "1", "]", ")", "\n", "mix_weight", "=", "tf", ".", "maximum", "(", "mix_weight", ",", "1.", "-", "mix_weight", ")", "\n", "images_mix_weight", "=", "tf", ".", "reshape", "(", "mix_weight", ",", "[", "batch_size", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "images_mix", "=", "(", "\n", "images", "*", "images_mix_weight", "+", "images", "[", ":", ":", "-", "1", "]", "*", "(", "1.", "-", "images_mix_weight", ")", ")", "\n", "labels_mix", "=", "labels", "*", "mix_weight", "+", "labels", "[", ":", ":", "-", "1", "]", "*", "(", "1.", "-", "mix_weight", ")", "\n", "return", "{", "'image'", ":", "images_mix", ",", "'label'", ":", "labels_mix", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.weak_image_augmentation": [[33, 58], ["tensorflow.image.random_flip_left_right", "tensorflow.shape", "tensorflow.pad", "tensorflow.image.random_crop"], "function", ["None"], ["def", "weak_image_augmentation", "(", "example", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ",", "\n", "random_crop_pad", ":", "int", "=", "4", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "  ", "\"\"\"Applies random crops and horizontal flips.\n\n  Simple data augmentations that are (almost) always used with cifar. Pad the\n  image with `random_crop_pad` before randomly cropping it to its original\n  size. Also randomly apply horizontal flip.\n\n  Args:\n    example: An example dict containing an image and a label.\n    random_crop_pad: By how many pixels should the image be padded on each side\n      before cropping.\n\n  Returns:\n    An example with the same label and an augmented version of the image.\n  \"\"\"", "\n", "image", ",", "label", "=", "example", "[", "'image'", "]", ",", "example", "[", "'label'", "]", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "image_shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "image", "=", "tf", ".", "pad", "(", "\n", "image", ",", "[", "[", "random_crop_pad", ",", "random_crop_pad", "]", ",", "\n", "[", "random_crop_pad", ",", "random_crop_pad", "]", ",", "[", "0", ",", "0", "]", "]", ",", "\n", "mode", "=", "'REFLECT'", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_crop", "(", "image", ",", "image_shape", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.auto_augmentation": [[60, 79], ["sam.autoaugment.autoaugment.distort_image_with_autoaugment"], "function", ["home.repos.pwc.inspect_result.google-research_sam.autoaugment.autoaugment.distort_image_with_autoaugment"], ["", "def", "auto_augmentation", "(", "example", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ",", "\n", "dataset_name", ":", "str", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "  ", "\"\"\"Applies the AutoAugment policy found for the dataset.\n\n  AutoAugment: Learning Augmentation Policies from Data\n  https://arxiv.org/abs/1805.09501\n\n  Args:\n    example: An example dict containing an image and a label.\n    dataset_name: Name of the dataset for which we should return the optimal\n      policy. Should be 'cifar[10|100]', 'svhn' or 'imagenet'.\n\n  Returns:\n    An example with the same label and an augmented version of the image.\n  \"\"\"", "\n", "if", "dataset_name", "in", "(", "'cifar10'", ",", "'cifar100'", ")", ":", "dataset_name", "=", "'cifar'", "\n", "image", ",", "label", "=", "example", "[", "'image'", "]", ",", "example", "[", "'label'", "]", "\n", "image", "=", "autoaugment", ".", "distort_image_with_autoaugment", "(", "image", ",", "dataset_name", ")", "\n", "return", "{", "'image'", ":", "image", ",", "'label'", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.cutout": [[81, 139], ["tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.pad", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.where", "tensorflow.squeeze", "tensorflow.shape", "tensorflow.zeros", "tensorflow.equal", "tensorflow.shape", "tensorflow.shape", "tensorflow.ones_like"], "function", ["None"], ["", "def", "cutout", "(", "batch", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "  ", "\"\"\"Applies cutout to a batch of images.\n\n  The cut out patch will be replaced by zeros (thus the batch should be\n  normalized before cutout is applied).\n\n  Reference:\n  Improved Regularization of Convolutional Neural Networks with Cutout\n  https://arxiv.org/abs/1708.04552\n\n  Implementation inspired by:\n  third_party/cloud_tpu/models/efficientnet/autoaugment.py\n\n  Args:\n    batch: A batch of images and labels.\n\n  Returns:\n    The same batch where cutout has been applied to the images.\n  \"\"\"", "\n", "length", ",", "replace", "=", "FLAGS", ".", "cutout_length", ",", "0.0", "\n", "images", ",", "labels", "=", "batch", "[", "'image'", "]", ",", "batch", "[", "'label'", "]", "\n", "num_channels", "=", "tf", ".", "shape", "(", "images", ")", "[", "3", "]", "\n", "image_height", ",", "image_width", "=", "tf", ".", "shape", "(", "images", ")", "[", "1", "]", ",", "tf", ".", "shape", "(", "images", ")", "[", "2", "]", "\n", "\n", "cutout_center_height", "=", "tf", ".", "random", ".", "uniform", "(", "\n", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_height", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "cutout_center_width", "=", "tf", ".", "random", ".", "uniform", "(", "\n", "shape", "=", "[", "]", ",", "minval", "=", "0", ",", "maxval", "=", "image_width", ",", "\n", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "lower_pad", "=", "tf", ".", "maximum", "(", "0", ",", "cutout_center_height", "-", "length", "//", "2", ")", "\n", "upper_pad", "=", "tf", ".", "maximum", "(", "0", ",", "image_height", "-", "cutout_center_height", "-", "length", "//", "2", ")", "\n", "left_pad", "=", "tf", ".", "maximum", "(", "0", ",", "cutout_center_width", "-", "length", "//", "2", ")", "\n", "right_pad", "=", "tf", ".", "maximum", "(", "0", ",", "image_width", "-", "cutout_center_width", "-", "length", "//", "2", ")", "\n", "\n", "cutout_shape", "=", "[", "image_height", "-", "(", "lower_pad", "+", "upper_pad", ")", ",", "\n", "image_width", "-", "(", "left_pad", "+", "right_pad", ")", "]", "\n", "\n", "padding_dims", "=", "[", "[", "lower_pad", ",", "upper_pad", "]", ",", "[", "left_pad", ",", "right_pad", "]", "]", "\n", "\n", "mask", "=", "tf", ".", "pad", "(", "\n", "tf", ".", "zeros", "(", "cutout_shape", ",", "dtype", "=", "images", ".", "dtype", ")", ",", "\n", "padding_dims", ",", "constant_values", "=", "1", ")", "\n", "\n", "patch", "=", "tf", ".", "ones_like", "(", "images", ",", "dtype", "=", "images", ".", "dtype", ")", "*", "replace", ",", "\n", "\n", "mask", "=", "tf", ".", "expand_dims", "(", "mask", ",", "-", "1", ")", "\n", "mask", "=", "tf", ".", "tile", "(", "mask", ",", "[", "1", ",", "1", ",", "num_channels", "]", ")", "\n", "\n", "images", "=", "tf", ".", "where", "(", "\n", "tf", ".", "equal", "(", "mask", ",", "0", ")", ",", "\n", "patch", ",", "\n", "images", ")", "\n", "\n", "images", "=", "tf", ".", "squeeze", "(", "images", ",", "axis", "=", "0", ")", "\n", "\n", "return", "{", "'image'", ":", "images", ",", "'label'", ":", "labels", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.augmentation.mixup": [[141, 161], ["tensorflow_probability.distributions.Beta().sample", "tensorflow.maximum", "tensorflow.reshape", "tensorflow_probability.distributions.Beta"], "function", ["None"], ["", "def", "mixup", "(", "batch", ":", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ",", "\n", "alpha", ":", "float", "=", "1.0", ")", "->", "Dict", "[", "str", ",", "tf", ".", "Tensor", "]", ":", "\n", "  ", "\"\"\"Generates augmented images using Mixup.\n\n  Arguments:\n    batch: Feature dict containing the images and the labels.\n    alpha: Float that controls the strength of Mixup regularization.\n\n  Returns:\n    A feature dict containing the images and labels augmented with mixup.\n  \"\"\"", "\n", "images", ",", "labels", "=", "batch", "[", "'image'", "]", ",", "batch", "[", "'label'", "]", "\n", "batch_size", "=", "1", "# Unique mixing parameter for all samples", "\n", "mix_weight", "=", "tfp", ".", "distributions", ".", "Beta", "(", "alpha", ",", "alpha", ")", ".", "sample", "(", "[", "batch_size", ",", "1", "]", ")", "\n", "mix_weight", "=", "tf", ".", "maximum", "(", "mix_weight", ",", "1.", "-", "mix_weight", ")", "\n", "images_mix_weight", "=", "tf", ".", "reshape", "(", "mix_weight", ",", "[", "batch_size", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "images_mix", "=", "(", "\n", "images", "*", "images_mix_weight", "+", "images", "[", ":", ":", "-", "1", "]", "*", "(", "1.", "-", "images_mix_weight", ")", ")", "\n", "labels_mix", "=", "labels", "*", "mix_weight", "+", "labels", "[", ":", ":", "-", "1", "]", "*", "(", "1.", "-", "mix_weight", ")", "\n", "return", "{", "'image'", ":", "images_mix", ",", "'label'", ":", "labels_mix", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_test.DatasetSourceTest.test_LoadCifar10": [[25, 41], ["absl.testing.parameterized.named_parameters", "sam.sam_jax.datasets.dataset_source.Cifar10", "sam.sam_jax.datasets.dataset_source.Cifar10.get_train", "sam.sam_jax.datasets.dataset_source.Cifar10.get_test", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test"], ["  ", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'none'", ",", "'none'", ")", ",", "\n", "(", "'cutout'", ",", "'cutout'", ")", ")", "\n", "def", "test_LoadCifar10", "(", "self", ",", "batch_level_augmentation", ":", "str", ")", ":", "\n", "    ", "cifar_10_source", "=", "dataset_source", ".", "Cifar10", "(", "\n", "2", ",", "\n", "image_level_augmentations", "=", "'autoaugment'", ",", "\n", "batch_level_augmentations", "=", "batch_level_augmentation", ")", "\n", "for", "batch", "in", "cifar_10_source", ".", "get_train", "(", "use_augmentations", "=", "True", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "10", "]", ")", "\n", "break", "\n", "", "for", "batch", "in", "cifar_10_source", ".", "get_test", "(", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "10", "]", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_test.DatasetSourceTest.test_LoadCifar100": [[42, 58], ["absl.testing.parameterized.named_parameters", "sam.sam_jax.datasets.dataset_source.Cifar100", "sam.sam_jax.datasets.dataset_source.Cifar100.get_train", "sam.sam_jax.datasets.dataset_source.Cifar100.get_test", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test"], ["", "", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'none'", ",", "'none'", ")", ",", "\n", "(", "'cutout'", ",", "'cutout'", ")", ")", "\n", "def", "test_LoadCifar100", "(", "self", ",", "batch_level_augmentation", ":", "str", ")", ":", "\n", "    ", "cifar_100_source", "=", "dataset_source", ".", "Cifar100", "(", "\n", "2", ",", "\n", "image_level_augmentations", "=", "'autoaugment'", ",", "\n", "batch_level_augmentations", "=", "batch_level_augmentation", ")", "\n", "for", "batch", "in", "cifar_100_source", ".", "get_train", "(", "use_augmentations", "=", "True", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "100", "]", ")", "\n", "break", "\n", "", "for", "batch", "in", "cifar_100_source", ".", "get_test", "(", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "100", "]", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.datasets.dataset_source_test.DatasetSourceTest.test_LoadFashionMnist": [[59, 75], ["absl.testing.parameterized.named_parameters", "sam.sam_jax.datasets.dataset_source.FashionMnist", "sam.sam_jax.datasets.dataset_source.FashionMnist.get_train", "sam.sam_jax.datasets.dataset_source.FashionMnist.get_test", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual", "dataset_source_test.DatasetSourceTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test"], ["", "", "@", "parameterized", ".", "named_parameters", "(", "\n", "(", "'none'", ",", "'none'", ")", ",", "\n", "(", "'cutout'", ",", "'cutout'", ")", ")", "\n", "def", "test_LoadFashionMnist", "(", "self", ",", "batch_level_augmentation", ":", "str", ")", ":", "\n", "    ", "fashion_mnist_source", "=", "dataset_source", ".", "FashionMnist", "(", "\n", "2", ",", "\n", "image_level_augmentations", "=", "'basic'", ",", "\n", "batch_level_augmentations", "=", "batch_level_augmentation", ")", "\n", "for", "batch", "in", "fashion_mnist_source", ".", "get_train", "(", "use_augmentations", "=", "True", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "10", "]", ")", "\n", "break", "\n", "", "for", "batch", "in", "fashion_mnist_source", ".", "get_test", "(", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "batch", "[", "'image'", "]", ".", "shape", ",", "[", "2", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "batch", "[", "'label'", "]", ".", "shape", ",", "[", "2", ",", "10", "]", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.local_replica_groups": [[95, 143], ["jax.device_count", "jax.device_count", "divmod", "flax_training.local_replica_groups.bounds_from_last_device"], "function", ["None"], ["def", "local_replica_groups", "(", "inner_group_size", ":", "int", ")", "->", "List", "[", "List", "[", "int", "]", "]", ":", "\n", "  ", "\"\"\"Constructs local nearest-neighbor rings given the JAX device assignment.\n\n  For inner_group_size=8, each inner group is a tray with replica order:\n\n  0/1 2/3\n  7/6 5/4\n\n  Args:\n    inner_group_size: Number of replica in each group.\n\n  Returns:\n    A list of replica id groups.\n  \"\"\"", "\n", "world_size", "=", "jax", ".", "device_count", "(", ")", "\n", "outer_group_size", ",", "ragged", "=", "divmod", "(", "world_size", ",", "inner_group_size", ")", "\n", "assert", "not", "ragged", ",", "'inner group size must evenly divide global device count'", "\n", "# the last device should have maximal x and y coordinate", "\n", "def", "bounds_from_last_device", "(", "device", ")", ":", "\n", "    ", "x", ",", "y", ",", "z", "=", "device", ".", "coords", "\n", "return", "(", "x", "+", "1", ")", "*", "(", "device", ".", "core_on_chip", "+", "1", ")", ",", "(", "y", "+", "1", ")", "*", "(", "z", "+", "1", ")", "\n", "", "global_x", ",", "_", "=", "bounds_from_last_device", "(", "jax", ".", "devices", "(", ")", "[", "-", "1", "]", ")", "\n", "per_host_x", ",", "per_host_y", "=", "bounds_from_last_device", "(", "jax", ".", "local_devices", "(", "0", ")", "[", "-", "1", "]", ")", "\n", "assert", "inner_group_size", "in", "[", "2", "**", "i", "for", "i", "in", "range", "(", "1", ",", "15", ")", "]", ",", "'inner group size must be a power of two'", "\n", "if", "inner_group_size", "<=", "4", ":", "\n", "# inner group is Nx1 (core, chip, 2x1)", "\n", "    ", "inner_x", ",", "inner_y", "=", "inner_group_size", ",", "1", "\n", "inner_perm", "=", "range", "(", "inner_group_size", ")", "\n", "", "else", ":", "\n", "    ", "if", "inner_group_size", "<=", "global_x", "*", "2", ":", "\n", "# inner group is Nx2 (2x2 tray, 4x2 DF pod host, row of hosts)", "\n", "      ", "inner_x", ",", "inner_y", "=", "inner_group_size", "//", "2", ",", "2", "\n", "", "else", ":", "\n", "# inner group covers the full x dimension and must be >2 in y", "\n", "      ", "inner_x", ",", "inner_y", "=", "global_x", ",", "inner_group_size", "//", "global_x", "\n", "", "p", "=", "np", ".", "arange", "(", "inner_group_size", ")", "\n", "per_group_hosts_x", "=", "1", "if", "inner_x", "<", "per_host_x", "else", "inner_x", "//", "per_host_x", "\n", "p", "=", "p", ".", "reshape", "(", "inner_y", "//", "per_host_y", ",", "per_group_hosts_x", ",", "\n", "per_host_y", ",", "inner_x", "//", "per_group_hosts_x", ")", "\n", "p", "=", "p", ".", "transpose", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "p", "=", "p", ".", "reshape", "(", "inner_y", "//", "2", ",", "2", ",", "inner_x", ")", "\n", "p", "[", ":", ",", "1", ",", ":", "]", "=", "p", "[", ":", ",", "1", ",", ":", ":", "-", "1", "]", "\n", "inner_perm", "=", "p", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "", "inner_replica_groups", "=", "[", "[", "o", "*", "inner_group_size", "+", "i", "for", "i", "in", "inner_perm", "]", "\n", "for", "o", "in", "range", "(", "outer_group_size", ")", "]", "\n", "return", "inner_replica_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint": [[145, 168], ["dict", "flax.training.checkpoints.restore_checkpoint"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint"], ["", "def", "restore_checkpoint", "(", "\n", "optimizer", ":", "flax", ".", "optim", ".", "Optimizer", ",", "\n", "model_state", ":", "Any", ",", "\n", "directory", ":", "str", ")", "->", "Tuple", "[", "flax", ".", "optim", ".", "Optimizer", ",", "flax", ".", "nn", ".", "Collection", ",", "int", "]", ":", "\n", "  ", "\"\"\"Restores a model and its state from a given checkpoint.\n\n  If several checkpoints are saved in the checkpoint directory, the latest one\n  will be loaded (based on the `epoch`).\n\n  Args:\n    optimizer: The optimizer containing the model that we are training.\n    model_state: Current state associated with the model.\n    directory: Directory where the checkpoints should be saved.\n\n  Returns:\n    The restored optimizer and model state, along with the number of epochs the\n      model was trained for.\n  \"\"\"", "\n", "train_state", "=", "dict", "(", "optimizer", "=", "optimizer", ",", "model_state", "=", "model_state", ",", "epoch", "=", "0", ")", "\n", "restored_state", "=", "checkpoints", ".", "restore_checkpoint", "(", "directory", ",", "train_state", ")", "\n", "return", "(", "restored_state", "[", "'optimizer'", "]", ",", "\n", "restored_state", "[", "'model_state'", "]", ",", "\n", "restored_state", "[", "'epoch'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint": [[170, 196], ["jax.tree_map", "jax.tree_map", "jax.tree_map", "jax.tree_map", "dict", "tensorflow.io.gfile.exists", "flax.training.checkpoints.save_checkpoint", "jax.host_id", "jax.host_id", "os.path.join", "tensorflow.io.gfile.remove", "jax.mean", "os.path.join", "str", "str"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint"], ["", "def", "save_checkpoint", "(", "optimizer", ":", "flax", ".", "optim", ".", "Optimizer", ",", "\n", "model_state", ":", "Any", ",", "\n", "directory", ":", "str", ",", "\n", "epoch", ":", "int", ")", ":", "\n", "  ", "\"\"\"Saves a model and its state.\n\n  Removes a checkpoint if it already exists for a given epoch. For multi-host\n  training, only the first host will save the checkpoint.\n\n  Args:\n    optimizer: The optimizer containing the model that we are training.\n    model_state: Current state associated with the model.\n    directory: Directory where the checkpoints should be saved.\n    epoch: Number of epochs the model has been trained for.\n  \"\"\"", "\n", "if", "jax", ".", "host_id", "(", ")", "!=", "0", ":", "\n", "    ", "return", "\n", "# Sync across replicas before saving.", "\n", "", "optimizer", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "optimizer", ")", "\n", "model_state", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "jnp", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", ",", "model_state", ")", "\n", "train_state", "=", "dict", "(", "optimizer", "=", "optimizer", ",", "\n", "model_state", "=", "model_state", ",", "\n", "epoch", "=", "epoch", ")", "\n", "if", "gfile", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'checkpoint_'", "+", "str", "(", "epoch", ")", ")", ")", ":", "\n", "    ", "gfile", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'checkpoint_'", "+", "str", "(", "epoch", ")", ")", ")", "\n", "", "checkpoints", ".", "save_checkpoint", "(", "directory", ",", "train_state", ",", "epoch", ",", "keep", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_optimizer": [[198, 223], ["optim.Momentum.create", "sam.sam_jax.efficientnet.optim.RMSProp", "flax.optim.Momentum"], "function", ["None"], ["", "def", "create_optimizer", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "\n", "learning_rate", ":", "float", ",", "\n", "beta", ":", "float", "=", "0.9", ")", "->", "flax", ".", "optim", ".", "Optimizer", ":", "\n", "  ", "\"\"\"Creates an optimizer.\n\n  Learning rate will be ignored when using a learning rate schedule.\n\n  Args:\n    model: The FLAX model to optimize.\n    learning_rate: Learning rate for the gradient descent.\n    beta: Momentum parameter.\n\n  Returns:\n    A SGD (or RMSProp) optimizer that targets the model.\n  \"\"\"", "\n", "if", "FLAGS", ".", "use_rmsprop", ":", "\n", "# We set beta2 and epsilon to the values used in the efficientnet paper.", "\n", "    ", "optimizer_def", "=", "efficientnet_optim", ".", "RMSProp", "(", "\n", "learning_rate", "=", "learning_rate", ",", "beta", "=", "beta", ",", "beta2", "=", "0.9", ",", "eps", "=", "0.001", ")", "\n", "", "else", ":", "\n", "    ", "optimizer_def", "=", "optim", ".", "Momentum", "(", "learning_rate", "=", "learning_rate", ",", "\n", "beta", "=", "beta", ",", "\n", "nesterov", "=", "True", ")", "\n", "", "optimizer", "=", "optimizer_def", ".", "create", "(", "model", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.cross_entropy_loss": [[225, 249], ["jax.nn.log_softmax", "jax.nn.log_softmax", "jnp.ones.reshape", "jax.nan_to_num", "jax.ones", "jnp.ones.sum", "jax.ones_like", "jax.sum"], "function", ["None"], ["", "def", "cross_entropy_loss", "(", "logits", ":", "jnp", ".", "ndarray", ",", "\n", "one_hot_labels", ":", "jnp", ".", "ndarray", ",", "\n", "mask", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Returns the cross entropy loss between some logits and some labels.\n\n  Args:\n    logits: Output of the model.\n    one_hot_labels: One-hot encoded labels. Dimensions should match the logits.\n    mask: Mask to apply to the loss to ignore some samples (usually, the padding\n      of the batch). Array of ones and zeros.\n\n  Returns:\n    The cross entropy, averaged over the first dimension (samples).\n  \"\"\"", "\n", "if", "FLAGS", ".", "label_smoothing", ">", "0", ":", "\n", "    ", "smoothing", "=", "jnp", ".", "ones_like", "(", "one_hot_labels", ")", "/", "one_hot_labels", ".", "shape", "[", "-", "1", "]", "\n", "one_hot_labels", "=", "(", "(", "1", "-", "FLAGS", ".", "label_smoothing", ")", "*", "one_hot_labels", "\n", "+", "FLAGS", ".", "label_smoothing", "*", "smoothing", ")", "\n", "", "log_softmax_logits", "=", "jax", ".", "nn", ".", "log_softmax", "(", "logits", ")", "\n", "if", "mask", "is", "None", ":", "\n", "    ", "mask", "=", "jnp", ".", "ones", "(", "[", "logits", ".", "shape", "[", "0", "]", "]", ")", "\n", "", "mask", "=", "mask", ".", "reshape", "(", "[", "logits", ".", "shape", "[", "0", "]", ",", "1", "]", ")", "\n", "loss", "=", "-", "jnp", ".", "sum", "(", "one_hot_labels", "*", "log_softmax_logits", "*", "mask", ")", "/", "mask", ".", "sum", "(", ")", "\n", "return", "jnp", ".", "nan_to_num", "(", "loss", ")", "# Set to zero if there is no non-masked samples.", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.error_rate_metric": [[251, 272], ["jnp.ones.reshape", "jax.nan_to_num", "jax.ones", "jnp.ones.sum", "jax.argmax", "jax.argmax"], "function", ["None"], ["", "def", "error_rate_metric", "(", "logits", ":", "jnp", ".", "ndarray", ",", "\n", "one_hot_labels", ":", "jnp", ".", "ndarray", ",", "\n", "mask", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Returns the error rate between some predictions and some labels.\n\n  Args:\n    logits: Output of the model.\n    one_hot_labels: One-hot encoded labels. Dimensions should match the logits.\n    mask: Mask to apply to the loss to ignore some samples (usually, the padding\n      of the batch). Array of ones and zeros.\n\n  Returns:\n    The error rate (1 - accuracy), averaged over the first dimension (samples).\n  \"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "    ", "mask", "=", "jnp", ".", "ones", "(", "[", "logits", ".", "shape", "[", "0", "]", "]", ")", "\n", "", "mask", "=", "mask", ".", "reshape", "(", "[", "logits", ".", "shape", "[", "0", "]", "]", ")", "\n", "error_rate", "=", "(", "(", "(", "jnp", ".", "argmax", "(", "logits", ",", "-", "1", ")", "!=", "jnp", ".", "argmax", "(", "one_hot_labels", ",", "-", "1", ")", ")", ")", "*", "\n", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "# Set to zero if there is no non-masked samples.", "\n", "return", "jnp", ".", "nan_to_num", "(", "error_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.top_k_error_rate_metric": [[274, 299], ["jnp.ones.reshape", "jax.argmax().reshape", "jax.nan_to_num", "jax.ones", "jax.argsort", "jax.vmap", "jax.vmap", "jax.argmax", "jnp.ones.sum"], "function", ["None"], ["", "def", "top_k_error_rate_metric", "(", "logits", ":", "jnp", ".", "ndarray", ",", "\n", "one_hot_labels", ":", "jnp", ".", "ndarray", ",", "\n", "k", ":", "int", "=", "5", ",", "\n", "mask", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Returns the top-K error rate between some predictions and some labels.\n\n  Args:\n    logits: Output of the model.\n    one_hot_labels: One-hot encoded labels. Dimensions should match the logits.\n    k: Number of class the model is allowed to predict for each example.\n    mask: Mask to apply to the loss to ignore some samples (usually, the padding\n      of the batch). Array of ones and zeros.\n\n  Returns:\n    The error rate (1 - accuracy), averaged over the first dimension (samples).\n  \"\"\"", "\n", "if", "mask", "is", "None", ":", "\n", "    ", "mask", "=", "jnp", ".", "ones", "(", "[", "logits", ".", "shape", "[", "0", "]", "]", ")", "\n", "", "mask", "=", "mask", ".", "reshape", "(", "[", "logits", ".", "shape", "[", "0", "]", "]", ")", "\n", "true_labels", "=", "jnp", ".", "argmax", "(", "one_hot_labels", ",", "-", "1", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "top_k_preds", "=", "jnp", ".", "argsort", "(", "logits", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "k", ":", "]", "\n", "hit", "=", "jax", ".", "vmap", "(", "jnp", ".", "isin", ")", "(", "true_labels", ",", "top_k_preds", ")", "\n", "error_rate", "=", "1", "-", "(", "(", "hit", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", ")", "\n", "# Set to zero if there is no non-masked samples.", "\n", "return", "jnp", ".", "nan_to_num", "(", "error_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.tensorflow_to_numpy": [[301, 315], ["jax.tree_map", "jax.tree_map", "x._numpy"], "function", ["None"], ["", "def", "tensorflow_to_numpy", "(", "xs", ")", ":", "\n", "  ", "\"\"\"Converts a tree of tensorflow tensors to numpy arrays.\n\n  Args:\n    xs: A pytree (such as nested tuples, lists, and dicts) where the leaves are\n      tensorflow tensors.\n\n  Returns:\n    A pytree with the same structure as xs, where the leaves have been converted\n      to jax numpy ndarrays.\n  \"\"\"", "\n", "# Use _numpy() for zero-copy conversion between TF and NumPy.", "\n", "xs", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", ".", "_numpy", "(", ")", ",", "xs", ")", "# pylint: disable=protected-access", "\n", "return", "xs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.shard_batch": [[317, 335], ["jax.local_device_count", "jax.local_device_count", "jax.tree_map", "jax.tree_map", "x.reshape"], "function", ["None"], ["", "def", "shard_batch", "(", "xs", ")", ":", "\n", "  ", "\"\"\"Shards a batch across all available replicas.\n\n  Assumes that the number of samples (first dimension of xs) is divisible by the\n  number of available replicas.\n\n  Args:\n    xs: A pytree (such as nested tuples, lists, and dicts) where the leaves are\n      numpy ndarrays.\n\n  Returns:\n    A pytree with the same structure as xs, where the leaves where added a\n      leading dimension representing the replica the tensor is on.\n  \"\"\"", "\n", "local_device_count", "=", "jax", ".", "local_device_count", "(", ")", "\n", "def", "_prepare", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "reshape", "(", "(", "local_device_count", ",", "-", "1", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "\n", "", "return", "jax", ".", "tree_map", "(", "_prepare", ",", "xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.load_and_shard_tf_batch": [[337, 349], ["flax_training.shard_batch", "flax_training.tensorflow_to_numpy"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.shard_batch", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.tensorflow_to_numpy"], ["", "def", "load_and_shard_tf_batch", "(", "xs", ")", ":", "\n", "  ", "\"\"\"Converts to numpy arrays and distribute a tensorflow batch.\n\n  Args:\n    xs: A pytree (such as nested tuples, lists, and dicts) where the leaves are\n      tensorflow tensors.\n\n  Returns:\n    A pytree of numpy ndarrays with the same structure as xs, where the leaves\n      where added a leading dimension representing the replica the tensor is on.\n  \"\"\"", "\n", "return", "shard_batch", "(", "tensorflow_to_numpy", "(", "xs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_exponential_learning_rate_schedule": [[351, 375], ["jax.minimum", "jax.exp"], "function", ["None"], ["", "def", "create_exponential_learning_rate_schedule", "(", "\n", "base_learning_rate", ":", "float", ",", "\n", "steps_per_epoch", ":", "int", ",", "\n", "lamba", ":", "float", ",", "\n", "warmup_epochs", ":", "int", "=", "0", ")", "->", "Callable", "[", "[", "int", "]", ",", "float", "]", ":", "\n", "  ", "\"\"\"Creates a exponential learning rate schedule with optional warmup.\n\n  Args:\n    base_learning_rate: The base learning rate.\n    steps_per_epoch: The number of iterations per epoch.\n    lamba: Decay is v0 * exp(-t / lambda).\n    warmup_epochs: Number of warmup epoch. The learning rate will be modulated\n      by a linear function going from 0 initially to 1 after warmup_epochs\n      epochs.\n\n  Returns:\n    Function `f(step) -> lr` that computes the learning rate for a given step.\n  \"\"\"", "\n", "def", "learning_rate_fn", "(", "step", ")", ":", "\n", "    ", "t", "=", "step", "/", "steps_per_epoch", "\n", "return", "base_learning_rate", "*", "jnp", ".", "exp", "(", "-", "t", "/", "lamba", ")", "*", "jnp", ".", "minimum", "(", "\n", "t", "/", "warmup_epochs", ",", "1", ")", "\n", "\n", "", "return", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.get_cosine_schedule": [[377, 397], ["int", "flax.training.lr_schedule.create_cosine_learning_rate_schedule", "math.floor", "jax.host_count", "jax.host_count", "sam.sam_jax.datasets.dataset_source.num_training_obs", "sam.sam_jax.datasets.dataset_source.batch_size"], "function", ["None"], ["", "def", "get_cosine_schedule", "(", "num_epochs", ":", "int", ",", "learning_rate", ":", "float", ",", "\n", "num_training_obs", ":", "int", ",", "\n", "batch_size", ":", "int", ")", "->", "Callable", "[", "[", "int", "]", ",", "float", "]", ":", "\n", "  ", "\"\"\"Returns a cosine learning rate schedule, without warm up.\n\n  Args:\n    num_epochs: Number of epochs the model will be trained for.\n    learning_rate: Initial learning rate.\n    num_training_obs: Number of training observations.\n    batch_size: Total batch size (number of samples seen per gradient step).\n\n  Returns:\n    A function that takes as input the current step and returns the learning\n      rate to use.\n  \"\"\"", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "floor", "(", "num_training_obs", "/", "batch_size", ")", ")", "\n", "learning_rate_fn", "=", "lr_schedule", ".", "create_cosine_learning_rate_schedule", "(", "\n", "learning_rate", ",", "steps_per_epoch", "//", "jax", ".", "host_count", "(", ")", ",", "num_epochs", ",", "\n", "warmup_length", "=", "0", ")", "\n", "return", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.get_exponential_schedule": [[399, 422], ["int", "flax_training.create_exponential_learning_rate_schedule", "math.floor", "math.log", "jax.host_count", "jax.host_count", "sam.sam_jax.datasets.dataset_source.num_training_obs", "sam.sam_jax.datasets.dataset_source.batch_size"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_exponential_learning_rate_schedule"], ["", "def", "get_exponential_schedule", "(", "num_epochs", ":", "int", ",", "learning_rate", ":", "float", ",", "\n", "num_training_obs", ":", "int", ",", "\n", "batch_size", ":", "int", ")", "->", "Callable", "[", "[", "int", "]", ",", "float", "]", ":", "\n", "  ", "\"\"\"Returns an exponential learning rate schedule, without warm up.\n\n  Args:\n    num_epochs: Number of epochs the model will be trained for.\n    learning_rate: Initial learning rate.\n    num_training_obs: Number of training observations.\n    batch_size: Total batch size (number of samples seen per gradient step).\n\n  Returns:\n    A function that takes as input the current step and returns the learning\n      rate to use.\n  \"\"\"", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "floor", "(", "num_training_obs", "/", "batch_size", ")", ")", "\n", "# At the end of the training, lr should be 1.2% of original value", "\n", "# This mimic the behavior from the efficientnet paper.", "\n", "end_lr_ratio", "=", "0.012", "\n", "lamba", "=", "-", "num_epochs", "/", "math", ".", "log", "(", "end_lr_ratio", ")", "\n", "learning_rate_fn", "=", "create_exponential_learning_rate_schedule", "(", "\n", "learning_rate", ",", "steps_per_epoch", "//", "jax", ".", "host_count", "(", ")", ",", "lamba", ")", "\n", "return", "learning_rate_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.global_norm": [[424, 432], ["jax.sqrt", "sum", "jax.sum", "jax.square", "jax.tree_leaves", "jax.tree_leaves"], "function", ["None"], ["", "def", "global_norm", "(", "updates", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Returns the l2 norm of the input.\n\n  Args:\n    updates: A pytree of ndarrays representing the gradient.\n  \"\"\"", "\n", "return", "jnp", ".", "sqrt", "(", "\n", "sum", "(", "[", "jnp", ".", "sum", "(", "jnp", ".", "square", "(", "x", ")", ")", "for", "x", "in", "jax", ".", "tree_leaves", "(", "updates", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.clip_by_global_norm": [[434, 452], ["flax_training.global_norm", "jax.tree_multimap", "jax.tree_multimap", "jax.where"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.global_norm"], ["", "def", "clip_by_global_norm", "(", "updates", ")", ":", "\n", "  ", "\"\"\"Clips the gradient by global norm.\n\n  Will have no effect if FLAGS.gradient_clipping is set to zero (no clipping).\n\n  Args:\n    updates: A pytree of numpy ndarray representing the gradient.\n\n  Returns:\n    The gradient clipped by global norm.\n  \"\"\"", "\n", "if", "FLAGS", ".", "gradient_clipping", ">", "0", ":", "\n", "    ", "g_norm", "=", "global_norm", "(", "updates", ")", "\n", "trigger", "=", "g_norm", "<", "FLAGS", ".", "gradient_clipping", "\n", "updates", "=", "jax", ".", "tree_multimap", "(", "\n", "lambda", "t", ":", "jnp", ".", "where", "(", "trigger", ",", "t", ",", "(", "t", "/", "g_norm", ")", "*", "FLAGS", ".", "gradient_clipping", ")", ",", "\n", "updates", ")", "\n", "", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.dual_vector": [[454, 464], ["jax.sqrt", "jax.tree_map", "jax.tree_map", "sum", "jax.sum", "jax.square", "jax.tree_util.tree_leaves", "jax.tree_util.tree_leaves"], "function", ["None"], ["", "def", "dual_vector", "(", "y", ":", "jnp", ".", "ndarray", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Returns the solution of max_x y^T x s.t. ||x||_2 <= 1.\n\n  Args:\n    y: A pytree of numpy ndarray, vector y in the equation above.\n  \"\"\"", "\n", "gradient_norm", "=", "jnp", ".", "sqrt", "(", "sum", "(", "\n", "[", "jnp", ".", "sum", "(", "jnp", ".", "square", "(", "e", ")", ")", "for", "e", "in", "jax", ".", "tree_util", ".", "tree_leaves", "(", "y", ")", "]", ")", ")", "\n", "normalized_gradient", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", "/", "gradient_norm", ",", "y", ")", "\n", "return", "normalized_gradient", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train_step": [[466, 584], ["flax_training.create_exponential_learning_rate_schedule.learning_rate_fn", "jax.lax.pmean", "jax.lax.pmean", "flax_training.clip_by_global_norm", "optimizer.apply_gradient", "jax.sqrt", "jax.sqrt", "flax_training.cross_entropy_loss", "jax.tree_leaves", "jax.tree_leaves", "flax_training.dual_vector", "jax.tree_multimap", "jax.tree_multimap", "flax_training.train_step.get_sam_gradient"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.clip_by_global_norm", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.cross_entropy_loss", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.dual_vector"], ["", "def", "train_step", "(", "\n", "optimizer", ":", "flax", ".", "optim", ".", "Optimizer", ",", "\n", "state", ":", "flax", ".", "nn", ".", "Collection", ",", "\n", "batch", ":", "Dict", "[", "str", ",", "jnp", ".", "ndarray", "]", ",", "\n", "prng_key", ":", "jnp", ".", "ndarray", ",", "\n", "learning_rate_fn", ":", "Callable", "[", "[", "int", "]", ",", "float", "]", ",", "\n", "l2_reg", ":", "float", "\n", ")", "->", "Tuple", "[", "flax", ".", "optim", ".", "Optimizer", ",", "flax", ".", "nn", ".", "Collection", ",", "Dict", "[", "str", ",", "float", "]", ",", "float", "]", ":", "\n", "  ", "\"\"\"Performs one gradient step.\n\n  Args:\n    optimizer: The optimizer targeting the model to train.\n    state: Current state associated with the model (contains the batch norm MA).\n    batch: Batch on which the gradient should be computed. Must have an `image`\n      and `label` key. Masks will not be used for training, so the batch is\n      expected to be full (with any potential remainder dropped).\n    prng_key: A PRNG key to use for stochasticity for this gradient step (e.g.\n      for sampling an eventual dropout mask).\n    learning_rate_fn: Function that takes the current step as input and return\n      the learning rate to use.\n    l2_reg: Weight decay parameter. The total weight decay penaly added to the\n      loss is equal to 0.5 * l2_reg * sum_i ||w_i||_2^2 where the sum is over\n      all trainable parameters of the model (bias and batch norm parameters\n      included).\n\n  Returns:\n    The updated optimizer (that includes the model), the updated state and\n      a dictionary containing the training loss and error rate on the batch.\n  \"\"\"", "\n", "\n", "def", "forward_and_loss", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "true_gradient", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Returns the model's loss, updated state and predictions.\n\n    Args:\n      model: The model that we are training.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass for the Shake Shake and Shake Drop\n        regularization (see papers for more details).\n    \"\"\"", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ")", "as", "new_state", ":", "\n", "      ", "with", "flax", ".", "nn", ".", "stochastic", "(", "prng_key", ")", ":", "\n", "        ", "try", ":", "\n", "          ", "logits", "=", "model", "(", "\n", "batch", "[", "'image'", "]", ",", "train", "=", "True", ",", "true_gradient", "=", "true_gradient", ")", "\n", "", "except", "TypeError", ":", "\n", "          ", "logits", "=", "model", "(", "batch", "[", "'image'", "]", ",", "train", "=", "True", ")", "\n", "", "", "", "loss", "=", "cross_entropy_loss", "(", "logits", ",", "batch", "[", "'label'", "]", ")", "\n", "# We apply weight decay to all parameters, including bias and batch norm", "\n", "# parameters.", "\n", "weight_penalty_params", "=", "jax", ".", "tree_leaves", "(", "model", ".", "params", ")", "\n", "if", "FLAGS", ".", "no_weight_decay_on_bn", ":", "\n", "      ", "weight_l2", "=", "sum", "(", "\n", "[", "jnp", ".", "sum", "(", "x", "**", "2", ")", "for", "x", "in", "weight_penalty_params", "if", "x", ".", "ndim", ">", "1", "]", ")", "\n", "", "else", ":", "\n", "      ", "weight_l2", "=", "sum", "(", "[", "jnp", ".", "sum", "(", "x", "**", "2", ")", "for", "x", "in", "weight_penalty_params", "]", ")", "\n", "", "weight_penalty", "=", "l2_reg", "*", "0.5", "*", "weight_l2", "\n", "loss", "=", "loss", "+", "weight_penalty", "\n", "return", "loss", ",", "(", "new_state", ",", "logits", ")", "\n", "\n", "", "step", "=", "optimizer", ".", "state", ".", "step", "\n", "\n", "def", "get_sam_gradient", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "rho", ":", "float", ")", ":", "\n", "    ", "\"\"\"Returns the gradient of the SAM loss loss, updated state and logits.\n\n    See https://arxiv.org/abs/2010.01412 for more details.\n\n    Args:\n      model: The model that we are training.\n      rho: Size of the perturbation.\n    \"\"\"", "\n", "# compute gradient on the whole batch", "\n", "(", "_", ",", "(", "inner_state", ",", "_", ")", ")", ",", "grad", "=", "jax", ".", "value_and_grad", "(", "\n", "lambda", "m", ":", "forward_and_loss", "(", "m", ",", "true_gradient", "=", "True", ")", ",", "has_aux", "=", "True", ")", "(", "model", ")", "\n", "if", "FLAGS", ".", "sync_perturbations", ":", "\n", "      ", "if", "FLAGS", ".", "inner_group_size", "is", "None", ":", "\n", "        ", "grad", "=", "jax", ".", "lax", ".", "pmean", "(", "grad", ",", "'batch'", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "jax", ".", "lax", ".", "pmean", "(", "\n", "grad", ",", "'batch'", ",", "\n", "axis_index_groups", "=", "local_replica_groups", "(", "FLAGS", ".", "inner_group_size", ")", ")", "\n", "", "", "grad", "=", "dual_vector", "(", "grad", ")", "\n", "noised_model", "=", "jax", ".", "tree_multimap", "(", "lambda", "a", ",", "b", ":", "a", "+", "rho", "*", "b", ",", "\n", "model", ",", "grad", ")", "\n", "(", "_", ",", "(", "_", ",", "logits", ")", ")", ",", "grad", "=", "jax", ".", "value_and_grad", "(", "\n", "forward_and_loss", ",", "has_aux", "=", "True", ")", "(", "noised_model", ")", "\n", "return", "(", "inner_state", ",", "logits", ")", ",", "grad", "\n", "\n", "", "lr", "=", "learning_rate_fn", "(", "step", ")", "\n", "rho", "=", "FLAGS", ".", "sam_rho", "\n", "\n", "if", "rho", ">", "0", ":", "# SAM loss", "\n", "    ", "(", "new_state", ",", "logits", ")", ",", "grad", "=", "get_sam_gradient", "(", "optimizer", ".", "target", ",", "rho", ")", "\n", "", "else", ":", "# Standard SGD", "\n", "    ", "(", "_", ",", "(", "new_state", ",", "logits", ")", ")", ",", "grad", "=", "jax", ".", "value_and_grad", "(", "\n", "forward_and_loss", ",", "has_aux", "=", "True", ")", "(", "\n", "optimizer", ".", "target", ")", "\n", "\n", "# We synchronize the gradients across replicas by averaging them.", "\n", "", "grad", "=", "jax", ".", "lax", ".", "pmean", "(", "grad", ",", "'batch'", ")", "\n", "\n", "# Gradient is clipped after being synchronized.", "\n", "grad", "=", "clip_by_global_norm", "(", "grad", ")", "\n", "new_optimizer", "=", "optimizer", ".", "apply_gradient", "(", "grad", ",", "learning_rate", "=", "lr", ")", "\n", "\n", "# Compute some norms to log on tensorboard.", "\n", "gradient_norm", "=", "jnp", ".", "sqrt", "(", "sum", "(", "\n", "[", "jnp", ".", "sum", "(", "jnp", ".", "square", "(", "e", ")", ")", "for", "e", "in", "jax", ".", "tree_util", ".", "tree_leaves", "(", "grad", ")", "]", ")", ")", "\n", "param_norm", "=", "jnp", ".", "sqrt", "(", "sum", "(", "\n", "[", "jnp", ".", "sum", "(", "jnp", ".", "square", "(", "e", ")", ")", "for", "e", "in", "jax", ".", "tree_util", ".", "tree_leaves", "(", "\n", "new_optimizer", ".", "target", ")", "]", ")", ")", "\n", "\n", "# Compute some metrics to monitor the training.", "\n", "metrics", "=", "{", "'train_error_rate'", ":", "error_rate_metric", "(", "logits", ",", "batch", "[", "'label'", "]", ")", ",", "\n", "'train_loss'", ":", "cross_entropy_loss", "(", "logits", ",", "batch", "[", "'label'", "]", ")", ",", "\n", "'gradient_norm'", ":", "gradient_norm", ",", "\n", "'param_norm'", ":", "param_norm", "}", "\n", "\n", "return", "new_optimizer", ",", "new_state", ",", "metrics", ",", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.eval_step": [[599, 642], ["jax.lax.pmean", "jax.lax.pmean", "batch.get", "jax.lax.psum", "jax.lax.psum", "flax.nn.stateful", "model", "batch[].sum", "jax.lax.psum.update", "flax_training.error_rate_metric", "flax_training.cross_entropy_loss", "flax_training.top_k_error_rate_metric"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.error_rate_metric", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.cross_entropy_loss", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.top_k_error_rate_metric"], ["def", "eval_step", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "state", ":", "flax", ".", "nn", ".", "Collection", ",", "\n", "batch", ":", "Dict", "[", "str", ",", "jnp", ".", "ndarray", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "  ", "\"\"\"Evaluates the model on a single batch.\n\n  Args:\n    model: The model to evaluate.\n    state: Current state associated with the model (contains the batch norm MA).\n    batch: Batch on which the model should be evaluated. Must have an `image`\n      and `label` key.\n\n  Returns:\n    A dictionary containing the loss and error rate on the batch. These metrics\n    are summed over the samples (and not averaged).\n  \"\"\"", "\n", "\n", "# Averages the batch norm moving averages.", "\n", "state", "=", "jax", ".", "lax", ".", "pmean", "(", "state", ",", "'batch'", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ",", "mutable", "=", "False", ")", ":", "\n", "    ", "logits", "=", "model", "(", "batch", "[", "'image'", "]", ",", "train", "=", "False", ")", "\n", "\n", "# Because we don't have a guarantee that all batches contains the same number", "\n", "# of samples, we can't average the metrics per batch and then average the", "\n", "# resulting values. To compute the metrics correctly, we sum them (error rate", "\n", "# and cross entropy returns means, thus we multiply by the number of samples),", "\n", "# and finally sum across replicas. These sums will be divided by the total", "\n", "# number of samples outside of this function.", "\n", "", "num_samples", "=", "(", "batch", "[", "'image'", "]", ".", "shape", "[", "0", "]", "if", "'mask'", "not", "in", "batch", "\n", "else", "batch", "[", "'mask'", "]", ".", "sum", "(", ")", ")", "\n", "mask", "=", "batch", ".", "get", "(", "'mask'", ",", "None", ")", "\n", "labels", "=", "batch", "[", "'label'", "]", "\n", "metrics", "=", "{", "\n", "'error_rate'", ":", "\n", "error_rate_metric", "(", "logits", ",", "labels", ",", "mask", ")", "*", "num_samples", ",", "\n", "'loss'", ":", "\n", "cross_entropy_loss", "(", "logits", ",", "labels", ",", "mask", ")", "*", "num_samples", "\n", "}", "\n", "if", "FLAGS", ".", "compute_top_5_error_rate", ":", "\n", "    ", "metrics", ".", "update", "(", "{", "\n", "'top_5_error_rate'", ":", "\n", "top_k_error_rate_metric", "(", "logits", ",", "labels", ",", "5", ",", "mask", ")", "*", "num_samples", "\n", "}", ")", "\n", "", "metrics", "=", "jax", ".", "lax", ".", "psum", "(", "metrics", ",", "'batch'", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.eval_on_dataset": [[650, 693], ["jax.pmap", "jax.pmap", "flax.training.common_utils.get_metrics", "jax.tree_map", "jax.tree_map", "flax_training.load_and_shard_tf_batch", "pmapped_eval_step", "common_utils.get_metrics.append", "jax.lax.psum", "jax.lax.psum", "[].sum", "jax.host_count", "jax.host_count", "x.sum", "jax.pmap."], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.load_and_shard_tf_batch"], ["def", "eval_on_dataset", "(", "\n", "model", ":", "flax", ".", "nn", ".", "Model", ",", "state", ":", "flax", ".", "nn", ".", "Collection", ",", "dataset", ":", "tf", ".", "data", ".", "Dataset", ",", "\n", "pmapped_eval_step", ":", "_EvalStep", ")", ":", "\n", "  ", "\"\"\"Evaluates the model on the whole dataset.\n\n  Args:\n    model: The model to evaluate.\n    state: Current state associated with the model (contains the batch norm MA).\n    dataset: Dataset on which the model should be evaluated. Should already\n      being batched.\n    pmapped_eval_step: A pmapped version of the `eval_step` function (see its\n      documentation for more details).\n\n  Returns:\n    A dictionary containing the loss and error rate on the batch. These metrics\n    are averaged over the samples.\n  \"\"\"", "\n", "eval_metrics", "=", "[", "]", "\n", "total_num_samples", "=", "0", "\n", "all_host_psum", "=", "jax", ".", "pmap", "(", "lambda", "x", ":", "jax", ".", "lax", ".", "psum", "(", "x", ",", "'i'", ")", ",", "'i'", ")", "\n", "\n", "for", "eval_batch", "in", "dataset", ":", "\n", "# Load and shard the TF batch.", "\n", "    ", "eval_batch", "=", "load_and_shard_tf_batch", "(", "eval_batch", ")", "\n", "# Compute metrics and sum over all observations in the batch.", "\n", "metrics", "=", "pmapped_eval_step", "(", "model", ",", "state", ",", "eval_batch", ")", "\n", "eval_metrics", ".", "append", "(", "metrics", ")", "\n", "if", "'mask'", "not", "in", "eval_batch", ":", "\n", "# Number of samples seen in num_replicas * per_replica_batch_size.", "\n", "      ", "total_num_samples", "+=", "(", "\n", "eval_batch", "[", "'label'", "]", ".", "shape", "[", "0", "]", "*", "eval_batch", "[", "'label'", "]", ".", "shape", "[", "1", "]", "*", "\n", "jax", ".", "host_count", "(", ")", ")", "\n", "", "else", ":", "\n", "      ", "total_num_samples", "+=", "all_host_psum", "(", "eval_batch", "[", "'mask'", "]", ")", "[", "0", "]", ".", "sum", "(", ")", "\n", "\n", "# Metrics are all the same across all replicas (since we applied psum in the", "\n", "# eval_step). The next line will fetch the metrics on one of them.", "\n", "", "", "eval_metrics", "=", "common_utils", ".", "get_metrics", "(", "eval_metrics", ")", "\n", "# Finally, we divide by the number of samples to get the mean error rate and", "\n", "# cross entropy.", "\n", "eval_summary", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", ".", "sum", "(", ")", "/", "total_num_samples", ",", "\n", "eval_metrics", ")", "\n", "return", "eval_summary", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train_for_one_epoch": [[701, 761], ["time.time", "sam.sam_jax.datasets.dataset_source.get_train", "flax.training.common_utils.get_metrics", "jax.tree_map", "jax.tree_map", "int", "absl.logging.info", "jax.tree_map.items", "summary_writer.flush", "jax.random.fold_in", "jax.random.fold_in", "flax_training.tensorflow_to_numpy", "flax_training.shard_batch", "flax.training.common_utils.shard_prng_key", "pmapped_train_step", "common_utils.get_metrics.append", "summary_writer.scalar", "pmapped_update_ema", "x.mean", "time.time", "sam.sam_jax.datasets.dataset_source"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.tensorflow_to_numpy", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.shard_batch"], ["def", "train_for_one_epoch", "(", "\n", "dataset_source", ":", "dataset_source_lib", ".", "DatasetSource", ",", "\n", "optimizer", ":", "flax", ".", "optim", ".", "Optimizer", ",", "state", ":", "flax", ".", "nn", ".", "Collection", ",", "\n", "prng_key", ":", "jnp", ".", "ndarray", ",", "pmapped_train_step", ":", "_TrainStep", ",", "\n", "pmapped_update_ema", ":", "Optional", "[", "_EMAUpdateStep", "]", ",", "\n", "moving_averages", ":", "Optional", "[", "efficientnet_optim", ".", "ExponentialMovingAverage", "]", ",", "\n", "summary_writer", ":", "tensorboard", ".", "SummaryWriter", "\n", ")", "->", "Tuple", "[", "flax", ".", "optim", ".", "Optimizer", ",", "flax", ".", "nn", ".", "Collection", ",", "\n", "Optional", "[", "efficientnet_optim", ".", "ExponentialMovingAverage", "]", "]", ":", "\n", "  ", "\"\"\"Trains the model for one epoch.\n\n  Args:\n    dataset_source: Container for the training dataset.\n    optimizer: The optimizer targeting the model to train.\n    state: Current state associated with the model (contains the batch norm MA).\n    prng_key: A PRNG key to use for stochasticity (e.g. for sampling an eventual\n      dropout mask). Is not used for shuffling the dataset.\n    pmapped_train_step: A pmapped version of the `train_step` function (see its\n      documentation for more details).\n    pmapped_update_ema: Function to update the parameter moving average. Can be\n      None if we don't use EMA.\n    moving_averages: Parameters moving average if used.\n    summary_writer: A Tensorboard SummaryWriter to use to log metrics.\n\n  Returns:\n    The updated optimizer (with the associated updated model), state and PRNG\n      key.\n  \"\"\"", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "cnt", "=", "0", "\n", "train_metrics", "=", "[", "]", "\n", "for", "batch", "in", "dataset_source", ".", "get_train", "(", "use_augmentations", "=", "True", ")", ":", "\n", "# Generate a PRNG key that will be rolled into the batch.", "\n", "    ", "step_key", "=", "jax", ".", "random", ".", "fold_in", "(", "prng_key", ",", "optimizer", ".", "state", ".", "step", "[", "0", "]", ")", "\n", "# Load and shard the TF batch.", "\n", "batch", "=", "tensorflow_to_numpy", "(", "batch", ")", "\n", "batch", "=", "shard_batch", "(", "batch", ")", "\n", "# Shard the step PRNG key.", "\n", "sharded_keys", "=", "common_utils", ".", "shard_prng_key", "(", "step_key", ")", "\n", "\n", "optimizer", ",", "state", ",", "metrics", ",", "lr", "=", "pmapped_train_step", "(", "\n", "optimizer", ",", "state", ",", "batch", ",", "sharded_keys", ")", "\n", "cnt", "+=", "1", "\n", "\n", "if", "moving_averages", "is", "not", "None", ":", "\n", "      ", "moving_averages", "=", "pmapped_update_ema", "(", "optimizer", ",", "state", ",", "moving_averages", ")", "\n", "\n", "", "train_metrics", ".", "append", "(", "metrics", ")", "\n", "", "train_metrics", "=", "common_utils", ".", "get_metrics", "(", "train_metrics", ")", "\n", "# Get training epoch summary for logging.", "\n", "train_summary", "=", "jax", ".", "tree_map", "(", "lambda", "x", ":", "x", ".", "mean", "(", ")", ",", "train_metrics", ")", "\n", "train_summary", "[", "'learning_rate'", "]", "=", "lr", "[", "0", "]", "\n", "current_step", "=", "int", "(", "optimizer", ".", "state", ".", "step", "[", "0", "]", ")", "\n", "info", "=", "'Whole training step done in {} ({} steps)'", ".", "format", "(", "\n", "time", ".", "time", "(", ")", "-", "start_time", ",", "cnt", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "train_summary", ".", "items", "(", ")", ":", "\n", "    ", "summary_writer", ".", "scalar", "(", "metric_name", ",", "metric_value", ",", "current_step", ")", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "return", "optimizer", ",", "state", ",", "moving_averages", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train": [[763, 917], ["os.path.join", "flax.metrics.tensorboard.SummaryWriter", "jax.random.PRNGKey", "jax.random.PRNGKey", "tensorflow.io.gfile.exists", "flax.jax_utils.replicate", "flax.jax_utils.replicate", "jax.pmap", "jax.pmap", "jax.pmap", "jax.pmap", "time.time", "range", "jax.host_id", "jax.host_id", "sam.sam_jax.efficientnet.optim.ExponentialMovingAverage", "jax.pmap", "jax.pmap", "absl.logging.info", "jax.array", "absl.logging.info", "flax.jax_utils.replicate", "functools.partial", "time.time", "flax_training.train_for_one_epoch", "time.time", "absl.logging.info", "flax_training.save_checkpoint", "flax_training.save_checkpoint", "ema.update_moving_average", "flax_training.restore_checkpoint", "flax_training.restore_checkpoint", "flax_training.get_cosine_schedule", "os.path.join", "flax_training.save_checkpoint", "absl.logging.info", "time.time", "int", "time.time", "time.time", "absl.logging.info", "flax_training.get_exponential_schedule", "ValueError", "sam.sam_jax.datasets.dataset_source.get_train", "flax_training.eval_on_dataset", "eval_on_dataset.items", "tensorboard.SummaryWriter.flush", "absl.logging.info", "sam.sam_jax.datasets.dataset_source.get_test", "flax_training.eval_on_dataset", "eval_on_dataset.items", "tensorboard.SummaryWriter.flush", "sam.sam_jax.datasets.dataset_source.get_test", "flax_training.eval_on_dataset", "eval_on_dataset.items", "tensorboard.SummaryWriter.flush", "time.time", "absl.logging.info", "flax_training.save_checkpoint", "flax_training.save_checkpoint", "str", "tensorboard.SummaryWriter.scalar", "tensorboard.SummaryWriter.scalar", "tensorboard.SummaryWriter.scalar"], "function", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train_for_one_epoch", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.optim.ExponentialMovingAverage.update_moving_average", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.get_cosine_schedule", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.get_exponential_schedule", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.eval_on_dataset", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.eval_on_dataset", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.eval_on_dataset", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.save_checkpoint"], ["", "def", "train", "(", "optimizer", ":", "flax", ".", "optim", ".", "Optimizer", ",", "\n", "state", ":", "flax", ".", "nn", ".", "Collection", ",", "\n", "dataset_source", ":", "dataset_source_lib", ".", "DatasetSource", ",", "\n", "training_dir", ":", "str", ",", "num_epochs", ":", "int", ")", ":", "\n", "  ", "\"\"\"Trains the model.\n\n  Args:\n    optimizer: The optimizer targeting the model to train.\n    state: Current state associated with the model (contains the batch norm MA).\n    dataset_source: Container for the training dataset.\n    training_dir: Parent directory where the tensorboard logs and model\n      checkpoints should be saved.\n   num_epochs: Number of epochs for which we want to train the model.\n  \"\"\"", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "training_dir", ",", "'checkpoints'", ")", "\n", "summary_writer", "=", "tensorboard", ".", "SummaryWriter", "(", "training_dir", ")", "\n", "if", "jax", ".", "host_id", "(", ")", "!=", "0", ":", "# Don't log if not first host.", "\n", "    ", "summary_writer", ".", "scalar", "=", "lambda", "*", "args", ":", "None", "\n", "", "prng_key", "=", "jax", ".", "random", ".", "PRNGKey", "(", "FLAGS", ".", "run_seed", ")", "\n", "\n", "if", "FLAGS", ".", "ema_decay", ":", "\n", "    ", "end_warmup_step", "=", "1560", "\n", "moving_averages", "=", "efficientnet_optim", ".", "ExponentialMovingAverage", "(", "\n", "(", "optimizer", ".", "target", ",", "state", ")", ",", "FLAGS", ".", "ema_decay", ",", "end_warmup_step", ")", "# pytype:disable=wrong-arg-count", "\n", "\n", "def", "update_ema", "(", "optimizer", ",", "state", ",", "ema", ")", ":", "\n", "      ", "step", "=", "optimizer", ".", "state", ".", "step", "\n", "return", "ema", ".", "update_moving_average", "(", "(", "optimizer", ".", "target", ",", "state", ")", ",", "step", ")", "\n", "\n", "", "pmapped_update_ema", "=", "jax", ".", "pmap", "(", "update_ema", ",", "axis_name", "=", "'batch'", ")", "\n", "", "else", ":", "\n", "    ", "pmapped_update_ema", "=", "moving_averages", "=", "None", "\n", "\n", "# Log initial results:", "\n", "", "if", "gfile", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "    ", "if", "FLAGS", ".", "ema_decay", ":", "\n", "      ", "optimizer", ",", "(", "state", ",", "\n", "moving_averages", ")", ",", "epoch_last_checkpoint", "=", "restore_checkpoint", "(", "\n", "optimizer", ",", "(", "state", ",", "moving_averages", ")", ",", "checkpoint_dir", ")", "\n", "", "else", ":", "\n", "      ", "optimizer", ",", "state", ",", "epoch_last_checkpoint", "=", "restore_checkpoint", "(", "\n", "optimizer", ",", "state", ",", "checkpoint_dir", ")", "\n", "# If last checkpoint was saved at the end of epoch n, then the first", "\n", "# training epochs to do when we resume training is n+1.", "\n", "", "initial_epoch", "=", "epoch_last_checkpoint", "+", "1", "\n", "info", "=", "'Resuming training from epoch {}'", ".", "format", "(", "initial_epoch", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "", "else", ":", "\n", "    ", "initial_epoch", "=", "jnp", ".", "array", "(", "0", ",", "dtype", "=", "jnp", ".", "int32", ")", "\n", "logging", ".", "info", "(", "'Starting training from scratch.'", ")", "\n", "\n", "", "optimizer", "=", "jax_utils", ".", "replicate", "(", "optimizer", ")", "\n", "state", "=", "jax_utils", ".", "replicate", "(", "state", ")", "\n", "if", "FLAGS", ".", "ema_decay", ":", "\n", "    ", "moving_averages", "=", "jax_utils", ".", "replicate", "(", "moving_averages", ")", "\n", "\n", "", "if", "FLAGS", ".", "use_learning_rate_schedule", ":", "\n", "    ", "if", "FLAGS", ".", "lr_schedule", "==", "'cosine'", ":", "\n", "      ", "learning_rate_fn", "=", "get_cosine_schedule", "(", "num_epochs", ",", "FLAGS", ".", "learning_rate", ",", "\n", "dataset_source", ".", "num_training_obs", ",", "\n", "dataset_source", ".", "batch_size", ")", "\n", "", "elif", "FLAGS", ".", "lr_schedule", "==", "'exponential'", ":", "\n", "      ", "learning_rate_fn", "=", "get_exponential_schedule", "(", "\n", "num_epochs", ",", "FLAGS", ".", "learning_rate", ",", "dataset_source", ".", "num_training_obs", ",", "\n", "dataset_source", ".", "batch_size", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "'Wrong schedule: '", "+", "FLAGS", ".", "lr_schedule", ")", "\n", "", "", "else", ":", "\n", "    ", "learning_rate_fn", "=", "lambda", "step", ":", "FLAGS", ".", "learning_rate", "\n", "\n", "# pmap the training and evaluation functions.", "\n", "", "pmapped_train_step", "=", "jax", ".", "pmap", "(", "\n", "functools", ".", "partial", "(", "\n", "train_step", ",", "\n", "learning_rate_fn", "=", "learning_rate_fn", ",", "\n", "l2_reg", "=", "FLAGS", ".", "weight_decay", ")", ",", "\n", "axis_name", "=", "'batch'", ",", "\n", "donate_argnums", "=", "(", "0", ",", "1", ")", ")", "\n", "pmapped_eval_step", "=", "jax", ".", "pmap", "(", "eval_step", ",", "axis_name", "=", "'batch'", ")", "\n", "\n", "time_at_last_checkpoint", "=", "time", ".", "time", "(", ")", "\n", "for", "epochs_id", "in", "range", "(", "initial_epoch", ",", "num_epochs", ")", ":", "\n", "    ", "if", "epochs_id", "in", "FLAGS", ".", "additional_checkpoints_at_epochs", ":", "\n", "# To save additional checkpoints that will not be erase by later version,", "\n", "# we save them in a new directory.", "\n", "      ", "c_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'additional_ckpt_'", "+", "str", "(", "epochs_id", ")", ")", "\n", "save_checkpoint", "(", "optimizer", ",", "state", ",", "c_path", ",", "epochs_id", ")", "\n", "", "tick", "=", "time", ".", "time", "(", ")", "\n", "\n", "optimizer", ",", "state", ",", "moving_averages", "=", "train_for_one_epoch", "(", "\n", "dataset_source", ",", "optimizer", ",", "state", ",", "prng_key", ",", "pmapped_train_step", ",", "\n", "pmapped_update_ema", ",", "moving_averages", ",", "summary_writer", ")", "\n", "\n", "tock", "=", "time", ".", "time", "(", ")", "\n", "info", "=", "'Epoch {} finished in {:.2f}s.'", ".", "format", "(", "epochs_id", ",", "tock", "-", "tick", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "\n", "# Evaluate the model on the test set, and optionally the training set.", "\n", "if", "(", "epochs_id", "+", "1", ")", "%", "FLAGS", ".", "evaluate_every", "==", "0", ":", "\n", "      ", "info", "=", "'Evaluating at end of epoch {} (0-indexed)'", ".", "format", "(", "epochs_id", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "tick", "=", "time", ".", "time", "(", ")", "\n", "current_step", "=", "int", "(", "optimizer", ".", "state", ".", "step", "[", "0", "]", ")", "\n", "if", "FLAGS", ".", "also_eval_on_training_set", ":", "\n", "        ", "train_ds", "=", "dataset_source", ".", "get_train", "(", "use_augmentations", "=", "False", ")", "\n", "train_metrics", "=", "eval_on_dataset", "(", "\n", "optimizer", ".", "target", ",", "state", ",", "train_ds", ",", "pmapped_eval_step", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "train_metrics", ".", "items", "(", ")", ":", "\n", "          ", "summary_writer", ".", "scalar", "(", "'eval_on_train_'", "+", "metric_name", ",", "\n", "metric_value", ",", "current_step", ")", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "if", "FLAGS", ".", "ema_decay", ":", "\n", "        ", "logging", ".", "info", "(", "'Evaluating with EMA.'", ")", "\n", "ema_model", ",", "ema_state", "=", "moving_averages", ".", "param_ema", "# pytype:disable=attribute-error", "\n", "test_ds", "=", "dataset_source", ".", "get_test", "(", ")", "\n", "test_metrics", "=", "eval_on_dataset", "(", "\n", "ema_model", ",", "ema_state", ",", "test_ds", ",", "pmapped_eval_step", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "          ", "summary_writer", ".", "scalar", "(", "'ema_test_'", "+", "metric_name", ",", "\n", "metric_value", ",", "current_step", ")", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "else", ":", "\n", "        ", "test_ds", "=", "dataset_source", ".", "get_test", "(", ")", "\n", "test_metrics", "=", "eval_on_dataset", "(", "\n", "optimizer", ".", "target", ",", "state", ",", "test_ds", ",", "pmapped_eval_step", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "test_metrics", ".", "items", "(", ")", ":", "\n", "          ", "summary_writer", ".", "scalar", "(", "'test_'", "+", "metric_name", ",", "\n", "metric_value", ",", "current_step", ")", "\n", "", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "tock", "=", "time", ".", "time", "(", ")", "\n", "info", "=", "'Evaluated model in {:.2f}.'", ".", "format", "(", "tock", "-", "tick", ")", "\n", "logging", ".", "info", "(", "info", ")", "\n", "\n", "# Save new checkpoint if the last one was saved more than", "\n", "# `save_progress_seconds` seconds ago.", "\n", "", "", "sec_from_last_ckpt", "=", "time", ".", "time", "(", ")", "-", "time_at_last_checkpoint", "\n", "if", "sec_from_last_ckpt", ">", "FLAGS", ".", "save_progress_seconds", ":", "\n", "      ", "if", "FLAGS", ".", "ema_decay", ":", "\n", "        ", "save_checkpoint", "(", "\n", "optimizer", ",", "(", "state", ",", "moving_averages", ")", ",", "checkpoint_dir", ",", "epochs_id", ")", "\n", "", "else", ":", "\n", "        ", "save_checkpoint", "(", "optimizer", ",", "state", ",", "checkpoint_dir", ",", "epochs_id", ")", "\n", "", "time_at_last_checkpoint", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "'Saved checkpoint.'", ")", "\n", "\n", "# Always save final checkpoint", "\n", "", "", "if", "FLAGS", ".", "ema_decay", ":", "\n", "    ", "save_checkpoint", "(", "\n", "optimizer", ",", "(", "state", ",", "moving_averages", ")", ",", "checkpoint_dir", ",", "epochs_id", ")", "\n", "", "else", ":", "\n", "    ", "save_checkpoint", "(", "optimizer", ",", "state", ",", "checkpoint_dir", ",", "epochs_id", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.__init__": [[43, 64], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat.numpy", "tensorflow.concat.numpy", "tensorflow.data.Dataset.from_tensor_slices", "tensorflow.data.Dataset.from_tensor_slices", "range", "range", "range", "range", "tensorflow.constant", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mask", "=", "False", ")", ":", "\n", "    ", "positive_input", "=", "tf", ".", "constant", "(", "[", "[", "1.0", "+", "i", "/", "20", "]", "for", "i", "in", "range", "(", "20", ")", "]", ")", "\n", "negative_input", "=", "tf", ".", "constant", "(", "[", "[", "-", "1.0", "-", "i", "/", "20", "]", "for", "i", "in", "range", "(", "20", ")", "]", ")", "\n", "positive_labels", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "0", "]", "for", "_", "in", "range", "(", "20", ")", "]", ")", "\n", "negative_labels", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "1", "]", "for", "_", "in", "range", "(", "20", ")", "]", ")", "\n", "inputs", "=", "tf", ".", "concat", "(", "(", "positive_input", ",", "negative_input", ")", ",", "0", ")", "\n", "labels", "=", "tf", ".", "concat", "(", "(", "positive_labels", ",", "negative_labels", ")", ",", "0", ")", "\n", "self", ".", "inputs", ",", "self", ".", "labels", "=", "inputs", ".", "numpy", "(", ")", ",", "labels", ".", "numpy", "(", ")", "\n", "if", "not", "mask", ":", "\n", "      ", "self", ".", "_ds", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "{", "\n", "'image'", ":", "inputs", ",", "\n", "'label'", ":", "labels", "\n", "}", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_ds", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "{", "\n", "'image'", ":", "inputs", ",", "\n", "'label'", ":", "labels", ",", "\n", "'mask'", ":", "tf", ".", "constant", "(", "[", "1.0", "for", "_", "in", "range", "(", "40", ")", "]", ")", "\n", "}", ")", "\n", "", "self", ".", "num_training_obs", "=", "40", "\n", "self", ".", "batch_size", "=", "16", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_train": [[65, 73], ["flax_training_test.MockDatasetSource._ds.batch"], "methods", ["None"], ["", "def", "get_train", "(", "self", ",", "use_augmentations", ":", "bool", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the training set.\n\n    Args:\n      use_augmentations: Ignored (see base class for more details).\n    \"\"\"", "\n", "del", "use_augmentations", "\n", "return", "self", ".", "_ds", ".", "batch", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.MockDatasetSource.get_test": [[74, 77], ["flax_training_test.MockDatasetSource._ds.batch"], "methods", ["None"], ["", "def", "get_test", "(", "self", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "\"\"\"Returns the test set.\"\"\"", "\n", "return", "self", ".", "_ds", ".", "batch", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.setUp": [[142, 153], ["super().setUp", "os.getenv", "jax.lib.xla_bridge.get_backend.cache_clear", "jax.lib.xla_bridge.get_backend.cache_clear"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "FlaxTrainingTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "global", "prev_xla_flags", "\n", "prev_xla_flags", "=", "os", ".", "getenv", "(", "'XLA_FLAGS'", ")", "\n", "flags_str", "=", "prev_xla_flags", "or", "''", "\n", "# Don't override user-specified device count, or other XLA flags.", "\n", "if", "'xla_force_host_platform_device_count'", "not", "in", "flags_str", ":", "\n", "      ", "os", ".", "environ", "[", "'XLA_FLAGS'", "]", "=", "(", "\n", "flags_str", "+", "' --xla_force_host_platform_device_count=8'", ")", "\n", "# Clear any cached backends so new CPU backend will pick up the env var.", "\n", "", "xla_bridge", ".", "get_backend", ".", "cache_clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.tearDown": [[155, 162], ["super().tearDown", "jax.lib.xla_bridge.get_backend.cache_clear", "jax.lib.xla_bridge.get_backend.cache_clear"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.tearDown"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "    ", "super", "(", "FlaxTrainingTest", ",", "self", ")", ".", "tearDown", "(", ")", "\n", "if", "prev_xla_flags", "is", "None", ":", "\n", "      ", "del", "os", ".", "environ", "[", "'XLA_FLAGS'", "]", "\n", "", "else", ":", "\n", "      ", "os", ".", "environ", "[", "'XLA_FLAGS'", "]", "=", "prev_xla_flags", "\n", "", "xla_bridge", ".", "get_backend", ".", "cache_clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_TrainSimpleModel": [[163, 179], ["flax_training_test._get_linear_model", "flax_training_test.MockDatasetSource", "sam.sam_jax.training_utils.flax_training.create_optimizer", "sam.sam_jax.training_utils.flax_training.train", "flax_training_test.tensorboard_event_to_dataframe", "records.sort_values.sort_values.sort_values", "flax_training_test.FlaxTrainingTest.assertEqual", "flax_training_test.FlaxTrainingTest.create_tempdir"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test._get_linear_model", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_optimizer", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.tensorboard_event_to_dataframe"], ["", "@", "flagsaver", ".", "flagsaver", "\n", "def", "test_TrainSimpleModel", "(", "self", ")", ":", "\n", "    ", "\"\"\"Model should reach 100% accuracy easily.\"\"\"", "\n", "model", ",", "state", "=", "_get_linear_model", "(", ")", "\n", "dataset", "=", "MockDatasetSource", "(", ")", "\n", "num_epochs", "=", "10", "\n", "optimizer", "=", "flax_training", ".", "create_optimizer", "(", "model", ",", "0.0", ")", "\n", "training_dir", "=", "self", ".", "create_tempdir", "(", ")", ".", "full_path", "\n", "FLAGS", ".", "learning_rate", "=", "0.01", "\n", "flax_training", ".", "train", "(", "\n", "optimizer", ",", "state", ",", "dataset", ",", "training_dir", ",", "num_epochs", ")", "\n", "records", "=", "tensorboard_event_to_dataframe", "(", "training_dir", ")", "\n", "# Train error rate at the last step should be 0.", "\n", "records", "=", "records", "[", "records", ".", "metric", "==", "'train_error_rate'", "]", "\n", "records", "=", "records", ".", "sort_values", "(", "'step'", ")", "\n", "self", ".", "assertEqual", "(", "records", ".", "value", ".", "values", "[", "-", "1", "]", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption": [[180, 214], ["flax_training_test._get_linear_model", "flax_training_test.MockDatasetSource", "sam.sam_jax.training_utils.flax_training.create_optimizer", "os.path.join", "sam.sam_jax.training_utils.flax_training.train", "flax_training_test.tensorboard_event_to_dataframe", "os.path.join", "sam.sam_jax.training_utils.flax_training.train", "sam.sam_jax.training_utils.flax_training.train", "flax_training_test.tensorboard_event_to_dataframe", "flax_training_test.FlaxTrainingTest.assertEqual", "flax_training_test.FlaxTrainingTest.create_tempdir", "str", "set", "set", "flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption._make_hashable"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test._get_linear_model", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_optimizer", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.tensorboard_event_to_dataframe", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.tensorboard_event_to_dataframe"], ["", "@", "flagsaver", ".", "flagsaver", "\n", "def", "_test_ResumeTrainingAfterInterruption", "(", "self", ",", "use_ema", ":", "bool", ")", ":", "# pylint:disable=invalid-name", "\n", "    ", "\"\"\"Resuming training should match a run without interruption.\"\"\"", "\n", "if", "use_ema", ":", "\n", "      ", "FLAGS", ".", "ema_decay", "=", "0.9", "\n", "", "model", ",", "state", "=", "_get_linear_model", "(", ")", "\n", "dataset", "=", "MockDatasetSource", "(", ")", "\n", "optimizer", "=", "flax_training", ".", "create_optimizer", "(", "model", ",", "0.0", ")", "\n", "training_dir", "=", "self", ".", "create_tempdir", "(", ")", ".", "full_path", "\n", "FLAGS", ".", "learning_rate", "=", "0.01", "\n", "FLAGS", ".", "use_learning_rate_schedule", "=", "False", "\n", "# First we train for 10 epochs and get the logs.", "\n", "num_epochs", "=", "10", "\n", "reference_run_dir", "=", "os", ".", "path", ".", "join", "(", "training_dir", ",", "'reference'", ")", "\n", "flax_training", ".", "train", "(", "\n", "optimizer", ",", "state", ",", "dataset", ",", "reference_run_dir", ",", "num_epochs", ")", "\n", "records", "=", "tensorboard_event_to_dataframe", "(", "reference_run_dir", ")", "\n", "# In another directory (new experiment), we run the model for 4 epochs and", "\n", "# then for 10 epochs, to simulate an interruption.", "\n", "interrupted_run_dir", "=", "os", ".", "path", ".", "join", "(", "training_dir", ",", "'interrupted'", ")", "\n", "flax_training", ".", "train", "(", "\n", "optimizer", ",", "state", ",", "dataset", ",", "interrupted_run_dir", ",", "4", ")", "\n", "flax_training", ".", "train", "(", "\n", "optimizer", ",", "state", ",", "dataset", ",", "interrupted_run_dir", ",", "10", ")", "\n", "records_interrupted", "=", "tensorboard_event_to_dataframe", "(", "interrupted_run_dir", ")", "\n", "\n", "# Logs should match (order doesn't matter as it is a dataframe in tidy", "\n", "# format).", "\n", "def", "_make_hashable", "(", "row", ")", ":", "\n", "      ", "return", "str", "(", "[", "e", "if", "not", "isinstance", "(", "e", ",", "float", ")", "else", "round", "(", "e", ",", "5", ")", "for", "e", "in", "row", "]", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "\n", "set", "(", "[", "_make_hashable", "(", "e", ")", "for", "e", "in", "records_interrupted", ".", "values", "]", ")", ",", "\n", "set", "(", "[", "_make_hashable", "(", "e", ")", "for", "e", "in", "records", ".", "values", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_ResumeTrainingAfterInterruptionEMA": [[215, 217], ["flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption"], ["", "def", "test_ResumeTrainingAfterInterruptionEMA", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_ResumeTrainingAfterInterruption", "(", "use_ema", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_ResumeTrainingAfterInterruption": [[218, 220], ["flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._test_ResumeTrainingAfterInterruption"], ["", "def", "test_ResumeTrainingAfterInterruption", "(", "self", ")", ":", "\n", "    ", "self", ".", "_test_ResumeTrainingAfterInterruption", "(", "use_ema", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._RecomputeTestLoss": [[221, 240], ["flax_training_test._get_linear_model", "flax_training_test.MockDatasetSource", "sam.sam_jax.training_utils.flax_training.create_optimizer", "sam.sam_jax.training_utils.flax_training.train", "flax_training_test.tensorboard_event_to_dataframe", "sam.sam_jax.training_utils.flax_training.restore_checkpoint", "sam.sam_jax.training_utils.flax_training.create_optimizer.target", "sam.sam_jax.training_utils.flax_training.cross_entropy_loss", "flax_training_test.FlaxTrainingTest.assertLess", "flax_training_test.FlaxTrainingTest.create_tempdir", "os.path.join", "abs", "tensorboard_event_to_dataframe.sort_values"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test._get_linear_model", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.create_optimizer", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.train", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.tensorboard_event_to_dataframe", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.cross_entropy_loss"], ["", "def", "_RecomputeTestLoss", "(", "self", ",", "masked", ":", "int", "=", "False", ")", ":", "# pylint:disable=invalid-name", "\n", "    ", "\"\"\"Recomputes the loss of the final model to check the value logged.\"\"\"", "\n", "FLAGS", ".", "compute_top_5_error_rate", "=", "True", "\n", "model", ",", "state", "=", "_get_linear_model", "(", ")", "\n", "dataset", "=", "MockDatasetSource", "(", "mask", "=", "masked", ")", "\n", "num_epochs", "=", "2", "\n", "optimizer", "=", "flax_training", ".", "create_optimizer", "(", "model", ",", "0.0", ")", "\n", "training_dir", "=", "self", ".", "create_tempdir", "(", ")", ".", "full_path", "\n", "flax_training", ".", "train", "(", "\n", "optimizer", ",", "state", ",", "dataset", ",", "training_dir", ",", "num_epochs", ")", "\n", "records", "=", "tensorboard_event_to_dataframe", "(", "training_dir", ")", "\n", "records", "=", "records", "[", "records", ".", "metric", "==", "'test_loss'", "]", "\n", "final_test_loss", "=", "records", ".", "sort_values", "(", "'step'", ")", ".", "value", ".", "values", "[", "-", "1", "]", "\n", "# Loads final model and state.", "\n", "optimizer", ",", "state", ",", "_", "=", "flax_training", ".", "restore_checkpoint", "(", "\n", "optimizer", ",", "state", ",", "os", ".", "path", ".", "join", "(", "training_dir", ",", "'checkpoints'", ")", ")", "\n", "logits", "=", "optimizer", ".", "target", "(", "dataset", ".", "inputs", ")", "\n", "loss", "=", "flax_training", ".", "cross_entropy_loss", "(", "logits", ",", "dataset", ".", "labels", ")", "\n", "self", ".", "assertLess", "(", "abs", "(", "final_test_loss", "-", "loss", ")", ",", "1e-7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_RecomputeTestLoss": [[241, 243], ["flax_training_test.FlaxTrainingTest._RecomputeTestLoss"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._RecomputeTestLoss"], ["", "def", "test_RecomputeTestLoss", "(", "self", ")", ":", "\n", "    ", "self", ".", "_RecomputeTestLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_RecomputeTestLossMasked": [[244, 246], ["flax_training_test.FlaxTrainingTest._RecomputeTestLoss"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest._RecomputeTestLoss"], ["", "def", "test_RecomputeTestLossMasked", "(", "self", ")", ":", "\n", "    ", "self", ".", "_RecomputeTestLoss", "(", "masked", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.FlaxTrainingTest.test_metrics": [[247, 253], ["jax.array", "jax.array", "jax.array", "jax.array", "jax.array", "jax.array", "flax_training_test.FlaxTrainingTest.assertEqual", "flax_training_test.FlaxTrainingTest.assertEqual", "sam.sam_jax.training_utils.flax_training.error_rate_metric", "sam.sam_jax.training_utils.flax_training.error_rate_metric"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.error_rate_metric", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.error_rate_metric"], ["", "def", "test_metrics", "(", "self", ")", ":", "\n", "    ", "logits", "=", "jnp", ".", "array", "(", "[", "[", "2.0", ",", "1.0", "]", ",", "[", "3.0", ",", "1.0", "]", ",", "[", "0.1", ",", "1.6", "]", ",", "[", "2.0", ",", "5.0", "]", "]", ")", "\n", "truth", "=", "jnp", ".", "array", "(", "[", "[", "1.0", ",", "0.0", "]", ",", "[", "1.0", ",", "0.0", "]", ",", "[", "1.0", ",", "0.0", "]", ",", "[", "0.0", ",", "1.0", "]", "]", ")", "\n", "mask", "=", "jnp", ".", "array", "(", "[", "1.0", ",", "1.0", ",", "1.0", ",", "0.0", "]", ")", "\n", "self", ".", "assertEqual", "(", "flax_training", ".", "error_rate_metric", "(", "logits", ",", "truth", ")", ",", "0.25", ")", "\n", "self", ".", "assertEqual", "(", "flax_training", ".", "error_rate_metric", "(", "logits", ",", "truth", ",", "mask", ")", ",", "1", "/", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test._get_linear_model": [[79, 111], ["LinearModel.partial", "flax.nn.stateful", "flax.nn.Dense", "flax.nn.stochastic", "LinearModel.partial.init_by_shape", "flax.nn.Model", "jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.PRNGKey"], "function", ["None"], ["", "", "def", "_get_linear_model", "(", ")", "->", "Tuple", "[", "flax", ".", "nn", ".", "Model", ",", "flax", ".", "nn", ".", "Collection", "]", ":", "\n", "  ", "\"\"\"Returns a linear model and its state.\"\"\"", "\n", "\n", "class", "LinearModel", "(", "flax", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Defines the linear model.\"\"\"", "\n", "\n", "def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "num_outputs", ":", "int", ",", "\n", "train", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "      ", "\"\"\"Forward pass with a linear model.\n\n      Args:\n        x: Input of shape [batch_size, num_features].\n        num_outputs: Number of classes.\n        train: Has no effect.\n\n      Returns:\n        A tensor of shape [batch_size, num_outputs].\n      \"\"\"", "\n", "del", "train", "\n", "x", "=", "flax", ".", "nn", ".", "Dense", "(", "x", ",", "num_outputs", ")", "\n", "return", "x", "\n", "\n", "", "", "input_shape", ",", "num_outputs", "=", "[", "1", "]", ",", "2", "\n", "module", "=", "LinearModel", ".", "partial", "(", "num_outputs", "=", "num_outputs", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", ")", "as", "init_state", ":", "\n", "    ", "with", "flax", ".", "nn", ".", "stochastic", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ")", ":", "\n", "      ", "_", ",", "initial_params", "=", "module", ".", "init_by_shape", "(", "\n", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ",", "[", "(", "input_shape", ",", "jnp", ".", "float32", ")", "]", ")", "\n", "model", "=", "flax", ".", "nn", ".", "Model", "(", "module", ",", "initial_params", ")", "\n", "", "", "return", "model", ",", "init_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training_test.tensorboard_event_to_dataframe": [[113, 133], ["tensorflow.io.gfile.glob", "pandas.DataFrame.from_records", "os.path.join", "tensorflow.compat.v1.train.summary_iterator", "records.append", "dict", "float", "tensorflow.make_ndarray"], "function", ["None"], ["", "def", "tensorboard_event_to_dataframe", "(", "path", ":", "str", ")", "->", "pd", ".", "DataFrame", ":", "\n", "  ", "\"\"\"Helper to get events written by tests.\n\n  Args:\n    path: Path where the tensorboard records were saved.\n\n  Returns:\n    The metric saved by tensorboard, as a dataframe.\n  \"\"\"", "\n", "records", "=", "[", "]", "\n", "all_tb_path", "=", "gfile", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'events.*.v2'", ")", ")", "\n", "for", "tb_event_path", "in", "all_tb_path", ":", "\n", "    ", "for", "e", "in", "tf", ".", "compat", ".", "v1", ".", "train", ".", "summary_iterator", "(", "tb_event_path", ")", ":", "\n", "      ", "if", "e", ".", "step", ":", "\n", "        ", "for", "v", "in", "e", ".", "summary", ".", "value", ":", "\n", "          ", "records", ".", "append", "(", "dict", "(", "\n", "step", "=", "e", ".", "step", ",", "metric", "=", "v", ".", "tag", ",", "\n", "value", "=", "float", "(", "tf", ".", "make_ndarray", "(", "v", ".", "tensor", ")", ")", ")", ")", "\n", "", "", "", "", "df", "=", "pd", ".", "DataFrame", ".", "from_records", "(", "records", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model.create_image_model": [[44, 65], ["flax.nn.stateful", "flax.nn.stochastic", "module.init_by_shape", "flax.nn.Model", "jax.random.PRNGKey"], "function", ["None"], ["def", "create_image_model", "(", "\n", "prng_key", ":", "jnp", ".", "ndarray", ",", "batch_size", ":", "int", ",", "image_size", ":", "int", ",", "\n", "module", ":", "flax", ".", "nn", ".", "Module", ")", "->", "Tuple", "[", "flax", ".", "nn", ".", "Model", ",", "flax", ".", "nn", ".", "Collection", "]", ":", "\n", "  ", "\"\"\"Instantiates a FLAX model and its state.\n\n  Args:\n    prng_key: PRNG key to use to sample the initial weights.\n    batch_size: Batch size that the model should expect.\n    image_size: Dimension of the image (assumed to be squared).\n    module: FLAX module describing the model to instantiates.\n\n  Returns:\n    A FLAX model and its state.\n  \"\"\"", "\n", "input_shape", "=", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "3", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", ")", "as", "init_state", ":", "\n", "    ", "with", "flax", ".", "nn", ".", "stochastic", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ")", ":", "\n", "      ", "_", ",", "initial_params", "=", "module", ".", "init_by_shape", "(", "\n", "prng_key", ",", "[", "(", "input_shape", ",", "jnp", ".", "float32", ")", "]", ")", "\n", "model", "=", "flax", ".", "nn", ".", "Model", "(", "module", ",", "initial_params", ")", "\n", "", "", "return", "model", ",", "init_state", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model._replace_dense_layer": [[72, 92], ["zip", "head.replace", "flax.traverse_util.flatten_dict().items", "flax.traverse_util.flatten_dict().items", "flax.traverse_util.unflatten_dict", "flax.traverse_util.flatten_dict", "flax.traverse_util.flatten_dict"], "function", ["None"], ["", "def", "_replace_dense_layer", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "head", ":", "flax", ".", "nn", ".", "Model", ")", ":", "\n", "  ", "\"\"\"Replaces the last layer (head) of a model with the head of another one.\n\n  Args:\n    model: Model for which we should keep all layers except the head.\n    head: Model from which we should copy the head.\n\n  Returns:\n    A model composed from the last layer of `head` and all the other layers of\n      `model`.\n  \"\"\"", "\n", "new_params", "=", "{", "}", "\n", "for", "(", "ak", ",", "av", ")", ",", "(", "bk", ",", "bv", ")", "in", "zip", "(", "\n", "flax", ".", "traverse_util", ".", "flatten_dict", "(", "model", ".", "params", ")", ".", "items", "(", ")", ",", "\n", "flax", ".", "traverse_util", ".", "flatten_dict", "(", "head", ".", "params", ")", ".", "items", "(", ")", ")", ":", "\n", "    ", "if", "ak", "[", "1", "]", "==", "'dense'", ":", "\n", "      ", "new_params", "[", "bk", "]", "=", "bv", "\n", "", "else", ":", "\n", "      ", "new_params", "[", "ak", "]", "=", "av", "\n", "", "", "return", "head", ".", "replace", "(", "params", "=", "flax", ".", "traverse_util", ".", "unflatten_dict", "(", "new_params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model.get_model": [[94, 162], ["load_model.create_image_model", "sam.sam_jax.imagenet_models.resnet.ResNet50.partial", "jax.random.PRNGKey", "sam.sam_jax.imagenet_models.resnet.ResNet101.partial", "ValueError", "flax.training.checkpoints.restore_checkpoint", "sam.sam_jax.efficientnet.efficientnet.get_efficientnet_module", "load_model.create_image_model", "flax.training.checkpoints.restore_checkpoint", "load_model._replace_dense_layer", "sam.sam_jax.imagenet_models.resnet.ResNet152.partial", "sam.sam_jax.efficientnet.efficientnet.get_efficientnet_module", "load_model.ModelNameError"], "function", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.create_image_model", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.get_efficientnet_module", "home.repos.pwc.inspect_result.google-research_sam.models.load_model.create_image_model", "home.repos.pwc.inspect_result.google-research_sam.training_utils.flax_training.restore_checkpoint", "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model._replace_dense_layer", "home.repos.pwc.inspect_result.google-research_sam.efficientnet.efficientnet.get_efficientnet_module"], ["", "def", "get_model", "(", "\n", "model_name", ":", "str", ",", "\n", "batch_size", ":", "int", ",", "\n", "image_size", ":", "int", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "prng_key", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "flax", ".", "nn", ".", "Model", ",", "flax", ".", "nn", ".", "Collection", "]", ":", "\n", "  ", "\"\"\"Returns an initialized model of the chosen architecture.\n\n  Args:\n    model_name: Name of the architecture to use. See image_classification.train\n      flags for a list of available models.\n    batch_size: The batch size that the model should expect.\n    image_size: Dimension of the image (assumed to be squared).\n    num_classes: Dimension of the output layer. Should be 1000, but is left as\n      an argument for consistency with other load_model functions. An error will\n      be raised if num_classes is not 1000.\n    prng_key: PRNG key to use to sample the weights.\n\n  Returns:\n    The initialized model and its state.\n\n  Raises:\n    ModelNameError: If the name of the architecture is not recognized.\n  \"\"\"", "\n", "if", "model_name", "==", "'Resnet50'", ":", "\n", "    ", "module", "=", "resnet", ".", "ResNet50", ".", "partial", "(", "num_classes", "=", "num_classes", ")", "\n", "", "elif", "model_name", "==", "'Resnet101'", ":", "\n", "    ", "module", "=", "resnet", ".", "ResNet101", ".", "partial", "(", "num_classes", "=", "num_classes", ")", "\n", "", "elif", "model_name", "==", "'Resnet152'", ":", "\n", "    ", "module", "=", "resnet", ".", "ResNet152", ".", "partial", "(", "num_classes", "=", "num_classes", ")", "\n", "", "elif", "model_name", "in", "efficientnet", ".", "MODEL_CONFIGS", ":", "\n", "    ", "module", "=", "efficientnet", ".", "get_efficientnet_module", "(", "\n", "model_name", ",", "num_classes", "=", "num_classes", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ModelNameError", "(", "'Unrecognized model name.'", ")", "\n", "", "if", "not", "prng_key", ":", "\n", "    ", "prng_key", "=", "random", ".", "PRNGKey", "(", "0", ")", "\n", "\n", "", "model", ",", "init_state", "=", "create_image_model", "(", "prng_key", ",", "batch_size", ",", "image_size", ",", "\n", "module", ")", "\n", "\n", "if", "FLAGS", ".", "from_pretrained_checkpoint", ":", "\n", "    ", "if", "FLAGS", ".", "efficientnet_checkpoint_path", "is", "None", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'For finetuning, must set `efficientnet_checkpoint_path` to a '", "\n", "'valid efficientnet checkpoint.'", ")", "\n", "# If the number of class is 1000, just load the imagenet/JFT checkpoint.", "\n", "", "if", "num_classes", "==", "1000", ":", "\n", "      ", "model", ",", "init_state", "=", "checkpoints", ".", "restore_checkpoint", "(", "\n", "FLAGS", ".", "efficientnet_checkpoint_path", ",", "\n", "(", "model", ",", "init_state", ")", ")", "\n", "# Else we need to change the size of the last layer (head):", "\n", "", "else", ":", "\n", "# Pretrained model on JFT/Imagenet.", "\n", "      ", "imagenet_module", "=", "efficientnet", ".", "get_efficientnet_module", "(", "\n", "model_name", ",", "num_classes", "=", "1000", ")", "\n", "imagenet_model", ",", "imagenet_state", "=", "create_image_model", "(", "\n", "prng_key", ",", "batch_size", ",", "image_size", ",", "imagenet_module", ")", "\n", "imagenet_model", ",", "imagenet_state", "=", "checkpoints", ".", "restore_checkpoint", "(", "\n", "FLAGS", ".", "efficientnet_checkpoint_path", ",", "\n", "(", "imagenet_model", ",", "imagenet_state", ")", ")", "\n", "# Replace all the layers of the initialized model with the weights", "\n", "# extracted from the pretrained model.", "\n", "model", "=", "_replace_dense_layer", "(", "imagenet_model", ",", "model", ")", "\n", "init_state", "=", "imagenet_state", "\n", "\n", "", "", "return", "model", ",", "init_state", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model_test.LoadModelTest.test_CreateEfficientnetModel": [[26, 34], ["sam.sam_jax.imagenet_models.load_model.get_model", "load_model_test.LoadModelTest.assertIsInstance", "load_model_test.LoadModelTest.assertIsInstance", "numpy.zeros", "load_model_test.LoadModelTest.assertEqual", "flax.nn.stateful", "model"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.get_model"], ["  ", "def", "test_CreateEfficientnetModel", "(", "self", ")", ":", "\n", "    ", "model", ",", "state", "=", "load_model", ".", "get_model", "(", "'efficientnet-b0'", ",", "1", ",", "224", ",", "1000", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "flax", ".", "nn", ".", "Model", ")", "\n", "self", ".", "assertIsInstance", "(", "state", ",", "flax", ".", "nn", ".", "Collection", ")", "\n", "fake_input", "=", "np", ".", "zeros", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ",", "mutable", "=", "False", ")", ":", "\n", "      ", "logits", "=", "model", "(", "fake_input", ",", "train", "=", "False", ")", "\n", "", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "(", "1", ",", "1000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.load_model_test.LoadModelTest.test_CreateResnetModel": [[35, 43], ["sam.sam_jax.imagenet_models.load_model.get_model", "load_model_test.LoadModelTest.assertIsInstance", "load_model_test.LoadModelTest.assertIsInstance", "numpy.zeros", "load_model_test.LoadModelTest.assertEqual", "flax.nn.stateful", "model"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.get_model"], ["", "def", "test_CreateResnetModel", "(", "self", ")", ":", "\n", "    ", "model", ",", "state", "=", "load_model", ".", "get_model", "(", "'Resnet50'", ",", "1", ",", "224", ",", "1000", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "flax", ".", "nn", ".", "Model", ")", "\n", "self", ".", "assertIsInstance", "(", "state", ",", "flax", ".", "nn", ".", "Collection", ")", "\n", "fake_input", "=", "np", ".", "zeros", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ",", "mutable", "=", "False", ")", ":", "\n", "      ", "logits", "=", "model", "(", "fake_input", ",", "train", "=", "False", ")", "\n", "", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "(", "1", ",", "1000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.resnet_test.ResNetTest.test_resnet_v1_module": [[30, 39], ["jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.PRNGKey", "sam.sam_jax.imagenet_models.resnet.ResNet50.partial", "sam.sam_jax.imagenet_models.resnet.ResNet50.partial.init_by_shape", "resnet_test.ResNetTest.assertEqual", "resnet_test.ResNetTest.assertLen"], "methods", ["None"], ["def", "test_resnet_v1_module", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests ResNet V1 model definition.\"\"\"", "\n", "rng", "=", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", "\n", "model_def", "=", "resnet", ".", "ResNet50", ".", "partial", "(", "num_classes", "=", "10", ",", "dtype", "=", "jnp", ".", "float32", ")", "\n", "output", ",", "init_params", "=", "model_def", ".", "init_by_shape", "(", "\n", "rng", ",", "[", "(", "(", "8", ",", "224", ",", "224", ",", "3", ")", ",", "jnp", ".", "float32", ")", "]", ")", "\n", "\n", "self", ".", "assertEqual", "(", "(", "8", ",", "10", ")", ",", "output", ".", "shape", ")", "\n", "self", ".", "assertLen", "(", "init_params", ",", "19", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.resnet.ResNetBlock.apply": [[30, 45], ["conv", "norm", "act", "conv", "norm", "act", "conv", "norm"], "methods", ["None"], ["def", "apply", "(", "self", ",", "x", ",", "filters", ",", "*", ",", "\n", "conv", ",", "norm", ",", "act", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "    ", "residual", "=", "x", "\n", "y", "=", "conv", "(", "x", ",", "filters", ",", "(", "3", ",", "3", ")", ",", "strides", ")", "\n", "y", "=", "norm", "(", "y", ")", "\n", "y", "=", "act", "(", "y", ")", "\n", "y", "=", "conv", "(", "y", ",", "filters", ",", "(", "3", ",", "3", ")", ")", "\n", "y", "=", "norm", "(", "y", ",", "scale_init", "=", "nn", ".", "initializers", ".", "zeros", ")", "\n", "\n", "if", "residual", ".", "shape", "!=", "y", ".", "shape", ":", "\n", "      ", "residual", "=", "conv", "(", "residual", ",", "filters", ",", "(", "1", ",", "1", ")", ",", "strides", ",", "name", "=", "'conv_proj'", ")", "\n", "residual", "=", "norm", "(", "residual", ",", "name", "=", "'norm_proj'", ")", "\n", "\n", "", "return", "act", "(", "residual", "+", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.resnet.BottleneckResNetBlock.apply": [[50, 68], ["conv", "norm", "act", "conv", "norm", "act", "conv", "norm", "act", "conv", "norm"], "methods", ["None"], ["def", "apply", "(", "self", ",", "x", ",", "filters", ",", "*", ",", "\n", "conv", ",", "norm", ",", "act", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "    ", "residual", "=", "x", "\n", "y", "=", "conv", "(", "x", ",", "filters", ",", "(", "1", ",", "1", ")", ")", "\n", "y", "=", "norm", "(", "y", ")", "\n", "y", "=", "act", "(", "y", ")", "\n", "y", "=", "conv", "(", "y", ",", "filters", ",", "(", "3", ",", "3", ")", ",", "strides", ")", "\n", "y", "=", "norm", "(", "y", ")", "\n", "y", "=", "act", "(", "y", ")", "\n", "y", "=", "conv", "(", "y", ",", "filters", "*", "4", ",", "(", "1", ",", "1", ")", ")", "\n", "y", "=", "norm", "(", "y", ",", "scale_init", "=", "nn", ".", "initializers", ".", "zeros", ")", "\n", "\n", "if", "residual", ".", "shape", "!=", "y", ".", "shape", ":", "\n", "      ", "residual", "=", "conv", "(", "residual", ",", "filters", "*", "4", ",", "(", "1", ",", "1", ")", ",", "strides", ",", "name", "=", "'conv_proj'", ")", "\n", "residual", "=", "norm", "(", "residual", ",", "name", "=", "'norm_proj'", ")", "\n", "\n", "", "return", "act", "(", "residual", "+", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.imagenet_models.resnet.ResNet.apply": [[73, 102], ["flax.nn.Conv.partial", "flax.nn.BatchNorm.partial", "flax.nn.Conv.partial.", "flax.nn.BatchNorm.partial.", "flax.nn.max_pool", "enumerate", "jax.mean", "flax.nn.Dense", "range", "block_cls"], "methods", ["None"], ["def", "apply", "(", "self", ",", "x", ",", "num_classes", ",", "*", ",", "\n", "stage_sizes", ",", "\n", "block_cls", ",", "\n", "num_filters", "=", "64", ",", "\n", "dtype", "=", "jnp", ".", "float32", ",", "\n", "act", "=", "nn", ".", "relu", ",", "\n", "train", "=", "True", ")", ":", "\n", "    ", "conv", "=", "nn", ".", "Conv", ".", "partial", "(", "bias", "=", "False", ",", "dtype", "=", "dtype", ")", "\n", "norm", "=", "nn", ".", "BatchNorm", ".", "partial", "(", "\n", "use_running_average", "=", "not", "train", ",", "\n", "momentum", "=", "0.9", ",", "epsilon", "=", "1e-5", ",", "\n", "dtype", "=", "dtype", ")", "\n", "\n", "x", "=", "conv", "(", "x", ",", "num_filters", ",", "(", "7", ",", "7", ")", ",", "(", "2", ",", "2", ")", ",", "\n", "padding", "=", "[", "(", "3", ",", "3", ")", ",", "(", "3", ",", "3", ")", "]", ",", "\n", "name", "=", "'conv_init'", ")", "\n", "x", "=", "norm", "(", "x", ",", "name", "=", "'bn_init'", ")", "\n", "x", "=", "nn", ".", "max_pool", "(", "x", ",", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "for", "i", ",", "block_size", "in", "enumerate", "(", "stage_sizes", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "block_size", ")", ":", "\n", "        ", "strides", "=", "(", "2", ",", "2", ")", "if", "i", ">", "0", "and", "j", "==", "0", "else", "(", "1", ",", "1", ")", "\n", "x", "=", "block_cls", "(", "x", ",", "num_filters", "*", "2", "**", "i", ",", "\n", "strides", "=", "strides", ",", "\n", "conv", "=", "conv", ",", "\n", "norm", "=", "norm", ",", "\n", "act", "=", "act", ")", "\n", "", "", "x", "=", "jnp", ".", "mean", "(", "x", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "x", "=", "nn", ".", "Dense", "(", "x", ",", "num_classes", ",", "dtype", "=", "dtype", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.load_model.create_image_model": [[38, 61], ["flax.nn.stateful", "flax.nn.stochastic", "module.init_by_shape", "flax.nn.Model", "jax.random.PRNGKey"], "function", ["None"], ["\n", "_AVAILABLE_MODEL_NAMES", "=", "[", "\n", "'Resnet'", "\n", "]", "+", "list", "(", "efficientnet", ".", "MODEL_CONFIGS", ".", "keys", "(", ")", ")", "\n", "\n", "\n", "def", "create_image_model", "(", "\n", "prng_key", ":", "jnp", ".", "ndarray", ",", "batch_size", ":", "int", ",", "image_size", ":", "int", ",", "\n", "module", ":", "flax", ".", "nn", ".", "Module", ")", "->", "Tuple", "[", "flax", ".", "nn", ".", "Model", ",", "flax", ".", "nn", ".", "Collection", "]", ":", "\n", "  ", "\"\"\"Instantiates a FLAX model and its state.\n\n  Args:\n    prng_key: PRNG key to use to sample the initial weights.\n    batch_size: Batch size that the model should expect.\n    image_size: Dimension of the image (assumed to be squared).\n    module: FLAX module describing the model to instantiates.\n\n  Returns:\n    A FLAX model and its state.\n  \"\"\"", "\n", "input_shape", "=", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "3", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", ")", "as", "init_state", ":", "\n", "    ", "with", "flax", ".", "nn", ".", "stochastic", "(", "jax", ".", "random", ".", "PRNGKey", "(", "0", ")", ")", ":", "\n", "      ", "_", ",", "initial_params", "=", "module", ".", "init_by_shape", "(", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.load_model.get_model": [[63, 121], ["load_model.create_image_model", "sam.sam_jax.models.wide_resnet.WideResnet.partial", "jax.random.PRNGKey", "sam.sam_jax.models.wide_resnet_shakeshake.WideResnetShakeShake.partial", "sam.sam_jax.models.pyramidnet.PyramidNetShakeDrop.partial", "sam.sam_jax.models.wide_resnet.WideResnet.partial", "sam.sam_jax.models.wide_resnet_shakeshake.WideResnetShakeShake.partial", "sam.sam_jax.models.pyramidnet.PyramidNetShakeDrop.partial", "ValueError"], "function", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.create_image_model"], ["model", "=", "flax", ".", "nn", ".", "Model", "(", "module", ",", "initial_params", ")", "\n", "", "", "return", "model", ",", "init_state", "\n", "\n", "\n", "", "class", "ModelNameError", "(", "Exception", ")", ":", "\n", "  ", "\"\"\"Exception to raise when the model name is not recognized.\"\"\"", "\n", "pass", "\n", "\n", "\n", "", "def", "_replace_dense_layer", "(", "model", ":", "flax", ".", "nn", ".", "Model", ",", "head", ":", "flax", ".", "nn", ".", "Model", ")", ":", "\n", "  ", "\"\"\"Replaces the last layer (head) of a model with the head of another one.\n\n  Args:\n    model: Model for which we should keep all layers except the head.\n    head: Model from which we should copy the head.\n\n  Returns:\n    A model composed from the last layer of `head` and all the other layers of\n      `model`.\n  \"\"\"", "\n", "new_params", "=", "{", "}", "\n", "for", "(", "ak", ",", "av", ")", ",", "(", "bk", ",", "bv", ")", "in", "zip", "(", "\n", "flax", ".", "traverse_util", ".", "flatten_dict", "(", "model", ".", "params", ")", ".", "items", "(", ")", ",", "\n", "flax", ".", "traverse_util", ".", "flatten_dict", "(", "head", ".", "params", ")", ".", "items", "(", ")", ")", ":", "\n", "    ", "if", "ak", "[", "1", "]", "==", "'dense'", ":", "\n", "      ", "new_params", "[", "bk", "]", "=", "bv", "\n", "", "else", ":", "\n", "      ", "new_params", "[", "ak", "]", "=", "av", "\n", "", "", "return", "head", ".", "replace", "(", "params", "=", "flax", ".", "traverse_util", ".", "unflatten_dict", "(", "new_params", ")", ")", "\n", "\n", "\n", "", "def", "get_model", "(", "\n", "model_name", ":", "str", ",", "\n", "batch_size", ":", "int", ",", "\n", "image_size", ":", "int", ",", "\n", "num_classes", ":", "int", "=", "1000", ",", "\n", "prng_key", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "flax", ".", "nn", ".", "Model", ",", "flax", ".", "nn", ".", "Collection", "]", ":", "\n", "  ", "\"\"\"Returns an initialized model of the chosen architecture.\n\n  Args:\n    model_name: Name of the architecture to use. See image_classification.train\n      flags for a list of available models.\n    batch_size: The batch size that the model should expect.\n    image_size: Dimension of the image (assumed to be squared).\n    num_classes: Dimension of the output layer. Should be 1000, but is left as\n      an argument for consistency with other load_model functions. An error will\n      be raised if num_classes is not 1000.\n    prng_key: PRNG key to use to sample the weights.\n\n  Returns:\n    The initialized model and its state.\n\n  Raises:\n    ModelNameError: If the name of the architecture is not recognized.\n  \"\"\"", "\n", "if", "model_name", "==", "'Resnet50'", ":", "\n", "    ", "module", "=", "resnet", ".", "ResNet50", ".", "partial", "(", "num_classes", "=", "num_classes", ")", "\n", "", "elif", "model_name", "==", "'Resnet101'", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.load_model_test.LoadModelTest.test_CreateModel": [[28, 40], ["absl.testing.parameterized.named_parameters", "sam.sam_jax.models.load_model.get_model", "load_model_test.LoadModelTest.assertIsInstance", "load_model_test.LoadModelTest.assertIsInstance", "numpy.zeros", "load_model_test.LoadModelTest.assertEqual", "flax.nn.stateful", "model"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.get_model"], ["self", ".", "assertIsInstance", "(", "model", ",", "flax", ".", "nn", ".", "Model", ")", "\n", "self", ".", "assertIsInstance", "(", "state", ",", "flax", ".", "nn", ".", "Collection", ")", "\n", "fake_input", "=", "np", ".", "zeros", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ",", "mutable", "=", "False", ")", ":", "\n", "      ", "logits", "=", "model", "(", "fake_input", ",", "train", "=", "False", ")", "\n", "", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "(", "1", ",", "1000", ")", ")", "\n", "\n", "", "def", "test_CreateResnetModel", "(", "self", ")", ":", "\n", "    ", "model", ",", "state", "=", "load_model", ".", "get_model", "(", "'Resnet50'", ",", "1", ",", "224", ",", "1000", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "flax", ".", "nn", ".", "Model", ")", "\n", "self", ".", "assertIsInstance", "(", "state", ",", "flax", ".", "nn", ".", "Collection", ")", "\n", "fake_input", "=", "np", ".", "zeros", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "with", "flax", ".", "nn", ".", "stateful", "(", "state", ",", "mutable", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.load_model_test.LoadModelTest.test_ParameterCount": [[41, 55], ["absl.testing.parameterized.named_parameters", "sam.sam_jax.models.load_model.get_model", "sum", "load_model_test.LoadModelTest.assertEqual", "numpy.prod", "jax.tree_leaves"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.load_model.get_model"], ["      ", "logits", "=", "model", "(", "fake_input", ",", "train", "=", "False", ")", "\n", "", "self", ".", "assertEqual", "(", "logits", ".", "shape", ",", "(", "1", ",", "1000", ")", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "  ", "absltest", ".", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet.BottleneckShakeDrop.apply": [[81, 148], ["sam.sam_jax.models.utils.activation", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "pyramidnet._shortcut", "sam.sam_jax.models.utils.shake_drop_train", "sam.sam_jax.models.utils.shake_drop_eval", "pyramidnet.BottleneckShakeDrop.is_initializing"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._shortcut", "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_drop_train", "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_drop_eval"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "prob", ":", "float", ",", "\n", "alpha_min", ":", "float", ",", "\n", "alpha_max", ":", "float", ",", "\n", "beta_min", ":", "float", ",", "\n", "beta_max", ":", "float", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      prob: Probability of dropping the block (see paper for details).\n      alpha_min: See paper.\n      alpha_max: See paper.\n      beta_min: See paper.\n      beta_max: See paper.\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass (see paper for more details).\n\n    Returns:\n      The output of the bottleneck block.\n    \"\"\"", "\n", "y", "=", "utils", ".", "activation", "(", "x", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'bn_1_pre'", ")", "\n", "y", "=", "nn", ".", "Conv", "(", "\n", "y", ",", "\n", "channels", ",", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'1x1_conv_contract'", ")", "\n", "y", "=", "utils", ".", "activation", "(", "y", ",", "train", "=", "train", ",", "name", "=", "'bn_1_post'", ")", "\n", "y", "=", "nn", ".", "Conv", "(", "\n", "y", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "strides", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'3x3'", ")", "\n", "y", "=", "utils", ".", "activation", "(", "y", ",", "train", "=", "train", ",", "name", "=", "'bn_2'", ")", "\n", "y", "=", "nn", ".", "Conv", "(", "\n", "y", ",", "\n", "channels", "*", "4", ",", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'1x1_conv_expand'", ")", "\n", "y", "=", "utils", ".", "activation", "(", "y", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'bn_3'", ")", "\n", "\n", "if", "train", "and", "not", "self", ".", "is_initializing", "(", ")", ":", "\n", "      ", "y", "=", "utils", ".", "shake_drop_train", "(", "y", ",", "prob", ",", "alpha_min", ",", "alpha_max", ",", "\n", "beta_min", ",", "beta_max", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "", "else", ":", "\n", "      ", "y", "=", "utils", ".", "shake_drop_eval", "(", "y", ",", "prob", ",", "alpha_min", ",", "alpha_max", ")", "\n", "\n", "", "x", "=", "_shortcut", "(", "x", ",", "channels", "*", "4", ",", "strides", ")", "\n", "return", "x", "+", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet.PyramidNetShakeDrop.apply": [[160, 257], ["flax.nn.Conv", "sam.sam_jax.models.utils.activation", "range", "range", "range", "sam.sam_jax.models.utils.activation", "flax.nn.avg_pool", "BottleneckShakeDrop.reshape", "flax.nn.Dense", "pyramidnet._calc_shakedrop_mask_prob", "pyramidnet.BottleneckShakeDrop", "pyramidnet._calc_shakedrop_mask_prob", "pyramidnet.BottleneckShakeDrop", "pyramidnet._calc_shakedrop_mask_prob", "pyramidnet.BottleneckShakeDrop", "int", "int", "int", "round", "round", "round"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._calc_shakedrop_mask_prob", "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._calc_shakedrop_mask_prob", "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._calc_shakedrop_mask_prob"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "num_outputs", ":", "int", ",", "\n", "pyramid_alpha", ":", "int", "=", "200", ",", "\n", "pyramid_depth", ":", "int", "=", "272", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, 3]\n        where dim is the resolution of the image.\n      num_outputs: Dimension of the output of the model (ie number of classes\n        for a classification problem).\n      pyramid_alpha: See paper.\n      pyramid_depth: See paper.\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass (see paper for more details).\n\n    Returns:\n      The output of the PyramidNet model, a tensor of shape\n        [batch_size, num_classes].\n    \"\"\"", "\n", "assert", "(", "pyramid_depth", "-", "2", ")", "%", "9", "==", "0", "\n", "\n", "# Shake-drop hyper-params", "\n", "mask_prob", "=", "0.5", "\n", "alpha_min", ",", "alpha_max", "=", "(", "-", "1.0", ",", "1.0", ")", "\n", "beta_min", ",", "beta_max", "=", "(", "0.0", ",", "1.0", ")", "\n", "\n", "# Bottleneck network size", "\n", "blocks_per_group", "=", "(", "pyramid_depth", "-", "2", ")", "//", "9", "\n", "# See Eqn 2 in https://arxiv.org/abs/1610.02915", "\n", "num_channels", "=", "16", "\n", "# N in https://arxiv.org/abs/1610.02915", "\n", "total_blocks", "=", "blocks_per_group", "*", "3", "\n", "delta_channels", "=", "pyramid_alpha", "/", "total_blocks", "\n", "\n", "x", "=", "nn", ".", "Conv", "(", "\n", "x", ",", "\n", "16", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "name", "=", "'init_conv'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ")", "\n", "x", "=", "utils", ".", "activation", "(", "x", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'init_bn'", ")", "\n", "\n", "layer_num", "=", "1", "\n", "\n", "for", "block_i", "in", "range", "(", "blocks_per_group", ")", ":", "\n", "      ", "num_channels", "+=", "delta_channels", "\n", "layer_mask_prob", "=", "_calc_shakedrop_mask_prob", "(", "layer_num", ",", "total_blocks", ",", "\n", "mask_prob", ")", "\n", "x", "=", "BottleneckShakeDrop", "(", "\n", "x", ",", "\n", "int", "(", "round", "(", "num_channels", ")", ")", ",", "(", "1", ",", "1", ")", ",", "\n", "layer_mask_prob", ",", "\n", "alpha_min", ",", "\n", "alpha_max", ",", "\n", "beta_min", ",", "\n", "beta_max", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "layer_num", "+=", "1", "\n", "\n", "", "for", "block_i", "in", "range", "(", "blocks_per_group", ")", ":", "\n", "      ", "num_channels", "+=", "delta_channels", "\n", "layer_mask_prob", "=", "_calc_shakedrop_mask_prob", "(", "\n", "layer_num", ",", "total_blocks", ",", "mask_prob", ")", "\n", "x", "=", "BottleneckShakeDrop", "(", "x", ",", "int", "(", "round", "(", "num_channels", ")", ")", ",", "\n", "(", "(", "2", ",", "2", ")", "if", "block_i", "==", "0", "else", "(", "1", ",", "1", ")", ")", ",", "\n", "layer_mask_prob", ",", "\n", "alpha_min", ",", "alpha_max", ",", "beta_min", ",", "beta_max", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "layer_num", "+=", "1", "\n", "\n", "", "for", "block_i", "in", "range", "(", "blocks_per_group", ")", ":", "\n", "      ", "num_channels", "+=", "delta_channels", "\n", "layer_mask_prob", "=", "_calc_shakedrop_mask_prob", "(", "\n", "layer_num", ",", "total_blocks", ",", "mask_prob", ")", "\n", "x", "=", "BottleneckShakeDrop", "(", "x", ",", "int", "(", "round", "(", "num_channels", ")", ")", ",", "\n", "(", "(", "2", ",", "2", ")", "if", "block_i", "==", "0", "else", "(", "1", ",", "1", ")", ")", ",", "\n", "layer_mask_prob", ",", "\n", "alpha_min", ",", "alpha_max", ",", "beta_min", ",", "beta_max", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "layer_num", "+=", "1", "\n", "\n", "", "assert", "layer_num", "-", "1", "==", "total_blocks", "\n", "x", "=", "utils", ".", "activation", "(", "x", ",", "train", "=", "train", ",", "name", "=", "'final_bn'", ")", "\n", "x", "=", "nn", ".", "avg_pool", "(", "x", ",", "(", "8", ",", "8", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "nn", ".", "Dense", "(", "x", ",", "num_outputs", ",", "kernel_init", "=", "utils", ".", "dense_layer_init_fn", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._shortcut": [[51, 76], ["flax.nn.avg_pool", "jax.pad"], "function", ["None"], ["def", "_shortcut", "(", "x", ":", "jnp", ".", "ndarray", ",", "chn_out", ":", "int", ",", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "\n", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Pyramid Net shortcut.\n\n  Use Average pooling to downsample.\n  Use zero-padding to increase channels.\n\n  Args:\n    x: Input. Should have shape [batch_size, dim, dim, features]\n      where dim is the resolution (width and height if the input is an image).\n    chn_out: Expected output channels.\n    strides: Output stride.\n\n  Returns:\n    Shortcut value for Pyramid Net. Shape will be\n    [batch_size, dim, dim, chn_out] if strides = (1, 1) (no downsampling) or\n    [batch_size, dim/2, dim/2, chn_out] if strides = (2, 2) (downsampling).\n  \"\"\"", "\n", "chn_in", "=", "x", ".", "shape", "[", "3", "]", "\n", "if", "strides", "!=", "(", "1", ",", "1", ")", ":", "\n", "    ", "x", "=", "nn", ".", "avg_pool", "(", "x", ",", "strides", ",", "strides", ")", "\n", "", "if", "chn_out", "!=", "chn_in", ":", "\n", "    ", "diff", "=", "chn_out", "-", "chn_in", "\n", "x", "=", "jnp", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "diff", "]", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.pyramidnet._calc_shakedrop_mask_prob": [[150, 155], ["float"], "function", ["None"], ["", "", "def", "_calc_shakedrop_mask_prob", "(", "curr_layer", ":", "int", ",", "\n", "total_layers", ":", "int", ",", "\n", "mask_prob", ":", "float", ")", "->", "float", ":", "\n", "  ", "\"\"\"Calculates drop prob depending on the current layer.\"\"\"", "\n", "return", "1", "-", "(", "float", "(", "curr_layer", ")", "/", "total_layers", ")", "*", "mask_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet_shakeshake.Shortcut.apply": [[50, 101], ["flax.nn.avg_pool", "flax.nn.Conv", "flax.nn.avg_pool", "flax.nn.Conv", "jax.numpy.concatenate", "sam.sam_jax.models.utils.activation", "jax.numpy.pad"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      train: If False, will use the moving average for batch norm statistics.\n\n    Returns:\n      The output of the resnet block. Will have shape\n        [batch_size, dim, dim, channels] if strides = (1, 1) or\n        [batch_size, dim/2, dim/2, channels] if strides = (2, 2).\n    \"\"\"", "\n", "\n", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "channels", ":", "\n", "      ", "return", "x", "\n", "\n", "# Skip path 1", "\n", "", "h1", "=", "nn", ".", "avg_pool", "(", "x", ",", "(", "1", ",", "1", ")", ",", "strides", "=", "strides", ",", "padding", "=", "'VALID'", ")", "\n", "h1", "=", "nn", ".", "Conv", "(", "\n", "h1", ",", "\n", "channels", "//", "2", ",", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_h1'", ")", "\n", "\n", "# Skip path 2", "\n", "# The next two lines offset the \"image\" by one pixel on the right and one", "\n", "# down (see Shake-Shake regularization, Xavier Gastaldi for details)", "\n", "pad_arr", "=", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", "\n", "h2", "=", "jnp", ".", "pad", "(", "x", ",", "pad_arr", ")", "[", ":", ",", "1", ":", ",", "1", ":", ",", ":", "]", "\n", "h2", "=", "nn", ".", "avg_pool", "(", "h2", ",", "(", "1", ",", "1", ")", ",", "strides", "=", "strides", ",", "padding", "=", "'VALID'", ")", "\n", "h2", "=", "nn", ".", "Conv", "(", "\n", "h2", ",", "\n", "channels", "//", "2", ",", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_h2'", ")", "\n", "merged_branches", "=", "jnp", ".", "concatenate", "(", "[", "h1", ",", "h2", "]", ",", "axis", "=", "3", ")", "\n", "return", "utils", ".", "activation", "(", "\n", "merged_branches", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'bn_residual'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet_shakeshake.ShakeShakeBlock.apply": [[106, 178], ["jax.nn.relu", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "jax.nn.relu", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "flax.nn.Conv", "sam.sam_jax.models.utils.activation", "wide_resnet_shakeshake.Shortcut", "sam.sam_jax.models.utils.shake_shake_train", "sam.sam_jax.models.utils.shake_shake_eval", "wide_resnet_shakeshake.ShakeShakeBlock.is_initializing"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_shake_train", "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_shake_eval"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass (see paper for more details).\n\n    Returns:\n      The output of the resnet block. Will have shape\n        [batch_size, dim, dim, channels] if strides = (1, 1) or\n        [batch_size, dim/2, dim/2, channels] if strides = (2, 2).\n    \"\"\"", "\n", "a", "=", "b", "=", "residual", "=", "x", "\n", "\n", "a", "=", "jax", ".", "nn", ".", "relu", "(", "a", ")", "\n", "a", "=", "nn", ".", "Conv", "(", "\n", "a", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "strides", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_a_1'", ")", "\n", "a", "=", "utils", ".", "activation", "(", "a", ",", "train", "=", "train", ",", "name", "=", "'bn_a_1'", ")", "\n", "a", "=", "nn", ".", "Conv", "(", "\n", "a", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_a_2'", ")", "\n", "a", "=", "utils", ".", "activation", "(", "a", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'bn_a_2'", ")", "\n", "\n", "b", "=", "jax", ".", "nn", ".", "relu", "(", "b", ")", "\n", "b", "=", "nn", ".", "Conv", "(", "\n", "b", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "strides", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_b_1'", ")", "\n", "b", "=", "utils", ".", "activation", "(", "b", ",", "train", "=", "train", ",", "name", "=", "'bn_b_1'", ")", "\n", "b", "=", "nn", ".", "Conv", "(", "\n", "b", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv_b_2'", ")", "\n", "b", "=", "utils", ".", "activation", "(", "b", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'bn_b_2'", ")", "\n", "\n", "if", "train", "and", "not", "self", ".", "is_initializing", "(", ")", ":", "\n", "      ", "ab", "=", "utils", ".", "shake_shake_train", "(", "a", ",", "b", ",", "true_gradient", "=", "true_gradient", ")", "\n", "", "else", ":", "\n", "      ", "ab", "=", "utils", ".", "shake_shake_eval", "(", "a", ",", "b", ")", "\n", "\n", "# Apply an up projection in case of channel mismatch.", "\n", "", "residual", "=", "Shortcut", "(", "residual", ",", "channels", ",", "strides", ",", "train", ")", "\n", "\n", "return", "residual", "+", "ab", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet_shakeshake.WideResnetShakeShakeGroup.apply": [[183, 217], ["range", "wide_resnet_shakeshake.ShakeShakeBlock"], "methods", ["None"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "blocks_per_group", ":", "int", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      blocks_per_group: How many resnet blocks to add to each group (should be\n        4 blocks for a WRN28, and 6 for a WRN40).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass (see paper for more details).\n\n    Returns:\n      The output of the resnet block. Will have shape\n        [batch_size, dim, dim, channels] if strides = (1, 1) or\n        [batch_size, dim/2, dim/2, channels] if strides = (2, 2).\n    \"\"\"", "\n", "for", "i", "in", "range", "(", "blocks_per_group", ")", ":", "\n", "      ", "x", "=", "ShakeShakeBlock", "(", "\n", "x", ",", "\n", "channels", ",", "\n", "strides", "if", "i", "==", "0", "else", "(", "1", ",", "1", ")", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet_shakeshake.WideResnetShakeShake.apply": [[222, 279], ["flax.nn.Conv", "sam.sam_jax.models.utils.activation", "wide_resnet_shakeshake.WideResnetShakeShakeGroup", "wide_resnet_shakeshake.WideResnetShakeShakeGroup", "wide_resnet_shakeshake.WideResnetShakeShakeGroup", "jax.nn.relu", "flax.nn.avg_pool", "x.reshape.reshape.reshape", "flax.nn.Dense"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "blocks_per_group", ":", "int", ",", "\n", "channel_multiplier", ":", "int", ",", "\n", "num_outputs", ":", "int", ",", "\n", "train", ":", "bool", "=", "True", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements a WideResnet with ShakeShake regularization module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, 3]\n        where dim is the resolution of the image.\n      blocks_per_group: How many resnet blocks to add to each group (should be\n        4 blocks for a WRN26 as per standard shake shake implementation).\n      channel_multiplier: The multiplier to apply to the number of filters in\n        the model (1 is classical resnet, 6 for WRN26-2x6, etc...).\n      num_outputs: Dimension of the output of the model (ie number of classes\n        for a classification problem).\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n      true_gradient: If true, the same mixing parameter will be used for the\n        forward and backward pass (see paper for more details).\n\n    Returns:\n      The output of the WideResnet with ShakeShake regularization, a tensor of\n      shape [batch_size, num_classes].\n    \"\"\"", "\n", "x", "=", "nn", ".", "Conv", "(", "\n", "x", ",", "\n", "16", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "'init_conv'", ")", "\n", "x", "=", "utils", ".", "activation", "(", "x", ",", "apply_relu", "=", "False", ",", "train", "=", "train", ",", "name", "=", "'init_bn'", ")", "\n", "x", "=", "WideResnetShakeShakeGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "16", "*", "channel_multiplier", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "x", "=", "WideResnetShakeShakeGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "32", "*", "channel_multiplier", ",", "(", "2", ",", "2", ")", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "x", "=", "WideResnetShakeShakeGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "64", "*", "channel_multiplier", ",", "(", "2", ",", "2", ")", ",", "\n", "train", "=", "train", ",", "\n", "true_gradient", "=", "true_gradient", ")", "\n", "x", "=", "jax", ".", "nn", ".", "relu", "(", "x", ")", "\n", "x", "=", "nn", ".", "avg_pool", "(", "x", ",", "x", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "return", "nn", ".", "Dense", "(", "x", ",", "num_outputs", ",", "kernel_init", "=", "utils", ".", "dense_layer_init_fn", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet.WideResnetBlock.apply": [[89, 139], ["flax.nn.Conv", "sam.sam_jax.models.utils.activation", "flax.nn.Conv", "wide_resnet._output_add", "sam.sam_jax.models.utils.activation", "sam.sam_jax.models.utils.activation"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet._output_add", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "activate_before_residual", ":", "bool", "=", "False", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      activate_before_residual: True if the batch norm and relu should be\n        applied before the residual branches out (should be True only for the\n        first block of the model).\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n\n    Returns:\n      The output of the resnet block.\n    \"\"\"", "\n", "if", "activate_before_residual", ":", "\n", "      ", "x", "=", "utils", ".", "activation", "(", "x", ",", "train", ",", "name", "=", "'init_bn'", ")", "\n", "orig_x", "=", "x", "\n", "", "else", ":", "\n", "      ", "orig_x", "=", "x", "\n", "\n", "", "block_x", "=", "x", "\n", "if", "not", "activate_before_residual", ":", "\n", "      ", "block_x", "=", "utils", ".", "activation", "(", "block_x", ",", "train", ",", "name", "=", "'init_bn'", ")", "\n", "\n", "", "block_x", "=", "nn", ".", "Conv", "(", "\n", "block_x", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "strides", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv1'", ")", "\n", "block_x", "=", "utils", ".", "activation", "(", "block_x", ",", "train", "=", "train", ",", "name", "=", "'bn_2'", ")", "\n", "block_x", "=", "nn", ".", "Conv", "(", "\n", "block_x", ",", "\n", "channels", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "bias", "=", "False", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "name", "=", "'conv2'", ")", "\n", "\n", "return", "_output_add", "(", "block_x", ",", "orig_x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet.WideResnetGroup.apply": [[144, 180], ["range", "wide_resnet.WideResnetBlock", "wide_resnet._output_add"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet._output_add"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "blocks_per_group", ":", "int", ",", "\n", "channels", ":", "int", ",", "\n", "strides", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "1", ",", "1", ")", ",", "\n", "activate_before_residual", ":", "bool", "=", "False", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements the forward pass in the module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, features]\n        where dim is the resolution (width and height if the input is an image).\n      blocks_per_group: How many resnet blocks to add to each group (should be\n        4 blocks for a WRN28, and 6 for a WRN40).\n      channels: How many channels to use in the convolutional layers.\n      strides: Strides for the pooling.\n      activate_before_residual: True if the batch norm and relu should be\n        applied before the residual branches out (should be True only for the\n        first group of the model).\n      train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n\n    Returns:\n      The output of the resnet block.\n    \"\"\"", "\n", "orig_x", "=", "x", "\n", "for", "i", "in", "range", "(", "blocks_per_group", ")", ":", "\n", "      ", "x", "=", "WideResnetBlock", "(", "\n", "x", ",", "\n", "channels", ",", "\n", "strides", "if", "i", "==", "0", "else", "(", "1", ",", "1", ")", ",", "\n", "activate_before_residual", "=", "activate_before_residual", "and", "not", "i", ",", "\n", "train", "=", "train", ")", "\n", "", "if", "FLAGS", ".", "use_additional_skip_connections", ":", "\n", "      ", "x", "=", "_output_add", "(", "x", ",", "orig_x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet.WideResnet.apply": [[185, 238], ["flax.nn.Conv", "wide_resnet.WideResnetGroup", "wide_resnet.WideResnetGroup", "wide_resnet.WideResnetGroup", "sam.sam_jax.models.utils.activation", "flax.nn.avg_pool", "_output_add.reshape", "flax.nn.Dense", "wide_resnet._output_add"], "methods", ["home.repos.pwc.inspect_result.google-research_sam.models.utils.activation", "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet._output_add"], ["def", "apply", "(", "self", ",", "\n", "x", ":", "jnp", ".", "ndarray", ",", "\n", "blocks_per_group", ":", "int", ",", "\n", "channel_multiplier", ":", "int", ",", "\n", "num_outputs", ":", "int", ",", "\n", "train", ":", "bool", "=", "True", ")", "->", "jnp", ".", "ndarray", ":", "\n", "    ", "\"\"\"Implements a WideResnet module.\n\n    Args:\n      x: Input to the module. Should have shape [batch_size, dim, dim, 3]\n        where dim is the resolution of the image.\n      blocks_per_group: How many resnet blocks to add to each group (should be\n        4 blocks for a WRN28, and 6 for a WRN40).\n      channel_multiplier: The multiplier to apply to the number of filters in\n        the model (1 is classical resnet, 10 for WRN28-10, etc...).\n      num_outputs: Dimension of the output of the model (ie number of classes\n        for a classification problem).\n      train: If False, will use the moving average for batch norm statistics.\n\n    Returns:\n      The output of the WideResnet, a tensor of shape [batch_size, num_classes].\n    \"\"\"", "\n", "first_x", "=", "x", "\n", "x", "=", "nn", ".", "Conv", "(", "\n", "x", ",", "\n", "16", ",", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "name", "=", "'init_conv'", ",", "\n", "kernel_init", "=", "utils", ".", "conv_kernel_init_fn", ",", "\n", "bias", "=", "False", ")", "\n", "x", "=", "WideResnetGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "16", "*", "channel_multiplier", ",", "\n", "activate_before_residual", "=", "True", ",", "\n", "train", "=", "train", ")", "\n", "x", "=", "WideResnetGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "32", "*", "channel_multiplier", ",", "(", "2", ",", "2", ")", ",", "\n", "train", "=", "train", ")", "\n", "x", "=", "WideResnetGroup", "(", "\n", "x", ",", "\n", "blocks_per_group", ",", "\n", "64", "*", "channel_multiplier", ",", "(", "2", ",", "2", ")", ",", "\n", "train", "=", "train", ")", "\n", "if", "FLAGS", ".", "use_additional_skip_connections", ":", "\n", "      ", "x", "=", "_output_add", "(", "x", ",", "first_x", ")", "\n", "", "x", "=", "utils", ".", "activation", "(", "x", ",", "train", "=", "train", ",", "name", "=", "'pre-pool-bn'", ")", "\n", "x", "=", "nn", ".", "avg_pool", "(", "x", ",", "x", ".", "shape", "[", "1", ":", "3", "]", ")", "\n", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "nn", ".", "Dense", "(", "x", ",", "num_outputs", ",", "kernel_init", "=", "utils", ".", "dense_layer_init_fn", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_sam.models.wide_resnet._output_add": [[66, 84], ["flax.nn.avg_pool", "jax.numpy.pad"], "function", ["None"], ["def", "_output_add", "(", "block_x", ":", "jnp", ".", "ndarray", ",", "orig_x", ":", "jnp", ".", "ndarray", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Add two tensors, padding them with zeros or pooling them if necessary.\n\n  Args:\n    block_x: Output of a resnet block.\n    orig_x: Residual branch to add to the output of the resnet block.\n\n  Returns:\n    The sum of blocks_x and orig_x. If necessary, orig_x will be average pooled\n      or zero padded so that its shape matches orig_x.\n  \"\"\"", "\n", "stride", "=", "orig_x", ".", "shape", "[", "-", "2", "]", "//", "block_x", ".", "shape", "[", "-", "2", "]", "\n", "strides", "=", "(", "stride", ",", "stride", ")", "\n", "if", "block_x", ".", "shape", "[", "-", "1", "]", "!=", "orig_x", ".", "shape", "[", "-", "1", "]", ":", "\n", "    ", "orig_x", "=", "nn", ".", "avg_pool", "(", "orig_x", ",", "strides", ",", "strides", ")", "\n", "channels_to_add", "=", "block_x", ".", "shape", "[", "-", "1", "]", "-", "orig_x", ".", "shape", "[", "-", "1", "]", "\n", "orig_x", "=", "jnp", ".", "pad", "(", "orig_x", ",", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "channels_to_add", ")", "]", ")", "\n", "", "return", "block_x", "+", "orig_x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.activation": [[32, 56], ["flax.nn.BatchNorm.partial", "nn.BatchNorm.partial.", "jax.nn.relu", "jax.nn.relu"], "function", ["None"], ["def", "activation", "(", "x", ":", "jnp", ".", "ndarray", ",", "\n", "train", ":", "bool", ",", "\n", "apply_relu", ":", "bool", "=", "True", ",", "\n", "name", ":", "str", "=", "''", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Applies BatchNorm and then (optionally) ReLU.\n\n  Args:\n    x: Tensor on which the activation should be applied.\n    train: If False, will use the moving average for batch norm statistics.\n        Else, will use statistics computed on the batch.\n    apply_relu: Whether or not ReLU should be applied after batch normalization.\n    name: How to name the BatchNorm layer.\n\n  Returns:\n    The input tensor where BatchNorm and (optionally) ReLU where applied.\n  \"\"\"", "\n", "batch_norm", "=", "nn", ".", "BatchNorm", ".", "partial", "(", "\n", "use_running_average", "=", "not", "train", ",", "\n", "momentum", "=", "_BATCHNORM_MOMENTUM", ",", "\n", "epsilon", "=", "_BATCHNORM_EPSILON", ")", "\n", "x", "=", "batch_norm", "(", "x", ",", "name", "=", "name", ")", "\n", "if", "apply_relu", ":", "\n", "    ", "x", "=", "jax", ".", "nn", ".", "relu", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.dense_layer_init_fn": [[64, 80], ["jax.random.uniform", "jax.random.uniform"], "function", ["None"], ["def", "dense_layer_init_fn", "(", "key", ":", "jnp", ".", "ndarray", ",", "\n", "shape", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "dtype", ":", "jnp", ".", "dtype", "=", "jnp", ".", "float32", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Initializer for the final dense layer.\n\n  Args:\n    key: PRNG key to use to sample the weights.\n    shape: Shape of the tensor to initialize.\n    dtype: Data type of the tensor to initialize.\n\n  Returns:\n    The initialized tensor.\n  \"\"\"", "\n", "num_units_out", "=", "shape", "[", "1", "]", "\n", "unif_init_range", "=", "1.0", "/", "(", "num_units_out", ")", "**", "(", "0.5", ")", "\n", "return", "jax", ".", "random", ".", "uniform", "(", "key", ",", "shape", ",", "dtype", ",", "-", "1", ")", "*", "unif_init_range", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_shake_train": [[82, 119], ["jax.random.split", "jax.random.split", "jax.random.uniform", "jax.random.uniform", "jax.random.uniform", "jax.random.uniform", "flax.nn.make_rng", "len", "jax.lax.stop_gradient", "jax.lax.stop_gradient"], "function", ["None"], ["", "def", "shake_shake_train", "(", "xa", ":", "jnp", ".", "ndarray", ",", "\n", "xb", ":", "jnp", ".", "ndarray", ",", "\n", "rng", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Shake-shake regularization in training mode.\n\n  Shake-shake regularization interpolates between inputs A and B\n  with *different* random uniform (per-sample) interpolation factors\n  for the forward and backward/gradient passes.\n\n  Args:\n    xa: Input, branch A.\n    xb: Input, branch B.\n    rng: PRNG key.\n    true_gradient: If true, the same mixing parameter will be used for the\n      forward and backward pass (see paper for more details).\n\n  Returns:\n    Mix of input branches.\n  \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "    ", "rng", "=", "flax", ".", "nn", ".", "make_rng", "(", ")", "\n", "", "gate_forward_key", ",", "gate_backward_key", "=", "jax", ".", "random", ".", "split", "(", "rng", ",", "num", "=", "2", ")", "\n", "gate_shape", "=", "(", "len", "(", "xa", ")", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "# Draw different interpolation factors (gate) for forward and backward pass.", "\n", "gate_forward", "=", "jax", ".", "random", ".", "uniform", "(", "\n", "gate_forward_key", ",", "gate_shape", ",", "dtype", "=", "jnp", ".", "float32", ",", "minval", "=", "0.0", ",", "maxval", "=", "1.0", ")", "\n", "x_forward", "=", "xa", "*", "gate_forward", "+", "xb", "*", "(", "1.0", "-", "gate_forward", ")", "\n", "if", "true_gradient", ":", "\n", "    ", "return", "x_forward", "\n", "", "gate_backward", "=", "jax", ".", "random", ".", "uniform", "(", "\n", "gate_backward_key", ",", "gate_shape", ",", "dtype", "=", "jnp", ".", "float32", ",", "minval", "=", "0.0", ",", "maxval", "=", "1.0", ")", "\n", "# Compute interpolated x for forward and backward.", "\n", "x_backward", "=", "xa", "*", "gate_backward", "+", "xb", "*", "(", "1.0", "-", "gate_backward", ")", "\n", "# Combine using stop_gradient.", "\n", "return", "x_backward", "+", "jax", ".", "lax", ".", "stop_gradient", "(", "x_forward", "-", "x_backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_shake_eval": [[121, 133], ["None"], "function", ["None"], ["", "def", "shake_shake_eval", "(", "xa", ":", "jnp", ".", "ndarray", ",", "xb", ":", "jnp", ".", "ndarray", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"Shake-shake regularization in testing mode.\n\n  Args:\n    xa: Input, branch A.\n    xb: Input, branch B.\n\n  Returns:\n    Mix of input branches.\n  \"\"\"", "\n", "# Blend between inputs A and B 50%-50%.", "\n", "return", "(", "xa", "+", "xb", ")", "*", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_drop_train": [[135, 184], ["jax.random.split", "jax.random.split", "jax.random.bernoulli", "jax.random.bernoulli", "mask.astype.astype", "jax.random.uniform", "jax.random.uniform", "jax.random.uniform", "jax.random.uniform", "flax.nn.make_rng", "len", "jax.lax.stop_gradient", "jax.lax.stop_gradient"], "function", ["None"], ["", "def", "shake_drop_train", "(", "x", ":", "jnp", ".", "ndarray", ",", "\n", "mask_prob", ":", "float", ",", "\n", "alpha_min", ":", "float", ",", "\n", "alpha_max", ":", "float", ",", "\n", "beta_min", ":", "float", ",", "\n", "beta_max", ":", "float", ",", "\n", "rng", ":", "Optional", "[", "jnp", ".", "ndarray", "]", "=", "None", ",", "\n", "true_gradient", ":", "bool", "=", "False", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"ShakeDrop training pass.\n\n  See https://arxiv.org/abs/1802.02375\n\n  Args:\n    x: Input to apply ShakeDrop to.\n    mask_prob: Mask probability.\n    alpha_min: Alpha range lower.\n    alpha_max: Alpha range upper.\n    beta_min: Beta range lower.\n    beta_max: Beta range upper.\n    rng: PRNG key (if `None`, uses `flax.nn.make_rng`).\n    true_gradient: If true, the same mixing parameter will be used for the\n      forward and backward pass (see paper for more details).\n\n  Returns:\n    The regularized tensor.\n  \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "    ", "rng", "=", "flax", ".", "nn", ".", "make_rng", "(", ")", "\n", "", "bern_key", ",", "alpha_key", ",", "beta_key", "=", "jax", ".", "random", ".", "split", "(", "rng", ",", "num", "=", "3", ")", "\n", "rnd_shape", "=", "(", "len", "(", "x", ")", ",", "1", ",", "1", ",", "1", ")", "\n", "# Bernoulli variable b_l in Eqn 6, https://arxiv.org/abs/1802.02375.", "\n", "mask", "=", "jax", ".", "random", ".", "bernoulli", "(", "bern_key", ",", "mask_prob", ",", "rnd_shape", ")", "\n", "mask", "=", "mask", ".", "astype", "(", "jnp", ".", "float32", ")", "\n", "\n", "alpha_values", "=", "jax", ".", "random", ".", "uniform", "(", "\n", "alpha_key", ",", "\n", "rnd_shape", ",", "\n", "dtype", "=", "jnp", ".", "float32", ",", "\n", "minval", "=", "alpha_min", ",", "\n", "maxval", "=", "alpha_max", ")", "\n", "beta_values", "=", "jax", ".", "random", ".", "uniform", "(", "\n", "beta_key", ",", "rnd_shape", ",", "dtype", "=", "jnp", ".", "float32", ",", "minval", "=", "beta_min", ",", "maxval", "=", "beta_max", ")", "\n", "# See Eqn 6 in https://arxiv.org/abs/1802.02375.", "\n", "rand_forward", "=", "mask", "+", "alpha_values", "-", "mask", "*", "alpha_values", "\n", "if", "true_gradient", ":", "\n", "    ", "return", "x", "*", "rand_forward", "\n", "", "rand_backward", "=", "mask", "+", "beta_values", "-", "mask", "*", "beta_values", "\n", "return", "x", "*", "rand_backward", "+", "jax", ".", "lax", ".", "stop_gradient", "(", "\n", "x", "*", "rand_forward", "-", "x", "*", "rand_backward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_sam.models.utils.shake_drop_eval": [[186, 206], ["None"], "function", ["None"], ["", "def", "shake_drop_eval", "(", "x", ":", "jnp", ".", "ndarray", ",", "\n", "mask_prob", ":", "float", ",", "\n", "alpha_min", ":", "float", ",", "\n", "alpha_max", ":", "float", ")", "->", "jnp", ".", "ndarray", ":", "\n", "  ", "\"\"\"ShakeDrop eval pass.\n\n  See https://arxiv.org/abs/1802.02375\n\n  Args:\n    x: Input to apply ShakeDrop to.\n    mask_prob: Mask probability.\n    alpha_min: Alpha range lower.\n    alpha_max: Alpha range upper.\n\n  Returns:\n    The regularized tensor.\n  \"\"\"", "\n", "expected_alpha", "=", "(", "alpha_max", "+", "alpha_min", ")", "/", "2", "\n", "# See Eqn 6 in https://arxiv.org/abs/1802.02375.", "\n", "return", "(", "mask_prob", "+", "expected_alpha", "-", "mask_prob", "*", "expected_alpha", ")", "*", "x", "\n", "", ""]]}