{"home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.inference.main": [[23, 122], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "yaml.load.update", "datasets.MelDataset", "logging.info", "torch.cuda.is_available", "utils.load_model", "logging.info", "model.eval().to.remove_weight_norm", "model.eval().to.eval().to", "logging.info", "logging.basicConfig", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.path.dirname", "os.path.dirname", "os.path.join", "os.path.join", "open", "yaml.load", "vars", "ValueError", "torch.device", "torch.cuda.set_device", "torch.device", "torch.no_grad", "tqdm.tqdm", "enumerate", "logging.basicConfig", "logging.basicConfig", "logging.warning", "utils.read_hdf5", "ValueError", "model.eval().to.eval", "torch.cuda.empty_cache", "len", "os.path.exists", "os.path.exists", "torch.tensor().to", "time.time", "model.eval().to.inference().view", "pbar.set_postfix", "soundfile.write", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "model.inference().view.cpu().numpy", "torch.tensor", "model.eval().to.inference", "time.time", "len", "model.inference().view.cpu"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.load_model", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.remove_weight_norm", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.inference"], ["def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Run decoding process.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Decode dumped features with trained Parallel WaveGAN Generator \"", "\n", "\"(See detail in parallel_wavegan/bin/decode.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--inputdir\"", ",", "'-i'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory including feature files. \"", "\n", "\"you need to specify either feats-scp or inputdir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--outdir\"", ",", "'-o'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory to save generated speech.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "'-c'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint file to be loaded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "'-g'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"yaml format configuration file. if not explicitly provided, \"", "\n", "\"it will be searched in the checkpoint directory. (default=None)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"logging level. higher is more logging. (default=1)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"rank for distributed training. no need to explictly specify.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--force_cpu\"", ",", "type", "=", "bool", ",", "default", "=", "False", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set logger", "\n", "if", "args", ".", "verbose", ">", "1", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "DEBUG", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "elif", "args", ".", "verbose", ">", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "WARN", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "logging", ".", "warning", "(", "\"Skip DEBUG/INFO messages\"", ")", "\n", "\n", "# check directory existence", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "outdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "outdir", ")", "\n", "\n", "# load config", "\n", "", "if", "args", ".", "config", "is", "None", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "checkpoint", ")", "\n", "args", ".", "config", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"config.yml\"", ")", "\n", "", "with", "open", "(", "args", ".", "config", ")", "as", "f", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "", "config", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "\n", "# check arguments", "\n", "if", "args", ".", "inputdir", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Please specify either --inputdir or --feats-scp.\"", ")", "\n", "\n", "# get dataset", "\n", "", "if", "config", "[", "\"format\"", "]", "==", "\"hdf5\"", ":", "\n", "        ", "mel_query", "=", "\"*.h5\"", "\n", "mel_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"mel\"", ")", "# NOQA", "\n", "", "elif", "config", "[", "\"format\"", "]", "==", "\"npy\"", ":", "\n", "        ", "mel_query", "=", "\"*-feats.npy\"", "\n", "mel_load_fn", "=", "np", ".", "load", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Support only hdf5 or npy format.\"", ")", "\n", "", "dataset", "=", "MelDataset", "(", "\n", "args", ".", "inputdir", ",", "\n", "mel_query", "=", "mel_query", ",", "\n", "mel_load_fn", "=", "mel_load_fn", ",", "\n", "return_utt_id", "=", "True", ",", "\n", ")", "\n", "logging", ".", "info", "(", "f\"The number of features to be decoded = {len(dataset)}.\"", ")", "\n", "\n", "# setup model", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "rank", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "model", "=", "load_model", "(", "args", ".", "checkpoint", ",", "config", ")", "\n", "logging", ".", "info", "(", "f\"Loaded model parameters from {args.checkpoint}.\"", ")", "\n", "model", ".", "remove_weight_norm", "(", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# start generation", "\n", "total_rtf", "=", "0.0", "\n", "with", "torch", ".", "no_grad", "(", ")", ",", "tqdm", "(", "dataset", ",", "desc", "=", "\"[decode]\"", ")", "as", "pbar", ":", "\n", "        ", "for", "idx", ",", "(", "utt_id", ",", "c", ")", "in", "enumerate", "(", "pbar", ",", "1", ")", ":", "# utt_id: mel id     c: mel feats", "\n", "# generate", "\n", "            ", "if", "not", "(", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"outdir\"", "]", ",", "f\"{utt_id}_gen.wav\"", ")", ")", ")", ":", "\n", "                ", "c", "=", "torch", ".", "tensor", "(", "c", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "y", "=", "model", ".", "inference", "(", "c", ")", ".", "view", "(", "-", "1", ")", "\n", "rtf", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "(", "len", "(", "y", ")", "/", "config", "[", "\"sampling_rate\"", "]", ")", "\n", "pbar", ".", "set_postfix", "(", "{", "\"RTF\"", ":", "rtf", "}", ")", "\n", "total_rtf", "+=", "rtf", "\n", "\n", "# save as PCM 16 bit wav file", "\n", "sf", ".", "write", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"outdir\"", "]", ",", "f\"{utt_id}_gen.wav\"", ")", ",", "\n", "y", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "config", "[", "\"sampling_rate\"", "]", ",", "\"PCM_16\"", ")", "\n", "del", "c", ",", "y", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# report average RTF", "\n", "", "", "logging", ".", "info", "(", "f\"Finished generation of {idx} utterances (RTF = {total_rtf / idx:.03f}).\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.__init__": [[45, 85], ["torch.device", "tensorboardX.SummaryWriter", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "steps", ",", "\n", "epochs", ",", "\n", "data_loader", ",", "\n", "sampler", ",", "\n", "model", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "config", ",", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize trainer.\n\n        Args:\n            steps (int): Initial global steps.\n            epochs (int): Initial global epochs.\n            data_loader (dict): Dict of data loaders. It must contrain \"train\" and \"dev\" loaders.\n            model (dict): Dict of models. It must contrain \"generator\" and \"discriminator\" models.\n            criterion (dict): Dict of criterions. It must contrain \"stft\" and \"mse\" criterions.\n            optimizer (dict): Dict of optimizers. It must contrain \"generator\" and \"discriminator\" optimizers.\n            scheduler (dict): Dict of schedulers. It must contrain \"generator\" and \"discriminator\" schedulers.\n            config (dict): Config dict loaded from yaml format configuration file.\n            device (torch.deive): Pytorch device instance.\n\n        \"\"\"", "\n", "self", ".", "steps", "=", "steps", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "config", "[", "\"outdir\"", "]", ")", "\n", "self", ".", "finish_train", "=", "False", "\n", "self", ".", "total_train_loss", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "total_eval_loss", "=", "defaultdict", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.run": [[86, 101], ["tqdm.tqdm.tqdm", "train.Trainer.tqdm.close", "logging.info", "train.Trainer._train_epoch"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._train_epoch"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run training.\"\"\"", "\n", "self", ".", "tqdm", "=", "tqdm", "(", "initial", "=", "self", ".", "steps", ",", "\n", "total", "=", "self", ".", "config", "[", "\"train_max_steps\"", "]", ",", "\n", "desc", "=", "\"[train]\"", ")", "\n", "while", "True", ":", "\n", "# train one epoch", "\n", "            ", "self", ".", "_train_epoch", "(", ")", "\n", "\n", "# check whether training is finished", "\n", "if", "self", ".", "finish_train", ":", "\n", "                ", "break", "\n", "\n", "", "", "self", ".", "tqdm", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\"Finished training.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.save_checkpoint": [[102, 135], ["torch.save", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "train.Trainer.optimizer[].state_dict", "train.Trainer.optimizer[].state_dict", "train.Trainer.scheduler[].state_dict", "train.Trainer.scheduler[].state_dict", "train.Trainer.model[].module.state_dict", "train.Trainer.model[].module.state_dict", "train.Trainer.model[].state_dict", "train.Trainer.model[].state_dict", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save"], ["", "def", "save_checkpoint", "(", "self", ",", "checkpoint_path", ")", ":", "\n", "        ", "\"\"\"Save checkpoint.\n\n        Args:\n            checkpoint_path (str): Checkpoint path to be saved.\n\n        \"\"\"", "\n", "state_dict", "=", "{", "\n", "\"optimizer\"", ":", "{", "\n", "\"generator\"", ":", "self", ".", "optimizer", "[", "\"generator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "optimizer", "[", "\"discriminator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "\"scheduler\"", ":", "{", "\n", "\"generator\"", ":", "self", ".", "scheduler", "[", "\"generator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "scheduler", "[", "\"discriminator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "\"steps\"", ":", "self", ".", "steps", ",", "\n", "\"epochs\"", ":", "self", ".", "epochs", ",", "\n", "}", "\n", "if", "self", ".", "config", "[", "\"distributed\"", "]", ":", "\n", "            ", "state_dict", "[", "\"model\"", "]", "=", "{", "\n", "\"generator\"", ":", "self", ".", "model", "[", "\"generator\"", "]", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "state_dict", "[", "\"model\"", "]", "=", "{", "\n", "\"generator\"", ":", "self", ".", "model", "[", "\"generator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "checkpoint_path", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "checkpoint_path", ")", ")", "\n", "", "torch", ".", "save", "(", "state_dict", ",", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.load_checkpoint": [[136, 158], ["torch.load", "train.Trainer.model[].module.load_state_dict", "train.Trainer.model[].module.load_state_dict", "train.Trainer.model[].load_state_dict", "train.Trainer.model[].load_state_dict", "train.Trainer.optimizer[].load_state_dict", "train.Trainer.optimizer[].load_state_dict", "train.Trainer.scheduler[].load_state_dict", "train.Trainer.scheduler[].load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "checkpoint_path", ",", "load_only_params", "=", "False", ")", ":", "\n", "        ", "\"\"\"Load checkpoint.\n\n        Args:\n            checkpoint_path (str): Checkpoint path to be loaded.\n            load_only_params (bool): Whether to load only model parameters.\n\n        \"\"\"", "\n", "state_dict", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "if", "self", ".", "config", "[", "\"distributed\"", "]", ":", "\n", "            ", "self", ".", "model", "[", "\"generator\"", "]", ".", "module", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", "[", "\"generator\"", "]", ")", "\n", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "module", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", "[", "\"discriminator\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "[", "\"generator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", "[", "\"generator\"", "]", ")", "\n", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", "[", "\"discriminator\"", "]", ")", "\n", "", "if", "not", "load_only_params", ":", "\n", "            ", "self", ".", "steps", "=", "state_dict", "[", "\"steps\"", "]", "\n", "self", ".", "epochs", "=", "state_dict", "[", "\"epochs\"", "]", "\n", "self", ".", "optimizer", "[", "\"generator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", "[", "\"generator\"", "]", ")", "\n", "self", ".", "optimizer", "[", "\"discriminator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", "[", "\"discriminator\"", "]", ")", "\n", "self", ".", "scheduler", "[", "\"generator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"scheduler\"", "]", "[", "\"generator\"", "]", ")", "\n", "self", ".", "scheduler", "[", "\"discriminator\"", "]", ".", "load_state_dict", "(", "state_dict", "[", "\"scheduler\"", "]", "[", "\"discriminator\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._train_step": [[159, 275], ["tuple.append", "tuple.append", "batch[].to", "batch[].to", "tuple", "range", "embed_loss.item", "numpy.mean", "sc_loss.item", "mag_loss.item", "gen_loss.item", "train.Trainer.optimizer[].zero_grad", "gen_loss.backward", "train.Trainer.optimizer[].step", "train.Trainer.scheduler[].step", "train.Trainer.tqdm.update", "train.Trainer._check_train_finish", "encoder.inference.inference.preprocess_wav_torch().squeeze", "encoder.inference.inference.embed_utterance_torch", "encoder.inference.inference.preprocess_wav_torch().squeeze", "encoder.inference.inference.embed_utterance_torch", "numpy.array", "y_.squeeze", "batch[].to.squeeze", "uncondition_adv_loss.item", "speaker_condition_adv_loss.item", "torch.nn.utils.clip_grad_norm_", "real_loss.item", "fake_loss.item", "uncondition_discriminator_loss.item", "speaker_condition_discriminator_loss.item", "train.Trainer.optimizer[].zero_grad", "uncondition_discriminator_loss.backward", "train.Trainer.optimizer[].step", "train.Trainer.scheduler[].step", "train.Trainer.optimizer[].zero_grad", "speaker_condition_discriminator_loss.backward", "train.Trainer.optimizer[].step", "train.Trainer.scheduler[].step", "x_.to", "p_.new_ones", "embed_p_.new_ones", "train.Trainer.model[].parameters", "torch.no_grad", "y_.detach", "y_.detach", "p.new_ones", "p_.new_zeros", "embed_p.new_ones", "embed_p_.new_zeros", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "encoder.inference.inference.preprocess_wav_torch", "encoder.inference.inference.preprocess_wav_torch", "p_.size", "embed_p_.size", "p.size", "p_.size", "embed_p.size", "embed_p_.size", "train.Trainer.model[].parameters", "train.Trainer.model[].parameters"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_train_finish", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch"], ["", "", "def", "_train_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Train model one step.\"\"\"", "\n", "# parse batch", "\n", "x", "=", "[", "]", "\n", "x", ".", "append", "(", "batch", "[", "'noise'", "]", ")", "\n", "x", ".", "append", "(", "batch", "[", "'feats'", "]", ")", "\n", "embed", "=", "batch", "[", "'embed'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "y", "=", "batch", "[", "'audios'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "x", "=", "tuple", "(", "[", "x_", ".", "to", "(", "self", ".", "device", ")", "for", "x_", "in", "x", "]", ")", "\n", "\n", "#######################", "\n", "#      Generator      #", "\n", "#######################", "\n", "y_", "=", "self", ".", "model", "[", "\"generator\"", "]", "(", "*", "x", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Singer Perceptual loss", "\n", "embed_loss", "=", "0", "\n", "spk_similariy", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y_", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "preprocess_", "=", "encoder", ".", "preprocess_wav_torch", "(", "y_", "[", "i", "]", ")", ".", "squeeze", "(", ")", "\n", "loss_embed_", "=", "encoder", ".", "embed_utterance_torch", "(", "preprocess_", ")", "\n", "preprocess", "=", "encoder", ".", "preprocess_wav_torch", "(", "y", "[", "i", "]", ")", ".", "squeeze", "(", ")", "\n", "loss_embed", "=", "encoder", ".", "embed_utterance_torch", "(", "preprocess", ")", "\n", "embed_loss", "+=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "loss_embed", ",", "loss_embed_", ")", "\n", "\n", "", "self", ".", "total_train_loss", "[", "\"train/embed_loss\"", "]", "+=", "embed_loss", ".", "item", "(", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/spk_similariy\"", "]", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "spk_similariy", ")", ")", "\n", "gen_loss", "=", "self", ".", "config", "[", "\"lambda_embed\"", "]", "*", "embed_loss", "\n", "\n", "# multi-resolution sfft loss", "\n", "\n", "sc_loss", ",", "mag_loss", "=", "self", ".", "criterion", "[", "\"stft\"", "]", "(", "y_", ".", "squeeze", "(", "1", ")", ",", "y", ".", "squeeze", "(", "1", ")", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/spectral_convergence_loss\"", "]", "+=", "sc_loss", ".", "item", "(", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/log_stft_magnitude_loss\"", "]", "+=", "mag_loss", ".", "item", "(", ")", "\n", "gen_loss", "+=", "sc_loss", "+", "mag_loss", "\n", "\n", "\n", "# adversarial loss", "\n", "if", "self", ".", "steps", ">", "self", ".", "config", "[", "\"discriminator_train_start_steps\"", "]", ":", "\n", "            ", "p_", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y_", ")", "\n", "embed_p_", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y_", ",", "embed", ")", "\n", "\n", "uncondition_adv_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p_", ",", "p_", ".", "new_ones", "(", "p_", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/uncondition_adv_loss\"", "]", "+=", "uncondition_adv_loss", ".", "item", "(", ")", "\n", "\n", "# Embed discriminator loss", "\n", "speaker_condition_adv_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p_", ",", "embed_p_", ".", "new_ones", "(", "embed_p_", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/speaker_condition_adv_loss\"", "]", "+=", "speaker_condition_adv_loss", ".", "item", "(", ")", "\n", "adv_loss", "=", "uncondition_adv_loss", "+", "speaker_condition_adv_loss", "\n", "\n", "# add adversarial loss to generator loss", "\n", "gen_loss", "+=", "self", ".", "config", "[", "\"lambda_adv\"", "]", "*", "adv_loss", "\n", "\n", "", "self", ".", "total_train_loss", "[", "\"train/generator_loss\"", "]", "+=", "gen_loss", ".", "item", "(", ")", "\n", "\n", "# update generator", "\n", "self", ".", "optimizer", "[", "\"generator\"", "]", ".", "zero_grad", "(", ")", "\n", "gen_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "config", "[", "\"generator_grad_norm\"", "]", ">", "0", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", "[", "\"generator\"", "]", ".", "parameters", "(", ")", ",", "\n", "self", ".", "config", "[", "\"generator_grad_norm\"", "]", ")", "\n", "", "self", ".", "optimizer", "[", "\"generator\"", "]", ".", "step", "(", ")", "\n", "self", ".", "scheduler", "[", "\"generator\"", "]", ".", "step", "(", ")", "\n", "\n", "#######################", "\n", "#    Discriminator    #", "\n", "#######################", "\n", "if", "self", ".", "steps", ">", "self", ".", "config", "[", "\"discriminator_train_start_steps\"", "]", "and", "self", ".", "steps", "%", "self", ".", "config", "[", "\"interval\"", "]", "==", "0", ":", "\n", "# re-compute y_ which leads better quality", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "y_", "=", "self", ".", "model", "[", "\"generator\"", "]", "(", "*", "x", ")", "\n", "\n", "# discriminator loss", "\n", "", "embed_p", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y", ",", "embed", ")", "\n", "embed_p_", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y_", ".", "detach", "(", ")", ",", "embed", ")", "\n", "\n", "p", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y", ")", "\n", "p_", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y_", ".", "detach", "(", ")", ")", "\n", "\n", "real_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p", ",", "p", ".", "new_ones", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "fake_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p_", ",", "p_", ".", "new_zeros", "(", "p_", ".", "size", "(", ")", ")", ")", "\n", "uncondition_discriminator_loss", "=", "real_loss", "+", "fake_loss", "\n", "\n", "embed_real_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p", ",", "embed_p", ".", "new_ones", "(", "embed_p", ".", "size", "(", ")", ")", ")", "\n", "embed_fake_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p_", ",", "embed_p_", ".", "new_zeros", "(", "embed_p_", ".", "size", "(", ")", ")", ")", "\n", "speaker_condition_discriminator_loss", "=", "embed_real_loss", "+", "embed_fake_loss", "\n", "\n", "self", ".", "total_train_loss", "[", "\"train/real_loss\"", "]", "+=", "real_loss", ".", "item", "(", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/fake_loss\"", "]", "+=", "fake_loss", ".", "item", "(", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/uncondition_discriminator_loss\"", "]", "+=", "uncondition_discriminator_loss", ".", "item", "(", ")", "\n", "self", ".", "total_train_loss", "[", "\"train/speaker_condition_discriminator_loss\"", "]", "+=", "speaker_condition_discriminator_loss", ".", "item", "(", ")", "\n", "# update discriminator", "\n", "self", ".", "optimizer", "[", "\"discriminator\"", "]", ".", "zero_grad", "(", ")", "\n", "uncondition_discriminator_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "config", "[", "\"discriminator_grad_norm\"", "]", ">", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "parameters", "(", ")", ",", "\n", "self", ".", "config", "[", "\"discriminator_grad_norm\"", "]", ")", "\n", "", "self", ".", "optimizer", "[", "\"discriminator\"", "]", ".", "step", "(", ")", "\n", "self", ".", "scheduler", "[", "\"discriminator\"", "]", ".", "step", "(", ")", "\n", "\n", "# update discriminator", "\n", "self", ".", "optimizer", "[", "\"embed_discriminator\"", "]", ".", "zero_grad", "(", ")", "\n", "speaker_condition_discriminator_loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "config", "[", "\"embed_discriminator_grad_norm\"", "]", ">", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", "[", "\"embed_discriminator\"", "]", ".", "parameters", "(", ")", ",", "\n", "self", ".", "config", "[", "\"embed_discriminator_grad_norm\"", "]", ")", "\n", "", "self", ".", "optimizer", "[", "\"embed_discriminator\"", "]", ".", "step", "(", ")", "\n", "self", ".", "scheduler", "[", "\"embed_discriminator\"", "]", ".", "step", "(", ")", "\n", "# update counts", "\n", "", "self", ".", "steps", "+=", "1", "\n", "self", ".", "tqdm", ".", "update", "(", "1", ")", "\n", "self", ".", "_check_train_finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._train_epoch": [[276, 300], ["enumerate", "logging.info", "train.Trainer._train_step", "train.Trainer._check_log_interval", "train.Trainer._check_eval_interval", "train.Trainer._check_save_interval", "train.Trainer.sampler[].set_epoch"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._train_step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_log_interval", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_eval_interval", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_save_interval"], ["", "def", "_train_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Train model one epoch.\"\"\"", "\n", "for", "train_steps_per_epoch", ",", "batch", "in", "enumerate", "(", "self", ".", "data_loader", "[", "\"train\"", "]", ",", "1", ")", ":", "\n", "# train one step", "\n", "            ", "self", ".", "_train_step", "(", "batch", ")", "\n", "\n", "# check interval", "\n", "self", ".", "_check_log_interval", "(", ")", "\n", "self", ".", "_check_eval_interval", "(", ")", "\n", "self", ".", "_check_save_interval", "(", ")", "\n", "\n", "# check whether training is finished", "\n", "if", "self", ".", "finish_train", ":", "\n", "                ", "return", "\n", "\n", "# update", "\n", "", "", "self", ".", "epochs", "+=", "1", "\n", "self", ".", "train_steps_per_epoch", "=", "train_steps_per_epoch", "\n", "logging", ".", "info", "(", "f\"(Steps: {self.steps}) Finished {self.epochs} epoch training \"", "\n", "f\"({self.train_steps_per_epoch} steps per epoch).\"", ")", "\n", "\n", "# needed for shuffle in distributed training", "\n", "if", "self", ".", "config", "[", "\"distributed\"", "]", ":", "\n", "            ", "self", ".", "sampler", "[", "\"train\"", "]", ".", "set_epoch", "(", "self", ".", "epochs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._eval_step": [[301, 381], ["torch.no_grad", "tuple.append", "batch[].to", "tuple", "batch[].to", "range", "embed_loss.item", "numpy.mean", "uncondition_adv_loss.item", "speaker_condition_adv_loss.item", "sc_loss.item", "mag_loss.item", "gen_loss.item", "real_loss.item", "fake_loss.item", "uncondition_discriminator_loss.item", "speaker_condition_discriminator_loss.item", "tuple.append", "tuple.append", "tuple.append", "encoder.inference.inference.preprocess_wav_torch().squeeze", "encoder.inference.inference.embed_utterance_torch", "encoder.inference.inference.preprocess_wav_torch().squeeze", "encoder.inference.inference.embed_utterance_torch", "spk_similariy.append", "numpy.array", "y_.squeeze", "batch[].to.squeeze", "p_.new_ones", "embed_p_.new_ones", "p.new_ones", "p_.new_zeros", "embed_p.new_ones", "embed_p_.new_zeros", "x_.to", "sklearn.metrics.pairwise.cosine_similarity", "p_.size", "embed_p_.size", "p.size", "p_.size", "embed_p.size", "embed_p_.size", "encoder.inference.inference.preprocess_wav_torch", "encoder.inference.inference.preprocess_wav_torch", "encoder.inference.embed_utterance_torch.reshape().cpu().numpy", "encoder.inference.embed_utterance_torch.reshape().cpu().numpy", "encoder.inference.embed_utterance_torch.reshape().cpu", "encoder.inference.embed_utterance_torch.reshape().cpu", "encoder.inference.embed_utterance_torch.reshape", "encoder.inference.embed_utterance_torch.reshape"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_eval_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Evaluate model one step.\"\"\"", "\n", "# parse batch", "\n", "x", "=", "[", "]", "\n", "\n", "\n", "if", "self", ".", "config", "[", "'use_noise_input'", "]", ":", "\n", "            ", "x", ".", "append", "(", "batch", "[", "'noise'", "]", ")", "\n", "", "if", "self", ".", "config", "[", "'use_f0'", "]", ":", "\n", "            ", "x", ".", "append", "(", "batch", "[", "'f0_origins'", "]", ")", "\n", "", "if", "self", ".", "config", "[", "'use_chroma'", "]", ":", "\n", "            ", "x", ".", "append", "(", "batch", "[", "'chromas'", "]", ")", "\n", "", "x", ".", "append", "(", "batch", "[", "'feats'", "]", ")", "\n", "\n", "y", "=", "batch", "[", "'audios'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "x", "=", "tuple", "(", "[", "x_", ".", "to", "(", "self", ".", "device", ")", "for", "x_", "in", "x", "]", ")", "\n", "embed", "=", "batch", "[", "'embed'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "#######################", "\n", "#      Generator      #", "\n", "#######################", "\n", "y_", "=", "self", ".", "model", "[", "\"generator\"", "]", "(", "*", "x", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Singer Perceptual loss", "\n", "embed_loss", "=", "0", "\n", "spk_similariy", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y_", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "preprocess_", "=", "encoder", ".", "preprocess_wav_torch", "(", "y_", "[", "i", "]", ")", ".", "squeeze", "(", ")", "\n", "loss_embed_", "=", "encoder", ".", "embed_utterance_torch", "(", "preprocess_", ")", "\n", "preprocess", "=", "encoder", ".", "preprocess_wav_torch", "(", "y", "[", "i", "]", ")", ".", "squeeze", "(", ")", "\n", "loss_embed", "=", "encoder", ".", "embed_utterance_torch", "(", "preprocess", ")", "\n", "embed_loss", "+=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "loss_embed", ",", "loss_embed_", ")", "\n", "spk_similariy", ".", "append", "(", "cosine_similarity", "(", "loss_embed_", ".", "reshape", "(", "1", ",", "256", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "loss_embed", ".", "reshape", "(", "1", ",", "256", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "gen_loss", "=", "self", ".", "config", "[", "\"lambda_embed\"", "]", "*", "embed_loss", "\n", "self", ".", "total_eval_loss", "[", "\"eval/embed_loss\"", "]", "+=", "embed_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/spk_similariy\"", "]", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "spk_similariy", ")", ")", "\n", "\n", "# multi-resolution stft loss", "\n", "sc_loss", ",", "mag_loss", "=", "self", ".", "criterion", "[", "\"stft\"", "]", "(", "y_", ".", "squeeze", "(", "1", ")", ",", "y", ".", "squeeze", "(", "1", ")", ")", "\n", "gen_loss", "+=", "sc_loss", "+", "mag_loss", "\n", "\n", "# Unconditional/Conditional Loss", "\n", "p_", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y_", ")", "\n", "embed_p_", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y_", ",", "embed", ")", "\n", "\n", "uncondition_adv_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p_", ",", "p_", ".", "new_ones", "(", "p_", ".", "size", "(", ")", ")", ")", "\n", "gen_loss", "+=", "self", ".", "config", "[", "\"lambda_adv\"", "]", "*", "uncondition_adv_loss", "\n", "speaker_condition_adv_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p_", ",", "embed_p_", ".", "new_ones", "(", "embed_p_", ".", "size", "(", ")", ")", ")", "\n", "gen_loss", "+=", "self", ".", "config", "[", "\"lambda_adv\"", "]", "*", "speaker_condition_adv_loss", "\n", "\n", "#######################", "\n", "#    Discriminator    #", "\n", "#######################", "\n", "p", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y", ")", "\n", "p_", "=", "self", ".", "model", "[", "\"discriminator\"", "]", "(", "y_", ")", "\n", "\n", "embed_p", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y", ",", "embed", ")", "\n", "embed_p_", "=", "self", ".", "model", "[", "\"embed_discriminator\"", "]", "(", "y_", ",", "embed", ")", "\n", "\n", "# Unconditional Loss", "\n", "real_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p", ",", "p", ".", "new_ones", "(", "p", ".", "size", "(", ")", ")", ")", "\n", "fake_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "p_", ",", "p_", ".", "new_zeros", "(", "p_", ".", "size", "(", ")", ")", ")", "\n", "uncondition_discriminator_loss", "=", "real_loss", "+", "fake_loss", "\n", "\n", "# Conditional Loss", "\n", "embed_real_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p", ",", "embed_p", ".", "new_ones", "(", "embed_p", ".", "size", "(", ")", ")", ")", "\n", "embed_fake_loss", "=", "self", ".", "criterion", "[", "\"mse\"", "]", "(", "embed_p_", ",", "embed_p_", ".", "new_zeros", "(", "embed_p_", ".", "size", "(", ")", ")", ")", "\n", "speaker_condition_discriminator_loss", "=", "embed_real_loss", "+", "embed_fake_loss", "\n", "\n", "# add to total eval loss", "\n", "self", ".", "total_eval_loss", "[", "\"eval/uncondition_adv_loss\"", "]", "+=", "uncondition_adv_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/speaker_condition_adv_loss\"", "]", "+=", "speaker_condition_adv_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/spectral_convergence_loss\"", "]", "+=", "sc_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/log_stft_magnitude_loss\"", "]", "+=", "mag_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/generator_loss\"", "]", "+=", "gen_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/real_loss\"", "]", "+=", "real_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/fake_loss\"", "]", "+=", "fake_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/uncondition_discriminator_loss\"", "]", "+=", "uncondition_discriminator_loss", ".", "item", "(", ")", "\n", "self", ".", "total_eval_loss", "[", "\"eval/speaker_condition_discriminator_loss\"", "]", "+=", "speaker_condition_discriminator_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._eval_epoch": [[382, 417], ["logging.info", "train.Trainer.model.keys", "enumerate", "logging.info", "train.Trainer.total_eval_loss.keys", "train.Trainer._write_to_tensorboard", "collections.defaultdict", "train.Trainer.model.keys", "train.Trainer.model[].eval", "tqdm.tqdm.tqdm", "train.Trainer._eval_step", "logging.info", "train.Trainer.model[].train", "train.Trainer._genearete_and_save_intermediate_result"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._write_to_tensorboard", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._eval_step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.train", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._genearete_and_save_intermediate_result"], ["", "def", "_eval_epoch", "(", "self", ")", ":", "\n", "\n", "        ", "\"\"\"Evaluate model one epoch.\"\"\"", "\n", "\n", "logging", ".", "info", "(", "f\"(Steps: {self.steps}) Start evaluation.\"", ")", "\n", "# change mode", "\n", "for", "key", "in", "self", ".", "model", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "model", "[", "key", "]", ".", "eval", "(", ")", "\n", "\n", "# calculate loss for each batch", "\n", "", "for", "eval_steps_per_epoch", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "self", ".", "data_loader", "[", "\"dev\"", "]", ",", "desc", "=", "\"[eval]\"", ")", ",", "1", ")", ":", "\n", "# eval one step", "\n", "            ", "self", ".", "_eval_step", "(", "batch", ")", "\n", "\n", "# save intermediate result", "\n", "if", "eval_steps_per_epoch", "==", "1", ":", "\n", "                ", "self", ".", "_genearete_and_save_intermediate_result", "(", "batch", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "f\"(Steps: {self.steps}) Finished evaluation \"", "\n", "f\"({eval_steps_per_epoch} steps per epoch).\"", ")", "\n", "\n", "# average loss", "\n", "for", "key", "in", "self", ".", "total_eval_loss", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "total_eval_loss", "[", "key", "]", "/=", "eval_steps_per_epoch", "\n", "logging", ".", "info", "(", "f\"(Steps: {self.steps}) {key} = {self.total_eval_loss[key]:.4f}.\"", ")", "\n", "\n", "# record", "\n", "", "self", ".", "_write_to_tensorboard", "(", "self", ".", "total_eval_loss", ")", "\n", "\n", "# reset", "\n", "self", ".", "total_eval_loss", "=", "defaultdict", "(", "float", ")", "\n", "\n", "# restore mode", "\n", "for", "key", "in", "self", ".", "model", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "model", "[", "key", "]", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._genearete_and_save_intermediate_result": [[418, 467], ["torch.no_grad", "x.append", "batch[].to", "tuple", "y_batch.to.to.to", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "enumerate", "x.append", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "zip", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "plt.subplot", "plt.plot", "plt.title", "plt.subplot", "plt.plot", "plt.title", "plt.tight_layout", "plt.savefig", "plt.close", "numpy.clip", "numpy.clip", "soundfile.write", "soundfile.write", "x_.to", "numpy.clip.view().cpu().numpy", "numpy.clip.view().cpu().numpy", "os.path.join.replace", "os.path.join.replace", "os.path.join.replace", "os.path.join.replace", "numpy.clip.view().cpu", "numpy.clip.view().cpu", "numpy.clip.view", "numpy.clip.view"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.plot", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.plot"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_genearete_and_save_intermediate_result", "(", "self", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Generate and save intermediate result.\"\"\"", "\n", "# delayed import to avoid error related backend error", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "# generate", "\n", "x", "=", "[", "]", "\n", "if", "self", ".", "config", "[", "'use_noise_input'", "]", ":", "\n", "            ", "x", ".", "append", "(", "batch", "[", "'noise'", "]", ")", "\n", "\n", "", "x", ".", "append", "(", "batch", "[", "'feats'", "]", ")", "\n", "y_batch", "=", "batch", "[", "'audios'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "x_batch", "=", "tuple", "(", "[", "x_", ".", "to", "(", "self", ".", "device", ")", "for", "x_", "in", "x", "]", ")", "\n", "\n", "y_batch", "=", "y_batch", ".", "to", "(", "self", ".", "device", ")", "\n", "y_batch_", "=", "self", ".", "model", "[", "\"generator\"", "]", "(", "*", "x_batch", ")", "\n", "\n", "# check directory", "\n", "dirname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "config", "[", "\"outdir\"", "]", ",", "f\"predictions/{self.steps}steps\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "for", "idx", ",", "(", "y", ",", "y_", ")", "in", "enumerate", "(", "zip", "(", "y_batch", ",", "y_batch_", ")", ",", "1", ")", ":", "\n", "# convert to ndarray", "\n", "            ", "y", ",", "y_", "=", "y", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "y_", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# plot figure and save it", "\n", "figname", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "f\"{idx}.png\"", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "1", ")", "\n", "plt", ".", "plot", "(", "y", ")", "\n", "plt", ".", "title", "(", "\"groundtruth speech\"", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "2", ")", "\n", "plt", ".", "plot", "(", "y_", ")", "\n", "plt", ".", "title", "(", "f\"generated speech @ {self.steps} steps\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "figname", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "# save as wavfile", "\n", "y", "=", "np", ".", "clip", "(", "y", ",", "-", "1", ",", "1", ")", "\n", "y_", "=", "np", ".", "clip", "(", "y_", ",", "-", "1", ",", "1", ")", "\n", "sf", ".", "write", "(", "figname", ".", "replace", "(", "\".png\"", ",", "\"_ref.wav\"", ")", ",", "y", ",", "\n", "self", ".", "config", "[", "\"sampling_rate\"", "]", ",", "\"PCM_16\"", ")", "\n", "sf", ".", "write", "(", "figname", ".", "replace", "(", "\".png\"", ",", "\"_gen.wav\"", ")", ",", "y_", ",", "\n", "self", ".", "config", "[", "\"sampling_rate\"", "]", ",", "\"PCM_16\"", ")", "\n", "\n", "if", "idx", ">=", "self", ".", "config", "[", "\"num_save_intermediate_results\"", "]", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._write_to_tensorboard": [[468, 472], ["loss.items", "train.Trainer.writer.add_scalar"], "methods", ["None"], ["", "", "", "def", "_write_to_tensorboard", "(", "self", ",", "loss", ")", ":", "\n", "        ", "\"\"\"Write to tensorboard.\"\"\"", "\n", "for", "key", ",", "value", "in", "loss", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "writer", ".", "add_scalar", "(", "key", ",", "value", ",", "self", ".", "steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_save_interval": [[473, 478], ["train.Trainer.save_checkpoint", "logging.info", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.save_checkpoint"], ["", "", "def", "_check_save_interval", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "steps", "%", "self", ".", "config", "[", "\"save_interval_steps\"", "]", "==", "0", ":", "\n", "            ", "self", ".", "save_checkpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "config", "[", "\"outdir\"", "]", ",", "f\"checkpoint-{self.steps}steps.pkl\"", ")", ")", "\n", "logging", ".", "info", "(", "f\"Successfully saved checkpoint @ {self.steps} steps.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_eval_interval": [[479, 482], ["train.Trainer._eval_epoch"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._eval_epoch"], ["", "", "def", "_check_eval_interval", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "steps", "%", "self", ".", "config", "[", "\"eval_interval_steps\"", "]", "==", "0", ":", "\n", "            ", "self", ".", "_eval_epoch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_log_interval": [[483, 492], ["train.Trainer.total_train_loss.keys", "train.Trainer._write_to_tensorboard", "collections.defaultdict", "logging.info"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._write_to_tensorboard"], ["", "", "def", "_check_log_interval", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "steps", "%", "self", ".", "config", "[", "\"log_interval_steps\"", "]", "==", "0", ":", "\n", "            ", "for", "key", "in", "self", ".", "total_train_loss", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "total_train_loss", "[", "key", "]", "/=", "self", ".", "config", "[", "\"log_interval_steps\"", "]", "\n", "logging", ".", "info", "(", "f\"(Steps: {self.steps}) {key} = {self.total_train_loss[key]:.4f}.\"", ")", "\n", "", "self", ".", "_write_to_tensorboard", "(", "self", ".", "total_train_loss", ")", "\n", "\n", "# reset", "\n", "self", ".", "total_train_loss", "=", "defaultdict", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._check_train_finish": [[493, 496], ["None"], "methods", ["None"], ["", "", "def", "_check_train_finish", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "steps", ">=", "self", ".", "config", "[", "\"train_max_steps\"", "]", ":", "\n", "            ", "self", ".", "finish_train", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer._adjust_length": [[497, 513], ["len", "numpy.pad", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "def", "_adjust_length", "(", "self", ",", "x", ",", "c", ")", ":", "\n", "        ", "\"\"\"Adjust the audio and feature lengths.\n\n        Note:\n            Basically we assume that the length of x and c are adjusted\n            through preprocessing stage, but if we use other library processed\n            features, this process will be needed.\n\n        \"\"\"", "\n", "if", "len", "(", "x", ")", "<", "len", "(", "c", ")", "*", "self", ".", "hop_size", ":", "\n", "            ", "x", "=", "np", ".", "pad", "(", "x", ",", "(", "0", ",", "len", "(", "c", ")", "*", "self", ".", "hop_size", "-", "len", "(", "x", ")", ")", ",", "mode", "=", "\"edge\"", ")", "\n", "\n", "# check the legnth is valid", "\n", "", "assert", "len", "(", "x", ")", "==", "len", "(", "c", ")", "*", "self", ".", "hop_size", "\n", "\n", "return", "x", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.main": [[515, 854], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "yaml.load.update", "yaml.load.items", "os.path.join", "os.path.join", "datasets.AudioMelEmbedDataset", "logging.info", "os.path.join", "os.path.join", "datasets.AudioMelEmbedDataset", "logging.info", "datasets.Embeds_Collater", "datasets.Embeds_Collater", "getattr", "getattr", "getattr", "getattr", "yaml.load.get", "yaml.load.get", "getattr", "getattr", "getattr", "getattr", "getattr", "getattr", "logging.info", "logging.info", "logging.info", "utils.simple_table", "train.Trainer", "encoder.inference.load_model", "logging.info", "encoder.inference._model.parameters", "encoder.inference.num_params", "torch.cuda.is_available", "torch.device", "print", "print", "torch.device", "torch.cuda.set_device", "logging.basicConfig", "os.path.exists", "os.path.exists", "os.makedirs", "os.makedirs", "open", "yaml.load", "vars", "open", "yaml.dump", "logging.info", "DistributedSampler", "DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "yaml.load.get", "yaml.load.get", "yaml.load.get", "yaml.load.get", "getattr.to", "getattr.to", "getattr.to", "getattr.to", "torch.nn.MSELoss().to", "torch.nn.L1Loss().to", "layers.PQMF().to", "losses.MultiResolutionSTFTLoss().to", "yaml.load.get", "yaml.load.get", "yaml.load.get", "getattr.", "getattr.", "getattr.", "yaml.load.get", "yaml.load.get", "yaml.load.get", "getattr.", "getattr.", "getattr.", "DistributedDataParallel", "DistributedDataParallel", "DistributedDataParallel", "len", "train.Trainer.load_checkpoint", "logging.info", "len", "train.Trainer.load_checkpoint", "logging.info", "train.Trainer.run", "int", "torch.distributed.init_process_group", "logging.basicConfig", "logging.basicConfig", "logging.warning", "os.path.join", "os.path.join", "yaml.load.get", "yaml.load.get", "yaml.load.get", "yaml.load.get", "config[].get", "config[].get", "model[].parameters", "model[].parameters", "model[].parameters", "train.Trainer.save_checkpoint", "logging.info", "config[].get", "len", "len", "getattr.", "getattr.", "getattr.", "getattr.", "torch.nn.MSELoss", "torch.nn.L1Loss", "layers.PQMF", "losses.MultiResolutionSTFTLoss", "ImportError", "os.path.join", "os.path.join", "yaml.load.get"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.simple_table", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.load_model", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.num_params", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.load_checkpoint", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.load_checkpoint", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.run", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.train.Trainer.save_checkpoint"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Run training process.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Train Multi-Singer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--inputdir\"", ",", "'-i'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory to input feats .\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--outdir\"", ",", "'-o'", ",", "type", "=", "str", ",", "default", "=", "\"checkpoints/\"", ",", "\n", "help", "=", "\"directory to save checkpoints.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "'-c'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"yaml format configuration file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pretrain\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "nargs", "=", "\"?\"", ",", "\n", "help", "=", "\"checkpoint file path to load pretrained params. (default=\\\"\\\")\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume\"", ",", "'-r'", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "nargs", "=", "\"?\"", ",", "\n", "help", "=", "\"checkpoint file path to resume training. (default=\\\"\\\")\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"logging level. higher is more logging. (default=1)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rank\"", ",", "\"--local_rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"rank for distributed training. no need to explictly specify.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "\n", "args", ".", "distributed", "=", "False", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "print", "(", "\"USE CPU\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"USE GPU %d\"", "%", "args", ".", "rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "# effective when using fixed size inputs", "\n", "# see https://discuss.pytorch.org/t/what-does-torch-backends-cudnn-benchmark-do/5936", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "rank", ")", "\n", "# setup for distributed training", "\n", "# see example: https://github.com/NVIDIA/apex/tree/master/examples/simple/distributed", "\n", "if", "\"WORLD_SIZE\"", "in", "os", ".", "environ", ":", "\n", "            ", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "args", ".", "distributed", "=", "args", ".", "world_size", ">", "1", "\n", "", "if", "args", ".", "distributed", ":", "\n", "            ", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ",", "init_method", "=", "\"env://\"", ")", "\n", "\n", "# suppress logging for distributed training", "\n", "# if args.rank != 0:", "\n", "#     sys.stdout = open(os.devnull, \"w\")", "\n", "\n", "# set logger", "\n", "", "", "if", "args", ".", "verbose", ">", "1", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "DEBUG", ",", "stream", "=", "sys", ".", "stdout", ",", "\n", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "elif", "args", ".", "verbose", ">", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "INFO", ",", "stream", "=", "sys", ".", "stdout", ",", "\n", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "WARN", ",", "stream", "=", "sys", ".", "stdout", ",", "\n", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "logging", ".", "warning", "(", "\"Skip DEBUG/INFO messages\"", ")", "\n", "\n", "# check directory existence", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "outdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "outdir", ")", "\n", "\n", "\n", "# load and save config", "\n", "", "with", "open", "(", "args", ".", "config", ")", "as", "f", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "", "config", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "config", "[", "\"version\"", "]", "=", "0.0", "# add version info", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "outdir", ",", "\"config.yml\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "config", ",", "f", ",", "Dumper", "=", "yaml", ".", "Dumper", ")", "\n", "", "for", "key", ",", "value", "in", "config", ".", "items", "(", ")", ":", "\n", "        ", "logging", ".", "info", "(", "f\"{key} = {value}\"", ")", "\n", "\n", "# get dataset", "\n", "", "if", "config", "[", "\"remove_short_samples\"", "]", ":", "\n", "        ", "frames_threshold", "=", "config", "[", "\"batch_max_steps\"", "]", "//", "config", "[", "\"hop_size\"", "]", "+", "2", "*", "config", "[", "\"generator_params\"", "]", ".", "get", "(", "\"aux_context_window\"", ",", "0", ")", "\n", "", "else", ":", "\n", "        ", "frames_threshold", "=", "None", "\n", "\n", "", "train_text", "=", "os", ".", "path", ".", "join", "(", "args", ".", "inputdir", ",", "'train.txt'", ")", "\n", "\n", "train_dataset", "=", "AudioMelEmbedDataset", "(", "\n", "root_file", "=", "train_text", ",", "\n", "feat_type", "=", "config", ".", "get", "(", "\"feat_type\"", ",", "\"librosa\"", ")", ",", "\n", "frames_threshold", "=", "frames_threshold", ",", "\n", "use_f0", "=", "config", "[", "'use_f0'", "]", ",", "\n", "use_chroma", "=", "config", "[", "'use_chroma'", "]", ",", "\n", "allow_cache", "=", "config", ".", "get", "(", "\"allow_cache\"", ",", "False", ")", ",", "# keep compatibility", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "f\"The number of training files = {len(train_dataset)}.\"", ")", "\n", "\n", "dev_text", "=", "os", ".", "path", ".", "join", "(", "args", ".", "inputdir", ",", "'dev.txt'", ")", "\n", "dev_dataset", "=", "AudioMelEmbedDataset", "(", "\n", "root_file", "=", "dev_text", ",", "\n", "feat_type", "=", "config", ".", "get", "(", "\"feat_type\"", ",", "\"librosa\"", ")", ",", "\n", "frames_threshold", "=", "frames_threshold", "*", "10", ",", "\n", "use_f0", "=", "config", "[", "'use_f0'", "]", ",", "\n", "use_chroma", "=", "config", "[", "'use_chroma'", "]", ",", "\n", "allow_cache", "=", "config", ".", "get", "(", "\"allow_cache\"", ",", "False", ")", ",", "# keep compatibility", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "f\"The number of development files = {len(dev_dataset)}.\"", ")", "\n", "dataset", "=", "{", "\n", "\"train\"", ":", "train_dataset", ",", "\n", "\"dev\"", ":", "dev_dataset", ",", "\n", "}", "\n", "\n", "# get data loader", "\n", "collater", "=", "Embeds_Collater", "(", "\n", "batch_max_steps", "=", "config", "[", "\"batch_max_steps\"", "]", ",", "\n", "out_dim", "=", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ",", "\n", "hop_size", "=", "config", "[", "\"hop_size\"", "]", ",", "\n", "# keep compatibility", "\n", "aux_context_window", "=", "config", "[", "\"generator_params\"", "]", ".", "get", "(", "\"aux_context_window\"", ",", "0", ")", ",", "\n", "# keep compatibility", "\n", "use_noise_input", "=", "config", "[", "'use_noise_input'", "]", ",", "\n", "use_f0", "=", "config", "[", "'use_f0'", "]", ",", "\n", "use_chroma", "=", "config", "[", "'use_chroma'", "]", "\n", ")", "\n", "eval_collater", "=", "Embeds_Collater", "(", "\n", "batch_max_steps", "=", "10", "*", "config", "[", "\"batch_max_steps\"", "]", ",", "\n", "out_dim", "=", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ",", "\n", "hop_size", "=", "config", "[", "\"hop_size\"", "]", ",", "\n", "# keep compatibility", "\n", "aux_context_window", "=", "config", "[", "\"generator_params\"", "]", ".", "get", "(", "\"aux_context_window\"", ",", "0", ")", ",", "\n", "# keep compatibility", "\n", "use_noise_input", "=", "config", "[", "'use_noise_input'", "]", ",", "\n", "use_f0", "=", "config", "[", "'use_f0'", "]", ",", "\n", "use_chroma", "=", "config", "[", "'use_chroma'", "]", "\n", ")", "\n", "sampler", "=", "{", "\"train\"", ":", "None", ",", "\"dev\"", ":", "None", "}", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "# setup sampler for distributed training", "\n", "        ", "from", "torch", ".", "utils", ".", "data", ".", "distributed", "import", "DistributedSampler", "\n", "sampler", "[", "\"train\"", "]", "=", "DistributedSampler", "(", "\n", "dataset", "=", "dataset", "[", "\"train\"", "]", ",", "\n", "num_replicas", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "sampler", "[", "\"dev\"", "]", "=", "DistributedSampler", "(", "\n", "dataset", "=", "dataset", "[", "\"dev\"", "]", ",", "\n", "num_replicas", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "", "data_loader", "=", "{", "\n", "\"train\"", ":", "DataLoader", "(", "\n", "dataset", "=", "dataset", "[", "\"train\"", "]", ",", "\n", "shuffle", "=", "False", "if", "args", ".", "distributed", "else", "True", ",", "\n", "collate_fn", "=", "collater", ",", "\n", "batch_size", "=", "config", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "config", "[", "\"num_workers\"", "]", ",", "\n", "sampler", "=", "sampler", "[", "\"train\"", "]", ",", "\n", "pin_memory", "=", "config", "[", "\"pin_memory\"", "]", ",", "\n", ")", ",", "\n", "\"dev\"", ":", "DataLoader", "(", "\n", "dataset", "=", "dataset", "[", "\"dev\"", "]", ",", "\n", "shuffle", "=", "False", "if", "args", ".", "distributed", "else", "True", ",", "\n", "collate_fn", "=", "eval_collater", ",", "\n", "batch_size", "=", "config", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "config", "[", "\"num_workers\"", "]", ",", "\n", "sampler", "=", "sampler", "[", "\"dev\"", "]", ",", "\n", "pin_memory", "=", "config", "[", "\"pin_memory\"", "]", ",", "\n", ")", ",", "\n", "}", "\n", "\n", "\n", "# define models and optimizers", "\n", "generator_class", "=", "getattr", "(", "\n", "models", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"generator_type\"", ",", "\"ParallelWaveGANGenerator\"", ")", ",", "\n", ")", "\n", "discriminator_class", "=", "getattr", "(", "\n", "models", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"discriminator_type\"", ",", "\"SC_ParallelWaveGANDiscriminator_01\"", ")", ",", "\n", ")", "\n", "embed_discriminator_class", "=", "getattr", "(", "\n", "models", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"embed_discriminator_type\"", ",", "\"SC_ParallelWaveGANDiscriminator_01\"", ")", ",", "\n", ")", "\n", "loss_class", "=", "getattr", "(", "\n", "losses", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"loss_type\"", ",", "\"MultiResolutionSTFTLoss\"", ")", ",", "\n", ")", "\n", "model", "=", "{", "\n", "\"generator\"", ":", "generator_class", "(", "\n", "**", "config", "[", "\"generator_params\"", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "\"discriminator\"", ":", "discriminator_class", "(", "\n", "**", "config", "[", "\"discriminator_params\"", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "\"embed_discriminator\"", ":", "embed_discriminator_class", "(", "\n", "**", "config", "[", "\"embed_discriminator_params\"", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "}", "\n", "criterion", "=", "{", "\n", "\"stft\"", ":", "loss_class", "(", "**", "config", "[", "\"stft_loss_params\"", "]", ")", ".", "to", "(", "device", ")", ",", "\n", "\"mse\"", ":", "torch", ".", "nn", ".", "MSELoss", "(", ")", ".", "to", "(", "device", ")", ",", "\n", "}", "\n", "\n", "if", "config", ".", "get", "(", "\"use_feat_match_loss\"", ",", "False", ")", ":", "# keep compatibility", "\n", "        ", "criterion", "[", "\"l1\"", "]", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", ".", "to", "(", "device", ")", "\n", "", "if", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ">", "1", ":", "\n", "        ", "criterion", "[", "\"pqmf\"", "]", "=", "PQMF", "(", "\n", "subbands", "=", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ",", "\n", "# keep compatibility", "\n", "**", "config", ".", "get", "(", "\"pqmf_params\"", ",", "{", "}", ")", "\n", ")", ".", "to", "(", "device", ")", "\n", "", "if", "config", ".", "get", "(", "\"use_subband_stft_loss\"", ",", "False", ")", ":", "# keep compatibility", "\n", "        ", "assert", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ">", "1", "\n", "criterion", "[", "\"sub_stft\"", "]", "=", "MultiResolutionSTFTLoss", "(", "\n", "**", "config", "[", "\"subband_stft_loss_params\"", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "generator_optimizer_class", "=", "getattr", "(", "\n", "optimizers", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"generator_optimizer_type\"", ",", "\"RAdam\"", ")", ",", "\n", ")", "\n", "discriminator_optimizer_class", "=", "getattr", "(", "\n", "optimizers", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"discriminator_optimizer_type\"", ",", "\"RAdam\"", ")", ",", "\n", ")", "\n", "embed_discriminator_optimizer_class", "=", "getattr", "(", "\n", "optimizers", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"embed_discriminator_optimizer_type\"", ",", "\"RAdam\"", ")", ",", "\n", ")", "\n", "optimizer", "=", "{", "\n", "\"generator\"", ":", "generator_optimizer_class", "(", "\n", "model", "[", "\"generator\"", "]", ".", "parameters", "(", ")", ",", "\n", "**", "config", "[", "\"generator_optimizer_params\"", "]", ",", "\n", ")", ",", "\n", "\"discriminator\"", ":", "discriminator_optimizer_class", "(", "\n", "model", "[", "\"discriminator\"", "]", ".", "parameters", "(", ")", ",", "\n", "**", "config", "[", "\"discriminator_optimizer_params\"", "]", ",", "\n", ")", ",", "\n", "\"embed_discriminator\"", ":", "embed_discriminator_optimizer_class", "(", "\n", "model", "[", "\"embed_discriminator\"", "]", ".", "parameters", "(", ")", ",", "\n", "**", "config", "[", "\"embed_discriminator_optimizer_params\"", "]", ",", "\n", ")", ",", "\n", "}", "\n", "generator_scheduler_class", "=", "getattr", "(", "\n", "torch", ".", "optim", ".", "lr_scheduler", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"generator_scheduler_type\"", ",", "\"StepLR\"", ")", ",", "\n", ")", "\n", "discriminator_scheduler_class", "=", "getattr", "(", "\n", "torch", ".", "optim", ".", "lr_scheduler", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"discriminator_scheduler_type\"", ",", "\"StepLR\"", ")", ",", "\n", ")", "\n", "embed_discriminator_scheduler_class", "=", "getattr", "(", "\n", "torch", ".", "optim", ".", "lr_scheduler", ",", "\n", "# keep compatibility", "\n", "config", ".", "get", "(", "\"embed_discriminator_scheduler_type\"", ",", "\"StepLR\"", ")", ",", "\n", ")", "\n", "scheduler", "=", "{", "\n", "\"generator\"", ":", "generator_scheduler_class", "(", "\n", "optimizer", "=", "optimizer", "[", "\"generator\"", "]", ",", "\n", "**", "config", "[", "\"generator_scheduler_params\"", "]", ",", "\n", ")", ",", "\n", "\"discriminator\"", ":", "discriminator_scheduler_class", "(", "\n", "optimizer", "=", "optimizer", "[", "\"discriminator\"", "]", ",", "\n", "**", "config", "[", "\"discriminator_scheduler_params\"", "]", ",", "\n", ")", ",", "\n", "\"embed_discriminator\"", ":", "embed_discriminator_scheduler_class", "(", "\n", "optimizer", "=", "optimizer", "[", "\"embed_discriminator\"", "]", ",", "\n", "**", "config", "[", "\"embed_discriminator_scheduler_params\"", "]", ",", "\n", ")", ",", "\n", "}", "\n", "if", "args", ".", "distributed", ":", "\n", "# wrap model for distributed training", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", ".", "parallel", "import", "DistributedDataParallel", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"apex is not installed. please check https://github.com/NVIDIA/apex.\"", ")", "\n", "", "model", "[", "\"generator\"", "]", "=", "DistributedDataParallel", "(", "model", "[", "\"generator\"", "]", ")", "\n", "model", "[", "\"discriminator\"", "]", "=", "DistributedDataParallel", "(", "model", "[", "\"discriminator\"", "]", ")", "\n", "model", "[", "\"embed_discriminator\"", "]", "=", "DistributedDataParallel", "(", "model", "[", "\"embed_discriminator\"", "]", ")", "\n", "", "logging", ".", "info", "(", "model", "[", "\"generator\"", "]", ")", "\n", "logging", ".", "info", "(", "model", "[", "\"discriminator\"", "]", ")", "\n", "logging", ".", "info", "(", "model", "[", "\"embed_discriminator\"", "]", ")", "\n", "\n", "simple_table", "(", "[", "\n", "(", "'PreprocessData Path'", ",", "args", ".", "inputdir", ")", ",", "\n", "(", "'Checkpoints Path'", ",", "args", ".", "outdir", ")", ",", "\n", "(", "'Config File'", ",", "args", ".", "config", ")", ",", "\n", "(", "'Generator File'", ",", "config", "[", "\"generator_type\"", "]", ")", ",", "\n", "(", "'Discriminator File'", ",", "config", "[", "\"discriminator_type\"", "]", ")", ",", "\n", "]", ")", "\n", "\n", "# define trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "steps", "=", "0", ",", "\n", "epochs", "=", "0", ",", "\n", "data_loader", "=", "data_loader", ",", "\n", "sampler", "=", "sampler", ",", "\n", "model", "=", "model", ",", "\n", "criterion", "=", "criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "config", ",", "\n", "device", "=", "device", ",", "\n", ")", "\n", "\n", "# load pretrained parameters from checkpoint", "\n", "if", "len", "(", "args", ".", "pretrain", ")", "!=", "0", ":", "\n", "        ", "trainer", ".", "load_checkpoint", "(", "args", ".", "pretrain", ",", "load_only_params", "=", "True", ")", "\n", "logging", ".", "info", "(", "f\"Successfully load parameters from {args.pretrain}.\"", ")", "\n", "\n", "# resume from checkpoint", "\n", "", "if", "len", "(", "args", ".", "resume", ")", "!=", "0", ":", "\n", "        ", "trainer", ".", "load_checkpoint", "(", "args", ".", "resume", ")", "\n", "logging", ".", "info", "(", "f\"Successfully resumed from {args.resume}.\"", ")", "\n", "\n", "# load encoder", "\n", "", "encoder", ".", "load_model", "(", "config", "[", "\"enc_model_fpath\"", "]", ",", "rank", "=", "args", ".", "rank", ")", "\n", "logging", ".", "info", "(", "f\"Successfully load parameters from %s.\"", "%", "config", "[", "\"enc_model_fpath\"", "]", ")", "\n", "\n", "for", "param", "in", "encoder", ".", "_model", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "encoder", ".", "num_params", "(", ")", "\n", "\n", "# run training loop", "\n", "try", ":", "\n", "        ", "trainer", ".", "run", "(", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "trainer", ".", "save_checkpoint", "(", "\n", "os", ".", "path", ".", "join", "(", "config", "[", "\"outdir\"", "]", ",", "f\"checkpoint-{trainer.steps}steps.pkl\"", ")", ")", "\n", "logging", ".", "info", "(", "f\"Successfully saved checkpoint @ {trainer.steps}steps.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.normalize": [[25, 27], ["numpy.clip"], "function", ["None"], ["def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "+", "100", ")", "/", "100", ",", "-", "2", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.extract_feats": [[29, 71], ["os.path.join", "numpy.pad", "utils.write_hdf5", "frontend.audio_preprocess.logmelfilterbank", "len", "utils.write_hdf5", "len", "np.pad.astype", "len", "numpy.abs().max", "preprocess.normalize", "frontend.audio_preprocess.logmelfilterbank.astype", "librosa.feature.chroma_stft", "utils.write_hdf5", "frontend.audio_preprocess.pitchfeats", "utils.write_hdf5", "torch.from_numpy", "encoder.inference.preprocess_wav_torch", "encoder.inference.embed_utterance_torch_preprocess", "embed.detach().numpy.detach().numpy", "utils.write_hdf5", "frontend.audio_world_process.world_feature_extract", "len", "utils.write_hdf5", "NotImplementedError", "librosa.feature.chroma_stft.T.astype", "frontend.audio_preprocess.pitchfeats.astype", "embed.detach().numpy.astype", "frontend.audio_world_process.world_feature_extract.astype", "numpy.abs", "embed.detach().numpy.detach"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.logmelfilterbank", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.normalize", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.pitchfeats", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch_preprocess", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.world_feature_extract", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5"], ["", "def", "extract_feats", "(", "wav", ",", "outdir", ",", "utt_id", ",", "config", ")", ":", "\n", "\n", "    ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "0.5", "\n", "h5_file", "=", "os", ".", "path", ".", "join", "(", "outdir", ",", "f\"{utt_id}.h5\"", ")", "\n", "if", "config", "[", "'feat_type'", "]", "==", "'librosa'", ":", "\n", "        ", "mel", "=", "logmelfilterbank", "(", "wav", ",", "config", ")", "#", "\n", "frames", "=", "len", "(", "mel", ")", "\n", "mel", "=", "normalize", "(", "mel", ")", "*", "2", "\n", "# mel = melspectrogram(x, config).T", "\n", "write_hdf5", "(", "h5_file", ",", "\"mel\"", ",", "mel", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "if", "config", "[", "\"use_chroma\"", "]", ":", "\n", "            ", "chromagram", "=", "librosa", ".", "feature", ".", "chroma_stft", "(", "wav", ",", "\n", "sr", "=", "config", "[", "\"sampling_rate\"", "]", ",", "\n", "hop_length", "=", "config", "[", "\"hop_size\"", "]", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"chroma\"", ",", "chromagram", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "if", "config", "[", "\"use_f0\"", "]", ":", "\n", "            ", "f0", "=", "pitchfeats", "(", "wav", ",", "config", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"f0_origin\"", ",", "f0", ".", "astype", "(", "np", ".", "float", ")", ")", "\n", "\n", "", "if", "config", "[", "\"use_embed\"", "]", ":", "\n", "            ", "wav_torch", "=", "torch", ".", "from_numpy", "(", "wav", ")", "\n", "preprocessed_wav", "=", "encoder", ".", "preprocess_wav_torch", "(", "wav_torch", ")", "\n", "embed", "=", "encoder", ".", "embed_utterance_torch_preprocess", "(", "preprocessed_wav", ")", "\n", "embed", "=", "embed", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"embed\"", ",", "embed", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "", "elif", "config", "[", "'feat_type'", "]", "==", "'world'", ":", "\n", "        ", "feats", "=", "world_feature_extract", "(", "wav", ",", "config", ")", "\n", "frames", "=", "len", "(", "feats", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"feats\"", ",", "feats", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Currently, only 'world'\u3001'librosa' are supported.\"", ")", "\n", "\n", "", "audio", "=", "np", ".", "pad", "(", "wav", ",", "(", "0", ",", "config", "[", "\"fft_size\"", "]", ")", ",", "mode", "=", "\"edge\"", ")", "\n", "audio", "=", "audio", "[", ":", "frames", "*", "config", "[", "\"hop_size\"", "]", "]", "\n", "assert", "frames", "*", "config", "[", "\"hop_size\"", "]", "==", "len", "(", "audio", ")", "\n", "\n", "write_hdf5", "(", "h5_file", ",", "\"wav\"", ",", "audio", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "return", "utt_id", ",", "h5_file", ",", "frames", ",", "len", "(", "audio", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.write2file": [[73, 91], ["open", "open", "sum", "sum", "logging.info", "logging.info", "logging.info", "os.path.join", "os.path.join", "open.write", "open.write", "int", "int", "len", "max", "max", "int", "str", "str"], "function", ["None"], ["", "def", "write2file", "(", "values", ",", "config", ",", "outdir", ")", ":", "\n", "    ", "test_nums", "=", "config", "[", "'test_num'", "]", "\n", "train_text", "=", "open", "(", "os", ".", "path", ".", "join", "(", "outdir", ",", "'train.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "dev_text", "=", "open", "(", "os", ".", "path", ".", "join", "(", "outdir", ",", "'dev.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "for", "v", "in", "values", "[", ":", "test_nums", "]", ":", "\n", "        ", "dev_text", ".", "write", "(", "'|'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "v", "]", ")", "+", "'\\n'", ")", "\n", "", "for", "v", "in", "values", "[", "test_nums", ":", "]", ":", "\n", "        ", "train_text", ".", "write", "(", "'|'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "v", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "mel_frames", "=", "sum", "(", "[", "int", "(", "m", "[", "2", "]", ")", "for", "m", "in", "values", "]", ")", "\n", "timesteps", "=", "sum", "(", "[", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "values", "]", ")", "\n", "sr", "=", "config", "[", "'sampling_rate'", "]", "\n", "hours", "=", "timesteps", "/", "sr", "/", "3600", "\n", "logging", ".", "info", "(", "'Write {} utterances, {} mel frames, {} audio timesteps, ({:.2f} hours)'", ".", "format", "(", "\n", "len", "(", "values", ")", ",", "mel_frames", ",", "timesteps", ",", "hours", ")", ")", "\n", "logging", ".", "info", "(", "'Max mel frames length: {}'", ".", "format", "(", "max", "(", "int", "(", "m", "[", "2", "]", ")", "for", "m", "in", "values", ")", ")", ")", "\n", "logging", ".", "info", "(", "'Max audio timesteps length: {}'", ".", "format", "(", "max", "(", "m", "[", "3", "]", "for", "m", "in", "values", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.main": [[93, 200], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "yaml.load.update", "datasets.AudioDataset", "multiprocessing.pool.Pool", "utils.simple_table", "tqdm.tqdm", "multiprocessing.pool.Pool.close", "tqdm.tqdm", "random.seed", "random.shuffle", "preprocess.write2file", "logging.basicConfig", "open", "yaml.load", "vars", "ValueError", "print", "encoder.inference.load_model", "os.path.exists", "os.makedirs", "int", "os.path.join", "os.makedirs", "futures.append", "values.append", "logging.basicConfig", "logging.basicConfig", "logging.warning", "os.getenv", "len", "numpy.abs().max", "librosa.effects.trim", "librosa.resample", "multiprocessing.pool.Pool.apply_async", "future.get", "os.cpu_count", "os.cpu_count", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.simple_table", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.None.preprocess.write2file", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.load_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Run preprocessing process.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Preprocess audio and then extract features (See detail in parallel_wavegan/bin/preprocess.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--inputdir\"", ",", "'-i'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory including wav files. you need to specify either scp or inputdir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dumpdir\"", ",", "'-o'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory to dump feature files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "'-c'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"yaml format configuration file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"logging level. higher is more logging. (default=1)\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set logger", "\n", "if", "args", ".", "verbose", ">", "1", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "DEBUG", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "elif", "args", ".", "verbose", ">", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "WARN", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "logging", ".", "warning", "(", "'Skip DEBUG/INFO messages'", ")", "\n", "\n", "# load config", "\n", "", "with", "open", "(", "args", ".", "config", ")", "as", "f", ":", "\n", "        ", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "", "config", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "# check arguments", "\n", "if", "args", ".", "inputdir", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Please specify either --rootdir or --wav-scp.\"", ")", "\n", "\n", "# get dataset", "\n", "", "assert", "args", ".", "inputdir", "is", "not", "None", "\n", "dataset", "=", "AudioDataset", "(", "\n", "args", ".", "inputdir", ",", "\"*.wav\"", ",", "\n", "audio_load_fn", "=", "sf", ".", "read", ",", "\n", "return_utt_id", "=", "True", ",", "\n", ")", "\n", "if", "config", "[", "\"use_embed\"", "]", ":", "\n", "        ", "print", "(", "\"Preparing the encoder...\"", ")", "\n", "encoder", ".", "load_model", "(", "config", "[", "\"enc_model_fpath\"", "]", ",", "preprocess", "=", "True", ")", "\n", "\n", "# check directly existence", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "dumpdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "dumpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# process each data", "\n", "", "futures", "=", "[", "]", "\n", "p", "=", "Pool", "(", "int", "(", "os", ".", "getenv", "(", "'N_PROC'", ",", "os", ".", "cpu_count", "(", ")", ")", ")", ")", "\n", "\n", "simple_table", "(", "[", "\n", "(", "'Data Path'", ",", "args", ".", "inputdir", ")", ",", "\n", "(", "'Preprocess Path'", ",", "args", ".", "dumpdir", ")", ",", "\n", "(", "'Config File'", ",", "args", ".", "config", ")", ",", "\n", "(", "'CPU Usage'", ",", "os", ".", "cpu_count", "(", ")", ")", "\n", "]", ")", "\n", "\n", "\n", "\n", "for", "utt_id", ",", "(", "audio", ",", "fs", ")", "in", "tqdm", "(", "dataset", ")", ":", "\n", "# check", "\n", "        ", "assert", "len", "(", "audio", ".", "shape", ")", "==", "1", ",", "f\"{utt_id} seems to be multi-channel signal.\"", "\n", "assert", "np", ".", "abs", "(", "audio", ")", ".", "max", "(", ")", "<=", "1.0", ",", "f\"{utt_id} seems to be different from 16 bit PCM.\"", "\n", "assert", "fs", "==", "config", "[", "\"sampling_rate\"", "]", ",", "f\"{utt_id} seems to have a different sampling rate.\"", "\n", "\n", "# trim silence", "\n", "if", "config", "[", "\"trim_silence\"", "]", ":", "\n", "            ", "audio", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "audio", ",", "\n", "top_db", "=", "config", "[", "\"trim_threshold_in_db\"", "]", ",", "\n", "frame_length", "=", "config", "[", "\"trim_frame_size\"", "]", ",", "\n", "hop_length", "=", "config", "[", "\"trim_hop_size\"", "]", ")", "\n", "\n", "", "if", "\"sampling_rate_for_feats\"", "not", "in", "config", ":", "\n", "            ", "x", "=", "audio", "\n", "sampling_rate", "=", "config", "[", "\"sampling_rate\"", "]", "\n", "hop_size", "=", "config", "[", "\"hop_size\"", "]", "\n", "", "else", ":", "\n", "\n", "            ", "x", "=", "librosa", ".", "resample", "(", "audio", ",", "fs", ",", "config", "[", "\"sampling_rate_for_feats\"", "]", ")", "\n", "sampling_rate", "=", "config", "[", "\"sampling_rate_for_feats\"", "]", "\n", "assert", "config", "[", "\"hop_size\"", "]", "*", "config", "[", "\"sampling_rate_for_feats\"", "]", "%", "fs", "==", "0", ",", "\"hop_size must be int value. please check sampling_rate_for_feats is correct.\"", "\n", "hop_size", "=", "config", "[", "\"hop_size\"", "]", "*", "config", "[", "\"sampling_rate_for_feats\"", "]", "//", "fs", "\n", "\n", "", "config", "[", "\"sampling_rate\"", "]", "=", "sampling_rate", "\n", "config", "[", "\"hop_size\"", "]", "=", "hop_size", "\n", "\n", "feats_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "dumpdir", ",", "'feats'", ")", "\n", "os", ".", "makedirs", "(", "feats_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "futures", ".", "append", "(", "p", ".", "apply_async", "(", "extract_feats", ",", "args", "=", "(", "x", ",", "feats_dir", ",", "utt_id", ",", "config", ")", ")", ")", "\n", "\n", "", "p", ".", "close", "(", ")", "\n", "values", "=", "[", "]", "\n", "for", "future", "in", "tqdm", "(", "futures", ")", ":", "\n", "        ", "values", ".", "append", "(", "future", ".", "get", "(", ")", ")", "\n", "\n", "", "random", ".", "seed", "(", "2020", ")", "\n", "random", ".", "shuffle", "(", "values", ")", "\n", "\n", "write2file", "(", "values", ",", "config", ",", "args", ".", "dumpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.load_model": [[15, 41], ["encoder.model.SpeakerEncoder", "torch.load", "encoder.model.SpeakerEncoder.load_state_dict", "print", "torch.device", "isinstance", "torch.device", "encoder.model.SpeakerEncoder.cuda", "torch.device", "torch.cuda.is_available"], "function", ["None"], ["\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "from", "datasets", "import", "MelDataset", "\n", "from", "utils", "import", "load_model", "\n", "from", "utils", "import", "read_hdf5", "\n", "import", "os", "\n", "\n", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Run decoding process.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Decode dumped features with trained Parallel WaveGAN Generator \"", "\n", "\"(See detail in parallel_wavegan/bin/decode.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--inputdir\"", ",", "'-i'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory including feature files. \"", "\n", "\"you need to specify either feats-scp or inputdir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--outdir\"", ",", "'-o'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory to save generated speech.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "'-c'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"checkpoint file to be loaded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "'-g'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"yaml format configuration file. if not explicitly provided, \"", "\n", "\"it will be searched in the checkpoint directory. (default=None)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"logging level. higher is more logging. (default=1)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rank\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"rank for distributed training. no need to explictly specify.\"", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.is_loaded": [[43, 45], ["None"], "function", ["None"], ["args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set logger", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.num_params": [[46, 50], ["filter", "print", "_model.parameters", "sum", "numpy.prod", "p.size"], "function", ["None"], ["if", "args", ".", "verbose", ">", "1", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "DEBUG", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "elif", "args", ".", "verbose", ">", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch_torch": [[51, 65], ["_model.forward", "Exception"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.forward"], ["level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "WARN", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "logging", ".", "warning", "(", "\"Skip DEBUG/INFO messages\"", ")", "\n", "\n", "# check directory existence", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "outdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "outdir", ")", "\n", "\n", "# load config", "\n", "", "if", "args", ".", "config", "is", "None", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "checkpoint", ")", "\n", "args", ".", "config", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"config.yml\"", ")", "\n", "", "with", "open", "(", "args", ".", "config", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch_torch_perceptual": [[67, 81], ["_model.forward_perceptual2", "Exception"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.forward_perceptual2"], ["", "config", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "\n", "# check arguments", "\n", "if", "args", ".", "inputdir", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Please specify either --inputdir or --feats-scp.\"", ")", "\n", "\n", "# get dataset", "\n", "", "if", "config", "[", "\"format\"", "]", "==", "\"hdf5\"", ":", "\n", "        ", "mel_query", "=", "\"*.h5\"", "\n", "mel_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"mel\"", ")", "# NOQA", "\n", "", "elif", "config", "[", "\"format\"", "]", "==", "\"npy\"", ":", "\n", "        ", "mel_query", "=", "\"*-feats.npy\"", "\n", "mel_load_fn", "=", "np", ".", "load", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Support only hdf5 or npy format.\"", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch": [[82, 96], ["torch.from_numpy().to", "_model.forward().detach().cpu().numpy", "Exception", "torch.from_numpy", "_model.forward().detach().cpu", "_model.forward().detach", "_model.forward"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.forward"], ["", "dataset", "=", "MelDataset", "(", "\n", "args", ".", "inputdir", ",", "\n", "mel_query", "=", "mel_query", ",", "\n", "mel_load_fn", "=", "mel_load_fn", ",", "\n", "return_utt_id", "=", "True", ",", "\n", ")", "\n", "logging", ".", "info", "(", "f\"The number of features to be decoded = {len(dataset)}.\"", ")", "\n", "\n", "# setup model", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "rank", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "model", "=", "load_model", "(", "args", ".", "checkpoint", ",", "config", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.compute_partial_slices": [[98, 148], ["int", "int", "max", "max", "range", "numpy.ceil", "int", "numpy.array", "mel_slices.append", "wav_slices.append", "numpy.round", "slice", "slice", "len"], "function", ["None"], ["model", ".", "remove_weight_norm", "(", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# start generation", "\n", "total_rtf", "=", "0.0", "\n", "with", "torch", ".", "no_grad", "(", ")", ",", "tqdm", "(", "dataset", ",", "desc", "=", "\"[decode]\"", ")", "as", "pbar", ":", "\n", "        ", "for", "idx", ",", "(", "utt_id", ",", "c", ")", "in", "enumerate", "(", "pbar", ",", "1", ")", ":", "# utt_id: mel id     c: mel feats", "\n", "# generate", "\n", "            ", "if", "not", "(", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"outdir\"", "]", ",", "f\"{utt_id}_gen.wav\"", ")", ")", ")", ":", "\n", "                ", "c", "=", "torch", ".", "tensor", "(", "c", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "device", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "y", "=", "model", ".", "inference", "(", "c", ")", ".", "view", "(", "-", "1", ")", "\n", "rtf", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "(", "len", "(", "y", ")", "/", "config", "[", "\"sampling_rate\"", "]", ")", "\n", "pbar", ".", "set_postfix", "(", "{", "\"RTF\"", ":", "rtf", "}", ")", "\n", "total_rtf", "+=", "rtf", "\n", "\n", "# save as PCM 16 bit wav file", "\n", "sf", ".", "write", "(", "os", ".", "path", ".", "join", "(", "config", "[", "\"outdir\"", "]", ",", "f\"{utt_id}_gen.wav\"", ")", ",", "\n", "y", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "config", "[", "\"sampling_rate\"", "]", ",", "\"PCM_16\"", ")", "\n", "del", "c", ",", "y", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# report average RTF", "\n", "", "", "logging", ".", "info", "(", "f\"Finished generation of {idx} utterances (RTF = {total_rtf / idx:.03f}).\"", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch_preprocess": [[150, 195], ["inference.compute_partial_slices", "encoder.audio.wav_to_mel_spectrogram_torch_preprocess", "torch.stack", "inference.embed_frames_batch_torch", "torch.mean", "encoder.audio.wav_to_mel_spectrogram", "len", "len", "torch.nn.functional.pad", "torch.norm", "inference.embed_frames_batch", "len"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.compute_partial_slices", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram_torch_preprocess", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch"], []], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch": [[199, 244], ["inference.compute_partial_slices", "encoder.audio.wav_to_mel_spectrogram_torch", "torch.stack", "inference.embed_frames_batch_torch", "torch.mean", "encoder.audio.wav_to_mel_spectrogram", "len", "len", "torch.nn.functional.pad", "torch.norm", "inference.embed_frames_batch", "len"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.compute_partial_slices", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch"], []], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_utterance_torch_perceptual": [[247, 286], ["inference.compute_partial_slices", "encoder.audio.wav_to_mel_spectrogram_torch", "torch.stack", "inference.embed_frames_batch_torch_perceptual", "encoder.audio.wav_to_mel_spectrogram", "len", "len", "torch.nn.functional.pad", "inference.embed_frames_batch", "len"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.compute_partial_slices", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram_torch", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch_torch_perceptual", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_frames_batch"], []], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.embed_speaker": [[288, 290], ["NotImplemented"], "function", ["None"], []], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.inference.plot_embedding_as_heatmap": [[292, 308], ["embed.reshape.reshape", "matplotlib.cm.get_cmap", "plt.gca.imshow", "matplotlib.colorbar", "plt.colorbar.set_clim", "plt.gca.set_title", "matplotlib.gca", "int", "plt.gca.set_xticks", "plt.gca.set_yticks", "numpy.sqrt", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav": [[15, 43], ["audio.normalize_volume", "isinstance", "isinstance", "librosa.load", "librosa.resample"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.normalize_volume"], ["def", "preprocess_wav", "(", "fpath_or_wav", ":", "Union", "[", "str", ",", "Path", ",", "np", ".", "ndarray", "]", ",", "\n", "source_sr", ":", "Optional", "[", "int", "]", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Applies the preprocessing operations used in training the Speaker Encoder to a waveform\n    either on disk or in memory. The waveform will be resampled to match the data hyperparameters.\n\n    :param fpath_or_wav: either a filepath to an audio file (many extensions are supported, not\n    just .wav), either the waveform as a numpy array of floats.\n    :param source_sr: if passing an audio waveform, the sampling rate of the waveform before\n    preprocessing. After preprocessing, the waveform's sampling rate will match the data\n    hyperparameters. If passing a filepath, the sampling rate will be automatically detected and\n    this argument will be ignored.\n    \"\"\"", "\n", "# Load the wav from disk if needed", "\n", "if", "isinstance", "(", "fpath_or_wav", ",", "str", ")", "or", "isinstance", "(", "fpath_or_wav", ",", "Path", ")", ":", "\n", "        ", "wav", ",", "source_sr", "=", "librosa", ".", "load", "(", "fpath_or_wav", ",", "sr", "=", "None", ")", "\n", "", "else", ":", "\n", "        ", "wav", "=", "fpath_or_wav", "\n", "\n", "# Resample the wav if needed", "\n", "", "if", "source_sr", "is", "not", "None", "and", "source_sr", "!=", "sampling_rate", ":", "\n", "        ", "wav", "=", "librosa", ".", "resample", "(", "wav", ",", "source_sr", ",", "sampling_rate", ")", "\n", "\n", "# Apply the preprocessing: normalize volume and shorten long silences", "\n", "", "wav", "=", "normalize_volume", "(", "wav", ",", "audio_norm_target_dBFS", ",", "increase_only", "=", "True", ")", "\n", "# wav = trim_long_silences(wav)", "\n", "\n", "return", "wav", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav_torch": [[45, 60], ["audio.normalize_volume_torch"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.normalize_volume_torch"], ["", "def", "preprocess_wav_torch", "(", "wav", ",", "source_sr", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Applies the preprocessing operations used in training the Speaker Encoder to a waveform\n    either on disk or in memory. The waveform will be resampled to match the data hyperparameters.\n\n    :param fpath_or_wav: either a filepath to an audio file (many extensions are supported, not\n    just .wav), either the waveform as a numpy array of floats.\n    :param source_sr: if passing an audio waveform, the sampling rate of the waveform before\n    preprocessing. After preprocessing, the waveform's sampling rate will match the data\n    hyperparameters. If passing a filepath, the sampling rate will be automatically detected and\n    this argument will be ignored.\n    \"\"\"", "\n", "# Apply the preprocessing: normalize volume and shorten long silences", "\n", "wav", "=", "normalize_volume_torch", "(", "wav", ",", "audio_norm_target_dBFS", ",", "increase_only", "=", "True", ")", "\n", "return", "wav", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram": [[61, 85], ["librosa.feature.melspectrogram", "librosa.feature.melspectrogram.astype"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.melspectrogram"], ["", "def", "wav_to_mel_spectrogram", "(", "wav", ")", ":", "\n", "    ", "\"\"\"\n    Derives a mel spectrogram ready to be used by the encoder from a preprocessed audio waveform.\n    Note: this not a log-mel spectrogram.\n    wav: numpy (T,)\n    return: numpy (T', n_mels)\n    \"\"\"", "\n", "# frames = librosa.feature.melspectrogram(", "\n", "#     wav,", "\n", "#     sampling_rate,", "\n", "#     n_fft=int(sampling_rate * mel_window_length / 1000),", "\n", "#     hop_length=int(sampling_rate * mel_window_step / 1000),", "\n", "#     n_mels=mel_n_channels", "\n", "# )", "\n", "frames", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "wav", ",", "\n", "sampling_rate", ",", "\n", "n_fft", "=", "n_fft", ",", "\n", "hop_length", "=", "hop_length", ",", "\n", "win_length", "=", "win_length", ",", "\n", "n_mels", "=", "mel_n_channels", ",", "\n", ")", "\n", "\n", "return", "frames", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram_torch_preprocess": [[86, 104], ["torchaudio.transforms.MelSpectrogram", "torchaudio.transforms.MelSpectrogram.", "wav.float"], "function", ["None"], ["", "def", "wav_to_mel_spectrogram_torch_preprocess", "(", "wav", ")", ":", "\n", "    ", "\"\"\"\n    Derives a mel spectrogram ready to be used by the encoder from a preprocessed audio waveform.\n    Note: this not a log-mel spectrogram.\n    wav: Tensor (T)\n    return: Tensor (n_mels, T')\n    \"\"\"", "\n", "\n", "MelSpectrogram", "=", "torchaudio", ".", "transforms", ".", "MelSpectrogram", "(", "\n", "sample_rate", "=", "sampling_rate", ",", "\n", "win_length", "=", "win_length", ",", "\n", "hop_length", "=", "hop_length", ",", "\n", "n_mels", "=", "mel_n_channels", ",", "\n", "n_fft", "=", "n_fft", ",", "\n", "power", "=", "2.0", ",", "\n", ")", "\n", "frames", "=", "MelSpectrogram", "(", "wav", ".", "float", "(", ")", ")", "\n", "return", "frames", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram_torch": [[105, 123], ["torchaudio.transforms.MelSpectrogram().cuda", "torchaudio.transforms.MelSpectrogram().cuda.", "wav.float", "torchaudio.transforms.MelSpectrogram"], "function", ["None"], ["", "def", "wav_to_mel_spectrogram_torch", "(", "wav", ")", ":", "\n", "    ", "\"\"\"\n    Derives a mel spectrogram ready to be used by the encoder from a preprocessed audio waveform.\n    Note: this not a log-mel spectrogram.\n    wav: Tensor (T)\n    return: Tensor (n_mels, T')\n    \"\"\"", "\n", "\n", "MelSpectrogram", "=", "torchaudio", ".", "transforms", ".", "MelSpectrogram", "(", "\n", "sample_rate", "=", "sampling_rate", ",", "\n", "win_length", "=", "win_length", ",", "\n", "hop_length", "=", "hop_length", ",", "\n", "n_mels", "=", "mel_n_channels", ",", "\n", "n_fft", "=", "n_fft", ",", "\n", "power", "=", "2.0", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "frames", "=", "MelSpectrogram", "(", "wav", ".", "float", "(", ")", ")", "\n", "return", "frames", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.trim_long_silences": [[125, 166], ["struct.pack", "webrtcvad.Vad", "range", "numpy.array", "audio.trim_long_silences.moving_average"], "function", ["None"], ["", "def", "trim_long_silences", "(", "wav", ")", ":", "\n", "    ", "\"\"\"\n    Ensures that segments without voice in the waveform remain no longer than a \n    threshold determined by the VAD parameters in params.py.\n\n    :param wav: the raw waveform as a numpy array of floats \n    :return: the same waveform with silences trimmed away (length <= original wav length)\n    \"\"\"", "\n", "# Compute the voice detection window size", "\n", "samples_per_window", "=", "(", "vad_window_length", "*", "sampling_rate", ")", "//", "1000", "\n", "\n", "# Trim the end of the audio to have a multiple of the window size", "\n", "wav", "=", "wav", "[", ":", "len", "(", "wav", ")", "-", "(", "len", "(", "wav", ")", "%", "samples_per_window", ")", "]", "\n", "\n", "# Convert the float waveform to 16-bit mono PCM", "\n", "pcm_wave", "=", "struct", ".", "pack", "(", "\"%dh\"", "%", "len", "(", "wav", ")", ",", "*", "(", "np", ".", "round", "(", "wav", "*", "int16_max", ")", ")", ".", "astype", "(", "np", ".", "int16", ")", ")", "\n", "\n", "# Perform voice activation detection", "\n", "voice_flags", "=", "[", "]", "\n", "vad", "=", "webrtcvad", ".", "Vad", "(", "mode", "=", "3", ")", "\n", "for", "window_start", "in", "range", "(", "0", ",", "len", "(", "wav", ")", ",", "samples_per_window", ")", ":", "\n", "        ", "window_end", "=", "window_start", "+", "samples_per_window", "\n", "voice_flags", ".", "append", "(", "vad", ".", "is_speech", "(", "pcm_wave", "[", "window_start", "*", "2", ":", "window_end", "*", "2", "]", ",", "\n", "sample_rate", "=", "sampling_rate", ")", ")", "\n", "", "voice_flags", "=", "np", ".", "array", "(", "voice_flags", ")", "\n", "\n", "# Smooth the voice detection with a moving average", "\n", "def", "moving_average", "(", "array", ",", "width", ")", ":", "\n", "        ", "array_padded", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros", "(", "(", "width", "-", "1", ")", "//", "2", ")", ",", "array", ",", "np", ".", "zeros", "(", "width", "//", "2", ")", ")", ")", "\n", "ret", "=", "np", ".", "cumsum", "(", "array_padded", ",", "dtype", "=", "float", ")", "\n", "ret", "[", "width", ":", "]", "=", "ret", "[", "width", ":", "]", "-", "ret", "[", ":", "-", "width", "]", "\n", "return", "ret", "[", "width", "-", "1", ":", "]", "/", "width", "\n", "\n", "", "audio_mask", "=", "moving_average", "(", "voice_flags", ",", "vad_moving_average_width", ")", "\n", "audio_mask", "=", "np", ".", "round", "(", "audio_mask", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "# Dilate the voiced regions", "\n", "audio_mask", "=", "binary_dilation", "(", "audio_mask", ",", "np", ".", "ones", "(", "vad_max_silence_length", "+", "1", ")", ")", "\n", "audio_mask", "=", "np", ".", "repeat", "(", "audio_mask", ",", "samples_per_window", ")", "\n", "\n", "return", "wav", "[", "audio_mask", "==", "True", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.normalize_volume": [[168, 176], ["ValueError", "numpy.log10", "numpy.mean"], "function", ["None"], ["", "def", "normalize_volume", "(", "wav", ",", "target_dBFS", ",", "increase_only", "=", "False", ",", "decrease_only", "=", "False", ")", ":", "\n", "    ", "if", "increase_only", "and", "decrease_only", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both increase only and decrease only are set\"", ")", "\n", "", "dBFS_change", "=", "target_dBFS", "-", "10", "*", "np", ".", "log10", "(", "np", ".", "mean", "(", "wav", "**", "2", ")", ")", "\n", "\n", "if", "(", "dBFS_change", "<", "0", "and", "increase_only", ")", "or", "(", "dBFS_change", ">", "0", "and", "decrease_only", ")", ":", "\n", "        ", "return", "wav", "\n", "", "return", "wav", "*", "(", "10", "**", "(", "dBFS_change", "/", "20", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.normalize_volume_torch": [[177, 185], ["ValueError", "torch.log10", "torch.mean"], "function", ["None"], ["", "def", "normalize_volume_torch", "(", "wav", ",", "target_dBFS", ",", "increase_only", "=", "False", ",", "decrease_only", "=", "False", ")", ":", "\n", "    ", "if", "increase_only", "and", "decrease_only", ":", "\n", "        ", "raise", "ValueError", "(", "\"Both increase only and decrease only are set\"", ")", "\n", "", "dBFS_change", "=", "target_dBFS", "-", "10", "*", "torch", ".", "log10", "(", "torch", ".", "mean", "(", "wav", "**", "2", ")", ")", "\n", "\n", "if", "(", "dBFS_change", "<", "0", "and", "increase_only", ")", "or", "(", "dBFS_change", ">", "0", "and", "decrease_only", ")", ":", "\n", "        ", "return", "wav", "\n", "", "return", "wav", "*", "(", "10", "**", "(", "dBFS_change", "/", "20", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.train.sync": [[9, 15], ["torch.cuda.synchronize"], "function", ["None"], ["import", "os", "\n", "import", "sys", "\n", "\n", "from", "collections", "import", "defaultdict", "\n", "from", "sklearn", ".", "metrics", ".", "pairwise", "import", "cosine_similarity", "\n", "import", "matplotlib", "\n", "import", "numpy", "as", "np", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.train.train": [[16, 125], ["encoder.data_objects.SpeakerVerificationDataset", "encoder.data_objects.SpeakerVerificationDataLoader", "torch.device", "torch.device", "encoder.model.SpeakerEncoder", "torch.optim.Adam", "models_dir.joinpath", "models_dir.joinpath", "encoder.model.SpeakerEncoder.train", "encoder.visualizations.Visualizations", "encoder.visualizations.Visualizations.log_dataset", "encoder.visualizations.Visualizations.log_params", "str", "encoder.visualizations.Visualizations.log_implementation", "utils.profiler.Profiler", "enumerate", "encoder.model.SpeakerEncoder.parameters", "models_dir.joinpath.exists", "print", "utils.profiler.Profiler.tick", "torch.from_numpy().to", "train.sync", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.", "train.sync", "utils.profiler.Profiler.tick", "embeds.detach().cpu().numpy.view().to", "encoder.model.SpeakerEncoder.loss", "train.sync", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.zero_grad", "loss.backward", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.do_gradient_ops", "torch.optim.Adam.step", "utils.profiler.Profiler.tick", "encoder.visualizations.Visualizations.update", "utils.profiler.Profiler.tick", "torch.cuda.is_available", "print", "torch.load", "encoder.model.SpeakerEncoder.load_state_dict", "torch.optim.Adam.load_state_dict", "print", "torch.cuda.is_available", "torch.cuda.get_device_name", "loss.item", "print", "models_dir.joinpath.mkdir", "models_dir.joinpath.joinpath", "embeds.detach().cpu().numpy.detach().cpu().numpy", "encoder.visualizations.Visualizations.draw_projections", "encoder.visualizations.Visualizations.save", "print", "torch.save", "print", "models_dir.joinpath.mkdir", "models_dir.joinpath.joinpath", "torch.save", "torch.from_numpy", "embeds.detach().cpu().numpy.view", "embeds.detach().cpu().numpy.detach().cpu", "encoder.model.SpeakerEncoder.state_dict", "torch.optim.Adam.state_dict", "encoder.model.SpeakerEncoder.state_dict", "torch.optim.Adam.state_dict", "embeds.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.train", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_dataset", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_params", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_implementation", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.loss", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.do_gradient_ops", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.draw_projections", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save"], ["import", "soundfile", "as", "sf", "\n", "import", "torch", "\n", "import", "yaml", "\n", "import", "losses", "\n", "\n", "from", "tensorboardX", "import", "SummaryWriter", "\n", "from", "torch", ".", "utils", ".", "data", "import", "DataLoader", "\n", "from", "tqdm", "import", "tqdm", "\n", "\n", "import", "models", "\n", "import", "optimizers", "\n", "\n", "from", "datasets", "import", "AudioMelEmbedDataset", "\n", "from", "datasets", "import", "Embeds_Collater", "\n", "from", "layers", "import", "PQMF", "\n", "from", "losses", "import", "MultiResolutionSTFTLoss", "\n", "from", "utils", "import", "read_hdf5", "\n", "import", "os", "\n", "from", "utils", "import", "simple_table", "\n", "from", "encoder", "import", "inference", "as", "encoder", "\n", "\n", "\n", "# set to avoid matplotlib error in CLI environment", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "\n", "\n", "class", "Trainer", "(", "object", ")", ":", "\n", "    ", "\"\"\"Customized trainer module for Multi-Singer training.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "steps", ",", "\n", "epochs", ",", "\n", "data_loader", ",", "\n", "sampler", ",", "\n", "model", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "config", ",", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize trainer.\n\n        Args:\n            steps (int): Initial global steps.\n            epochs (int): Initial global epochs.\n            data_loader (dict): Dict of data loaders. It must contrain \"train\" and \"dev\" loaders.\n            model (dict): Dict of models. It must contrain \"generator\" and \"discriminator\" models.\n            criterion (dict): Dict of criterions. It must contrain \"stft\" and \"mse\" criterions.\n            optimizer (dict): Dict of optimizers. It must contrain \"generator\" and \"discriminator\" optimizers.\n            scheduler (dict): Dict of schedulers. It must contrain \"generator\" and \"discriminator\" schedulers.\n            config (dict): Config dict loaded from yaml format configuration file.\n            device (torch.deive): Pytorch device instance.\n\n        \"\"\"", "\n", "self", ".", "steps", "=", "steps", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "sampler", "=", "sampler", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "config", "[", "\"outdir\"", "]", ")", "\n", "self", ".", "finish_train", "=", "False", "\n", "self", ".", "total_train_loss", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "total_eval_loss", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run training.\"\"\"", "\n", "self", ".", "tqdm", "=", "tqdm", "(", "initial", "=", "self", ".", "steps", ",", "\n", "total", "=", "self", ".", "config", "[", "\"train_max_steps\"", "]", ",", "\n", "desc", "=", "\"[train]\"", ")", "\n", "while", "True", ":", "\n", "# train one epoch", "\n", "            ", "self", ".", "_train_epoch", "(", ")", "\n", "\n", "# check whether training is finished", "\n", "if", "self", ".", "finish_train", ":", "\n", "                ", "break", "\n", "\n", "", "", "self", ".", "tqdm", ".", "close", "(", ")", "\n", "logging", ".", "info", "(", "\"Finished training.\"", ")", "\n", "\n", "", "def", "save_checkpoint", "(", "self", ",", "checkpoint_path", ")", ":", "\n", "        ", "\"\"\"Save checkpoint.\n\n        Args:\n            checkpoint_path (str): Checkpoint path to be saved.\n\n        \"\"\"", "\n", "state_dict", "=", "{", "\n", "\"optimizer\"", ":", "{", "\n", "\"generator\"", ":", "self", ".", "optimizer", "[", "\"generator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "optimizer", "[", "\"discriminator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "\"scheduler\"", ":", "{", "\n", "\"generator\"", ":", "self", ".", "scheduler", "[", "\"generator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "scheduler", "[", "\"discriminator\"", "]", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "\"steps\"", ":", "self", ".", "steps", ",", "\n", "\"epochs\"", ":", "self", ".", "epochs", ",", "\n", "}", "\n", "if", "self", ".", "config", "[", "\"distributed\"", "]", ":", "\n", "            ", "state_dict", "[", "\"model\"", "]", "=", "{", "\n", "\"generator\"", ":", "self", ".", "model", "[", "\"generator\"", "]", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "model", "[", "\"discriminator\"", "]", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.__init__": [[15, 23], ["open", "dict", "str", "preprocess.DatasetLog.write_line", "preprocess.DatasetLog.write_line", "preprocess.DatasetLog._log_params", "pathlib.Path", "datetime.datetime.datetime.now().strftime", "name.replace", "datetime.datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog._log_params"], ["from", "multiprocessing", ".", "pool", "import", "Pool", "\n", "\n", "from", "datasets", "import", "AudioDataset", "\n", "from", "frontend", ".", "audio_preprocess", "import", "logmelfilterbank", ",", "pitchfeats", ",", "f0_to_coarse", "\n", "from", "frontend", ".", "audio_world_process", "import", "world_feature_extract", ",", "convert_continuos_f0", ",", "low_pass_filter", "\n", "from", "utils", "import", "write_hdf5", "\n", "from", "utils", "import", "simple_table", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog._log_params": [[24, 31], ["preprocess.DatasetLog.write_line", "preprocess.DatasetLog.write_line", "getattr", "preprocess.DatasetLog.write_line", "dir", "p.startswith"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line"], ["\n", "def", "normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "+", "100", ")", "/", "100", ",", "-", "2", ",", "2", ")", "\n", "\n", "\n", "", "def", "extract_feats", "(", "wav", ",", "outdir", ",", "utt_id", ",", "config", ")", ":", "\n", "\n", "    ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "0.5", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line": [[32, 34], ["preprocess.DatasetLog.text_file.write"], "methods", ["None"], ["h5_file", "=", "os", ".", "path", ".", "join", "(", "outdir", ",", "f\"{utt_id}.h5\"", ")", "\n", "if", "config", "[", "'feat_type'", "]", "==", "'librosa'", ":", "\n", "        ", "mel", "=", "logmelfilterbank", "(", "wav", ",", "config", ")", "#", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.add_sample": [[35, 40], ["kwargs.items", "preprocess.DatasetLog.sample_data[].append"], "methods", ["None"], ["frames", "=", "len", "(", "mel", ")", "\n", "mel", "=", "normalize", "(", "mel", ")", "*", "2", "\n", "# mel = melspectrogram(x, config).T", "\n", "write_hdf5", "(", "h5_file", ",", "\"mel\"", ",", "mel", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "if", "config", "[", "\"use_chroma\"", "]", ":", "\n", "            ", "chromagram", "=", "librosa", ".", "feature", ".", "chroma_stft", "(", "wav", ",", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.finalize": [[41, 51], ["preprocess.DatasetLog.write_line", "preprocess.DatasetLog.sample_data.items", "preprocess.DatasetLog.write_line", "str", "preprocess.DatasetLog.write_line", "preprocess.DatasetLog.text_file.close", "preprocess.DatasetLog.write_line", "preprocess.DatasetLog.write_line", "preprocess.DatasetLog.write_line", "datetime.datetime.datetime.now().strftime", "datetime.datetime.datetime.now", "numpy.min", "numpy.max", "numpy.mean", "numpy.median"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.write_line"], ["sr", "=", "config", "[", "\"sampling_rate\"", "]", ",", "\n", "hop_length", "=", "config", "[", "\"hop_size\"", "]", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"chroma\"", ",", "chromagram", ".", "T", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "if", "config", "[", "\"use_f0\"", "]", ":", "\n", "            ", "f0", "=", "pitchfeats", "(", "wav", ",", "config", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"f0_origin\"", ",", "f0", ".", "astype", "(", "np", ".", "float", ")", ")", "\n", "\n", "", "if", "config", "[", "\"use_embed\"", "]", ":", "\n", "            ", "wav_torch", "=", "torch", ".", "from_numpy", "(", "wav", ")", "\n", "preprocessed_wav", "=", "encoder", ".", "preprocess_wav_torch", "(", "wav_torch", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._init_preprocess_dataset": [[53, 59], ["datasets_root.joinpath", "datasets_root.joinpath.exists", "print", "preprocess.DatasetLog"], "function", ["None"], ["embed", "=", "embed", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"embed\"", ",", "embed", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "", "elif", "config", "[", "'feat_type'", "]", "==", "'world'", ":", "\n", "        ", "feats", "=", "world_feature_extract", "(", "wav", ",", "config", ")", "\n", "frames", "=", "len", "(", "feats", ")", "\n", "write_hdf5", "(", "h5_file", ",", "\"feats\"", ",", "feats", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._preprocess_speaker_dirs": [[61, 119], ["print", "logger.finalize", "print", "out_dir.joinpath", "out_dir.joinpath.mkdir", "out_dir.joinpath.joinpath", "speaker_out_dir.joinpath.exists", "speaker_out_dir.joinpath.open", "speaker_dir.glob", "sources_fpath.open.close", "multiprocess.pool.ThreadPool", "list", "out_fname.replace.replace", "encoder.audio.preprocess_wav", "encoder.audio.wav_to_mel_spectrogram", "out_dir.joinpath.joinpath", "numpy.save", "logger.add_sample", "sources_fpath.open.write", "tqdm.tqdm", "len", "speaker_dir.relative_to", "len", "len", "pool.imap", "len", "speaker_out_dir.joinpath.open", "in_fpath.relative_to", "len", "line.split"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.finalize", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.preprocess_wav", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.audio.wav_to_mel_spectrogram", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.DatasetLog.add_sample"], ["", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Currently, only 'world'\u3001'librosa' are supported.\"", ")", "\n", "\n", "", "audio", "=", "np", ".", "pad", "(", "wav", ",", "(", "0", ",", "config", "[", "\"fft_size\"", "]", ")", ",", "mode", "=", "\"edge\"", ")", "\n", "audio", "=", "audio", "[", ":", "frames", "*", "config", "[", "\"hop_size\"", "]", "]", "\n", "assert", "frames", "*", "config", "[", "\"hop_size\"", "]", "==", "len", "(", "audio", ")", "\n", "\n", "write_hdf5", "(", "h5_file", ",", "\"wav\"", ",", "audio", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "return", "utt_id", ",", "h5_file", ",", "frames", ",", "len", "(", "audio", ")", "\n", "\n", "\n", "", "def", "write2file", "(", "values", ",", "config", ",", "outdir", ")", ":", "\n", "    ", "test_nums", "=", "config", "[", "'test_num'", "]", "\n", "train_text", "=", "open", "(", "os", ".", "path", ".", "join", "(", "outdir", ",", "'train.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "dev_text", "=", "open", "(", "os", ".", "path", ".", "join", "(", "outdir", ",", "'dev.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "for", "v", "in", "values", "[", ":", "test_nums", "]", ":", "\n", "        ", "dev_text", ".", "write", "(", "'|'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "v", "]", ")", "+", "'\\n'", ")", "\n", "", "for", "v", "in", "values", "[", "test_nums", ":", "]", ":", "\n", "        ", "train_text", ".", "write", "(", "'|'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "v", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "mel_frames", "=", "sum", "(", "[", "int", "(", "m", "[", "2", "]", ")", "for", "m", "in", "values", "]", ")", "\n", "timesteps", "=", "sum", "(", "[", "int", "(", "m", "[", "3", "]", ")", "for", "m", "in", "values", "]", ")", "\n", "sr", "=", "config", "[", "'sampling_rate'", "]", "\n", "hours", "=", "timesteps", "/", "sr", "/", "3600", "\n", "logging", ".", "info", "(", "'Write {} utterances, {} mel frames, {} audio timesteps, ({:.2f} hours)'", ".", "format", "(", "\n", "len", "(", "values", ")", ",", "mel_frames", ",", "timesteps", ",", "hours", ")", ")", "\n", "logging", ".", "info", "(", "'Max mel frames length: {}'", ".", "format", "(", "max", "(", "int", "(", "m", "[", "2", "]", ")", "for", "m", "in", "values", ")", ")", ")", "\n", "logging", ".", "info", "(", "'Max audio timesteps length: {}'", ".", "format", "(", "max", "(", "m", "[", "3", "]", "for", "m", "in", "values", ")", ")", ")", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Run preprocessing process.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Preprocess audio and then extract features (See detail in parallel_wavegan/bin/preprocess.py).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--inputdir\"", ",", "'-i'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory including wav files. you need to specify either scp or inputdir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dumpdir\"", ",", "'-o'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"directory to dump feature files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "'-c'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"yaml format configuration file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--verbose\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"logging level. higher is more logging. (default=1)\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set logger", "\n", "if", "args", ".", "verbose", ">", "1", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "DEBUG", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "elif", "args", ".", "verbose", ">", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "level", "=", "logging", ".", "WARN", ",", "format", "=", "\"%(asctime)s (%(module)s:%(lineno)d) %(levelname)s: %(message)s\"", ")", "\n", "logging", ".", "warning", "(", "'Skip DEBUG/INFO messages'", ")", "\n", "\n", "# load config", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.preprocess_librispeech": [[121, 132], ["preprocess._init_preprocess_dataset", "list", "preprocess._preprocess_speaker_dirs", "dataset_root.glob"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._init_preprocess_dataset", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._preprocess_speaker_dirs"], ["        ", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "", "config", ".", "update", "(", "vars", "(", "args", ")", ")", "\n", "# check arguments", "\n", "if", "args", ".", "inputdir", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Please specify either --rootdir or --wav-scp.\"", ")", "\n", "\n", "# get dataset", "\n", "", "assert", "args", ".", "inputdir", "is", "not", "None", "\n", "dataset", "=", "AudioDataset", "(", "\n", "args", ".", "inputdir", ",", "\"*.wav\"", ",", "\n", "audio_load_fn", "=", "sf", ".", "read", ",", "\n", "return_utt_id", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.preprocess_voxceleb1": [[134, 162], ["preprocess._init_preprocess_dataset", "print", "dataset_root.joinpath().glob", "print", "preprocess._preprocess_speaker_dirs", "dataset_root.joinpath().open", "nationalities.items", "dataset_root.joinpath", "dataset_root.joinpath", "line.split", "nationality.lower", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._init_preprocess_dataset", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._preprocess_speaker_dirs"], ["if", "config", "[", "\"use_embed\"", "]", ":", "\n", "        ", "print", "(", "\"Preparing the encoder...\"", ")", "\n", "encoder", ".", "load_model", "(", "config", "[", "\"enc_model_fpath\"", "]", ",", "preprocess", "=", "True", ")", "\n", "\n", "# check directly existence", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "dumpdir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "dumpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# process each data", "\n", "", "futures", "=", "[", "]", "\n", "p", "=", "Pool", "(", "int", "(", "os", ".", "getenv", "(", "'N_PROC'", ",", "os", ".", "cpu_count", "(", ")", ")", ")", ")", "\n", "\n", "simple_table", "(", "[", "\n", "(", "'Data Path'", ",", "args", ".", "inputdir", ")", ",", "\n", "(", "'Preprocess Path'", ",", "args", ".", "dumpdir", ")", ",", "\n", "(", "'Config File'", ",", "args", ".", "config", ")", ",", "\n", "(", "'CPU Usage'", ",", "os", ".", "cpu_count", "(", ")", ")", "\n", "]", ")", "\n", "\n", "\n", "\n", "for", "utt_id", ",", "(", "audio", ",", "fs", ")", "in", "tqdm", "(", "dataset", ")", ":", "\n", "# check", "\n", "        ", "assert", "len", "(", "audio", ".", "shape", ")", "==", "1", ",", "f\"{utt_id} seems to be multi-channel signal.\"", "\n", "assert", "np", ".", "abs", "(", "audio", ")", ".", "max", "(", ")", "<=", "1.0", ",", "f\"{utt_id} seems to be different from 16 bit PCM.\"", "\n", "assert", "fs", "==", "config", "[", "\"sampling_rate\"", "]", ",", "f\"{utt_id} seems to have a different sampling rate.\"", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess.preprocess_voxceleb2": [[164, 176], ["preprocess._init_preprocess_dataset", "list", "preprocess._preprocess_speaker_dirs", "dataset_root.joinpath().glob", "dataset_root.joinpath"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._init_preprocess_dataset", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.preprocess._preprocess_speaker_dirs"], ["# trim silence", "\n", "if", "config", "[", "\"trim_silence\"", "]", ":", "\n", "            ", "audio", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "audio", ",", "\n", "top_db", "=", "config", "[", "\"trim_threshold_in_db\"", "]", ",", "\n", "frame_length", "=", "config", "[", "\"trim_frame_size\"", "]", ",", "\n", "hop_length", "=", "config", "[", "\"trim_hop_size\"", "]", ")", "\n", "\n", "", "if", "\"sampling_rate_for_feats\"", "not", "in", "config", ":", "\n", "            ", "x", "=", "audio", "\n", "sampling_rate", "=", "config", "[", "\"sampling_rate\"", "]", "\n", "hop_size", "=", "config", "[", "\"hop_size\"", "]", "\n", "", "else", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync": [[9, 15], ["torch.cuda.synchronize"], "function", ["None"], ["def", "sync", "(", "device", ":", "torch", ".", "device", ")", ":", "\n", "# FIXME", "\n", "    ", "return", "\n", "# For correct profiling (cuda operations are async)", "\n", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.train": [[16, 103], ["encoder.data_objects.SpeakerVerificationDataset", "encoder.data_objects.SpeakerVerificationDataLoader", "torch.device", "torch.device", "encoder.model.SpeakerEncoder", "torch.optim.Adam", "models_dir.joinpath", "models_dir.joinpath", "encoder.model.SpeakerEncoder.train", "encoder.visualizations.Visualizations", "encoder.visualizations.Visualizations.log_dataset", "encoder.visualizations.Visualizations.log_params", "str", "encoder.visualizations.Visualizations.log_implementation", "utils.profiler.Profiler", "enumerate", "encoder.model.SpeakerEncoder.parameters", "models_dir.joinpath.exists", "print", "utils.profiler.Profiler.tick", "torch.from_numpy().to", "plot_umap.sync", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.", "plot_umap.sync", "utils.profiler.Profiler.tick", "embeds.detach().cpu().numpy.view().to", "encoder.model.SpeakerEncoder.loss", "plot_umap.sync", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.zero_grad", "loss.backward", "utils.profiler.Profiler.tick", "encoder.model.SpeakerEncoder.do_gradient_ops", "torch.optim.Adam.step", "utils.profiler.Profiler.tick", "encoder.visualizations.Visualizations.update", "torch.cuda.is_available", "print", "torch.load", "encoder.model.SpeakerEncoder.load_state_dict", "torch.optim.Adam.load_state_dict", "print", "torch.cuda.is_available", "torch.cuda.get_device_name", "loss.item", "print", "models_dir.joinpath.mkdir", "models_dir.joinpath.joinpath", "embeds.detach().cpu().numpy.detach().cpu().numpy", "encoder.visualizations.Visualizations.draw_projections", "encoder.visualizations.Visualizations.save", "torch.from_numpy", "embeds.detach().cpu().numpy.view", "embeds.detach().cpu().numpy.detach().cpu", "embeds.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.train", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_dataset", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_params", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_implementation", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.loss", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.plot_umap.sync", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.do_gradient_ops", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.draw_projections", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save"], ["", "", "def", "train", "(", "run_id", ":", "str", ",", "clean_data_root", ":", "Path", ",", "models_dir", ":", "Path", ",", "umap_every", ":", "int", ",", "save_every", ":", "int", ",", "\n", "backup_every", ":", "int", ",", "vis_every", ":", "int", ",", "force_restart", ":", "bool", ",", "visdom_server", ":", "str", ",", "\n", "no_visdom", ":", "bool", ")", ":", "\n", "# Create a dataset and a dataloader", "\n", "    ", "dataset", "=", "SpeakerVerificationDataset", "(", "clean_data_root", ")", "\n", "loader", "=", "SpeakerVerificationDataLoader", "(", "\n", "dataset", ",", "\n", "speakers_per_batch", ",", "\n", "utterances_per_speaker", ",", "\n", "num_workers", "=", "8", ",", "\n", ")", "\n", "\n", "# Setup the device on which to run the forward pass and the loss. These can be different, ", "\n", "# because the forward pass is faster on the GPU whereas the loss is often (depending on your", "\n", "# hyperparameters) faster on the CPU.", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "# FIXME: currently, the gradient is None if loss_device is cuda", "\n", "loss_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# Create the model and the optimizer", "\n", "model", "=", "SpeakerEncoder", "(", "device", ",", "loss_device", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate_init", ")", "\n", "init_step", "=", "1", "\n", "\n", "# Configure file path for the model", "\n", "state_fpath", "=", "models_dir", ".", "joinpath", "(", "run_id", "+", "\".pt\"", ")", "\n", "backup_dir", "=", "models_dir", ".", "joinpath", "(", "run_id", "+", "\"_backups\"", ")", "\n", "\n", "# Load any existing model", "\n", "if", "not", "force_restart", ":", "\n", "        ", "if", "state_fpath", ".", "exists", "(", ")", ":", "\n", "            ", "print", "(", "\"Found existing model \\\"%s\\\", loading it and resuming training.\"", "%", "run_id", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "state_fpath", ")", "\n", "init_step", "=", "checkpoint", "[", "\"step\"", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"model_state\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer_state\"", "]", ")", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "=", "learning_rate_init", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"No model \\\"%s\\\" found, starting training from scratch.\"", "%", "run_id", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"Starting the training from scratch.\"", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "# Initialize the visualization environment", "\n", "vis", "=", "Visualizations", "(", "run_id", ",", "vis_every", ",", "server", "=", "visdom_server", ",", "disabled", "=", "no_visdom", ")", "\n", "vis", ".", "log_dataset", "(", "dataset", ")", "\n", "vis", ".", "log_params", "(", ")", "\n", "device_name", "=", "str", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "0", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"CPU\"", ")", "\n", "vis", ".", "log_implementation", "(", "{", "\"Device\"", ":", "device_name", "}", ")", "\n", "\n", "# Training loop", "\n", "profiler", "=", "Profiler", "(", "summarize_every", "=", "10", ",", "disabled", "=", "False", ")", "\n", "for", "step", ",", "speaker_batch", "in", "enumerate", "(", "loader", ",", "init_step", ")", ":", "\n", "        ", "profiler", ".", "tick", "(", "\"Blocking, waiting for batch (threaded)\"", ")", "\n", "\n", "# Forward pass", "\n", "inputs", "=", "torch", ".", "from_numpy", "(", "speaker_batch", ".", "data", ")", ".", "to", "(", "device", ")", "\n", "sync", "(", "device", ")", "\n", "profiler", ".", "tick", "(", "\"Data to %s\"", "%", "device", ")", "\n", "embeds", "=", "model", "(", "inputs", ")", "\n", "sync", "(", "device", ")", "\n", "profiler", ".", "tick", "(", "\"Forward pass\"", ")", "\n", "embeds_loss", "=", "embeds", ".", "view", "(", "(", "speakers_per_batch", ",", "utterances_per_speaker", ",", "-", "1", ")", ")", ".", "to", "(", "loss_device", ")", "\n", "loss", ",", "eer", "=", "model", ".", "loss", "(", "embeds_loss", ")", "\n", "sync", "(", "loss_device", ")", "\n", "profiler", ".", "tick", "(", "\"Loss\"", ")", "\n", "\n", "# Backward pass", "\n", "model", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "profiler", ".", "tick", "(", "\"Backward pass\"", ")", "\n", "model", ".", "do_gradient_ops", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "profiler", ".", "tick", "(", "\"Parameter update\"", ")", "\n", "\n", "# Update visualizations", "\n", "# learning_rate = optimizer.param_groups[0][\"lr\"]", "\n", "vis", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "eer", ",", "step", ")", "\n", "\n", "# Draw projections and save them to the backup folder", "\n", "if", "umap_every", "!=", "0", "and", "step", "%", "umap_every", "==", "0", ":", "\n", "            ", "print", "(", "\"Drawing and saving projections (step %d)\"", "%", "step", ")", "\n", "backup_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "projection_fpath", "=", "backup_dir", ".", "joinpath", "(", "\"%s_umap_%06d.png\"", "%", "(", "run_id", ",", "step", ")", ")", "\n", "embeds", "=", "embeds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "vis", ".", "draw_projections", "(", "embeds", ",", "utterances_per_speaker", ",", "step", ",", "projection_fpath", ")", "\n", "vis", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.__init__": [[13, 32], ["torch.nn.Module.__init__", "torch.nn.LSTM().to", "torch.nn.Linear().to", "torch.nn.ReLU().to", "torch.nn.Parameter().to", "torch.nn.Parameter().to", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.CrossEntropyLoss", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "device", ",", "loss_device", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_device", "=", "loss_device", "\n", "\n", "# Network defition", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "mel_n_channels", ",", "\n", "hidden_size", "=", "model_hidden_size", ",", "\n", "num_layers", "=", "model_num_layers", ",", "\n", "batch_first", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_features", "=", "model_hidden_size", ",", "\n", "out_features", "=", "model_embedding_size", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Cosine similarity scaling (with fixed initial parameter values)", "\n", "self", ".", "similarity_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "10.", "]", ")", ")", ".", "to", "(", "loss_device", ")", "\n", "self", ".", "similarity_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "-", "5.", "]", ")", ")", ".", "to", "(", "loss_device", ")", "\n", "\n", "# Loss", "\n", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.do_gradient_ops": [[33, 40], ["torch.nn.utils.clip_grad_norm_", "model.SpeakerEncoder.parameters"], "methods", ["None"], ["", "def", "do_gradient_ops", "(", "self", ")", ":", "\n", "# Gradient scale", "\n", "        ", "self", ".", "similarity_weight", ".", "grad", "*=", "0.01", "\n", "self", ".", "similarity_bias", ".", "grad", "*=", "0.01", "\n", "\n", "# Gradient clipping", "\n", "clip_grad_norm_", "(", "self", ".", "parameters", "(", ")", ",", "3", ",", "norm_type", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.forward": [[41, 64], ["model.SpeakerEncoder.lstm", "model.SpeakerEncoder.relu", "model.SpeakerEncoder.linear", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "utterances", ",", "hidden_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings of a batch of utterance spectrograms.\n        \n        :param utterances: batch of mel-scale filterbanks of same duration as a tensor of shape \n        (batch_size, n_frames, n_channels) \n        :param hidden_init: initial hidden state of the LSTM as a tensor of shape (num_layers, \n        batch_size, hidden_size). Will default to a tensor of zeros if None.\n        :return: the embeddings as a tensor of shape (batch_size, embedding_size)\n        \"\"\"", "\n", "# Pass the input through the LSTM layers and retrieve all outputs, the final hidden state", "\n", "# and the final cell state.", "\n", "# if not (next(self.lstm.parameters())).is_cuda:", "\n", "#     self.lstm.cuda()", "\n", "out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "lstm", "(", "utterances", ",", "hidden_init", ")", "\n", "\n", "# We take only the hidden state of the last layer", "\n", "embeds_raw", "=", "self", ".", "relu", "(", "self", ".", "linear", "(", "hidden", "[", "-", "1", "]", ")", ")", "\n", "\n", "# L2-normalize it", "\n", "embeds", "=", "embeds_raw", "/", "torch", ".", "norm", "(", "embeds_raw", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "return", "embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.forward_perceptual": [[65, 84], ["model.SpeakerEncoder.lstm", "model.SpeakerEncoder.relu", "model.SpeakerEncoder.linear"], "methods", ["None"], ["", "def", "forward_perceptual", "(", "self", ",", "utterances", ",", "hidden_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings of a batch of utterance spectrograms.\n\n        :param utterances: batch of mel-scale filterbanks of same duration as a tensor of shape\n        (batch_size, n_frames, n_channels)\n        :param hidden_init: initial hidden state of the LSTM as a tensor of shape (num_layers,\n        batch_size, hidden_size). Will default to a tensor of zeros if None.\n        :return: the embeddings as a tensor of shape (batch_size, embedding_size)\n        \"\"\"", "\n", "# Pass the input through the LSTM layers and retrieve all outputs, the final hidden state", "\n", "# and the final cell state.", "\n", "# if not (next(self.lstm.parameters())).is_cuda:", "\n", "#     self.lstm.cuda()", "\n", "out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "lstm", "(", "utterances", ",", "hidden_init", ")", "\n", "\n", "# We take only the hidden state of the last layer", "\n", "embeds_raw", "=", "self", ".", "relu", "(", "self", ".", "linear", "(", "hidden", "[", "-", "1", "]", ")", ")", "\n", "return", "embeds_raw", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.forward_perceptual2": [[86, 103], ["model.SpeakerEncoder.lstm"], "methods", ["None"], ["", "def", "forward_perceptual2", "(", "self", ",", "utterances", ",", "hidden_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings of a batch of utterance spectrograms.\n\n        :param utterances: batch of mel-scale filterbanks of same duration as a tensor of shape\n        (batch_size, n_frames, n_channels)\n        :param hidden_init: initial hidden state of the LSTM as a tensor of shape (num_layers,\n        batch_size, hidden_size). Will default to a tensor of zeros if None.\n        :return: the embeddings as a tensor of shape (batch_size, embedding_size)\n        \"\"\"", "\n", "# Pass the input through the LSTM layers and retrieve all outputs, the final hidden state", "\n", "# and the final cell state.", "\n", "# if not (next(self.lstm.parameters())).is_cuda:", "\n", "#     self.lstm.cuda()", "\n", "out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "lstm", "(", "utterances", ",", "hidden_init", ")", "\n", "\n", "return", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.similarity_matrix": [[104, 147], ["torch.mean", "torch.zeros().to", "range", "torch.mean.clone", "torch.norm", "torch.sum", "centroids_excl.clone", "torch.norm", "numpy.eye", "torch.zeros", "numpy.where"], "methods", ["None"], ["", "def", "similarity_matrix", "(", "self", ",", "embeds", ")", ":", "\n", "        ", "\"\"\"\n        Computes the similarity matrix according the section 2.1 of GE2E.\n\n        :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n        utterances_per_speaker, embedding_size)\n        :return: the similarity matrix as a tensor of shape (speakers_per_batch,\n        utterances_per_speaker, speakers_per_batch)\n        \"\"\"", "\n", "speakers_per_batch", ",", "utterances_per_speaker", "=", "embeds", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Inclusive centroids (1 per speaker). Cloning is needed for reverse differentiation", "\n", "centroids_incl", "=", "torch", ".", "mean", "(", "embeds", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "centroids_incl", "=", "centroids_incl", ".", "clone", "(", ")", "/", "torch", ".", "norm", "(", "centroids_incl", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Exclusive centroids (1 per utterance)", "\n", "centroids_excl", "=", "(", "torch", ".", "sum", "(", "embeds", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "-", "embeds", ")", "\n", "centroids_excl", "/=", "(", "utterances_per_speaker", "-", "1", ")", "\n", "centroids_excl", "=", "centroids_excl", ".", "clone", "(", ")", "/", "torch", ".", "norm", "(", "centroids_excl", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Similarity matrix. The cosine similarity of already 2-normed vectors is simply the dot", "\n", "# product of these vectors (which is just an element-wise multiplication reduced by a sum).", "\n", "# We vectorize the computation for efficiency.", "\n", "sim_matrix", "=", "torch", ".", "zeros", "(", "speakers_per_batch", ",", "utterances_per_speaker", ",", "\n", "speakers_per_batch", ")", ".", "to", "(", "self", ".", "loss_device", ")", "\n", "mask_matrix", "=", "1", "-", "np", ".", "eye", "(", "speakers_per_batch", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "j", "in", "range", "(", "speakers_per_batch", ")", ":", "\n", "            ", "mask", "=", "np", ".", "where", "(", "mask_matrix", "[", "j", "]", ")", "[", "0", "]", "\n", "sim_matrix", "[", "mask", ",", ":", ",", "j", "]", "=", "(", "embeds", "[", "mask", "]", "*", "centroids_incl", "[", "j", "]", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "sim_matrix", "[", "j", ",", ":", ",", "j", "]", "=", "(", "embeds", "[", "j", "]", "*", "centroids_excl", "[", "j", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "## Even more vectorized version (slower maybe because of transpose)", "\n", "# sim_matrix2 = torch.zeros(speakers_per_batch, speakers_per_batch, utterances_per_speaker", "\n", "#                           ).to(self.loss_device)", "\n", "# eye = np.eye(speakers_per_batch, dtype=np.int)", "\n", "# mask = np.where(1 - eye)", "\n", "# sim_matrix2[mask] = (embeds[mask[0]] * centroids_incl[mask[1]]).sum(dim=2)", "\n", "# mask = np.where(eye)", "\n", "# sim_matrix2[mask] = (embeds * centroids_excl).sum(dim=2)", "\n", "# sim_matrix2 = sim_matrix2.transpose(1, 2)", "\n", "\n", "", "sim_matrix", "=", "sim_matrix", "*", "self", ".", "similarity_weight", "+", "self", ".", "similarity_bias", "\n", "return", "sim_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.loss": [[148, 177], ["model.SpeakerEncoder.similarity_matrix", "sim_matrix.reshape.reshape.reshape", "numpy.repeat", "torch.from_numpy().long().to", "model.SpeakerEncoder.loss_fn", "numpy.arange", "torch.no_grad", "numpy.array", "sim_matrix.reshape.reshape.detach().cpu().numpy", "sklearn.metrics.roc_curve", "scipy.optimize.brentq", "torch.from_numpy().long", "numpy.array.flatten", "sim_matrix.reshape.detach().cpu().numpy.flatten", "numpy.eye", "inv_argmax", "sim_matrix.reshape.reshape.detach().cpu", "torch.from_numpy", "sim_matrix.reshape.reshape.detach", "scipy.interpolate.interp1d"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.model.SpeakerEncoder.similarity_matrix"], ["", "def", "loss", "(", "self", ",", "embeds", ")", ":", "\n", "        ", "\"\"\"\n        Computes the softmax loss according the section 2.1 of GE2E.\n        \n        :param embeds: the embeddings as a tensor of shape (speakers_per_batch, \n        utterances_per_speaker, embedding_size)\n        :return: the loss and the EER for this batch of embeddings.\n        \"\"\"", "\n", "speakers_per_batch", ",", "utterances_per_speaker", "=", "embeds", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Loss", "\n", "sim_matrix", "=", "self", ".", "similarity_matrix", "(", "embeds", ")", "\n", "sim_matrix", "=", "sim_matrix", ".", "reshape", "(", "(", "speakers_per_batch", "*", "utterances_per_speaker", ",", "\n", "speakers_per_batch", ")", ")", "\n", "ground_truth", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "speakers_per_batch", ")", ",", "utterances_per_speaker", ")", "\n", "target", "=", "torch", ".", "from_numpy", "(", "ground_truth", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "loss_device", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "sim_matrix", ",", "target", ")", "\n", "\n", "# EER (not backpropagated)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inv_argmax", "=", "lambda", "i", ":", "np", ".", "eye", "(", "1", ",", "speakers_per_batch", ",", "i", ",", "dtype", "=", "np", ".", "int", ")", "[", "0", "]", "\n", "labels", "=", "np", ".", "array", "(", "[", "inv_argmax", "(", "i", ")", "for", "i", "in", "ground_truth", "]", ")", "\n", "preds", "=", "sim_matrix", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Snippet from https://yangcha.github.io/EER-ROC/", "\n", "fpr", ",", "tpr", ",", "thresholds", "=", "roc_curve", "(", "labels", ".", "flatten", "(", ")", ",", "preds", ".", "flatten", "(", ")", ")", "\n", "eer", "=", "brentq", "(", "lambda", "x", ":", "1.", "-", "x", "-", "interp1d", "(", "fpr", ",", "tpr", ")", "(", "x", ")", ",", "0.", ",", "1.", ")", "\n", "\n", "", "return", "loss", ",", "eer", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.__init__": [[28, 64], ["time.perf_counter", "print", "str", "datetime.datetime.datetime.now().strftime", "visdom.Visdom", "Exception", "datetime.datetime.datetime.now"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "env_name", "=", "None", ",", "update_every", "=", "10", ",", "server", "=", "\"http://localhost\"", ",", "disabled", "=", "False", ")", ":", "\n", "# Tracking data", "\n", "        ", "self", ".", "last_update_timestamp", "=", "timer", "(", ")", "\n", "self", ".", "update_every", "=", "update_every", "\n", "self", ".", "step_times", "=", "[", "]", "\n", "self", ".", "losses", "=", "[", "]", "\n", "self", ".", "eers", "=", "[", "]", "\n", "print", "(", "\"Updating the visualizations every %d steps.\"", "%", "update_every", ")", "\n", "\n", "# If visdom is disabled TODO: use a better paradigm for that", "\n", "self", ".", "disabled", "=", "disabled", "\n", "if", "self", ".", "disabled", ":", "\n", "            ", "return", "\n", "\n", "# Set the environment name", "\n", "", "now", "=", "str", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d-%m %Hh%M\"", ")", ")", "\n", "if", "env_name", "is", "None", ":", "\n", "            ", "self", ".", "env_name", "=", "now", "\n", "", "else", ":", "\n", "            ", "self", ".", "env_name", "=", "\"%s (%s)\"", "%", "(", "env_name", ",", "now", ")", "\n", "\n", "# Connect to visdom and open the corresponding window in the browser", "\n", "", "try", ":", "\n", "            ", "self", ".", "vis", "=", "visdom", ".", "Visdom", "(", "server", ",", "env", "=", "self", ".", "env_name", ",", "raise_exceptions", "=", "True", ")", "\n", "", "except", "ConnectionError", ":", "\n", "            ", "raise", "Exception", "(", "\"No visdom server detected. Run the command \\\"visdom\\\" in your CLI to \"", "\n", "\"start it.\"", ")", "\n", "# webbrowser.open(\"http://localhost:8097/env/\" + self.env_name)", "\n", "\n", "# Create the windows", "\n", "", "self", ".", "loss_win", "=", "None", "\n", "self", ".", "eer_win", "=", "None", "\n", "# self.lr_win = None", "\n", "self", ".", "implementation_win", "=", "None", "\n", "self", ".", "projection_win", "=", "None", "\n", "self", ".", "implementation_string", "=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_params": [[65, 79], ["visualizations.Visualizations.vis.text", "getattr", "getattr", "dir", "dir", "p.startswith", "p.startswith"], "methods", ["None"], ["", "def", "log_params", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "disabled", ":", "\n", "            ", "return", "\n", "", "from", "encoder", "import", "params_data", "\n", "from", "encoder", "import", "params_model", "\n", "param_string", "=", "\"<b>Model parameters</b>:<br>\"", "\n", "for", "param_name", "in", "(", "p", "for", "p", "in", "dir", "(", "params_model", ")", "if", "not", "p", ".", "startswith", "(", "\"__\"", ")", ")", ":", "\n", "            ", "value", "=", "getattr", "(", "params_model", ",", "param_name", ")", "\n", "param_string", "+=", "\"\\t%s: %s<br>\"", "%", "(", "param_name", ",", "value", ")", "\n", "", "param_string", "+=", "\"<b>Data parameters</b>:<br>\"", "\n", "for", "param_name", "in", "(", "p", "for", "p", "in", "dir", "(", "params_data", ")", "if", "not", "p", ".", "startswith", "(", "\"__\"", ")", ")", ":", "\n", "            ", "value", "=", "getattr", "(", "params_data", ",", "param_name", ")", "\n", "param_string", "+=", "\"\\t%s: %s<br>\"", "%", "(", "param_name", ",", "value", ")", "\n", "", "self", ".", "vis", ".", "text", "(", "param_string", ",", "opts", "=", "{", "\"title\"", ":", "\"Parameters\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_dataset": [[80, 88], ["dataset_string.replace.replace.replace", "visualizations.Visualizations.vis.text", "len", "dataset.get_logs"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataset.get_logs"], ["", "def", "log_dataset", "(", "self", ",", "dataset", ":", "SpeakerVerificationDataset", ")", ":", "\n", "        ", "if", "self", ".", "disabled", ":", "\n", "            ", "return", "\n", "", "dataset_string", "=", "\"\"", "\n", "dataset_string", "+=", "\"<b>Speakers</b>: %s\\n\"", "%", "len", "(", "dataset", ".", "speakers", ")", "\n", "dataset_string", "+=", "\"\\n\"", "+", "dataset", ".", "get_logs", "(", ")", "\n", "dataset_string", "=", "dataset_string", ".", "replace", "(", "\"\\n\"", ",", "\"<br>\"", ")", "\n", "self", ".", "vis", ".", "text", "(", "dataset_string", ",", "opts", "=", "{", "\"title\"", ":", "\"Dataset\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.log_implementation": [[89, 100], ["params.items", "visualizations.Visualizations.vis.text", "implementation_string.replace.replace.replace"], "methods", ["None"], ["", "def", "log_implementation", "(", "self", ",", "params", ")", ":", "\n", "        ", "if", "self", ".", "disabled", ":", "\n", "            ", "return", "\n", "", "implementation_string", "=", "\"\"", "\n", "for", "param", ",", "value", "in", "params", ".", "items", "(", ")", ":", "\n", "            ", "implementation_string", "+=", "\"<b>%s</b>: %s\\n\"", "%", "(", "param", ",", "value", ")", "\n", "implementation_string", "=", "implementation_string", ".", "replace", "(", "\"\\n\"", ",", "\"<br>\"", ")", "\n", "", "self", ".", "implementation_string", "=", "implementation_string", "\n", "self", ".", "implementation_win", "=", "self", ".", "vis", ".", "text", "(", "\n", "implementation_string", ",", "\n", "opts", "=", "{", "\"title\"", ":", "\"Training implementation\"", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update": [[102, 154], ["time.perf_counter", "visualizations.Visualizations.step_times.append", "visualizations.Visualizations.losses.append", "visualizations.Visualizations.eers.append", "print", "print", "visualizations.Visualizations.losses.clear", "visualizations.Visualizations.eers.clear", "visualizations.Visualizations.step_times.clear", "visualizations.Visualizations.vis.line", "visualizations.Visualizations.vis.line", "int", "int", "visualizations.Visualizations.vis.text", "numpy.mean", "numpy.std", "numpy.mean", "numpy.mean", "numpy.mean", "dict", "numpy.mean", "dict"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "loss", ",", "eer", ",", "step", ")", ":", "\n", "# Update the tracking data", "\n", "        ", "now", "=", "timer", "(", ")", "\n", "self", ".", "step_times", ".", "append", "(", "1000", "*", "(", "now", "-", "self", ".", "last_update_timestamp", ")", ")", "\n", "self", ".", "last_update_timestamp", "=", "now", "\n", "self", ".", "losses", ".", "append", "(", "loss", ")", "\n", "self", ".", "eers", ".", "append", "(", "eer", ")", "\n", "print", "(", "\".\"", ",", "end", "=", "\"\"", ")", "\n", "\n", "# Update the plots every <update_every> steps", "\n", "if", "step", "%", "self", ".", "update_every", "!=", "0", ":", "\n", "            ", "return", "\n", "", "time_string", "=", "\"Step time:  mean: %5dms  std: %5dms\"", "%", "(", "int", "(", "np", ".", "mean", "(", "self", ".", "step_times", ")", ")", ",", "int", "(", "np", ".", "std", "(", "self", ".", "step_times", ")", ")", ")", "\n", "print", "(", "\"\\nStep %6d   Loss: %.4f   EER: %.4f   %s\"", "%", "\n", "(", "step", ",", "np", ".", "mean", "(", "self", ".", "losses", ")", ",", "np", ".", "mean", "(", "self", ".", "eers", ")", ",", "time_string", ")", ")", "\n", "if", "not", "self", ".", "disabled", ":", "\n", "            ", "self", ".", "loss_win", "=", "self", ".", "vis", ".", "line", "(", "\n", "[", "np", ".", "mean", "(", "self", ".", "losses", ")", "]", ",", "\n", "[", "step", "]", ",", "\n", "win", "=", "self", ".", "loss_win", ",", "\n", "update", "=", "\"append\"", "if", "self", ".", "loss_win", "else", "None", ",", "\n", "opts", "=", "dict", "(", "\n", "legend", "=", "[", "\"Avg. loss\"", "]", ",", "\n", "xlabel", "=", "\"Step\"", ",", "\n", "ylabel", "=", "\"Loss\"", ",", "\n", "title", "=", "\"Loss\"", ",", "\n", ")", "\n", ")", "\n", "self", ".", "eer_win", "=", "self", ".", "vis", ".", "line", "(", "\n", "[", "np", ".", "mean", "(", "self", ".", "eers", ")", "]", ",", "\n", "[", "step", "]", ",", "\n", "win", "=", "self", ".", "eer_win", ",", "\n", "update", "=", "\"append\"", "if", "self", ".", "eer_win", "else", "None", ",", "\n", "opts", "=", "dict", "(", "\n", "legend", "=", "[", "\"Avg. EER\"", "]", ",", "\n", "xlabel", "=", "\"Step\"", ",", "\n", "ylabel", "=", "\"EER\"", ",", "\n", "title", "=", "\"Equal error rate\"", "\n", ")", "\n", ")", "\n", "if", "self", ".", "implementation_win", "is", "not", "None", ":", "\n", "                ", "self", ".", "vis", ".", "text", "(", "\n", "self", ".", "implementation_string", "+", "(", "\"<b>%s</b>\"", "%", "time_string", ")", ",", "\n", "win", "=", "self", ".", "implementation_win", ",", "\n", "opts", "=", "{", "\"title\"", ":", "\"Training implementation\"", "}", ",", "\n", ")", "\n", "\n", "# Reset the tracking", "\n", "", "", "self", ".", "losses", ".", "clear", "(", ")", "\n", "self", ".", "eers", ".", "clear", "(", ")", "\n", "self", ".", "step_times", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.draw_projections": [[155, 174], ["min", "numpy.repeat", "umap.UMAP", "umap.UMAP.fit_transform", "matplotlib.scatter", "matplotlib.gca().set_aspect", "matplotlib.title", "matplotlib.clf", "len", "len", "numpy.arange", "visualizations.Visualizations.vis.matplot", "matplotlib.savefig", "matplotlib.gca"], "methods", ["None"], ["", "def", "draw_projections", "(", "self", ",", "embeds", ",", "utterances_per_speaker", ",", "step", ",", "out_fpath", "=", "None", ",", "\n", "max_speakers", "=", "10", ")", ":", "\n", "        ", "max_speakers", "=", "min", "(", "max_speakers", ",", "len", "(", "colormap", ")", ")", "\n", "embeds", "=", "embeds", "[", ":", "max_speakers", "*", "utterances_per_speaker", "]", "\n", "\n", "n_speakers", "=", "len", "(", "embeds", ")", "//", "utterances_per_speaker", "\n", "ground_truth", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "n_speakers", ")", ",", "utterances_per_speaker", ")", "\n", "colors", "=", "[", "colormap", "[", "i", "]", "for", "i", "in", "ground_truth", "]", "\n", "\n", "reducer", "=", "umap", ".", "UMAP", "(", ")", "\n", "projected", "=", "reducer", ".", "fit_transform", "(", "embeds", ")", "\n", "plt", ".", "scatter", "(", "projected", "[", ":", ",", "0", "]", ",", "projected", "[", ":", ",", "1", "]", ",", "c", "=", "colors", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_aspect", "(", "\"equal\"", ",", "\"datalim\"", ")", "\n", "plt", ".", "title", "(", "\"UMAP projection (step %d)\"", "%", "step", ")", "\n", "if", "not", "self", ".", "disabled", ":", "\n", "            ", "self", ".", "projection_win", "=", "self", ".", "vis", ".", "matplot", "(", "plt", ",", "win", "=", "self", ".", "projection_win", ")", "\n", "", "if", "out_fpath", "is", "not", "None", ":", "\n", "            ", "plt", ".", "savefig", "(", "out_fpath", ")", "\n", "", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save": [[175, 178], ["visualizations.Visualizations.vis.save"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.save"], ["", "def", "save", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "disabled", ":", "\n", "            ", "self", ".", "vis", ".", "save", "(", "[", "self", ".", "env_name", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataset.__init__": [[11, 19], ["encoder.data_objects.random_cycler.RandomCycler", "len", "Exception", "encoder.data_objects.speaker.Speaker", "speaker_verification_dataset.SpeakerVerificationDataset.root.glob", "f.is_dir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "datasets_root", ":", "Path", ")", ":", "\n", "        ", "self", ".", "root", "=", "datasets_root", "\n", "speaker_dirs", "=", "[", "f", "for", "f", "in", "self", ".", "root", ".", "glob", "(", "\"*\"", ")", "if", "f", ".", "is_dir", "(", ")", "]", "\n", "if", "len", "(", "speaker_dirs", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"No speakers found. Make sure you are pointing to the directory \"", "\n", "\"containing all preprocessed speaker directories.\"", ")", "\n", "", "self", ".", "speakers", "=", "[", "Speaker", "(", "speaker_dir", ")", "for", "speaker_dir", "in", "speaker_dirs", "]", "\n", "self", ".", "speaker_cycler", "=", "RandomCycler", "(", "self", ".", "speakers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataset.__len__": [[20, 22], ["int"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "1e10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataset.__getitem__": [[23, 25], ["next"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "speaker_cycler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataset.get_logs": [[26, 32], ["speaker_verification_dataset.SpeakerVerificationDataset.root.glob", "log_fpath.open", "log_file.readlines"], "methods", ["None"], ["", "def", "get_logs", "(", "self", ")", ":", "\n", "        ", "log_string", "=", "\"\"", "\n", "for", "log_fpath", "in", "self", ".", "root", ".", "glob", "(", "\"*.txt\"", ")", ":", "\n", "            ", "with", "log_fpath", ".", "open", "(", "\"r\"", ")", "as", "log_file", ":", "\n", "                ", "log_string", "+=", "\"\"", ".", "join", "(", "log_file", ".", "readlines", "(", ")", ")", "\n", "", "", "return", "log_string", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataLoader.__init__": [[35, 52], ["torch.utils.data.DataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "speakers_per_batch", ",", "utterances_per_speaker", ",", "sampler", "=", "None", ",", "\n", "batch_sampler", "=", "None", ",", "num_workers", "=", "0", ",", "pin_memory", "=", "False", ",", "timeout", "=", "0", ",", "\n", "worker_init_fn", "=", "None", ")", ":", "\n", "        ", "self", ".", "utterances_per_speaker", "=", "utterances_per_speaker", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "speakers_per_batch", ",", "\n", "shuffle", "=", "False", ",", "\n", "sampler", "=", "sampler", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "self", ".", "collate", ",", "\n", "pin_memory", "=", "pin_memory", ",", "\n", "drop_last", "=", "False", ",", "\n", "timeout", "=", "timeout", ",", "\n", "worker_init_fn", "=", "worker_init_fn", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_verification_dataset.SpeakerVerificationDataLoader.collate": [[54, 56], ["encoder.data_objects.speaker_batch.SpeakerBatch"], "methods", ["None"], ["", "def", "collate", "(", "self", ",", "speakers", ")", ":", "\n", "        ", "return", "SpeakerBatch", "(", "speakers", ",", "self", ".", "utterances_per_speaker", ",", "partials_n_frames", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker_batch.SpeakerBatch.__init__": [[6, 13], ["numpy.array", "s.random_partial"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.random_partial"], ["    ", "def", "__init__", "(", "self", ",", "speakers", ":", "List", "[", "Speaker", "]", ",", "utterances_per_speaker", ":", "int", ",", "n_frames", ":", "int", ")", ":", "\n", "        ", "self", ".", "speakers", "=", "speakers", "\n", "self", ".", "partials", "=", "{", "s", ":", "s", ".", "random_partial", "(", "utterances_per_speaker", ",", "n_frames", ")", "for", "s", "in", "speakers", "}", "\n", "\n", "# Array of shape (n_speakers * n_utterances, n_frames, mel_n), e.g. for 3 speakers with", "\n", "# 4 utterances each of 160 frames of 40 mel coefficients: (12, 160, 40)", "\n", "self", ".", "data", "=", "np", ".", "array", "(", "[", "frames", "for", "s", "in", "speakers", "for", "_", ",", "frames", ",", "_", "in", "self", ".", "partials", "[", "s", "]", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.__init__": [[12, 17], ["list", "len", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "source", ")", ":", "\n", "        ", "if", "len", "(", "source", ")", "==", "0", ":", "\n", "            ", "raise", "Exception", "(", "\"Can't create RandomCycler from an empty collection\"", ")", "\n", "", "self", ".", "all_items", "=", "list", "(", "source", ")", "\n", "self", ".", "next_items", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.sample": [[18, 34], ["random.sample", "min", "out.extend", "len", "len", "out.extend", "len", "len", "len", "shuffle", "shuffle", "list", "list"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.sample"], ["", "def", "sample", "(", "self", ",", "count", ":", "int", ")", ":", "\n", "        ", "shuffle", "=", "lambda", "l", ":", "random", ".", "sample", "(", "l", ",", "len", "(", "l", ")", ")", "\n", "\n", "out", "=", "[", "]", "\n", "while", "count", ">", "0", ":", "\n", "            ", "if", "count", ">=", "len", "(", "self", ".", "all_items", ")", ":", "\n", "                ", "out", ".", "extend", "(", "shuffle", "(", "list", "(", "self", ".", "all_items", ")", ")", ")", "\n", "count", "-=", "len", "(", "self", ".", "all_items", ")", "\n", "continue", "\n", "", "n", "=", "min", "(", "count", ",", "len", "(", "self", ".", "next_items", ")", ")", "\n", "out", ".", "extend", "(", "self", ".", "next_items", "[", ":", "n", "]", ")", "\n", "count", "-=", "n", "\n", "self", ".", "next_items", "=", "self", ".", "next_items", "[", "n", ":", "]", "\n", "if", "len", "(", "self", ".", "next_items", ")", "==", "0", ":", "\n", "                ", "self", ".", "next_items", "=", "shuffle", "(", "list", "(", "self", ".", "all_items", ")", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.__next__": [[35, 37], ["random_cycler.RandomCycler.sample"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.sample"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sample", "(", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker.Speaker.__init__": [[7, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ":", "Path", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "name", "=", "root", ".", "name", "\n", "self", ".", "utterances", "=", "None", "\n", "self", ".", "utterance_cycler", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker.Speaker._load_utterances": [[13, 19], ["encoder.data_objects.random_cycler.RandomCycler", "speaker.Speaker.root.joinpath().open", "encoder.data_objects.utterance.Utterance", "l.split", "speaker.Speaker.root.joinpath", "sources.items", "speaker.Speaker.root.joinpath"], "methods", ["None"], ["", "def", "_load_utterances", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "root", ".", "joinpath", "(", "\"_sources.txt\"", ")", ".", "open", "(", "\"r\"", ")", "as", "sources_file", ":", "\n", "            ", "sources", "=", "[", "l", ".", "split", "(", "\",\"", ")", "for", "l", "in", "sources_file", "]", "\n", "", "sources", "=", "{", "frames_fname", ":", "wave_fpath", "for", "frames_fname", ",", "wave_fpath", "in", "sources", "}", "\n", "self", ".", "utterances", "=", "[", "Utterance", "(", "self", ".", "root", ".", "joinpath", "(", "f", ")", ",", "w", ")", "for", "f", ",", "w", "in", "sources", ".", "items", "(", ")", "]", "\n", "self", ".", "utterance_cycler", "=", "RandomCycler", "(", "self", ".", "utterances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker.Speaker.random_partial": [[20, 41], ["speaker.Speaker.utterance_cycler.sample", "speaker.Speaker._load_utterances", "u.random_partial"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.random_cycler.RandomCycler.sample", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.speaker.Speaker._load_utterances", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.random_partial"], ["", "def", "random_partial", "(", "self", ",", "count", ",", "n_frames", ")", ":", "\n", "        ", "\"\"\"\n        Samples a batch of <count> unique partial utterances from the disk in a way that all \n        utterances come up at least once every two cycles and in a random order every time.\n        \n        :param count: The number of partial utterances to sample from the set of utterances from \n        that speaker. Utterances are guaranteed not to be repeated if <count> is not larger than \n        the number of utterances available.\n        :param n_frames: The number of frames in the partial utterance.\n        :return: A list of tuples (utterance, frames, range) where utterance is an Utterance, \n        frames are the frames of the partial utterances and range is the range of the partial \n        utterance with regard to the complete utterance.\n        \"\"\"", "\n", "if", "self", ".", "utterances", "is", "None", ":", "\n", "            ", "self", ".", "_load_utterances", "(", ")", "\n", "\n", "", "utterances", "=", "self", ".", "utterance_cycler", ".", "sample", "(", "count", ")", "\n", "\n", "a", "=", "[", "(", "u", ",", ")", "+", "u", ".", "random_partial", "(", "n_frames", ")", "for", "u", "in", "utterances", "]", "\n", "\n", "return", "a", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.__init__": [[5, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "frames_fpath", ",", "wave_fpath", ")", ":", "\n", "        ", "self", ".", "frames_fpath", "=", "frames_fpath", "\n", "self", ".", "wave_fpath", "=", "wave_fpath", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.get_frames": [[9, 11], ["numpy.load"], "methods", ["None"], ["", "def", "get_frames", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "load", "(", "self", ".", "frames_fpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.random_partial": [[12, 27], ["utterance.Utterance.get_frames", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.data_objects.utterance.Utterance.get_frames"], ["", "def", "random_partial", "(", "self", ",", "n_frames", ")", ":", "\n", "        ", "\"\"\"\n        Crops the frames into a partial utterance of n_frames\n        \n        :param n_frames: The number of frames of the partial utterance\n        :return: the partial utterance frames and a tuple indicating the start and end of the \n        partial utterance in the complete utterance.\n        \"\"\"", "\n", "frames", "=", "self", ".", "get_frames", "(", ")", "\n", "if", "frames", ".", "shape", "[", "0", "]", "==", "n_frames", ":", "\n", "            ", "start", "=", "0", "\n", "", "else", ":", "\n", "            ", "start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "frames", ".", "shape", "[", "0", "]", "-", "n_frames", ")", "\n", "", "end", "=", "start", "+", "n_frames", "\n", "return", "frames", "[", "start", ":", "end", "]", ",", "(", "start", ",", "end", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.progbar": [[9, 15], ["range"], "function", ["None"], ["def", "progbar", "(", "i", ",", "n", ",", "size", "=", "16", ")", ":", "\n", "    ", "done", "=", "(", "i", "*", "size", ")", "//", "n", "\n", "bar", "=", "''", "\n", "for", "i", "in", "range", "(", "size", ")", ":", "\n", "        ", "bar", "+=", "'\u2588'", "if", "i", "<=", "done", "else", "'\u2591'", "\n", "", "return", "bar", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.stream": [[17, 19], ["sys.stdout.write"], "function", ["None"], ["", "def", "stream", "(", "message", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "f\"\\r{message}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.simple_table": [[21, 70], ["range", "print", "print", "print", "print", "print", "print", "abs", "len", "str", "str", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "simple_table", "(", "item_tuples", ")", ":", "\n", "\n", "    ", "border_pattern", "=", "'+---------------------------------------'", "\n", "whitespace", "=", "'                                            '", "\n", "\n", "headings", ",", "cells", ",", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "item", "in", "item_tuples", ":", "\n", "\n", "        ", "heading", ",", "cell", "=", "str", "(", "item", "[", "0", "]", ")", ",", "str", "(", "item", "[", "1", "]", ")", "\n", "\n", "pad_head", "=", "True", "if", "len", "(", "heading", ")", "<", "len", "(", "cell", ")", "else", "False", "\n", "\n", "pad", "=", "abs", "(", "len", "(", "heading", ")", "-", "len", "(", "cell", ")", ")", "\n", "pad", "=", "whitespace", "[", ":", "pad", "]", "\n", "\n", "pad_left", "=", "pad", "[", ":", "len", "(", "pad", ")", "//", "2", "]", "\n", "pad_right", "=", "pad", "[", "len", "(", "pad", ")", "//", "2", ":", "]", "\n", "\n", "if", "pad_head", ":", "\n", "            ", "heading", "=", "pad_left", "+", "heading", "+", "pad_right", "\n", "", "else", ":", "\n", "            ", "cell", "=", "pad_left", "+", "cell", "+", "pad_right", "\n", "\n", "", "headings", "+=", "[", "heading", "]", "\n", "cells", "+=", "[", "cell", "]", "\n", "\n", "", "border", ",", "head", ",", "body", "=", "''", ",", "''", ",", "''", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "item_tuples", ")", ")", ":", "\n", "\n", "        ", "temp_head", "=", "f'| {headings[i]} '", "\n", "temp_body", "=", "f'| {cells[i]} '", "\n", "\n", "border", "+=", "border_pattern", "[", ":", "len", "(", "temp_head", ")", "]", "\n", "head", "+=", "temp_head", "\n", "body", "+=", "temp_body", "\n", "\n", "if", "i", "==", "len", "(", "item_tuples", ")", "-", "1", ":", "\n", "            ", "head", "+=", "'|'", "\n", "body", "+=", "'|'", "\n", "border", "+=", "'+'", "\n", "\n", "", "", "print", "(", "border", ")", "\n", "print", "(", "head", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "body", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.time_since": [[72, 82], ["int", "int", "time.time", "int"], "function", ["None"], ["", "def", "time_since", "(", "started", ")", ":", "\n", "    ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "started", "\n", "m", "=", "int", "(", "elapsed", "//", "60", ")", "\n", "s", "=", "int", "(", "elapsed", "%", "60", ")", "\n", "if", "m", ">=", "60", ":", "\n", "        ", "h", "=", "int", "(", "m", "//", "60", ")", "\n", "m", "=", "m", "%", "60", "\n", "return", "f'{h}h {m}m {s}s'", "\n", "", "else", ":", "\n", "        ", "return", "f'{m}m {s}s'", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.save_attention": [[84, 89], ["matplotlib.figure", "matplotlib.imshow", "plt.figure.savefig", "matplotlib.close"], "function", ["None"], ["", "", "def", "save_attention", "(", "attn", ",", "path", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "plt", ".", "imshow", "(", "attn", ".", "T", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "fig", ".", "savefig", "(", "path", ".", "parent", "/", "f'{path.stem}.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.save_spectrogram": [[91, 98], ["numpy.flip", "matplotlib.figure", "matplotlib.imshow", "plt.figure.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "save_spectrogram", "(", "M", ",", "path", ",", "length", "=", "None", ")", ":", "\n", "    ", "M", "=", "np", ".", "flip", "(", "M", ",", "axis", "=", "0", ")", "\n", "if", "length", ":", "M", "=", "M", "[", ":", ",", ":", "length", "]", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "plt", ".", "imshow", "(", "M", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "fig", ".", "savefig", "(", "f'{path}.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.plot": [[100, 112], ["matplotlib.interactive", "matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.xaxis.label.set_color", "fig.add_subplot.yaxis.label.set_color", "fig.add_subplot.xaxis.label.set_fontsize", "fig.add_subplot.yaxis.label.set_fontsize", "fig.add_subplot.tick_params", "fig.add_subplot.tick_params", "matplotlib.plot", "matplotlib.interactive"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.plot"], ["", "def", "plot", "(", "array", ")", ":", "\n", "    ", "mpl", ".", "interactive", "(", "True", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "30", ",", "5", ")", ")", "\n", "ax", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "ax", ".", "xaxis", ".", "label", ".", "set_color", "(", "'grey'", ")", "\n", "ax", ".", "yaxis", ".", "label", ".", "set_color", "(", "'grey'", ")", "\n", "ax", ".", "xaxis", ".", "label", ".", "set_fontsize", "(", "23", ")", "\n", "ax", ".", "yaxis", ".", "label", ".", "set_fontsize", "(", "23", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'x'", ",", "colors", "=", "'grey'", ",", "labelsize", "=", "23", ")", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'y'", ",", "colors", "=", "'grey'", ",", "labelsize", "=", "23", ")", "\n", "plt", ".", "plot", "(", "array", ")", "\n", "mpl", ".", "interactive", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.display.plot_spec": [[114, 121], ["matplotlib.interactive", "numpy.flip", "matplotlib.figure", "matplotlib.imshow", "matplotlib.show", "matplotlib.interactive"], "function", ["None"], ["", "def", "plot_spec", "(", "M", ")", ":", "\n", "    ", "mpl", ".", "interactive", "(", "True", ")", "\n", "M", "=", "np", ".", "flip", "(", "M", ",", "axis", "=", "0", ")", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "18", ",", "4", ")", ")", "\n", "plt", ".", "imshow", "(", "M", ",", "interpolation", "=", "'nearest'", ",", "aspect", "=", "'auto'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "mpl", ".", "interactive", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.__init__": [[166, 181], ["open", "line.split", "line.replace", "f.readlines"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "feats_scp", ",", "default_hdf5_path", "=", "\"feats\"", ")", ":", "\n", "        ", "\"\"\"Initialize HDF5 scp loader.\n\n        Args:\n            feats_scp (str): Kaldi-style feats.scp file with hdf5 format.\n            default_hdf5_path (str): Path in hdf5 file. If the scp contain the info, not used.\n\n        \"\"\"", "\n", "self", ".", "default_hdf5_path", "=", "default_hdf5_path", "\n", "with", "open", "(", "feats_scp", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "self", ".", "data", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "key", ",", "value", "=", "line", ".", "split", "(", ")", "\n", "self", ".", "data", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.get_path": [[182, 185], ["None"], "methods", ["None"], ["", "", "def", "get_path", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"\"\"Get hdf5 file path for a given key.\"\"\"", "\n", "return", "self", ".", "data", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.__getitem__": [[186, 198], ["utils.read_hdf5", "len", "utils.read_hdf5", "p.split", "numpy.concatenate", "p.split", "utils.read_hdf5", "p.split", "p2.split", "f.reshape", "len"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"\"\"Get ndarray for a given key.\"\"\"", "\n", "p", "=", "self", ".", "data", "[", "key", "]", "\n", "if", "\":\"", "in", "p", ":", "\n", "            ", "if", "len", "(", "p", ".", "split", "(", "\",\"", ")", ")", "==", "1", ":", "\n", "                ", "return", "read_hdf5", "(", "*", "p", ".", "split", "(", "\":\"", ")", ")", "\n", "", "else", ":", "\n", "                ", "p1", ",", "p2", "=", "p", ".", "split", "(", "\":\"", ")", "\n", "feats", "=", "[", "read_hdf5", "(", "p1", ",", "p", ")", "for", "p", "in", "p2", ".", "split", "(", "\",\"", ")", "]", "\n", "return", "np", ".", "concatenate", "(", "[", "f", "if", "len", "(", "f", ".", "shape", ")", "!=", "1", "else", "f", ".", "reshape", "(", "-", "1", ",", "1", ")", "for", "f", "in", "feats", "]", ",", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "read_hdf5", "(", "p", ",", "self", ".", "default_hdf5_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.__len__": [[199, 202], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the length of the scp file.\"\"\"", "\n", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.__iter__": [[203, 206], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the iterator of the scp file.\"\"\"", "\n", "return", "iter", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.keys": [[207, 210], ["utils.HDF5ScpLoader.data.keys"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the keys of the scp file.\"\"\"", "\n", "return", "self", ".", "data", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.HDF5ScpLoader.values": [[211, 215], ["utils.HDF5ScpLoader.keys"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys"], ["", "def", "values", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the values of the scp file.\"\"\"", "\n", "for", "key", "in", "self", ".", "keys", "(", ")", ":", "\n", "            ", "yield", "self", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.__init__": [[231, 244], ["open", "line.split", "line.replace", "f.readlines"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "feats_scp", ")", ":", "\n", "        ", "\"\"\"Initialize npy scp loader.\n\n        Args:\n            feats_scp (str): Kaldi-style feats.scp file with npy format.\n\n        \"\"\"", "\n", "with", "open", "(", "feats_scp", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "", "self", ".", "data", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "key", ",", "value", "=", "line", ".", "split", "(", ")", "\n", "self", ".", "data", "[", "key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.get_path": [[245, 248], ["None"], "methods", ["None"], ["", "", "def", "get_path", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"\"\"Get npy file path for a given key.\"\"\"", "\n", "return", "self", ".", "data", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.__getitem__": [[249, 252], ["numpy.load"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "\"\"\"Get ndarray for a given key.\"\"\"", "\n", "return", "np", ".", "load", "(", "self", ".", "data", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.__len__": [[253, 256], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the length of the scp file.\"\"\"", "\n", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.__iter__": [[257, 260], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the iterator of the scp file.\"\"\"", "\n", "return", "iter", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys": [[261, 264], ["utils.NpyScpLoader.data.keys"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the keys of the scp file.\"\"\"", "\n", "return", "self", ".", "data", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.values": [[265, 269], ["utils.NpyScpLoader.keys"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.NpyScpLoader.keys"], ["", "def", "values", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the values of the scp file.\"\"\"", "\n", "for", "key", "in", "self", ".", "keys", "(", ")", ":", "\n", "            ", "yield", "self", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.find_files": [[43, 63], ["os.walk", "fnmatch.filter", "files.append", "file_.replace", "os.path.join"], "function", ["None"], ["def", "find_files", "(", "root_dir", ",", "query", "=", "\"*.wav\"", ",", "include_root_dir", "=", "True", ")", ":", "\n", "    ", "\"\"\"Find files recursively.\n\n    Args:\n        root_dir (str): Root root_dir to find.\n        query (str): Query to find.\n        include_root_dir (bool): If False, root_dir name is not included.\n\n    Returns:\n        list: List of found filenames.\n\n    \"\"\"", "\n", "files", "=", "[", "]", "\n", "for", "root", ",", "dirnames", ",", "filenames", "in", "os", ".", "walk", "(", "root_dir", ",", "followlinks", "=", "True", ")", ":", "\n", "        ", "for", "filename", "in", "fnmatch", ".", "filter", "(", "filenames", ",", "query", ")", ":", "\n", "            ", "files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ")", "\n", "", "", "if", "not", "include_root_dir", ":", "\n", "        ", "files", "=", "[", "file_", ".", "replace", "(", "root_dir", "+", "\"/\"", ",", "\"\"", ")", "for", "file_", "in", "files", "]", "\n", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5": [[65, 90], ["h5py.File", "h5py.File.close", "os.path.exists", "logging.error", "sys.exit", "logging.error", "sys.exit"], "function", ["None"], ["", "def", "read_hdf5", "(", "hdf5_name", ",", "hdf5_path", ")", ":", "\n", "    ", "\"\"\"Read hdf5 dataset.\n\n    Args:\n        hdf5_name (str): Filename of hdf5 file.\n        hdf5_path (str): Dataset name in hdf5 file.\n\n    Return:\n        any: Dataset values.\n\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "hdf5_name", ")", ":", "\n", "        ", "logging", ".", "error", "(", "f\"There is no such a hdf5 file ({hdf5_name}).\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "hdf5_file", "=", "h5py", ".", "File", "(", "hdf5_name", ",", "\"r\"", ")", "\n", "\n", "if", "hdf5_path", "not", "in", "hdf5_file", ":", "\n", "        ", "logging", ".", "error", "(", "f\"There is no such a data in hdf5 file. ({hdf5_path})\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "hdf5_data", "=", "hdf5_file", "[", "hdf5_path", "]", "[", "(", ")", "]", "\n", "hdf5_file", ".", "close", "(", ")", "\n", "\n", "return", "hdf5_data", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.write_hdf5": [[92, 133], ["numpy.array", "os.path.split", "os.path.exists", "h5py.File.create_dataset", "h5py.File.flush", "h5py.File.close", "os.makedirs", "h5py.File", "h5py.File", "os.path.exists", "len", "logging.warning", "h5py.File.__delitem__", "logging.error", "h5py.File.close", "sys.exit"], "function", ["None"], ["", "def", "write_hdf5", "(", "hdf5_name", ",", "hdf5_path", ",", "write_data", ",", "is_overwrite", "=", "True", ")", ":", "\n", "    ", "\"\"\"Write dataset to hdf5.\n\n    Args:\n        hdf5_name (str): Hdf5 dataset filename.\n        hdf5_path (str): Dataset path in hdf5.\n        write_data (ndarray): Data to write.\n        is_overwrite (bool): Whether to overwrite dataset.\n\n    \"\"\"", "\n", "# convert to numpy array", "\n", "write_data", "=", "np", ".", "array", "(", "write_data", ")", "\n", "\n", "# check folder existence", "\n", "folder_name", ",", "_", "=", "os", ".", "path", ".", "split", "(", "hdf5_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "folder_name", ")", "and", "len", "(", "folder_name", ")", "!=", "0", ":", "\n", "        ", "os", ".", "makedirs", "(", "folder_name", ")", "\n", "\n", "# check hdf5 existence", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "hdf5_name", ")", ":", "\n", "# if already exists, open with r+ mode", "\n", "        ", "hdf5_file", "=", "h5py", ".", "File", "(", "hdf5_name", ",", "\"r+\"", ")", "\n", "# check dataset existence", "\n", "if", "hdf5_path", "in", "hdf5_file", ":", "\n", "            ", "if", "is_overwrite", ":", "\n", "                ", "logging", ".", "warning", "(", "\"Dataset in hdf5 file already exists. \"", "\n", "\"recreate dataset in hdf5.\"", ")", "\n", "hdf5_file", ".", "__delitem__", "(", "hdf5_path", ")", "\n", "", "else", ":", "\n", "                ", "logging", ".", "error", "(", "\"Dataset in hdf5 file already exists. \"", "\n", "\"if you want to overwrite, please set is_overwrite = True.\"", ")", "\n", "hdf5_file", ".", "close", "(", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", "", "else", ":", "\n", "# if not exists, open with w mode", "\n", "        ", "hdf5_file", "=", "h5py", ".", "File", "(", "hdf5_name", ",", "\"w\"", ")", "\n", "\n", "# write data to hdf5", "\n", "", "hdf5_file", ".", "create_dataset", "(", "hdf5_path", ",", "data", "=", "write_data", ")", "\n", "hdf5_file", ".", "flush", "(", ")", "\n", "hdf5_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.load_model": [[271, 317], ["getattr", "getattr.", "model_class.load_state_dict", "os.path.dirname", "os.path.join", "yaml.load.get", "PQMF", "open", "yaml.load", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "pqmf_params.update", "torch.load", "yaml.load.get", "yaml.load.get"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update"], ["", "", "", "def", "load_model", "(", "checkpoint", ",", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load trained model.\n\n    Args:\n        checkpoint (str): Checkpoint path.\n        config (dict): Configuration dict.\n\n    Return:\n        torch.nn.Module: Model instance.\n\n    \"\"\"", "\n", "# load config if not provided", "\n", "if", "config", "is", "None", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "checkpoint", ")", "\n", "config", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "\"config.yml\"", ")", "\n", "with", "open", "(", "config", ")", "as", "f", ":", "\n", "            ", "config", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "Loader", ")", "\n", "\n", "# lazy load for circular error", "\n", "", "", "import", "models", "\n", "\n", "# get model and load parameters", "\n", "model_class", "=", "getattr", "(", "\n", "models", ",", "\n", "config", ".", "get", "(", "\"generator_type\"", ",", "\"ParallelWaveGANGenerator\"", ")", "\n", ")", "\n", "model", "=", "model_class", "(", "**", "config", "[", "\"generator_params\"", "]", ")", "\n", "model", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "\"cpu\"", ")", "[", "\"model\"", "]", "[", "\"generator\"", "]", "\n", ")", "\n", "\n", "# add pqmf if needed", "\n", "if", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ">", "1", ":", "\n", "# lazy load for circular error", "\n", "        ", "from", "layers", "import", "PQMF", "\n", "\n", "pqmf_params", "=", "{", "}", "\n", "if", "LooseVersion", "(", "config", ".", "get", "(", "\"version\"", ",", "\"0.1.0\"", ")", ")", "<=", "LooseVersion", "(", "\"0.4.2\"", ")", ":", "\n", "# For compatibility, here we set default values in version <= 0.4.2", "\n", "            ", "pqmf_params", ".", "update", "(", "taps", "=", "62", ",", "cutoff_ratio", "=", "0.15", ",", "beta", "=", "9.0", ")", "\n", "", "model", ".", "pqmf", "=", "PQMF", "(", "\n", "subbands", "=", "config", "[", "\"generator_params\"", "]", "[", "\"out_channels\"", "]", ",", "\n", "**", "config", ".", "get", "(", "\"pqmf_params\"", ",", "pqmf_params", ")", ",", "\n", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.download_pretrained_model": [[319, 349], ["os.makedirs", "utils.find_files", "os.path.expanduser", "os.path.exists", "gdown.download", "tarfile.open", "tar.getmembers", "member.isreg", "os.path.basename", "tar.extract"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.find_files"], ["", "def", "download_pretrained_model", "(", "tag", ",", "download_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Download pretrained model form google drive.\n\n    Args:\n        tag (str): Pretrained model tag.\n        download_dir (str): Directory to save downloaded files.\n\n    Returns:\n        str: Path of downloaded model checkpoint.\n\n    \"\"\"", "\n", "assert", "tag", "in", "PRETRAINED_MODEL_LIST", ",", "f\"{tag} does not exists.\"", "\n", "id_", "=", "PRETRAINED_MODEL_LIST", "[", "tag", "]", "\n", "if", "download_dir", "is", "None", ":", "\n", "        ", "download_dir", "=", "os", ".", "path", ".", "expanduser", "(", "\"~/.cache/parallel_wavegan\"", ")", "\n", "", "output_path", "=", "f\"{download_dir}/{tag}.tar.gz\"", "\n", "os", ".", "makedirs", "(", "f\"{download_dir}\"", ",", "exist_ok", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "# lazy load for compatibility", "\n", "        ", "import", "gdown", "\n", "\n", "gdown", ".", "download", "(", "f\"https://drive.google.com/uc?id={id_}\"", ",", "output_path", ",", "quiet", "=", "False", ")", "\n", "with", "tarfile", ".", "open", "(", "output_path", ",", "'r:*'", ")", "as", "tar", ":", "\n", "            ", "for", "member", "in", "tar", ".", "getmembers", "(", ")", ":", "\n", "                ", "if", "member", ".", "isreg", "(", ")", ":", "\n", "                    ", "member", ".", "name", "=", "os", ".", "path", ".", "basename", "(", "member", ".", "name", ")", "\n", "tar", ".", "extract", "(", "member", ",", "f\"{download_dir}/{tag}\"", ")", "\n", "", "", "", "", "checkpoint_path", "=", "find_files", "(", "f\"{download_dir}/{tag}\"", ",", "\"checkpoint*.pkl\"", ")", "\n", "\n", "return", "checkpoint_path", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.simple_table": [[351, 400], ["range", "print", "print", "print", "print", "print", "print", "abs", "len", "str", "str", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "simple_table", "(", "item_tuples", ")", ":", "\n", "\n", "    ", "border_pattern", "=", "'+---------------------------------------'", "\n", "whitespace", "=", "'                                            '", "\n", "\n", "headings", ",", "cells", ",", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "item", "in", "item_tuples", ":", "\n", "\n", "        ", "heading", ",", "cell", "=", "str", "(", "item", "[", "0", "]", ")", ",", "str", "(", "item", "[", "1", "]", ")", "\n", "\n", "pad_head", "=", "True", "if", "len", "(", "heading", ")", "<", "len", "(", "cell", ")", "else", "False", "\n", "\n", "pad", "=", "abs", "(", "len", "(", "heading", ")", "-", "len", "(", "cell", ")", ")", "\n", "pad", "=", "whitespace", "[", ":", "pad", "]", "\n", "\n", "pad_left", "=", "pad", "[", ":", "len", "(", "pad", ")", "//", "2", "]", "\n", "pad_right", "=", "pad", "[", "len", "(", "pad", ")", "//", "2", ":", "]", "\n", "\n", "if", "pad_head", ":", "\n", "            ", "heading", "=", "pad_left", "+", "heading", "+", "pad_right", "\n", "", "else", ":", "\n", "            ", "cell", "=", "pad_left", "+", "cell", "+", "pad_right", "\n", "\n", "", "headings", "+=", "[", "heading", "]", "\n", "cells", "+=", "[", "cell", "]", "\n", "\n", "", "border", ",", "head", ",", "body", "=", "''", ",", "''", ",", "''", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "item_tuples", ")", ")", ":", "\n", "\n", "        ", "temp_head", "=", "f'| {headings[i]} '", "\n", "temp_body", "=", "f'| {cells[i]} '", "\n", "\n", "border", "+=", "border_pattern", "[", ":", "len", "(", "temp_head", ")", "]", "\n", "head", "+=", "temp_head", "\n", "body", "+=", "temp_body", "\n", "\n", "if", "i", "==", "len", "(", "item_tuples", ")", "-", "1", ":", "\n", "            ", "head", "+=", "'|'", "\n", "body", "+=", "'|'", "\n", "border", "+=", "'+'", "\n", "\n", "", "", "print", "(", "border", ")", "\n", "print", "(", "head", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "body", ")", "\n", "print", "(", "border", ")", "\n", "print", "(", "' '", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args": [[17, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\"Parse arguments.\"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "description", "=", "\"PyTorch distributed training launch \"", "\n", "\"helper utilty that will spawn up \"", "\n", "\"multiple distributed processes\"", ")", "\n", "\n", "# Optional arguments for the launch helper", "\n", "parser", ".", "add_argument", "(", "\"--nnodes\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"The number of nodes to use for distributed \"", "\n", "\"training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--node_rank\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"The rank of the node for multi-node distributed \"", "\n", "\"training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--nproc_per_node\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"The number of processes to launch on each node, \"", "\n", "\"for GPU training, this is recommended to be set \"", "\n", "\"to the number of GPUs in your system so that \"", "\n", "\"each process can be bound to a single GPU.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--master_addr\"", ",", "default", "=", "\"127.0.0.1\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Master node (rank 0)'s address, should be either \"", "\n", "\"the IP address or the hostname of node 0, for \"", "\n", "\"single node multi-proc training, the \"", "\n", "\"--master_addr can simply be 127.0.0.1\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--master_port\"", ",", "default", "=", "29500", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Master node (rank 0)'s free port that needs to \"", "\n", "\"be used for communciation during distributed \"", "\n", "\"training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_env\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use environment variable to pass \"", "\n", "\"'local rank'. For legacy reasons, the default value is False. \"", "\n", "\"If set to True, the script will not pass \"", "\n", "\"--local_rank as argument, and will instead set LOCAL_RANK.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-m\"", ",", "\"--module\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Changes each process to interpret the launch script \"", "\n", "\"as a python module, executing with the same behavior as\"", "\n", "\"'python -m'.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-c\"", ",", "\"--command\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Changes each process to interpret the launch script \"", "\n", "\"as a command.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--start\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Changes each process to interpret the launch script \"", "\n", "\"as a command.\"", ")", "\n", "# positional", "\n", "parser", ".", "add_argument", "(", "\"training_script\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The full path to the single GPU training \"", "\n", "\"program/script/command to be launched in parallel, \"", "\n", "\"followed by all the arguments for the \"", "\n", "\"training script\"", ")", "\n", "\n", "# rest from the training program", "\n", "parser", ".", "add_argument", "(", "'training_script_args'", ",", "nargs", "=", "REMAINDER", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.main": [[71, 123], ["launch.parse_args", "os.environ.copy", "str", "str", "range", "str", "print", "str", "str", "cmd.extend", "subprocess.Popen", "processes.append", "subprocess.Popen.wait", "cmd.append", "cmd.append", "subprocess.CalledProcessError", "cmd.append"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.distributed.launch.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\"Launch distributed processes.\"\"\"", "\n", "args", "=", "parse_args", "(", ")", "\n", "\n", "# world size in terms of number of processes", "\n", "dist_world_size", "=", "args", ".", "nproc_per_node", "*", "args", ".", "nnodes", "\n", "\n", "# set PyTorch distributed related environmental variables", "\n", "current_env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "current_env", "[", "\"MASTER_ADDR\"", "]", "=", "args", ".", "master_addr", "\n", "current_env", "[", "\"MASTER_PORT\"", "]", "=", "str", "(", "args", ".", "master_port", ")", "\n", "current_env", "[", "\"WORLD_SIZE\"", "]", "=", "str", "(", "dist_world_size", ")", "\n", "\n", "processes", "=", "[", "]", "\n", "\n", "if", "'OMP_NUM_THREADS'", "not", "in", "os", ".", "environ", "and", "args", ".", "nproc_per_node", ">", "1", ":", "\n", "        ", "current_env", "[", "\"OMP_NUM_THREADS\"", "]", "=", "str", "(", "1", ")", "\n", "print", "(", "\"*****************************************\\n\"", "\n", "\"Setting OMP_NUM_THREADS environment variable for each process \"", "\n", "\"to be {} in default, to avoid your system being overloaded, \"", "\n", "\"please further tune the variable for optimal performance in \"", "\n", "\"your application as needed. \\n\"", "\n", "\"*****************************************\"", ".", "format", "(", "current_env", "[", "\"OMP_NUM_THREADS\"", "]", ")", ")", "\n", "\n", "", "for", "local_rank", "in", "range", "(", "args", ".", "start", ",", "args", ".", "nproc_per_node", ")", ":", "\n", "# each process's rank", "\n", "        ", "dist_rank", "=", "args", ".", "nproc_per_node", "*", "args", ".", "node_rank", "+", "local_rank", "\n", "current_env", "[", "\"RANK\"", "]", "=", "str", "(", "dist_rank", ")", "\n", "current_env", "[", "\"LOCAL_RANK\"", "]", "=", "str", "(", "local_rank", ")", "\n", "\n", "# spawn the processes", "\n", "if", "args", ".", "command", ":", "\n", "            ", "cmd", "=", "[", "args", ".", "training_script", "]", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "[", "sys", ".", "executable", ",", "\"-u\"", "]", "\n", "if", "args", ".", "module", ":", "\n", "                ", "cmd", ".", "append", "(", "\"-m\"", ")", "\n", "", "cmd", ".", "append", "(", "args", ".", "training_script", ")", "\n", "\n", "", "if", "not", "args", ".", "use_env", ":", "\n", "            ", "cmd", ".", "append", "(", "\"--local_rank={}\"", ".", "format", "(", "local_rank", ")", ")", "\n", "\n", "", "cmd", ".", "extend", "(", "args", ".", "training_script_args", ")", "\n", "\n", "process", "=", "subprocess", ".", "Popen", "(", "cmd", ",", "env", "=", "current_env", ")", "\n", "processes", ".", "append", "(", "process", ")", "\n", "\n", "", "for", "process", "in", "processes", ":", "\n", "        ", "process", ".", "wait", "(", ")", "\n", "if", "process", ".", "returncode", "!=", "0", ":", "\n", "            ", "raise", "subprocess", ".", "CalledProcessError", "(", "\n", "returncode", "=", "process", ".", "returncode", ",", "cmd", "=", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.collater.Feats_Collater.__init__": [[20, 54], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "batch_max_steps", "=", "20480", ",", "\n", "out_dim", "=", "1", ",", "\n", "hop_size", "=", "256", ",", "\n", "aux_context_window", "=", "2", ",", "\n", "use_noise_input", "=", "False", ",", "\n", "use_f0", "=", "False", ",", "\n", "use_chroma", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize customized collater for PyTorch DataLoader.\n\n        Args:\n            batch_max_steps (int): The maximum length of input signal in batch.\n            hop_size (int): Hop size of auxiliary features.\n            aux_context_window (int): Context window size for auxiliary feature conv.\n            use_noise_input (bool): Whether to use noise input.\n\n        \"\"\"", "\n", "if", "batch_max_steps", "%", "hop_size", "!=", "0", ":", "\n", "            ", "batch_max_steps", "+=", "-", "(", "batch_max_steps", "%", "hop_size", ")", "\n", "", "assert", "batch_max_steps", "%", "hop_size", "==", "0", "\n", "self", ".", "batch_max_steps", "=", "batch_max_steps", "\n", "self", ".", "out_dim", "=", "out_dim", "\n", "self", ".", "batch_max_frames", "=", "batch_max_steps", "//", "hop_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "aux_context_window", "=", "aux_context_window", "\n", "self", ".", "use_noise_input", "=", "use_noise_input", "\n", "self", ".", "use_f0", "=", "use_f0", "\n", "self", ".", "use_chroma", "=", "use_chroma", "\n", "\n", "# set useful values in random cutting  \u968f\u673a\u622a\u53d6\u957f\u5ea6", "\n", "self", ".", "start_offset", "=", "aux_context_window", "# \u5f00\u59cb\u504f\u79fb\u4f4d\u7f6e = \u7a97\u5927\u5c0f", "\n", "self", ".", "end_offset", "=", "-", "(", "self", ".", "batch_max_frames", "+", "aux_context_window", ")", "# \u7ed3\u675f\u504f\u79fb\u4f4d\u7f6e = -(\u6700\u5927\u5e27\u957f + \u7a97\u5927\u5c0f)", "\n", "self", ".", "mel_threshold", "=", "self", ".", "batch_max_frames", "+", "2", "*", "aux_context_window", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.collater.Feats_Collater.__call__": [[55, 105], ["numpy.array", "torch.tensor().unsqueeze", "torch.tensor().transpose", "len", "torch.tensor", "torch.tensor().transpose", "torch.randn", "numpy.random.randint", "zip", "zip", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze.size", "zip", "zip", "torch.tensor", "torch.tensor().unsqueeze.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "# check length", "\n", "# batch = [self._adjust_length(*b) for b in batch if len(b[1]) > self.mel_threshold]", "\n", "        ", "xs", ",", "cs", "=", "[", "b", "[", "'audio'", "]", "for", "b", "in", "batch", "]", ",", "[", "b", "[", "'feat'", "]", "for", "b", "in", "batch", "]", "# batch \u5305\u542baudio & feat(mel)", "\n", "\n", "# make batch with random cut  \u968f\u673a\u88c1\u526a\u7a97", "\n", "c_lengths", "=", "[", "len", "(", "c", ")", "for", "c", "in", "cs", "]", "\n", "start_frames", "=", "np", ".", "array", "(", "[", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "start_offset", ",", "cl", "+", "self", ".", "end_offset", ")", "for", "cl", "in", "c_lengths", "]", ")", "\n", "x_starts", "=", "start_frames", "*", "self", ".", "hop_size", "# audio \u8d77\u59cb", "\n", "x_ends", "=", "x_starts", "+", "self", ".", "batch_max_steps", "# audio \u7ed3\u675f", "\n", "c_starts", "=", "start_frames", "-", "self", ".", "aux_context_window", "# mel \u8d77\u59cb", "\n", "c_ends", "=", "start_frames", "+", "self", ".", "batch_max_frames", "+", "self", ".", "aux_context_window", "# mel \u7ed3\u675f", "\n", "y_batch", "=", "[", "x", "[", "start", ":", "end", "]", "for", "x", ",", "start", ",", "end", "in", "zip", "(", "xs", ",", "x_starts", ",", "x_ends", ")", "]", "# \u5f97\u5230audio", "\n", "c_batch", "=", "[", "c", "[", "start", ":", "end", "]", "for", "c", ",", "start", ",", "end", "in", "zip", "(", "cs", ",", "c_starts", ",", "c_ends", ")", "]", "# \u5f97\u5230mel", "\n", "\n", "# convert each batch to tensor, asuume that each item in batch has the same length\u2014\u2014\u2014\u2014\u2014\u5c06numpy\u8f6c\u4e3atensor", "\n", "y_batch", "=", "torch", ".", "tensor", "(", "y_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "# (B, 1, T)", "\n", "c_batch", "=", "torch", ".", "tensor", "(", "c_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "transpose", "(", "2", ",", "1", ")", "# (B, C, T')", "\n", "\n", "batchs", "=", "{", "'audios'", ":", "y_batch", ",", "'feats'", ":", "c_batch", "}", "###################    \u5f97\u5230 batch[\"audio\"] \u4e0e batch[\"feats\"]   ###################", "\n", "\n", "if", "self", ".", "use_f0", ":", "\n", "# f0s = [b['f0'] for b in batch if 'f0' in b]", "\n", "# f0_batch = [f0[start: end] for f0, start, end in zip(f0s, c_starts, c_ends)]", "\n", "# f0_batch = torch.tensor(f0_batch, dtype=torch.long)", "\n", "# batchs['f0s'] = f0_batch", "\n", "\n", "            ", "f0_origins", "=", "[", "b", "[", "'f0_origin'", "]", "for", "b", "in", "batch", "if", "\"f0_origin\"", "in", "b", "]", "\n", "f0_origins_batch", "=", "[", "f0", "[", "start", "+", "self", ".", "aux_context_window", ":", "end", "-", "self", ".", "aux_context_window", "]", "for", "f0", ",", "start", ",", "end", "in", "zip", "(", "f0_origins", ",", "c_starts", ",", "c_ends", ")", "]", "\n", "f0_origins_batch", "=", "torch", ".", "tensor", "(", "f0_origins_batch", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "batchs", "[", "'f0_origins'", "]", "=", "f0_origins_batch", "\n", "\n", "# vus = [b['uv']  for b in batch if \"uv\" in b]", "\n", "# vus_batch = [vu[start: end] for vu, start, end in zip(vus, c_starts, c_ends)]", "\n", "# vus_batch = torch.tensor(vus_batch, dtype=torch.long)", "\n", "# batchs['uvs'] = vus_batch", "\n", "\n", "", "if", "self", ".", "use_chroma", ":", "\n", "            ", "chromas", "=", "[", "b", "[", "'chroma'", "]", "for", "b", "in", "batch", "if", "'chroma'", "in", "b", "]", "\n", "chroma_batch", "=", "[", "chromas", "[", "start", ":", "end", "]", "for", "chroma", ",", "start", ",", "end", "in", "zip", "(", "chromas", ",", "c_starts", ",", "c_ends", ")", "]", "\n", "chroma_batch", "=", "torch", ".", "tensor", "(", "chroma_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "transpose", "(", "2", ",", "1", ")", "# (B, C, T')", "\n", "batchs", "[", "'chromas'", "]", "=", "chroma_batch", "\n", "# make input noise signal batch tensor", "\n", "", "if", "self", ".", "use_noise_input", ":", "\n", "# z_batch = torch.randn(y_batch.size())  # (B, 1, T)", "\n", "            ", "z_batch", "=", "torch", ".", "randn", "(", "y_batch", ".", "size", "(", "0", ")", ",", "self", ".", "out_dim", ",", "y_batch", ".", "size", "(", "2", ")", "//", "self", ".", "out_dim", ")", "# (B, 1, T)", "\n", "batchs", "[", "'noise'", "]", "=", "z_batch", "\n", "\n", "", "return", "batchs", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.collater.Embeds_Collater.__init__": [[110, 144], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "batch_max_steps", "=", "20480", ",", "\n", "out_dim", "=", "1", ",", "\n", "hop_size", "=", "256", ",", "\n", "aux_context_window", "=", "2", ",", "\n", "use_noise_input", "=", "False", ",", "\n", "use_f0", "=", "False", ",", "\n", "use_chroma", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize customized collater for PyTorch DataLoader.\n\n        Args:\n            batch_max_steps (int): The maximum length of input signal in batch.\n            hop_size (int): Hop size of auxiliary features.\n            aux_context_window (int): Context window size for auxiliary feature conv.\n            use_noise_input (bool): Whether to use noise input.\n\n        \"\"\"", "\n", "if", "batch_max_steps", "%", "hop_size", "!=", "0", ":", "\n", "            ", "batch_max_steps", "+=", "-", "(", "batch_max_steps", "%", "hop_size", ")", "\n", "", "assert", "batch_max_steps", "%", "hop_size", "==", "0", "\n", "self", ".", "batch_max_steps", "=", "batch_max_steps", "\n", "self", ".", "out_dim", "=", "out_dim", "\n", "self", ".", "batch_max_frames", "=", "batch_max_steps", "//", "hop_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "aux_context_window", "=", "aux_context_window", "\n", "self", ".", "use_noise_input", "=", "use_noise_input", "\n", "self", ".", "use_f0", "=", "use_f0", "\n", "self", ".", "use_chroma", "=", "use_chroma", "\n", "\n", "# set useful values in random cutting  \u968f\u673a\u622a\u53d6\u957f\u5ea6", "\n", "self", ".", "start_offset", "=", "aux_context_window", "# \u5f00\u59cb\u504f\u79fb\u4f4d\u7f6e = \u7a97\u5927\u5c0f", "\n", "self", ".", "end_offset", "=", "-", "(", "self", ".", "batch_max_frames", "+", "aux_context_window", ")", "# \u7ed3\u675f\u504f\u79fb\u4f4d\u7f6e = -(\u6700\u5927\u5e27\u957f + \u7a97\u5927\u5c0f)", "\n", "self", ".", "mel_threshold", "=", "self", ".", "batch_max_frames", "+", "2", "*", "aux_context_window", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.collater.Embeds_Collater.__call__": [[145, 197], ["numpy.array", "torch.tensor().unsqueeze", "torch.tensor().transpose", "torch.tensor().unsqueeze", "len", "torch.tensor", "torch.tensor().transpose", "torch.randn", "numpy.random.randint", "zip", "zip", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().unsqueeze.size", "zip", "zip", "torch.tensor", "torch.tensor().unsqueeze.size"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "batch", ")", ":", "\n", "# check length", "\n", "# batch = [self._adjust_length(*b) for b in batch if len(b[1]) > self.mel_threshold]", "\n", "        ", "xs", ",", "cs", "=", "[", "b", "[", "'audio'", "]", "for", "b", "in", "batch", "]", ",", "[", "b", "[", "'feat'", "]", "for", "b", "in", "batch", "]", "# batch \u5305\u542baudio & feat(mel)", "\n", "embed", "=", "[", "b", "[", "'embed'", "]", "for", "b", "in", "batch", "]", "\n", "\n", "# make batch with random cut  \u968f\u673a\u88c1\u526a\u7a97", "\n", "c_lengths", "=", "[", "len", "(", "c", ")", "for", "c", "in", "cs", "]", "\n", "start_frames", "=", "np", ".", "array", "(", "[", "np", ".", "random", ".", "randint", "(", "\n", "self", ".", "start_offset", ",", "cl", "+", "self", ".", "end_offset", ")", "for", "cl", "in", "c_lengths", "]", ")", "\n", "x_starts", "=", "start_frames", "*", "self", ".", "hop_size", "# audio \u8d77\u59cb", "\n", "x_ends", "=", "x_starts", "+", "self", ".", "batch_max_steps", "# audio \u7ed3\u675f", "\n", "c_starts", "=", "start_frames", "-", "self", ".", "aux_context_window", "# mel \u8d77\u59cb", "\n", "c_ends", "=", "start_frames", "+", "self", ".", "batch_max_frames", "+", "self", ".", "aux_context_window", "# mel \u7ed3\u675f", "\n", "y_batch", "=", "[", "x", "[", "start", ":", "end", "]", "for", "x", ",", "start", ",", "end", "in", "zip", "(", "xs", ",", "x_starts", ",", "x_ends", ")", "]", "# \u5f97\u5230audio", "\n", "c_batch", "=", "[", "c", "[", "start", ":", "end", "]", "for", "c", ",", "start", ",", "end", "in", "zip", "(", "cs", ",", "c_starts", ",", "c_ends", ")", "]", "# \u5f97\u5230mel", "\n", "\n", "# convert each batch to tensor, asuume that each item in batch has the same length\u2014\u2014\u2014\u2014\u2014\u5c06numpy\u8f6c\u4e3atensor", "\n", "y_batch", "=", "torch", ".", "tensor", "(", "y_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "# (B, 1, T)", "\n", "c_batch", "=", "torch", ".", "tensor", "(", "c_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "transpose", "(", "2", ",", "1", ")", "# (B, C, T')", "\n", "embed_batch", "=", "torch", ".", "tensor", "(", "embed", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "-", "1", ")", "# (B, 128) -> (B, 128, 1)", "\n", "\n", "batchs", "=", "{", "'audios'", ":", "y_batch", ",", "'feats'", ":", "c_batch", ",", "'embed'", ":", "embed_batch", "}", "###################    \u5f97\u5230 batch[\"audio\"] \u4e0e batch[\"feats\"]   ###################", "\n", "\n", "if", "self", ".", "use_f0", ":", "\n", "# f0s = [b['f0'] for b in batch if 'f0' in b]", "\n", "# f0_batch = [f0[start: end] for f0, start, end in zip(f0s, c_starts, c_ends)]", "\n", "# f0_batch = torch.tensor(f0_batch, dtype=torch.long)", "\n", "# batchs['f0s'] = f0_batch", "\n", "\n", "            ", "f0_origins", "=", "[", "b", "[", "'f0_origin'", "]", "for", "b", "in", "batch", "if", "\"f0_origin\"", "in", "b", "]", "\n", "f0_origins_batch", "=", "[", "f0", "[", "start", "+", "self", ".", "aux_context_window", ":", "end", "-", "self", ".", "aux_context_window", "]", "for", "f0", ",", "start", ",", "end", "in", "zip", "(", "f0_origins", ",", "c_starts", ",", "c_ends", ")", "]", "\n", "f0_origins_batch", "=", "torch", ".", "tensor", "(", "f0_origins_batch", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "batchs", "[", "'f0_origins'", "]", "=", "f0_origins_batch", "\n", "\n", "# vus = [b['uv']  for b in batch if \"uv\" in b]", "\n", "# vus_batch = [vu[start: end] for vu, start, end in zip(vus, c_starts, c_ends)]", "\n", "# vus_batch = torch.tensor(vus_batch, dtype=torch.long)", "\n", "# batchs['uvs'] = vus_batch", "\n", "\n", "", "if", "self", ".", "use_chroma", ":", "\n", "            ", "chromas", "=", "[", "b", "[", "'chroma'", "]", "for", "b", "in", "batch", "if", "'chroma'", "in", "b", "]", "\n", "chroma_batch", "=", "[", "chromas", "[", "start", ":", "end", "]", "for", "chroma", ",", "start", ",", "end", "in", "zip", "(", "chromas", ",", "c_starts", ",", "c_ends", ")", "]", "\n", "chroma_batch", "=", "torch", ".", "tensor", "(", "chroma_batch", ",", "dtype", "=", "torch", ".", "float", ")", ".", "transpose", "(", "2", ",", "1", ")", "# (B, C, T')", "\n", "batchs", "[", "'chromas'", "]", "=", "chroma_batch", "\n", "# make input noise signal batch tensor", "\n", "", "if", "self", ".", "use_noise_input", ":", "\n", "# z_batch = torch.randn(y_batch.size())  # (B, 1, T)", "\n", "            ", "z_batch", "=", "torch", ".", "randn", "(", "y_batch", ".", "size", "(", "0", ")", ",", "1", ",", "y_batch", ".", "size", "(", "2", ")", "//", "self", ".", "out_dim", ")", "# (B, 1, T)", "\n", "batchs", "[", "'noise'", "]", "=", "z_batch", "\n", "\n", "", "return", "batchs", "", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioMelEmbedDataset.__init__": [[25, 110], ["sorted", "sorted", "utils.read_hdf5", "utils.read_hdf5", "utils.read_hdf5", "len", "multiprocessing.Manager", "audio_mel_dataset.AudioMelEmbedDataset.manager.list", "utils.find_files", "open", "utils.read_hdf5", "len", "len", "logging.warning", "len", "len", "logging.warning", "os.path.splitext", "utils.read_hdf5", "utils.read_hdf5", "sorted.append", "range", "range", "os.path.basename", "range", "audio_load_fn", "len", "feat_load_fn", "len", "len", "line.strip().split", "len", "len", "len", "len", "line.strip"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.find_files", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.read_hdf5"], ["def", "__init__", "(", "self", ",", "\n", "root_file", ",", "\n", "feat_type", "=", "'librosa'", ",", "\n", "audio_length_threshold", "=", "None", ",", "\n", "frames_threshold", "=", "None", ",", "\n", "use_f0", "=", "False", ",", "\n", "use_chroma", "=", "False", ",", "\n", "use_utt_id", "=", "False", ",", "\n", "allow_cache", "=", "False", ",", "\n", "eval", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize dataset.\n\n        Args:\n            root_dir (str): Root directory including dumped files.\n            audio_query (str): Query to find audio files in root_dir.\n            mel_query (str): Query to find feature files in root_dir.\n            audio_load_fn (func): Function to load audio file.\n            mel_load_fn (func): Function to load feature file.\n            audio_length_threshold (int): Threshold to remove short audio files.\n            mel_length_threshold (int): Threshold to remove short feature files.\n            return_utt_id (bool): Whether to return the utterance id with arrays.\n            allow_cache (bool): Whether to allow cache of the loaded files.\n\n        \"\"\"", "\n", "# find all of audio and mel files", "\n", "if", "eval", ":", "\n", "            ", "files", "=", "sorted", "(", "find_files", "(", "root_file", ",", "\"*.h5\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "files", "=", "[", "]", "\n", "with", "open", "(", "root_file", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "files", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "[", "1", "]", ")", "\n", "", "", "files", "=", "sorted", "(", "files", ")", "\n", "\n", "", "audio_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"wav\"", ")", "# \u8bfb\u53d6\u97f3\u9891\u6587\u4ef6\u6620\u5c04\u51fd\u6570: h5[\"wav\"]", "\n", "feat_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"mel\"", ")", "# \u8bfb\u53d6\u6885\u5c14\u6587\u4ef6\u6620\u5c04\u51fd\u6570: h5[\"mel\"]", "\n", "embed_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"embed\"", ")", "# \u8bfb\u53d6embed\u6587\u4ef6\u6620\u5c04\u51fd\u6570: h5[\"embed\"]", "\n", "\n", "if", "feat_type", "==", "\"world\"", ":", "# \u8bfb\u53d6world\u63d0\u53d6\u7279\u5f81", "\n", "            ", "feat_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"feats\"", ")", "# \u4f7f\u7528world\u63d0\u53d6\u7279\u5f81 h5[\"feats\"]", "\n", "\n", "# filter by threshold", "\n", "", "if", "audio_length_threshold", "is", "not", "None", ":", "# \u8bbe\u7f6e\u97f3\u9891\u6700\u957f\u957f\u5ea6", "\n", "            ", "audio_lengths", "=", "[", "audio_load_fn", "(", "f", ")", ".", "shape", "[", "0", "]", "for", "f", "in", "files", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", "in", "range", "(", "len", "(", "files", ")", ")", "if", "audio_lengths", "[", "idx", "]", ">", "audio_length_threshold", "]", "# \u8fc7\u6ee4\u5f97\u5230\u97f3\u9891\u957f\u5ea6\u8d85\u8fc7\u9608\u503c", "\n", "if", "len", "(", "files", ")", "!=", "len", "(", "idxs", ")", ":", "\n", "                ", "logging", ".", "warning", "(", "f\"Some files are filtered by audio length threshold \"", "\n", "f\"({len(files)} -> {len(idxs)}).\"", ")", "\n", "", "files", "=", "[", "files", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "", "if", "frames_threshold", "is", "not", "None", ":", "\n", "            ", "frames", "=", "[", "feat_load_fn", "(", "f", ")", ".", "shape", "[", "0", "]", "for", "f", "in", "files", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", "in", "range", "(", "len", "(", "files", ")", ")", "if", "frames", "[", "idx", "]", ">", "frames_threshold", "]", "# \u8fc7\u6ee4\u5f97\u5230\u6885\u5c14\u957f\u5ea6\u8d85\u8fc7\u9608\u503c", "\n", "if", "len", "(", "files", ")", "!=", "len", "(", "idxs", ")", ":", "\n", "                ", "logging", ".", "warning", "(", "f\"Some files are filtered by mel length threshold \"", "\n", "f\"({len(files)} -> {len(idxs)}).\"", ")", "\n", "", "files", "=", "[", "files", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "\n", "# assert the number of files", "\n", "", "assert", "len", "(", "files", ")", "!=", "0", ",", "f\"Not found any audio files in ${root_file}.\"", "\n", "\n", "self", ".", "files", "=", "files", "\n", "self", ".", "audio_load_fn", "=", "audio_load_fn", "\n", "self", ".", "feat_load_fn", "=", "feat_load_fn", "\n", "self", ".", "embed_load_fn", "=", "embed_load_fn", "\n", "\n", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "files", "]", "\n", "self", ".", "use_f0", "=", "use_f0", "\n", "self", ".", "use_chroma", "=", "use_chroma", "\n", "self", ".", "use_utt_id", "=", "use_utt_id", "\n", "self", ".", "allow_cache", "=", "allow_cache", "\n", "\n", "if", "use_f0", ":", "\n", "            ", "self", ".", "f0_origin_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"f0_origin\"", ")", "\n", "# self.uv_load_fn = lambda x: read_hdf5(x, \"uv\")", "\n", "# self.f0_load_fn = lambda x: read_hdf5(x, \"f0\")", "\n", "\n", "", "if", "use_chroma", ":", "\n", "            ", "self", ".", "chroma_load_fn", "=", "lambda", "x", ":", "read_hdf5", "(", "x", ",", "\"chroma\"", ")", "\n", "\n", "", "if", "allow_cache", ":", "\n", "# NOTE(kan-bayashi): Manager is need to share memory in dataloader with num_workers > 0", "\n", "            ", "self", ".", "manager", "=", "Manager", "(", ")", "\n", "self", ".", "caches", "=", "self", ".", "manager", ".", "list", "(", ")", "\n", "self", ".", "caches", "+=", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "files", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioMelEmbedDataset.__getitem__": [[111, 144], ["audio_mel_dataset.AudioMelEmbedDataset.audio_load_fn", "audio_mel_dataset.AudioMelEmbedDataset.feat_load_fn", "audio_mel_dataset.AudioMelEmbedDataset.embed_load_fn", "audio_mel_dataset.AudioMelEmbedDataset.chroma_load_fn", "audio_mel_dataset.AudioMelEmbedDataset.f0_origin_load_fn", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get specified idx items.\n\n        Args:\n            idx (int): Index of the item.\n\n        Returns:\n            str: Utterance id (only in return_utt_id = True).\n            ndarray: Audio signal (T,).\n            ndarray: Feature (T', C).\n            ndarray: embed (256, ).\n        \"\"\"", "\n", "if", "self", ".", "allow_cache", "and", "len", "(", "self", ".", "caches", "[", "idx", "]", ")", "!=", "0", ":", "\n", "            ", "return", "self", ".", "caches", "[", "idx", "]", "\n", "\n", "", "audio", "=", "self", ".", "audio_load_fn", "(", "self", ".", "files", "[", "idx", "]", ")", "\n", "feat", "=", "self", ".", "feat_load_fn", "(", "self", ".", "files", "[", "idx", "]", ")", "\n", "embed", "=", "self", ".", "embed_load_fn", "(", "self", ".", "files", "[", "idx", "]", ")", "\n", "items", "=", "{", "'audio'", ":", "audio", ",", "'feat'", ":", "feat", ",", "'embed'", ":", "embed", "}", "\n", "\n", "if", "self", ".", "use_utt_id", ":", "\n", "            ", "items", "[", "'utt_id'", "]", "=", "self", ".", "utt_ids", "[", "idx", "]", "\n", "", "if", "self", ".", "use_chroma", ":", "\n", "            ", "items", "[", "'chroma'", "]", "=", "self", ".", "chroma_load_fn", "(", "self", ".", "files", "[", "idx", "]", ")", "\n", "", "if", "self", ".", "use_f0", ":", "\n", "# items['f0'] = self.f0_load_fn(self.files[idx])", "\n", "            ", "items", "[", "'f0_origin'", "]", "=", "self", ".", "f0_origin_load_fn", "(", "self", ".", "files", "[", "idx", "]", ")", "\n", "# items['uv'] = self.uv_load_fn(self.files[idx])", "\n", "\n", "", "if", "self", ".", "allow_cache", ":", "\n", "            ", "self", ".", "caches", "[", "idx", "]", "=", "items", "\n", "\n", "", "return", "items", "# \u8fd4\u56de\u97f3\u9891\u4e0e\u6885\u5c14\u9891\u8c31\uff0c\u4ee5\u53ca\u5176\u4ed6\u53ef\u9009\u53c2\u6570(F0)", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioMelEmbedDataset.__len__": [[145, 153], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return dataset length.\n\n        Returns:\n            int: The length of dataset.\n\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioDataset.__init__": [[157, 204], ["sorted", "utils.find_files", "len", "multiprocessing.Manager", "audio_mel_dataset.AudioDataset.manager.list", "len", "len", "logging.waning", "os.path.basename().replace", "range", "os.path.splitext", "range", "audio_load_fn", "len", "os.path.basename", "os.path.basename", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.find_files"], ["def", "__init__", "(", "self", ",", "\n", "root_dir", ",", "\n", "audio_query", "=", "\"*-wave.npy\"", ",", "\n", "audio_length_threshold", "=", "None", ",", "\n", "audio_load_fn", "=", "np", ".", "load", ",", "\n", "return_utt_id", "=", "False", ",", "\n", "allow_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize dataset.\n\n        Args:\n            root_dir (str): Root directory including dumped files.\n            audio_query (str): Query to find audio files in root_dir.\n            audio_load_fn (func): Function to load audio file.\n            audio_length_threshold (int): Threshold to remove short audio files.\n            return_utt_id (bool): Whether to return the utterance id with arrays.\n            allow_cache (bool): Whether to allow cache of the loaded files.\n\n        \"\"\"", "\n", "# find all of audio and mel files", "\n", "audio_files", "=", "sorted", "(", "find_files", "(", "root_dir", ",", "audio_query", ")", ")", "\n", "\n", "# filter by threshold", "\n", "if", "audio_length_threshold", "is", "not", "None", ":", "\n", "            ", "audio_lengths", "=", "[", "audio_load_fn", "(", "f", ")", ".", "shape", "[", "0", "]", "for", "f", "in", "audio_files", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", "in", "range", "(", "len", "(", "audio_files", ")", ")", "if", "audio_lengths", "[", "idx", "]", ">", "audio_length_threshold", "]", "\n", "if", "len", "(", "audio_files", ")", "!=", "len", "(", "idxs", ")", ":", "\n", "                ", "logging", ".", "waning", "(", "f\"some files are filtered by audio length threshold \"", "\n", "f\"({len(audio_files)} -> {len(idxs)}).\"", ")", "\n", "", "audio_files", "=", "[", "audio_files", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "\n", "# assert the number of files", "\n", "", "assert", "len", "(", "audio_files", ")", "!=", "0", ",", "f\"Not found any audio files in ${root_dir}.\"", "\n", "\n", "self", ".", "audio_files", "=", "audio_files", "\n", "self", ".", "audio_load_fn", "=", "audio_load_fn", "\n", "self", ".", "return_utt_id", "=", "return_utt_id", "\n", "if", "\".npy\"", "in", "audio_query", ":", "\n", "            ", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "basename", "(", "f", ")", ".", "replace", "(", "\"-wave.npy\"", ",", "\"\"", ")", "for", "f", "in", "audio_files", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "audio_files", "]", "\n", "", "self", ".", "allow_cache", "=", "allow_cache", "\n", "if", "allow_cache", ":", "\n", "# NOTE(kan-bayashi): Manager is need to share memory in dataloader with num_workers > 0", "\n", "            ", "self", ".", "manager", "=", "Manager", "(", ")", "\n", "self", ".", "caches", "=", "self", ".", "manager", ".", "list", "(", ")", "\n", "self", ".", "caches", "+=", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "audio_files", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioDataset.__getitem__": [[205, 231], ["audio_mel_dataset.AudioDataset.audio_load_fn", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get specified idx items.\n\n        Args:\n            idx (int): Index of the item.\n\n        Returns:\n            str: Utterance id (only in return_utt_id = True).\n            ndarray: Audio (T,).\n\n        \"\"\"", "\n", "if", "self", ".", "allow_cache", "and", "len", "(", "self", ".", "caches", "[", "idx", "]", ")", "!=", "0", ":", "\n", "            ", "return", "self", ".", "caches", "[", "idx", "]", "\n", "\n", "", "utt_id", "=", "self", ".", "utt_ids", "[", "idx", "]", "\n", "audio", "=", "self", ".", "audio_load_fn", "(", "self", ".", "audio_files", "[", "idx", "]", ")", "\n", "\n", "if", "self", ".", "return_utt_id", ":", "\n", "            ", "items", "=", "utt_id", ",", "audio", "\n", "", "else", ":", "\n", "            ", "items", "=", "audio", "\n", "\n", "", "if", "self", ".", "allow_cache", ":", "\n", "            ", "self", ".", "caches", "[", "idx", "]", "=", "items", "\n", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.AudioDataset.__len__": [[232, 240], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return dataset length.\n\n        Returns:\n            int: The length of dataset.\n\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "audio_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.MelDataset.__init__": [[245, 293], ["sorted", "utils.find_files", "len", "multiprocessing.Manager", "audio_mel_dataset.MelDataset.manager.list", "len", "len", "logging.warning", "os.path.splitext", "os.path.basename().replace", "range", "os.path.basename", "os.path.splitext", "range", "mel_load_fn", "len", "os.path.basename", "os.path.basename", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.utils.utils.find_files"], ["def", "__init__", "(", "self", ",", "\n", "root_dir", ",", "\n", "mel_query", "=", "\"*-feats.npy\"", ",", "\n", "mel_length_threshold", "=", "None", ",", "\n", "mel_load_fn", "=", "np", ".", "load", ",", "\n", "return_utt_id", "=", "False", ",", "\n", "allow_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize dataset.\n\n        Args:\n            root_dir (str): Root directory including dumped files.\n            mel_query (str): Query to find feature files in root_dir.\n            mel_load_fn (func): Function to load feature file.\n            mel_length_threshold (int): Threshold to remove short feature files.\n            return_utt_id (bool): Whether to return the utterance id with arrays.\n            allow_cache (bool): Whether to allow cache of the loaded files.\n\n        \"\"\"", "\n", "# find all of the mel files", "\n", "mel_files", "=", "sorted", "(", "find_files", "(", "root_dir", ",", "mel_query", ")", ")", "\n", "\n", "# filter by threshold", "\n", "if", "mel_length_threshold", "is", "not", "None", ":", "\n", "            ", "mel_lengths", "=", "[", "mel_load_fn", "(", "f", ")", ".", "shape", "[", "0", "]", "for", "f", "in", "mel_files", "]", "\n", "idxs", "=", "[", "idx", "for", "idx", "in", "range", "(", "len", "(", "mel_files", ")", ")", "if", "mel_lengths", "[", "idx", "]", ">", "mel_length_threshold", "]", "\n", "if", "len", "(", "mel_files", ")", "!=", "len", "(", "idxs", ")", ":", "\n", "                ", "logging", ".", "warning", "(", "f\"Some files are filtered by mel length threshold \"", "\n", "f\"({len(mel_files)} -> {len(idxs)}).\"", ")", "\n", "", "mel_files", "=", "[", "mel_files", "[", "idx", "]", "for", "idx", "in", "idxs", "]", "\n", "\n", "# assert the number of files", "\n", "", "assert", "len", "(", "mel_files", ")", "!=", "0", ",", "f\"Not found any mel files in ${root_dir}.\"", "\n", "\n", "self", ".", "mel_files", "=", "mel_files", "\n", "self", ".", "mel_load_fn", "=", "mel_load_fn", "\n", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "mel_files", "]", "\n", "if", "\".npy\"", "in", "mel_query", ":", "\n", "            ", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "basename", "(", "f", ")", ".", "replace", "(", "\"-feats.npy\"", ",", "\"\"", ")", "for", "f", "in", "mel_files", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "utt_ids", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "mel_files", "]", "\n", "", "self", ".", "return_utt_id", "=", "return_utt_id", "\n", "self", ".", "allow_cache", "=", "allow_cache", "\n", "if", "allow_cache", ":", "\n", "# NOTE(kan-bayashi): Manager is need to share memory in dataloader with num_workers > 0", "\n", "            ", "self", ".", "manager", "=", "Manager", "(", ")", "\n", "self", ".", "caches", "=", "self", ".", "manager", ".", "list", "(", ")", "\n", "self", ".", "caches", "+=", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "mel_files", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.MelDataset.__getitem__": [[294, 320], ["audio_mel_dataset.MelDataset.mel_load_fn", "len"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Get specified idx items.\n\n        Args:\n            idx (int): Index of the item.\n\n        Returns:\n            str: Utterance id (only in return_utt_id = True).\n            ndarray: Feature (T', C).\n\n        \"\"\"", "\n", "if", "self", ".", "allow_cache", "and", "len", "(", "self", ".", "caches", "[", "idx", "]", ")", "!=", "0", ":", "\n", "            ", "return", "self", ".", "caches", "[", "idx", "]", "\n", "\n", "", "utt_id", "=", "self", ".", "utt_ids", "[", "idx", "]", "\n", "mel", "=", "self", ".", "mel_load_fn", "(", "self", ".", "mel_files", "[", "idx", "]", ")", "\n", "\n", "if", "self", ".", "return_utt_id", ":", "\n", "            ", "items", "=", "utt_id", ",", "mel", "\n", "", "else", ":", "\n", "            ", "items", "=", "mel", "\n", "\n", "", "if", "self", ".", "allow_cache", ":", "\n", "            ", "self", ".", "caches", "[", "idx", "]", "=", "items", "\n", "\n", "", "return", "items", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.datasets.audio_mel_dataset.MelDataset.__len__": [[321, 329], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return dataset length.\n\n        Returns:\n            int: The length of dataset.\n\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "mel_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFReflectionPad1d.__init__": [[14, 23], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "padding_size", ")", ":", "\n", "        ", "\"\"\"Initialize TFReflectionPad1d module.\n\n        Args:\n            padding_size (int): Padding size.\n\n        \"\"\"", "\n", "super", "(", "TFReflectionPad1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding_size", "=", "padding_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFReflectionPad1d.call": [[24, 36], ["tensorflow.pad"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, T, 1, C).\n\n        Returns:\n            Tensor: Padded tensor (B, T + 2 * padding_size, 1, C).\n\n        \"\"\"", "\n", "return", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "self", ".", "padding_size", ",", "self", ".", "padding_size", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ",", "\"REFLECT\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFConvTranspose1d.__init__": [[41, 57], ["super().__init__", "tensorflow.keras.layers.Conv2DTranspose"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "channels", ",", "kernel_size", ",", "stride", ",", "padding", ")", ":", "\n", "        ", "\"\"\"Initialize TFConvTranspose1d( module.\n\n        Args:\n            channels (int): Number of channels.\n            kernel_size (int): kernel size.\n            strides (int): Stride width.\n            padding (str): Padding type (\"same\" or \"valid\").\n\n        \"\"\"", "\n", "super", "(", "TFConvTranspose1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1d_transpose", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "\n", "filters", "=", "channels", ",", "\n", "kernel_size", "=", "(", "kernel_size", ",", "1", ")", ",", "\n", "strides", "=", "(", "stride", ",", "1", ")", ",", "\n", "padding", "=", "padding", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFConvTranspose1d.call": [[59, 72], ["tf_layers.TFConvTranspose1d.conv1d_transpose"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, T, 1, C).\n\n        Returns:\n            Tensors: Output tensor (B, T', 1, C').\n\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1d_transpose", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFResidualStack.__init__": [[77, 113], ["super().__init__", "tensorflow.keras.layers.Conv2D", "tf_layers.TFReflectionPad1d", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "kernel_size", ",", "\n", "channels", ",", "\n", "dilation", ",", "\n", "bias", ",", "\n", "nonlinear_activation", ",", "\n", "nonlinear_activation_params", ",", "\n", "padding", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize TFResidualStack module.\n\n        Args:\n            kernel_size (int): Kernel size.\n            channles (int): Number of channels.\n            dilation (int): Dilation ine.\n            bias (bool): Whether to add bias parameter in convolution layers.\n            nonlinear_activation (str): Activation function module name.\n            nonlinear_activation_params (dict): Hyperparameters for activation function.\n            padding (str): Padding type (\"same\" or \"valid\").\n\n        \"\"\"", "\n", "super", "(", "TFResidualStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block", "=", "[", "\n", "getattr", "(", "tf", ".", "keras", ".", "layers", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "TFReflectionPad1d", "(", "dilation", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "\n", "filters", "=", "channels", ",", "\n", "kernel_size", "=", "(", "kernel_size", ",", "1", ")", ",", "\n", "dilation_rate", "=", "(", "dilation", ",", "1", ")", ",", "\n", "use_bias", "=", "bias", ",", "\n", "padding", "=", "\"valid\"", ",", "\n", ")", ",", "\n", "getattr", "(", "tf", ".", "keras", ".", "layers", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "channels", ",", "kernel_size", "=", "1", ",", "use_bias", "=", "bias", ")", "\n", "]", "\n", "self", ".", "shortcut", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "channels", ",", "kernel_size", "=", "1", ",", "use_bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.tf_layers.TFResidualStack.call": [[114, 130], ["tensorflow.identity", "enumerate", "tf_layers.TFResidualStack.shortcut", "layer"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, T, 1, C).\n\n        Returns:\n            Tensor: Output tensor (B, T, 1, C).\n\n        \"\"\"", "\n", "_x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "block", ")", ":", "\n", "            ", "_x", "=", "layer", "(", "_x", ")", "\n", "", "shortcut", "=", "self", ".", "shortcut", "(", "x", ")", "\n", "return", "shortcut", "+", "_x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.__init__": [[61, 107], ["super().__init__", "pqmf.design_prototype_filter", "numpy.zeros", "numpy.zeros", "range", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "torch.from_numpy().float().unsqueeze", "pqmf.PQMF.register_buffer", "pqmf.PQMF.register_buffer", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "torch.zeros().float", "range", "pqmf.PQMF.register_buffer", "torch.nn.ConstantPad1d", "torch.nn.ConstantPad1d", "torch.nn.ConstantPad1d", "torch.nn.ConstantPad1d", "len", "len", "numpy.cos", "numpy.cos", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.design_prototype_filter"], ["def", "__init__", "(", "self", ",", "subbands", "=", "4", ",", "taps", "=", "62", ",", "cutoff_ratio", "=", "0.142", ",", "beta", "=", "9.0", ")", ":", "\n", "        ", "\"\"\"Initilize PQMF module.\n\n        The cutoff_ratio and beta parameters are optimized for #subbands = 4.\n        See dicussion in https://github.com/kan-bayashi/ParallelWaveGAN/issues/195.\n\n        Args:\n            subbands (int): The number of subbands.\n            taps (int): The number of filter taps.\n            cutoff_ratio (float): Cut-off frequency ratio.\n            beta (float): Beta coefficient for kaiser window.\n\n        \"\"\"", "\n", "super", "(", "PQMF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# build analysis & synthesis filter coefficients", "\n", "h_proto", "=", "design_prototype_filter", "(", "taps", ",", "cutoff_ratio", ",", "beta", ")", "\n", "h_analysis", "=", "np", ".", "zeros", "(", "(", "subbands", ",", "len", "(", "h_proto", ")", ")", ")", "\n", "h_synthesis", "=", "np", ".", "zeros", "(", "(", "subbands", ",", "len", "(", "h_proto", ")", ")", ")", "\n", "for", "k", "in", "range", "(", "subbands", ")", ":", "\n", "            ", "h_analysis", "[", "k", "]", "=", "2", "*", "h_proto", "*", "np", ".", "cos", "(", "\n", "(", "2", "*", "k", "+", "1", ")", "*", "(", "np", ".", "pi", "/", "(", "2", "*", "subbands", ")", ")", "*", "\n", "(", "np", ".", "arange", "(", "taps", "+", "1", ")", "-", "(", "taps", "/", "2", ")", ")", "+", "\n", "(", "-", "1", ")", "**", "k", "*", "np", ".", "pi", "/", "4", ")", "\n", "h_synthesis", "[", "k", "]", "=", "2", "*", "h_proto", "*", "np", ".", "cos", "(", "\n", "(", "2", "*", "k", "+", "1", ")", "*", "(", "np", ".", "pi", "/", "(", "2", "*", "subbands", ")", ")", "*", "\n", "(", "np", ".", "arange", "(", "taps", "+", "1", ")", "-", "(", "taps", "/", "2", ")", ")", "-", "\n", "(", "-", "1", ")", "**", "k", "*", "np", ".", "pi", "/", "4", ")", "\n", "\n", "# convert to tensor", "\n", "", "analysis_filter", "=", "torch", ".", "from_numpy", "(", "h_analysis", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "synthesis_filter", "=", "torch", ".", "from_numpy", "(", "h_synthesis", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# register coefficients as beffer", "\n", "self", ".", "register_buffer", "(", "\"analysis_filter\"", ",", "analysis_filter", ")", "\n", "self", ".", "register_buffer", "(", "\"synthesis_filter\"", ",", "synthesis_filter", ")", "\n", "\n", "# filter for downsampling & upsampling", "\n", "updown_filter", "=", "torch", ".", "zeros", "(", "(", "subbands", ",", "subbands", ",", "subbands", ")", ")", ".", "float", "(", ")", "\n", "for", "k", "in", "range", "(", "subbands", ")", ":", "\n", "            ", "updown_filter", "[", "k", ",", "k", ",", "0", "]", "=", "1.0", "\n", "", "self", ".", "register_buffer", "(", "\"updown_filter\"", ",", "updown_filter", ")", "\n", "self", ".", "subbands", "=", "subbands", "\n", "\n", "# keep padding info", "\n", "self", ".", "pad_fn", "=", "torch", ".", "nn", ".", "ConstantPad1d", "(", "taps", "//", "2", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.analysis": [[108, 120], ["torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d", "pqmf.PQMF.pad_fn"], "methods", ["None"], ["", "def", "analysis", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Analysis with PQMF.\n\n        Args:\n            x (Tensor): Input tensor (B, 1, T).\n\n        Returns:\n            Tensor: Output tensor (B, subbands, T // subbands).\n\n        \"\"\"", "\n", "x", "=", "F", ".", "conv1d", "(", "self", ".", "pad_fn", "(", "x", ")", ",", "self", ".", "analysis_filter", ")", "\n", "return", "F", ".", "conv1d", "(", "x", ",", "self", ".", "updown_filter", ",", "stride", "=", "self", ".", "subbands", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.synthesis": [[121, 136], ["torch.conv_transpose1d", "torch.conv_transpose1d", "torch.conv1d", "torch.conv1d", "pqmf.PQMF.pad_fn"], "methods", ["None"], ["", "def", "synthesis", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Synthesis with PQMF.\n\n        Args:\n            x (Tensor): Input tensor (B, subbands, T // subbands).\n\n        Returns:\n            Tensor: Output tensor (B, 1, T).\n\n        \"\"\"", "\n", "# NOTE(kan-bayashi): Power will be dreased so here multipy by # subbands.", "\n", "#   Not sure this is the correct way, it is better to check again.", "\n", "# TODO(kan-bayashi): Understand the reconstruction procedure", "\n", "x", "=", "F", ".", "conv_transpose1d", "(", "x", ",", "self", ".", "updown_filter", "*", "self", ".", "subbands", ",", "stride", "=", "self", ".", "subbands", ")", "\n", "return", "F", ".", "conv1d", "(", "self", ".", "pad_fn", "(", "x", ")", ",", "self", ".", "synthesis_filter", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.design_prototype_filter": [[15, 49], ["scipy.signal.kaiser", "numpy.errstate", "numpy.cos", "numpy.sin", "numpy.arange", "numpy.arange"], "function", ["None"], ["def", "design_prototype_filter", "(", "taps", "=", "62", ",", "cutoff_ratio", "=", "0.142", ",", "beta", "=", "9.0", ")", ":", "\n", "    ", "\"\"\"Design prototype filter for PQMF.\n\n    This method is based on `A Kaiser window approach for the design of prototype\n    filters of cosine modulated filterbanks`_.\n\n    Args:\n        taps (int): The number of filter taps.\n        cutoff_ratio (float): Cut-off frequency ratio.\n        beta (float): Beta coefficient for kaiser window.\n\n    Returns:\n        ndarray: Impluse response of prototype filter (taps + 1,).\n\n    .. _`A Kaiser window approach for the design of prototype filters of cosine modulated filterbanks`:\n        https://ieeexplore.ieee.org/abstract/document/681427\n\n    \"\"\"", "\n", "# check the arguments are valid", "\n", "assert", "taps", "%", "2", "==", "0", ",", "\"The number of taps mush be even number.\"", "\n", "assert", "0.0", "<", "cutoff_ratio", "<", "1.0", ",", "\"Cutoff ratio must be > 0.0 and < 1.0.\"", "\n", "\n", "# make initial filter", "\n", "omega_c", "=", "np", ".", "pi", "*", "cutoff_ratio", "\n", "with", "np", ".", "errstate", "(", "invalid", "=", "'ignore'", ")", ":", "\n", "        ", "h_i", "=", "np", ".", "sin", "(", "omega_c", "*", "(", "np", ".", "arange", "(", "taps", "+", "1", ")", "-", "0.5", "*", "taps", ")", ")", "/", "(", "np", ".", "pi", "*", "(", "np", ".", "arange", "(", "taps", "+", "1", ")", "-", "0.5", "*", "taps", ")", ")", "\n", "", "h_i", "[", "taps", "//", "2", "]", "=", "np", ".", "cos", "(", "0", ")", "*", "cutoff_ratio", "# fix nan due to indeterminate form", "\n", "\n", "# apply kaiser window", "\n", "w", "=", "kaiser", "(", "taps", "+", "1", ",", "beta", ")", "\n", "h", "=", "h_i", "*", "w", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.causal_conv.CausalConv1d.__init__": [[15, 22], ["super().__init__", "torch.nn.Conv1d", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "dilation", "=", "1", ",", "bias", "=", "True", ",", "pad", "=", "\"ConstantPad1d\"", ",", "pad_params", "=", "{", "\"value\"", ":", "0.0", "}", ")", ":", "\n", "        ", "\"\"\"Initialize CausalConv1d module.\"\"\"", "\n", "super", "(", "CausalConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pad", "=", "getattr", "(", "torch", ".", "nn", ",", "pad", ")", "(", "(", "kernel_size", "-", "1", ")", "*", "dilation", ",", "**", "pad_params", ")", "\n", "self", ".", "conv", "=", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.causal_conv.CausalConv1d.forward": [[23, 34], ["causal_conv.CausalConv1d.conv", "causal_conv.CausalConv1d.pad", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, in_channels, T).\n\n        Returns:\n            Tensor: Output tensor (B, out_channels, T).\n\n        \"\"\"", "\n", "return", "self", ".", "conv", "(", "self", ".", "pad", "(", "x", ")", ")", "[", ":", ",", ":", ",", ":", "x", ".", "size", "(", "2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.causal_conv.CausalConvTranspose1d.__init__": [[39, 45], ["super().__init__", "torch.nn.ConvTranspose1d"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"Initialize CausalConvTranspose1d module.\"\"\"", "\n", "super", "(", "CausalConvTranspose1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "deconv", "=", "torch", ".", "nn", ".", "ConvTranspose1d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "bias", "=", "bias", ")", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.causal_conv.CausalConvTranspose1d.forward": [[46, 57], ["causal_conv.CausalConvTranspose1d.deconv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, in_channels, T_in).\n\n        Returns:\n            Tensor: Output tensor (B, out_channels, T_out).\n\n        \"\"\"", "\n", "return", "self", ".", "deconv", "(", "x", ")", "[", ":", ",", ":", ",", ":", "-", "self", ".", "stride", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.Conv1d.__init__": [[18, 21], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize Conv1d module.\"\"\"", "\n", "super", "(", "Conv1d", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.Conv1d.reset_parameters": [[22, 27], ["torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset parameters.\"\"\"", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.Conv1d1x1.__init__": [[32, 37], ["residual_block.Conv1d.__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "bias", ")", ":", "\n", "        ", "\"\"\"Initialize 1x1 Conv1d module.\"\"\"", "\n", "super", "(", "Conv1d1x1", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.ResidualBlock.__init__": [[42, 90], ["super().__init__", "residual_block.Conv1d", "residual_block.Conv1d1x1", "residual_block.Conv1d1x1", "residual_block.Conv1d1x1"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "kernel_size", "=", "3", ",", "\n", "residual_channels", "=", "64", ",", "\n", "gate_channels", "=", "128", ",", "\n", "skip_channels", "=", "64", ",", "\n", "aux_channels", "=", "80", ",", "# \u6761\u4ef6\u8f93\u5165\u7ef4\u5ea6:80\u7ef4Mel\u9891\u8c31", "\n", "dropout", "=", "0.0", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "use_causal_conv", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize ResidualBlock module.\n\n        Args:\n            kernel_size (int): Kernel size of dilation convolution layer.\n            residual_channels (int): Number of channels for residual connection.\n            skip_channels (int): Number of channels for skip connection.\n            aux_channels (int): Local conditioning channels i.e. auxiliary input dimension.\n            dropout (float): Dropout probability.\n            dilation (int): Dilation factor.\n            bias (bool): Whether to add bias parameter in convolution layers.\n            use_causal_conv (bool): Whether to use use_causal_conv or non-use_causal_conv convolution.\n\n        \"\"\"", "\n", "super", "(", "ResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "# no future time stamps available", "\n", "if", "use_causal_conv", ":", "\n", "            ", "padding", "=", "(", "kernel_size", "-", "1", ")", "*", "dilation", "\n", "", "else", ":", "\n", "            ", "assert", "(", "kernel_size", "-", "1", ")", "%", "2", "==", "0", ",", "\"Not support even number kernel size.\"", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "*", "dilation", "\n", "", "self", ".", "use_causal_conv", "=", "use_causal_conv", "\n", "\n", "# dilation conv", "\n", "self", ".", "conv", "=", "Conv1d", "(", "residual_channels", ",", "gate_channels", ",", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", "\n", "\n", "# local conditioning  \u52a0\u5165\u6761\u4ef6\u8f93\u5165 (B, aux_channels, T) -> (B, gate_channels, T)", "\n", "if", "aux_channels", ">", "0", ":", "\n", "            ", "self", ".", "conv1x1_aux", "=", "Conv1d1x1", "(", "aux_channels", ",", "gate_channels", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1x1_aux", "=", "None", "\n", "\n", "# conv output is split into two groups   GAU\u95e8\u8f93\u51fa\u62c6\u4e3a\u4e24\u90e8\u5206: residual\u4e0eskip connection", "\n", "", "gate_out_channels", "=", "gate_channels", "//", "2", "\n", "self", ".", "conv1x1_out", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "residual_channels", ",", "bias", "=", "bias", ")", "\n", "self", ".", "conv1x1_skip", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "skip_channels", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.ResidualBlock.forward": [[91, 130], ["torch.dropout", "torch.dropout", "residual_block.ResidualBlock.conv", "residual_block.ResidualBlock.split", "residual_block.ResidualBlock.conv1x1_skip", "residual_block.ResidualBlock.conv1x1_aux", "residual_block.ResidualBlock.split", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "math.sqrt", "residual_block.ResidualBlock.size", "residual_block.ResidualBlock.conv1x1_out", "residual_block.ResidualBlock.size", "residual.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, residual_channels, T).\n            c (Tensor): Local conditioning auxiliary tensor (B, aux_channels, T).\n\n        Returns:\n            Tensor: Output tensor for residual connection (B, residual_channels, T).\n            Tensor: Output tensor for skip connection (B, skip_channels, T).\n\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "# x\u7ecf\u8fc7\u81a8\u80c0\u5377\u79ef  (B, residual_channels, T) -> (B, gate_channels, T)", "\n", "\n", "# remove future time steps if use_causal_conv conv \u53bb\u9664x\u4e2dresidual\u672a\u6765\u7684\u65f6\u95f4\u6b65", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", "residual", ".", "size", "(", "-", "1", ")", "]", "if", "self", ".", "use_causal_conv", "else", "x", "\n", "\n", "# split into two part for gated activation  (B, gate_channels, T) -> 2*(B, gate_channels/2, T)", "\n", "splitdim", "=", "1", "\n", "xa", ",", "xb", "=", "x", ".", "split", "(", "x", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "# \u62c6\u5206\u540e\u5206\u522b\u901a\u8fc7tanh\u4e0esigmoid", "\n", "\n", "# local conditioning: WaveNet\u4e2d\u7684\u6761\u4ef6\u8f93\u5165,\u540c\u6837\u7ecf\u8fc7\u62c6\u5206\u540e\u9644\u52a0\u5230xa,xb\u4e0a", "\n", "if", "c", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "conv1x1_aux", "is", "not", "None", "\n", "c", "=", "self", ".", "conv1x1_aux", "(", "c", ")", "# condition\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef", "\n", "ca", ",", "cb", "=", "c", ".", "split", "(", "c", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "xa", ",", "xb", "=", "xa", "+", "ca", ",", "xb", "+", "cb", "\n", "\n", "", "x", "=", "torch", ".", "tanh", "(", "xa", ")", "*", "torch", ".", "sigmoid", "(", "xb", ")", "\n", "\n", "# for skip connection", "\n", "s", "=", "self", ".", "conv1x1_skip", "(", "x", ")", "\n", "\n", "# for residual connection  \u5377\u79ef\u8f93\u51fa+\u6b8b\u5dee\u5feb", "\n", "x", "=", "(", "self", ".", "conv1x1_out", "(", "x", ")", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "return", "x", ",", "s", "# \u8fd4\u56deresidual \u548c skip", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.ResidualEmbeddingBlock.__init__": [[136, 190], ["super().__init__", "residual_block.Conv1d", "residual_block.Conv1d1x1", "residual_block.Conv1d1x1", "residual_block.Conv1d1x1", "residual_block.Conv1d1x1"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "kernel_size", "=", "3", ",", "\n", "residual_channels", "=", "64", ",", "\n", "gate_channels", "=", "128", ",", "\n", "skip_channels", "=", "64", ",", "\n", "aux_channels", "=", "80", ",", "# \u6761\u4ef6\u8f93\u5165\u7ef4\u5ea6:80\u7ef4Mel\u9891\u8c31", "\n", "embed_channels", "=", "256", ",", "\n", "dropout", "=", "0.0", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "use_causal_conv", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize ResidualBlock module.\n\n        Args:\n            kernel_size (int): Kernel size of dilation convolution layer.\n            residual_channels (int): Number of channels for residual connection.\n            skip_channels (int): Number of channels for skip connection.\n            aux_channels (int): Local conditioning channels i.e. auxiliary input dimension.\n            dropout (float): Dropout probability.\n            dilation (int): Dilation factor.\n            bias (bool): Whether to add bias parameter in convolution layers.\n            use_causal_conv (bool): Whether to use use_causal_conv or non-use_causal_conv convolution.\n\n        \"\"\"", "\n", "super", "(", "ResidualEmbeddingBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "# no future time stamps available", "\n", "if", "use_causal_conv", ":", "\n", "            ", "padding", "=", "(", "kernel_size", "-", "1", ")", "*", "dilation", "\n", "", "else", ":", "\n", "            ", "assert", "(", "kernel_size", "-", "1", ")", "%", "2", "==", "0", ",", "\"Not support even number kernel size.\"", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "*", "dilation", "\n", "", "self", ".", "use_causal_conv", "=", "use_causal_conv", "\n", "\n", "# dilation conv", "\n", "self", ".", "conv", "=", "Conv1d", "(", "residual_channels", ",", "gate_channels", ",", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", "\n", "\n", "# local conditioning  \u52a0\u5165\u6761\u4ef6\u8f93\u5165 (B, aux_channels, T) -> (B, gate_channels, T)", "\n", "if", "aux_channels", ">", "0", ":", "\n", "            ", "self", ".", "conv1x1_aux", "=", "Conv1d1x1", "(", "aux_channels", ",", "gate_channels", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1x1_aux", "=", "None", "\n", "\n", "", "if", "aux_channels", ">", "0", ":", "\n", "            ", "self", ".", "conv1x1_embed", "=", "Conv1d1x1", "(", "embed_channels", ",", "gate_channels", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1x1_embed", "=", "None", "\n", "\n", "# conv output is split into two groups   GAU\u95e8\u8f93\u51fa\u62c6\u4e3a\u4e24\u90e8\u5206: residual\u4e0eskip connection", "\n", "", "gate_out_channels", "=", "gate_channels", "//", "2", "\n", "self", ".", "conv1x1_out", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "residual_channels", ",", "bias", "=", "bias", ")", "\n", "self", ".", "conv1x1_skip", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "skip_channels", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_block.ResidualEmbeddingBlock.forward": [[191, 235], ["torch.dropout", "torch.dropout", "residual_block.ResidualEmbeddingBlock.conv", "residual_block.ResidualEmbeddingBlock.split", "residual_block.ResidualEmbeddingBlock.conv1x1_skip", "residual_block.ResidualEmbeddingBlock.conv1x1_aux", "residual_block.ResidualEmbeddingBlock.split", "residual_block.ResidualEmbeddingBlock.conv1x1_embed", "residual_block.ResidualEmbeddingBlock.split", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "math.sqrt", "residual_block.ResidualEmbeddingBlock.size", "residual_block.ResidualEmbeddingBlock.conv1x1_out", "residual_block.ResidualEmbeddingBlock.size", "residual_block.ResidualEmbeddingBlock.size", "residual.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", ",", "embed", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, residual_channels, T).\n            c (Tensor): Local conditioning auxiliary tensor (B, aux_channels, T).\n            embed (Tensor): Local conditioning auxiliary tensor (B, embed_channels, T).\n\n        Returns:\n            Tensor: Output tensor for residual connection (B, residual_channels, T).\n            Tensor: Output tensor for skip connection (B, skip_channels, T).\n\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "# x\u7ecf\u8fc7\u81a8\u80c0\u5377\u79ef  (B, residual_channels, T) -> (B, gate_channels, T)", "\n", "\n", "# remove future time steps if use_causal_conv conv \u53bb\u9664x\u4e2dresidual\u672a\u6765\u7684\u65f6\u95f4\u6b65", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", "residual", ".", "size", "(", "-", "1", ")", "]", "if", "self", ".", "use_causal_conv", "else", "x", "\n", "\n", "# split into two part for gated activation  (B, gate_channels, T) -> 2*(B, gate_channels/2, T)", "\n", "splitdim", "=", "1", "\n", "xa", ",", "xb", "=", "x", ".", "split", "(", "x", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "# \u62c6\u5206\u540e\u5206\u522b\u901a\u8fc7tanh\u4e0esigmoid", "\n", "\n", "# local conditioning: WaveNet\u4e2d\u7684\u6761\u4ef6\u8f93\u5165,\u540c\u6837\u7ecf\u8fc7\u62c6\u5206\u540e\u9644\u52a0\u5230xa,xb\u4e0a", "\n", "if", "c", "is", "not", "None", "and", "embed", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "conv1x1_aux", "is", "not", "None", "\n", "assert", "self", ".", "conv1x1_embed", "is", "not", "None", "\n", "c", "=", "self", ".", "conv1x1_aux", "(", "c", ")", "# condition\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef", "\n", "ca", ",", "cb", "=", "c", ".", "split", "(", "c", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "\n", "embed", "=", "self", ".", "conv1x1_embed", "(", "embed", ")", "# condition\u7ecf\u8fc7\u4e00\u5c42\u5377\u79ef", "\n", "ea", ",", "eb", "=", "embed", ".", "split", "(", "embed", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "xa", ",", "xb", "=", "xa", "+", "ca", "+", "ea", ",", "xb", "+", "cb", "+", "eb", "\n", "\n", "", "x", "=", "torch", ".", "tanh", "(", "xa", ")", "*", "torch", ".", "sigmoid", "(", "xb", ")", "\n", "\n", "# for skip connection", "\n", "s", "=", "self", ".", "conv1x1_skip", "(", "x", ")", "\n", "\n", "# for residual connection  \u5377\u79ef\u8f93\u51fa+\u6b8b\u5dee\u5feb", "\n", "x", "=", "(", "self", ".", "conv1x1_out", "(", "x", ")", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "\n", "return", "x", ",", "s", "# \u8fd4\u56deresidual \u548c skip", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_stack.ResidualStack.__init__": [[16, 64], ["super().__init__", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv1d", "torch.nn.Conv1d", "layers.CausalConv1d", "torch.nn.Conv1d", "getattr", "getattr", "getattr", "getattr", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "kernel_size", "=", "3", ",", "\n", "channels", "=", "32", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "nonlinear_activation", "=", "\"LeakyReLU\"", ",", "\n", "nonlinear_activation_params", "=", "{", "\"negative_slope\"", ":", "0.2", "}", ",", "\n", "pad", "=", "\"ReflectionPad1d\"", ",", "\n", "pad_params", "=", "{", "}", ",", "\n", "use_causal_conv", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize ResidualStack module.\n\n        Args:\n            kernel_size (int): Kernel size of dilation convolution layer.\n            channels (int): Number of channels of convolution layers.\n            dilation (int): Dilation factor.\n            bias (bool): Whether to add bias parameter in convolution layers.\n            nonlinear_activation (str): Activation function module name.\n            nonlinear_activation_params (dict): Hyperparameters for activation function.\n            pad (str): Padding function module name before dilated convolution layer.\n            pad_params (dict): Hyperparameters for padding function.\n            use_causal_conv (bool): Whether to use causal convolution.\n\n        \"\"\"", "\n", "super", "(", "ResidualStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# defile residual stack part", "\n", "if", "not", "use_causal_conv", ":", "\n", "            ", "assert", "(", "kernel_size", "-", "1", ")", "%", "2", "==", "0", ",", "\"Not support even number kernel size.\"", "\n", "self", ".", "stack", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "pad", ")", "(", "(", "kernel_size", "-", "1", ")", "//", "2", "*", "dilation", ",", "**", "pad_params", ")", ",", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "kernel_size", ",", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "1", ",", "bias", "=", "bias", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "stack", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "CausalConv1d", "(", "channels", ",", "channels", ",", "kernel_size", ",", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "pad", "=", "pad", ",", "pad_params", "=", "pad_params", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "1", ",", "bias", "=", "bias", ")", ",", "\n", ")", "\n", "\n", "# defile extra layer for skip connection", "\n", "", "self", ".", "skip_layer", "=", "torch", ".", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "1", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.residual_stack.ResidualStack.forward": [[65, 76], ["residual_stack.ResidualStack.stack", "residual_stack.ResidualStack.skip_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            c (Tensor): Input tensor (B, channels, T).\n\n        Returns:\n            Tensor: Output tensor (B, channels, T).\n\n        \"\"\"", "\n", "return", "self", ".", "stack", "(", "c", ")", "+", "self", ".", "skip_layer", "(", "c", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.Stretch2d.__init__": [[19, 32], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "x_scale", ",", "y_scale", ",", "mode", "=", "\"nearest\"", ")", ":", "\n", "        ", "\"\"\"Initialize Stretch2d module.\n\n        Args:\n            x_scale (int): X scaling factor (Time axis in spectrogram).\n            y_scale (int): Y scaling factor (Frequency axis in spectrogram).\n            mode (str): Interpolation mode.\n\n        \"\"\"", "\n", "super", "(", "Stretch2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "x_scale", "=", "x_scale", "\n", "self", ".", "y_scale", "=", "y_scale", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.Stretch2d.forward": [[33, 45], ["torch.interpolate", "torch.interpolate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input tensor (B, C, F, T).\n\n        Returns:\n            Tensor: Interpolated tensor (B, C, F * y_scale, T * x_scale),\n\n        \"\"\"", "\n", "return", "F", ".", "interpolate", "(", "\n", "x", ",", "scale_factor", "=", "(", "self", ".", "y_scale", ",", "self", ".", "x_scale", ")", ",", "mode", "=", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.Conv2d.__init__": [[50, 53], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Initialize Conv2d module.\"\"\"", "\n", "super", "(", "Conv2d", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.Conv2d.reset_parameters": [[54, 59], ["upsample.Conv2d.weight.data.fill_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "numpy.prod"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset parameters.\"\"\"", "\n", "self", ".", "weight", ".", "data", ".", "fill_", "(", "1.", "/", "np", ".", "prod", "(", "self", ".", "kernel_size", ")", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.UpsampleNetwork.__init__": [[64, 105], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "upsample.Stretch2d", "upsample.Conv2d", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "upsample_scales", ",", "\n", "nonlinear_activation", "=", "None", ",", "\n", "nonlinear_activation_params", "=", "{", "}", ",", "\n", "interpolate_mode", "=", "\"nearest\"", ",", "\n", "freq_axis_kernel_size", "=", "1", ",", "\n", "use_causal_conv", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize upsampling network module.\n\n        Args:\n            upsample_scales (list): List of upsampling scales.\n            nonlinear_activation (str): Activation function name.\n            nonlinear_activation_params (dict): Arguments for specified activation function.\n            interpolate_mode (str): Interpolation mode.\n            freq_axis_kernel_size (int): Kernel size in the direction of frequency axis.\n\n        \"\"\"", "\n", "super", "(", "UpsampleNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_causal_conv", "=", "use_causal_conv", "# \u662f\u5426\u4f7f\u7528\u56e0\u679c\u5377\u79ef", "\n", "self", ".", "up_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "scale", "in", "upsample_scales", ":", "\n", "# interpolation layer", "\n", "            ", "stretch", "=", "Stretch2d", "(", "scale", ",", "1", ",", "interpolate_mode", ")", "\n", "self", ".", "up_layers", "+=", "[", "stretch", "]", "\n", "\n", "# conv layer", "\n", "assert", "(", "freq_axis_kernel_size", "-", "1", ")", "%", "2", "==", "0", ",", "\"Not support even number freq axis kernel size.\"", "\n", "freq_axis_padding", "=", "(", "freq_axis_kernel_size", "-", "1", ")", "//", "2", "\n", "kernel_size", "=", "(", "freq_axis_kernel_size", ",", "scale", "*", "2", "+", "1", ")", "\n", "if", "use_causal_conv", ":", "\n", "                ", "padding", "=", "(", "freq_axis_padding", ",", "scale", "*", "2", ")", "\n", "", "else", ":", "\n", "                ", "padding", "=", "(", "freq_axis_padding", ",", "scale", ")", "\n", "", "conv", "=", "Conv2d", "(", "1", ",", "1", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "self", ".", "up_layers", "+=", "[", "conv", "]", "\n", "\n", "# nonlinear", "\n", "if", "nonlinear_activation", "is", "not", "None", ":", "# \u4f7f\u7528\u975e\u7ebf\u6027\u6fc0\u6d3b", "\n", "                ", "nonlinear", "=", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", "\n", "self", ".", "up_layers", "+=", "[", "nonlinear", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.UpsampleNetwork.forward": [[106, 123], ["f.unsqueeze", "f.squeeze", "isinstance", "f", "f", "f.size"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            c : Input tensor (B, C, T).\n\n        Returns:\n            Tensor: Upsampled tensor (B, C, T'), where T' = T * prod(upsample_scales).\n\n        \"\"\"", "\n", "c", "=", "c", ".", "unsqueeze", "(", "1", ")", "# (B, 1, C, T)", "\n", "for", "f", "in", "self", ".", "up_layers", ":", "\n", "            ", "if", "self", ".", "use_causal_conv", "and", "isinstance", "(", "f", ",", "Conv2d", ")", ":", "# \u82e5\u4f7f\u7528\u56e0\u679c\u5377\u79ef\u4e14\u5f53\u524d\u4e3a\u5377\u79ef\u5c42", "\n", "                ", "c", "=", "f", "(", "c", ")", "[", "...", ",", ":", "c", ".", "size", "(", "-", "1", ")", "]", "# \u83b7\u5f97[B, 1, C, T'']\uff0c\u5373\u5728\u65f6\u95f4\u6b65\u4e0a\u5b9e\u73b0\u56e0\u679c", "\n", "", "else", ":", "\n", "                ", "c", "=", "f", "(", "c", ")", "\n", "", "", "return", "c", ".", "squeeze", "(", "1", ")", "# (B, C, T')", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.ConvInUpsampleNetwork.__init__": [[128, 165], ["super().__init__", "layers.Conv1d", "upsample.UpsampleNetwork"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "upsample_scales", ",", "\n", "nonlinear_activation", "=", "None", ",", "\n", "nonlinear_activation_params", "=", "{", "}", ",", "\n", "interpolate_mode", "=", "\"nearest\"", ",", "\n", "freq_axis_kernel_size", "=", "1", ",", "\n", "aux_channels", "=", "80", ",", "\n", "aux_context_window", "=", "0", ",", "\n", "use_causal_conv", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize convolution + upsampling network module.\n\n        Args:\n            upsample_scales (list): List of upsampling scales.\n            nonlinear_activation (str): Activation function name.\n            nonlinear_activation_params (dict): Arguments for specified activation function.\n            mode (str): Interpolation mode.\n            freq_axis_kernel_size (int): Kernel size in the direction of frequency axis.\n            aux_channels (int): Number of channels of pre-convolutional layer.\n            aux_context_window (int): Context window size of the pre-convolutional layer.\n            use_causal_conv (bool): Whether to use causal structure.\n\n        \"\"\"", "\n", "super", "(", "ConvInUpsampleNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "aux_context_window", "=", "aux_context_window", "\n", "self", ".", "use_causal_conv", "=", "use_causal_conv", "and", "aux_context_window", ">", "0", "\n", "# To capture wide-context information in conditional features  \u4f7f\u7528\u5377\u79ef\u5c42+\u4e0a\u91c7\u6837\u5c42", "\n", "kernel_size", "=", "aux_context_window", "+", "1", "if", "use_causal_conv", "else", "2", "*", "aux_context_window", "+", "1", "\n", "# NOTE(kan-bayashi): Here do not use padding because the input is already padded", "\n", "self", ".", "conv_in", "=", "Conv1d", "(", "aux_channels", ",", "aux_channels", ",", "kernel_size", "=", "kernel_size", ",", "bias", "=", "False", ")", "#  \u65f6\u95f4\u6b65T' -> (T' - aux_context_window * 2)", "\n", "self", ".", "upsample", "=", "UpsampleNetwork", "(", "\n", "upsample_scales", "=", "upsample_scales", ",", "\n", "nonlinear_activation", "=", "nonlinear_activation", ",", "\n", "nonlinear_activation_params", "=", "nonlinear_activation_params", ",", "\n", "interpolate_mode", "=", "interpolate_mode", ",", "\n", "freq_axis_kernel_size", "=", "freq_axis_kernel_size", ",", "\n", "use_causal_conv", "=", "use_causal_conv", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.upsample.ConvInUpsampleNetwork.forward": [[167, 184], ["upsample.ConvInUpsampleNetwork.conv_in", "upsample.ConvInUpsampleNetwork.upsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "c", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            c : Input tensor (B, C, T').\n\n        Returns:\n            Tensor: Upsampled tensor (B, C, T),\n                where T = (T' - aux_context_window * 2) * prod(upsample_scales).\n\n        Note:\n            The length of inputs considers the context window size.\n\n        \"\"\"", "\n", "c_", "=", "self", ".", "conv_in", "(", "c", ")", "\n", "c", "=", "c_", "[", ":", ",", ":", ",", ":", "-", "self", ".", "aux_context_window", "]", "if", "self", ".", "use_causal_conv", "else", "c_", "\n", "return", "self", ".", "upsample", "(", "c", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.__init__": [[17, 22], ["dict", "torch.optim.optimizer.Optimizer.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "\"\"\"Initilize RAdam optimizer.\"\"\"", "\n", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "self", ".", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "ind", "in", "range", "(", "10", ")", "]", "\n", "super", "(", "RAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.__setstate__": [[23, 26], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\"Set state.\"\"\"", "\n", "super", "(", "RAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.optimizers.radam.RAdam.step": [[27, 92], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "math.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Run one step.\"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "self", ".", "buffer", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "                    ", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "                    ", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                        ", "step_size", "=", "math", ".", "sqrt", "(", "\n", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "# NOQA", "\n", "", "else", ":", "\n", "                        ", "step_size", "=", "1.0", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.__init__": [[22, 137], ["super().__init__", "layers.Conv1d1x1", "torch.nn.ModuleList", "range", "torch.nn.ModuleList", "layers.Conv1d", "layers.Conv1d", "layers.PQMF", "upsample_params.update", "numpy.prod", "layers.ResidualBlock", "Generator.Generator1.apply_weight_norm", "upsample_params.update", "torch.nn.ReLU", "layers.Conv1d1x1", "torch.nn.ReLU", "layers.Conv1d1x1", "getattr", "upsample_params.update", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.apply_weight_norm", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "1", ",", "\n", "out_channels", "=", "1", ",", "\n", "kernel_size", "=", "3", ",", "\n", "layers", "=", "30", ",", "\n", "stacks", "=", "3", ",", "\n", "residual_channels", "=", "64", ",", "\n", "gate_channels", "=", "128", ",", "\n", "skip_channels", "=", "64", ",", "\n", "aux_channels", "=", "80", ",", "\n", "aux_context_window", "=", "2", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "use_weight_norm", "=", "True", ",", "\n", "use_causal_conv", "=", "False", ",", "\n", "upsample_conditional_features", "=", "True", ",", "\n", "upsample_net", "=", "\"ConvInUpsampleNetwork\"", ",", "\n", "upsample_params", "=", "{", "\"upsample_scales\"", ":", "[", "4", ",", "4", ",", "4", ",", "4", "]", "}", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize Generator module.\n\n        Args:\n            in_channels (int): Number of input channels.\n            out_channels (int): Number of output channels.\n            kernel_size (int): Kernel size of dilated convolution.\n            layers (int): Number of residual block layers.\n            stacks (int): Number of stacks i.e., dilation cycles.\n            residual_channels (int): Number of channels in residual conv.\n            gate_channels (int):  Number of channels in gated conv.\n            skip_channels (int): Number of channels in skip conv.\n            aux_channels (int): Number of channels for auxiliary feature conv.\n            aux_context_window (int): Context window size for auxiliary feature.\n            dropout (float): Dropout rate. 0.0 means no dropout applied.\n            bias (bool): Whether to use bias parameter in conv layer.\n            use_weight_norm (bool): Whether to use weight norm.\n                If set to true, it will be applied to all of the conv layers.\n            use_causal_conv (bool): Whether to use causal structure.\n            upsample_conditional_features (bool): Whether to use upsampling network.\n            upsample_net (str): Upsampling network architecture.\n            upsample_params (dict): Upsampling network parameters.\n\n        \"\"\"", "\n", "super", "(", "Generator1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "aux_channels", "=", "aux_channels", "\n", "self", ".", "aux_context_window", "=", "aux_context_window", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "stacks", "=", "stacks", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "\n", "# check the number of layers and stacks", "\n", "assert", "layers", "%", "stacks", "==", "0", "\n", "layers_per_stack", "=", "layers", "//", "stacks", "\n", "\n", "# define first convolution", "\n", "self", ".", "first_conv", "=", "Conv1d1x1", "(", "in_channels", ",", "residual_channels", ",", "bias", "=", "True", ")", "\n", "\n", "# define conv + upsampling network", "\n", "if", "upsample_conditional_features", ":", "\n", "            ", "upsample_params", ".", "update", "(", "{", "\n", "\"use_causal_conv\"", ":", "use_causal_conv", ",", "\n", "}", ")", "\n", "if", "upsample_net", "==", "\"MelGANGenerator\"", ":", "\n", "                ", "assert", "aux_context_window", "==", "0", "\n", "upsample_params", ".", "update", "(", "{", "\n", "\"use_weight_norm\"", ":", "False", ",", "# not to apply twice", "\n", "\"use_final_nonlinear_activation\"", ":", "False", ",", "\n", "}", ")", "\n", "self", ".", "upsample_net", "=", "getattr", "(", "models", ",", "upsample_net", ")", "(", "**", "upsample_params", ")", "\n", "", "else", ":", "\n", "                ", "if", "upsample_net", "==", "\"ConvInUpsampleNetwork\"", ":", "\n", "                    ", "upsample_params", ".", "update", "(", "{", "\n", "\"aux_channels\"", ":", "aux_channels", ",", "\n", "\"aux_context_window\"", ":", "aux_context_window", ",", "\n", "}", ")", "\n", "", "self", ".", "upsample_net", "=", "getattr", "(", "upsample", ",", "upsample_net", ")", "(", "**", "upsample_params", ")", "\n", "", "self", ".", "upsample_factor", "=", "np", ".", "prod", "(", "upsample_params", "[", "\"upsample_scales\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "upsample_net", "=", "None", "\n", "self", ".", "upsample_factor", "=", "1", "\n", "\n", "# define residual blocks", "\n", "", "self", ".", "conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "layers", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "layer", "%", "layers_per_stack", ")", "\n", "conv", "=", "ResidualBlock", "(", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "residual_channels", "=", "residual_channels", ",", "\n", "gate_channels", "=", "gate_channels", ",", "\n", "skip_channels", "=", "skip_channels", ",", "\n", "aux_channels", "=", "aux_channels", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bias", "=", "bias", ",", "\n", "use_causal_conv", "=", "use_causal_conv", ",", "\n", ")", "\n", "self", ".", "conv_layers", "+=", "[", "conv", "]", "\n", "\n", "# define output layers", "\n", "", "self", ".", "last_conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "skip_channels", ",", "skip_channels", ",", "bias", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "skip_channels", ",", "in_channels", ",", "bias", "=", "True", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "pqmf_conv1", "=", "Conv1d", "(", "1", ",", "128", ",", "kernel_size", ",", "1", ",", "padding", "=", "3", ")", "\n", "self", ".", "pqmf_conv2", "=", "Conv1d", "(", "128", ",", "1", ",", "kernel_size", ",", "1", ",", "padding", "=", "3", ")", "\n", "\n", "# apply weight norm", "\n", "if", "use_weight_norm", ":", "\n", "            ", "self", ".", "apply_weight_norm", "(", ")", "\n", "\n", "", "self", ".", "pqmf", "=", "PQMF", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.forward": [[139, 175], ["Generator.Generator1.pqmf.analysis", "Generator.Generator1.first_conv", "math.sqrt", "Generator.Generator1.pqmf.synthesis", "Generator.Generator1.pqmf_conv1", "Generator.Generator1.pqmf_conv2", "Generator.Generator1.upsample_net", "f", "f", "f.size", "len", "Generator.Generator1.size"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.analysis", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.synthesis"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input noise signal (B, 1, T).\n            c (Tensor): Local conditioning auxiliary features (B, C ,T').\n\n        Returns:\n            Tensor: Output tensor (B, out_channels, T)\n\n        \"\"\"", "\n", "\n", "# perform upsampling", "\n", "\n", "if", "c", "is", "not", "None", "and", "self", ".", "upsample_net", "is", "not", "None", ":", "\n", "            ", "c", "=", "self", ".", "upsample_net", "(", "c", ")", "\n", "assert", "c", ".", "size", "(", "-", "1", ")", "*", "4", "==", "x", ".", "size", "(", "-", "1", ")", "\n", "", "x", "=", "self", ".", "pqmf", ".", "analysis", "(", "x", ")", "\n", "\n", "# encode to hidden representation", "\n", "x", "=", "self", ".", "first_conv", "(", "x", ")", "\n", "skips", "=", "0", "\n", "for", "f", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", ",", "h", "=", "f", "(", "x", ",", "c", ")", "\n", "skips", "+=", "h", "\n", "", "skips", "*=", "math", ".", "sqrt", "(", "1.0", "/", "len", "(", "self", ".", "conv_layers", ")", ")", "\n", "\n", "# apply final layers", "\n", "x", "=", "skips", "\n", "for", "f", "in", "self", ".", "last_conv_layers", ":", "\n", "            ", "x", "=", "f", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "pqmf", ".", "synthesis", "(", "x", ")", "\n", "x", "=", "self", ".", "pqmf_conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "pqmf_conv2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.inference": [[176, 201], ["Generator.Generator1.forward().squeeze().transpose", "torch.tensor().to.transpose().unsqueeze", "torch.randn().to", "torch.tensor().to.transpose().unsqueeze", "isinstance", "torch.tensor().to", "isinstance", "torch.tensor().to", "torch.nn.ReplicationPad1d", "Generator.Generator1.forward().squeeze", "torch.tensor().to.transpose", "torch.randn", "next", "torch.tensor().to.transpose", "torch.tensor", "next", "Generator.Generator1.parameters", "torch.tensor", "next", "Generator.Generator1.forward", "Generator.Generator1.parameters", "Generator.Generator1.parameters", "len"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.forward"], ["", "def", "inference", "(", "self", ",", "c", "=", "None", ",", "x", "=", "None", ")", ":", "\n", "        ", "\"\"\"Perform inference.\n\n        Args:\n            c (Union[Tensor, ndarray]): Local conditioning auxiliary features (T' ,C).\n            x (Union[Tensor, ndarray]): Input noise signal (T, 1).\n\n        Returns:\n            Tensor: Output tensor (T, out_channels)\n\n        \"\"\"", "\n", "if", "x", "is", "not", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "x", "=", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "", "x", "=", "x", ".", "transpose", "(", "1", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "c", "is", "not", "None", "\n", "x", "=", "torch", ".", "randn", "(", "1", ",", "1", ",", "len", "(", "c", ")", "*", "self", ".", "upsample_factor", "*", "4", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "", "if", "c", "is", "not", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "c", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "c", "=", "torch", ".", "tensor", "(", "c", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "", "c", "=", "c", ".", "transpose", "(", "1", ",", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "c", "=", "torch", ".", "nn", ".", "ReplicationPad1d", "(", "self", ".", "aux_context_window", ")", "(", "c", ")", "\n", "\n", "", "return", "self", ".", "forward", "(", "x", ",", "c", ")", ".", "squeeze", "(", "0", ")", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.remove_weight_norm": [[202, 212], ["Generator.Generator1.apply", "logging.debug", "torch.nn.utils.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.remove_weight_norm"], ["", "def", "remove_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Remove weight normalization module from all of the layers.\"\"\"", "\n", "def", "_remove_weight_norm", "(", "m", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "logging", ".", "debug", "(", "f\"Weight norm is removed from {m}.\"", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "m", ")", "\n", "", "except", "ValueError", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "_remove_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.apply_weight_norm": [[213, 221], ["Generator.Generator1.apply", "isinstance", "isinstance", "torch.nn.utils.weight_norm", "logging.debug"], "methods", ["None"], ["", "def", "apply_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Apply weight normalization module from all of the layers.\"\"\"", "\n", "def", "_apply_weight_norm", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv1d", ")", "or", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "logging", ".", "debug", "(", "f\"Weight norm is applied to {m}.\"", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1._get_receptive_field_size": [[222, 229], ["dilation", "range", "sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_receptive_field_size", "(", "layers", ",", "stacks", ",", "kernel_size", ",", "\n", "dilation", "=", "lambda", "x", ":", "2", "**", "x", ")", ":", "\n", "        ", "assert", "layers", "%", "stacks", "==", "0", "\n", "layers_per_cycle", "=", "layers", "//", "stacks", "\n", "dilations", "=", "[", "dilation", "(", "i", "%", "layers_per_cycle", ")", "for", "i", "in", "range", "(", "layers", ")", "]", "\n", "return", "(", "kernel_size", "-", "1", ")", "*", "sum", "(", "dilations", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator1.receptive_field_size": [[230, 234], ["Generator.Generator1._get_receptive_field_size"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2._get_receptive_field_size"], ["", "@", "property", "\n", "def", "receptive_field_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return receptive field size.\"\"\"", "\n", "return", "self", ".", "_get_receptive_field_size", "(", "self", ".", "layers", ",", "self", ".", "stacks", ",", "self", ".", "kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2.__init__": [[238, 320], ["super().__init__", "layers.PQMF", "layers.Conv1d1x1", "layers.Conv1d1x1", "upsample_params.update", "torch.nn.ModuleList", "range", "torch.nn.ModuleList", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "numpy.prod", "getattr", "layers.ResidualBlock", "layers.ResidualBlock", "Generator.Generator2.apply_weight_norm", "torch.nn.ReLU", "layers.Conv1d1x1", "torch.nn.ReLU", "layers.Conv1d1x1", "torch.nn.ReLU", "layers.Conv1d1x1", "torch.nn.ReLU", "layers.Conv1d1x1"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.encoder.visualizations.Visualizations.update", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.apply_weight_norm"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "1", ",", "\n", "out_channels", "=", "4", ",", "\n", "kernel_sizes", "=", "[", "7", ",", "5", "]", ",", "\n", "layers", "=", "[", "16", ",", "15", "]", ",", "\n", "stacks", "=", "[", "8", ",", "5", "]", ",", "\n", "residual_channels", "=", "64", ",", "\n", "aux_channels", "=", "80", ",", "\n", "aux_context_window", "=", "2", ",", "\n", "dropout", "=", "0.0", ",", "\n", "bias", "=", "True", ",", "\n", "use_weight_norm", "=", "True", ",", "\n", "upsample_net", "=", "\"ConvInUpsampleNetwork\"", ",", "\n", "upsample_params", "=", "{", "\"upsample_scales\"", ":", "[", "4", ",", "4", ",", "4", ",", "4", "]", "}", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "Generator2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "aux_channels", "=", "aux_channels", "\n", "self", ".", "stacks", "=", "stacks", "\n", "self", ".", "pqmf", "=", "PQMF", "(", "out_channels", ")", "\n", "self", ".", "aux_context_window", "=", "aux_context_window", "\n", "# define first convolution", "\n", "self", ".", "low_first_conv", "=", "Conv1d1x1", "(", "in_channels", ",", "residual_channels", ",", "bias", "=", "True", ")", "\n", "self", ".", "up_first_conv", "=", "Conv1d1x1", "(", "in_channels", ",", "residual_channels", ",", "bias", "=", "True", ")", "\n", "\n", "# define conv + upsampling network", "\n", "upsample_params", ".", "update", "(", "{", "\n", "\"aux_channels\"", ":", "aux_channels", ",", "\n", "\"aux_context_window\"", ":", "aux_context_window", ",", "\n", "}", ")", "\n", "self", ".", "upsample_net", "=", "getattr", "(", "upsample", ",", "upsample_net", ")", "(", "**", "upsample_params", ")", "\n", "\n", "# define residual blocks", "\n", "self", ".", "low_conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "layers", "[", "0", "]", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "layer", "%", "stacks", "[", "0", "]", ")", "\n", "conv", "=", "ResidualBlock", "(", "\n", "kernel_size", "=", "kernel_sizes", "[", "0", "]", ",", "\n", "residual_channels", "=", "residual_channels", ",", "\n", "aux_channels", "=", "aux_channels", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "low_conv_layers", "+=", "[", "conv", "]", "\n", "\n", "", "self", ".", "up_conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "layers", "[", "1", "]", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "layer", "%", "stacks", "[", "1", "]", ")", "\n", "conv", "=", "ResidualBlock", "(", "\n", "kernel_size", "=", "kernel_sizes", "[", "1", "]", ",", "\n", "residual_channels", "=", "residual_channels", ",", "\n", "aux_channels", "=", "aux_channels", ",", "\n", "dilation", "=", "dilation", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "up_conv_layers", "+=", "[", "conv", "]", "\n", "\n", "# define output layers", "\n", "", "self", ".", "last_low_conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "residual_channels", ",", "residual_channels", ",", "bias", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "residual_channels", ",", "out_channels", "//", "2", ",", "bias", "=", "True", ")", ",", "\n", "]", ")", "\n", "\n", "self", ".", "last_up_conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "residual_channels", ",", "residual_channels", ",", "bias", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "residual_channels", ",", "out_channels", "//", "2", ",", "bias", "=", "True", ")", ",", "\n", "]", ")", "\n", "self", ".", "upsample_factor", "=", "np", ".", "prod", "(", "upsample_params", "[", "\"upsample_scales\"", "]", ")", "\n", "\n", "\n", "\n", "# apply weight norm", "\n", "if", "use_weight_norm", ":", "\n", "            ", "self", ".", "apply_weight_norm", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2.forward": [[321, 356], ["Generator.Generator2.low_first_conv", "Generator.Generator2.up_first_conv", "math.sqrt", "math.sqrt", "torch.cat", "Generator.Generator2.pqmf.synthesis", "Generator.Generator2.upsample_net", "f", "f", "f", "f", "Generator.Generator2.size", "x.size", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.layers.pqmf.PQMF.synthesis"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "c", ")", ":", "\n", "\n", "# perform upsampling", "\n", "        ", "if", "c", "is", "not", "None", "and", "self", ".", "upsample_net", "is", "not", "None", ":", "\n", "            ", "c", "=", "self", ".", "upsample_net", "(", "c", ")", "\n", "assert", "c", ".", "size", "(", "-", "1", ")", "==", "x", ".", "size", "(", "-", "1", ")", "\n", "\n", "", "x1", "=", "self", ".", "low_first_conv", "(", "x", ")", "\n", "x2", "=", "self", ".", "up_first_conv", "(", "x", ")", "\n", "\n", "skips", "=", "0", "\n", "for", "f", "in", "self", ".", "low_conv_layers", ":", "\n", "            ", "x1", ",", "h", "=", "f", "(", "x1", ",", "c", ")", "\n", "skips", "+=", "h", "\n", "", "skips", "*=", "math", ".", "sqrt", "(", "1.0", "/", "len", "(", "self", ".", "low_conv_layers", ")", ")", "\n", "\n", "# apply final layers", "\n", "x1", "=", "skips", "\n", "for", "f", "in", "self", ".", "last_low_conv_layers", ":", "\n", "            ", "x1", "=", "f", "(", "x1", ")", "\n", "\n", "", "skips", "=", "0", "\n", "for", "f", "in", "self", ".", "up_conv_layers", ":", "\n", "            ", "x2", ",", "h", "=", "f", "(", "x2", ",", "c", ")", "\n", "skips", "+=", "h", "\n", "", "skips", "*=", "math", ".", "sqrt", "(", "1.0", "/", "len", "(", "self", ".", "up_conv_layers", ")", ")", "\n", "\n", "# apply final layers", "\n", "x2", "=", "skips", "\n", "for", "f", "in", "self", ".", "last_up_conv_layers", ":", "\n", "            ", "x2", "=", "f", "(", "x2", ")", "\n", "\n", "", "w", "=", "torch", ".", "cat", "(", "(", "x1", ",", "x2", ")", ",", "dim", "=", "1", ")", "\n", "res", "=", "self", ".", "pqmf", ".", "synthesis", "(", "w", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2.remove_weight_norm": [[357, 367], ["Generator.Generator2.apply", "logging.debug", "torch.nn.utils.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.remove_weight_norm"], ["", "def", "remove_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Remove weight normalization module from all of the layers.\"\"\"", "\n", "def", "_remove_weight_norm", "(", "m", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "logging", ".", "debug", "(", "f\"Weight norm is removed from {m}.\"", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "m", ")", "\n", "", "except", "ValueError", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "_remove_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2.apply_weight_norm": [[368, 376], ["Generator.Generator2.apply", "isinstance", "isinstance", "torch.nn.utils.weight_norm", "logging.debug"], "methods", ["None"], ["", "def", "apply_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Apply weight normalization module from all of the layers.\"\"\"", "\n", "def", "_apply_weight_norm", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv1d", ")", "or", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "logging", ".", "debug", "(", "f\"Weight norm is applied to {m}.\"", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2._get_receptive_field_size": [[377, 384], ["dilation", "range", "sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_receptive_field_size", "(", "layers", ",", "stacks", ",", "kernel_size", ",", "\n", "dilation", "=", "lambda", "x", ":", "2", "**", "x", ")", ":", "\n", "        ", "assert", "layers", "%", "stacks", "==", "0", "\n", "layers_per_cycle", "=", "layers", "//", "stacks", "\n", "dilations", "=", "[", "dilation", "(", "i", "%", "layers_per_cycle", ")", "for", "i", "in", "range", "(", "layers", ")", "]", "\n", "return", "(", "kernel_size", "-", "1", ")", "*", "sum", "(", "dilations", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2.receptive_field_size": [[385, 389], ["Generator.Generator2._get_receptive_field_size"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Generator.Generator2._get_receptive_field_size"], ["", "@", "property", "\n", "def", "receptive_field_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return receptive field size.\"\"\"", "\n", "return", "self", ".", "_get_receptive_field_size", "(", "self", ".", "layers", ",", "self", ".", "stacks", ",", "self", ".", "kernel_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.__init__": [[17, 75], ["super().__init__", "torch.nn.ModuleList", "range", "layers.Conv1d", "Discriminator.Unconditional_Discriminator.apply_weight_norm", "layers.Conv1d", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.apply_weight_norm"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "1", ",", "\n", "out_channels", "=", "1", ",", "\n", "kernel_size", "=", "3", ",", "\n", "layers", "=", "10", ",", "\n", "conv_channels", "=", "64", ",", "\n", "dilation_factor", "=", "1", ",", "\n", "nonlinear_activation", "=", "\"LeakyReLU\"", ",", "\n", "nonlinear_activation_params", "=", "{", "\"negative_slope\"", ":", "0.2", "}", ",", "\n", "bias", "=", "True", ",", "\n", "use_weight_norm", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize Unconditional Discriminator module.\n\n        Args:\n            in_channels (int): Number of input channels.\n            out_channels (int): Number of output channels.\n            kernel_size (int): Number of output channels.\n            layers (int): Number of conv layers.\n            conv_channels (int): Number of chnn layers.\n            dilation_factor (int): Dilation factor. For example, if dilation_factor = 2,\n                the dilation will be 2, 4, 8, ..., and so on.\n            nonlinear_activation (str): Nonlinear function after each conv.\n            nonlinear_activation_params (dict): Nonlinear function parameters\n            bias (bool): Whether to use bias parameter in conv.\n            use_weight_norm (bool) Whether to use weight norm.\n                If set to true, it will be applied to all of the conv layers.\n\n        \"\"\"", "\n", "\n", "super", "(", "Unconditional_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "(", "kernel_size", "-", "1", ")", "%", "2", "==", "0", ",", "\"Not support even number kernel size.\"", "\n", "assert", "dilation_factor", ">", "0", ",", "\"Dilation factor must be > 0.\"", "\n", "self", ".", "conv_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "conv_in_channels", "=", "in_channels", "\n", "for", "i", "in", "range", "(", "layers", "-", "1", ")", ":", "# (B, 1, T) -> (B, 64, T)", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "dilation", "=", "1", "\n", "", "else", ":", "\n", "                ", "dilation", "=", "i", "if", "dilation_factor", "==", "1", "else", "dilation_factor", "**", "i", "\n", "conv_in_channels", "=", "conv_channels", "\n", "", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "*", "dilation", "\n", "conv_layer", "=", "[", "\n", "Conv1d", "(", "conv_in_channels", ",", "conv_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "\n", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "inplace", "=", "True", ",", "**", "nonlinear_activation_params", ")", "\n", "]", "\n", "self", ".", "conv_layers", "+=", "conv_layer", "\n", "", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "\n", "last_conv_layer", "=", "Conv1d", "(", "# (B, 64, T) -> (B, 1, T)", "\n", "conv_in_channels", ",", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", ",", "bias", "=", "bias", ")", "\n", "self", ".", "conv_layers", "+=", "[", "last_conv_layer", "]", "\n", "\n", "# apply weight norm", "\n", "if", "use_weight_norm", ":", "\n", "            ", "self", ".", "apply_weight_norm", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.forward": [[76, 89], ["f"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input noise signal (B, 1, T).\n\n        Returns:\n            Tensor: Output tensor (B, 1, T)\n\n        \"\"\"", "\n", "for", "f", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", "=", "f", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.apply_weight_norm": [[90, 98], ["Discriminator.Unconditional_Discriminator.apply", "isinstance", "isinstance", "torch.nn.utils.weight_norm", "logging.debug"], "methods", ["None"], ["", "def", "apply_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Apply weight normalization module from all of the layers.\"\"\"", "\n", "def", "_apply_weight_norm", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv1d", ")", "or", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "logging", ".", "debug", "(", "f\"Weight norm is applied to {m}.\"", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "_apply_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.remove_weight_norm": [[99, 109], ["Discriminator.Unconditional_Discriminator.apply", "logging.debug", "torch.nn.utils.remove_weight_norm"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.Unconditional_Discriminator.remove_weight_norm"], ["", "def", "remove_weight_norm", "(", "self", ")", ":", "\n", "        ", "\"\"\"Remove weight normalization module from all of the layers.\"\"\"", "\n", "def", "_remove_weight_norm", "(", "m", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "logging", ".", "debug", "(", "f\"Weight norm is removed from {m}.\"", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "remove_weight_norm", "(", "m", ")", "\n", "", "except", "ValueError", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "\n", "", "", "self", ".", "apply", "(", "_remove_weight_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.SingerConditional_Discriminator.__init__": [[114, 188], ["super().__init__", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ModuleList", "min", "torch.nn.Sequential", "min", "torch.nn.Sequential", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Conv1d", "getattr", "numpy.prod", "getattr", "torch.nn.Conv1d", "getattr", "getattr", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ",", "\n", "in_channels", "=", "1", ",", "\n", "out_channels", "=", "256", ",", "\n", "kernel_sizes", "=", "[", "5", ",", "3", "]", ",", "\n", "channels", "=", "16", ",", "\n", "max_downsample_channels", "=", "1024", ",", "\n", "bias", "=", "True", ",", "\n", "downsample_scales", "=", "[", "4", ",", "4", ",", "4", ",", "4", "]", ",", "\n", "nonlinear_activation", "=", "\"LeakyReLU\"", ",", "\n", "nonlinear_activation_params", "=", "{", "\"negative_slope\"", ":", "0.2", "}", ",", "\n", "pad", "=", "\"ReflectionPad1d\"", ",", "\n", "pad_params", "=", "{", "}", ",", "\n", "model_hidden_size", "=", "256", ",", "\n", "model_num_layers", "=", "3", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize SingerConditional Discriminator module.\n        \"\"\"", "\n", "super", "(", "SingerConditional_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lstm", "=", "torch", ".", "nn", ".", "LSTM", "(", "input_size", "=", "model_hidden_size", ",", "\n", "hidden_size", "=", "model_hidden_size", ",", "\n", "num_layers", "=", "model_num_layers", ")", "\n", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "model_hidden_size", ",", "1", ")", "\n", "self", ".", "relu", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "\n", "# add first layer   (B, 1, T) ->  (B, channels, T)", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layers", "+=", "[", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "getattr", "(", "torch", ".", "nn", ",", "pad", ")", "(", "(", "np", ".", "prod", "(", "kernel_sizes", ")", "-", "1", ")", "//", "2", ",", "**", "pad_params", ")", ",", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", ",", "channels", ",", "np", ".", "prod", "(", "kernel_sizes", ")", ",", "bias", "=", "bias", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", ")", "\n", "]", "\n", "\n", "# add downsample layers    (B, channels, T) -> (B, channels*downsample_scale[0], T/downsample_scale[0])", "\n", "# -> ...  -> (B, channels*downsample_scale[0]*...*downsample_scale[3], T/(downsample_scale[0]*...*downsample_scale[3]))", "\n", "# -> ...  -> (B, channels*downsample_scale[0]*...*downsample_scale[3], T/product(downsample_scale))", "\n", "in_chs", "=", "channels", "\n", "for", "downsample_scale", "in", "downsample_scales", ":", "\n", "            ", "out_chs", "=", "min", "(", "in_chs", "*", "downsample_scale", ",", "max_downsample_channels", ")", "\n", "self", ".", "layers", "+=", "[", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "\n", "in_chs", ",", "out_chs", ",", "\n", "kernel_size", "=", "downsample_scale", "*", "10", "+", "1", ",", "\n", "stride", "=", "downsample_scale", ",", "\n", "padding", "=", "downsample_scale", "*", "5", ",", "\n", "groups", "=", "in_chs", "//", "4", ",", "\n", "bias", "=", "bias", ",", "\n", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", ")", "\n", "]", "\n", "in_chs", "=", "out_chs", "\n", "\n", "# add final layers  (B, channels*downsample_scale[0]*...*downsample_scale[3], T/product(downsample_scale)) -> (B, channels*downsample_scale[0]*...*downsample_scale[3], T/product(downsample_scale))", "\n", "", "out_chs", "=", "min", "(", "in_chs", "*", "2", ",", "max_downsample_channels", ")", "\n", "self", ".", "layers", "+=", "[", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "\n", "in_chs", ",", "out_chs", ",", "kernel_sizes", "[", "0", "]", ",", "\n", "padding", "=", "(", "kernel_sizes", "[", "0", "]", "-", "1", ")", "//", "2", ",", "\n", "bias", "=", "bias", ",", "\n", ")", ",", "\n", "getattr", "(", "torch", ".", "nn", ",", "nonlinear_activation", ")", "(", "**", "nonlinear_activation_params", ")", ",", "\n", ")", "\n", "]", "\n", "self", ".", "layers", "+=", "[", "# (B, channels*downsample_scale[0]*...*downsample_scale[3], T/product(downsample_scale)) -> (B, 1,  T/product(downsample_scale))", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "\n", "out_chs", ",", "out_channels", ",", "kernel_sizes", "[", "1", "]", ",", "\n", "padding", "=", "(", "kernel_sizes", "[", "1", "]", "-", "1", ")", "//", "2", ",", "\n", "bias", "=", "bias", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.models.Discriminator.SingerConditional_Discriminator.forward": [[192, 213], ["f.permute", "Discriminator.SingerConditional_Discriminator.lstm", "Discriminator.SingerConditional_Discriminator.relu", "f", "embed.squeeze", "Discriminator.SingerConditional_Discriminator.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "embed", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Input noise signal (B, 1, T).\n            embed (Tensor): Local conditioning auxiliary features (B, C ,1).\n\n        Returns:\n            Tensor: Output tensor (B, out_channels, T)\n\n        \"\"\"", "\n", "\n", "for", "f", "in", "self", ".", "layers", ":", "# (B, 1, T) -> (B, 256, T/prob(downscale))", "\n", "            ", "x", "=", "f", "(", "x", ")", "\n", "\n", "", "frames_batch", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# (B, 256, T/prob(downscale))  -> (seq_len, B, 256)", "\n", "output", ",", "(", "hn", ",", "cn", ")", "=", "self", ".", "lstm", "(", "frames_batch", ")", "# output: (seq_len, batch, model_embedding_size)  hidden: (layers, batch, model_embedding_size)", "\n", "\n", "p", "=", "output", "[", "-", "1", "]", "+", "embed", ".", "squeeze", "(", "2", ")", "# (batch, model_embedding_size) + (batch, model_embedding_size)", "\n", "p", "=", "self", ".", "relu", "(", "self", ".", "linear", "(", "p", ")", ")", "# (batch, 1)", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.load_from_file": [[14, 20], ["numpy.fromfile", "data.reshape.reshape", "RuntimeError", "len"], "function", ["None"], ["def", "load_from_file", "(", "path", ",", "dimension", ")", ":", "\n", "    ", "data", "=", "np", ".", "fromfile", "(", "path", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "if", "len", "(", "data", ")", "%", "dimension", "!=", "0", ":", "\n", "        ", "raise", "RuntimeError", "(", "'%s data size is not divided by %d'", "%", "(", "path", ",", "dimension", ")", ")", "\n", "", "data", "=", "data", ".", "reshape", "(", "[", "-", "1", ",", "dimension", "]", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.save_to_file": [[22, 24], ["data.astype().tofile", "data.astype"], "function", ["None"], ["", "def", "save_to_file", "(", "data", ",", "path", ")", ":", "\n", "    ", "data", ".", "astype", "(", "np", ".", "float32", ")", ".", "tofile", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._lf02vuv": [[26, 62], ["numpy.reshape", "numpy.zeros", "range", "range", "range", "range", "range", "float"], "function", ["None"], ["", "def", "_lf02vuv", "(", "data", ")", ":", "\n", "    ", "'''\n    generate vuv feature by interpolating lf0\n    '''", "\n", "data", "=", "np", ".", "reshape", "(", "data", ",", "(", "data", ".", "size", ",", "1", ")", ")", "\n", "\n", "vuv_vector", "=", "np", ".", "zeros", "(", "(", "data", ".", "size", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "vuv_vector", "[", "data", ">", "0.0", "]", "=", "1.0", "\n", "vuv_vector", "[", "data", "<=", "0.0", "]", "=", "0.0", "\n", "\n", "ip_data", "=", "data", "\n", "\n", "frame_number", "=", "data", ".", "size", "\n", "last_value", "=", "0.0", "\n", "for", "i", "in", "range", "(", "frame_number", ")", ":", "\n", "        ", "if", "data", "[", "i", "]", "<=", "0.0", ":", "\n", "            ", "j", "=", "i", "+", "1", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "frame_number", ")", ":", "\n", "                ", "if", "data", "[", "j", "]", ">", "0.0", ":", "\n", "                    ", "break", "\n", "", "", "if", "j", "<", "frame_number", "-", "1", ":", "\n", "                ", "if", "last_value", ">", "0.0", ":", "\n", "                    ", "step", "=", "(", "data", "[", "j", "]", "-", "data", "[", "i", "-", "1", "]", ")", "/", "float", "(", "j", "-", "i", "+", "1", ")", "\n", "for", "k", "in", "range", "(", "i", ",", "j", ")", ":", "\n", "                        ", "ip_data", "[", "k", "]", "=", "data", "[", "i", "-", "1", "]", "+", "step", "*", "(", "k", "-", "i", "+", "1", ")", "\n", "", "", "else", ":", "\n", "                    ", "for", "k", "in", "range", "(", "i", ",", "j", ")", ":", "\n", "                        ", "ip_data", "[", "k", "]", "=", "data", "[", "j", "]", "\n", "", "", "", "else", ":", "\n", "                ", "for", "k", "in", "range", "(", "i", ",", "frame_number", ")", ":", "\n", "                    ", "ip_data", "[", "k", "]", "=", "last_value", "\n", "", "", "", "else", ":", "\n", "            ", "ip_data", "[", "i", "]", "=", "data", "[", "i", "]", "\n", "last_value", "=", "data", "[", "i", "]", "\n", "\n", "", "", "return", "ip_data", ",", "vuv_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d": [[64, 80], ["kernel.reshape.reshape", "int", "range", "numpy.concatenate", "data_matrix[].reshape", "numpy.pad", "np.concatenate.append", "len", "numpy.correlate().reshape", "numpy.correlate"], "function", ["None"], ["", "def", "_conv1d", "(", "data_matrix", ",", "kernel", ")", ":", "\n", "    ", "'''\n    convolve each column in data_matrix with kernel\n    \u7c7b\u4f3cCNN\u7684\u90a3\u79cd1d\u5377\u79ef\n    '''", "\n", "kernel", "=", "kernel", ".", "reshape", "(", "[", "-", "1", ",", "]", ")", "\n", "kernel_width", "=", "int", "(", "len", "(", "kernel", ")", "/", "2", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "dim", "in", "range", "(", "data_matrix", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "vector", "=", "data_matrix", "[", ":", ",", "dim", "]", ".", "reshape", "(", "[", "-", "1", ",", "]", ")", "\n", "vector", "=", "np", ".", "pad", "(", "vector", ",", "(", "kernel_width", ",", "kernel_width", ")", ",", "'edge'", ")", "\n", "res", ".", "append", "(", "np", ".", "correlate", "(", "vector", ",", "kernel", ",", "mode", "=", "'valid'", ")", ".", "reshape", "(", "[", "-", "1", ",", "1", "]", ")", ")", "\n", "\n", "", "res", "=", "np", ".", "concatenate", "(", "res", ",", "axis", "=", "-", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.extract_feats": [[83, 90], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "extract_feats", "(", "world_analysis", ",", "wav_dir", ",", "feat_dir", ",", "filename", ",", "mgc_dim", "=", "60", ")", ":", "\n", "    ", "world_analysis_cmd", "=", "\"{analyze} {wav} {lf0} {mgc} {bap} {mgc_dim}\"", ".", "format", "(", "analyze", "=", "world_analysis", ",", "\n", "wav", "=", "os", ".", "path", ".", "join", "(", "wav_dir", ",", "filename", "+", "'.wav'", ")", ",", "\n", "lf0", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.lf0'", ")", ",", "\n", "mgc", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.mgc'", ")", ",", "\n", "bap", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.bap'", ")", ",", "\n", "mgc_dim", "=", "mgc_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._merge_feat": [[92, 132], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "audio_world_process.load_from_file", "audio_world_process.load_from_file", "audio_world_process.load_from_file", "mgc_matrix.reshape.reshape", "bap_matrix.reshape.reshape", "audio_world_process._lf02vuv", "numpy.array", "numpy.array", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "np.concatenate.append", "numpy.concatenate", "audio_world_process.save_to_file", "audio_world_process._conv1d", "audio_world_process._conv1d", "audio_world_process._conv1d", "audio_world_process._conv1d", "audio_world_process._conv1d", "audio_world_process._conv1d"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.load_from_file", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.load_from_file", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.load_from_file", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._lf02vuv", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.save_to_file", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process._conv1d"], ["", "def", "_merge_feat", "(", "feat_dir", ",", "out_dir", ",", "filenames", ")", ":", "\n", "    ", "'''\n    merge acoustic features\n    \u6700\u7ec8\u751f\u6210\u7684\u7279\u5f81\u4e3a[lf0, lf0\u4e0edelta\u7684\u5377\u79ef\uff0c lf0\u4e0eacc\u7684\u5377\u79ef\uff0c mgc\uff0c mgc\u4e0edelta\u7684\u5377\u79ef\uff0c mgc\u4e0eacc\u7684\u5377\u79ef\uff0c bap\uff0c bap\u4e0edelta\u7684\u5377\u79ef\uff0c\n    bap\u4e0eacc\u7684\u5377\u79ef\uff0c vuv]\n    '''", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "lf0_path", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.lf0'", ")", "\n", "mgc_path", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.mgc'", ")", "\n", "bap_path", "=", "os", ".", "path", ".", "join", "(", "feat_dir", ",", "filename", "+", "'.bap'", ")", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "filename", "+", "'.cmp'", ")", "\n", "\n", "lf0_matrix", "=", "load_from_file", "(", "lf0_path", ",", "1", ")", "\n", "mgc_matrix", "=", "load_from_file", "(", "mgc_path", ",", "1", ")", "\n", "bap_matrix", "=", "load_from_file", "(", "bap_path", ",", "1", ")", "\n", "\n", "frame_num", "=", "lf0_matrix", ".", "shape", "[", "0", "]", "\n", "mgc_matrix", "=", "mgc_matrix", ".", "reshape", "(", "[", "frame_num", ",", "-", "1", "]", ")", "\n", "bap_matrix", "=", "bap_matrix", ".", "reshape", "(", "[", "frame_num", ",", "-", "1", "]", ")", "\n", "\n", "lf0_matrix", ",", "vuv_matrix", "=", "_lf02vuv", "(", "lf0_matrix", ")", "\n", "\n", "delta_win", "=", "np", ".", "array", "(", "[", "-", "0.5", ",", "0.0", ",", "0.5", "]", ")", "\n", "acc_win", "=", "np", ".", "array", "(", "[", "1.0", ",", "-", "2.0", ",", "1.0", "]", ")", "\n", "res", "=", "[", "]", "\n", "res", ".", "append", "(", "lf0_matrix", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "lf0_matrix", ",", "delta_win", ")", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "lf0_matrix", ",", "acc_win", ")", ")", "\n", "res", ".", "append", "(", "mgc_matrix", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "mgc_matrix", ",", "delta_win", ")", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "mgc_matrix", ",", "acc_win", ")", ")", "\n", "res", ".", "append", "(", "bap_matrix", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "bap_matrix", ",", "delta_win", ")", ")", "\n", "res", ".", "append", "(", "_conv1d", "(", "bap_matrix", ",", "acc_win", ")", ")", "\n", "res", ".", "append", "(", "vuv_matrix", ")", "\n", "res", "=", "np", ".", "concatenate", "(", "res", ",", "axis", "=", "-", "1", ")", "\n", "\n", "save_to_file", "(", "res", ",", "out_path", ")", "\n", "\n", "", "return", "lf0_matrix", ".", "shape", "[", "1", "]", "*", "3", ",", "mgc_matrix", ".", "shape", "[", "1", "]", "*", "3", ",", "bap_matrix", ".", "shape", "[", "1", "]", "*", "3", ",", "vuv_matrix", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.wav_preprocess": [[134, 171], ["logging.getLogger", "logging.getLogger.setLevel", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "list", "os.path.join", "logging.getLogger.info", "multiprocessing.Pool", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "logging.getLogger.info", "multiprocessing.Pool", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "logging.getLogger.info", "set", "multiprocessing.cpu_count", "results.append", "res.get", "multiprocessing.cpu_count", "results.append", "range", "multiprocessing.Pool.apply_async", "multiprocessing.Pool.apply_async", "multiprocessing.cpu_count", "multiprocessing.cpu_count", "filename.split", "os.listdir"], "function", ["None"], ["", "def", "wav_preprocess", "(", "data_dir", ",", "tmp_dir", ",", "world_dir", ")", ":", "\n", "    ", "'''\n    \u4ece\u97f3\u9891\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5e76\u5c06\u4ed6\u4eec\u5408\u8d77\u6765\uff0c\u8ba1\u7b97\u65b0\u7279\u5f81\n    '''", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'preprocess'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "wav_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'wavs'", ")", "\n", "feat_dir", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'feats'", ")", "\n", "cmp_dir", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'cmp'", ")", "\n", "os", ".", "makedirs", "(", "feat_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "cmp_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "filenames", "=", "list", "(", "set", "(", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", "for", "filename", "in", "os", ".", "listdir", "(", "wav_dir", ")", ")", ")", "\n", "split_filenames", "=", "[", "filenames", "[", "i", ":", ":", "cpu_count", "(", ")", "]", "for", "i", "in", "range", "(", "cpu_count", "(", ")", ")", "]", "\n", "world_analysis", "=", "os", ".", "path", ".", "join", "(", "world_dir", ",", "'analysis'", ")", "\n", "\n", "# \u4f7f\u7528world\u63d0\u53d6\u7279\u5f81", "\n", "logger", ".", "info", "(", "'extract feat from wav'", ")", "\n", "p", "=", "Pool", "(", "cpu_count", "(", ")", ")", "\n", "results", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "results", ".", "append", "(", "p", ".", "apply_async", "(", "extract_feats", ",", "args", "=", "[", "world_analysis", ",", "wav_dir", ",", "feat_dir", ",", "filename", "]", ")", ")", "\n", "", "p", ".", "close", "(", ")", "\n", "p", ".", "join", "(", ")", "\n", "results", "=", "[", "res", ".", "get", "(", ")", "for", "res", "in", "results", "]", "\n", "\n", "# \u5c06lf0\uff0cmgc\uff0cbap\u5408\u8d77\u6765\uff0c\u5e76\u5f97\u5230\u65b0\u7279\u5f81", "\n", "logger", ".", "info", "(", "'merge lf0 mgc bap feat'", ")", "\n", "p", "=", "Pool", "(", "cpu_count", "(", ")", ")", "\n", "results", "=", "[", "]", "\n", "for", "filenames", "in", "split_filenames", ":", "\n", "        ", "results", ".", "append", "(", "p", ".", "apply_async", "(", "_merge_feat", ",", "args", "=", "[", "feat_dir", ",", "cmp_dir", ",", "filenames", "]", ")", ")", "\n", "", "p", ".", "close", "(", ")", "\n", "p", ".", "join", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'preprocess wav finish'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.world_feature_extract": [[173, 211], ["FeatureExtractor", "FeatureExtractor.analyze", "FeatureExtractor.codeap", "FeatureExtractor.mcep", "FeatureExtractor.npow", "audio_world_process.convert_continuos_f0", "int", "audio_world_process.low_pass_filter", "numpy.expand_dims", "numpy.expand_dims", "numpy.concatenate", "audio_world_process.low_pass_filter"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.convert_continuos_f0", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.low_pass_filter", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.low_pass_filter"], ["", "def", "world_feature_extract", "(", "wav", ",", "config", ")", ":", "\n", "    ", "\"\"\"WORLD feature extraction\n\n    Args:\n        queue (multiprocessing.Queue): the queue to store the file name of utterance\n        wav_list (list): list of the wav files\n        config (dict): feature extraction config\n\n    \"\"\"", "\n", "# define feature extractor", "\n", "feature_extractor", "=", "FeatureExtractor", "(", "\n", "analyzer", "=", "\"world\"", ",", "\n", "fs", "=", "config", "[", "'sampling_rate'", "]", ",", "\n", "shiftms", "=", "config", "[", "'hop_size'", "]", "/", "config", "[", "'sampling_rate'", "]", "*", "1000", ",", "\n", "minf0", "=", "config", "[", "'minf0'", "]", ",", "\n", "maxf0", "=", "config", "[", "'maxf0'", "]", ",", "\n", "fftl", "=", "config", "[", "'fft_size'", "]", ")", "\n", "# extraction", "\n", "\n", "# extract features", "\n", "f0", ",", "spc", ",", "ap", "=", "feature_extractor", ".", "analyze", "(", "wav", ")", "\n", "codeap", "=", "feature_extractor", ".", "codeap", "(", ")", "\n", "mcep", "=", "feature_extractor", ".", "mcep", "(", "dim", "=", "config", "[", "'mcep_dim'", "]", ",", "alpha", "=", "config", "[", "'mcep_alpha'", "]", ")", "\n", "npow", "=", "feature_extractor", ".", "npow", "(", ")", "\n", "uv", ",", "cont_f0", "=", "convert_continuos_f0", "(", "f0", ")", "\n", "lpf_fs", "=", "int", "(", "config", "[", "'sampling_rate'", "]", "/", "config", "[", "'hop_size'", "]", ")", "\n", "cont_f0_lpf", "=", "low_pass_filter", "(", "cont_f0", ",", "lpf_fs", ",", "cutoff", "=", "20", ")", "\n", "next_cutoff", "=", "70", "\n", "while", "not", "(", "cont_f0_lpf", ">=", "[", "0", "]", ")", ".", "all", "(", ")", ":", "\n", "        ", "cont_f0_lpf", "=", "low_pass_filter", "(", "cont_f0", ",", "lpf_fs", ",", "cutoff", "=", "next_cutoff", ")", "\n", "next_cutoff", "*=", "2", "\n", "# concatenate", "\n", "", "cont_f0_lpf", "=", "np", ".", "expand_dims", "(", "cont_f0_lpf", ",", "axis", "=", "-", "1", ")", "\n", "uv", "=", "np", ".", "expand_dims", "(", "uv", ",", "axis", "=", "-", "1", ")", "\n", "feats", "=", "np", ".", "concatenate", "(", "[", "uv", ",", "cont_f0_lpf", ",", "mcep", ",", "codeap", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# return (feats, f0, ap, spc, npow)", "\n", "return", "feats", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.convert_continuos_f0": [[212, 242], ["numpy.float32", "copy.deepcopy", "scipy.interpolate.interp1d", "scipy.interpolate.interp1d.", "logging.warn", "numpy.where", "numpy.arange", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "convert_continuos_f0", "(", "f0", ")", ":", "\n", "    ", "\"\"\"Convert F0 to continuous F0\n\n    Args:\n        f0 (ndarray): original f0 sequence with the shape (T)\n    Return:\n        (ndarray): continuous f0 with the shape (T)\n\n    \"\"\"", "\n", "# get uv information as binary", "\n", "uv", "=", "np", ".", "float32", "(", "f0", "!=", "0", ")", "\n", "# get start and end of f0", "\n", "if", "(", "f0", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "        ", "logging", ".", "warn", "(", "\"all of the f0 values are 0.\"", ")", "\n", "return", "uv", ",", "f0", "\n", "", "start_f0", "=", "f0", "[", "f0", "!=", "0", "]", "[", "0", "]", "\n", "end_f0", "=", "f0", "[", "f0", "!=", "0", "]", "[", "-", "1", "]", "\n", "# padding start and end of f0 sequence", "\n", "cont_f0", "=", "copy", ".", "deepcopy", "(", "f0", ")", "\n", "start_idx", "=", "np", ".", "where", "(", "cont_f0", "==", "start_f0", ")", "[", "0", "]", "[", "0", "]", "\n", "end_idx", "=", "np", ".", "where", "(", "cont_f0", "==", "end_f0", ")", "[", "0", "]", "[", "-", "1", "]", "\n", "cont_f0", "[", ":", "start_idx", "]", "=", "start_f0", "\n", "cont_f0", "[", "end_idx", ":", "]", "=", "end_f0", "\n", "# get non-zero frame index", "\n", "nz_frames", "=", "np", ".", "where", "(", "cont_f0", "!=", "0", ")", "[", "0", "]", "\n", "# perform linear interpolation", "\n", "f", "=", "interp1d", "(", "nz_frames", ",", "cont_f0", "[", "nz_frames", "]", ")", "\n", "cont_f0", "=", "f", "(", "np", ".", "arange", "(", "0", ",", "cont_f0", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "return", "uv", ",", "cont_f0", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_world_process.low_pass_filter": [[244, 264], ["scipy.signal.firwin", "numpy.pad", "scipy.signal.lfilter"], "function", ["None"], ["", "def", "low_pass_filter", "(", "x", ",", "fs", ",", "cutoff", "=", "70", ",", "padding", "=", "True", ")", ":", "\n", "    ", "\"\"\"Low pass filter\n\n    Args:\n        x (ndarray): Waveform sequence\n        fs (int): Sampling frequency\n        cutoff (float): Cutoff frequency of low pass filter\n    Return:\n        (ndarray): Low pass filtered waveform sequence\n\n    \"\"\"", "\n", "nyquist", "=", "fs", "//", "2", "\n", "norm_cutoff", "=", "cutoff", "/", "nyquist", "\n", "numtaps", "=", "255", "\n", "fil", "=", "firwin", "(", "numtaps", ",", "norm_cutoff", ")", "\n", "x_pad", "=", "np", ".", "pad", "(", "x", ",", "(", "numtaps", ",", "numtaps", ")", ",", "'edge'", ")", "\n", "lpf_x", "=", "lfilter", "(", "fil", ",", "1", ",", "x_pad", ")", "\n", "lpf_x", "=", "lpf_x", "[", "numtaps", "+", "numtaps", "//", "2", ":", "-", "numtaps", "//", "2", "]", "\n", "\n", "return", "lpf_x", "\n", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.load_wav": [[10, 12], ["librosa.core.load", "librosa.core.load"], "function", ["None"], ["def", "load_wav", "(", "path", ",", "sr", ")", ":", "\n", "    ", "return", "librosa", ".", "core", ".", "load", "(", "path", ",", "sr", "=", "sr", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.save_wav": [[14, 25], ["scipy.signal.convolve", "scipy.io.wavfile.write", "max", "numpy.sign", "numpy.power", "scipy.signal.firwin", "signal.convolve.astype", "numpy.abs().max", "numpy.max", "numpy.abs", "numpy.abs", "numpy.abs"], "function", ["None"], ["", "def", "save_wav", "(", "wav", ",", "path", ",", "hparams", ")", ":", "\n", "    ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "0.999", "\n", "f1", "=", "0.5", "*", "32767", "/", "max", "(", "0.01", ",", "np", ".", "max", "(", "np", ".", "abs", "(", "wav", ")", ")", ")", "\n", "f2", "=", "np", ".", "sign", "(", "wav", ")", "*", "np", ".", "power", "(", "np", ".", "abs", "(", "wav", ")", ",", "0.95", ")", "\n", "wav", "=", "f1", "*", "f2", "\n", "wav", "=", "signal", ".", "convolve", "(", "wav", ",", "signal", ".", "firwin", "(", "hparams", "[", "'num_freq'", "]", ",", "\n", "[", "hparams", "[", "'fmin'", "]", ",", "hparams", "[", "'fmax'", "]", "]", ",", "\n", "pass_zero", "=", "False", ",", "\n", "fs", "=", "hparams", "[", "'audio_sample_rate'", "]", ")", ")", "\n", "# proposed by @dsmiller", "\n", "wavfile", ".", "write", "(", "path", ",", "hparams", "[", "'audio_sample_rate'", "]", ",", "wav", ".", "astype", "(", "np", ".", "int16", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.save_wavenet_wav": [[27, 29], ["librosa.output.write_wav", "librosa.output.write_wav"], "function", ["None"], ["", "def", "save_wavenet_wav", "(", "wav", ",", "path", ",", "sr", ")", ":", "\n", "    ", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "wav", ",", "sr", "=", "sr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.save_melGAN_wav": [[31, 35], ["audio.reshape.reshape", "soundfile.write"], "function", ["None"], ["", "def", "save_melGAN_wav", "(", "file_path", ",", "sampling_rate", ",", "audio", ")", ":", "\n", "    ", "audio", "=", "audio", ".", "reshape", "(", "(", "-", "1", ",", ")", ")", "\n", "sf", ".", "write", "(", "file_path", ",", "\n", "audio", ",", "sampling_rate", ",", "\"PCM_16\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.preemphasis": [[37, 39], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "preemphasis", "(", "wav", ",", "k", ")", ":", "\n", "    ", "return", "signal", ".", "lfilter", "(", "[", "1", ",", "-", "k", "]", ",", "[", "1", "]", ",", "wav", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.inv_preemphasis": [[41, 43], ["scipy.signal.lfilter"], "function", ["None"], ["", "def", "inv_preemphasis", "(", "wav", ",", "k", ")", ":", "\n", "    ", "return", "signal", ".", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "k", "]", ",", "wav", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.trim_silence": [[45, 68], ["librosa.effects._signal_to_frame_nonsilent", "librosa.effects._signal_to_frame_nonsilent", "numpy.flatnonzero", "slice", "int", "min", "librosa.core.frames_to_samples", "librosa.core.frames_to_samples", "int", "slice", "tuple", "librosa.core.frames_to_samples", "librosa.core.frames_to_samples"], "function", ["None"], ["", "def", "trim_silence", "(", "wav", ",", "hparams", ",", "only_front", "=", "True", ")", ":", "\n", "    ", "non_silent", "=", "librosa", ".", "effects", ".", "_signal_to_frame_nonsilent", "(", "wav", ",", "\n", "frame_length", "=", "hparams", "[", "'trim_fft_size'", "]", ",", "\n", "hop_length", "=", "hparams", "[", "'trim_hop_size'", "]", ",", "\n", "ref", "=", "np", ".", "max", ",", "\n", "top_db", "=", "hparams", "[", "'trim_top_db'", "]", ")", "\n", "\n", "nonzero", "=", "np", ".", "flatnonzero", "(", "non_silent", ")", "\n", "if", "nonzero", ".", "size", ">", "0", ":", "\n", "# Compute the start and end positions", "\n", "# End position goes one frame past the last non-zero", "\n", "        ", "start", "=", "int", "(", "librosa", ".", "core", ".", "frames_to_samples", "(", "nonzero", "[", "0", "]", ",", "hparams", "[", "'trim_hop_size'", "]", ")", ")", "\n", "end", "=", "min", "(", "wav", ".", "shape", "[", "-", "1", "]", ",", "\n", "int", "(", "librosa", ".", "core", ".", "frames_to_samples", "(", "nonzero", "[", "-", "1", "]", "+", "1", ",", "hparams", "[", "'trim_hop_size'", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "# The signal only contains zeros", "\n", "        ", "start", ",", "end", "=", "0", ",", "0", "\n", "", "if", "only_front", ":", "\n", "        ", "end", "=", "wav", ".", "shape", "[", "0", "]", "\n", "", "full_index", "=", "[", "slice", "(", "None", ")", "]", "*", "wav", ".", "ndim", "\n", "full_index", "[", "-", "1", "]", "=", "slice", "(", "start", ",", "end", ")", "\n", "\n", "return", "wav", "[", "tuple", "(", "full_index", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.get_hop_size": [[70, 76], ["int"], "function", ["None"], ["", "def", "get_hop_size", "(", "hparams", ")", ":", "\n", "    ", "hop_size", "=", "hparams", "[", "'hop_size'", "]", "\n", "if", "hop_size", "is", "None", ":", "\n", "        ", "assert", "hparams", "[", "'frame_shift_ms'", "]", "is", "not", "None", "\n", "hop_size", "=", "int", "(", "hparams", "[", "'frame_shift_ms'", "]", "/", "1000", "*", "hparams", "[", "'sampling_rate'", "]", ")", "\n", "", "return", "hop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.inv_linear_spectrogram": [[78, 88], ["audio_preprocess._db_to_amp", "audio_preprocess.inv_preemphasis", "audio_preprocess._denormalize", "audio_preprocess._griffin_lim"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._db_to_amp", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.inv_preemphasis", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._denormalize", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._griffin_lim"], ["", "def", "inv_linear_spectrogram", "(", "linear_spectrogram", ",", "hparams", ")", ":", "\n", "    ", "'''Converts linear spectrogram to waveform using librosa'''", "\n", "if", "hparams", ".", "signal_normalization", ":", "\n", "        ", "D", "=", "_denormalize", "(", "linear_spectrogram", ",", "hparams", ")", "\n", "", "else", ":", "\n", "        ", "D", "=", "linear_spectrogram", "\n", "\n", "", "S", "=", "_db_to_amp", "(", "D", "+", "hparams", ".", "ref_level_db", ")", "# Convert back to linear", "\n", "\n", "return", "inv_preemphasis", "(", "_griffin_lim", "(", "S", "**", "hparams", ".", "power", ",", "hparams", ")", ",", "hparams", ".", "preemphasis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._griffin_lim": [[90, 101], ["numpy.exp", "numpy.abs().astype", "audio_preprocess._istft", "range", "numpy.exp", "audio_preprocess._istft", "numpy.random.rand", "numpy.abs", "numpy.angle", "audio_preprocess._stft"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._istft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._istft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._stft"], ["", "def", "_griffin_lim", "(", "S", ",", "hparams", ")", ":", "\n", "    ", "'''librosa implementation of Griffin-Lim\n    Based on https://github.com/librosa/librosa/issues/434\n    '''", "\n", "angles", "=", "np", ".", "exp", "(", "2j", "*", "np", ".", "pi", "*", "np", ".", "random", ".", "rand", "(", "*", "S", ".", "shape", ")", ")", "\n", "S_complex", "=", "np", ".", "abs", "(", "S", ")", ".", "astype", "(", "np", ".", "complex", ")", "\n", "y", "=", "_istft", "(", "S_complex", "*", "angles", ",", "hparams", ")", "\n", "for", "i", "in", "range", "(", "hparams", ".", "griffin_lim_iters", ")", ":", "\n", "        ", "angles", "=", "np", ".", "exp", "(", "1j", "*", "np", ".", "angle", "(", "_stft", "(", "y", ",", "hparams", ")", ")", ")", "\n", "y", "=", "_istft", "(", "S_complex", "*", "angles", ",", "hparams", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._stft": [[103, 106], ["librosa.stft", "librosa.stft", "audio_preprocess.get_hop_size"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.get_hop_size"], ["", "def", "_stft", "(", "y", ",", "hparams", ")", ":", "\n", "    ", "return", "librosa", ".", "stft", "(", "y", "=", "y", ",", "n_fft", "=", "hparams", "[", "'fft_size'", "]", ",", "hop_length", "=", "get_hop_size", "(", "hparams", ")", ",", "\n", "win_length", "=", "hparams", "[", "'win_length'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._istft": [[107, 109], ["librosa.istft", "librosa.istft", "audio_preprocess.get_hop_size"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.get_hop_size"], ["", "def", "_istft", "(", "y", ",", "hparams", ")", ":", "\n", "    ", "return", "librosa", ".", "istft", "(", "y", ",", "hop_length", "=", "get_hop_size", "(", "hparams", ")", ",", "win_length", "=", "hparams", "[", "'win_length'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._build_mel_basis": [[115, 119], ["librosa.filters.mel", "librosa.filters.mel"], "function", ["None"], ["def", "_build_mel_basis", "(", "hparams", ")", ":", "\n", "    ", "assert", "hparams", "[", "'fmax'", "]", "<=", "hparams", "[", "'sampling_rate'", "]", "//", "2", "\n", "return", "librosa", ".", "filters", ".", "mel", "(", "hparams", "[", "'sampling_rate'", "]", ",", "hparams", "[", "'fft_size'", "]", ",", "n_mels", "=", "hparams", "[", "'num_mels'", "]", ",", "\n", "fmin", "=", "hparams", "[", "'fmin'", "]", ",", "fmax", "=", "hparams", "[", "'fmax'", "]", ")", "#,norm=None if hparams['use_same_high'] else 1)", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._linear_to_mel": [[121, 126], ["numpy.dot", "audio_preprocess._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._build_mel_basis"], ["", "def", "_linear_to_mel", "(", "spectogram", ",", "hparams", ")", ":", "\n", "    ", "global", "_mel_basis", "\n", "if", "_mel_basis", "is", "None", ":", "\n", "        ", "_mel_basis", "=", "_build_mel_basis", "(", "hparams", ")", "\n", "", "return", "np", ".", "dot", "(", "_mel_basis", ",", "spectogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._mel_to_linear": [[128, 133], ["numpy.maximum", "numpy.linalg.pinv", "numpy.dot", "audio_preprocess._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._build_mel_basis"], ["", "def", "_mel_to_linear", "(", "mel_spectrogram", ",", "hparams", ")", ":", "\n", "    ", "global", "_inv_mel_basis", "\n", "if", "_inv_mel_basis", "is", "None", ":", "\n", "        ", "_inv_mel_basis", "=", "np", ".", "linalg", ".", "pinv", "(", "_build_mel_basis", "(", "hparams", ")", ")", "\n", "", "return", "np", ".", "maximum", "(", "1e-10", ",", "np", ".", "dot", "(", "_inv_mel_basis", ",", "mel_spectrogram", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._amp_to_db": [[135, 138], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "function", ["None"], ["", "def", "_amp_to_db", "(", "x", ",", "hparams", ")", ":", "\n", "    ", "min_level", "=", "np", ".", "exp", "(", "hparams", "[", "'min_level_db'", "]", "/", "20", "*", "np", ".", "log", "(", "10", ")", ")", "# np.log()\u4ee5e\u4e3a\u5e95\uff0cnp.exp()\u8fd4\u56dee\u7684\u5e42\u6b21\u65b9", "\n", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "min_level", ",", "x", ")", ")", "# np.maximum\u9010\u4f4d\u8fd4\u56de\u4e24\u4e2a\u53c2\u6570\u8f83\u5927\u503c", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._db_to_amp": [[140, 142], ["numpy.power"], "function", ["None"], ["", "def", "_db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "(", "x", ")", "*", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._normalize": [[144, 159], ["numpy.clip", "numpy.clip"], "function", ["None"], ["", "def", "_normalize", "(", "S", ",", "hparams", ")", ":", "\n", "    ", "if", "hparams", "[", "'allow_clipping_in_normalization'", "]", ":", "\n", "        ", "if", "hparams", "[", "'symmetric_mels'", "]", ":", "\n", "            ", "return", "np", ".", "clip", "(", "(", "2", "*", "hparams", "[", "'max_abs_value'", "]", ")", "*", "(", "\n", "(", "S", "-", "hparams", "[", "'min_level_db'", "]", ")", "/", "(", "-", "hparams", "[", "'min_level_db'", "]", ")", ")", "-", "hparams", "[", "'max_abs_value'", "]", ",", "\n", "-", "hparams", "[", "'max_abs_value'", "]", ",", "hparams", "[", "'max_abs_value'", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "clip", "(", "hparams", "[", "'max_abs_value'", "]", "*", "(", "(", "S", "-", "hparams", "[", "'min_level_db'", "]", ")", "/", "(", "-", "hparams", "[", "'min_level_db'", "]", ")", ")", ",", "0", ",", "\n", "hparams", "[", "'max_abs_value'", "]", ")", "\n", "\n", "", "", "if", "hparams", "[", "'symmetric_mels'", "]", ":", "\n", "        ", "return", "(", "2", "*", "hparams", "[", "'max_abs_value'", "]", ")", "*", "(", "\n", "(", "S", "-", "hparams", "[", "'min_level_db'", "]", ")", "/", "(", "-", "hparams", "[", "'min_level_db'", "]", ")", ")", "-", "hparams", "[", "'max_abs_value'", "]", "\n", "", "else", ":", "\n", "        ", "return", "hparams", "[", "'max_abs_value'", "]", "*", "(", "(", "S", "-", "hparams", "[", "'min_level_db'", "]", ")", "/", "(", "-", "hparams", "[", "'min_level_db'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._denormalize": [[161, 177], ["numpy.clip", "numpy.clip"], "function", ["None"], ["", "", "def", "_denormalize", "(", "D", ",", "hparams", ")", ":", "\n", "    ", "if", "hparams", "[", "'allow_clipping_in_normalization'", "]", ":", "\n", "        ", "if", "hparams", "[", "'symmetric_mels'", "]", ":", "\n", "            ", "return", "(", "(", "(", "np", ".", "clip", "(", "D", ",", "-", "hparams", "[", "'max_abs_value'", "]", ",", "\n", "hparams", "[", "'max_abs_value'", "]", ")", "+", "hparams", "[", "'max_abs_value'", "]", ")", "*", "-", "hparams", "[", "'min_level_db'", "]", "/", "(", "\n", "2", "*", "hparams", "[", "'max_abs_value'", "]", ")", ")", "\n", "+", "hparams", "[", "'min_level_db'", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "(", "np", ".", "clip", "(", "D", ",", "0", ",", "\n", "hparams", "[", "'max_abs_value'", "]", ")", "*", "-", "hparams", "[", "'min_level_db'", "]", "/", "hparams", "[", "'max_abs_value'", "]", ")", "+", "hparams", "[", "'min_level_db'", "]", ")", "\n", "\n", "", "", "if", "hparams", "[", "'symmetric_mels'", "]", ":", "\n", "        ", "return", "(", "(", "(", "D", "+", "hparams", "[", "'max_abs_value'", "]", ")", "*", "-", "hparams", "[", "'min_level_db'", "]", "/", "(", "\n", "2", "*", "hparams", "[", "'max_abs_value'", "]", ")", ")", "+", "hparams", "[", "'min_level_db'", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "(", "D", "*", "-", "hparams", "[", "'min_level_db'", "]", "/", "hparams", "[", "'max_abs_value'", "]", ")", "+", "hparams", "[", "'min_level_db'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.linearspectrogram": [[179, 188], ["audio_preprocess._stft", "audio_preprocess.preemphasis", "audio_preprocess._amp_to_db", "audio_preprocess._normalize", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.preemphasis", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._amp_to_db", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._normalize"], ["", "", "def", "linearspectrogram", "(", "wav", ",", "hparams", ")", ":", "\n", "    ", "if", "hparams", "[", "'preemphasis'", "]", ":", "\n", "        ", "wav", "=", "preemphasis", "(", "wav", ",", "hparams", "[", "'preemphasis_value'", "]", ")", "\n", "", "D", "=", "_stft", "(", "wav", ",", "hparams", ")", "\n", "S", "=", "_amp_to_db", "(", "np", ".", "abs", "(", "D", ")", ",", "hparams", ")", "-", "hparams", "[", "'ref_level_db'", "]", "\n", "\n", "if", "hparams", "[", "'signal_normalization'", "]", ":", "\n", "        ", "return", "_normalize", "(", "S", ",", "hparams", ")", "\n", "", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.melspectrogram": [[190, 199], ["audio_preprocess._stft", "audio_preprocess.preemphasis", "audio_preprocess._amp_to_db", "audio_preprocess._normalize", "audio_preprocess._linear_to_mel", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.preemphasis", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._amp_to_db", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._normalize", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._linear_to_mel"], ["", "def", "melspectrogram", "(", "wav", ",", "hparams", ")", ":", "\n", "    ", "if", "hparams", "[", "'preemphasis'", "]", ":", "\n", "        ", "wav", "=", "preemphasis", "(", "wav", ",", "hparams", "[", "'preemphasis_value'", "]", ")", "\n", "", "D", "=", "_stft", "(", "wav", ",", "hparams", ")", "\n", "S", "=", "_amp_to_db", "(", "_linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ",", "hparams", ")", ",", "hparams", ")", "-", "hparams", "[", "'ref_level_db'", "]", "\n", "\n", "if", "hparams", "[", "'signal_normalization'", "]", ":", "\n", "        ", "return", "_normalize", "(", "S", ",", "hparams", ")", "\n", "", "return", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.logmelfilterbank": [[201, 213], ["librosa.stft", "librosa.stft", "librosa.filters.mel", "librosa.filters.mel", "numpy.abs", "numpy.log10", "numpy.maximum", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft"], ["", "def", "logmelfilterbank", "(", "audio", ",", "config", ",", "eps", "=", "1e-10", ")", ":", "\n", "\n", "    ", "x_stft", "=", "librosa", ".", "stft", "(", "audio", ",", "n_fft", "=", "config", "[", "\"fft_size\"", "]", ",", "hop_length", "=", "config", "[", "\"hop_size\"", "]", ",", "# stft\u53d8\u6362", "\n", "win_length", "=", "config", "[", "\"win_length\"", "]", ",", "window", "=", "config", "[", "\"window\"", "]", ",", "pad_mode", "=", "\"reflect\"", ")", "\n", "spc", "=", "np", ".", "abs", "(", "x_stft", ")", ".", "T", "# (#frames, #bins)", "\n", "\n", "# get mel basis  \u5f97\u5230mel\u504f\u79fb\u91cf", "\n", "mel_basis", "=", "librosa", ".", "filters", ".", "mel", "(", "sr", "=", "config", "[", "\"sampling_rate\"", "]", ",", "n_fft", "=", "config", "[", "\"fft_size\"", "]", ",", "\n", "n_mels", "=", "config", "[", "\"num_mels\"", "]", ",", "fmin", "=", "config", "[", "\"fmin\"", "]", ",", "fmax", "=", "config", "[", "\"fmax\"", "]", ")", "\n", "# norm=None if config['use_same_high_mel'] else 1)", "\n", "\n", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "eps", ",", "np", ".", "dot", "(", "spc", ",", "mel_basis", ".", "T", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.inv_mel_spectrogram": [[231, 241], ["audio_preprocess._mel_to_linear", "audio_preprocess.inv_preemphasis", "audio_preprocess._denormalize", "audio_preprocess._db_to_amp", "audio_preprocess._griffin_lim"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._mel_to_linear", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.inv_preemphasis", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._denormalize", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._db_to_amp", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess._griffin_lim"], ["", "def", "inv_mel_spectrogram", "(", "mel_spectrogram", ",", "hparams", ")", ":", "\n", "    ", "'''Converts mel spectrogram to waveform using librosa'''", "\n", "if", "hparams", "[", "'signal_normalization'", "]", ":", "\n", "        ", "D", "=", "_denormalize", "(", "mel_spectrogram", ",", "hparams", ")", "\n", "", "else", ":", "\n", "        ", "D", "=", "mel_spectrogram", "\n", "\n", "", "S", "=", "_mel_to_linear", "(", "_db_to_amp", "(", "D", "+", "hparams", "[", "'ref_level_db'", "]", ")", ",", "hparams", ")", "# Convert back to linear", "\n", "\n", "return", "inv_preemphasis", "(", "_griffin_lim", "(", "S", "**", "hparams", "[", "'power'", "]", ",", "hparams", ")", ",", "hparams", "[", "'preemphasis'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.encode_mu_law": [[244, 248], ["numpy.floor", "numpy.log", "numpy.sign", "numpy.log", "numpy.abs"], "function", ["None"], ["", "def", "encode_mu_law", "(", "x", ",", "mu", ")", ":", "\n", "    ", "mu", "=", "mu", "-", "1", "\n", "fx", "=", "np", ".", "sign", "(", "x", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "x", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "return", "np", ".", "floor", "(", "(", "fx", "+", "1", ")", "/", "2", "*", "mu", "+", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.decode_mu_law": [[249, 255], ["audio_preprocess.label_2_float", "math.log2", "numpy.sign", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.label_2_float"], ["", "def", "decode_mu_law", "(", "y", ",", "mu", ",", "from_labels", "=", "True", ")", ":", "\n", "# TODO : get rid of log2 - makes no sense", "\n", "    ", "if", "from_labels", ":", "y", "=", "label_2_float", "(", "y", ",", "math", ".", "log2", "(", "mu", ")", ")", "\n", "mu", "=", "mu", "-", "1", "\n", "x", "=", "np", ".", "sign", "(", "y", ")", "/", "mu", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "y", ")", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.float_2_label": [[256, 260], ["x.clip", "abs().max", "abs"], "function", ["None"], ["", "def", "float_2_label", "(", "x", ",", "bits", ")", ":", "\n", "    ", "assert", "abs", "(", "x", ")", ".", "max", "(", ")", "<=", "1.0", "\n", "x", "=", "(", "x", "+", "1.", ")", "*", "(", "2", "**", "bits", "-", "1", ")", "/", "2", "\n", "return", "x", ".", "clip", "(", "0", ",", "2", "**", "bits", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.label_2_float": [[261, 263], ["None"], "function", ["None"], ["", "def", "label_2_float", "(", "x", ",", "bits", ")", ":", "\n", "    ", "return", "2", "*", "x", "/", "(", "2", "**", "bits", "-", "1.", ")", "-", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.num_frames": [[265, 274], ["None"], "function", ["None"], ["", "def", "num_frames", "(", "length", ",", "fsize", ",", "fshift", ")", ":", "\n", "    ", "\"\"\"Compute number of time frames of spectrogram\n    \"\"\"", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "if", "length", "%", "fshift", "==", "0", ":", "\n", "        ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "1", "\n", "", "else", ":", "\n", "        ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "2", "\n", "", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.pad_lr": [[276, 284], ["audio_preprocess.num_frames", "len", "len"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.num_frames"], ["", "def", "pad_lr", "(", "x", ",", "fsize", ",", "fshift", ")", ":", "\n", "    ", "\"\"\"Compute left and right padding\n    \"\"\"", "\n", "M", "=", "num_frames", "(", "len", "(", "x", ")", ",", "fsize", ",", "fshift", ")", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "T", "=", "len", "(", "x", ")", "+", "2", "*", "pad", "\n", "r", "=", "(", "M", "-", "1", ")", "*", "fshift", "+", "fsize", "-", "T", "\n", "return", "pad", ",", "pad", "+", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.plot_spec": [[289, 302], ["matplotlib.figure", "matplotlib.pcolor", "plt.figure.colorbar", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["def", "plot_spec", "(", "spec", ",", "path", ",", "info", "=", "None", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "14", ",", "7", ")", ")", "\n", "heatmap", "=", "plt", ".", "pcolor", "(", "spec", ")", "\n", "fig", ".", "colorbar", "(", "heatmap", ")", "\n", "\n", "xlabel", "=", "'Time'", "\n", "if", "info", "is", "not", "None", ":", "\n", "        ", "xlabel", "+=", "'\\n\\n'", "+", "info", "\n", "", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "plt", ".", "ylabel", "(", "'Mel filterbank'", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "path", ",", "format", "=", "'png'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.dynamic_range_compression": [[304, 311], ["numpy.log", "numpy.clip"], "function", ["None"], ["", "def", "dynamic_range_compression", "(", "x", ",", "C", "=", "1", ",", "clip_val", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\"\n    PARAMS\n    ------\n    C: compression factor\n    \"\"\"", "\n", "return", "np", ".", "log", "(", "np", ".", "clip", "(", "x", ",", "a_min", "=", "clip_val", ",", "a_max", "=", "None", ")", "*", "C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.dynamic_range_decompression": [[312, 319], ["numpy.exp"], "function", ["None"], ["", "def", "dynamic_range_decompression", "(", "x", ",", "C", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    PARAMS\n    ------\n    C: compression factor used to compress\n    \"\"\"", "\n", "return", "np", ".", "exp", "(", "x", ")", "/", "C", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.pitchfeats": [[321, 336], ["librosa.piptrack", "librosa.piptrack", "numpy.asarray", "enumerate", "audio_preprocess.find_f0"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.find_f0"], ["", "def", "pitchfeats", "(", "wav", ",", "hparams", ")", ":", "# \u63d0\u53d6pitch\u7279\u5f81", "\n", "\n", "    ", "pitches", ",", "magnitudes", "=", "librosa", ".", "piptrack", "(", "wav", ",", "hparams", "[", "'sampling_rate'", "]", ",", "\n", "n_fft", "=", "hparams", "[", "'fft_size'", "]", ",", "\n", "hop_length", "=", "hparams", "[", "'hop_size'", "]", ",", "\n", "fmin", "=", "hparams", "[", "'fmin'", "]", ",", "\n", "fmax", "=", "2000", ",", "\n", "win_length", "=", "hparams", "[", "'win_length'", "]", ")", "\n", "pitches", "=", "pitches", ".", "T", "\n", "magnitudes", "=", "magnitudes", ".", "T", "\n", "assert", "pitches", ".", "shape", "==", "magnitudes", ".", "shape", "\n", "\n", "pitches", "=", "[", "pitches", "[", "i", "]", "[", "find_f0", "(", "magnitudes", "[", "i", "]", ")", "]", "for", "i", ",", "_", "in", "enumerate", "(", "pitches", ")", "]", "# \u5bfb\u627epitches\u4e8c\u7ef4\u5411\u91cf\u4e2d\u6700\u5927\u503c", "\n", "\n", "return", "np", ".", "asarray", "(", "pitches", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.find_f0": [[338, 352], ["list", "enumerate", "list.index", "max"], "function", ["None"], ["", "def", "find_f0", "(", "mags", ")", ":", "\n", "    ", "tmp", "=", "0", "\n", "mags", "=", "list", "(", "mags", ")", "\n", "for", "i", ",", "mag", "in", "enumerate", "(", "mags", ")", ":", "\n", "        ", "if", "mag", "<", "tmp", ":", "# \u82e5\u8d4b\u503c<0:", "\n", "# return i-1", "\n", "            ", "if", "tmp", "-", "mag", ">", "2", ":", "# \u82e5\u8d4b\u503c<2+tmp", "\n", "#return i-1", "\n", "                ", "return", "mags", ".", "index", "(", "max", "(", "mags", "[", "0", ":", "i", "]", ")", ")", "#\u8fd4\u56de\u6700\u5927\u503c\u6240\u5728\u4e0b\u4e0b\u6807", "\n", "", "else", ":", "\n", "                ", "return", "0", "\n", "", "", "else", ":", "# \u82e5\u8d4b\u503c>0:\u4ee4tmp = mag", "\n", "            ", "tmp", "=", "mag", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.frontend.audio_preprocess.f0_to_coarse": [[354, 369], ["numpy.rint().astype", "numpy.log", "numpy.log", "numpy.log", "numpy.rint", "numpy.max", "numpy.min"], "function", ["None"], ["", "def", "f0_to_coarse", "(", "f0", ",", "f0_min", "=", "35", ",", "f0_max", "=", "1400", ",", "f0_bin", "=", "256", ")", ":", "\n", "\n", "    ", "f0_mel", "=", "1127", "*", "np", ".", "log", "(", "1", "+", "f0", "/", "700", ")", "\n", "f0_mel_min", "=", "1127", "*", "np", ".", "log", "(", "1", "+", "f0_min", "/", "700", ")", "\n", "f0_mel_max", "=", "1127", "*", "np", ".", "log", "(", "1", "+", "f0_max", "/", "700", ")", "\n", "# f0_mel[f0_mel == 0] = 0", "\n", "# \u5927\u4e8e0\u7684\u5206\u4e3a255\u4e2a\u7bb1", "\n", "f0_mel", "[", "f0_mel", ">", "0", "]", "=", "(", "f0_mel", "[", "f0_mel", ">", "0", "]", "-", "f0_mel_min", ")", "*", "(", "f0_bin", "-", "2", ")", "/", "(", "f0_mel_max", "-", "f0_mel_min", ")", "+", "1", "\n", "\n", "f0_mel", "[", "f0_mel", "<", "0", "]", "=", "1", "\n", "f0_mel", "[", "f0_mel", ">", "f0_bin", "-", "1", "]", "=", "f0_bin", "-", "1", "\n", "f0_coarse", "=", "np", ".", "rint", "(", "f0_mel", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "# print('Max f0', np.max(f0_coarse), ' ||Min f0', np.min(f0_coarse))", "\n", "assert", "(", "np", ".", "max", "(", "f0_coarse", ")", "<=", "256", "and", "np", ".", "min", "(", "f0_coarse", ")", ">=", "0", ")", "\n", "return", "f0_coarse", "\n", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.SpectralConvergenceLoss.__init__": [[45, 48], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initilize spectral convergence loss module.\"\"\"", "\n", "super", "(", "SpectralConvergenceLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.SpectralConvergenceLoss.forward": [[49, 61], ["torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_mag", ",", "y_mag", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x_mag (Tensor): Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).\n            y_mag (Tensor): Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).\n\n        Returns:\n            Tensor: Spectral convergence loss value.\n\n        \"\"\"", "\n", "return", "torch", ".", "norm", "(", "y_mag", "-", "x_mag", ",", "p", "=", "\"fro\"", ")", "/", "torch", ".", "norm", "(", "y_mag", ",", "p", "=", "\"fro\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.LogSTFTMagnitudeLoss.__init__": [[66, 69], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initilize los STFT magnitude loss module.\"\"\"", "\n", "super", "(", "LogSTFTMagnitudeLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.LogSTFTMagnitudeLoss.forward": [[70, 82], ["torch.l1_loss", "torch.l1_loss", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_mag", ",", "y_mag", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x_mag (Tensor): Magnitude spectrogram of predicted signal (B, #frames, #freq_bins).\n            y_mag (Tensor): Magnitude spectrogram of groundtruth signal (B, #frames, #freq_bins).\n\n        Returns:\n            Tensor: Log STFT magnitude loss value.\n\n        \"\"\"", "\n", "return", "F", ".", "l1_loss", "(", "torch", ".", "log", "(", "y_mag", ")", ",", "torch", ".", "log", "(", "x_mag", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.STFTLoss.__init__": [[87, 99], ["super().__init__", "stft_loss.SpectralConvergenceLoss", "stft_loss.LogSTFTMagnitudeLoss", "stft_loss.STFTLoss.register_buffer", "getattr"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "\n", "self", ",", "fft_size", "=", "1024", ",", "shift_size", "=", "120", ",", "win_length", "=", "600", ",", "window", "=", "\"hann_window\"", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize STFT loss module.\"\"\"", "\n", "super", "(", "STFTLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fft_size", "=", "fft_size", "\n", "self", ".", "shift_size", "=", "shift_size", "\n", "self", ".", "win_length", "=", "win_length", "\n", "self", ".", "spectral_convergence_loss", "=", "SpectralConvergenceLoss", "(", ")", "\n", "self", ".", "log_stft_magnitude_loss", "=", "LogSTFTMagnitudeLoss", "(", ")", "\n", "# NOTE(kan-bayashi): Use register_buffer to fix #223", "\n", "self", ".", "register_buffer", "(", "\"window\"", ",", "getattr", "(", "torch", ",", "window", ")", "(", "win_length", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.STFTLoss.forward": [[100, 118], ["stft_loss.stft", "stft_loss.stft", "stft_loss.STFTLoss.spectral_convergence_loss", "stft_loss.STFTLoss.log_stft_magnitude_loss"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Predicted signal (B, T).\n            y (Tensor): Groundtruth signal (B, T).\n\n        Returns:\n            Tensor: Spectral convergence loss value.\n            Tensor: Log STFT magnitude loss value.\n\n        \"\"\"", "\n", "x_mag", "=", "stft", "(", "x", ",", "self", ".", "fft_size", ",", "self", ".", "shift_size", ",", "self", ".", "win_length", ",", "self", ".", "window", ")", "\n", "y_mag", "=", "stft", "(", "y", ",", "self", ".", "fft_size", ",", "self", ".", "shift_size", ",", "self", ".", "win_length", ",", "self", ".", "window", ")", "\n", "sc_loss", "=", "self", ".", "spectral_convergence_loss", "(", "x_mag", ",", "y_mag", ")", "\n", "mag_loss", "=", "self", ".", "log_stft_magnitude_loss", "(", "x_mag", ",", "y_mag", ")", "\n", "\n", "return", "sc_loss", ",", "mag_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__": [[123, 144], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "zip", "len", "len", "len", "stft_loss.STFTLoss"], "methods", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fft_sizes", "=", "[", "1024", ",", "2048", ",", "512", "]", ",", "\n", "hop_sizes", "=", "[", "120", ",", "240", ",", "50", "]", ",", "\n", "win_lengths", "=", "[", "600", ",", "1200", ",", "240", "]", ",", "\n", "window", "=", "\"hann_window\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize Multi resolution STFT loss module.\n\n        Args:\n            fft_sizes (list): List of FFT sizes.\n            hop_sizes (list): List of hop sizes.\n            win_lengths (list): List of window lengths.\n            window (str): Window function type.\n\n        \"\"\"", "\n", "super", "(", "MultiResolutionSTFTLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "fft_sizes", ")", "==", "len", "(", "hop_sizes", ")", "==", "len", "(", "win_lengths", ")", "\n", "self", ".", "stft_losses", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "fs", ",", "ss", ",", "wl", "in", "zip", "(", "fft_sizes", ",", "hop_sizes", ",", "win_lengths", ")", ":", "\n", "            ", "self", ".", "stft_losses", "+=", "[", "STFTLoss", "(", "fs", ",", "ss", ",", "wl", ",", "window", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.MultiResolutionSTFTLoss.forward": [[145, 167], ["len", "len", "f"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"Calculate forward propagation.\n\n        Args:\n            x (Tensor): Predicted signal (B, T).\n            y (Tensor): Groundtruth signal (B, T).\n\n        Returns:\n            Tensor: Multi resolution spectral convergence loss value.\n            Tensor: Multi resolution log STFT magnitude loss value.\n\n        \"\"\"", "\n", "sc_loss", "=", "0.0", "\n", "mag_loss", "=", "0.0", "\n", "for", "f", "in", "self", ".", "stft_losses", ":", "\n", "            ", "sc_l", ",", "mag_l", "=", "f", "(", "x", ",", "y", ")", "\n", "sc_loss", "+=", "sc_l", "\n", "mag_loss", "+=", "mag_l", "\n", "", "sc_loss", "/=", "len", "(", "self", ".", "stft_losses", ")", "\n", "mag_loss", "/=", "len", "(", "self", ".", "stft_losses", ")", "\n", "\n", "return", "sc_loss", ",", "mag_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft": [[15, 40], ["torch.sqrt().transpose", "torch.sqrt().transpose", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.sqrt", "torch.sqrt", "torch.clamp", "torch.clamp"], "function", ["home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft", "home.repos.pwc.inspect_result.Rongjiehuang_Multi-Singer.losses.stft_loss.stft"], ["def", "stft", "(", "x", ",", "fft_size", ",", "hop_size", ",", "win_length", ",", "window", ")", ":", "\n", "    ", "\"\"\"Perform STFT and convert to magnitude spectrogram.\n\n    Args:\n        x (Tensor): Input signal tensor (B, T).\n        fft_size (int): FFT size.\n        hop_size (int): Hop size.\n        win_length (int): Window length.\n        window (str): Window function type.\n\n    Returns:\n        Tensor: Magnitude spectrogram (B, #frames, fft_size // 2 + 1).\n\n    \"\"\"", "\n", "if", "is_pytorch_17plus", ":", "\n", "        ", "x_stft", "=", "torch", ".", "stft", "(", "\n", "x", ",", "fft_size", ",", "hop_size", ",", "win_length", ",", "window", ",", "return_complex", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "        ", "x_stft", "=", "torch", ".", "stft", "(", "x", ",", "fft_size", ",", "hop_size", ",", "win_length", ",", "window", ")", "\n", "", "real", "=", "x_stft", "[", "...", ",", "0", "]", "\n", "imag", "=", "x_stft", "[", "...", ",", "1", "]", "\n", "\n", "# NOTE(kan-bayashi): clamp is needed to avoid nan or inf", "\n", "return", "torch", ".", "sqrt", "(", "torch", ".", "clamp", "(", "real", "**", "2", "+", "imag", "**", "2", ",", "min", "=", "1e-7", ")", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n"]]}