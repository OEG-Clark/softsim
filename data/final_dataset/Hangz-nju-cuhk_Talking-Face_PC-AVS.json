{"home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.video_concat": [[12, 24], ["len", "os.system", "inference.video_add_audio", "str", "str", "str", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.video_add_audio"], ["def", "video_concat", "(", "processed_file_savepath", ",", "name", ",", "video_names", ",", "audio_path", ")", ":", "\n", "    ", "cmd", "=", "[", "'ffmpeg'", "]", "\n", "num_inputs", "=", "len", "(", "video_names", ")", "\n", "for", "video_name", "in", "video_names", ":", "\n", "        ", "cmd", "+=", "[", "'-i'", ",", "'\\''", "+", "str", "(", "os", ".", "path", ".", "join", "(", "processed_file_savepath", ",", "video_name", "+", "'.mp4'", ")", ")", "+", "'\\''", ",", "]", "\n", "\n", "", "cmd", "+=", "[", "'-filter_complex hstack=inputs='", "+", "str", "(", "num_inputs", ")", ",", "\n", "'\\''", "+", "str", "(", "os", ".", "path", ".", "join", "(", "processed_file_savepath", ",", "name", "+", "'.mp4'", ")", ")", "+", "'\\''", ",", "'-loglevel error -y'", "]", "\n", "cmd", "=", "' '", ".", "join", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "video_add_audio", "(", "name", ",", "audio_path", ",", "processed_file_savepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.video_add_audio": [[26, 36], ["os.system", "os.system", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "video_add_audio", "(", "name", ",", "audio_path", ",", "processed_file_savepath", ")", ":", "\n", "    ", "os", ".", "system", "(", "'cp {} {}'", ".", "format", "(", "audio_path", ",", "processed_file_savepath", ")", ")", "\n", "cmd", "=", "[", "'ffmpeg'", ",", "'-i'", ",", "'\\''", "+", "os", ".", "path", ".", "join", "(", "processed_file_savepath", ",", "name", "+", "'.mp4'", ")", "+", "'\\''", ",", "\n", "'-i'", ",", "audio_path", ",", "\n", "'-q:v 0'", ",", "\n", "'-strict -2'", ",", "\n", "'\\''", "+", "os", ".", "path", ".", "join", "(", "processed_file_savepath", ",", "'av'", "+", "name", "+", "'.mp4'", ")", "+", "'\\''", ",", "\n", "'-loglevel error -y'", "]", "\n", "cmd", "=", "' '", ".", "join", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.img2video": [[38, 43], ["os.system"], "function", ["None"], ["", "def", "img2video", "(", "dst_path", ",", "prefix", ",", "video_path", ")", ":", "\n", "    ", "cmd", "=", "[", "'ffmpeg'", ",", "'-i'", ",", "'\\''", "+", "video_path", "+", "'/'", "+", "prefix", "+", "'%d.jpg'", "\n", "+", "'\\''", ",", "'-q:v 0'", ",", "'\\''", "+", "dst_path", "+", "'/'", "+", "prefix", "+", "'.mp4'", "+", "'\\''", ",", "'-loglevel error -y'", "]", "\n", "cmd", "=", "' '", ".", "join", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.inference_single_audio": [[45, 90], ["data.create_dataloader", "data.create_dataloader.dataset.get_processed_file_savepath", "os.path.isdir", "tqdm.tqdm", "print", "video_names.pop", "os.path.join", "util.mkdir", "save_paths.append", "model.forward", "range", "enumerate", "inference.video_concat", "len", "util.save_torch_img", "inference.img2video", "os.path.join", "util.save_torch_img", "util.save_torch_img", "util.save_torch_img", "util.save_torch_img", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.create_dataloader", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.get_processed_file_savepath", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.video_concat", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.img2video", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img"], ["", "def", "inference_single_audio", "(", "opt", ",", "path_label", ",", "model", ")", ":", "\n", "#", "\n", "    ", "opt", ".", "path_label", "=", "path_label", "\n", "dataloader", "=", "data", ".", "create_dataloader", "(", "opt", ")", "\n", "processed_file_savepath", "=", "dataloader", ".", "dataset", ".", "get_processed_file_savepath", "(", ")", "\n", "\n", "idx", "=", "0", "\n", "if", "opt", ".", "driving_pose", ":", "\n", "        ", "video_names", "=", "[", "'Input_'", ",", "'G_Pose_Driven_'", ",", "'Pose_Source_'", ",", "'Mouth_Source_'", "]", "\n", "", "else", ":", "\n", "        ", "video_names", "=", "[", "'Input_'", ",", "'G_Fix_Pose_'", ",", "'Mouth_Source_'", "]", "\n", "", "is_mouth_frame", "=", "os", ".", "path", ".", "isdir", "(", "dataloader", ".", "dataset", ".", "mouth_frame_path", ")", "\n", "if", "not", "is_mouth_frame", ":", "\n", "        ", "video_names", ".", "pop", "(", ")", "\n", "", "save_paths", "=", "[", "]", "\n", "for", "name", "in", "video_names", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "join", "(", "processed_file_savepath", ",", "name", ")", "\n", "util", ".", "mkdir", "(", "save_path", ")", "\n", "save_paths", ".", "append", "(", "save_path", ")", "\n", "", "for", "data_i", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "# print('==============', i, '===============')", "\n", "        ", "fake_image_original_pose_a", ",", "fake_image_driven_pose_a", "=", "model", ".", "forward", "(", "data_i", ",", "mode", "=", "'inference'", ")", "\n", "\n", "for", "num", "in", "range", "(", "len", "(", "fake_image_driven_pose_a", ")", ")", ":", "\n", "            ", "util", ".", "save_torch_img", "(", "data_i", "[", "'input'", "]", "[", "num", "]", ",", "os", ".", "path", ".", "join", "(", "save_paths", "[", "0", "]", ",", "video_names", "[", "0", "]", "+", "str", "(", "idx", ")", "+", "'.jpg'", ")", ")", "\n", "if", "opt", ".", "driving_pose", ":", "\n", "                ", "util", ".", "save_torch_img", "(", "fake_image_driven_pose_a", "[", "num", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_paths", "[", "1", "]", ",", "video_names", "[", "1", "]", "+", "str", "(", "idx", ")", "+", "'.jpg'", ")", ")", "\n", "util", ".", "save_torch_img", "(", "data_i", "[", "'driving_pose_frames'", "]", "[", "num", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_paths", "[", "2", "]", ",", "video_names", "[", "2", "]", "+", "str", "(", "idx", ")", "+", "'.jpg'", ")", ")", "\n", "", "else", ":", "\n", "                ", "util", ".", "save_torch_img", "(", "fake_image_original_pose_a", "[", "num", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_paths", "[", "1", "]", ",", "video_names", "[", "1", "]", "+", "str", "(", "idx", ")", "+", "'.jpg'", ")", ")", "\n", "", "if", "is_mouth_frame", ":", "\n", "                ", "util", ".", "save_torch_img", "(", "data_i", "[", "'target'", "]", "[", "num", "]", ",", "os", ".", "path", ".", "join", "(", "save_paths", "[", "-", "1", "]", ",", "video_names", "[", "-", "1", "]", "+", "str", "(", "idx", ")", "+", "'.jpg'", ")", ")", "\n", "", "idx", "+=", "1", "\n", "\n", "", "", "if", "opt", ".", "gen_video", ":", "\n", "        ", "for", "i", ",", "video_name", "in", "enumerate", "(", "video_names", ")", ":", "\n", "            ", "img2video", "(", "processed_file_savepath", ",", "video_name", ",", "save_paths", "[", "i", "]", ")", "\n", "", "video_concat", "(", "processed_file_savepath", ",", "'concat'", ",", "video_names", ",", "dataloader", ".", "dataset", ".", "audio_path", ")", "\n", "\n", "", "print", "(", "'results saved...'", "+", "processed_file_savepath", ")", "\n", "del", "dataloader", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.main": [[92, 114], ["options.test_options.TestOptions().parse", "torch.manual_seed", "models.create_model().cuda", "create_model().cuda.eval", "enumerate", "open", "f.read().splitlines", "options.test_options.TestOptions", "models.create_model", "inference.inference_single_audio", "f.read", "len", "traceback.print_exc", "print", "print", "path_label.split", "str"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.parse", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.create_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.None.inference.inference_single_audio"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "opt", "=", "TestOptions", "(", ")", ".", "parse", "(", ")", "\n", "opt", ".", "isTrain", "=", "False", "\n", "torch", ".", "manual_seed", "(", "0", ")", "\n", "model", "=", "create_model", "(", "opt", ")", ".", "cuda", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "open", "(", "opt", ".", "meta_path_vox", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "for", "clip_idx", ",", "path_label", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "assert", "len", "(", "path_label", ".", "split", "(", ")", ")", "==", "8", ",", "path_label", "\n", "\n", "inference_single_audio", "(", "opt", ",", "path_label", ",", "model", ")", "\n", "\n", "", "except", "Exception", "as", "ex", ":", "\n", "            ", "import", "traceback", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "print", "(", "path_label", "+", "'\\n'", ")", "\n", "print", "(", "str", "(", "ex", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.__init__": [[10, 38], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "frame_rate", "=", "25", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "num_mels", "=", "80", ",", "\n", "fft_size", "=", "1280", ",", "\n", "hop_size", "=", "160", ",", "\n", "num_frames_per_clip", "=", "5", ",", "\n", "save_mel", "=", "True", "\n", ")", ":", "\n", "        ", "self", ".", "frame_rate", "=", "frame_rate", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "num_bins_per_frame", "=", "int", "(", "sample_rate", "/", "hop_size", "/", "frame_rate", ")", "\n", "self", ".", "num_frames_per_clip", "=", "num_frames_per_clip", "\n", "self", ".", "silence_threshold", "=", "2", "\n", "self", ".", "num_mels", "=", "num_mels", "\n", "self", ".", "save_mel", "=", "save_mel", "\n", "self", ".", "fmin", "=", "125", "\n", "self", ".", "fmax", "=", "7600", "\n", "self", ".", "fft_size", "=", "fft_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "frame_shift_ms", "=", "None", "\n", "self", ".", "min_level_db", "=", "-", "100", "\n", "self", ".", "ref_level_db", "=", "20", "\n", "self", ".", "rescaling", "=", "True", "\n", "self", ".", "rescaling_max", "=", "0.999", "\n", "self", ".", "allow_clipping_in_normalization", "=", "True", "\n", "self", ".", "log_scale_min", "=", "-", "32.23619130191664", "\n", "self", ".", "norm_audio", "=", "True", "\n", "self", ".", "with_phase", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.load_wav": [[39, 41], ["librosa.core.load", "librosa.core.load", "librosa.core.load", "librosa.core.load"], "methods", ["None"], ["", "def", "load_wav", "(", "self", ",", "path", ")", ":", "\n", "        ", "return", "librosa", ".", "core", ".", "load", "(", "path", ",", "sr", "=", "self", ".", "sample_rate", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.audio_normalize": [[42, 46], ["numpy.maximum", "numpy.sqrt", "numpy.mean"], "methods", ["None"], ["", "def", "audio_normalize", "(", "self", ",", "samples", ",", "desired_rms", "=", "0.1", ",", "eps", "=", "1e-4", ")", ":", "\n", "        ", "rms", "=", "np", ".", "maximum", "(", "eps", ",", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "samples", "**", "2", ")", ")", ")", "\n", "samples", "=", "samples", "*", "(", "desired_rms", "/", "rms", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.generate_spectrogram_magphase": [[47, 56], ["librosa.core.stft", "librosa.core.stft", "librosa.core.stft", "librosa.core.stft", "librosa.core.magphase", "librosa.core.magphase", "librosa.core.magphase", "librosa.core.magphase", "numpy.expand_dims", "numpy.expand_dims", "AudioConfig.AudioConfig.get_hop_size", "numpy.angle"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.get_hop_size"], ["", "def", "generate_spectrogram_magphase", "(", "self", ",", "audio", ")", ":", "\n", "        ", "spectro", "=", "librosa", ".", "core", ".", "stft", "(", "audio", ",", "hop_length", "=", "self", ".", "get_hop_size", "(", ")", ",", "n_fft", "=", "self", ".", "fft_size", ",", "center", "=", "True", ")", "\n", "spectro_mag", ",", "spectro_phase", "=", "librosa", ".", "core", ".", "magphase", "(", "spectro", ")", "\n", "spectro_mag", "=", "np", ".", "expand_dims", "(", "spectro_mag", ",", "axis", "=", "0", ")", "\n", "if", "self", ".", "with_phase", ":", "\n", "            ", "spectro_phase", "=", "np", ".", "expand_dims", "(", "np", ".", "angle", "(", "spectro_phase", ")", ",", "axis", "=", "0", ")", "\n", "return", "spectro_mag", ",", "spectro_phase", "\n", "", "else", ":", "\n", "            ", "return", "spectro_mag", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.save_wav": [[57, 60], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "methods", ["None"], ["", "", "def", "save_wav", "(", "self", ",", "wav", ",", "path", ")", ":", "\n", "        ", "wav", "*=", "32767", "/", "max", "(", "0.01", ",", "np", ".", "max", "(", "np", ".", "abs", "(", "wav", ")", ")", ")", "\n", "wavfile", ".", "write", "(", "path", ",", "self", ".", "sample_rate", ",", "wav", ".", "astype", "(", "np", ".", "int16", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.trim": [[61, 64], ["AudioConfig.AudioConfig.start_and_end_indices"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.start_and_end_indices"], ["", "def", "trim", "(", "self", ",", "quantized", ")", ":", "\n", "        ", "start", ",", "end", "=", "self", ".", "start_and_end_indices", "(", "quantized", ",", "self", ".", "silence_threshold", ")", "\n", "return", "quantized", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.adjust_time_resolution": [[65, 89], ["numpy.repeat", "AudioConfig.AudioConfig.start_and_end_indices", "len", "len", "numpy.pad"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.start_and_end_indices"], ["", "def", "adjust_time_resolution", "(", "self", ",", "quantized", ",", "mel", ")", ":", "\n", "        ", "\"\"\"Adjust time resolution by repeating features\n\n        Args:\n            quantized (ndarray): (T,)\n            mel (ndarray): (N, D)\n\n        Returns:\n            tuple: Tuple of (T,) and (T, D)\n        \"\"\"", "\n", "assert", "len", "(", "quantized", ".", "shape", ")", "==", "1", "\n", "assert", "len", "(", "mel", ".", "shape", ")", "==", "2", "\n", "\n", "upsample_factor", "=", "quantized", ".", "size", "//", "mel", ".", "shape", "[", "0", "]", "\n", "mel", "=", "np", ".", "repeat", "(", "mel", ",", "upsample_factor", ",", "axis", "=", "0", ")", "\n", "n_pad", "=", "quantized", ".", "size", "-", "mel", ".", "shape", "[", "0", "]", "\n", "if", "n_pad", "!=", "0", ":", "\n", "            ", "assert", "n_pad", ">", "0", "\n", "mel", "=", "np", ".", "pad", "(", "mel", ",", "[", "(", "0", ",", "n_pad", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "\n", "# trim", "\n", "", "start", ",", "end", "=", "self", ".", "start_and_end_indices", "(", "quantized", ",", "self", ".", "silence_threshold", ")", "\n", "\n", "return", "quantized", "[", "start", ":", "end", "]", ",", "mel", "[", "start", ":", "end", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.start_and_end_indices": [[92, 104], ["range", "range", "abs", "abs", "abs", "abs"], "methods", ["None"], ["def", "start_and_end_indices", "(", "self", ",", "quantized", ",", "silence_threshold", "=", "2", ")", ":", "\n", "        ", "for", "start", "in", "range", "(", "quantized", ".", "size", ")", ":", "\n", "            ", "if", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "                ", "break", "\n", "", "", "for", "end", "in", "range", "(", "quantized", ".", "size", "-", "1", ",", "1", ",", "-", "1", ")", ":", "\n", "            ", "if", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "                ", "break", "\n", "\n", "", "", "assert", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", "\n", "assert", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", "\n", "\n", "return", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.melspectrogram": [[105, 111], ["AudioConfig.AudioConfig._normalize", "AudioConfig.AudioConfig._lws_processor().stft", "AudioConfig.AudioConfig._amp_to_db", "AudioConfig.AudioConfig._linear_to_mel", "AudioConfig.AudioConfig._lws_processor", "numpy.abs", "S.max", "S.min"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._normalize", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._amp_to_db", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._linear_to_mel", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._lws_processor"], ["", "def", "melspectrogram", "(", "self", ",", "y", ")", ":", "\n", "        ", "D", "=", "self", ".", "_lws_processor", "(", ")", ".", "stft", "(", "y", ")", ".", "T", "\n", "S", "=", "self", ".", "_amp_to_db", "(", "self", ".", "_linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "-", "self", ".", "ref_level_db", "\n", "if", "not", "self", ".", "allow_clipping_in_normalization", ":", "\n", "            ", "assert", "S", ".", "max", "(", ")", "<=", "0", "and", "S", ".", "min", "(", ")", "-", "self", ".", "min_level_db", ">=", "0", "\n", "", "return", "self", ".", "_normalize", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.get_hop_size": [[112, 118], ["int"], "methods", ["None"], ["", "def", "get_hop_size", "(", "self", ")", ":", "\n", "        ", "hop_size", "=", "self", ".", "hop_size", "\n", "if", "hop_size", "is", "None", ":", "\n", "            ", "assert", "self", ".", "frame_shift_ms", "is", "not", "None", "\n", "hop_size", "=", "int", "(", "self", ".", "frame_shift_ms", "/", "1000", "*", "self", ".", "sample_rate", ")", "\n", "", "return", "hop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._lws_processor": [[119, 121], ["lws.lws", "AudioConfig.AudioConfig.get_hop_size"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.get_hop_size"], ["", "def", "_lws_processor", "(", "self", ")", ":", "\n", "        ", "return", "lws", ".", "lws", "(", "self", ".", "fft_size", ",", "self", ".", "get_hop_size", "(", ")", ",", "mode", "=", "\"speech\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.lws_num_frames": [[122, 131], ["None"], "methods", ["None"], ["", "def", "lws_num_frames", "(", "self", ",", "length", ",", "fsize", ",", "fshift", ")", ":", "\n", "        ", "\"\"\"Compute number of time frames of lws spectrogram\n        \"\"\"", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "if", "length", "%", "fshift", "==", "0", ":", "\n", "            ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "1", "\n", "", "else", ":", "\n", "            ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "2", "\n", "", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.lws_pad_lr": [[132, 140], ["AudioConfig.AudioConfig.lws_num_frames", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.lws_num_frames"], ["", "def", "lws_pad_lr", "(", "self", ",", "x", ",", "fsize", ",", "fshift", ")", ":", "\n", "        ", "\"\"\"Compute left and right padding lws internally uses\n        \"\"\"", "\n", "M", "=", "self", ".", "lws_num_frames", "(", "len", "(", "x", ")", ",", "fsize", ",", "fshift", ")", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "T", "=", "len", "(", "x", ")", "+", "2", "*", "pad", "\n", "r", "=", "(", "M", "-", "1", ")", "*", "fshift", "+", "fsize", "-", "T", "\n", "return", "pad", ",", "pad", "+", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._linear_to_mel": [[142, 146], ["AudioConfig.AudioConfig._build_mel_basis", "numpy.dot"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._build_mel_basis"], ["", "def", "_linear_to_mel", "(", "self", ",", "spectrogram", ")", ":", "\n", "        ", "global", "_mel_basis", "\n", "_mel_basis", "=", "self", ".", "_build_mel_basis", "(", ")", "\n", "return", "np", ".", "dot", "(", "_mel_basis", ",", "spectrogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._build_mel_basis": [[147, 152], ["librosa.filters.mel", "librosa.filters.mel", "librosa.filters.mel", "librosa.filters.mel"], "methods", ["None"], ["", "def", "_build_mel_basis", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "fmax", "<=", "self", ".", "sample_rate", "//", "2", "\n", "return", "librosa", ".", "filters", ".", "mel", "(", "self", ".", "sample_rate", ",", "self", ".", "fft_size", ",", "\n", "fmin", "=", "self", ".", "fmin", ",", "fmax", "=", "self", ".", "fmax", ",", "\n", "n_mels", "=", "self", ".", "num_mels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._amp_to_db": [[153, 156], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "methods", ["None"], ["", "def", "_amp_to_db", "(", "self", ",", "x", ")", ":", "\n", "        ", "min_level", "=", "np", ".", "exp", "(", "self", ".", "min_level_db", "/", "20", "*", "np", ".", "log", "(", "10", ")", ")", "\n", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "min_level", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._db_to_amp": [[157, 159], ["numpy.power"], "methods", ["None"], ["", "def", "_db_to_amp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._normalize": [[160, 162], ["numpy.clip"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "S", ")", ":", "\n", "        ", "return", "np", ".", "clip", "(", "(", "S", "-", "self", ".", "min_level_db", ")", "/", "-", "self", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig._denormalize": [[163, 165], ["numpy.clip"], "methods", ["None"], ["", "def", "_denormalize", "(", "self", ",", "S", ")", ":", "\n", "        ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "self", ".", "min_level_db", ")", "+", "self", ".", "min_level_db", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.read_audio": [[166, 174], ["AudioConfig.AudioConfig.load_wav", "AudioConfig.AudioConfig.audio_normalize", "numpy.abs().max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.load_wav", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.audio_normalize"], ["", "def", "read_audio", "(", "self", ",", "audio_path", ")", ":", "\n", "        ", "wav", "=", "self", ".", "load_wav", "(", "audio_path", ")", "\n", "if", "self", ".", "norm_audio", ":", "\n", "            ", "wav", "=", "self", ".", "audio_normalize", "(", "wav", ")", "\n", "", "else", ":", "\n", "            ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "\n", "\n", "", "return", "wav", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.audio_to_spectrogram": [[175, 181], ["AudioConfig.AudioConfig.generate_spectrogram_magphase", "AudioConfig.AudioConfig.melspectrogram().astype", "AudioConfig.AudioConfig.melspectrogram"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.generate_spectrogram_magphase", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.melspectrogram"], ["", "def", "audio_to_spectrogram", "(", "self", ",", "wav", ")", ":", "\n", "        ", "if", "self", ".", "save_mel", ":", "\n", "            ", "spectrogram", "=", "self", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "", "else", ":", "\n", "            ", "spectrogram", "=", "self", ".", "generate_spectrogram_magphase", "(", "wav", ")", "\n", "", "return", "spectrogram", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.get_affine": [[12, 20], ["numpy.array", "skimage.SimilarityTransform", "trans.SimilarityTransform.estimate"], "function", ["None"], ["def", "get_affine", "(", "src", ")", ":", "\n", "    ", "dst", "=", "np", ".", "array", "(", "[", "[", "87", ",", "59", "]", ",", "\n", "[", "137", ",", "59", "]", ",", "\n", "[", "112", ",", "120", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "tform", "=", "trans", ".", "SimilarityTransform", "(", ")", "\n", "tform", ".", "estimate", "(", "src", ",", "dst", ")", "\n", "M", "=", "tform", ".", "params", "[", "0", ":", "2", ",", ":", "]", "\n", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.affine_align_img": [[22, 25], ["cv2.warpAffine"], "function", ["None"], ["", "def", "affine_align_img", "(", "img", ",", "M", ",", "crop_size", "=", "224", ")", ":", "\n", "    ", "warped", "=", "cv2", ".", "warpAffine", "(", "img", ",", "M", ",", "(", "crop_size", ",", "crop_size", ")", ",", "borderValue", "=", "0.0", ")", "\n", "return", "warped", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.affine_align_3landmarks": [[27, 31], ["numpy.concatenate", "numpy.matmul", "M.transpose", "numpy.ones"], "function", ["None"], ["", "def", "affine_align_3landmarks", "(", "landmarks", ",", "M", ")", ":", "\n", "    ", "new_landmarks", "=", "np", ".", "concatenate", "(", "[", "landmarks", ",", "np", ".", "ones", "(", "(", "3", ",", "1", ")", ")", "]", ",", "1", ")", "\n", "affined_landmarks", "=", "np", ".", "matmul", "(", "new_landmarks", ",", "M", ".", "transpose", "(", ")", ")", "\n", "return", "affined_landmarks", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.get_eyes_mouths": [[33, 39], ["numpy.zeros", "landmark[].mean", "landmark[].mean", "landmark[].mean"], "function", ["None"], ["", "def", "get_eyes_mouths", "(", "landmark", ")", ":", "\n", "    ", "three_points", "=", "np", ".", "zeros", "(", "(", "3", ",", "2", ")", ")", "\n", "three_points", "[", "0", "]", "=", "landmark", "[", "36", ":", "42", "]", ".", "mean", "(", "0", ")", "\n", "three_points", "[", "1", "]", "=", "landmark", "[", "42", ":", "48", "]", ".", "mean", "(", "0", ")", "\n", "three_points", "[", "2", "]", "=", "landmark", "[", "60", ":", "68", "]", ".", "mean", "(", "0", ")", "\n", "return", "three_points", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.get_mouth_bias": [[41, 44], ["numpy.array"], "function", ["None"], ["", "def", "get_mouth_bias", "(", "three_points", ")", ":", "\n", "    ", "bias", "=", "np", ".", "array", "(", "[", "112", ",", "120", "]", ")", "-", "three_points", "[", "2", "]", "\n", "return", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.align_folder": [[46, 89], ["face_alignment.FaceAlignment", "face_alignment.FaceAlignment.get_landmarks_from_directory", "fa.get_landmarks_from_directory.keys", "align_68.get_affine", "enumerate", "print", "numpy.array", "len", "fa.get_landmarks_from_directory.keys", "align_68.affine_align_3landmarks", "align_68.get_mouth_bias", "get_affine.copy", "cv2.imread", "align_68.affine_align_img", "os.path.join", "cv2.imwrite", "print", "len", "align_68.get_eyes_mouths", "three_points_list.append", "print", "img_pth.split"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.get_affine", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.affine_align_3landmarks", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.get_mouth_bias", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.affine_align_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.get_eyes_mouths"], ["", "def", "align_folder", "(", "folder_path", ",", "folder_save_path", ")", ":", "\n", "\n", "    ", "fa", "=", "face_alignment", ".", "FaceAlignment", "(", "face_alignment", ".", "LandmarksType", ".", "_2D", ",", "device", "=", "device", ")", "\n", "preds", "=", "fa", ".", "get_landmarks_from_directory", "(", "folder_path", ")", "\n", "\n", "sumpoints", "=", "0", "\n", "three_points_list", "=", "[", "]", "\n", "\n", "for", "img", "in", "preds", ".", "keys", "(", ")", ":", "\n", "        ", "pred_points", "=", "np", ".", "array", "(", "preds", "[", "img", "]", ")", "\n", "if", "pred_points", "is", "None", "or", "len", "(", "pred_points", ".", "shape", ")", "!=", "3", ":", "\n", "            ", "print", "(", "'preprocessing failed'", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "            ", "num_faces", ",", "size", ",", "_", "=", "pred_points", ".", "shape", "\n", "if", "num_faces", "==", "1", "and", "size", "==", "68", ":", "\n", "\n", "                ", "three_points", "=", "get_eyes_mouths", "(", "pred_points", "[", "0", "]", ")", "\n", "sumpoints", "+=", "three_points", "\n", "three_points_list", ".", "append", "(", "three_points", ")", "\n", "", "else", ":", "\n", "\n", "                ", "print", "(", "'preprocessing failed'", ")", "\n", "return", "False", "\n", "", "", "", "avg_points", "=", "sumpoints", "/", "len", "(", "preds", ")", "\n", "M", "=", "get_affine", "(", "avg_points", ")", "\n", "p_bias", "=", "None", "\n", "for", "i", ",", "img_pth", "in", "enumerate", "(", "preds", ".", "keys", "(", ")", ")", ":", "\n", "        ", "three_points", "=", "three_points_list", "[", "i", "]", "\n", "affined_3landmarks", "=", "affine_align_3landmarks", "(", "three_points", ",", "M", ")", "\n", "bias", "=", "get_mouth_bias", "(", "affined_3landmarks", ")", "\n", "if", "p_bias", "is", "None", ":", "\n", "            ", "bias", "=", "bias", "\n", "", "else", ":", "\n", "            ", "bias", "=", "p_bias", "*", "0.2", "+", "bias", "*", "0.8", "\n", "", "p_bias", "=", "bias", "\n", "M_i", "=", "M", ".", "copy", "(", ")", "\n", "M_i", "[", ":", ",", "2", "]", "=", "M", "[", ":", ",", "2", "]", "+", "bias", "\n", "img", "=", "cv2", ".", "imread", "(", "img_pth", ")", "\n", "wrapped", "=", "affine_align_img", "(", "img", ",", "M_i", ")", "\n", "img_save_path", "=", "os", ".", "path", ".", "join", "(", "folder_save_path", ",", "img_pth", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "cv2", ".", "imwrite", "(", "img_save_path", ",", "wrapped", ")", "\n", "", "print", "(", "'cropped files saved at {}'", ".", "format", "(", "folder_save_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.main": [[91, 102], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.isdir", "os.path.join", "os.makedirs", "align_68.align_folder", "parser.parse_args.folder_path.split", "parser.parse_args.folder_path.split"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.align_68.align_folder"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--folder_path'", ",", "help", "=", "'the folder which needs processing'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "args", ".", "folder_path", ")", ":", "\n", "        ", "home_path", "=", "'/'", ".", "join", "(", "args", ".", "folder_path", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "save_img_path", "=", "os", ".", "path", ".", "join", "(", "home_path", ",", "args", ".", "folder_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'_cropped'", ")", "\n", "os", ".", "makedirs", "(", "save_img_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "align_folder", "(", "args", ".", "folder_path", ",", "save_img_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.prepare_testing_files.mkdir": [[11, 14], ["os.path.exists", "os.makedirs"], "function", ["None"], ["def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.prepare_testing_files.proc_frames": [[16, 21], ["os.system", "glob.glob", "len", "os.path.join"], "function", ["None"], ["", "", "def", "proc_frames", "(", "src_path", ",", "dst_path", ")", ":", "\n", "    ", "cmd", "=", "'ffmpeg -i \\\"{}\\\" -start_number 0 -qscale:v 2 \\\"{}\\\"/%06d.jpg -loglevel error -y'", ".", "format", "(", "src_path", ",", "dst_path", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "frames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "dst_path", ",", "'*.jpg'", ")", ")", "\n", "return", "len", "(", "frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.scripts.prepare_testing_files.proc_audio": [[23, 27], ["os.system"], "function", ["None"], ["", "def", "proc_audio", "(", "src_mouth_path", ",", "dst_audio_path", ")", ":", "\n", "    ", "audio_command", "=", "'ffmpeg -i \\\"{}\\\" -loglevel error -y -f wav -acodec pcm_s16le '", "'-ar 16000 \\\"{}\\\"'", ".", "format", "(", "src_mouth_path", ",", "dst_audio_path", ")", "\n", "os", ".", "system", "(", "audio_command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.__init__": [[8, 26], ["os.path.join", "numpy.loadtxt", "print", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dataset_size", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "dataset_size", "=", "dataset_size", "\n", "\n", "self", ".", "first_epoch", "=", "1", "\n", "self", ".", "total_epochs", "=", "opt", ".", "niter", "+", "opt", ".", "niter_decay", "if", "opt", ".", "isTrain", "else", "1", "\n", "self", ".", "epoch_iter", "=", "0", "# iter number within each epoch", "\n", "self", ".", "iter_record_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "checkpoints_dir", ",", "self", ".", "opt", ".", "name", ",", "'iter.txt'", ")", "\n", "if", "opt", ".", "isTrain", "and", "opt", ".", "continue_train", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "first_epoch", ",", "self", ".", "epoch_iter", "=", "np", ".", "loadtxt", "(", "\n", "self", ".", "iter_record_path", ",", "delimiter", "=", "','", ",", "dtype", "=", "int", ")", "\n", "print", "(", "'Resuming from epoch %d at iteration %d'", "%", "(", "self", ".", "first_epoch", ",", "self", ".", "epoch_iter", ")", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "'Could not load iteration record at %s. Starting from beginning.'", "%", "\n", "self", ".", "iter_record_path", ")", "\n", "\n", "", "", "self", ".", "total_steps_so_far", "=", "(", "self", ".", "first_epoch", "-", "1", ")", "*", "dataset_size", "+", "self", ".", "epoch_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.training_epochs": [[28, 30], ["range"], "methods", ["None"], ["", "def", "training_epochs", "(", "self", ")", ":", "\n", "        ", "return", "range", "(", "self", ".", "first_epoch", ",", "self", ".", "total_epochs", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.record_epoch_start": [[31, 36], ["time.time", "time.time"], "methods", ["None"], ["", "def", "record_epoch_start", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "epoch_iter", "=", "0", "\n", "self", ".", "last_iter_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.record_one_iteration": [[37, 46], ["time.time"], "methods", ["None"], ["", "def", "record_one_iteration", "(", "self", ")", ":", "\n", "        ", "current_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# the last remaining batch is dropped (see data/__init__.py),", "\n", "# so we can assume batch size is always opt.batchSize", "\n", "self", ".", "time_per_iter", "=", "(", "current_time", "-", "self", ".", "last_iter_time", ")", "/", "self", ".", "opt", ".", "batchSize", "\n", "self", ".", "last_iter_time", "=", "current_time", "\n", "self", ".", "total_steps_so_far", "+=", "self", ".", "opt", ".", "batchSize", "\n", "self", ".", "epoch_iter", "+=", "self", ".", "opt", ".", "batchSize", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.record_epoch_end": [[47, 56], ["time.time", "print", "numpy.savetxt", "print"], "methods", ["None"], ["", "def", "record_epoch_end", "(", "self", ")", ":", "\n", "        ", "current_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "time_per_epoch", "=", "current_time", "-", "self", ".", "epoch_start_time", "\n", "print", "(", "'End of epoch %d / %d \\t Time Taken: %d sec'", "%", "\n", "(", "self", ".", "current_epoch", ",", "self", ".", "total_epochs", ",", "self", ".", "time_per_epoch", ")", ")", "\n", "if", "self", ".", "current_epoch", "%", "self", ".", "opt", ".", "save_epoch_freq", "==", "0", ":", "\n", "            ", "np", ".", "savetxt", "(", "self", ".", "iter_record_path", ",", "(", "self", ".", "current_epoch", "+", "1", ",", "0", ")", ",", "\n", "delimiter", "=", "','", ",", "fmt", "=", "'%d'", ")", "\n", "print", "(", "'Saved current iteration count at %s.'", "%", "self", ".", "iter_record_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.record_current_iter": [[57, 61], ["numpy.savetxt", "print"], "methods", ["None"], ["", "", "def", "record_current_iter", "(", "self", ")", ":", "\n", "        ", "np", ".", "savetxt", "(", "self", ".", "iter_record_path", ",", "(", "self", ".", "current_epoch", ",", "self", ".", "epoch_iter", ")", ",", "\n", "delimiter", "=", "','", ",", "fmt", "=", "'%d'", ")", "\n", "print", "(", "'Saved current iteration count at %s.'", "%", "self", ".", "iter_record_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.needs_saving": [[62, 64], ["None"], "methods", ["None"], ["", "def", "needs_saving", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "total_steps_so_far", "%", "self", ".", "opt", ".", "save_latest_freq", ")", "<", "self", ".", "opt", ".", "batchSize", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.needs_printing": [[65, 67], ["None"], "methods", ["None"], ["", "def", "needs_printing", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "total_steps_so_far", "%", "self", ".", "opt", ".", "print_freq", ")", "<", "self", ".", "opt", ".", "batchSize", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.iter_counter.IterationCounter.needs_displaying": [[68, 70], ["None"], "methods", ["None"], ["", "def", "needs_displaying", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "total_steps_so_far", "%", "self", ".", "opt", ".", "display_freq", ")", "<", "self", ".", "opt", ".", "batchSize", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.__init__": [[8, 28], ["web_dir.endswith", "os.path.join", "dominate.document", "os.path.split", "os.makedirs", "os.makedirs", "h1", "len", "os.path.exists", "len", "os.path.exists", "datetime.datetime.now().strftime", "meta", "datetime.datetime.now", "str"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "        ", "if", "web_dir", ".", "endswith", "(", "'.html'", ")", ":", "\n", "            ", "web_dir", ",", "html_name", "=", "os", ".", "path", ".", "split", "(", "web_dir", ")", "\n", "", "else", ":", "\n", "            ", "web_dir", ",", "html_name", "=", "web_dir", ",", "'index.html'", "\n", "", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "html_name", "=", "html_name", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "if", "len", "(", "self", ".", "web_dir", ")", ">", "0", "and", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "len", "(", "self", ".", "web_dir", ")", ">", "0", "and", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "with", "self", ".", "doc", ":", "\n", "            ", "h1", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%I:%M%p on %B %d, %Y\"", ")", ")", "\n", "", "if", "refresh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.get_image_dir": [[29, 31], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_header": [[32, 35], ["h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "str", ")", ":", "\n", "        ", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_table": [[36, 39], ["table", "html.HTML.doc.add"], "methods", ["None"], ["", "", "def", "add_table", "(", "self", ",", "border", "=", "1", ")", ":", "\n", "        ", "self", ".", "t", "=", "table", "(", "border", "=", "border", ",", "style", "=", "\"table-layout: fixed;\"", ")", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_images": [[40, 51], ["html.HTML.add_table", "tr", "zip", "td", "p", "br", "p", "a", "img", "txt.encode", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_table"], ["", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "512", ")", ":", "\n", "        ", "self", ".", "add_table", "(", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "with", "td", "(", "style", "=", "\"word-wrap: break-word;\"", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "style", "=", "\"width:%dpx\"", "%", "(", "width", ")", ",", "src", "=", "os", ".", "path", ".", "join", "(", "'images'", ",", "im", ")", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.save": [[52, 57], ["os.path.join", "open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "html_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "self", ".", "html_name", ")", "\n", "f", "=", "open", "(", "html_file", ",", "'wt'", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.__init__": [[16, 43], ["os.path.join", "tf.summary.FileWriter", "os.path.join", "torch.utils.tensorboard.SummaryWriter", "os.path.join", "os.path.join", "print", "util.mkdirs", "os.path.join", "open", "time.strftime", "log_file.write"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdirs"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "tf_log", "=", "opt", ".", "isTrain", "and", "opt", ".", "tf_log", "\n", "self", ".", "tensorboard", "=", "opt", ".", "isTrain", "and", "opt", ".", "tensorboard", "\n", "self", ".", "use_html", "=", "opt", ".", "isTrain", "and", "not", "opt", ".", "no_html", "\n", "self", ".", "win_size", "=", "opt", ".", "display_winsize", "\n", "self", ".", "name", "=", "opt", ".", "name", "\n", "if", "self", ".", "tf_log", ":", "\n", "            ", "import", "tensorflow", "as", "tf", "\n", "self", ".", "tf", "=", "tf", "\n", "self", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'logs'", ")", "\n", "self", ".", "writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "self", ".", "log_dir", ")", "\n", "\n", "", "if", "self", ".", "tensorboard", ":", "\n", "            ", "self", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'logs'", ")", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "self", ".", "log_dir", ",", "comment", "=", "opt", ".", "name", ")", "\n", "\n", "", "if", "self", ".", "use_html", ":", "\n", "            ", "self", ".", "web_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'web'", ")", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "'images'", ")", "\n", "print", "(", "'create web directory %s...'", "%", "self", ".", "web_dir", ")", "\n", "util", ".", "mkdirs", "(", "[", "self", ".", "web_dir", ",", "self", ".", "img_dir", "]", ")", "\n", "", "if", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "                ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.display_current_results": [[45, 129], ["visualizer.Visualizer.convert_visuals_to_numpy", "visualizer.Visualizer.items", "visualizer.Visualizer.tf.Summary", "visualizer.Visualizer.writer.add_summary", "visualizer.Visualizer.items", "visualizer.Visualizer.items", "html.HTML", "range", "html.HTML.save", "scipy.misc.toimage().save", "visualizer.Visualizer.tf.Summary.Image", "img_summaries.append", "image_numpy.size", "torchvision.make_grid", "visualizer.Visualizer.writer.add_image", "isinstance", "html.HTML.add_header", "visualizer.Visualizer.items", "StringIO", "len", "visualizer.Visualizer.tf.Summary.Value", "StringIO", "range", "os.path.join", "util.save_image", "isinstance", "len", "html.HTML.add_images", "int", "html.HTML.add_images", "html.HTML.add_images", "BytesIO", "scipy.misc.toimage", "BytesIO.getvalue", "BytesIO", "len", "os.path.join", "util.save_image", "len", "range", "ims.append", "txts.append", "links.append", "round", "min", "len", "ims.append", "txts.append", "links.append", "len", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.convert_visuals_to_numpy", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_header", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.save_image", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.save_image"], ["", "", "", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "step", ")", ":", "\n", "\n", "## convert tensors to numpy arrays", "\n", "\n", "\n", "        ", "if", "self", ".", "tf_log", ":", "# show images in tensorboard output", "\n", "            ", "img_summaries", "=", "[", "]", "\n", "visuals", "=", "self", ".", "convert_visuals_to_numpy", "(", "visuals", ")", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "# Write the image to a string", "\n", "                ", "try", ":", "\n", "                    ", "s", "=", "StringIO", "(", ")", "\n", "", "except", ":", "\n", "                    ", "s", "=", "BytesIO", "(", ")", "\n", "", "if", "len", "(", "image_numpy", ".", "shape", ")", ">=", "4", ":", "\n", "                    ", "image_numpy", "=", "image_numpy", "[", "0", "]", "\n", "", "scipy", ".", "misc", ".", "toimage", "(", "image_numpy", ")", ".", "save", "(", "s", ",", "format", "=", "\"jpeg\"", ")", "\n", "# Create an Image object", "\n", "img_sum", "=", "self", ".", "tf", ".", "Summary", ".", "Image", "(", "encoded_image_string", "=", "s", ".", "getvalue", "(", ")", ",", "height", "=", "image_numpy", ".", "shape", "[", "0", "]", ",", "width", "=", "image_numpy", ".", "shape", "[", "1", "]", ")", "\n", "# Create a Summary value", "\n", "img_summaries", ".", "append", "(", "self", ".", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "label", ",", "image", "=", "img_sum", ")", ")", "\n", "\n", "# Create and write Summary", "\n", "", "summary", "=", "self", ".", "tf", ".", "Summary", "(", "value", "=", "img_summaries", ")", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n", "", "if", "self", ".", "tensorboard", ":", "# show images in tensorboard output", "\n", "            ", "img_summaries", "=", "[", "]", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "# Write the image to a string", "\n", "                ", "try", ":", "\n", "                    ", "s", "=", "StringIO", "(", ")", "\n", "", "except", ":", "\n", "                    ", "s", "=", "BytesIO", "(", ")", "\n", "# if len(image_numpy.shape) >= 4:", "\n", "#     image_numpy = image_numpy[0]", "\n", "# scipy.misc.toimage(image_numpy).save(s, format=\"jpeg\")", "\n", "# Create an Image object", "\n", "# self.writer.add_image(tag=label, img_tensor=image_numpy, global_step=step, dataformats='HWC')", "\n", "# Create a Summary value", "\n", "", "batch_size", "=", "image_numpy", ".", "size", "(", "0", ")", "\n", "x", "=", "vutils", ".", "make_grid", "(", "image_numpy", "[", ":", "min", "(", "batch_size", ",", "16", ")", "]", ",", "normalize", "=", "True", ",", "scale_each", "=", "True", ")", "\n", "self", ".", "writer", ".", "add_image", "(", "label", ",", "x", ",", "step", ")", "\n", "\n", "\n", "", "", "if", "self", ".", "use_html", ":", "# save images to a html file", "\n", "            ", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "image_numpy", ",", "list", ")", ":", "\n", "                    ", "for", "i", "in", "range", "(", "len", "(", "image_numpy", ")", ")", ":", "\n", "                        ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_iter%.3d_%s_%d.png'", "%", "(", "epoch", ",", "step", ",", "label", ",", "i", ")", ")", "\n", "util", ".", "save_image", "(", "image_numpy", "[", "i", "]", ",", "img_path", ")", "\n", "", "", "else", ":", "\n", "                    ", "img_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "img_dir", ",", "'epoch%.3d_iter%.3d_%s.png'", "%", "(", "epoch", ",", "step", ",", "label", ")", ")", "\n", "if", "len", "(", "image_numpy", ".", "shape", ")", ">=", "4", ":", "\n", "                        ", "image_numpy", "=", "image_numpy", "[", "0", "]", "\n", "", "util", ".", "save_image", "(", "image_numpy", ",", "img_path", ")", "\n", "\n", "# update website", "\n", "", "", "webpage", "=", "html", ".", "HTML", "(", "self", ".", "web_dir", ",", "'Experiment name = %s'", "%", "self", ".", "name", ",", "refresh", "=", "5", ")", "\n", "for", "n", "in", "range", "(", "epoch", ",", "0", ",", "-", "1", ")", ":", "\n", "                ", "webpage", ".", "add_header", "(", "'epoch [%d]'", "%", "n", ")", "\n", "ims", "=", "[", "]", "\n", "txts", "=", "[", "]", "\n", "links", "=", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "image_numpy", ",", "list", ")", ":", "\n", "                        ", "for", "i", "in", "range", "(", "len", "(", "image_numpy", ")", ")", ":", "\n", "                            ", "img_path", "=", "'epoch%.3d_iter%.3d_%s_%d.png'", "%", "(", "n", ",", "step", ",", "label", ",", "i", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", "+", "str", "(", "i", ")", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "", "else", ":", "\n", "                        ", "img_path", "=", "'epoch%.3d_iter%.3d_%s.png'", "%", "(", "n", ",", "step", ",", "label", ")", "\n", "ims", ".", "append", "(", "img_path", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "img_path", ")", "\n", "", "", "if", "len", "(", "ims", ")", "<", "10", ":", "\n", "                    ", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "else", ":", "\n", "                    ", "num", "=", "int", "(", "round", "(", "len", "(", "ims", ")", "/", "2.0", ")", ")", "\n", "webpage", ".", "add_images", "(", "ims", "[", ":", "num", "]", ",", "txts", "[", ":", "num", "]", ",", "links", "[", ":", "num", "]", ",", "width", "=", "self", ".", "win_size", ")", "\n", "webpage", ".", "add_images", "(", "ims", "[", "num", ":", "]", ",", "txts", "[", "num", ":", "]", ",", "links", "[", "num", ":", "]", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "", "webpage", ".", "save", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.plot_current_errors": [[131, 142], ["errors.items", "errors.items", "value.mean().float.mean().float.mean().float", "visualizer.Visualizer.tf.Summary", "visualizer.Visualizer.writer.add_summary", "value.mean().float.mean().float.mean().float", "visualizer.Visualizer.writer.add_scalar", "value.mean().float.mean().float.mean", "value.mean().float.mean().float.mean", "visualizer.Visualizer.tf.Summary.Value"], "methods", ["None"], ["", "", "def", "plot_current_errors", "(", "self", ",", "errors", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tf_log", ":", "\n", "            ", "for", "tag", ",", "value", "in", "errors", ".", "items", "(", ")", ":", "\n", "                ", "value", "=", "value", ".", "mean", "(", ")", ".", "float", "(", ")", "\n", "summary", "=", "self", ".", "tf", ".", "Summary", "(", "value", "=", "[", "self", ".", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "tag", ",", "simple_value", "=", "value", ")", "]", ")", "\n", "self", ".", "writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n", "", "", "if", "self", ".", "tensorboard", ":", "\n", "            ", "for", "tag", ",", "value", "in", "errors", ".", "items", "(", ")", ":", "\n", "                ", "value", "=", "value", ".", "mean", "(", ")", ".", "float", "(", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "tag", "=", "tag", ",", "scalar_value", "=", "value", ",", "global_step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.print_current_errors": [[144, 155], ["errors.items", "print", "v.mean().float.mean().float.mean().float", "open", "log_file.write", "v.mean().float.mean().float.mean"], "methods", ["None"], ["", "", "", "def", "print_current_errors", "(", "self", ",", "opt", ",", "epoch", ",", "i", ",", "errors", ",", "t", ")", ":", "\n", "        ", "message", "=", "opt", ".", "name", "+", "' (epoch: %d, iters: %d, time: %.3f) '", "%", "(", "epoch", ",", "i", ",", "t", ")", "\n", "for", "k", ",", "v", "in", "errors", ".", "items", "(", ")", ":", "\n", "#print(v)", "\n", "#if v != 0:", "\n", "            ", "v", "=", "v", ".", "mean", "(", ")", ".", "float", "(", ")", "\n", "message", "+=", "'%s: %.3f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.convert_visuals_to_numpy": [[156, 165], ["visuals.items", "util.tensor2label", "util.tensor2im"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.tensor2im"], ["", "", "def", "convert_visuals_to_numpy", "(", "self", ",", "visuals", ")", ":", "\n", "        ", "for", "key", ",", "t", "in", "visuals", ".", "items", "(", ")", ":", "\n", "            ", "tile", "=", "self", ".", "opt", ".", "batchSize", ">", "8", "\n", "if", "'input_label'", "==", "key", ":", "\n", "                ", "t", "=", "util", ".", "tensor2label", "(", "t", ",", "self", ".", "opt", ".", "label_nc", "+", "2", ",", "tile", "=", "tile", ")", "\n", "", "else", ":", "\n", "                ", "t", "=", "util", ".", "tensor2im", "(", "t", ",", "tile", "=", "tile", ")", "\n", "", "visuals", "[", "key", "]", "=", "t", "\n", "", "return", "visuals", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.save_images": [[167, 188], ["visualizer.Visualizer.convert_visuals_to_numpy", "webpage.get_image_dir", "ntpath.basename", "webpage.add_header", "visualizer.Visualizer.items", "webpage.add_images", "os.path.splitext", "os.path.join", "os.path.join", "util.save_image", "ims.append", "txts.append", "links.append"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.visualizer.Visualizer.convert_visuals_to_numpy", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.get_image_dir", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_header", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.html.HTML.add_images", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.save_image"], ["", "def", "save_images", "(", "self", ",", "webpage", ",", "visuals", ",", "image_path", ")", ":", "\n", "        ", "visuals", "=", "self", ".", "convert_visuals_to_numpy", "(", "visuals", ")", "\n", "\n", "image_dir", "=", "webpage", ".", "get_image_dir", "(", ")", "\n", "short_path", "=", "ntpath", ".", "basename", "(", "image_path", "[", "0", "]", ")", "\n", "name", "=", "os", ".", "path", ".", "splitext", "(", "short_path", ")", "[", "0", "]", "\n", "\n", "webpage", ".", "add_header", "(", "name", ")", "\n", "ims", "=", "[", "]", "\n", "txts", "=", "[", "]", "\n", "links", "=", "[", "]", "\n", "\n", "for", "label", ",", "image_numpy", "in", "visuals", ".", "items", "(", ")", ":", "\n", "            ", "image_name", "=", "os", ".", "path", ".", "join", "(", "label", ",", "'%s.png'", "%", "(", "name", ")", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "image_name", ")", "\n", "util", ".", "save_image", "(", "image_numpy", ",", "save_path", ",", "create_dir", "=", "True", ")", "\n", "\n", "ims", ".", "append", "(", "image_name", ")", "\n", "txts", ".", "append", "(", "label", ")", "\n", "links", ".", "append", "(", "image_name", ")", "\n", "", "webpage", ".", "add_images", "(", "ims", ",", "txts", ",", "links", ",", "width", "=", "self", ".", "win_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_obj": [[14, 17], ["open", "dill.dump"], "function", ["None"], ["def", "save_obj", "(", "obj", ",", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.load_obj": [[19, 22], ["open", "dill.load"], "function", ["None"], ["", "", "def", "load_obj", "(", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copyconf": [[28, 34], ["argparse.Namespace", "print", "setattr", "vars"], "function", ["None"], ["", "", "def", "copyconf", "(", "default_opt", ",", "**", "kwargs", ")", ":", "\n", "    ", "conf", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "default_opt", ")", ")", "\n", "for", "key", "in", "kwargs", ":", "\n", "        ", "print", "(", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "setattr", "(", "conf", ",", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "", "return", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.tile_images": [[36, 56], ["range", "numpy.concatenate", "numpy.concatenate", "np.concatenate.append", "numpy.concatenate", "numpy.zeros", "range"], "function", ["None"], ["", "def", "tile_images", "(", "imgs", ",", "picturesPerRow", "=", "4", ")", ":", "\n", "    ", "\"\"\" Code borrowed from\n    https://stackoverflow.com/questions/26521365/cleanly-tile-numpy-array-of-images-stored-in-a-flattened-1d-format/26521997\n    \"\"\"", "\n", "\n", "# Padding", "\n", "if", "imgs", ".", "shape", "[", "0", "]", "%", "picturesPerRow", "==", "0", ":", "\n", "        ", "rowPadding", "=", "0", "\n", "", "else", ":", "\n", "        ", "rowPadding", "=", "picturesPerRow", "-", "imgs", ".", "shape", "[", "0", "]", "%", "picturesPerRow", "\n", "", "if", "rowPadding", ">", "0", ":", "\n", "        ", "imgs", "=", "np", ".", "concatenate", "(", "[", "imgs", ",", "np", ".", "zeros", "(", "(", "rowPadding", ",", "*", "imgs", ".", "shape", "[", "1", ":", "]", ")", ",", "dtype", "=", "imgs", ".", "dtype", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "# Tiling Loop (The conditionals are not necessary anymore)", "\n", "", "tiled", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "imgs", ".", "shape", "[", "0", "]", ",", "picturesPerRow", ")", ":", "\n", "        ", "tiled", ".", "append", "(", "np", ".", "concatenate", "(", "[", "imgs", "[", "j", "]", "for", "j", "in", "range", "(", "i", ",", "i", "+", "picturesPerRow", ")", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "tiled", "=", "np", ".", "concatenate", "(", "tiled", ",", "axis", "=", "0", ")", "\n", "return", "tiled", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.tensor2im": [[60, 94], ["isinstance", "image_tensor.unsqueeze.detach().cpu().float().numpy", "numpy.clip", "np.clip.astype", "range", "image_tensor.unsqueeze.dim", "range", "numpy.concatenate", "image_tensor.unsqueeze.dim", "image_tensor.unsqueeze.unsqueeze", "len", "np.clip.append", "image_tensor.unsqueeze.size", "util.tensor2im", "np.concatenate.append", "util.tile_images", "image_tensor.unsqueeze.detach().cpu().float", "numpy.transpose", "util.tensor2im", "tensor2im.reshape", "len", "image_tensor.unsqueeze.detach().cpu", "numpy.transpose", "image_tensor.unsqueeze.detach"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.tensor2im", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.tile_images", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.tensor2im"], ["", "def", "tensor2im", "(", "image_tensor", ",", "imtype", "=", "np", ".", "uint8", ",", "normalize", "=", "True", ",", "tile", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "image_tensor", ",", "list", ")", ":", "\n", "        ", "image_numpy", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "image_tensor", ")", ")", ":", "\n", "            ", "image_numpy", ".", "append", "(", "tensor2im", "(", "image_tensor", "[", "i", "]", ",", "imtype", ",", "normalize", ")", ")", "\n", "", "return", "image_numpy", "\n", "\n", "", "if", "image_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "# transform each image in the batch", "\n", "        ", "images_np", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "image_tensor", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "one_image", "=", "image_tensor", "[", "b", "]", "\n", "one_image_np", "=", "tensor2im", "(", "one_image", ")", "\n", "images_np", ".", "append", "(", "one_image_np", ".", "reshape", "(", "1", ",", "*", "one_image_np", ".", "shape", ")", ")", "\n", "", "images_np", "=", "np", ".", "concatenate", "(", "images_np", ",", "axis", "=", "0", ")", "\n", "if", "tile", ":", "\n", "            ", "images_tiled", "=", "tile_images", "(", "images_np", ")", "\n", "return", "images_tiled", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "images_np", ".", "shape", ")", "==", "4", "and", "images_np", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                ", "images_np", "=", "images_np", "[", "0", "]", "\n", "", "return", "images_np", "\n", "\n", "", "", "if", "image_tensor", ".", "dim", "(", ")", "==", "2", ":", "\n", "        ", "image_tensor", "=", "image_tensor", ".", "unsqueeze", "(", "0", ")", "\n", "", "image_numpy", "=", "image_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "if", "normalize", ":", "\n", "        ", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "\n", "", "else", ":", "\n", "        ", "image_numpy", "=", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "*", "255.0", "\n", "", "image_numpy", "=", "np", ".", "clip", "(", "image_numpy", ",", "0", ",", "255", ")", "\n", "if", "image_numpy", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "image_numpy", "=", "image_numpy", "[", ":", ",", ":", ",", "0", "]", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_image": [[97, 110], ["PIL.Image.fromarray", "Image.fromarray.save", "os.makedirs", "len", "len", "numpy.expand_dims", "numpy.repeat", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ",", "create_dir", "=", "False", ")", ":", "\n", "    ", "if", "create_dir", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "image_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "len", "(", "image_numpy", ".", "shape", ")", "==", "4", ":", "\n", "        ", "image_numpy", "=", "image_numpy", "[", "0", "]", "\n", "", "if", "len", "(", "image_numpy", ".", "shape", ")", "==", "2", ":", "\n", "        ", "image_numpy", "=", "np", ".", "expand_dims", "(", "image_numpy", ",", "axis", "=", "2", ")", "\n", "", "if", "image_numpy", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "image_numpy", "=", "np", ".", "repeat", "(", "image_numpy", ",", "3", ",", "2", ")", "\n", "", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "\n", "# save to png", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "# image_pil.save(image_path.replace('.jpg', '.png'))", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_torch_img": [[113, 117], ["util.tensor2im", "util.save_image"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.tensor2im", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.save_image"], ["", "def", "save_torch_img", "(", "img", ",", "save_path", ")", ":", "\n", "    ", "image_numpy", "=", "tensor2im", "(", "img", ",", "tile", "=", "False", ")", "\n", "save_image", "(", "image_numpy", ",", "save_path", ",", "create_dir", "=", "True", ")", "\n", "return", "image_numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.mkdirs": [[120, 126], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir"], ["", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.mkdir": [[128, 131], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.atoi": [[133, 135], ["text.isdigit", "int"], "function", ["None"], ["", "", "def", "atoi", "(", "text", ")", ":", "\n", "    ", "return", "int", "(", "text", ")", "if", "text", ".", "isdigit", "(", ")", "else", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.natural_keys": [[137, 144], ["util.atoi", "re.split"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.atoi"], ["", "def", "natural_keys", "(", "text", ")", ":", "\n", "    ", "'''\n    alist.sort(key=natural_keys) sorts in human order\n    http://nedbatchelder.com/blog/200712/human_sorting.html\n    (See Toothy's implementation in the comments)\n    '''", "\n", "return", "[", "atoi", "(", "c", ")", "for", "c", "in", "re", ".", "split", "(", "'(\\d+)'", ",", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.natural_sort": [[146, 148], ["items.sort"], "function", ["None"], ["", "def", "natural_sort", "(", "items", ")", ":", "\n", "    ", "items", ".", "sort", "(", "key", "=", "natural_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.str2bool": [[150, 157], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.find_class_in_module": [[159, 172], ["target_cls_name.replace().lower.replace().lower", "importlib.import_module", "importlib.import_module.__dict__.items", "print", "exit", "target_cls_name.replace().lower.replace", "name.lower"], "function", ["None"], ["", "", "def", "find_class_in_module", "(", "target_cls_name", ",", "module", ")", ":", "\n", "    ", "target_cls_name", "=", "target_cls_name", ".", "replace", "(", "'_'", ",", "''", ")", ".", "lower", "(", ")", "\n", "clslib", "=", "importlib", ".", "import_module", "(", "module", ")", "\n", "cls", "=", "None", "\n", "for", "name", ",", "clsobj", "in", "clslib", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "name", ".", "lower", "(", ")", "==", "target_cls_name", ":", "\n", "            ", "cls", "=", "clsobj", "\n", "\n", "", "", "if", "cls", "is", "None", ":", "\n", "        ", "print", "(", "\"In %s, there should be a class whose name matches %s in lowercase without underscore(_)\"", "%", "(", "module", ",", "target_cls_name", ")", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network": [[174, 180], ["os.path.join", "torch.save", "net.cpu().state_dict", "len", "torch.cuda.is_available", "net.cuda", "net.cpu"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save"], ["", "def", "save_network", "(", "net", ",", "label", ",", "epoch", ",", "opt", ")", ":", "\n", "    ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "label", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "save_filename", ")", "\n", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "if", "len", "(", "opt", ".", "gpu_ids", ")", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "net", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.load_network": [[182, 189], ["os.path.join", "os.path.join", "torch.load", "net.load_state_dict"], "function", ["None"], ["", "", "def", "load_network", "(", "net", ",", "label", ",", "epoch", ",", "opt", ")", ":", "\n", "    ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "label", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "save_filename", ")", "\n", "weights", "=", "torch", ".", "load", "(", "save_path", ")", "\n", "net", ".", "load_state_dict", "(", "weights", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copy_state_dict": [[191, 212], ["model.state_dict", "set", "state_dict.items", "isinstance", "tgt_state[].copy_", "set.add", "set", "len", "print", "name.replace.startswith", "name.replace.replace", "param.size", "tgt_state[].size", "print", "model.state_dict.keys", "param.size", "tgt_state[].size", "len"], "function", ["None"], ["", "def", "copy_state_dict", "(", "state_dict", ",", "model", ",", "strip", "=", "None", ",", "replace", "=", "None", ")", ":", "\n", "    ", "tgt_state", "=", "model", ".", "state_dict", "(", ")", "\n", "copied_names", "=", "set", "(", ")", "\n", "for", "name", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "strip", "is", "not", "None", "and", "replace", "is", "None", "and", "name", ".", "startswith", "(", "strip", ")", ":", "\n", "            ", "name", "=", "name", "[", "len", "(", "strip", ")", ":", "]", "\n", "", "if", "strip", "is", "not", "None", "and", "replace", "is", "not", "None", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "strip", ",", "replace", ")", "\n", "", "if", "name", "not", "in", "tgt_state", ":", "\n", "            ", "continue", "\n", "", "if", "isinstance", "(", "param", ",", "torch", ".", "nn", ".", "Parameter", ")", ":", "\n", "            ", "param", "=", "param", ".", "data", "\n", "", "if", "param", ".", "size", "(", ")", "!=", "tgt_state", "[", "name", "]", ".", "size", "(", ")", ":", "\n", "            ", "print", "(", "'mismatch:'", ",", "name", ",", "param", ".", "size", "(", ")", ",", "tgt_state", "[", "name", "]", ".", "size", "(", ")", ")", "\n", "continue", "\n", "", "tgt_state", "[", "name", "]", ".", "copy_", "(", "param", ")", "\n", "copied_names", ".", "add", "(", "name", ")", "\n", "\n", "", "missing", "=", "set", "(", "tgt_state", ".", "keys", "(", ")", ")", "-", "copied_names", "\n", "if", "len", "(", "missing", ")", ">", "0", ":", "\n", "        ", "print", "(", "\"missing keys in state_dict:\"", ",", "missing", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model": [[215, 218], ["net.parameters"], "function", ["None"], ["", "", "def", "freeze_model", "(", "net", ")", ":", "\n", "    ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "param", ".", "requires_grad", "=", "False", "\n", "###############################################################################", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.uint82bin": [[223, 226], ["str", "range"], "function", ["None"], ["", "", "def", "uint82bin", "(", "n", ",", "count", "=", "8", ")", ":", "\n", "    ", "\"\"\"returns the binary of integer n, count refers to amount of bits\"\"\"", "\n", "return", "''", ".", "join", "(", "[", "str", "(", "(", "n", ">>", "y", ")", "&", "1", ")", "for", "y", "in", "range", "(", "count", "-", "1", ",", "-", "1", ",", "-", "1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.build_landmark_dict": [[227, 249], ["open", "f.readlines", "line.strip().split", "paths.append", "float", "len", "line.strip", "key.split", "float", "len", "float", "len", "float"], "function", ["None"], ["", "def", "build_landmark_dict", "(", "ldmk_path", ")", ":", "\n", "    ", "with", "open", "(", "ldmk_path", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "ldmk_dict", "=", "{", "}", "\n", "paths", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "info", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "key", "=", "info", "[", "-", "1", "]", "\n", "if", "\"/\"", "in", "key", ":", "\n", "            ", "key", "=", "key", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "# key = int(key.split(\".\")[0])", "\n", "", "value", "=", "info", "[", ":", "-", "1", "]", "\n", "paths", ".", "append", "(", "key", ")", "\n", "value", "=", "[", "float", "(", "it", ")", "for", "it", "in", "value", "]", "\n", "if", "len", "(", "info", ")", "==", "106", "*", "2", "+", "1", ":", "# landmark+name", "\n", "            ", "value", "=", "[", "float", "(", "it", ")", "for", "it", "in", "info", "[", ":", "106", "*", "2", "]", "]", "\n", "", "elif", "len", "(", "info", ")", "==", "106", "*", "2", "+", "1", "+", "6", ":", "# affmat+landmark+name", "\n", "            ", "value", "=", "[", "float", "(", "it", ")", "for", "it", "in", "info", "[", "6", ":", "106", "*", "2", "+", "6", "]", "]", "\n", "", "elif", "len", "(", "info", ")", "==", "20", "*", "2", "+", "2", ":", "# mouth landmark+name", "\n", "            ", "value", "=", "[", "float", "(", "it", ")", "for", "it", "in", "info", "[", ":", "-", "1", "]", "]", "\n", "", "ldmk_dict", "[", "key", "]", "=", "value", "\n", "", "return", "ldmk_dict", ",", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.get_affine": [[251, 256], ["skimage.SimilarityTransform", "trans.SimilarityTransform.estimate"], "function", ["None"], ["", "def", "get_affine", "(", "src", ",", "dst", ")", ":", "\n", "    ", "tform", "=", "trans", ".", "SimilarityTransform", "(", ")", "\n", "tform", ".", "estimate", "(", "src", ",", "dst", ")", "\n", "M", "=", "tform", ".", "params", "[", "0", ":", "2", ",", ":", "]", "\n", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.affine_align_img": [[257, 260], ["cv2.warpAffine"], "function", ["None"], ["", "def", "affine_align_img", "(", "img", ",", "M", ",", "crop_size", "=", "224", ")", ":", "\n", "    ", "warped", "=", "cv2", ".", "warpAffine", "(", "img", ",", "M", ",", "(", "crop_size", ",", "crop_size", ")", ",", "borderValue", "=", "0.0", ")", "\n", "return", "warped", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.calc_loop_idx": [[261, 265], ["None"], "function", ["None"], ["", "def", "calc_loop_idx", "(", "idx", ",", "loop_num", ")", ":", "\n", "    ", "flag", "=", "-", "1", "*", "(", "(", "idx", "//", "loop_num", "%", "2", ")", "*", "2", "-", "1", ")", "\n", "new_idx", "=", "-", "flag", "*", "(", "flag", "-", "1", ")", "//", "2", "+", "flag", "*", "(", "idx", "%", "loop_num", ")", "\n", "return", "(", "new_idx", "+", "loop_num", ")", "%", "loop_num", "\n", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.modify_commandline_options": [[10, 14], ["models.modify_commandline_options"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "networks", ".", "modify_commandline_options", "(", "parser", ",", "is_train", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.__init__": [[15, 49], ["super().__init__", "os.path.join", "av_model.AvModel.initialize_networks", "av_model.AvModel.use_gpu", "av_model.AvModel.use_gpu", "models.networks.loss.CrossEntropyLoss", "torch.nn.L1Loss", "models.SoftmaxContrastiveLoss", "models.GANLoss", "models.L2SoftmaxLoss", "models.VGGLoss", "models.networks.architecture.VGGFace19", "models.VGGLoss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.initialize_networks", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.use_gpu", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.use_gpu"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AvModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "self", ".", "FloatTensor", "=", "torch", ".", "cuda", ".", "FloatTensor", "if", "self", ".", "use_gpu", "(", ")", "else", "torch", ".", "FloatTensor", "\n", "self", ".", "ByteTensor", "=", "torch", ".", "cuda", ".", "ByteTensor", "if", "self", ".", "use_gpu", "(", ")", "else", "torch", ".", "ByteTensor", "\n", "self", ".", "netG", ",", "self", ".", "netD", ",", "self", ".", "netA", ",", "self", ".", "netA_sync", ",", "self", ".", "netV", ",", "self", ".", "netE", "=", "self", ".", "initialize_networks", "(", "opt", ")", "\n", "\n", "# set loss functions", "\n", "if", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "loss_cls", "=", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "criterionFeat", "=", "torch", ".", "nn", ".", "L1Loss", "(", ")", "\n", "\n", "if", "opt", ".", "softmax_contrastive", ":", "\n", "                ", "self", ".", "criterionSoftmaxContrastive", "=", "networks", ".", "SoftmaxContrastiveLoss", "(", ")", "\n", "", "if", "opt", ".", "train_recognition", "or", "opt", ".", "train_sync", ":", "\n", "                ", "pass", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "criterionGAN", "=", "networks", ".", "GANLoss", "(", "\n", "opt", ".", "gan_mode", ",", "tensor", "=", "self", ".", "FloatTensor", ",", "opt", "=", "self", ".", "opt", ")", "\n", "\n", "if", "not", "opt", ".", "no_vgg_loss", ":", "\n", "                    ", "self", ".", "criterionVGG", "=", "networks", ".", "VGGLoss", "(", "self", ".", "opt", ")", "\n", "\n", "", "if", "opt", ".", "vgg_face", ":", "\n", "                    ", "self", ".", "VGGFace", "=", "VGGFace19", "(", "self", ".", "opt", ")", "\n", "self", ".", "criterionVGGFace", "=", "networks", ".", "VGGLoss", "(", "self", ".", "opt", ",", "self", ".", "VGGFace", ")", "\n", "\n", "", "", "if", "opt", ".", "disentangle", ":", "\n", "                ", "self", ".", "criterionLogSoftmax", "=", "networks", ".", "L2SoftmaxLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.preprocessing": [[55, 65], ["data[].cuda", "data[].cuda", "data[].cuda", "target_images.view.view.view", "augmented.view.view.view", "data[].cuda"], "methods", ["None"], ["", "", "", "def", "preprocessing", "(", "self", ",", "data", ")", ":", "\n", "        ", "target_images", "=", "data", "[", "'target'", "]", ".", "cuda", "(", ")", "\n", "input_image", "=", "data", "[", "'input'", "]", ".", "cuda", "(", ")", "\n", "augmented", "=", "data", "[", "'augmented'", "]", ".", "cuda", "(", ")", "\n", "spectrogram", "=", "data", "[", "'spectrograms'", "]", ".", "cuda", "(", ")", "if", "self", ".", "opt", ".", "use_audio", "else", "None", "\n", "\n", "target_images", "=", "target_images", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "augmented", "=", "augmented", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "\n", "return", "input_image", ",", "target_images", ",", "augmented", ",", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.forward": [[66, 98], ["av_model.AvModel.preprocessing", "av_model.AvModel.compute_generator_loss", "av_model.AvModel.compute_encoder_loss", "av_model.AvModel.sync", "av_model.AvModel.sync_D", "av_model.AvModel.compute_discriminator_loss", "data[].cuda", "ValueError", "torch.no_grad", "av_model.AvModel.inference"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.preprocessing", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_generator_loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_encoder_loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.sync", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.sync_D", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_discriminator_loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.inference"], ["", "def", "forward", "(", "self", ",", "data", ",", "mode", ")", ":", "\n", "        ", "labels", "=", "data", "[", "'label'", "]", "\n", "input_image", ",", "target_images", ",", "augmentated", ",", "spectrogram", "=", "self", ".", "preprocessing", "(", "data", ")", "\n", "if", "mode", "==", "'generator'", ":", "\n", "            ", "g_loss", ",", "generated", ",", "id_scores", "=", "self", ".", "compute_generator_loss", "(", "\n", "input_image", ",", "target_images", ",", "augmentated", ",", "spectrogram", ",", "\n", "netD", "=", "self", ".", "netD", ",", "labels", "=", "labels", ",", "no_ganFeat_loss", "=", "self", ".", "opt", ".", "no_ganFeat_loss", ",", "\n", "no_vgg_loss", "=", "self", ".", "opt", ".", "no_vgg_loss", ",", "lambda_D", "=", "self", ".", "opt", ".", "lambda_D", ")", "\n", "return", "g_loss", ",", "generated", ",", "id_scores", "\n", "", "if", "mode", "==", "'encoder'", ":", "\n", "            ", "g_loss", ",", "cls_score", "=", "self", ".", "compute_encoder_loss", "(", "\n", "input_image", ",", "target_images", ",", "spectrogram", ",", "labels", ")", "\n", "return", "g_loss", ",", "cls_score", "\n", "", "if", "mode", "==", "'sync'", ":", "\n", "            ", "g_loss", "=", "self", ".", "sync", "(", "augmentated", ",", "spectrogram", ")", "\n", "return", "g_loss", "\n", "", "if", "mode", "==", "'sync_D'", ":", "\n", "            ", "d_loss", "=", "self", ".", "sync_D", "(", "spectrogram", ",", "labels", ")", "\n", "return", "d_loss", "\n", "", "elif", "mode", "==", "'discriminator'", ":", "\n", "            ", "d_loss", "=", "self", ".", "compute_discriminator_loss", "(", "\n", "input_image", ",", "target_images", ",", "augmentated", ",", "spectrogram", ",", "netD", "=", "self", ".", "netD", ",", "labels", "=", "labels", ",", "lambda_D", "=", "self", ".", "opt", ".", "lambda_D", ")", "\n", "return", "d_loss", "\n", "", "elif", "mode", "==", "'inference'", ":", "\n", "            ", "assert", "self", ".", "opt", ".", "use_audio", ",", "'must use audio driven strategy.'", "\n", "driving_pose_frames", "=", "data", "[", "'driving_pose_frames'", "]", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "fake_image_ref_pose_a", ",", "fake_image_driven_pose_a", "=", "self", ".", "inference", "(", "input_image", ",", "spectrogram", ",", "\n", "driving_pose_frames", ")", "\n", "", "return", "fake_image_ref_pose_a", ",", "fake_image_driven_pose_a", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"|mode| is invalid\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.create_optimizers": [[99, 225], ["util.freeze_model", "av_model.AvModel.netV.fc.parameters", "list", "list", "torch.optim.SGD", "torch.optim.Adam", "av_model.AvModel.netV.fc.parameters", "av_model.AvModel.netA.parameters", "list", "list", "torch.optim.Adam", "av_model.AvModel.netA_sync.model.parameters", "av_model.AvModel.netE.to_mouth.parameters", "list", "list", "list", "list", "list", "list", "list", "list", "list", "av_model.AvModel.netA_sync.fc.parameters", "av_model.AvModel.netE.classifier.parameters", "list", "list", "av_model.AvModel.netG.parameters", "av_model.AvModel.netV.parameters", "av_model.AvModel.netE.model.parameters", "list", "list", "list", "util.freeze_model", "util.freeze_model", "util.freeze_model", "util.freeze_model", "util.freeze_model", "util.freeze_model", "util.freeze_model", "list", "av_model.AvModel.netG.parameters", "list", "av_model.AvModel.netE.to_mouth.parameters", "av_model.AvModel.netV.parameters", "av_model.AvModel.netE.model.parameters", "util.freeze_model", "util.freeze_model", "util.freeze_model", "list", "av_model.AvModel.netE.pure_pose.parameters", "av_model.AvModel.netE.headpose_embed.parameters", "av_model.AvModel.netA_sync.parameters", "av_model.AvModel.netE.to_mouth.parameters", "av_model.AvModel.netE.mouth_fc.parameters", "util.freeze_model", "av_model.AvModel.netD.parameters", "torch.optim.Adam", "util.freeze_model", "av_model.AvModel.netA_sync.model.parameters", "av_model.AvModel.netD.parameters", "torch.optim.Adam", "util.freeze_model", "util.freeze_model", "list", "list", "av_model.AvModel.netE.classifier.parameters", "av_model.AvModel.netE.headpose_fc.parameters"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.freeze_model"], ["", "", "def", "create_optimizers", "(", "self", ",", "opt", ")", ":", "\n", "        ", "optimizer_D", "=", "None", "\n", "if", "opt", ".", "no_TTUR", ":", "\n", "            ", "beta1", ",", "beta2", "=", "opt", ".", "beta1", ",", "opt", ".", "beta2", "\n", "G_lr", ",", "D_lr", "=", "opt", ".", "lr", ",", "opt", ".", "lr", "\n", "", "else", ":", "\n", "            ", "beta1", ",", "beta2", "=", "0", ",", "0.9", "\n", "G_lr", ",", "D_lr", "=", "opt", ".", "lr", "/", "2", ",", "opt", ".", "lr", "*", "2", "\n", "\n", "", "if", "opt", ".", "train_recognition", ":", "\n", "\n", "            ", "util", ".", "freeze_model", "(", "self", ".", "netV", ")", "\n", "for", "param", "in", "self", ".", "netV", ".", "fc", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "True", "\n", "", "netV_params", "=", "list", "(", "self", ".", "netV", ".", "fc", ".", "parameters", "(", ")", ")", "\n", "netA_params", "=", "list", "(", "self", ".", "netA", ".", "parameters", "(", ")", ")", "\n", "G_params", "=", "netV_params", "+", "netA_params", "\n", "\n", "", "elif", "opt", ".", "train_sync", ":", "\n", "\n", "            ", "netA_sync_params", "=", "list", "(", "self", ".", "netA_sync", ".", "model", ".", "parameters", "(", ")", ")", "\n", "# netE_params = list(self.netE.model.parameters())", "\n", "netE_mouth_params", "=", "list", "(", "self", ".", "netE", ".", "to_mouth", ".", "parameters", "(", ")", ")", "\n", "G_params", "=", "netA_sync_params", "+", "netE_mouth_params", "\n", "\n", "D_params", "=", "list", "(", "self", ".", "netA_sync", ".", "fc", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "netE", ".", "classifier", ".", "parameters", "(", ")", ")", "\n", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "D_params", ",", "lr", "=", "D_lr", ",", "betas", "=", "(", "beta1", ",", "beta2", ")", ")", "\n", "\n", "", "elif", "opt", ".", "train_dis_pose", ":", "\n", "            ", "netE_pure_pose_params", "=", "list", "(", "self", ".", "netE", ".", "pure_pose", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "netE", ".", "headpose_embed", ".", "parameters", "(", ")", ")", "\n", "netG_params", "=", "list", "(", "self", ".", "netG", ".", "parameters", "(", ")", ")", "\n", "netV_params", "=", "list", "(", "self", ".", "netV", ".", "parameters", "(", ")", ")", "\n", "netE_params", "=", "list", "(", "self", ".", "netE", ".", "model", ".", "parameters", "(", ")", ")", "\n", "netA_sync_params", "=", "list", "(", "self", ".", "netA_sync", ".", "parameters", "(", ")", ")", "if", "self", ".", "opt", ".", "use_audio", "else", "None", "\n", "netE_mouth_all_params", "=", "list", "(", "self", ".", "netE", ".", "to_mouth", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "netE", ".", "mouth_fc", ".", "parameters", "(", ")", ")", "\n", "\n", "G_params", "=", "[", "]", "\n", "\n", "if", "not", "opt", ".", "fix_netE_mouth", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netE_mouth_all_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "to_mouth", ")", "\n", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "mouth_fc", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netE_headpose", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netE_pure_pose_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "pure_pose", ")", "\n", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "headpose_embed", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netG", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netG_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netG", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netV", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netV_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netV", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netE", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netE_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "model", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "if", "not", "opt", ".", "fix_netA_sync", ":", "\n", "                    ", "G_params", "=", "G_params", "+", "netA_sync_params", "\n", "", "else", ":", "\n", "                    ", "util", ".", "freeze_model", "(", "self", ".", "netA_sync", ")", "\n", "\n", "", "", "if", "opt", ".", "isTrain", ":", "\n", "                ", "D_params", "=", "list", "(", "self", ".", "netD", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "disentangle", ":", "\n", "\n", "                    ", "if", "not", "opt", ".", "fix_netE_headpose", ":", "\n", "                        ", "D_params", "=", "list", "(", "self", ".", "netE", ".", "headpose_fc", ".", "parameters", "(", ")", ")", "+", "D_params", "\n", "", "else", ":", "\n", "                        ", "util", ".", "freeze_model", "(", "self", ".", "netE", ".", "headpose_fc", ")", "\n", "\n", "", "", "if", "not", "opt", ".", "fix_netD", ":", "\n", "                    ", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "D_params", ",", "lr", "=", "D_lr", ",", "betas", "=", "(", "beta1", ",", "beta2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "util", ".", "freeze_model", "(", "self", ".", "netD", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "netG_params", "=", "list", "(", "self", ".", "netG", ".", "parameters", "(", ")", ")", "\n", "netA_sync_params", "=", "list", "(", "self", ".", "netA_sync", ".", "model", ".", "parameters", "(", ")", ")", "if", "opt", ".", "use_audio", "else", "0", "\n", "netE_mouth_params", "=", "list", "(", "self", ".", "netE", ".", "to_mouth", ".", "parameters", "(", ")", ")", "\n", "netV_params", "=", "list", "(", "self", ".", "netV", ".", "parameters", "(", ")", ")", "\n", "netE_params", "=", "list", "(", "self", ".", "netE", ".", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "G_params", "=", "netA_sync_params", "+", "netE_mouth_params", "\n", "if", "not", "opt", ".", "fix_netV", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netV_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netV", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netE", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netE_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netE", ")", "\n", "\n", "", "if", "not", "opt", ".", "fix_netG", ":", "\n", "                ", "G_params", "=", "G_params", "+", "netG_params", "\n", "", "else", ":", "\n", "                ", "util", ".", "freeze_model", "(", "self", ".", "netG", ")", "\n", "\n", "", "if", "opt", ".", "isTrain", ":", "\n", "                ", "D_params", "=", "list", "(", "self", ".", "netD", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "disentangle", ":", "\n", "                    ", "D_params", "=", "list", "(", "self", ".", "netE", ".", "classifier", ".", "parameters", "(", ")", ")", "+", "D_params", "\n", "\n", "", "if", "not", "opt", ".", "fix_netD", ":", "\n", "                    ", "optimizer_D", "=", "torch", ".", "optim", ".", "Adam", "(", "D_params", ",", "lr", "=", "D_lr", ",", "betas", "=", "(", "beta1", ",", "beta2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "util", ".", "freeze_model", "(", "self", ".", "netD", ")", "\n", "\n", "", "", "", "if", "opt", ".", "optimizer", "==", "'sgd'", ":", "\n", "            ", "optimizer_G", "=", "torch", ".", "optim", ".", "SGD", "(", "G_params", ",", "lr", "=", "G_lr", ",", "momentum", "=", "0.9", ",", "nesterov", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "G_params", ",", "lr", "=", "G_lr", ",", "betas", "=", "(", "beta1", ",", "beta2", ")", ",", "amsgrad", "=", "True", ")", "\n", "\n", "", "return", "optimizer_G", ",", "optimizer_D", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save": [[226, 242], ["util.save_network", "util.save_network", "util.save_network", "util.save_network", "util.save_network", "util.save_network", "util.save_network", "util.save_network"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.save_network"], ["", "def", "save", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "if", "self", ".", "opt", ".", "train_recognition", ":", "\n", "            ", "util", ".", "save_network", "(", "self", ".", "netV", ",", "'V'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "", "elif", "self", ".", "opt", ".", "train_sync", ":", "\n", "            ", "util", ".", "save_network", "(", "self", ".", "netE", ",", "'E'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "util", ".", "save_network", "(", "self", ".", "netA_sync", ",", "'A_sync'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "", "", "else", ":", "\n", "            ", "util", ".", "save_network", "(", "self", ".", "netG", ",", "'G'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "# util.save_network(self.netD, 'D', epoch, self.opt)", "\n", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "if", "self", ".", "opt", ".", "use_audio_id", ":", "\n", "                    ", "util", ".", "save_network", "(", "self", ".", "netA", ",", "'A'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "", "util", ".", "save_network", "(", "self", ".", "netA_sync", ",", "'A_sync'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "", "util", ".", "save_network", "(", "self", ".", "netV", ",", "'V'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "util", ".", "save_network", "(", "self", ".", "netE", ",", "'E'", ",", "epoch", ",", "self", ".", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.initialize_networks": [[248, 298], ["models.define_V", "av_model.AvModel.load_network", "av_model.AvModel.load_network", "av_model.AvModel.load_network", "models.define_E", "models.define_G", "models.define_E", "models.define_V", "av_model.AvModel.load_network", "av_model.AvModel.load_network", "av_model.AvModel.load_pretrain", "av_model.AvModel.load_separately", "av_model.AvModel.load_separately", "av_model.AvModel.load_separately", "models.define_A_sync", "models.define_A", "models.define_A_sync", "models.define_D", "av_model.AvModel.load_network", "av_model.AvModel.load_pretrain", "av_model.AvModel.load_separately", "av_model.AvModel.load_separately", "av_model.AvModel.load_separately"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_V", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_E", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_G", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_E", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_V", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.load_pretrain", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_A_sync", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_A", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_A_sync", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_D", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.load_pretrain", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately"], ["", "", "def", "initialize_networks", "(", "self", ",", "opt", ")", ":", "\n", "        ", "netG", "=", "None", "\n", "netD", "=", "None", "\n", "netE", "=", "None", "\n", "netV", "=", "None", "\n", "netA", "=", "None", "\n", "netA_sync", "=", "None", "\n", "if", "opt", ".", "train_recognition", ":", "\n", "            ", "netV", "=", "networks", ".", "define_V", "(", "opt", ")", "\n", "", "elif", "opt", ".", "train_sync", ":", "\n", "            ", "netA_sync", "=", "networks", ".", "define_A_sync", "(", "opt", ")", "if", "opt", ".", "use_audio", "else", "None", "\n", "netE", "=", "networks", ".", "define_E", "(", "opt", ")", "\n", "", "else", ":", "\n", "\n", "            ", "netG", "=", "networks", ".", "define_G", "(", "opt", ")", "\n", "netA", "=", "networks", ".", "define_A", "(", "opt", ")", "if", "opt", ".", "use_audio", "and", "opt", ".", "use_audio_id", "else", "None", "\n", "netA_sync", "=", "networks", ".", "define_A_sync", "(", "opt", ")", "if", "opt", ".", "use_audio", "else", "None", "\n", "netE", "=", "networks", ".", "define_E", "(", "opt", ")", "\n", "netV", "=", "networks", ".", "define_V", "(", "opt", ")", "\n", "\n", "if", "opt", ".", "isTrain", ":", "\n", "                ", "netD", "=", "networks", ".", "define_D", "(", "opt", ")", "\n", "\n", "", "", "if", "not", "opt", ".", "isTrain", "or", "opt", ".", "continue_train", ":", "\n", "            ", "self", ".", "load_network", "(", "netG", ",", "'G'", ",", "opt", ".", "which_epoch", ")", "\n", "self", ".", "load_network", "(", "netV", ",", "'V'", ",", "opt", ".", "which_epoch", ")", "\n", "self", ".", "load_network", "(", "netE", ",", "'E'", ",", "opt", ".", "which_epoch", ")", "\n", "if", "opt", ".", "use_audio", ":", "\n", "                ", "if", "opt", ".", "use_audio_id", ":", "\n", "                    ", "self", ".", "load_network", "(", "netA", ",", "'A'", ",", "opt", ".", "which_epoch", ")", "\n", "", "self", ".", "load_network", "(", "netA_sync", ",", "'A_sync'", ",", "opt", ".", "which_epoch", ")", "\n", "\n", "", "if", "opt", ".", "isTrain", "and", "not", "opt", ".", "noload_D", ":", "\n", "                ", "self", ".", "load_network", "(", "netD", ",", "'D'", ",", "opt", ".", "which_epoch", ")", "\n", "# self.load_network(netD_rotate, 'D_rotate', opt.which_epoch, pretrained_path)", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "opt", ".", "pretrain", ":", "\n", "                ", "if", "opt", ".", "netE", "==", "'fan'", ":", "\n", "                    ", "netE", ".", "load_pretrain", "(", ")", "\n", "", "netV", ".", "load_pretrain", "(", ")", "\n", "", "if", "opt", ".", "load_separately", ":", "\n", "                ", "netG", "=", "self", ".", "load_separately", "(", "netG", ",", "'G'", ",", "opt", ")", "\n", "netA", "=", "self", ".", "load_separately", "(", "netA", ",", "'A'", ",", "opt", ")", "if", "opt", ".", "use_audio", "and", "opt", ".", "use_audio_id", "else", "None", "\n", "netA_sync", "=", "self", ".", "load_separately", "(", "netA_sync", ",", "'A_sync'", ",", "opt", ")", "if", "opt", ".", "use_audio", "else", "None", "\n", "netV", "=", "self", ".", "load_separately", "(", "netV", ",", "'V'", ",", "opt", ")", "\n", "netE", "=", "self", ".", "load_separately", "(", "netE", ",", "'E'", ",", "opt", ")", "\n", "if", "not", "opt", ".", "noload_D", ":", "\n", "                    ", "netD", "=", "self", ".", "load_separately", "(", "netD", ",", "'D'", ",", "opt", ")", "\n", "", "", "", "return", "netG", ",", "netD", ",", "netA", ",", "netA_sync", ",", "netV", ",", "netE", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_encoder_loss": [[299, 319], ["real_image.view.view.view", "av_model.AvModel.netV.forward", "av_model.AvModel.netA.forward", "torch.mean.view", "torch.mean", "av_model.AvModel.loss_cls", "av_model.AvModel.netV.fc.forward", "av_model.AvModel.loss_cls", "av_model.AvModel.criterionFeat", "av_model.AvModel.criterionSoftmaxContrastive", "image_feature.detach", "image_feature.detach"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward"], ["", "def", "compute_encoder_loss", "(", "self", ",", "input_img", ",", "real_image", ",", "spectrogram", ",", "labels", ")", ":", "\n", "        ", "G_losses", "=", "{", "}", "\n", "real_image", "=", "real_image", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "\n", "[", "image_feature", ",", "net_V_feature", "]", ",", "cls_score_V", "=", "self", ".", "netV", ".", "forward", "(", "real_image", ")", "\n", "audio_feature", ",", "cls_score_A_2", "=", "self", ".", "netA", ".", "forward", "(", "spectrogram", ")", "\n", "audio_feature", "=", "audio_feature", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "audio_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "audio_feature", "=", "torch", ".", "mean", "(", "audio_feature", ",", "1", ")", "\n", "\n", "G_losses", "[", "'loss_cls_V'", "]", "=", "self", ".", "loss_cls", "(", "cls_score_V", ",", "labels", ")", "\n", "cls_score_A", "=", "self", ".", "netV", ".", "fc", ".", "forward", "(", "audio_feature", ")", "\n", "G_losses", "[", "'loss_cls_A'", "]", "=", "self", ".", "loss_cls", "(", "cls_score_A", ",", "labels", ")", "\n", "# G_losses['loss_cls_A_2'] = self.loss_cls(cls_score_A_2, labels)", "\n", "if", "not", "self", ".", "opt", ".", "no_cross_modal", ":", "\n", "            ", "G_losses", "[", "'CrossModal'", "]", "=", "self", ".", "criterionFeat", "(", "image_feature", ".", "detach", "(", ")", ",", "audio_feature", ")", "*", "self", ".", "opt", ".", "lambda_crossmodal", "\n", "\n", "", "if", "self", ".", "opt", ".", "softmax_contrastive", ":", "\n", "            ", "G_losses", "[", "'SoftmaxContrastive'", "]", "=", "self", ".", "criterionSoftmaxContrastive", "(", "image_feature", ".", "detach", "(", ")", ",", "audio_feature", ")", "*", "self", ".", "opt", ".", "lambda_contrastive", "\n", "\n", "", "return", "G_losses", ",", "cls_score_A", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.sync_D": [[320, 332], ["av_model.AvModel.netA_sync.fc.forward", "labels.unsqueeze.unsqueeze.unsqueeze", "labels.unsqueeze.unsqueeze.expand", "labels_expand.contiguous().view.contiguous().view.contiguous().view", "av_model.AvModel.loss_cls", "torch.no_grad", "av_model.AvModel.netA_sync.forward_feature", "audio_content_feature.detach.detach.detach", "audio_content_feature.detach.detach.requires_grad_", "labels_expand.contiguous().view.contiguous().view.contiguous"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "sync_D", "(", "self", ",", "spectrogram", ",", "labels", ")", ":", "\n", "        ", "D_losses", "=", "{", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "audio_content_feature", "=", "self", ".", "netA_sync", ".", "forward_feature", "(", "spectrogram", ")", "\n", "audio_content_feature", "=", "audio_content_feature", ".", "detach", "(", ")", "\n", "audio_content_feature", ".", "requires_grad_", "(", ")", "\n", "", "cls_score_A", "=", "self", ".", "netA_sync", ".", "fc", ".", "forward", "(", "audio_content_feature", ")", "\n", "labels", "=", "labels", ".", "unsqueeze", "(", "1", ")", "\n", "labels_expand", "=", "labels", ".", "expand", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ")", "\n", "labels_expand", "=", "labels_expand", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "D_losses", "[", "'loss_cls_A'", "]", "=", "self", ".", "loss_cls", "(", "cls_score_A", ",", "labels_expand", ")", "\n", "return", "D_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_audiosync_feature": [[334, 340], ["av_model.AvModel.netA_sync.forward_feature", "audio_content_feature.view.view.view"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "encode_audiosync_feature", "(", "self", ",", "spectrogram", ")", ":", "\n", "\n", "        ", "audio_content_feature", "=", "self", ".", "netA_sync", ".", "forward_feature", "(", "spectrogram", ")", "\n", "\n", "audio_content_feature", "=", "audio_content_feature", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "audio_content_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "return", "audio_content_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.sync": [[341, 349], ["av_model.AvModel.encode_noid_feature", "av_model.AvModel.encode_audiosync_feature", "av_model.AvModel.compute_sync_loss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_noid_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_audiosync_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_sync_loss"], ["", "def", "sync", "(", "self", ",", "augmented", ",", "spectrogram", ")", ":", "\n", "        ", "G_losses", "=", "{", "}", "\n", "pose_feature", "=", "self", ".", "encode_noid_feature", "(", "augmented", ")", "\n", "\n", "audio_content_feature", "=", "self", ".", "encode_audiosync_feature", "(", "spectrogram", ")", "\n", "\n", "G_losses", "=", "self", ".", "compute_sync_loss", "(", "pose_feature", ",", "audio_content_feature", ",", "G_losses", ")", "\n", "return", "G_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_sync_loss": [[350, 364], ["audio_content_feature.view", "image_content_feature.view", "av_model.AvModel.criterionFeat", "av_model.AvModel.criterionSoftmaxContrastive", "av_model.AvModel.criterionSoftmaxContrastive", "image_content_feature.view.detach", "image_content_feature.view.detach", "audio_content_feature.view.detach"], "methods", ["None"], ["", "def", "compute_sync_loss", "(", "self", ",", "image_content_feature", ",", "audio_content_feature", ",", "G_losses", ",", "name", "=", "''", ")", ":", "\n", "\n", "        ", "audio_content_feature_all", "=", "audio_content_feature", ".", "view", "(", "audio_content_feature", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "image_content_feature_all", "=", "image_content_feature", ".", "view", "(", "image_content_feature", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "if", "not", "self", ".", "opt", ".", "no_cross_modal", ":", "\n", "            ", "G_losses", "[", "'CrossModal{}'", ".", "format", "(", "name", ")", "]", "=", "self", ".", "criterionFeat", "(", "image_content_feature_all", ".", "detach", "(", ")", ",", "\n", "audio_content_feature_all", ")", "*", "self", ".", "opt", ".", "lambda_crossmodal", "\n", "\n", "", "if", "self", ".", "opt", ".", "softmax_contrastive", ":", "\n", "            ", "G_losses", "[", "'SoftmaxContrastive{}'", ".", "format", "(", "name", ")", "]", "=", "self", ".", "criterionSoftmaxContrastive", "(", "image_content_feature_all", ".", "detach", "(", ")", ",", "audio_content_feature_all", ")", "*", "self", ".", "opt", ".", "lambda_contrastive", "\n", "G_losses", "[", "'SoftmaxContrastive_v2a'", "]", "=", "self", ".", "criterionSoftmaxContrastive", "(", "audio_content_feature_all", ".", "detach", "(", ")", ",", "image_content_feature_all", ")", "*", "self", ".", "opt", ".", "lambda_contrastive", "\n", "\n", "", "return", "G_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.audio_identity_feature": [[365, 373], ["id_mel.view.view.view", "av_model.AvModel.netA", "torch.no_grad", "av_model.AvModel.netA"], "methods", ["None"], ["", "def", "audio_identity_feature", "(", "self", ",", "id_mel", ",", "no_grad", "=", "True", ")", ":", "\n", "        ", "id_mel", "=", "id_mel", ".", "view", "(", "-", "1", ",", "1", ",", "id_mel", ".", "shape", "[", "-", "2", "]", ",", "id_mel", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "no_grad", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "id_feature", ",", "id_scores", "=", "self", ".", "netA", "(", "id_mel", ")", "\n", "", "", "else", ":", "\n", "            ", "id_feature", ",", "id_scores", "=", "self", ".", "netA", "(", "id_mel", ")", "\n", "", "return", "id_feature", ",", "id_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_identity_feature": [[374, 387], ["input_img.view.view.view", "id_feature[].unsqueeze().repeat().view", "id_feature[].unsqueeze().repeat().view", "av_model.AvModel.netV", "torch.no_grad", "av_model.AvModel.netV", "id_feature[].unsqueeze().repeat", "id_feature[].unsqueeze().repeat", "id_feature[].unsqueeze", "id_feature[].unsqueeze"], "methods", ["None"], ["", "def", "encode_identity_feature", "(", "self", ",", "input_img", ")", ":", "\n", "\n", "        ", "input_img", "=", "input_img", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "if", "not", "self", ".", "opt", ".", "isTrain", "or", "self", ".", "opt", ".", "fix_netV", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "id_feature", ",", "id_scores", "=", "self", ".", "netV", "(", "input_img", ")", "\n", "", "", "else", ":", "\n", "            ", "id_feature", ",", "id_scores", "=", "self", ".", "netV", "(", "input_img", ")", "\n", "\n", "", "id_feature", "[", "0", "]", "=", "id_feature", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "1", ")", ".", "view", "(", "-", "1", ",", "*", "id_feature", "[", "0", "]", ".", "shape", "[", "1", ":", "]", ")", "\n", "id_feature", "[", "1", "]", "=", "id_feature", "[", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "1", ",", "1", ",", "1", ")", ".", "view", "(", "-", "1", ",", "*", "id_feature", "[", "1", "]", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "return", "id_feature", ",", "id_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_ref_noid": [[388, 395], ["input_img.view.view.view", "av_model.AvModel.view", "av_model.AvModel.mean().unsqueeze().repeat", "torch.no_grad", "av_model.AvModel.netE.forward_feature", "av_model.AvModel.mean().unsqueeze", "av_model.AvModel.mean"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "encode_ref_noid", "(", "self", ",", "input_img", ")", ":", "\n", "        ", "input_img", "=", "input_img", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "ref_noid_feature", "=", "self", ".", "netE", ".", "forward_feature", "(", "input_img", ")", "\n", "", "ref_noid_feature", "=", "ref_noid_feature", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "num_inputs", ",", "ref_noid_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "ref_noid_feature", "=", "ref_noid_feature", ".", "mean", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "1", ")", "\n", "return", "ref_noid_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_pose_diff": [[396, 400], ["pose_feature.view.view.view"], "methods", ["None"], ["", "def", "compute_pose_diff", "(", "self", ",", "pose_feature", ",", "ref_noid_feature", ")", ":", "\n", "        ", "pose_feature", "=", "pose_feature", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "pose_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "pose_differences", "=", "pose_feature", "-", "ref_noid_feature", "\n", "return", "pose_differences", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_diff_loss": [[401, 412], ["pose_feature_audio.view.view.view", "av_model.AvModel.encode_ref_noid", "av_model.AvModel.compute_pose_diff", "av_model.AvModel.compute_sync_loss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_ref_noid", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_pose_diff", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_sync_loss"], ["", "def", "compute_diff_loss", "(", "self", ",", "input_img", ",", "pose_feature", ",", "pose_feature_audio", ",", "G_losses", ")", ":", "\n", "\n", "        ", "pose_feature_audio", "=", "pose_feature_audio", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "pose_feature_audio", ".", "shape", "[", "-", "1", "]", ")", "\n", "ref_noid_feature", "=", "self", ".", "encode_ref_noid", "(", "input_img", ")", "\n", "pose_differences", "=", "self", ".", "compute_pose_diff", "(", "pose_feature", ",", "ref_noid_feature", ")", "\n", "\n", "self", ".", "compute_sync_loss", "(", "pose_differences", ",", "pose_feature_audio", ",", "G_losses", ")", "\n", "\n", "pose_feature_audio", "=", "ref_noid_feature", "+", "pose_feature_audio", "\n", "\n", "return", "pose_feature_audio", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_noid_feature": [[413, 423], ["augmented.view.view.view", "av_model.AvModel.view", "av_model.AvModel.netE.forward_feature", "torch.no_grad", "av_model.AvModel.netE.forward_feature"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "encode_noid_feature", "(", "self", ",", "augmented", ")", ":", "\n", "        ", "augmented", "=", "augmented", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "if", "(", "not", "self", ".", "opt", ".", "isTrain", ")", "or", "self", ".", "opt", ".", "train_sync", "or", "self", ".", "opt", ".", "fix_netE", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "noid_feature", "=", "self", ".", "netE", ".", "forward_feature", "(", "augmented", ")", "\n", "", "", "else", ":", "\n", "            ", "noid_feature", "=", "self", ".", "netE", ".", "forward_feature", "(", "augmented", ")", "\n", "\n", "", "noid_feature", "=", "noid_feature", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "noid_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "return", "noid_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames": [[424, 440], ["len", "in_obj_ts.view", "obj_ts[].contiguous", "in_obj_ts[].contiguous.view", "len", "in_obj_ts[].contiguous", "len", "in_obj_ts.view", "obj_ts[].contiguous", "in_obj_ts[].contiguous.view", "len", "in_obj_ts[].contiguous"], "methods", ["None"], ["", "def", "select_frames", "(", "self", ",", "in_obj_ts", ")", ":", "\n", "        ", "if", "len", "(", "in_obj_ts", ".", "shape", ")", "==", "2", ":", "\n", "            ", "obj_ts", "=", "in_obj_ts", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "in_obj_ts", ".", "shape", "[", "-", "1", "]", ")", "\n", "obj_ts", "=", "obj_ts", "[", ":", ",", ":", ":", "self", ".", "opt", ".", "generate_interval", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "obj_ts", "=", "obj_ts", ".", "view", "(", "-", "1", ",", "obj_ts", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "elif", "len", "(", "in_obj_ts", ".", "shape", ")", "==", "3", ":", "\n", "            ", "obj_ts", "=", "in_obj_ts", "[", ":", ",", ":", ":", "self", ".", "opt", ".", "generate_interval", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "elif", "len", "(", "in_obj_ts", ".", "shape", ")", "==", "4", ":", "\n", "            ", "obj_ts", "=", "in_obj_ts", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", ",", "*", "in_obj_ts", ".", "shape", "[", "1", ":", "]", ")", "\n", "obj_ts", "=", "obj_ts", "[", ":", ",", ":", ":", "self", ".", "opt", ".", "generate_interval", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "obj_ts", "=", "obj_ts", ".", "view", "(", "-", "1", ",", "*", "obj_ts", ".", "shape", "[", "2", ":", "]", ")", "\n", "", "elif", "len", "(", "in_obj_ts", ".", "shape", ")", "==", "5", ":", "\n", "            ", "obj_ts", "=", "in_obj_ts", "[", ":", ",", ":", ":", "self", ".", "opt", ".", "generate_interval", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "return", "obj_ts", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake": [[441, 453], ["pose_feature.view.view.view", "torch.cat", "fake_image.view.view.view", "av_model.AvModel.netG", "av_model.AvModel.netG"], "methods", ["None"], ["", "def", "generate_fake", "(", "self", ",", "id_feature", ",", "pose_feature", ")", ":", "\n", "        ", "pose_feature", "=", "pose_feature", ".", "view", "(", "-", "1", ",", "pose_feature", ".", "shape", "[", "-", "1", "]", ")", "\n", "style", "=", "torch", ".", "cat", "(", "[", "id_feature", "[", "0", "]", ",", "pose_feature", "]", ",", "1", ")", "\n", "style", "=", "[", "style", "]", "\n", "if", "self", ".", "opt", ".", "input_id_feature", ":", "\n", "            ", "fake_image", ",", "style_rgb", "=", "self", ".", "netG", "(", "style", ",", "identity_style", "=", "id_feature", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "fake_image", ",", "style_rgb", "=", "self", ".", "netG", "(", "style", ")", "\n", "\n", "", "fake_image", "=", "fake_image", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "\n", "return", "fake_image", ",", "style_rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose": [[454, 462], ["av_model.AvModel.netE.mouth_embed", "torch.cat", "av_model.AvModel.netE.headpose_embed"], "methods", ["None"], ["", "def", "merge_mouthpose", "(", "self", ",", "mouth_feature", ",", "headpose_feature", ",", "embed_headpose", "=", "False", ")", ":", "\n", "\n", "        ", "mouth_feature", "=", "self", ".", "netE", ".", "mouth_embed", "(", "mouth_feature", ")", "\n", "if", "not", "embed_headpose", ":", "\n", "            ", "headpose_feature", "=", "self", ".", "netE", ".", "headpose_embed", "(", "headpose_feature", ")", "\n", "", "pose_feature", "=", "torch", ".", "cat", "(", "(", "mouth_feature", ",", "headpose_feature", ")", ",", "dim", "=", "2", ")", "\n", "\n", "return", "pose_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.inference": [[463, 493], ["av_model.AvModel.encode_identity_feature", "av_model.AvModel.encode_audiosync_feature", "sel_id_feature.append", "sel_id_feature.append", "av_model.AvModel.encode_ref_noid", "av_model.AvModel.netE.to_headpose", "av_model.AvModel.select_frames", "av_model.AvModel.generate_fake", "av_model.AvModel.select_frames", "av_model.AvModel.select_frames", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.encode_noid_feature", "av_model.AvModel.netE.to_headpose", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.select_frames", "av_model.AvModel.generate_fake"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_identity_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_audiosync_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_ref_noid", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_noid_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake"], ["", "def", "inference", "(", "self", ",", "input_img", ",", "spectrogram", ",", "\n", "driving_pose_frames", ",", "mouth_feature_weight", "=", "1.2", ")", ":", "\n", "\n", "##### ***************** encode image feature and generate ******************************", "\n", "        ", "id_feature", ",", "_", "=", "self", ".", "encode_identity_feature", "(", "input_img", ")", "\n", "\n", "fake_image_pose_driven_a", "=", "None", "\n", "if", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "            ", "assert", "self", ".", "opt", ".", "use_audio", ",", "'must use audio in this case'", "\n", "\n", "", "A_mouth_feature", "=", "self", ".", "encode_audiosync_feature", "(", "spectrogram", ")", "\n", "A_mouth_feature", "=", "A_mouth_feature", "*", "mouth_feature_weight", "\n", "\n", "sel_id_feature", "=", "[", "]", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "0", "]", ")", ")", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "1", "]", ")", ")", "\n", "\n", "V_noid_ref_feature", "=", "self", ".", "encode_ref_noid", "(", "input_img", ")", "\n", "V_headpose_ref_feature", "=", "self", ".", "netE", ".", "to_headpose", "(", "V_noid_ref_feature", ")", "\n", "\n", "ref_merge_feature_a", "=", "self", ".", "select_frames", "(", "self", ".", "merge_mouthpose", "(", "A_mouth_feature", ",", "V_headpose_ref_feature", ")", ")", "\n", "fake_image_ref_pose_a", ",", "_", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "ref_merge_feature_a", ")", "\n", "if", "self", ".", "opt", ".", "driving_pose", ":", "\n", "            ", "V_noid_driving_feature", "=", "self", ".", "encode_noid_feature", "(", "driving_pose_frames", ")", "\n", "V_headpose_feature", "=", "self", ".", "netE", ".", "to_headpose", "(", "V_noid_driving_feature", ")", "\n", "driven_merge_feature_a", "=", "self", ".", "merge_mouthpose", "(", "A_mouth_feature", ",", "V_headpose_feature", ")", "\n", "sel_driven_pose_feature_a", "=", "self", ".", "select_frames", "(", "driven_merge_feature_a", ")", "\n", "fake_image_pose_driven_a", ",", "_", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_driven_pose_feature_a", ")", "\n", "\n", "", "return", "fake_image_ref_pose_a", ",", "fake_image_pose_driven_a", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_generator_loss": [[494, 590], ["real_image.view.view.view", "av_model.AvModel.encode_noid_feature", "av_model.AvModel.netE.to_mouth", "av_model.AvModel.netE.to_headpose", "av_model.AvModel.encode_identity_feature", "sel_id_feature.append", "sel_id_feature.append", "av_model.AvModel.select_frames", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.select_frames", "av_model.AvModel.discriminate_single", "av_model.AvModel.select_frames", "av_model.AvModel.select_frames", "av_model.AvModel.encode_audiosync_feature", "av_model.AvModel.compute_sync_loss", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.select_frames", "av_model.AvModel.generate_fake", "av_model.AvModel.discriminate_single", "av_model.AvModel.generate_fake", "av_model.AvModel.discriminate_single", "av_model.AvModel.loss_cls", "av_model.AvModel.netE.headpose_embed", "av_model.AvModel.generate_fake", "av_model.AvModel.compute_GAN_Feat_loss", "av_model.AvModel.compute_GAN_Feat_loss", "torch.no_grad", "av_model.AvModel.view", "av_model.AvModel.netE.headpose_fc", "av_model.AvModel.criterionLogSoftmax", "av_model.AvModel.criterionGAN", "av_model.AvModel.criterionGAN", "av_model.AvModel.criterionVGG", "av_model.AvModel.criterionVGG", "av_model.AvModel.criterionVGGFace", "av_model.AvModel.criterionVGGFace"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_noid_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_identity_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate_single", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_audiosync_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_sync_loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate_single", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate_single", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_GAN_Feat_loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_GAN_Feat_loss"], ["", "def", "compute_generator_loss", "(", "self", ",", "input_img", ",", "real_image", ",", "augmented", ",", "spectrogram", ",", "\n", "netD", ",", "labels", ",", "no_ganFeat_loss", "=", "False", ",", "no_vgg_loss", "=", "False", ",", "lambda_D", "=", "1", ")", ":", "\n", "\n", "        ", "G_losses", "=", "{", "}", "\n", "\n", "real_image", "=", "real_image", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "\n", "##### ***************** encode image feature and generate ******************************", "\n", "\n", "V_noid_feature", "=", "self", ".", "encode_noid_feature", "(", "augmented", ")", "\n", "\n", "V_mouth_feature", "=", "self", ".", "netE", ".", "to_mouth", "(", "V_noid_feature", ")", "\n", "V_headpose_feature", "=", "self", ".", "netE", ".", "to_headpose", "(", "V_noid_feature", ")", "\n", "id_feature", ",", "id_scores", "=", "self", ".", "encode_identity_feature", "(", "input_img", ")", "\n", "\n", "sel_id_feature", "=", "[", "]", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "0", "]", ")", ")", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "1", "]", ")", ")", "\n", "\n", "sel_real_image", "=", "self", ".", "select_frames", "(", "real_image", ")", "\n", "\n", "fake_image_A", ",", "fake_image_V", "=", "None", ",", "None", "\n", "\n", "if", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "            ", "assert", "self", ".", "opt", ".", "use_audio", ",", "'must use audio in this case'", "\n", "\n", "", "V_merge_feature", "=", "self", ".", "merge_mouthpose", "(", "V_mouth_feature", ",", "V_headpose_feature", ")", "\n", "\n", "sel_V_merge_feature", "=", "self", ".", "select_frames", "(", "V_merge_feature", ")", "\n", "if", "self", ".", "opt", ".", "use_audio", ":", "# use audio pose feature", "\n", "\n", "            ", "A_mouth_feature", "=", "self", ".", "encode_audiosync_feature", "(", "spectrogram", ")", "\n", "self", ".", "compute_sync_loss", "(", "V_mouth_feature", ",", "A_mouth_feature", ",", "G_losses", ")", "\n", "\n", "A_merge_feature", "=", "self", ".", "merge_mouthpose", "(", "A_mouth_feature", ",", "V_headpose_feature", ")", "\n", "sel_A_merge_feature", "=", "self", ".", "select_frames", "(", "A_merge_feature", ")", "\n", "fake_image_A", ",", "style_rgb_a", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_A_merge_feature", ")", "\n", "pred_fake_audio", "=", "self", ".", "discriminate_single", "(", "fake_image_A", ",", "netD", ")", "\n", "\n", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "# use both audio and image pose feature", "\n", "                ", "fake_image_V", ",", "style_rgb_v", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_V_merge_feature", ")", "\n", "\n", "", "", "else", ":", "# only use image pose feature", "\n", "            ", "fake_image_V", ",", "style_rgb_v", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_V_merge_feature", ")", "\n", "\n", "", "pred_real", "=", "self", ".", "discriminate_single", "(", "sel_real_image", ",", "netD", ")", "\n", "\n", "##### ****************************************************************************", "\n", "\n", "if", "(", "not", "self", ".", "opt", ".", "generate_from_audio_only", ")", "or", "(", "not", "self", ".", "opt", ".", "use_audio", ")", ":", "\n", "            ", "pred_fake", "=", "self", ".", "discriminate_single", "(", "fake_image_V", ",", "netD", ")", "\n", "\n", "", "if", "not", "no_ganFeat_loss", ":", "\n", "            ", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "G_losses", "[", "'GAN_Feat'", "]", "=", "self", ".", "compute_GAN_Feat_loss", "(", "pred_fake", ",", "pred_real", ")", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "G_losses", "[", "'GAN_Feat_audio'", "]", "=", "self", ".", "compute_GAN_Feat_loss", "(", "pred_fake_audio", ",", "pred_real", ")", "\n", "\n", "", "", "if", "not", "self", ".", "opt", ".", "fix_netD", ":", "\n", "            ", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "G_losses", "[", "'GANv'", "]", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "True", ",", "\n", "for_discriminator", "=", "False", ")", "*", "lambda_D", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "G_losses", "[", "'GANa'", "]", "=", "self", ".", "criterionGAN", "(", "pred_fake_audio", ",", "True", ",", "\n", "for_discriminator", "=", "False", ")", "*", "lambda_D", "\n", "\n", "", "", "if", "not", "no_vgg_loss", ":", "\n", "            ", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "G_losses", "[", "'VGGv'", "]", "=", "self", ".", "criterionVGG", "(", "fake_image_V", ",", "sel_real_image", ")", "*", "self", ".", "opt", ".", "lambda_vgg", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "G_losses", "[", "'VGGa'", "]", "=", "self", ".", "criterionVGG", "(", "fake_image_A", ",", "sel_real_image", ")", "*", "self", ".", "opt", ".", "lambda_vgg", "\n", "\n", "", "", "if", "self", ".", "opt", ".", "vgg_face", ":", "\n", "            ", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "G_losses", "[", "'VGGFace_v'", "]", "=", "self", ".", "criterionVGGFace", "(", "fake_image_V", ",", "sel_real_image", ",", "layer", "=", "2", ")", "*", "self", ".", "opt", ".", "lambda_vggface", "\n", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "                ", "G_losses", "[", "'VGGFace_a'", "]", "=", "self", ".", "criterionVGGFace", "(", "fake_image_A", ",", "sel_real_image", ",", "layer", "=", "2", ")", "*", "self", ".", "opt", ".", "lambda_vggface", "\n", "\n", "\n", "", "", "if", "not", "self", ".", "opt", ".", "no_id_loss", "or", "not", "self", ".", "fix_netV", ":", "\n", "            ", "G_losses", "[", "'loss_cls'", "]", "=", "self", ".", "loss_cls", "(", "id_scores", ",", "labels", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "disentangle", "and", "self", ".", "opt", ".", "clip_len", "*", "self", ".", "opt", ".", "frame_interval", ">=", "20", ":", "\n", "            ", "V_headpose_embed", "=", "self", ".", "netE", ".", "headpose_embed", "(", "V_headpose_feature", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "V_all_headpose_embed", "=", "V_headpose_embed", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", "*", "V_headpose_embed", ".", "shape", "[", "-", "1", "]", ")", "\n", "headpose_word_scores", "=", "self", ".", "netE", ".", "headpose_fc", "(", "V_all_headpose_embed", ")", "\n", "", "G_losses", "[", "'logSoftmax_v'", "]", "=", "self", ".", "criterionLogSoftmax", "(", "headpose_word_scores", ")", "*", "self", ".", "opt", ".", "lambda_softmax", "\n", "\n", "", "return", "G_losses", ",", "[", "sel_real_image", ",", "fake_image_V", ",", "fake_image_A", ",", "\n", "]", ",", "id_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_GAN_Feat_loss": [[595, 608], ["len", "av_model.AvModel.FloatTensor().fill_", "range", "range", "av_model.AvModel.FloatTensor", "len", "av_model.AvModel.criterionFeat", "[].detach"], "methods", ["None"], ["", "def", "compute_GAN_Feat_loss", "(", "self", ",", "pred_fake", ",", "pred_real", ")", ":", "\n", "        ", "num_D", "=", "len", "(", "pred_fake", ")", "\n", "GAN_Feat_loss", "=", "self", ".", "FloatTensor", "(", "1", ")", ".", "fill_", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "num_D", ")", ":", "# for each discriminator", "\n", "# last output is the final prediction, so we exclude it", "\n", "            ", "num_intermediate_outputs", "=", "len", "(", "pred_fake", "[", "i", "]", ")", "-", "1", "\n", "for", "j", "in", "range", "(", "num_intermediate_outputs", ")", ":", "# for each layer output", "\n", "                ", "unweighted_loss", "=", "self", ".", "criterionFeat", "(", "\n", "pred_fake", "[", "i", "]", "[", "j", "]", ",", "pred_real", "[", "i", "]", "[", "j", "]", ".", "detach", "(", ")", ")", "\n", "if", "j", "==", "0", ":", "\n", "                    ", "unweighted_loss", "*=", "self", ".", "opt", ".", "lambda_image", "\n", "", "GAN_Feat_loss", "+=", "unweighted_loss", "*", "self", ".", "opt", ".", "lambda_feat", "/", "num_D", "\n", "", "", "return", "GAN_Feat_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.compute_discriminator_loss": [[609, 695], ["av_model.AvModel.discriminate", "torch.no_grad", "av_model.AvModel.encode_identity_feature", "sel_id_feature.append", "sel_id_feature.append", "av_model.AvModel.select_frames", "av_model.AvModel.select_frames", "av_model.AvModel.encode_noid_feature", "V_noid_feature.detach.detach.detach", "V_noid_feature.detach.detach.requires_grad_", "av_model.AvModel.netE.to_mouth", "av_model.AvModel.netE.to_headpose", "torch.cat", "torch.cat", "av_model.AvModel.discriminate", "av_model.AvModel.criterionGAN", "av_model.AvModel.criterionGAN", "V_headpose_embed.detach.detach.view", "av_model.AvModel.netE.headpose_fc", "av_model.AvModel.loss_cls", "av_model.AvModel.select_frames", "av_model.AvModel.select_frames", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.select_frames", "av_model.AvModel.encode_audiosync_feature", "av_model.AvModel.merge_mouthpose", "av_model.AvModel.select_frames", "av_model.AvModel.generate_fake", "av_model.AvModel.generate_fake", "torch.cat.detach", "torch.cat.requires_grad_", "fake_image_audio.detach.detach.detach", "fake_image_audio.detach.detach.requires_grad_", "av_model.AvModel.netE.headpose_embed", "V_headpose_embed.detach.detach.detach", "V_headpose_embed.detach.detach.requires_grad_", "pred_fake.append", "pred_real.append", "pred_fake.append", "pred_real.append", "av_model.AvModel.generate_fake", "torch.cat", "type", "type", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_identity_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_noid_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.encode_audiosync_feature", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.merge_mouthpose", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.select_frames", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.generate_fake"], ["", "def", "compute_discriminator_loss", "(", "self", ",", "input_img", ",", "real_image", ",", "augmented", ",", "spectrogram", ",", "netD", ",", "labels", ",", "lambda_D", "=", "1", ")", ":", "\n", "        ", "D_losses", "=", "{", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "##### ***************** encode feature and generate ******************************", "\n", "\n", "            ", "id_feature", ",", "_", "=", "self", ".", "encode_identity_feature", "(", "input_img", ")", "\n", "sel_id_feature", "=", "[", "]", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "0", "]", ")", ")", "\n", "sel_id_feature", ".", "append", "(", "self", ".", "select_frames", "(", "id_feature", "[", "1", "]", ")", ")", "\n", "\n", "sel_real_image", "=", "self", ".", "select_frames", "(", "real_image", ")", "\n", "sel_input_img", "=", "self", ".", "select_frames", "(", "input_img", ")", "\n", "\n", "V_noid_feature", "=", "self", ".", "encode_noid_feature", "(", "augmented", ")", "\n", "V_noid_feature", "=", "V_noid_feature", ".", "detach", "(", ")", "\n", "V_noid_feature", ".", "requires_grad_", "(", ")", "\n", "\n", "V_mouth_feature", "=", "self", ".", "netE", ".", "to_mouth", "(", "V_noid_feature", ")", "\n", "V_headpose_feature", "=", "self", ".", "netE", ".", "to_headpose", "(", "V_noid_feature", ")", "\n", "\n", "fake_image_audio", ",", "fake_image", "=", "None", ",", "None", "\n", "\n", "if", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "assert", "self", ".", "opt", ".", "use_audio", ",", "'must use audio in this case'", "\n", "\n", "", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "\n", "                ", "V_merge_feature", "=", "self", ".", "merge_mouthpose", "(", "V_mouth_feature", ",", "V_headpose_feature", ")", "\n", "\n", "sel_V_merge_feature", "=", "self", ".", "select_frames", "(", "V_merge_feature", ")", "\n", "", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "\n", "                ", "A_mouth_feature", "=", "self", ".", "encode_audiosync_feature", "(", "spectrogram", ")", "\n", "A_pose_feature", "=", "self", ".", "merge_mouthpose", "(", "A_mouth_feature", ",", "V_headpose_feature", ")", "\n", "sel_A_pose_feature", "=", "self", ".", "select_frames", "(", "A_pose_feature", ")", "\n", "fake_image_audio", ",", "style_rgb_a", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_A_pose_feature", ")", "\n", "fake_image", "=", "fake_image_audio", "\n", "\n", "if", "not", "self", ".", "opt", ".", "generate_from_audio_only", ":", "# use both audio and image pose feature", "\n", "                    ", "fake_image", ",", "style_rgb_v", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_V_merge_feature", ")", "\n", "fake_image", "=", "torch", ".", "cat", "(", "[", "fake_image_audio", ",", "fake_image", "]", ",", "0", ")", "\n", "\n", "", "", "else", ":", "# only use image pose feature", "\n", "                ", "fake_image", ",", "style_rgb_v", "=", "self", ".", "generate_fake", "(", "sel_id_feature", ",", "sel_V_merge_feature", ")", "\n", "\n", "", "sel_real_image", "=", "torch", ".", "cat", "(", "[", "sel_real_image", ",", "]", "*", "(", "len", "(", "fake_image", ")", "//", "len", "(", "sel_real_image", ")", ")", ",", "0", ")", "\n", "sel_input_img", "=", "torch", ".", "cat", "(", "[", "sel_input_img", ",", "]", "*", "(", "len", "(", "fake_image", ")", "//", "len", "(", "sel_input_img", ")", ")", ",", "0", ")", "\n", "\n", "if", "fake_image", "is", "not", "None", ":", "\n", "                ", "fake_image", "=", "fake_image", ".", "detach", "(", ")", "\n", "fake_image", ".", "requires_grad_", "(", ")", "\n", "", "if", "fake_image_audio", "is", "not", "None", ":", "\n", "                ", "fake_image_audio", "=", "fake_image_audio", ".", "detach", "(", ")", "\n", "fake_image_audio", ".", "requires_grad_", "(", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "disentangle", ":", "\n", "                ", "V_headpose_embed", "=", "self", ".", "netE", ".", "headpose_embed", "(", "V_headpose_feature", ")", "\n", "V_headpose_embed", "=", "V_headpose_embed", ".", "detach", "(", ")", "\n", "V_headpose_embed", ".", "requires_grad_", "(", ")", "\n", "\n", "", "", "pred_fake", ",", "pred_real", "=", "self", ".", "discriminate", "(", "\n", "sel_input_img", ",", "fake_image", ",", "sel_real_image", ",", "netD", ")", "\n", "\n", "if", "self", ".", "opt", ".", "stylegan_D", ":", "\n", "            ", "pred_fake_styleGAN", ",", "pred_real_styleGAN", "=", "self", ".", "discriminate", "(", "\n", "sel_input_img", ",", "fake_image", ",", "sel_real_image", ",", "self", ".", "net_styleGAN_D", ")", "\n", "if", "type", "(", "pred_fake", ")", "==", "list", "and", "type", "(", "pred_real", ")", "==", "list", ":", "\n", "                ", "pred_fake", ".", "append", "(", "pred_fake_styleGAN", ")", "\n", "pred_real", ".", "append", "(", "pred_real_styleGAN", ")", "\n", "", "else", ":", "\n", "                ", "pred_fake", "=", "[", "pred_fake", "]", "\n", "pred_fake", ".", "append", "(", "pred_fake_styleGAN", ")", "\n", "pred_real", "=", "[", "pred_real", "]", "\n", "pred_real", ".", "append", "(", "pred_real_styleGAN", ")", "\n", "\n", "", "", "D_losses", "[", "'D_Fake'", "]", "=", "self", ".", "criterionGAN", "(", "pred_fake", ",", "False", ",", "\n", "for_discriminator", "=", "True", ")", "*", "lambda_D", "\n", "\n", "D_losses", "[", "'D_real'", "]", "=", "self", ".", "criterionGAN", "(", "pred_real", ",", "True", ",", "\n", "for_discriminator", "=", "True", ")", "*", "lambda_D", "\n", "\n", "if", "self", ".", "opt", ".", "disentangle", "and", "self", ".", "opt", ".", "clip_len", "*", "self", ".", "opt", ".", "frame_interval", ">=", "20", ":", "\n", "            ", "V_all_headpose_embed", "=", "V_headpose_embed", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "clip_len", "*", "V_headpose_embed", ".", "shape", "[", "-", "1", "]", ")", "\n", "headpose_word_scores", "=", "self", ".", "netE", ".", "headpose_fc", "(", "V_all_headpose_embed", ")", "\n", "D_losses", "[", "'headpose_feature_cls'", "]", "=", "self", ".", "loss_cls", "(", "headpose_word_scores", ",", "labels", ")", "\n", "\n", "", "return", "D_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate": [[696, 711], ["torch.cat", "netD", "av_model.AvModel.divide_pred", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.divide_pred"], ["", "def", "discriminate", "(", "self", ",", "input", ",", "fake_image", ",", "real_image", ",", "netD", ")", ":", "\n", "        ", "if", "self", ".", "opt", ".", "D_input", "==", "\"concat\"", ":", "\n", "            ", "fake_concat", "=", "torch", ".", "cat", "(", "[", "input", ",", "fake_image", "]", ",", "dim", "=", "1", ")", "\n", "real_concat", "=", "torch", ".", "cat", "(", "[", "input", ",", "real_image", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fake_concat", "=", "fake_image", "\n", "real_concat", "=", "real_image", "\n", "\n", "", "fake_and_real", "=", "torch", ".", "cat", "(", "[", "fake_concat", ",", "real_concat", "]", ",", "dim", "=", "0", ")", "\n", "\n", "discriminator_out", "=", "netD", "(", "fake_and_real", ")", "\n", "\n", "pred_fake", ",", "pred_real", "=", "self", ".", "divide_pred", "(", "discriminator_out", ")", "\n", "\n", "return", "pred_fake", ",", "pred_real", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.discriminate_single": [[712, 720], ["netD", "single_image.view.view.dim", "single_image.view.view.view"], "methods", ["None"], ["", "def", "discriminate_single", "(", "self", ",", "single_image", ",", "netD", ")", ":", "\n", "\n", "        ", "if", "single_image", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "single_image", "=", "single_image", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "\n", "", "pred_single", "=", "netD", "(", "single_image", ")", "\n", "\n", "return", "pred_single", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.divide_pred": [[722, 737], ["type", "fake.append", "real.append", "pred.size", "pred.size", "tensor.size", "tensor.size"], "methods", ["None"], ["", "def", "divide_pred", "(", "self", ",", "pred", ")", ":", "\n", "# the prediction contains the intermediate outputs of multiscale GAN,", "\n", "# so it's usually a list", "\n", "        ", "if", "type", "(", "pred", ")", "==", "list", ":", "\n", "            ", "fake", "=", "[", "]", "\n", "real", "=", "[", "]", "\n", "for", "p", "in", "pred", ":", "\n", "                ", "fake", ".", "append", "(", "[", "tensor", "[", ":", "tensor", ".", "size", "(", "0", ")", "//", "2", "]", "for", "tensor", "in", "p", "]", ")", "\n", "real", ".", "append", "(", "[", "tensor", "[", "tensor", ".", "size", "(", "0", ")", "//", "2", ":", "]", "for", "tensor", "in", "p", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "fake", "=", "pred", "[", ":", "pred", ".", "size", "(", "0", ")", "//", "2", "]", "\n", "# rotate_fake = pred[pred.size(0) // 3: pred.size(0) * 2 // 3]", "\n", "real", "=", "pred", "[", "pred", ".", "size", "(", "0", ")", "//", "2", ":", "]", "\n", "\n", "", "return", "fake", ",", "real", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_separately": [[738, 764], ["os.path.isfile", "print", "print", "torch.load", "util.copy_state_dict"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copy_state_dict"], ["", "def", "load_separately", "(", "self", ",", "network", ",", "network_label", ",", "opt", ")", ":", "\n", "        ", "load_path", "=", "None", "\n", "if", "network_label", "==", "'G'", ":", "\n", "            ", "load_path", "=", "opt", ".", "G_pretrain_path", "\n", "", "elif", "network_label", "==", "'D'", ":", "\n", "\n", "            ", "load_path", "=", "opt", ".", "D_pretrain_path", "\n", "", "elif", "network_label", "==", "'D_rotate'", ":", "\n", "            ", "load_path", "=", "opt", ".", "D_rotate_pretrain_path", "\n", "", "elif", "network_label", "==", "'E'", ":", "\n", "            ", "load_path", "=", "opt", ".", "E_pretrain_path", "\n", "", "elif", "network_label", "==", "'A'", ":", "\n", "            ", "load_path", "=", "opt", ".", "A_pretrain_path", "\n", "", "elif", "network_label", "==", "'A_sync'", ":", "\n", "            ", "load_path", "=", "opt", ".", "A_sync_pretrain_path", "\n", "", "elif", "network_label", "==", "'V'", ":", "\n", "            ", "load_path", "=", "opt", ".", "V_pretrain_path", "\n", "\n", "", "if", "load_path", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "load_path", ")", ":", "\n", "                ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "load_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "load_path", ")", "\n", "util", ".", "copy_state_dict", "(", "checkpoint", ",", "network", ",", "strip", "=", "'MobileNet'", ",", "replace", "=", "'model'", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "\"no load_path\"", ")", "\n", "", "return", "network", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.load_network": [[765, 802], ["os.path.join", "os.path.isfile", "print", "network.load_state_dict", "torch.load", "torch.load", "network.state_dict", "network.load_state_dict", "print", "print", "torch.load.items", "set", "network.state_dict.items", "print", "network.load_state_dict", "torch.load.items", "sorted", "v.size", "model_dict[].size", "set.add", "v.size", "pretrained_dict[].size", "k.split"], "methods", ["None"], ["", "def", "load_network", "(", "self", ",", "network", ",", "network_label", ",", "epoch_label", ")", ":", "\n", "        ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch_label", ",", "network_label", ")", "\n", "save_dir", "=", "self", ".", "save_dir", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "save_filename", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "save_path", ")", ":", "\n", "            ", "if", "not", "self", ".", "opt", ".", "train_recognition", ":", "\n", "                ", "print", "(", "'%s not exists yet!'", "%", "save_path", ")", "\n", "if", "network_label", "==", "'G'", ":", "\n", "                    ", "raise", "(", "'Generator must exist!'", ")", "\n", "", "", "", "else", ":", "\n", "# network.load_state_dict(torch.load(save_path))", "\n", "            ", "try", ":", "\n", "                ", "network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "save_path", ")", ")", "\n", "", "except", ":", "\n", "                ", "pretrained_dict", "=", "torch", ".", "load", "(", "save_path", ")", "\n", "model_dict", "=", "network", ".", "state_dict", "(", ")", "\n", "try", ":", "\n", "\n", "                    ", "pretrained_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", "if", "k", "in", "model_dict", "}", "\n", "network", ".", "load_state_dict", "(", "pretrained_dict", ")", "\n", "if", "self", ".", "opt", ".", "verbose", ":", "\n", "                        ", "print", "(", "\n", "'Pretrained network %s has excessive layers; Only loading layers that are used'", "%", "network_label", ")", "\n", "", "", "except", ":", "\n", "                    ", "print", "(", "'Pretrained network %s has fewer layers; The following are not initialized:'", "%", "network_label", ")", "\n", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", ":", "\n", "                        ", "if", "v", ".", "size", "(", ")", "==", "model_dict", "[", "k", "]", ".", "size", "(", ")", ":", "\n", "                            ", "model_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "", "not_initialized", "=", "set", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "model_dict", ".", "items", "(", ")", ":", "\n", "                        ", "if", "k", "not", "in", "pretrained_dict", "or", "v", ".", "size", "(", ")", "!=", "pretrained_dict", "[", "k", "]", ".", "size", "(", ")", ":", "\n", "                            ", "not_initialized", ".", "add", "(", "k", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "", "", "print", "(", "sorted", "(", "not_initialized", ")", ")", "\n", "network", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.use_gpu": [[803, 805], ["len"], "methods", ["None"], ["", "", "", "", "def", "use_gpu", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "opt", ".", "gpu_ids", ")", ">", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.find_model_using_name": [[3, 24], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "name.lower", "target_model_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.get_option_setter": [[26, 29], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.create_model": [[31, 37], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.__init__.find_model_using_name"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.modify_commandline_options": [[11, 25], ["parser.add_argument", "parser.add_argument", "parser.parse_known_args", "util.find_class_in_module", "util.find_class_in_module.modify_commandline_options"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.find_class_in_module", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "'--netD_subarch'", ",", "type", "=", "str", ",", "default", "=", "'n_layer'", ",", "\n", "help", "=", "'architecture of each discriminator'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_D'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'number of discriminators to be used in multiscale'", ")", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# define properties of each discriminator of the multiscale discriminator", "\n", "subnetD", "=", "util", ".", "find_class_in_module", "(", "opt", ".", "netD_subarch", "+", "'discriminator'", ",", "\n", "'models.networks.discriminator'", ")", "\n", "subnetD", ".", "modify_commandline_options", "(", "parser", ",", "is_train", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.__init__": [[26, 33], ["models.networks.base_network.BaseNetwork.__init__", "range", "discriminator.MultiscaleDiscriminator.create_single_discriminator", "discriminator.MultiscaleDiscriminator.add_module"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.create_single_discriminator"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "MultiscaleDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "for", "i", "in", "range", "(", "opt", ".", "num_D", ")", ":", "\n", "            ", "subnetD", "=", "self", ".", "create_single_discriminator", "(", "opt", ")", "\n", "self", ".", "add_module", "(", "'discriminator_%d'", "%", "i", ",", "subnetD", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.create_single_discriminator": [[34, 41], ["discriminator.NLayerDiscriminator", "ValueError"], "methods", ["None"], ["", "", "def", "create_single_discriminator", "(", "self", ",", "opt", ")", ":", "\n", "        ", "subarch", "=", "opt", ".", "netD_subarch", "\n", "if", "subarch", "==", "'n_layer'", ":", "\n", "            ", "netD", "=", "NLayerDiscriminator", "(", "opt", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unrecognized discriminator subarchitecture %s'", "%", "subarch", ")", "\n", "", "return", "netD", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.downsample": [[42, 46], ["torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d"], "methods", ["None"], ["", "def", "downsample", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "avg_pool2d", "(", "input", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "padding", "=", "[", "1", ",", "1", "]", ",", "\n", "count_include_pad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.forward": [[49, 60], ["discriminator.MultiscaleDiscriminator.named_children", "D", "result.append", "discriminator.MultiscaleDiscriminator.downsample"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.downsample"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "get_intermediate_features", "=", "not", "self", ".", "opt", ".", "no_ganFeat_loss", "\n", "for", "name", ",", "D", "in", "self", ".", "named_children", "(", ")", ":", "\n", "            ", "out", "=", "D", "(", "input", ")", "\n", "if", "not", "get_intermediate_features", ":", "\n", "                ", "out", "=", "[", "out", "]", "\n", "", "result", ".", "append", "(", "out", ")", "\n", "input", "=", "self", ".", "downsample", "(", "input", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.NLayerDiscriminator.modify_commandline_options": [[64, 69], ["parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'# layers in each discriminator'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.NLayerDiscriminator.__init__": [[70, 98], ["models.networks.base_network.BaseNetwork.__init__", "int", "discriminator.NLayerDiscriminator.compute_D_input_nc", "models.networks.architecture.get_nonspade_norm_layer", "range", "range", "numpy.ceil", "min", "len", "discriminator.NLayerDiscriminator.add_module", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "models.networks.architecture.get_nonspade_norm_layer.", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "str", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.NLayerDiscriminator.compute_D_input_nc", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.get_nonspade_norm_layer"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "\n", "        ", "super", "(", "NLayerDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "kw", "=", "4", "\n", "padw", "=", "int", "(", "np", ".", "ceil", "(", "(", "kw", "-", "1.0", ")", "/", "2", ")", ")", "\n", "nf", "=", "opt", ".", "ndf", "\n", "input_nc", "=", "self", ".", "compute_D_input_nc", "(", "opt", ")", "\n", "\n", "norm_layer", "=", "get_nonspade_norm_layer", "(", "opt", ",", "opt", ".", "norm_D", ")", "\n", "sequence", "=", "[", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "nf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "False", ")", "]", "]", "\n", "\n", "for", "n", "in", "range", "(", "1", ",", "opt", ".", "n_layers_D", ")", ":", "\n", "            ", "nf_prev", "=", "nf", "\n", "nf", "=", "min", "(", "nf", "*", "2", ",", "512", ")", "\n", "stride", "=", "1", "if", "n", "==", "opt", ".", "n_layers_D", "-", "1", "else", "2", "\n", "sequence", "+=", "[", "[", "norm_layer", "(", "nn", ".", "Conv2d", "(", "nf_prev", ",", "nf", ",", "kernel_size", "=", "kw", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padw", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "False", ")", "\n", "]", "]", "\n", "\n", "", "sequence", "+=", "[", "[", "nn", ".", "Conv2d", "(", "nf", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "]", "\n", "\n", "# We divide the layers into groups to extract intermediate layer outputs", "\n", "for", "n", "in", "range", "(", "len", "(", "sequence", ")", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "'model'", "+", "str", "(", "n", ")", ",", "nn", ".", "Sequential", "(", "*", "sequence", "[", "n", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.NLayerDiscriminator.compute_D_input_nc": [[99, 109], ["None"], "methods", ["None"], ["", "", "def", "compute_D_input_nc", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "D_input", "==", "\"concat\"", ":", "\n", "            ", "input_nc", "=", "opt", ".", "label_nc", "+", "opt", ".", "output_nc", "\n", "if", "opt", ".", "contain_dontcare_label", ":", "\n", "                ", "input_nc", "+=", "1", "\n", "", "if", "not", "opt", ".", "no_instance", ":", "\n", "                ", "input_nc", "+=", "1", "\n", "", "", "else", ":", "\n", "            ", "input_nc", "=", "3", "\n", "", "return", "input_nc", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.NLayerDiscriminator.forward": [[110, 123], ["discriminator.NLayerDiscriminator.children", "submodel", "results.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "results", "=", "[", "input", "]", "\n", "for", "submodel", "in", "self", ".", "children", "(", ")", ":", "\n", "\n", "# intermediate_output = checkpoint(submodel, results[-1])", "\n", "            ", "intermediate_output", "=", "submodel", "(", "results", "[", "-", "1", "]", ")", "\n", "results", ".", "append", "(", "intermediate_output", ")", "\n", "\n", "", "get_intermediate_features", "=", "not", "self", ".", "opt", ".", "no_ganFeat_loss", "\n", "if", "get_intermediate_features", ":", "\n", "            ", "return", "results", "[", "0", ":", "]", "\n", "", "else", ":", "\n", "            ", "return", "results", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.AudioSubDiscriminator.__init__": [[126, 141], ["models.networks.base_network.BaseNetwork.__init__", "models.networks.architecture.get_nonspade_norm_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.Linear", "torch.Linear", "torch.Linear", "models.networks.architecture.get_nonspade_norm_layer.", "torch.ReLU", "torch.ReLU", "torch.ReLU", "models.networks.architecture.get_nonspade_norm_layer.", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.get_nonspade_norm_layer"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "nc", ",", "audio_nc", ")", ":", "\n", "        ", "super", "(", "AudioSubDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "norm_layer", "=", "get_nonspade_norm_layer", "(", "opt", ",", "opt", ".", "norm_D", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "sequence", "=", "[", "]", "\n", "sequence", "+=", "[", "norm_layer", "(", "nn", ".", "Conv1d", "(", "nc", ",", "nc", ",", "3", ",", "2", ",", "1", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", "]", "\n", "sequence", "+=", "[", "norm_layer", "(", "nn", ".", "Conv1d", "(", "nc", ",", "audio_nc", ",", "3", ",", "2", ",", "1", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", "]", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "self", ".", "cosine", "=", "nn", ".", "CosineSimilarity", "(", ")", "\n", "self", ".", "mapping", "=", "nn", ".", "Linear", "(", "audio_nc", ",", "audio_nc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.AudioSubDiscriminator.forward": [[142, 147], ["discriminator.AudioSubDiscriminator.avgpool", "discriminator.AudioSubDiscriminator.cosine", "discriminator.AudioSubDiscriminator.mapping"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "result", ",", "audio", ")", ":", "\n", "        ", "region", "=", "result", "[", "result", ".", "shape", "[", "3", "]", "//", "2", ":", "result", ".", "shape", "[", "3", "]", "-", "2", ",", "result", ".", "shape", "[", "4", "]", "//", "3", ":", "2", "*", "result", ".", "shape", "[", "4", "]", "//", "3", "]", "\n", "visual", "=", "self", ".", "avgpool", "(", "region", ")", "\n", "cos", "=", "self", ".", "cosine", "(", "visual", ",", "self", ".", "mapping", "(", "audio", ")", ")", "\n", "return", "cos", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.ImageDiscriminator.modify_commandline_options": [[151, 155], ["parser.add_argument"], "methods", ["None"], ["def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "'--n_layers_D'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'# layers in each discriminator'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.ImageDiscriminator.__init__": [[156, 195], ["models.networks.base_network.BaseNetwork.__init__", "range", "min", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["", "def", "__init__", "(", "self", ",", "opt", ",", "n_layers", "=", "3", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "\"\"\"Construct a PatchGAN discriminator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            ndf (int)       -- the number of filters in the last conv layer\n            n_layers (int)  -- the number of conv layers in the discriminator\n            norm_layer      -- normalization layer\n        \"\"\"", "\n", "super", "(", "ImageDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "use_bias", "=", "norm_layer", "==", "nn", ".", "InstanceNorm2d", "\n", "if", "opt", ".", "D_input", "==", "\"concat\"", ":", "\n", "            ", "input_nc", "=", "opt", ".", "label_nc", "+", "opt", ".", "output_nc", "\n", "", "else", ":", "\n", "            ", "input_nc", "=", "opt", ".", "label_nc", "\n", "", "ndf", "=", "64", "\n", "kw", "=", "4", "\n", "padw", "=", "1", "\n", "sequence", "=", "[", "nn", ".", "Conv2d", "(", "input_nc", ",", "ndf", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ")", ",", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "]", "\n", "nf_mult", "=", "1", "\n", "nf_mult_prev", "=", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "n_layers", ")", ":", "# gradually increase the number of filters", "\n", "            ", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "2", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "", "nf_mult_prev", "=", "nf_mult", "\n", "nf_mult", "=", "min", "(", "2", "**", "n_layers", ",", "8", ")", "\n", "sequence", "+=", "[", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult_prev", ",", "ndf", "*", "nf_mult", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ",", "bias", "=", "use_bias", ")", ",", "\n", "norm_layer", "(", "ndf", "*", "nf_mult", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "]", "\n", "\n", "sequence", "+=", "[", "nn", ".", "Conv2d", "(", "ndf", "*", "nf_mult", ",", "1", ",", "kernel_size", "=", "kw", ",", "stride", "=", "1", ",", "padding", "=", "padw", ")", "]", "# output 1 channel prediction map", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.ImageDiscriminator.forward": [[196, 199], ["discriminator.ImageDiscriminator.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Standard forward.\"\"\"", "\n", "return", "self", ".", "model", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.FeatureDiscriminator.__init__": [[202, 207], ["models.networks.base_network.BaseNetwork.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "FeatureDiscriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", ",", "opt", ".", "num_labels", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.FeatureDiscriminator.forward": [[208, 213], ["x.view", "discriminator.FeatureDiscriminator.dropout", "discriminator.FeatureDiscriminator.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "x", ".", "view", "(", "-", "1", ",", "512", ")", "\n", "net", "=", "self", ".", "dropout", "(", "x0", ")", "\n", "net", "=", "self", ".", "fc", "(", "net", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.ResSEAudioEncoder.__init__": [[15, 24], ["models.networks.base_network.BaseNetwork.__init__", "models.networks.audio_network.ResNetSE", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "nOut", "=", "2048", ",", "n_mel_T", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResSEAudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nOut", "=", "nOut", "\n", "# Number of filters", "\n", "num_filters", "=", "[", "32", ",", "64", ",", "128", ",", "256", "]", "\n", "if", "n_mel_T", "is", "None", ":", "# use it when use audio identity", "\n", "            ", "n_mel_T", "=", "opt", ".", "n_mel_T", "\n", "", "self", ".", "model", "=", "ResNetSE", "(", "SEBasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_filters", ",", "self", ".", "nOut", ",", "n_mel_T", "=", "n_mel_T", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "nOut", ",", "opt", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.ResSEAudioEncoder.forward_feature": [[25, 33], ["x.view.view.size", "encoder.ResSEAudioEncoder.model", "len", "x.view.view.view"], "methods", ["None"], ["", "def", "forward_feature", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "input_size", "=", "x", ".", "size", "(", ")", "\n", "if", "len", "(", "input_size", ")", "==", "5", ":", "\n", "            ", "bz", ",", "clip_len", ",", "c", ",", "f", ",", "t", "=", "input_size", "\n", "x", "=", "x", ".", "view", "(", "bz", "*", "clip_len", ",", "c", ",", "f", ",", "t", ")", "\n", "", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.ResSEAudioEncoder.forward": [[34, 38], ["encoder.ResSEAudioEncoder.forward_feature", "encoder.ResSEAudioEncoder.fc"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "forward_feature", "(", "x", ")", "\n", "score", "=", "self", ".", "fc", "(", "out", ")", "\n", "return", "out", ",", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.ResSESyncEncoder.__init__": [[41, 43], ["encoder.ResSEAudioEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ResSESyncEncoder", ",", "self", ")", ".", "__init__", "(", "opt", ",", "nOut", "=", "512", ",", "n_mel_T", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.ResNeXtEncoder.__init__": [[46, 48], ["models.networks.vision_network.ResNeXt50.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ResNeXtEncoder", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.VGGEncoder.__init__": [[51, 54], ["models.networks.base_network.BaseNetwork.__init__", "torchvision.models.vgg.vgg19_bn"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "VGGEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "vgg19_bn", "(", "num_classes", "=", "opt", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.VGGEncoder.forward": [[55, 57], ["encoder.VGGEncoder.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.FanEncoder.__init__": [[60, 76], ["models.networks.base_network.BaseNetwork.__init__", "models.networks.FAN_feature_extractor.FAN_use", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "FanEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "pose_dim", "=", "self", ".", "opt", ".", "pose_dim", "\n", "self", ".", "model", "=", "FAN_use", "(", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", ",", "opt", ".", "num_classes", ")", ")", "\n", "\n", "# mapper to mouth subspace", "\n", "self", ".", "to_mouth", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", ",", "512", ")", ")", "\n", "self", ".", "mouth_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", ",", "512", "-", "pose_dim", ")", ")", "\n", "self", ".", "mouth_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", "*", "opt", ".", "clip_len", ",", "opt", ".", "num_classes", ")", ")", "\n", "\n", "# mapper to head pose subspace", "\n", "self", ".", "to_headpose", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "512", ",", "512", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", ",", "512", ")", ")", "\n", "self", ".", "headpose_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "512", ",", "pose_dim", ")", ")", "\n", "self", ".", "headpose_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "pose_dim", "*", "opt", ".", "clip_len", ",", "opt", ".", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.FanEncoder.load_pretrain": [[77, 81], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "util.util.util.copy_state_dict"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copy_state_dict"], ["", "def", "load_pretrain", "(", "self", ")", ":", "\n", "        ", "check_point", "=", "torch", ".", "load", "(", "self", ".", "opt", ".", "FAN_pretrain_path", ")", "\n", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "self", ".", "opt", ".", "FAN_pretrain_path", ")", ")", "\n", "util", ".", "copy_state_dict", "(", "check_point", ",", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.FanEncoder.forward_feature": [[82, 85], ["encoder.FanEncoder.model"], "methods", ["None"], ["", "def", "forward_feature", "(", "self", ",", "x", ")", ":", "\n", "        ", "net", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.encoder.FanEncoder.forward": [[86, 91], ["x.view", "encoder.FanEncoder.forward_feature", "encoder.FanEncoder.classifier", "encoder.FanEncoder.view().mean", "encoder.FanEncoder.view"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "net", "=", "self", ".", "forward_feature", "(", "x0", ")", "\n", "scores", "=", "self", ".", "classifier", "(", "net", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "num_clips", ",", "512", ")", ".", "mean", "(", "1", ")", ")", "\n", "return", "net", ",", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.ConvBlock.__init__": [[14, 32], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "FAN_feature_extractor.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "FAN_feature_extractor.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "FAN_feature_extractor.conv3x3", "int", "int", "int", "int", "int", "int", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.conv3x3", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.conv3x3", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ")", ":", "\n", "        ", "super", "(", "ConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "in_planes", ",", "int", "(", "out_planes", "/", "2", ")", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "int", "(", "out_planes", "/", "2", ")", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "int", "(", "out_planes", "/", "2", ")", ",", "int", "(", "out_planes", "/", "4", ")", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "int", "(", "out_planes", "/", "4", ")", ")", "\n", "self", ".", "conv3", "=", "conv3x3", "(", "int", "(", "out_planes", "/", "4", ")", ",", "int", "(", "out_planes", "/", "4", ")", ")", "\n", "\n", "if", "in_planes", "!=", "out_planes", ":", "\n", "            ", "self", ".", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "downsample", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.ConvBlock.forward": [[33, 56], ["FAN_feature_extractor.ConvBlock.bn1", "torch.relu", "torch.relu", "torch.relu", "FAN_feature_extractor.ConvBlock.conv1", "FAN_feature_extractor.ConvBlock.bn2", "torch.relu", "torch.relu", "torch.relu", "FAN_feature_extractor.ConvBlock.conv2", "FAN_feature_extractor.ConvBlock.bn3", "torch.relu", "torch.relu", "torch.relu", "FAN_feature_extractor.ConvBlock.conv3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "FAN_feature_extractor.ConvBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.downsample"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out1", "=", "self", ".", "bn1", "(", "x", ")", "\n", "out1", "=", "F", ".", "relu", "(", "out1", ",", "True", ")", "\n", "out1", "=", "self", ".", "conv1", "(", "out1", ")", "\n", "\n", "out2", "=", "self", ".", "bn2", "(", "out1", ")", "\n", "out2", "=", "F", ".", "relu", "(", "out2", ",", "True", ")", "\n", "out2", "=", "self", ".", "conv2", "(", "out2", ")", "\n", "\n", "out3", "=", "self", ".", "bn3", "(", "out2", ")", "\n", "out3", "=", "F", ".", "relu", "(", "out3", ",", "True", ")", "\n", "out3", "=", "self", ".", "conv3", "(", "out3", ")", "\n", "\n", "out3", "=", "torch", ".", "cat", "(", "(", "out1", ",", "out2", ",", "out3", ")", ",", "1", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "residual", ")", "\n", "\n", "", "out3", "+=", "residual", "\n", "\n", "return", "out3", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass.__init__": [[59, 67], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "FAN_feature_extractor.HourGlass._generate_network"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._generate_network"], ["    ", "def", "__init__", "(", "self", ",", "num_modules", ",", "depth", ",", "num_features", ")", ":", "\n", "        ", "super", "(", "HourGlass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_modules", "=", "num_modules", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "features", "=", "num_features", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.5", ")", "\n", "\n", "self", ".", "_generate_network", "(", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._generate_network": [[68, 79], ["FAN_feature_extractor.HourGlass.add_module", "FAN_feature_extractor.HourGlass.add_module", "FAN_feature_extractor.HourGlass.add_module", "FAN_feature_extractor.ConvBlock", "FAN_feature_extractor.ConvBlock", "FAN_feature_extractor.HourGlass._generate_network", "FAN_feature_extractor.HourGlass.add_module", "FAN_feature_extractor.ConvBlock", "str", "str", "FAN_feature_extractor.ConvBlock", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._generate_network"], ["", "def", "_generate_network", "(", "self", ",", "level", ")", ":", "\n", "        ", "self", ".", "add_module", "(", "'b1_'", "+", "str", "(", "level", ")", ",", "ConvBlock", "(", "256", ",", "256", ")", ")", "\n", "\n", "self", ".", "add_module", "(", "'b2_'", "+", "str", "(", "level", ")", ",", "ConvBlock", "(", "256", ",", "256", ")", ")", "\n", "\n", "if", "level", ">", "1", ":", "\n", "            ", "self", ".", "_generate_network", "(", "level", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "add_module", "(", "'b2_plus_'", "+", "str", "(", "level", ")", ",", "ConvBlock", "(", "256", ",", "256", ")", ")", "\n", "\n", "", "self", ".", "add_module", "(", "'b3_'", "+", "str", "(", "level", ")", ",", "ConvBlock", "(", "256", ",", "256", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._forward": [[80, 102], ["FAN_feature_extractor.HourGlass.dropout", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "FAN_feature_extractor.HourGlass.size", "torch.upsample", "torch.upsample", "torch.upsample", "FAN_feature_extractor.HourGlass._forward", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._forward"], ["", "def", "_forward", "(", "self", ",", "level", ",", "inp", ")", ":", "\n", "# Upper branch", "\n", "        ", "up1", "=", "inp", "\n", "up1", "=", "self", ".", "_modules", "[", "'b1_'", "+", "str", "(", "level", ")", "]", "(", "up1", ")", "\n", "up1", "=", "self", ".", "dropout", "(", "up1", ")", "\n", "# Lower branch", "\n", "low1", "=", "F", ".", "max_pool2d", "(", "inp", ",", "2", ",", "stride", "=", "2", ")", "\n", "low1", "=", "self", ".", "_modules", "[", "'b2_'", "+", "str", "(", "level", ")", "]", "(", "low1", ")", "\n", "\n", "if", "level", ">", "1", ":", "\n", "            ", "low2", "=", "self", ".", "_forward", "(", "level", "-", "1", ",", "low1", ")", "\n", "", "else", ":", "\n", "            ", "low2", "=", "low1", "\n", "low2", "=", "self", ".", "_modules", "[", "'b2_plus_'", "+", "str", "(", "level", ")", "]", "(", "low2", ")", "\n", "\n", "", "low3", "=", "low2", "\n", "low3", "=", "self", ".", "_modules", "[", "'b3_'", "+", "str", "(", "level", ")", "]", "(", "low3", ")", "\n", "up1size", "=", "up1", ".", "size", "(", ")", "\n", "rescale_size", "=", "(", "up1size", "[", "2", "]", ",", "up1size", "[", "3", "]", ")", "\n", "up2", "=", "F", ".", "upsample", "(", "low3", ",", "size", "=", "rescale_size", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "return", "up1", "+", "up2", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass.forward": [[103, 105], ["FAN_feature_extractor.HourGlass._forward"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.HourGlass._forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_forward", "(", "self", ".", "depth", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.FAN_use.__init__": [[108, 140], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "FAN_feature_extractor.ConvBlock", "FAN_feature_extractor.ConvBlock", "FAN_feature_extractor.ConvBlock", "FAN_feature_extractor.FAN_use.add_module", "FAN_feature_extractor.FAN_use.add_module", "FAN_feature_extractor.FAN_use.add_module", "FAN_feature_extractor.FAN_use.add_module", "FAN_feature_extractor.FAN_use.add_module", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "FAN_feature_extractor.HourGlass", "FAN_feature_extractor.ConvBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "FAN_feature_extractor.FAN_use.add_module", "FAN_feature_extractor.FAN_use.add_module", "str", "str", "str", "str", "str", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "FAN_use", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_modules", "=", "1", "\n", "\n", "# Base part", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "conv2", "=", "ConvBlock", "(", "64", ",", "128", ")", "\n", "self", ".", "conv3", "=", "ConvBlock", "(", "128", ",", "128", ")", "\n", "self", ".", "conv4", "=", "ConvBlock", "(", "128", ",", "256", ")", "\n", "\n", "# Stacking part", "\n", "hg_module", "=", "0", "\n", "self", ".", "add_module", "(", "'m'", "+", "str", "(", "hg_module", ")", ",", "HourGlass", "(", "1", ",", "4", ",", "256", ")", ")", "\n", "self", ".", "add_module", "(", "'top_m_'", "+", "str", "(", "hg_module", ")", ",", "ConvBlock", "(", "256", ",", "256", ")", ")", "\n", "self", ".", "add_module", "(", "'conv_last'", "+", "str", "(", "hg_module", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "self", ".", "add_module", "(", "'l'", "+", "str", "(", "hg_module", ")", ",", "nn", ".", "Conv2d", "(", "256", ",", "\n", "68", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "self", ".", "add_module", "(", "'bn_end'", "+", "str", "(", "hg_module", ")", ",", "nn", ".", "BatchNorm2d", "(", "256", ")", ")", "\n", "\n", "if", "hg_module", "<", "self", ".", "num_modules", "-", "1", ":", "\n", "            ", "self", ".", "add_module", "(", "\n", "'bl'", "+", "str", "(", "hg_module", ")", ",", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "self", ".", "add_module", "(", "'al'", "+", "str", "(", "hg_module", ")", ",", "nn", ".", "Conv2d", "(", "68", ",", "\n", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "\n", "", "self", ".", "avgpool", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "2", ")", "\n", "self", ".", "conv6", "=", "nn", ".", "Conv2d", "(", "68", ",", "1", ",", "3", ",", "2", ",", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "28", "*", "28", ",", "512", ")", "\n", "self", ".", "bn5", "=", "nn", ".", "BatchNorm2d", "(", "68", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.FAN_use.forward": [[141, 164], ["torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "FAN_feature_extractor.FAN_use.conv3", "FAN_feature_extractor.FAN_use.conv4", "FAN_feature_extractor.FAN_use.relu", "FAN_feature_extractor.FAN_use.conv6", "FAN_feature_extractor.FAN_use.view", "FAN_feature_extractor.FAN_use.relu", "FAN_feature_extractor.FAN_use.fc", "FAN_feature_extractor.FAN_use.bn1", "FAN_feature_extractor.FAN_use.conv2", "torch.relu", "torch.relu", "torch.relu", "FAN_feature_extractor.FAN_use.bn5", "FAN_feature_extractor.FAN_use.conv1", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ",", "True", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "self", ".", "conv2", "(", "x", ")", ",", "2", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "\n", "previous", "=", "x", "\n", "\n", "i", "=", "0", "\n", "hg", "=", "self", ".", "_modules", "[", "'m'", "+", "str", "(", "i", ")", "]", "(", "previous", ")", "\n", "\n", "ll", "=", "hg", "\n", "ll", "=", "self", ".", "_modules", "[", "'top_m_'", "+", "str", "(", "i", ")", "]", "(", "ll", ")", "\n", "\n", "ll", "=", "self", ".", "_modules", "[", "'bn_end'", "+", "str", "(", "i", ")", "]", "(", "self", ".", "_modules", "[", "'conv_last'", "+", "str", "(", "i", ")", "]", "(", "ll", ")", ")", "\n", "tmp_out", "=", "self", ".", "_modules", "[", "'l'", "+", "str", "(", "i", ")", "]", "(", "F", ".", "relu", "(", "ll", ")", ")", "\n", "\n", "net", "=", "self", ".", "relu", "(", "self", ".", "bn5", "(", "tmp_out", ")", ")", "\n", "net", "=", "self", ".", "conv6", "(", "net", ")", "\n", "net", "=", "net", ".", "view", "(", "-", "1", ",", "net", ".", "shape", "[", "-", "2", "]", "*", "net", ".", "shape", "[", "-", "1", "]", ")", "\n", "net", "=", "self", ".", "relu", "(", "net", ")", "\n", "net", "=", "self", ".", "fc", "(", "net", ")", "\n", "return", "net", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.FAN_feature_extractor.conv3x3": [[7, 11], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "strd", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "\n", "stride", "=", "strd", ",", "padding", "=", "padding", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.VGG19.__init__": [[13, 34], ["super().__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "range", "torchvision.models.vgg19", "architecture.VGG19.slice1.add_module", "architecture.VGG19.slice2.add_module", "architecture.VGG19.slice3.add_module", "architecture.VGG19.slice4.add_module", "architecture.VGG19.slice5.add_module", "architecture.VGG19.parameters", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "super", "(", "VGG19", ",", "self", ")", ".", "__init__", "(", ")", "\n", "vgg_pretrained_features", "=", "torchvision", ".", "models", ".", "vgg19", "(", "pretrained", "=", "True", ")", ".", "features", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice5", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "2", ",", "7", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "7", ",", "12", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "12", ",", "21", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "21", ",", "30", ")", ":", "\n", "            ", "self", ".", "slice5", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.VGG19.forward": [[35, 43], ["architecture.VGG19.slice1", "architecture.VGG19.slice2", "architecture.VGG19.slice3", "architecture.VGG19.slice4", "architecture.VGG19.slice5"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "h_relu1", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu2", "=", "self", ".", "slice2", "(", "h_relu1", ")", "\n", "h_relu3", "=", "self", ".", "slice3", "(", "h_relu2", ")", "\n", "h_relu4", "=", "self", ".", "slice4", "(", "h_relu3", ")", "\n", "h_relu5", "=", "self", ".", "slice5", "(", "h_relu4", ")", "\n", "out", "=", "[", "h_relu1", ",", "h_relu2", ",", "h_relu3", ",", "h_relu4", ",", "h_relu5", "]", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.VGGFace19.__init__": [[46, 77], ["super().__init__", "models.networks.encoder.VGGEncoder", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "print", "util.util.util.copy_state_dict", "len", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "range", "range", "range", "range", "range", "range", "architecture.VGGFace19.slice1.add_module", "architecture.VGGFace19.slice2.add_module", "architecture.VGGFace19.slice3.add_module", "architecture.VGGFace19.slice4.add_module", "architecture.VGGFace19.slice5.add_module", "architecture.VGGFace19.slice6.add_module", "architecture.VGGFace19.parameters", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copy_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "super", "(", "VGGFace19", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "VGGEncoder", "(", "opt", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "ckpt", "=", "torch", ".", "load", "(", "opt", ".", "VGGFace_pretrain_path", ")", "\n", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "opt", ".", "VGGFace_pretrain_path", ")", ")", "\n", "util", ".", "copy_state_dict", "(", "ckpt", ",", "self", ".", "model", ")", "\n", "vgg_pretrained_features", "=", "self", ".", "model", ".", "model", ".", "features", "\n", "len_features", "=", "len", "(", "self", ".", "model", ".", "model", ".", "features", ")", "\n", "self", ".", "slice1", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice2", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice3", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice4", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice5", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "slice6", "=", "torch", ".", "nn", ".", "Sequential", "(", ")", "\n", "\n", "for", "x", "in", "range", "(", "2", ")", ":", "\n", "            ", "self", ".", "slice1", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "2", ",", "7", ")", ":", "\n", "            ", "self", ".", "slice2", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "7", ",", "12", ")", ":", "\n", "            ", "self", ".", "slice3", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "12", ",", "21", ")", ":", "\n", "            ", "self", ".", "slice4", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "21", ",", "30", ")", ":", "\n", "            ", "self", ".", "slice5", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "for", "x", "in", "range", "(", "30", ",", "len_features", ")", ":", "\n", "            ", "self", ".", "slice6", ".", "add_module", "(", "str", "(", "x", ")", ",", "vgg_pretrained_features", "[", "x", "]", ")", "\n", "", "if", "not", "requires_grad", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.VGGFace19.forward": [[78, 88], ["X.view.view.view", "architecture.VGGFace19.slice1", "architecture.VGGFace19.slice2", "architecture.VGGFace19.slice3", "architecture.VGGFace19.slice4", "architecture.VGGFace19.slice5", "architecture.VGGFace19.slice6"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "X", "=", "X", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "h_relu1", "=", "self", ".", "slice1", "(", "X", ")", "\n", "h_relu2", "=", "self", ".", "slice2", "(", "h_relu1", ")", "\n", "h_relu3", "=", "self", ".", "slice3", "(", "h_relu2", ")", "\n", "h_relu4", "=", "self", ".", "slice4", "(", "h_relu3", ")", "\n", "h_relu5", "=", "self", ".", "slice5", "(", "h_relu4", ")", "\n", "h_relu6", "=", "self", ".", "slice6", "(", "h_relu5", ")", "\n", "out", "=", "[", "h_relu3", ",", "h_relu4", ",", "h_relu5", ",", "h_relu6", ",", "h_relu6", "]", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.architecture.get_nonspade_norm_layer": [[92, 129], ["hasattr", "torch.weight.size", "norm_type.startswith", "torch.Sequential", "getattr", "torch", "getattr", "delattr", "torch.register_parameter", "torch.BatchNorm2d", "len", "architecture.get_nonspade_norm_layer.get_out_channel"], "function", ["None"], ["", "", "def", "get_nonspade_norm_layer", "(", "opt", ",", "norm_type", "=", "'instance'", ")", ":", "\n", "# helper function to get # output channels of the previous layer", "\n", "    ", "def", "get_out_channel", "(", "layer", ")", ":", "\n", "        ", "if", "hasattr", "(", "layer", ",", "'out_channels'", ")", ":", "\n", "            ", "return", "getattr", "(", "layer", ",", "'out_channels'", ")", "\n", "", "return", "layer", ".", "weight", ".", "size", "(", "0", ")", "\n", "\n", "# this function will be returned", "\n", "", "def", "add_norm_layer", "(", "layer", ")", ":", "\n", "        ", "nonlocal", "norm_type", "\n", "if", "norm_type", ".", "startswith", "(", "'spectral'", ")", ":", "\n", "            ", "layer", "=", "spectral_norm", "(", "layer", ")", "\n", "subnorm_type", "=", "norm_type", "[", "len", "(", "'spectral'", ")", ":", "]", "\n", "", "else", ":", "\n", "            ", "subnorm_type", "=", "norm_type", "\n", "\n", "", "if", "subnorm_type", "==", "'none'", "or", "len", "(", "subnorm_type", ")", "==", "0", ":", "\n", "            ", "return", "layer", "\n", "\n", "# remove bias in the previous layer, which is meaningless", "\n", "# since it has no effect after normalization", "\n", "", "if", "getattr", "(", "layer", ",", "'bias'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "delattr", "(", "layer", ",", "'bias'", ")", "\n", "layer", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "if", "subnorm_type", "==", "'batch'", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "(", "get_out_channel", "(", "layer", ")", ",", "affine", "=", "True", ")", "\n", "", "elif", "subnorm_type", "==", "'syncbatch'", ":", "\n", "            ", "norm_layer", "=", "SynchronizedBatchNorm2d", "(", "get_out_channel", "(", "layer", ")", ",", "affine", "=", "True", ")", "\n", "", "elif", "subnorm_type", "==", "'instance'", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "InstanceNorm2d", "(", "get_out_channel", "(", "layer", ")", ",", "affine", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'normalization layer %s is not recognized'", "%", "subnorm_type", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "layer", ",", "norm_layer", ")", "\n", "\n", "", "return", "add_norm_layer", "\n", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE.__init__": [[6, 52], ["torch.Module.__init__", "print", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.BatchNorm2d", "torch.BatchNorm2d", "audio_network.ResNetSE._make_layer", "audio_network.ResNetSE._make_layer", "audio_network.ResNetSE._make_layer", "audio_network.ResNetSE._make_layer", "torch.InstanceNorm1d", "torch.InstanceNorm1d", "int", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "audio_network.ResNetSE.modules", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Softmax", "torch.Softmax", "isinstance", "ValueError", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE._make_layer", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE._make_layer", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE._make_layer", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_filters", ",", "nOut", ",", "encoder_type", "=", "'SAP'", ",", "n_mels", "=", "80", ",", "n_mel_T", "=", "1", ",", "log_input", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNetSE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "print", "(", "'Embedding size is %d, encoder %s.'", "%", "(", "nOut", ",", "encoder_type", ")", ")", "\n", "\n", "self", ".", "inplanes", "=", "num_filters", "[", "0", "]", "\n", "self", ".", "encoder_type", "=", "encoder_type", "\n", "self", ".", "n_mels", "=", "n_mels", "\n", "self", ".", "log_input", "=", "log_input", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "num_filters", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "num_filters", "[", "0", "]", ")", "\n", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "0", "]", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "1", "]", ",", "layers", "[", "1", "]", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "2", "]", ",", "layers", "[", "2", "]", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "num_filters", "[", "3", "]", ",", "layers", "[", "3", "]", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "self", ".", "instancenorm", "=", "nn", ".", "InstanceNorm1d", "(", "n_mels", ")", "\n", "\n", "outmap_size", "=", "int", "(", "self", ".", "n_mels", "*", "n_mel_T", "/", "8", ")", "\n", "\n", "self", ".", "attention", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "num_filters", "[", "3", "]", "*", "outmap_size", ",", "128", ",", "kernel_size", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "128", ")", ",", "\n", "nn", ".", "Conv1d", "(", "128", ",", "num_filters", "[", "3", "]", "*", "outmap_size", ",", "kernel_size", "=", "1", ")", ",", "\n", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "encoder_type", "==", "\"SAP\"", ":", "\n", "            ", "out_dim", "=", "num_filters", "[", "3", "]", "*", "outmap_size", "\n", "", "elif", "self", ".", "encoder_type", "==", "\"ASP\"", ":", "\n", "            ", "out_dim", "=", "num_filters", "[", "3", "]", "*", "outmap_size", "*", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Undefined encoder'", ")", "\n", "\n", "", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "out_dim", ",", "nOut", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE._make_layer": [[53, 69], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE.new_parameter": [[70, 74], ["torch.Parameter", "torch.Parameter", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "new_parameter", "(", "self", ",", "*", "size", ")", ":", "\n", "        ", "out", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "*", "size", ")", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.ResNetSE.forward": [[75, 106], ["audio_network.ResNetSE.conv1", "audio_network.ResNetSE.relu", "audio_network.ResNetSE.bn1", "audio_network.ResNetSE.layer1", "audio_network.ResNetSE.layer2", "audio_network.ResNetSE.layer3", "audio_network.ResNetSE.layer4", "torch.cat.reshape", "torch.cat.reshape", "audio_network.ResNetSE.attention", "torch.cat.view", "torch.cat.view", "audio_network.ResNetSE.fc", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "# with torch.no_grad():", "\n", "#     x = self.torchfb(x) + 1e-6", "\n", "#     if self.log_input: x = x.log()", "\n", "#     x = self.instancenorm(x).unsqueeze(1)", "\n", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ",", "x", ".", "size", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "w", "=", "self", ".", "attention", "(", "x", ")", "\n", "\n", "if", "self", ".", "encoder_type", "==", "\"SAP\"", ":", "\n", "            ", "x", "=", "torch", ".", "sum", "(", "x", "*", "w", ",", "dim", "=", "2", ")", "\n", "", "elif", "self", ".", "encoder_type", "==", "\"ASP\"", ":", "\n", "            ", "mu", "=", "torch", ".", "sum", "(", "x", "*", "w", ",", "dim", "=", "2", ")", "\n", "sg", "=", "torch", ".", "sqrt", "(", "(", "torch", ".", "sum", "(", "(", "x", "**", "2", ")", "*", "w", ",", "dim", "=", "2", ")", "-", "mu", "**", "2", ")", ".", "clamp", "(", "min", "=", "1e-5", ")", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "mu", ",", "sg", ")", ",", "1", ")", "\n", "\n", "", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SEBasicBlock.__init__": [[113, 123], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "audio_network.SELayer"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "reduction", "=", "8", ")", ":", "\n", "        ", "super", "(", "SEBasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "planes", ",", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SEBasicBlock.forward": [[124, 141], ["audio_network.SEBasicBlock.conv1", "audio_network.SEBasicBlock.relu", "audio_network.SEBasicBlock.bn1", "audio_network.SEBasicBlock.conv2", "audio_network.SEBasicBlock.bn2", "audio_network.SEBasicBlock.se", "audio_network.SEBasicBlock.relu", "audio_network.SEBasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SEBottleneck.__init__": [[146, 159], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "audio_network.SELayer"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "reduction", "=", "8", ")", ":", "\n", "        ", "super", "(", "SEBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "se", "=", "SELayer", "(", "planes", "*", "4", ",", "reduction", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SEBottleneck.forward": [[160, 182], ["audio_network.SEBottleneck.conv1", "audio_network.SEBottleneck.bn1", "audio_network.SEBottleneck.relu", "audio_network.SEBottleneck.conv2", "audio_network.SEBottleneck.bn2", "audio_network.SEBottleneck.relu", "audio_network.SEBottleneck.conv3", "audio_network.SEBottleneck.bn3", "audio_network.SEBottleneck.se", "audio_network.SEBottleneck.relu", "audio_network.SEBottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.discriminator.MultiscaleDiscriminator.downsample"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "out", "=", "self", ".", "se", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SELayer.__init__": [[185, 193], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "reduction", "=", "8", ")", ":", "\n", "        ", "super", "(", "SELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "channel", ",", "channel", "//", "reduction", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "channel", "//", "reduction", ",", "channel", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.audio_network.SELayer.forward": [[195, 200], ["x.size", "audio_network.SELayer.avg_pool().view", "audio_network.SELayer.fc().view", "audio_network.SELayer.avg_pool", "audio_network.SELayer.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b", ",", "c", ",", "_", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "y", "=", "self", ".", "avg_pool", "(", "x", ")", ".", "view", "(", "b", ",", "c", ")", "\n", "y", "=", "self", ".", "fc", "(", "y", ")", ".", "view", "(", "b", ",", "c", ",", "1", ",", "1", ")", "\n", "return", "x", "*", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.__init__": [[12, 33], ["torch.Module.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gan_mode", ",", "target_real_label", "=", "1.0", ",", "target_fake_label", "=", "0.0", ",", "\n", "tensor", "=", "torch", ".", "FloatTensor", ",", "opt", "=", "None", ")", ":", "\n", "        ", "super", "(", "GANLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "real_label", "=", "target_real_label", "\n", "self", ".", "fake_label", "=", "target_fake_label", "\n", "self", ".", "real_label_tensor", "=", "None", "\n", "self", ".", "fake_label_tensor", "=", "None", "\n", "self", ".", "zero_tensor", "=", "None", "\n", "self", ".", "Tensor", "=", "tensor", "\n", "self", ".", "gan_mode", "=", "gan_mode", "\n", "self", ".", "opt", "=", "opt", "\n", "if", "gan_mode", "==", "'ls'", ":", "\n", "            ", "pass", "\n", "", "elif", "gan_mode", "==", "'original'", ":", "\n", "            ", "pass", "\n", "", "elif", "gan_mode", "==", "'w'", ":", "\n", "            ", "pass", "\n", "", "elif", "gan_mode", "==", "'hinge'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unexpected gan_mode {}'", ".", "format", "(", "gan_mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_target_tensor": [[34, 45], ["loss.GANLoss.real_label_tensor.expand_as", "loss.GANLoss.fake_label_tensor.expand_as", "loss.GANLoss.Tensor().fill_", "loss.GANLoss.real_label_tensor.requires_grad_", "loss.GANLoss.Tensor().fill_", "loss.GANLoss.fake_label_tensor.requires_grad_", "loss.GANLoss.Tensor", "loss.GANLoss.Tensor"], "methods", ["None"], ["", "", "def", "get_target_tensor", "(", "self", ",", "input", ",", "target_is_real", ")", ":", "\n", "        ", "if", "target_is_real", ":", "\n", "            ", "if", "self", ".", "real_label_tensor", "is", "None", ":", "\n", "                ", "self", ".", "real_label_tensor", "=", "self", ".", "Tensor", "(", "1", ")", ".", "fill_", "(", "self", ".", "real_label", ")", "\n", "self", ".", "real_label_tensor", ".", "requires_grad_", "(", "False", ")", "\n", "", "return", "self", ".", "real_label_tensor", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "fake_label_tensor", "is", "None", ":", "\n", "                ", "self", ".", "fake_label_tensor", "=", "self", ".", "Tensor", "(", "1", ")", ".", "fill_", "(", "self", ".", "fake_label", ")", "\n", "self", ".", "fake_label_tensor", ".", "requires_grad_", "(", "False", ")", "\n", "", "return", "self", ".", "fake_label_tensor", ".", "expand_as", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_zero_tensor": [[46, 51], ["loss.GANLoss.zero_tensor.expand_as", "loss.GANLoss.Tensor().fill_", "loss.GANLoss.zero_tensor.requires_grad_", "loss.GANLoss.Tensor"], "methods", ["None"], ["", "", "def", "get_zero_tensor", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "zero_tensor", "is", "None", ":", "\n", "            ", "self", ".", "zero_tensor", "=", "self", ".", "Tensor", "(", "1", ")", ".", "fill_", "(", "0", ")", "\n", "self", ".", "zero_tensor", ".", "requires_grad_", "(", "False", ")", "\n", "", "return", "self", ".", "zero_tensor", ".", "expand_as", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.loss": [[52, 78], ["F.binary_cross_entropy_with_logits.GANLoss.get_target_tensor", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "F.binary_cross_entropy_with_logits.GANLoss.get_target_tensor", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "input.mean", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "input.mean", "F.binary_cross_entropy_with_logits.GANLoss.get_zero_tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "F.binary_cross_entropy_with_logits.GANLoss.get_zero_tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_target_tensor", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_target_tensor", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_zero_tensor", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.get_zero_tensor"], ["", "def", "loss", "(", "self", ",", "input", ",", "target_is_real", ",", "for_discriminator", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "gan_mode", "==", "'original'", ":", "# cross entropy loss", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "input", ",", "target_is_real", ")", "\n", "loss", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "input", ",", "target_tensor", ")", "\n", "return", "loss", "\n", "", "elif", "self", ".", "gan_mode", "==", "'ls'", ":", "\n", "            ", "target_tensor", "=", "self", ".", "get_target_tensor", "(", "input", ",", "target_is_real", ")", "\n", "return", "F", ".", "mse_loss", "(", "input", ",", "target_tensor", ")", "\n", "", "elif", "self", ".", "gan_mode", "==", "'hinge'", ":", "\n", "            ", "if", "for_discriminator", ":", "\n", "                ", "if", "target_is_real", ":", "\n", "                    ", "minval", "=", "torch", ".", "min", "(", "input", "-", "1", ",", "self", ".", "get_zero_tensor", "(", "input", ")", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "minval", ")", "\n", "", "else", ":", "\n", "                    ", "minval", "=", "torch", ".", "min", "(", "-", "input", "-", "1", ",", "self", ".", "get_zero_tensor", "(", "input", ")", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "minval", ")", "\n", "", "", "else", ":", "\n", "                ", "assert", "target_is_real", ",", "\"The generator's hinge loss must be aiming for real\"", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "input", ")", "\n", "", "return", "loss", "\n", "", "else", ":", "\n", "# wgan", "\n", "            ", "if", "target_is_real", ":", "\n", "                ", "return", "-", "input", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "return", "input", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.__call__": [[79, 94], ["isinstance", "loss.GANLoss.loss", "isinstance", "loss.GANLoss.loss", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "len", "loss.GANLoss.size", "loss.GANLoss.view", "len", "loss.GANLoss.size"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.loss", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.GANLoss.loss"], ["", "", "", "def", "__call__", "(", "self", ",", "input", ",", "target_is_real", ",", "for_discriminator", "=", "True", ")", ":", "\n", "# computing loss is a bit complicated because |input| may not be", "\n", "# a tensor, but list of tensors in case of multiscale discriminator", "\n", "        ", "if", "isinstance", "(", "input", ",", "list", ")", ":", "\n", "            ", "loss", "=", "0", "\n", "for", "pred_i", "in", "input", ":", "\n", "                ", "if", "isinstance", "(", "pred_i", ",", "list", ")", ":", "\n", "                    ", "pred_i", "=", "pred_i", "[", "-", "1", "]", "\n", "", "loss_tensor", "=", "self", ".", "loss", "(", "pred_i", ",", "target_is_real", ",", "for_discriminator", ")", "\n", "bs", "=", "1", "if", "len", "(", "loss_tensor", ".", "size", "(", ")", ")", "==", "0", "else", "loss_tensor", ".", "size", "(", "0", ")", "\n", "new_loss", "=", "torch", ".", "mean", "(", "loss_tensor", ".", "view", "(", "bs", ",", "-", "1", ")", ",", "dim", "=", "1", ")", "\n", "loss", "+=", "new_loss", "\n", "", "return", "loss", "/", "len", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "loss", "(", "input", ",", "target_is_real", ",", "for_discriminator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.VGGLoss.__init__": [[98, 103], ["models.networks.architecture.VGG19", "torch.Module.__init__", "vgg.cuda", "torch.L1Loss", "torch.L1Loss", "torch.L1Loss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "vgg", "=", "VGG19", "(", ")", ")", ":", "\n", "        ", "super", "(", "VGGLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vgg", "=", "vgg", ".", "cuda", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "L1Loss", "(", ")", "\n", "self", ".", "weights", "=", "[", "1.0", "/", "32", ",", "1.0", "/", "16", ",", "1.0", "/", "8", ",", "1.0", "/", "4", ",", "1.0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.VGGLoss.forward": [[104, 111], ["range", "loss.VGGLoss.vgg", "loss.VGGLoss.vgg", "len", "loss.VGGLoss.criterion", "y_vgg[].detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "layer", "=", "0", ")", ":", "\n", "        ", "x_vgg", ",", "y_vgg", "=", "self", ".", "vgg", "(", "x", ")", ",", "self", ".", "vgg", "(", "y", ")", "\n", "loss", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "x_vgg", ")", ")", ":", "\n", "            ", "if", "i", ">=", "layer", ":", "\n", "                ", "loss", "+=", "self", ".", "weights", "[", "i", "]", "*", "self", ".", "criterion", "(", "x_vgg", "[", "i", "]", ",", "y_vgg", "[", "i", "]", ".", "detach", "(", ")", ")", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.KLDLoss.forward": [[115, 117], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "logvar.exp", "mu.pow"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "return", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "logvar", "-", "mu", ".", "pow", "(", "2", ")", "-", "logvar", ".", "exp", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.CrossEntropyLoss.forward": [[125, 128], ["torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["def", "forward", "(", "self", ",", "cls_score", ",", "label", ")", ":", "\n", "        ", "loss_cls", "=", "F", ".", "cross_entropy", "(", "cls_score", ",", "label", ")", "\n", "return", "loss_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SumLogSoftmaxLoss.forward": [[132, 136], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "out", ")", "+", "torch", ".", "mean", "(", "F", ".", "log_softmax", "(", "torch", ".", "ones_like", "(", "out", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.L2SoftmaxLoss.__init__": [[139, 144], ["torch.Module.__init__", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "L2SoftmaxLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "L2loss", "=", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "label", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.L2SoftmaxLoss.forward": [[145, 150], ["loss.L2SoftmaxLoss.L2SoftmaxLoss.softmax", "loss.L2SoftmaxLoss.L2SoftmaxLoss.L2loss", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "x.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "loss.L2SoftmaxLoss.L2SoftmaxLoss.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "softmax", "(", "x", ")", "\n", "self", ".", "label", "=", "(", "torch", ".", "ones", "(", "out", ".", "size", "(", ")", ")", ".", "float", "(", ")", "*", "(", "1", "/", "x", ".", "size", "(", "1", ")", ")", ")", ".", "cuda", "(", ")", "\n", "loss", "=", "self", ".", "L2loss", "(", "out", ",", "self", ".", "label", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.__init__": [[153, 156], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "SoftmaxContrastiveLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cross_ent", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_norm": [[157, 160], ["torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["", "def", "l2_norm", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_norm", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "return", "x_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_sim": [[161, 164], ["feature1.expand().transpose", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "feature1.expand", "feature1.size", "feature1.size", "feature1.size"], "methods", ["None"], ["", "def", "l2_sim", "(", "self", ",", "feature1", ",", "feature2", ")", ":", "\n", "        ", "Feature", "=", "feature1", ".", "expand", "(", "feature1", ".", "size", "(", "0", ")", ",", "feature1", ".", "size", "(", "0", ")", ",", "feature1", ".", "size", "(", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "torch", ".", "norm", "(", "Feature", "-", "feature2", ",", "p", "=", "2", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.evaluate": [[165, 182], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "loss.SoftmaxContrastiveLoss.l2_norm", "loss.SoftmaxContrastiveLoss.l2_norm", "print", "loss.SoftmaxContrastiveLoss.l2_sim", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.arange().to.size", "torch.arange().to.size", "torch.arange().to.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "loss.SoftmaxContrastiveLoss.size"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_norm", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_norm", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_sim"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "evaluate", "(", "self", ",", "face_feat", ",", "audio_feat", ",", "mode", "=", "'max'", ")", ":", "\n", "        ", "assert", "mode", "in", "'max'", "or", "'confusion'", ",", "'{} must be in max or confusion'", ".", "format", "(", "mode", ")", "\n", "face_feat", "=", "self", ".", "l2_norm", "(", "face_feat", ")", "\n", "audio_feat", "=", "self", ".", "l2_norm", "(", "audio_feat", ")", "\n", "cross_dist", "=", "1.0", "/", "self", ".", "l2_sim", "(", "face_feat", ",", "audio_feat", ")", "\n", "\n", "print", "(", "cross_dist", ")", "\n", "if", "mode", "==", "'max'", ":", "\n", "            ", "label", "=", "torch", ".", "arange", "(", "face_feat", ".", "size", "(", "0", ")", ")", ".", "to", "(", "cross_dist", ".", "device", ")", "\n", "max_idx", "=", "torch", ".", "argmax", "(", "cross_dist", ",", "dim", "=", "1", ")", "\n", "# print(max_idx, label)", "\n", "acc", "=", "torch", ".", "sum", "(", "label", "==", "max_idx", ")", "*", "1.0", "/", "label", ".", "size", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.forward": [[183, 197], ["F.cross_entropy.SoftmaxContrastiveLoss.l2_norm", "F.cross_entropy.SoftmaxContrastiveLoss.l2_norm", "F.cross_entropy.SoftmaxContrastiveLoss.l2_sim", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "F.cross_entropy.SoftmaxContrastiveLoss.size"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_norm", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_norm", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.loss.SoftmaxContrastiveLoss.l2_sim"], ["", "def", "forward", "(", "self", ",", "face_feat", ",", "audio_feat", ",", "mode", "=", "'max'", ")", ":", "\n", "        ", "assert", "mode", "in", "'max'", "or", "'confusion'", ",", "'{} must be in max or confusion'", ".", "format", "(", "mode", ")", "\n", "\n", "face_feat", "=", "self", ".", "l2_norm", "(", "face_feat", ")", "\n", "audio_feat", "=", "self", ".", "l2_norm", "(", "audio_feat", ")", "\n", "\n", "cross_dist", "=", "1.0", "/", "self", ".", "l2_sim", "(", "face_feat", ",", "audio_feat", ")", "\n", "\n", "if", "mode", "==", "'max'", ":", "\n", "            ", "label", "=", "torch", ".", "arange", "(", "face_feat", ".", "size", "(", "0", ")", ")", ".", "to", "(", "cross_dist", ".", "device", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "cross_dist", ",", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.FusedLeakyReLU.__init__": [[14, 19], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "2", "**", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "channel", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "negative_slope", "=", "negative_slope", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.FusedLeakyReLU.forward": [[20, 27], ["generator.fused_leaky_relu"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.fused_leaky_relu"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# print(\"FusedLeakyReLU: \", input.abs().mean())", "\n", "        ", "out", "=", "fused_leaky_relu", "(", "input", ",", "self", ".", "bias", ",", "\n", "self", ".", "negative_slope", ",", "\n", "self", ".", "scale", ")", "\n", "# print(\"FusedLeakyReLU: \", out.abs().mean())", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.PixelNorm.__init__": [[71, 73], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.PixelNorm.forward": [[74, 76], ["torch.rsqrt", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "*", "torch", ".", "rsqrt", "(", "torch", ".", "mean", "(", "input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Upsample.__init__": [[90, 103], ["torch.nn.Module.__init__", "generator.Upsample.register_buffer", "generator.make_kernel"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "factor", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "factor", "=", "factor", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "*", "(", "factor", "**", "2", ")", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "p", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "+", "factor", "-", "1", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "pad", "=", "(", "pad0", ",", "pad1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Upsample.forward": [[104, 108], ["generator.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "up", "=", "self", ".", "factor", ",", "down", "=", "1", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Downsample.__init__": [[111, 124], ["torch.nn.Module.__init__", "generator.make_kernel", "generator.Downsample.register_buffer"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "factor", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "factor", "=", "factor", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "p", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "pad", "=", "(", "pad0", ",", "pad1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Downsample.forward": [[125, 129], ["generator.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "up", "=", "1", ",", "down", "=", "self", ".", "factor", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Blur.__init__": [[132, 143], ["torch.nn.Module.__init__", "generator.make_kernel", "generator.Blur.register_buffer"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.make_kernel"], ["    ", "def", "__init__", "(", "self", ",", "kernel", ",", "pad", ",", "upsample_factor", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "kernel", "=", "make_kernel", "(", "kernel", ")", "\n", "\n", "if", "upsample_factor", ">", "1", ":", "\n", "            ", "kernel", "=", "kernel", "*", "(", "upsample_factor", "**", "2", ")", "\n", "\n", "", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.Blur.forward": [[144, 148], ["generator.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "pad", "=", "self", ".", "pad", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualConv2d.__init__": [[151, 169], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn", "math.sqrt", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_channel", ",", "out_channel", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "out_channel", ",", "in_channel", ",", "kernel_size", ",", "kernel_size", ")", "\n", ")", "\n", "self", ".", "scale", "=", "1", "/", "math", ".", "sqrt", "(", "in_channel", "*", "kernel_size", "**", "2", ")", "\n", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_channel", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualConv2d.forward": [[170, 180], ["torch.nn.functional.conv2d"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "F", ".", "conv2d", "(", "\n", "input", ",", "\n", "self", ".", "weight", "*", "self", ".", "scale", ",", "\n", "bias", "=", "self", ".", "bias", ",", "\n", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualConv2d.__repr__": [[181, 184], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]},'", "\n", "f' {self.weight.shape[2]}, stride={self.stride}, padding={self.padding})'", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualLinear.__init__": [[189, 206], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn().div_", "torch.nn.Parameter", "torch.zeros().fill_", "math.sqrt", "torch.randn", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "in_dim", ",", "out_dim", ",", "bias", "=", "True", ",", "bias_init", "=", "0", ",", "lr_mul", "=", "1", ",", "activation", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "out_dim", ",", "in_dim", ")", ".", "div_", "(", "lr_mul", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_dim", ")", ".", "fill_", "(", "bias_init", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "self", ".", "activation", "=", "activation", "\n", "\n", "self", ".", "scale", "=", "(", "1", "/", "math", ".", "sqrt", "(", "in_dim", ")", ")", "*", "lr_mul", "\n", "self", ".", "lr_mul", "=", "lr_mul", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualLinear.forward": [[207, 218], ["torch.nn.functional.linear", "generator.fused_leaky_relu", "torch.nn.functional.linear"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.fused_leaky_relu"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "activation", ":", "\n", "            ", "out", "=", "F", ".", "linear", "(", "input", ",", "self", ".", "weight", "*", "self", ".", "scale", ")", "\n", "out", "=", "fused_leaky_relu", "(", "out", ",", "self", ".", "bias", "*", "self", ".", "lr_mul", ")", "\n", "\n", "", "else", ":", "\n", "            ", "out", "=", "F", ".", "linear", "(", "\n", "input", ",", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "lr_mul", "\n", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.EqualLinear.__repr__": [[219, 222], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.weight.shape[1]}, {self.weight.shape[0]})'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ScaledLeakyReLU.__init__": [[226, 230], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "negative_slope", "=", "0.2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "negative_slope", "=", "negative_slope", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ScaledLeakyReLU.forward": [[231, 235], ["torch.nn.functional.leaky_relu", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "F", ".", "leaky_relu", "(", "input", ",", "negative_slope", "=", "self", ".", "negative_slope", ")", "\n", "\n", "return", "out", "*", "math", ".", "sqrt", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ModulatedConv2d.__init__": [[238, 285], ["torch.nn.Module.__init__", "torch.nn.Parameter", "generator.EqualLinear", "generator.Blur", "generator.Blur", "math.sqrt", "torch.randn", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", ",", "\n", "demodulate", "=", "True", ",", "\n", "upsample", "=", "False", ",", "\n", "downsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "1e-8", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "in_channel", "=", "in_channel", "\n", "self", ".", "out_channel", "=", "out_channel", "\n", "self", ".", "upsample", "=", "upsample", "\n", "self", ".", "downsample", "=", "downsample", "\n", "\n", "if", "upsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "-", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "+", "factor", "-", "1", "\n", "pad1", "=", "p", "//", "2", "+", "1", "\n", "\n", "self", ".", "blur", "=", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ",", "upsample_factor", "=", "factor", ")", "\n", "\n", "", "if", "downsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "self", ".", "blur", "=", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ")", "\n", "\n", "", "fan_in", "=", "in_channel", "*", "kernel_size", "**", "2", "\n", "self", ".", "scale", "=", "1", "/", "math", ".", "sqrt", "(", "fan_in", ")", "\n", "self", ".", "padding", "=", "kernel_size", "//", "2", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "1", ",", "out_channel", ",", "in_channel", ",", "kernel_size", ",", "kernel_size", ")", "\n", ")", "\n", "\n", "self", ".", "modulation", "=", "EqualLinear", "(", "style_dim", ",", "in_channel", ",", "bias_init", "=", "1", ")", "\n", "\n", "self", ".", "demodulate", "=", "demodulate", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ModulatedConv2d.__repr__": [[286, 289], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f'{self.__class__.__name__}({self.in_channel}, {self.out_channel}, {self.kernel_size}, '", "\n", "f'upsample={self.upsample}, downsample={self.downsample})'", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ModulatedConv2d.forward": [[292, 334], ["generator.ModulatedConv2d.modulation().view", "weight.transpose().reshape.transpose().reshape.view", "torch.rsqrt", "input.view.view.view", "weight.transpose().reshape.transpose().reshape.view", "weight.transpose().reshape.transpose().reshape.transpose().reshape", "torch.nn.functional.conv_transpose2d", "out.view.view.view", "generator.ModulatedConv2d.blur", "generator.ModulatedConv2d.modulation", "torch.rsqrt.view", "generator.ModulatedConv2d.blur", "input.view.view.view", "torch.nn.functional.conv2d", "out.view.view.view", "input.view.view.view", "torch.nn.functional.conv2d", "out.view.view.view", "weight.transpose().reshape.transpose().reshape.pow().sum", "weight.transpose().reshape.transpose().reshape.transpose", "weight.transpose().reshape.transpose().reshape.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", ")", ":", "\n", "        ", "batch", ",", "in_channel", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "\n", "style", "=", "self", ".", "modulation", "(", "style", ")", ".", "view", "(", "batch", ",", "1", ",", "in_channel", ",", "1", ",", "1", ")", "\n", "weight", "=", "self", ".", "scale", "*", "self", ".", "weight", "*", "style", "\n", "\n", "if", "self", ".", "demodulate", ":", "\n", "            ", "demod", "=", "torch", ".", "rsqrt", "(", "weight", ".", "pow", "(", "2", ")", ".", "sum", "(", "[", "2", ",", "3", ",", "4", "]", ")", "+", "1e-8", ")", "\n", "weight", "=", "weight", "*", "demod", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "weight", "=", "weight", ".", "view", "(", "\n", "batch", "*", "self", ".", "out_channel", ",", "in_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "\n", "if", "self", ".", "upsample", ":", "\n", "            ", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "weight", "=", "weight", ".", "view", "(", "\n", "batch", ",", "self", ".", "out_channel", ",", "in_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "weight", "=", "weight", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "\n", "batch", "*", "in_channel", ",", "self", ".", "out_channel", ",", "self", ".", "kernel_size", ",", "self", ".", "kernel_size", "\n", ")", "\n", "out", "=", "F", ".", "conv_transpose2d", "(", "input", ",", "weight", ",", "padding", "=", "0", ",", "stride", "=", "2", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "self", ".", "blur", "(", "out", ")", "\n", "\n", "", "elif", "self", ".", "downsample", ":", "\n", "            ", "input", "=", "self", ".", "blur", "(", "input", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "padding", "=", "0", ",", "stride", "=", "2", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "\n", "", "else", ":", "\n", "            ", "input", "=", "input", ".", "view", "(", "1", ",", "batch", "*", "in_channel", ",", "height", ",", "width", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "padding", "=", "self", ".", "padding", ",", "groups", "=", "batch", ")", "\n", "_", ",", "_", ",", "height", ",", "width", "=", "out", ".", "shape", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "self", ".", "out_channel", ",", "height", ",", "width", ")", "\n", "\n", "", "return", "out", ",", "style", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.NoiseInjection.__init__": [[337, 341], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.NoiseInjection.forward": [[342, 348], ["image.new_empty().normal_", "image.new_empty"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ",", "noise", "=", "None", ")", ":", "\n", "        ", "if", "noise", "is", "None", ":", "\n", "            ", "batch", ",", "_", ",", "height", ",", "width", "=", "image", ".", "shape", "\n", "noise", "=", "image", ".", "new_empty", "(", "batch", ",", "1", ",", "height", ",", "width", ")", ".", "normal_", "(", ")", "\n", "\n", "", "return", "image", "+", "self", ".", "weight", "*", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ConstantInput.__init__": [[351, 355], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "size", "=", "7", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "1", ",", "channel", ",", "size", ",", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ConstantInput.forward": [[356, 361], ["generator.ConstantInput.input.repeat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "batch", "=", "input", ".", "shape", "[", "0", "]", "\n", "out", "=", "self", ".", "input", ".", "repeat", "(", "batch", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.StyledConv.__init__": [[364, 390], ["torch.nn.Module.__init__", "generator.ModulatedConv2d", "generator.NoiseInjection", "generator.FusedLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", ",", "\n", "upsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "demodulate", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "ModulatedConv2d", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "style_dim", ",", "\n", "upsample", "=", "upsample", ",", "\n", "blur_kernel", "=", "blur_kernel", ",", "\n", "demodulate", "=", "demodulate", ",", "\n", ")", "\n", "\n", "self", ".", "noise", "=", "NoiseInjection", "(", ")", "\n", "# self.bias = nn.Parameter(torch.zeros(1, out_channel, 1, 1))", "\n", "# self.activate = ScaledLeakyReLU(0.2)", "\n", "self", ".", "activate", "=", "FusedLeakyReLU", "(", "out_channel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.StyledConv.forward": [[391, 398], ["generator.StyledConv.conv", "generator.StyledConv.noise", "generator.StyledConv.activate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", ",", "noise", "=", "None", ")", ":", "\n", "        ", "out", ",", "_", "=", "self", ".", "conv", "(", "input", ",", "style", ")", "\n", "out", "=", "self", ".", "noise", "(", "out", ",", "noise", "=", "noise", ")", "\n", "# out = out + self.bias", "\n", "out", "=", "self", ".", "activate", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ToRGB.__init__": [[401, 409], ["torch.nn.Module.__init__", "generator.ModulatedConv2d", "torch.nn.Parameter", "generator.Upsample", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "style_dim", ",", "upsample", "=", "True", ",", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "upsample", ":", "\n", "            ", "self", ".", "upsample", "=", "Upsample", "(", "blur_kernel", ")", "\n", "\n", "", "self", ".", "conv", "=", "ModulatedConv2d", "(", "in_channel", ",", "3", ",", "1", ",", "style_dim", ",", "demodulate", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ToRGB.forward": [[410, 420], ["generator.ToRGB.conv", "generator.ToRGB.upsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "style", ",", "skip", "=", "None", ")", ":", "\n", "        ", "out", ",", "style", "=", "self", ".", "conv", "(", "input", ",", "style", ")", "\n", "out", "=", "out", "+", "self", ".", "bias", "\n", "\n", "if", "skip", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "upsample", "(", "skip", ")", "\n", "\n", "out", "=", "out", "+", "skip", "\n", "\n", "", "return", "out", ",", "style", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.StyleGAN2Generator.__init__": [[423, 526], ["models.networks.BaseNetwork.__init__", "range", "torch.nn.Sequential", "generator.ConstantInput", "generator.StyledConv", "generator.ToRGB", "int", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Module", "range", "range", "torch.nn.Tanh", "generator.PixelNorm", "layers.append", "math.log", "generator.StyleGAN2Generator.noises.register_buffer", "generator.StyleGAN2Generator.convs.append", "generator.StyleGAN2Generator.convs.append", "generator.StyleGAN2Generator.to_rgbs.append", "generator.EqualLinear", "torch.randn", "generator.StyledConv", "generator.StyledConv", "generator.ToRGB"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "opt", ",", "\n", "style_dim", "=", "2580", ",", "\n", "n_mlp", "=", "8", ",", "\n", "channel_multiplier", "=", "2", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "lr_mlp", "=", "0.01", ",", "\n", "input_is_latent", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "size", "=", "opt", ".", "crop_size", "\n", "\n", "self", ".", "feature_encoded_dim", "=", "opt", ".", "feature_encoded_dim", "\n", "\n", "self", ".", "style_dim", "=", "style_dim", "\n", "\n", "self", ".", "input_is_latent", "=", "input_is_latent", "\n", "\n", "layers", "=", "[", "PixelNorm", "(", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_mlp", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "EqualLinear", "(", "\n", "self", ".", "feature_encoded_dim", ",", "self", ".", "style_dim", ",", "lr_mul", "=", "lr_mlp", ",", "activation", "=", "'fused_lrelu'", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "style", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "init_size", "=", "4", "\n", "if", "self", ".", "size", "%", "7", "==", "0", ":", "\n", "            ", "self", ".", "channels", "=", "{", "\n", "7", ":", "512", ",", "\n", "14", ":", "512", ",", "\n", "28", ":", "512", ",", "\n", "56", ":", "256", "*", "channel_multiplier", ",", "\n", "112", ":", "128", "*", "channel_multiplier", ",", "\n", "224", ":", "64", "*", "channel_multiplier", ",", "\n", "448", ":", "32", "*", "channel_multiplier", ",", "\n", "}", "\n", "self", ".", "init_size", "=", "7", "\n", "", "else", ":", "\n", "            ", "self", ".", "channels", "=", "{", "\n", "4", ":", "512", ",", "\n", "8", ":", "512", ",", "\n", "16", ":", "512", ",", "\n", "32", ":", "512", ",", "\n", "64", ":", "256", "*", "channel_multiplier", ",", "\n", "128", ":", "128", "*", "channel_multiplier", ",", "\n", "256", ":", "64", "*", "channel_multiplier", ",", "\n", "512", ":", "32", "*", "channel_multiplier", ",", "\n", "1024", ":", "16", "*", "channel_multiplier", ",", "\n", "}", "\n", "\n", "", "self", ".", "input", "=", "ConstantInput", "(", "self", ".", "channels", "[", "self", ".", "init_size", "]", ",", "size", "=", "self", ".", "init_size", ")", "\n", "self", ".", "conv1", "=", "StyledConv", "(", "\n", "self", ".", "channels", "[", "self", ".", "init_size", "]", ",", "self", ".", "channels", "[", "self", ".", "init_size", "]", ",", "3", ",", "self", ".", "style_dim", ",", "blur_kernel", "=", "blur_kernel", "\n", ")", "\n", "self", ".", "to_rgb1", "=", "ToRGB", "(", "self", ".", "channels", "[", "self", ".", "init_size", "]", ",", "self", ".", "style_dim", ",", "upsample", "=", "False", ")", "\n", "\n", "self", ".", "log_size", "=", "int", "(", "math", ".", "log", "(", "self", ".", "size", "//", "self", ".", "init_size", ",", "2", ")", ")", "\n", "self", ".", "num_layers", "=", "self", ".", "log_size", "*", "2", "+", "1", "\n", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "upsamples", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "to_rgbs", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "noises", "=", "nn", ".", "Module", "(", ")", "\n", "self", ".", "return_middle", "=", "opt", ".", "style_feature_loss", "\n", "\n", "in_channel", "=", "self", ".", "channels", "[", "self", ".", "init_size", "]", "\n", "\n", "for", "layer_idx", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "res", "=", "(", "layer_idx", "+", "1", ")", "//", "2", "\n", "shape", "=", "[", "1", ",", "1", ",", "self", ".", "init_size", "*", "2", "**", "res", ",", "self", ".", "init_size", "*", "2", "**", "res", "]", "\n", "self", ".", "noises", ".", "register_buffer", "(", "f'noise_{layer_idx}'", ",", "torch", ".", "randn", "(", "*", "shape", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "self", ".", "log_size", "+", "1", ")", ":", "\n", "            ", "out_channel", "=", "self", ".", "channels", "[", "self", ".", "init_size", "*", "2", "**", "i", "]", "\n", "\n", "self", ".", "convs", ".", "append", "(", "\n", "StyledConv", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "3", ",", "\n", "self", ".", "style_dim", ",", "\n", "upsample", "=", "True", ",", "\n", "blur_kernel", "=", "blur_kernel", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "convs", ".", "append", "(", "\n", "StyledConv", "(", "\n", "out_channel", ",", "out_channel", ",", "3", ",", "self", ".", "style_dim", ",", "blur_kernel", "=", "blur_kernel", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "to_rgbs", ".", "append", "(", "ToRGB", "(", "out_channel", ",", "self", ".", "style_dim", ")", ")", "\n", "\n", "in_channel", "=", "out_channel", "\n", "\n", "", "self", ".", "n_latent", "=", "self", ".", "log_size", "*", "2", "+", "2", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.StyleGAN2Generator.forward": [[527, 608], ["generator.StyleGAN2Generator.conv1", "generator.StyleGAN2Generator.to_rgb1", "Style_RGB.append", "zip", "generator.StyleGAN2Generator.tanh", "len", "styles[].unsqueeze().repeat", "styles[].unsqueeze().repeat", "torch.cat", "generator.StyleGAN2Generator.input", "conv1", "conv2", "to_rgb", "Style_RGB.append", "generator.StyleGAN2Generator.style", "style_t.append", "styles[].unsqueeze().repeat", "random.randint", "getattr", "styles[].unsqueeze", "styles[].unsqueeze", "range", "styles[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "styles", ",", "\n", "identity_style", "=", "None", ",", "\n", "return_latents", "=", "False", ",", "\n", "inject_index", "=", "None", ",", "\n", "truncation", "=", "1", ",", "\n", "truncation_latent", "=", "None", ",", "\n", "noise", "=", "None", ",", "\n", "randomize_noise", "=", "True", ",", "\n", ")", ":", "\n", "\n", "        ", "Style_RGB", "=", "[", "]", "\n", "if", "not", "self", ".", "input_is_latent", ":", "\n", "            ", "styles", "=", "[", "self", ".", "style", "(", "s", ")", "for", "s", "in", "styles", "]", "\n", "\n", "", "if", "noise", "is", "None", ":", "\n", "            ", "if", "randomize_noise", ":", "\n", "                ", "noise", "=", "[", "None", "]", "*", "self", ".", "num_layers", "\n", "", "else", ":", "\n", "                ", "noise", "=", "[", "\n", "getattr", "(", "self", ".", "noises", ",", "f'noise_{i}'", ")", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "\n", "]", "\n", "\n", "", "", "if", "truncation", "<", "1", ":", "\n", "            ", "style_t", "=", "[", "]", "\n", "\n", "for", "style", "in", "styles", ":", "\n", "                ", "style_t", ".", "append", "(", "\n", "truncation_latent", "+", "truncation", "*", "(", "style", "-", "truncation_latent", ")", "\n", ")", "\n", "\n", "", "styles", "=", "style_t", "\n", "\n", "", "if", "len", "(", "styles", ")", "<", "2", ":", "\n", "            ", "inject_index", "=", "self", ".", "n_latent", "\n", "\n", "if", "styles", "[", "0", "]", ".", "ndim", "<", "3", ":", "\n", "                ", "latent", "=", "styles", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inject_index", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "latent", "=", "styles", "[", "0", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "inject_index", "is", "None", ":", "\n", "                ", "inject_index", "=", "random", ".", "randint", "(", "1", ",", "self", ".", "n_latent", "-", "1", ")", "\n", "\n", "", "latent", "=", "styles", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inject_index", ",", "1", ")", "\n", "latent2", "=", "styles", "[", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "n_latent", "-", "inject_index", ",", "1", ")", "\n", "\n", "latent", "=", "torch", ".", "cat", "(", "[", "latent", ",", "latent2", "]", ",", "1", ")", "\n", "\n", "", "if", "identity_style", "is", "not", "None", ":", "\n", "            ", "out", "=", "identity_style", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "input", "(", "latent", ")", "\n", "", "out", "=", "self", ".", "conv1", "(", "out", ",", "latent", "[", ":", ",", "0", "]", ",", "noise", "=", "noise", "[", "0", "]", ")", "\n", "\n", "skip", ",", "style_rgb", "=", "self", ".", "to_rgb1", "(", "out", ",", "latent", "[", ":", ",", "1", "]", ")", "\n", "Style_RGB", ".", "append", "(", "style_rgb", ")", "\n", "\n", "i", "=", "1", "\n", "for", "conv1", ",", "conv2", ",", "noise1", ",", "noise2", ",", "to_rgb", "in", "zip", "(", "\n", "self", ".", "convs", "[", ":", ":", "2", "]", ",", "self", ".", "convs", "[", "1", ":", ":", "2", "]", ",", "noise", "[", "1", ":", ":", "2", "]", ",", "noise", "[", "2", ":", ":", "2", "]", ",", "self", ".", "to_rgbs", "\n", ")", ":", "\n", "            ", "out", "=", "conv1", "(", "out", ",", "latent", "[", ":", ",", "i", "]", ",", "noise", "=", "noise1", ")", "\n", "out", "=", "conv2", "(", "out", ",", "latent", "[", ":", ",", "i", "+", "1", "]", ",", "noise", "=", "noise2", ")", "\n", "skip", ",", "style_rgb", "=", "to_rgb", "(", "out", ",", "latent", "[", ":", ",", "i", "+", "2", "]", ",", "skip", ")", "\n", "Style_RGB", ".", "append", "(", "style_rgb", ")", "\n", "i", "+=", "2", "\n", "\n", "", "image", "=", "skip", "\n", "image", "=", "self", ".", "tanh", "(", "image", ")", "\n", "\n", "if", "return_latents", ":", "\n", "            ", "return", "image", ",", "latent", "\n", "", "elif", "self", ".", "return_middle", ":", "\n", "            ", "return", "image", ",", "Style_RGB", "\n", "\n", "", "else", ":", "\n", "            ", "return", "image", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ConvLayer.__init__": [[611, 657], ["layers.append", "torch.nn.Sequential.__init__", "layers.append", "generator.EqualConv2d", "generator.Blur", "layers.append", "layers.append", "len", "generator.FusedLeakyReLU", "generator.ScaledLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "downsample", "=", "False", ",", "\n", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "bias", "=", "True", ",", "\n", "activate", "=", "True", ",", "\n", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "\n", "if", "downsample", ":", "\n", "            ", "factor", "=", "2", "\n", "p", "=", "(", "len", "(", "blur_kernel", ")", "-", "factor", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "pad0", "=", "(", "p", "+", "1", ")", "//", "2", "\n", "pad1", "=", "p", "//", "2", "\n", "\n", "layers", ".", "append", "(", "Blur", "(", "blur_kernel", ",", "pad", "=", "(", "pad0", ",", "pad1", ")", ")", ")", "\n", "\n", "stride", "=", "2", "\n", "self", ".", "padding", "=", "0", "\n", "\n", "", "else", ":", "\n", "            ", "stride", "=", "1", "\n", "self", ".", "padding", "=", "kernel_size", "//", "2", "\n", "\n", "", "layers", ".", "append", "(", "\n", "EqualConv2d", "(", "\n", "in_channel", ",", "\n", "out_channel", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "bias", "and", "not", "activate", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "activate", ":", "\n", "            ", "if", "bias", ":", "\n", "                ", "layers", ".", "append", "(", "FusedLeakyReLU", "(", "out_channel", ")", ")", "\n", "\n", "", "else", ":", "\n", "                ", "layers", ".", "append", "(", "ScaledLeakyReLU", "(", "0.2", ")", ")", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ResBlock.__init__": [[660, 668], ["torch.nn.Module.__init__", "generator.ConvLayer", "generator.ConvLayer", "generator.ConvLayer"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channel", ",", "out_channel", ",", "blur_kernel", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "ConvLayer", "(", "in_channel", ",", "in_channel", ",", "3", ")", "\n", "self", ".", "conv2", "=", "ConvLayer", "(", "in_channel", ",", "out_channel", ",", "3", ",", "downsample", "=", "True", ")", "\n", "\n", "self", ".", "skip", "=", "ConvLayer", "(", "\n", "in_channel", ",", "out_channel", ",", "1", ",", "downsample", "=", "True", ",", "activate", "=", "False", ",", "bias", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ResBlock.forward": [[670, 678], ["generator.ResBlock.conv1", "generator.ResBlock.conv2", "generator.ResBlock.skip", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "input", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "skip", "=", "self", ".", "skip", "(", "input", ")", "\n", "out", "=", "(", "out", "+", "skip", ")", "/", "math", ".", "sqrt", "(", "2", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.ModulateGenerator.__init__": [[680, 682], ["generator.StyleGAN2Generator.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ModulateGenerator", ",", "self", ")", ".", "__init__", "(", "opt", ",", "style_dim", "=", "opt", ".", "style_dim", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.fused_leaky_relu": [[9, 11], ["torch.nn.functional.leaky_relu"], "function", ["None"], ["def", "fused_leaky_relu", "(", "input", ",", "bias", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "2", "**", "0.5", ")", ":", "\n", "    ", "return", "F", ".", "leaky_relu", "(", "input", "+", "bias", ",", "negative_slope", ")", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d_native": [[29, 64], ["input.view", "torch.nn.functional.pad", "out.reshape.view", "torch.nn.functional.pad", "out.reshape.reshape", "torch.flip().view", "torch.nn.functional.conv2d", "out.reshape.reshape", "max", "max", "max", "max", "torch.flip", "max", "max", "max", "max"], "function", ["None"], ["", "", "def", "upfirdn2d_native", "(", "\n", "input", ",", "kernel", ",", "up_x", ",", "up_y", ",", "down_x", ",", "down_y", ",", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "\n", ")", ":", "\n", "    ", "_", ",", "minor", ",", "in_h", ",", "in_w", "=", "input", ".", "shape", "\n", "kernel_h", ",", "kernel_w", "=", "kernel", ".", "shape", "\n", "\n", "out", "=", "input", ".", "view", "(", "-", "1", ",", "minor", ",", "in_h", ",", "1", ",", "in_w", ",", "1", ")", "\n", "out", "=", "F", ".", "pad", "(", "out", ",", "[", "0", ",", "up_x", "-", "1", ",", "0", ",", "0", ",", "0", ",", "up_y", "-", "1", ",", "0", ",", "0", "]", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "minor", ",", "in_h", "*", "up_y", ",", "in_w", "*", "up_x", ")", "\n", "\n", "out", "=", "F", ".", "pad", "(", "\n", "out", ",", "[", "max", "(", "pad_x0", ",", "0", ")", ",", "max", "(", "pad_x1", ",", "0", ")", ",", "max", "(", "pad_y0", ",", "0", ")", ",", "max", "(", "pad_y1", ",", "0", ")", "]", "\n", ")", "\n", "out", "=", "out", "[", "\n", ":", ",", "\n", ":", ",", "\n", "max", "(", "-", "pad_y0", ",", "0", ")", ":", "out", ".", "shape", "[", "2", "]", "-", "max", "(", "-", "pad_y1", ",", "0", ")", ",", "\n", "max", "(", "-", "pad_x0", ",", "0", ")", ":", "out", ".", "shape", "[", "3", "]", "-", "max", "(", "-", "pad_x1", ",", "0", ")", ",", "\n", "]", "\n", "\n", "# out = out.permute(0, 3, 1, 2)", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "[", "-", "1", ",", "1", ",", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", ",", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "]", "\n", ")", "\n", "w", "=", "torch", ".", "flip", "(", "kernel", ",", "[", "0", ",", "1", "]", ")", ".", "view", "(", "1", ",", "1", ",", "kernel_h", ",", "kernel_w", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "out", ",", "w", ")", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "-", "1", ",", "\n", "minor", ",", "\n", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", "-", "kernel_h", "+", "1", ",", "\n", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "-", "kernel_w", "+", "1", ",", "\n", ")", "\n", "# out = out.permute(0, 2, 3, 1)", "\n", "\n", "return", "out", "[", ":", ",", ":", ",", ":", ":", "down_y", ",", ":", ":", "down_x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d": [[66, 68], ["generator.upfirdn2d_native"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.upfirdn2d_native"], ["", "def", "upfirdn2d", "(", "input", ",", "kernel", ",", "up", "=", "1", ",", "down", "=", "1", ",", "pad", "=", "(", "0", ",", "0", ")", ")", ":", "\n", "    ", "return", "upfirdn2d_native", "(", "input", ",", "kernel", ",", "up", ",", "up", ",", "down", ",", "down", ",", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ",", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.generator.make_kernel": [[78, 87], ["torch.tensor", "torch.tensor.sum"], "function", ["None"], ["", "", "def", "make_kernel", "(", "k", ")", ":", "\n", "    ", "k", "=", "torch", ".", "tensor", "(", "k", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "if", "k", ".", "ndim", "==", "1", ":", "\n", "        ", "k", "=", "k", "[", "None", ",", ":", "]", "*", "k", "[", ":", ",", "None", "]", "\n", "\n", "", "k", "/=", "k", ".", "sum", "(", ")", "\n", "\n", "return", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.modify_commandline_options": [[9, 12], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.print_network": [[13, 22], ["isinstance", "base_network.BaseNetwork.parameters", "print", "param.numel", "type"], "methods", ["None"], ["", "def", "print_network", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "list", ")", ":", "\n", "            ", "self", "=", "self", "[", "0", "]", "\n", "", "num_params", "=", "0", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "print", "(", "'Network [%s] was created. Total number of parameters: %.1f million. '", "\n", "'To see the architecture, do print(network).'", "\n", "%", "(", "type", "(", "self", ")", ".", "__name__", ",", "num_params", "/", "1000000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.init_weights": [[23, 55], ["base_network.BaseNetwork.apply", "base_network.BaseNetwork.children", "hasattr", "classname.find", "m.init_weights", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "hasattr", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_uniform_", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "m.reset_parameters", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.init_weights", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters"], ["", "def", "init_weights", "(", "self", ",", "init_type", "=", "'normal'", ",", "gain", "=", "0.02", ")", ":", "\n", "        ", "def", "init_func", "(", "m", ")", ":", "\n", "            ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "                ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                    ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "gain", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "                ", "if", "init_type", "==", "'normal'", ":", "\n", "                    ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                    ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "elif", "init_type", "==", "'xavier_uniform'", ":", "\n", "                    ", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "1.0", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                    ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                    ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "gain", ")", "\n", "", "elif", "init_type", "==", "'none'", ":", "# uses pytorch's default init method", "\n", "                    ", "m", ".", "reset_parameters", "(", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "", "self", ".", "apply", "(", "init_func", ")", "\n", "\n", "# propagate to children", "\n", "for", "m", "in", "self", ".", "children", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'init_weights'", ")", ":", "\n", "                ", "m", ".", "init_weights", "(", "init_type", ",", "gain", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name": [[10, 19], ["util.find_class_in_module", "issubclass"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.find_class_in_module"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.modify_commandline_options": [[21, 34], ["netD_cls.modify_commandline_options.parse_known_args", "__init__.find_network_using_name", "find_network_using_name.modify_commandline_options", "__init__.find_network_using_name", "find_network_using_name.modify_commandline_options", "__init__.find_network_using_name", "find_network_using_name.modify_commandline_options"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network": [[36, 44], ["cls", "cls.print_network", "cls.init_weights", "len", "torch.cuda.is_available", "cls.cuda"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.print_network", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.base_network.BaseNetwork.init_weights"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_networks": [[46, 49], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_G": [[50, 53], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_D": [[55, 58], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_A": [[59, 62], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_A_sync": [[63, 66], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_E": [[68, 72], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_V": [[74, 78], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_P": [[80, 83], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.define_F_rec": [[85, 88], ["__init__.find_network_using_name", "__init__.create_network"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.find_network_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.__init__.create_network"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.P2sRt": [[9, 28], ["numpy.cross", "numpy.concatenate", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["import", "dill", "as", "pickle", "\n", "import", "skimage", ".", "transform", "as", "trans", "\n", "import", "cv2", "\n", "\n", "\n", "def", "save_obj", "(", "obj", ",", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "\n", "", "", "def", "load_obj", "(", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "# returns a configuration for creating a generator", "\n", "# |default_opt| should be the opt of the current experiment", "\n", "# |**kwargs|: if any configuration should be overriden, it can be specified here", "\n", "\n", "\n", "", "", "def", "copyconf", "(", "default_opt", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.matrix2angle": [[29, 55], ["atan2", "atan2", "asin", "max", "cos", "cos", "cos", "cos", "atan2", "atan2", "min"], "function", ["None"], ["    ", "conf", "=", "argparse", ".", "Namespace", "(", "**", "vars", "(", "default_opt", ")", ")", "\n", "for", "key", "in", "kwargs", ":", "\n", "        ", "print", "(", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "setattr", "(", "conf", ",", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "", "return", "conf", "\n", "\n", "\n", "", "def", "tile_images", "(", "imgs", ",", "picturesPerRow", "=", "4", ")", ":", "\n", "    ", "\"\"\" Code borrowed from\n    https://stackoverflow.com/questions/26521365/cleanly-tile-numpy-array-of-images-stored-in-a-flattened-1d-format/26521997\n    \"\"\"", "\n", "\n", "# Padding", "\n", "if", "imgs", ".", "shape", "[", "0", "]", "%", "picturesPerRow", "==", "0", ":", "\n", "        ", "rowPadding", "=", "0", "\n", "", "else", ":", "\n", "        ", "rowPadding", "=", "picturesPerRow", "-", "imgs", ".", "shape", "[", "0", "]", "%", "picturesPerRow", "\n", "", "if", "rowPadding", ">", "0", ":", "\n", "        ", "imgs", "=", "np", ".", "concatenate", "(", "[", "imgs", ",", "np", ".", "zeros", "(", "(", "rowPadding", ",", "*", "imgs", ".", "shape", "[", "1", ":", "]", ")", ",", "dtype", "=", "imgs", ".", "dtype", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "# Tiling Loop (The conditionals are not necessary anymore)", "\n", "", "tiled", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "imgs", ".", "shape", "[", "0", "]", ",", "picturesPerRow", ")", ":", "\n", "        ", "tiled", ".", "append", "(", "np", ".", "concatenate", "(", "[", "imgs", "[", "j", "]", "for", "j", "in", "range", "(", "i", ",", "i", "+", "picturesPerRow", ")", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "tiled", "=", "np", ".", "concatenate", "(", "tiled", ",", "axis", "=", "0", ")", "\n", "return", "tiled", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.angle2matrix": [[56, 84], ["numpy.array", "numpy.array", "numpy.array", "np.array.dot().dot", "Rz.dot().dot.astype", "np.array.dot", "cos", "sin", "cos", "cos", "sin", "cos", "cos", "sin", "cos", "sin", "sin", "sin"], "function", ["None"], ["\n", "\n", "# Converts a Tensor into a Numpy array", "\n", "# |imtype|: the desired type of the converted numpy array", "\n", "", "def", "tensor2im", "(", "image_tensor", ",", "imtype", "=", "np", ".", "uint8", ",", "normalize", "=", "True", ",", "tile", "=", "True", ")", ":", "\n", "    ", "if", "isinstance", "(", "image_tensor", ",", "list", ")", ":", "\n", "        ", "image_numpy", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "image_tensor", ")", ")", ":", "\n", "            ", "image_numpy", ".", "append", "(", "tensor2im", "(", "image_tensor", "[", "i", "]", ",", "imtype", ",", "normalize", ")", ")", "\n", "", "return", "image_numpy", "\n", "\n", "", "if", "image_tensor", ".", "dim", "(", ")", "==", "4", ":", "\n", "# transform each image in the batch", "\n", "        ", "images_np", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "image_tensor", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "one_image", "=", "image_tensor", "[", "b", "]", "\n", "one_image_np", "=", "tensor2im", "(", "one_image", ")", "\n", "images_np", ".", "append", "(", "one_image_np", ".", "reshape", "(", "1", ",", "*", "one_image_np", ".", "shape", ")", ")", "\n", "", "images_np", "=", "np", ".", "concatenate", "(", "images_np", ",", "axis", "=", "0", ")", "\n", "if", "tile", ":", "\n", "            ", "images_tiled", "=", "tile_images", "(", "images_np", ")", "\n", "return", "images_tiled", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "images_np", ".", "shape", ")", "==", "4", "and", "images_np", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                ", "images_np", "=", "images_np", "[", "0", "]", "\n", "", "return", "images_np", "\n", "\n", "", "", "if", "image_tensor", ".", "dim", "(", ")", "==", "2", ":", "\n", "        ", "image_tensor", "=", "image_tensor", ".", "unsqueeze", "(", "0", ")", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.tensor2im": [[85, 104], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].cpu().float().numpy", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["", "image_numpy", "=", "image_tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "if", "normalize", ":", "\n", "        ", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "\n", "", "else", ":", "\n", "        ", "image_numpy", "=", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "*", "255.0", "\n", "", "image_numpy", "=", "np", ".", "clip", "(", "image_numpy", ",", "0", ",", "255", ")", "\n", "if", "image_numpy", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "image_numpy", "=", "image_numpy", "[", ":", ",", ":", ",", "0", "]", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n", "\n", "\n", "", "def", "save_image", "(", "image_numpy", ",", "image_path", ",", "create_dir", "=", "False", ")", ":", "\n", "    ", "if", "create_dir", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "image_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "len", "(", "image_numpy", ".", "shape", ")", "==", "4", ":", "\n", "        ", "image_numpy", "=", "image_numpy", "[", "0", "]", "\n", "", "if", "len", "(", "image_numpy", ".", "shape", ")", "==", "2", ":", "\n", "        ", "image_numpy", "=", "np", ".", "expand_dims", "(", "image_numpy", ",", "axis", "=", "2", ")", "\n", "", "if", "image_numpy", ".", "shape", "[", "2", "]", "==", "1", ":", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.diagnose_network": [[106, 123], ["net.parameters", "print", "print", "torch.mean", "torch.abs"], "function", ["None"], ["", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "\n", "# save to png", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "# image_pil.save(image_path.replace('.jpg', '.png'))", "\n", "\n", "\n", "", "def", "save_torch_img", "(", "img", ",", "save_path", ")", ":", "\n", "    ", "image_numpy", "=", "tensor2im", "(", "img", ",", "tile", "=", "False", ")", "\n", "save_image", "(", "image_numpy", ",", "save_path", ",", "create_dir", "=", "True", ")", "\n", "return", "image_numpy", "\n", "\n", "\n", "\n", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.save_image": [[125, 134], ["PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.models.av_model.AvModel.save"], ["        ", "mkdir", "(", "paths", ")", "\n", "\n", "\n", "", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n", "\n", "", "", "def", "atoi", "(", "text", ")", ":", "\n", "    ", "return", "int", "(", "text", ")", "if", "text", ".", "isdigit", "(", ")", "else", "text", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.print_numpy": [[136, 150], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["\n", "", "def", "natural_keys", "(", "text", ")", ":", "\n", "    ", "'''\n    alist.sort(key=natural_keys) sorts in human order\n    http://nedbatchelder.com/blog/200712/human_sorting.html\n    (See Toothy's implementation in the comments)\n    '''", "\n", "return", "[", "atoi", "(", "c", ")", "for", "c", "in", "re", ".", "split", "(", "'(\\d+)'", ",", "text", ")", "]", "\n", "\n", "\n", "", "def", "natural_sort", "(", "items", ")", ":", "\n", "    ", "items", ".", "sort", "(", "key", "=", "natural_keys", ")", "\n", "\n", "\n", "", "def", "str2bool", "(", "v", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdirs": [[152, 163], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir"], ["        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n", "\n", "", "", "def", "find_class_in_module", "(", "target_cls_name", ",", "module", ")", ":", "\n", "    ", "target_cls_name", "=", "target_cls_name", ".", "replace", "(", "'_'", ",", "''", ")", ".", "lower", "(", ")", "\n", "clslib", "=", "importlib", ".", "import_module", "(", "module", ")", "\n", "cls", "=", "None", "\n", "for", "name", ",", "clsobj", "in", "clslib", ".", "__dict__", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdir": [[165, 173], ["os.path.exists", "os.makedirs"], "function", ["None"], ["            ", "cls", "=", "clsobj", "\n", "\n", "", "", "if", "cls", "is", "None", ":", "\n", "        ", "print", "(", "\"In %s, there should be a class whose name matches %s in lowercase without underscore(_)\"", "%", "(", "module", ",", "target_cls_name", ")", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "cls", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.__init__": [[14, 21], ["models.networks.base_network.BaseNetwork.__init__", "torchvision.models.resnet.ResNet", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ResNeXt50", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "groups", "=", "32", ",", "width_per_group", "=", "4", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "# self.reduced_id_dim = opt.reduced_id_dim", "\n", "self", ".", "conv1x1", "=", "nn", ".", "Conv2d", "(", "512", "*", "Bottleneck", ".", "expansion", ",", "512", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "Bottleneck", ".", "expansion", ",", "opt", ".", "num_classes", ")", "\n", "# self.fc_pre = nn.Sequential(nn.Linear(512 * Bottleneck.expansion, self.reduced_id_dim), nn.ReLU())", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.load_pretrain": [[24, 27], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "util.util.util.copy_state_dict"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.copy_state_dict"], ["", "def", "load_pretrain", "(", "self", ")", ":", "\n", "        ", "check_point", "=", "torch", ".", "load", "(", "model_urls", "[", "'resnext50_32x4d'", "]", ")", "\n", "util", ".", "copy_state_dict", "(", "check_point", ",", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature": [[28, 43], ["vision_network.ResNeXt50.model.conv1", "vision_network.ResNeXt50.model.bn1", "vision_network.ResNeXt50.model.relu", "vision_network.ResNeXt50.model.maxpool", "vision_network.ResNeXt50.model.layer1", "vision_network.ResNeXt50.model.layer2", "vision_network.ResNeXt50.model.layer3", "vision_network.ResNeXt50.model.layer4", "vision_network.ResNeXt50.model.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "vision_network.ResNeXt50.conv1x1"], "methods", ["None"], ["", "def", "forward_feature", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", ".", "conv1", "(", "input", ")", "\n", "x", "=", "self", ".", "model", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "model", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "model", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "model", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "model", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "model", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "model", ".", "layer4", "(", "x", ")", "\n", "net", "=", "self", ".", "model", ".", "avgpool", "(", "x", ")", "\n", "net", "=", "torch", ".", "flatten", "(", "net", ",", "1", ")", "\n", "x", "=", "self", ".", "conv1x1", "(", "x", ")", "\n", "# x = self.fc_pre(x)", "\n", "return", "net", ",", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward": [[44, 55], ["input.view", "vision_network.ResNeXt50.forward_feature", "torch.mean.view", "torch.mean.view", "torch.mean.view", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.mean.view", "torch.mean.view", "torch.mean.view", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "vision_network.ResNeXt50.fc"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.vision_network.ResNeXt50.forward_feature"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "input_batch", "=", "input", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "output_nc", ",", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", "\n", "net", ",", "x", "=", "self", ".", "forward_feature", "(", "input_batch", ")", "\n", "net", "=", "net", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "num_inputs", ",", "512", "*", "Bottleneck", ".", "expansion", ")", "\n", "x", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "(", "7", ",", "7", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "opt", ".", "num_inputs", ",", "512", ",", "7", ",", "7", ")", "\n", "net", "=", "torch", ".", "mean", "(", "net", ",", "1", ")", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "1", ")", "\n", "cls_scores", "=", "self", ".", "fc", "(", "net", ")", "\n", "\n", "return", "[", "net", ",", "x", "]", ",", "cls_scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.__init__": [[55, 75], ["torch.nn.parallel.data_parallel.DataParallel.__init__", "torch.cuda.is_available", "list", "len", "replicate.DataParallelWithCallback.module.cuda", "range", "torch.cuda.device_count"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["def", "__init__", "(", "self", ",", "module", ",", "device_ids", "=", "None", ",", "output_device", "=", "None", ",", "dim", "=", "0", ",", "chunk_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "DataParallelWithCallback", ",", "self", ")", ".", "__init__", "(", "module", ")", "\n", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "module", "=", "module", "\n", "self", ".", "device_ids", "=", "[", "]", "\n", "return", "\n", "\n", "", "if", "device_ids", "is", "None", ":", "\n", "            ", "device_ids", "=", "list", "(", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ")", "\n", "", "if", "output_device", "is", "None", ":", "\n", "            ", "output_device", "=", "device_ids", "[", "0", "]", "\n", "", "self", ".", "dim", "=", "dim", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "self", ".", "output_device", "=", "output_device", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n", "if", "len", "(", "self", ".", "device_ids", ")", "==", "1", ":", "\n", "            ", "self", ".", "module", ".", "cuda", "(", "device_ids", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.forward": [[76, 85], ["replicate.DataParallelWithCallback.scatter", "replicate.DataParallelWithCallback.replicate", "replicate.DataParallelWithCallback.parallel_apply", "replicate.DataParallelWithCallback.gather", "replicate.DataParallelWithCallback.module", "len", "replicate.DataParallelWithCallback.module", "len"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.replicate"], ["", "", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "device_ids", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "inputs", ",", "kwargs", "=", "self", ".", "scatter", "(", "inputs", ",", "kwargs", ",", "self", ".", "device_ids", ",", "self", ".", "chunk_size", ")", "\n", "if", "len", "(", "self", ".", "device_ids", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", "[", "0", "]", ",", "**", "kwargs", "[", "0", "]", ")", "\n", "", "replicas", "=", "self", ".", "replicate", "(", "self", ".", "module", ",", "self", ".", "device_ids", "[", ":", "len", "(", "inputs", ")", "]", ")", "\n", "outputs", "=", "self", ".", "parallel_apply", "(", "replicas", ",", "inputs", ",", "kwargs", ")", "\n", "return", "self", ".", "gather", "(", "outputs", ",", "self", ".", "output_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.scatter": [[86, 88], ["scatter_gather.scatter_kwargs"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter_kwargs"], ["", "def", "scatter", "(", "self", ",", "inputs", ",", "kwargs", ",", "device_ids", ",", "chunk_size", ")", ":", "\n", "        ", "return", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "device_ids", ",", "dim", "=", "self", ".", "dim", ",", "chunk_size", "=", "self", ".", "chunk_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.replicate": [[89, 93], ["super().replicate", "replicate.execute_replication_callbacks"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.DataParallelWithCallback.replicate", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.execute_replication_callbacks"], ["", "def", "replicate", "(", "self", ",", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "super", "(", "DataParallelWithCallback", ",", "self", ")", ".", "replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.execute_replication_callbacks": [[19, 40], ["len", "enumerate", "list", "replicate.CallbackContext", "enumerate", "master_copy.modules", "range", "module.modules", "hasattr", "m.__data_parallel_replicate__"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__"], ["", "def", "execute_replication_callbacks", "(", "modules", ")", ":", "\n", "    ", "\"\"\"\n    Execute an replication callback `__data_parallel_replicate__` on each module created by original replication.\n\n    The callback will be invoked with arguments `__data_parallel_replicate__(ctx, copy_id)`\n\n    Note that, as all modules are isomorphism, we assign each sub-module with a context\n    (shared among multiple copies of this module on different devices).\n    Through this context, different copies can share some information.\n\n    We guarantee that the callback on the master copy (the first copy) will be called ahead of calling the callback\n    of any slave copies.\n    \"\"\"", "\n", "master_copy", "=", "modules", "[", "0", "]", "\n", "nr_modules", "=", "len", "(", "list", "(", "master_copy", ".", "modules", "(", ")", ")", ")", "\n", "ctxs", "=", "[", "CallbackContext", "(", ")", "for", "_", "in", "range", "(", "nr_modules", ")", "]", "\n", "\n", "for", "i", ",", "module", "in", "enumerate", "(", "modules", ")", ":", "\n", "        ", "for", "j", ",", "m", "in", "enumerate", "(", "module", ".", "modules", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'__data_parallel_replicate__'", ")", ":", "\n", "                ", "m", ".", "__data_parallel_replicate__", "(", "ctxs", "[", "j", "]", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.patch_replication_callback": [[96, 121], ["isinstance", "functools.wraps", "old_replicate", "replicate.execute_replication_callbacks"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.replicate.execute_replication_callbacks"], ["", "", "def", "patch_replication_callback", "(", "data_parallel", ")", ":", "\n", "    ", "\"\"\"\n    Monkey-patch an existing `DataParallel` object. Add the replication callback.\n    Useful when you have customized `DataParallel` implementation.\n\n    Examples:\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallel(sync_bn, device_ids=[0, 1])\n        > patch_replication_callback(sync_bn)\n        # this is equivalent to\n        > sync_bn = SynchronizedBatchNorm1d(10, eps=1e-5, affine=False)\n        > sync_bn = DataParallelWithCallback(sync_bn, device_ids=[0, 1])\n    \"\"\"", "\n", "\n", "assert", "isinstance", "(", "data_parallel", ",", "DataParallel", ")", "\n", "\n", "old_replicate", "=", "data_parallel", ".", "replicate", "\n", "\n", "@", "functools", ".", "wraps", "(", "old_replicate", ")", "\n", "def", "new_replicate", "(", "module", ",", "device_ids", ")", ":", "\n", "        ", "modules", "=", "old_replicate", "(", "module", ",", "device_ids", ")", "\n", "execute_replication_callbacks", "(", "modules", ")", "\n", "return", "modules", "\n", "\n", "", "data_parallel", ".", "replicate", "=", "new_replicate", "\n", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.__init__": [[11, 15], ["threading.Lock", "threading.Condition"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_result", "=", "None", "\n", "self", ".", "_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "_cond", "=", "threading", ".", "Condition", "(", "self", ".", "_lock", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.put": [[16, 21], ["comm.FutureResult._cond.notify"], "methods", ["None"], ["", "def", "put", "(", "self", ",", "result", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "assert", "self", ".", "_result", "is", "None", ",", "'Previous result has\\'t been fetched.'", "\n", "self", ".", "_result", "=", "result", "\n", "self", ".", "_cond", ".", "notify", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.get": [[22, 30], ["comm.FutureResult._cond.wait"], "methods", ["None"], ["", "", "def", "get", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "_lock", ":", "\n", "            ", "if", "self", ".", "_result", "is", "None", ":", "\n", "                ", "self", ".", "_cond", ".", "wait", "(", ")", "\n", "\n", "", "res", "=", "self", ".", "_result", "\n", "self", ".", "_result", "=", "None", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SlavePipe.run_slave": [[39, 44], ["comm.SlavePipe.queue.put", "comm.SlavePipe.result.get", "comm.SlavePipe.queue.put"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.put"], ["def", "run_slave", "(", "self", ",", "msg", ")", ":", "\n", "        ", "self", ".", "queue", ".", "put", "(", "(", "self", ".", "identifier", ",", "msg", ")", ")", "\n", "ret", "=", "self", ".", "result", ".", "get", "(", ")", "\n", "self", ".", "queue", ".", "put", "(", "True", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.__init__": [[57, 67], ["queue.Queue", "collections.OrderedDict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "master_callback", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            master_callback: a callback to be invoked after having collected messages from slave devices.\n        \"\"\"", "\n", "self", ".", "_master_callback", "=", "master_callback", "\n", "self", ".", "_queue", "=", "queue", ".", "Queue", "(", ")", "\n", "self", ".", "_registry", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "_activated", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.__getstate__": [[68, 70], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "{", "'master_callback'", ":", "self", ".", "_master_callback", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.__setstate__": [[71, 73], ["comm.SyncMaster.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "self", ".", "__init__", "(", "state", "[", "'master_callback'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.register_slave": [[74, 91], ["comm.FutureResult", "_MasterRegistry", "comm.SlavePipe", "comm.SyncMaster._queue.empty", "comm.SyncMaster._registry.clear"], "methods", ["None"], ["", "def", "register_slave", "(", "self", ",", "identifier", ")", ":", "\n", "        ", "\"\"\"\n        Register an slave device.\n\n        Args:\n            identifier: an identifier, usually is the device id.\n\n        Returns: a `SlavePipe` object which can be used to communicate with the master device.\n\n        \"\"\"", "\n", "if", "self", ".", "_activated", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "empty", "(", ")", ",", "'Queue is not clean before next initialization.'", "\n", "self", ".", "_activated", "=", "False", "\n", "self", ".", "_registry", ".", "clear", "(", ")", "\n", "", "future", "=", "FutureResult", "(", ")", "\n", "self", ".", "_registry", "[", "identifier", "]", "=", "_MasterRegistry", "(", "future", ")", "\n", "return", "SlavePipe", "(", "identifier", ",", "self", ".", "_queue", ",", "future", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.run_master": [[92, 124], ["range", "comm.SyncMaster._master_callback", "range", "intermediates.append", "comm.SyncMaster._registry[].result.put", "comm.SyncMaster._queue.get", "comm.SyncMaster._queue.get"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.put", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.get", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.FutureResult.get"], ["", "def", "run_master", "(", "self", ",", "master_msg", ")", ":", "\n", "        ", "\"\"\"\n        Main entry for the master device in each forward pass.\n        The messages were first collected from each devices (including the master device), and then\n        an callback will be invoked to compute the message to be sent back to each devices\n        (including the master device).\n\n        Args:\n            master_msg: the message that the master want to send to itself. This will be placed as the first\n            message when calling `master_callback`. For detailed usage, see `_SynchronizedBatchNorm` for an example.\n\n        Returns: the message to be sent back to the master device.\n\n        \"\"\"", "\n", "self", ".", "_activated", "=", "True", "\n", "\n", "intermediates", "=", "[", "(", "0", ",", "master_msg", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "intermediates", ".", "append", "(", "self", ".", "_queue", ".", "get", "(", ")", ")", "\n", "\n", "", "results", "=", "self", ".", "_master_callback", "(", "intermediates", ")", "\n", "assert", "results", "[", "0", "]", "[", "0", "]", "==", "0", ",", "'The first result should belongs to the master.'", "\n", "\n", "for", "i", ",", "res", "in", "results", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "_registry", "[", "i", "]", ".", "result", ".", "put", "(", "res", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "nr_slaves", ")", ":", "\n", "            ", "assert", "self", ".", "_queue", ".", "get", "(", ")", "is", "True", "\n", "\n", "", "return", "results", "[", "0", "]", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.nr_slaves": [[125, 128], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "nr_slaves", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_registry", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.unittest.TorchTestCase.assertTensorClose": [[6, 19], ["float", "unittest.TorchTestCase.assertTrue", "float", "torch.allclose"], "methods", ["None"], ["    ", "def", "assertTensorClose", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "adiff", "=", "float", "(", "(", "x", "-", "y", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ")", "\n", "if", "(", "y", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "            ", "rdiff", "=", "'NaN'", "\n", "", "else", ":", "\n", "            ", "rdiff", "=", "float", "(", "(", "adiff", "/", "y", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ")", "\n", "\n", "", "message", "=", "(", "\n", "'Tensor close check failed\\n'", "\n", "'adiff={}\\n'", "\n", "'rdiff={}\\n'", "\n", ")", ".", "format", "(", "adiff", ",", "rdiff", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "x", ",", "y", ")", ",", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter": [[5, 32], ["isinstance", "scatter_gather.scatter.scatter_map"], "function", ["None"], ["def", "scatter", "(", "inputs", ",", "target_gpus", ",", "dim", "=", "0", ",", "chunk_size", "=", "None", ")", ":", "\n", "    ", "r\"\"\"\n    Slices tensors into approximately equal chunks and\n    distributes them across given GPUs. Duplicates\n    references to objects that are not tensors.\n    \"\"\"", "\n", "def", "scatter_map", "(", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "Scatter", ".", "apply", "(", "target_gpus", ",", "chunk_size", ",", "dim", ",", "obj", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "tuple", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "list", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "dict", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "type", "(", "obj", ")", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ".", "items", "(", ")", ")", ")", ")", ")", "\n", "", "return", "[", "obj", "for", "targets", "in", "target_gpus", "]", "\n", "\n", "# After scatter_map is called, a scatter_map cell will exist. This cell", "\n", "# has a reference to the actual function scatter_map, which has references", "\n", "# to a closure that has a reference to the scatter_map cell (because the", "\n", "# fn is recursive). To avoid this reference cycle, we set the function to", "\n", "# None, clearing the cell", "\n", "", "try", ":", "\n", "        ", "res", "=", "scatter_map", "(", "inputs", ")", "\n", "", "finally", ":", "\n", "        ", "scatter_map", "=", "None", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter_kwargs": [[34, 45], ["tuple", "tuple", "scatter_gather.scatter", "scatter_gather.scatter", "len", "len", "tuple.extend", "len", "len", "tuple.extend", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.scatter_gather.scatter"], ["", "def", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "target_gpus", ",", "dim", "=", "0", ",", "chunk_size", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Scatter with support for kwargs dictionary\"\"\"", "\n", "inputs", "=", "scatter", "(", "inputs", ",", "target_gpus", ",", "dim", ",", "chunk_size", ")", "if", "inputs", "else", "[", "]", "\n", "kwargs", "=", "scatter", "(", "kwargs", ",", "target_gpus", ",", "dim", ",", "chunk_size", ")", "if", "kwargs", "else", "[", "]", "\n", "if", "len", "(", "inputs", ")", "<", "len", "(", "kwargs", ")", ":", "\n", "        ", "inputs", ".", "extend", "(", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "kwargs", ")", "-", "len", "(", "inputs", ")", ")", "]", ")", "\n", "", "elif", "len", "(", "kwargs", ")", "<", "len", "(", "inputs", ")", ":", "\n", "        ", "kwargs", ".", "extend", "(", "[", "{", "}", "for", "_", "in", "range", "(", "len", "(", "inputs", ")", "-", "len", "(", "kwargs", ")", ")", "]", ")", "\n", "", "inputs", "=", "tuple", "(", "inputs", ")", "\n", "kwargs", "=", "tuple", "(", "kwargs", ")", "\n", "return", "inputs", ",", "kwargs", "\n", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__init__": [[42, 52], ["torch.nn.modules.batchnorm._BatchNorm.__init__", "SyncMaster"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ")", ":", "\n", "        ", "assert", "ReduceAddCoalesced", "is", "not", "None", ",", "'Can not use Synchronized Batch Normalization without CUDA support.'", "\n", "\n", "super", "(", "_SynchronizedBatchNorm", ",", "self", ")", ".", "__init__", "(", "num_features", ",", "eps", "=", "eps", ",", "momentum", "=", "momentum", ",", "affine", "=", "affine", ")", "\n", "\n", "self", ".", "_sync_master", "=", "SyncMaster", "(", "self", ".", "_data_parallel_master", ")", "\n", "\n", "self", ".", "_is_parallel", "=", "False", "\n", "self", ".", "_parallel_id", "=", "None", "\n", "self", ".", "_slave_pipe", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm.forward": [[53, 84], ["input.view.view.size", "input.view.view.view", "batchnorm._sum_ft", "batchnorm._sum_ft", "output.view", "torch.batch_norm", "torch.batch_norm", "input.view.view.size", "input.view.view.size", "input.view.view.size", "batchnorm._SynchronizedBatchNorm._sync_master.run_master", "batchnorm._SynchronizedBatchNorm._slave_pipe.run_slave", "_ChildMessage", "_ChildMessage", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft", "batchnorm._unsqueeze_ft"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._sum_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.run_master", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SlavePipe.run_slave", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# If it is not parallel computation or is in evaluation mode, use PyTorch's implementation.", "\n", "        ", "if", "not", "(", "self", ".", "_is_parallel", "and", "self", ".", "training", ")", ":", "\n", "            ", "return", "F", ".", "batch_norm", "(", "\n", "input", ",", "self", ".", "running_mean", ",", "self", ".", "running_var", ",", "self", ".", "weight", ",", "self", ".", "bias", ",", "\n", "self", ".", "training", ",", "self", ".", "momentum", ",", "self", ".", "eps", ")", "\n", "\n", "# Resize the input to (B, C, -1).", "\n", "", "input_shape", "=", "input", ".", "size", "(", ")", "\n", "input", "=", "input", ".", "view", "(", "input", ".", "size", "(", "0", ")", ",", "self", ".", "num_features", ",", "-", "1", ")", "\n", "\n", "# Compute the sum and square-sum.", "\n", "sum_size", "=", "input", ".", "size", "(", "0", ")", "*", "input", ".", "size", "(", "2", ")", "\n", "input_sum", "=", "_sum_ft", "(", "input", ")", "\n", "input_ssum", "=", "_sum_ft", "(", "input", "**", "2", ")", "\n", "\n", "# Reduce-and-broadcast the statistics.", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_sync_master", ".", "run_master", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "mean", ",", "inv_std", "=", "self", ".", "_slave_pipe", ".", "run_slave", "(", "_ChildMessage", "(", "input_sum", ",", "input_ssum", ",", "sum_size", ")", ")", "\n", "\n", "# Compute the output.", "\n", "", "if", "self", ".", "affine", ":", "\n", "# MJY:: Fuse the multiplication for speed.", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", "*", "self", ".", "weight", ")", "+", "_unsqueeze_ft", "(", "self", ".", "bias", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "(", "input", "-", "_unsqueeze_ft", "(", "mean", ")", ")", "*", "_unsqueeze_ft", "(", "inv_std", ")", "\n", "\n", "# Reshape it.", "\n", "", "return", "output", ".", "view", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm.__data_parallel_replicate__": [[85, 94], ["ctx.sync_master.register_slave"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.comm.SyncMaster.register_slave"], ["", "def", "__data_parallel_replicate__", "(", "self", ",", "ctx", ",", "copy_id", ")", ":", "\n", "        ", "self", ".", "_is_parallel", "=", "True", "\n", "self", ".", "_parallel_id", "=", "copy_id", "\n", "\n", "# parallel_id == 0 means master device.", "\n", "if", "self", ".", "_parallel_id", "==", "0", ":", "\n", "            ", "ctx", ".", "sync_master", "=", "self", ".", "_sync_master", "\n", "", "else", ":", "\n", "            ", "self", ".", "_slave_pipe", "=", "ctx", ".", "sync_master", ".", "register_slave", "(", "copy_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm._data_parallel_master": [[95, 117], ["sorted", "sum", "ReduceAddCoalesced.apply", "batchnorm._SynchronizedBatchNorm._compute_mean_std", "Broadcast.apply", "enumerate", "i[].sum.get_device", "outputs.append", "i[].sum.get_device", "_MasterMessage"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std"], ["", "", "def", "_data_parallel_master", "(", "self", ",", "intermediates", ")", ":", "\n", "        ", "\"\"\"Reduce the sum and square-sum, compute the statistics, and broadcast it.\"\"\"", "\n", "\n", "# Always using same \"device order\" makes the ReduceAdd operation faster.", "\n", "# Thanks to:: Tete Xiao (http://tetexiao.com/)", "\n", "intermediates", "=", "sorted", "(", "intermediates", ",", "key", "=", "lambda", "i", ":", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", ")", "\n", "\n", "to_reduce", "=", "[", "i", "[", "1", "]", "[", ":", "2", "]", "for", "i", "in", "intermediates", "]", "\n", "to_reduce", "=", "[", "j", "for", "i", "in", "to_reduce", "for", "j", "in", "i", "]", "# flatten", "\n", "target_gpus", "=", "[", "i", "[", "1", "]", ".", "sum", ".", "get_device", "(", ")", "for", "i", "in", "intermediates", "]", "\n", "\n", "sum_size", "=", "sum", "(", "[", "i", "[", "1", "]", ".", "sum_size", "for", "i", "in", "intermediates", "]", ")", "\n", "sum_", ",", "ssum", "=", "ReduceAddCoalesced", ".", "apply", "(", "target_gpus", "[", "0", "]", ",", "2", ",", "*", "to_reduce", ")", "\n", "mean", ",", "inv_std", "=", "self", ".", "_compute_mean_std", "(", "sum_", ",", "ssum", ",", "sum_size", ")", "\n", "\n", "broadcasted", "=", "Broadcast", ".", "apply", "(", "target_gpus", ",", "mean", ",", "inv_std", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "for", "i", ",", "rec", "in", "enumerate", "(", "intermediates", ")", ":", "\n", "            ", "outputs", ".", "append", "(", "(", "rec", "[", "0", "]", ",", "_MasterMessage", "(", "*", "broadcasted", "[", "i", "*", "2", ":", "i", "*", "2", "+", "2", "]", ")", ")", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._SynchronizedBatchNorm._compute_mean_std": [[118, 136], ["hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bias_var.clamp"], "methods", ["None"], ["", "def", "_compute_mean_std", "(", "self", ",", "sum_", ",", "ssum", ",", "size", ")", ":", "\n", "        ", "\"\"\"Compute the mean and standard-deviation with sum and square-sum. This method\n        also maintains the moving average on the master device.\"\"\"", "\n", "assert", "size", ">", "1", ",", "'BatchNorm computes unbiased standard-deviation, which requires size > 1.'", "\n", "mean", "=", "sum_", "/", "size", "\n", "sumvar", "=", "ssum", "-", "sum_", "*", "mean", "\n", "unbias_var", "=", "sumvar", "/", "(", "size", "-", "1", ")", "\n", "bias_var", "=", "sumvar", "/", "size", "\n", "\n", "if", "hasattr", "(", "torch", ",", "'no_grad'", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "running_mean", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "+", "self", ".", "momentum", "*", "mean", ".", "data", "\n", "self", ".", "running_var", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "+", "self", ".", "momentum", "*", "unbias_var", ".", "data", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "running_mean", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "+", "self", ".", "momentum", "*", "mean", ".", "data", "\n", "self", ".", "running_var", "=", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "+", "self", ".", "momentum", "*", "unbias_var", ".", "data", "\n", "\n", "", "return", "mean", ",", "bias_var", ".", "clamp", "(", "self", ".", "eps", ")", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm1d._check_input_dim": [[194, 199], ["super()._check_input_dim", "ValueError", "input.dim", "input.dim", "input.dim"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "2", "and", "input", ".", "dim", "(", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 2D or 3D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm1d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm2d._check_input_dim": [[257, 262], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 4D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm2d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim": [[321, 326], ["super()._check_input_dim", "input.dim", "ValueError", "input.dim"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.SynchronizedBatchNorm3d._check_input_dim"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "!=", "5", ":", "\n", "            ", "raise", "ValueError", "(", "'expected 5D input (got {}D input)'", "\n", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "", "super", "(", "SynchronizedBatchNorm3d", ",", "self", ")", ".", "_check_input_dim", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._sum_ft": [[27, 30], ["tensor.sum().sum", "tensor.sum"], "function", ["None"], ["def", "_sum_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"sum over the first and last dimention\"\"\"", "\n", "return", "tensor", ".", "sum", "(", "dim", "=", "0", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm._unsqueeze_ft": [[32, 35], ["tensor.unsqueeze().unsqueeze", "tensor.unsqueeze"], "function", ["None"], ["", "def", "_unsqueeze_ft", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"add new dimensions at the front and the tail\"\"\"", "\n", "return", "tensor", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.patch_sync_batchnorm": [[328, 341], ["None"], "function", ["None"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "patch_sync_batchnorm", "(", ")", ":", "\n", "    ", "import", "torch", ".", "nn", "as", "nn", "\n", "\n", "backup", "=", "nn", ".", "BatchNorm1d", ",", "nn", ".", "BatchNorm2d", ",", "nn", ".", "BatchNorm3d", "\n", "\n", "nn", ".", "BatchNorm1d", "=", "SynchronizedBatchNorm1d", "\n", "nn", ".", "BatchNorm2d", "=", "SynchronizedBatchNorm2d", "\n", "nn", ".", "BatchNorm3d", "=", "SynchronizedBatchNorm3d", "\n", "\n", "yield", "\n", "\n", "nn", ".", "BatchNorm1d", ",", "nn", ".", "BatchNorm2d", ",", "nn", ".", "BatchNorm3d", "=", "backup", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.convert_model": [[343, 385], ["isinstance", "zip", "module.named_children", "batchnorm.convert_model", "DataParallelWithCallback", "isinstance", "sync_module.add_module", "sync_module", "batchnorm.convert_model", "module.weight.data.clone().detach", "module.bias.data.clone().detach", "module.weight.data.clone", "module.bias.data.clone"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.convert_model", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm.convert_model"], ["", "def", "convert_model", "(", "module", ")", ":", "\n", "    ", "\"\"\"Traverse the input module and its child recursively\n       and replace all instance of torch.nn.modules.batchnorm.BatchNorm*N*d\n       to SynchronizedBatchNorm*N*d\n\n    Args:\n        module: the input module needs to be convert to SyncBN model\n\n    Examples:\n        >>> import torch.nn as nn\n        >>> import torchvision\n        >>> # m is a standard pytorch model\n        >>> m = torchvision.models.resnet18(True)\n        >>> m = nn.DataParallel(m)\n        >>> # after convert, m is using SyncBN\n        >>> m = convert_model(m)\n    \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "mod", "=", "module", ".", "module", "\n", "mod", "=", "convert_model", "(", "mod", ")", "\n", "mod", "=", "DataParallelWithCallback", "(", "mod", ")", "\n", "return", "mod", "\n", "\n", "", "mod", "=", "module", "\n", "for", "pth_module", ",", "sync_module", "in", "zip", "(", "[", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm1d", ",", "\n", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm2d", ",", "\n", "torch", ".", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm3d", "]", ",", "\n", "[", "SynchronizedBatchNorm1d", ",", "\n", "SynchronizedBatchNorm2d", ",", "\n", "SynchronizedBatchNorm3d", "]", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "pth_module", ")", ":", "\n", "            ", "mod", "=", "sync_module", "(", "module", ".", "num_features", ",", "module", ".", "eps", ",", "module", ".", "momentum", ",", "module", ".", "affine", ")", "\n", "mod", ".", "running_mean", "=", "module", ".", "running_mean", "\n", "mod", ".", "running_var", "=", "module", ".", "running_var", "\n", "if", "module", ".", "affine", ":", "\n", "                ", "mod", ".", "weight", ".", "data", "=", "module", ".", "weight", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mod", ".", "bias", ".", "data", "=", "module", ".", "bias", ".", "data", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "", "", "for", "name", ",", "child", "in", "module", ".", "named_children", "(", ")", ":", "\n", "        ", "mod", ".", "add_module", "(", "name", ",", "convert_model", "(", "child", ")", ")", "\n", "\n", "", "return", "mod", "\n", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.__init__": [[17, 28], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "batchnorm_reimpl.BatchNorm2dReimpl.register_buffer", "batchnorm_reimpl.BatchNorm2dReimpl.register_buffer", "batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "num_features", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "num_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_var'", ",", "torch", ".", "ones", "(", "num_features", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats": [[29, 32], ["batchnorm_reimpl.BatchNorm2dReimpl.running_mean.zero_", "batchnorm_reimpl.BatchNorm2dReimpl.running_var.fill_"], "methods", ["None"], ["", "def", "reset_running_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "running_mean", ".", "zero_", "(", ")", "\n", "self", ".", "running_var", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_parameters": [[33, 37], ["batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats", "torch.uniform_", "torch.uniform_", "torch.uniform_", "torch.zeros_", "torch.zeros_", "torch.zeros_"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.reset_running_stats"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset_running_stats", "(", ")", "\n", "init", ".", "uniform_", "(", "self", ".", "weight", ")", "\n", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.sync_batchnorm.batchnorm_reimpl.BatchNorm2dReimpl.forward": [[38, 64], ["input_.permute().contiguous().view.permute().contiguous().view.size", "input_.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "input_.permute().contiguous().view.permute().contiguous().view.sum", "input_.permute().contiguous().view.permute().contiguous().view.pow().sum", "output.view().permute().contiguous", "batchnorm_reimpl.BatchNorm2dReimpl.bias.unsqueeze", "input_.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "input_.permute().contiguous().view.permute().contiguous().view.pow", "mean.detach", "unbias_var.detach", "batchnorm_reimpl.BatchNorm2dReimpl.weight.unsqueeze", "output.view().permute", "inv_std.unsqueeze", "input_.permute().contiguous().view.permute().contiguous().view.permute", "mean.unsqueeze", "output.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_", ")", ":", "\n", "        ", "batchsize", ",", "channels", ",", "height", ",", "width", "=", "input_", ".", "size", "(", ")", "\n", "numel", "=", "batchsize", "*", "height", "*", "width", "\n", "input_", "=", "input_", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "channels", ",", "numel", ")", "\n", "sum_", "=", "input_", ".", "sum", "(", "1", ")", "\n", "sum_of_square", "=", "input_", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", "\n", "mean", "=", "sum_", "/", "numel", "\n", "sumvar", "=", "sum_of_square", "-", "sum_", "*", "mean", "\n", "\n", "self", ".", "running_mean", "=", "(", "\n", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_mean", "\n", "+", "self", ".", "momentum", "*", "mean", ".", "detach", "(", ")", "\n", ")", "\n", "unbias_var", "=", "sumvar", "/", "(", "numel", "-", "1", ")", "\n", "self", ".", "running_var", "=", "(", "\n", "(", "1", "-", "self", ".", "momentum", ")", "*", "self", ".", "running_var", "\n", "+", "self", ".", "momentum", "*", "unbias_var", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "bias_var", "=", "sumvar", "/", "numel", "\n", "inv_std", "=", "1", "/", "(", "bias_var", "+", "self", ".", "eps", ")", ".", "pow", "(", "0.5", ")", "\n", "output", "=", "(", "\n", "(", "input_", "-", "mean", ".", "unsqueeze", "(", "1", ")", ")", "*", "inv_std", ".", "unsqueeze", "(", "1", ")", "*", "\n", "self", ".", "weight", ".", "unsqueeze", "(", "1", ")", "+", "self", ".", "bias", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "return", "output", ".", "view", "(", "channels", ",", "batchsize", ",", "height", ",", "width", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.modify_commandline_options": [[16, 21], ["parser.add_argument"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "'--no_pairing_check'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If specified, skip sanity check of correct label-image file pairing'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.cv2_loader": [[22, 25], ["numpy.frombuffer", "cv2.imdecode"], "methods", ["None"], ["", "def", "cv2_loader", "(", "self", ",", "img_str", ")", ":", "\n", "        ", "img_array", "=", "np", ".", "frombuffer", "(", "img_str", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "return", "cv2", ".", "imdecode", "(", "img_array", ",", "cv2", ".", "IMREAD_COLOR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_img": [[26, 43], ["cv2.imread", "cv2.cvtColor", "Exception", "cv2.warpAffine", "cv2.resize"], "methods", ["None"], ["", "def", "load_img", "(", "self", ",", "image_path", ",", "M", "=", "None", ",", "crop", "=", "True", ",", "crop_len", "=", "16", ")", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "\n", "if", "img", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "'None Image'", ")", "\n", "\n", "", "if", "M", "is", "not", "None", ":", "\n", "            ", "img", "=", "cv2", ".", "warpAffine", "(", "img", ",", "M", ",", "(", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", ",", "borderMode", "=", "cv2", ".", "BORDER_REPLICATE", ")", "\n", "\n", "", "if", "crop", ":", "\n", "            ", "img", "=", "img", "[", ":", "self", ".", "opt", ".", "crop_size", "-", "crop_len", "*", "2", ",", "crop_len", ":", "self", ".", "opt", ".", "crop_size", "-", "crop_len", "]", "\n", "if", "self", ".", "opt", ".", "target_crop_len", ">", "0", ":", "\n", "                ", "img", "=", "img", "[", "self", ".", "opt", ".", "target_crop_len", ":", "self", ".", "opt", ".", "crop_size", "-", "self", ".", "opt", ".", "target_crop_len", ",", "self", ".", "opt", ".", "target_crop_len", ":", "self", ".", "opt", ".", "crop_size", "-", "self", ".", "opt", ".", "target_crop_len", "]", "\n", "", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "self", ".", "opt", ".", "crop_size", ",", "self", ".", "opt", ".", "crop_size", ")", ")", "\n", "\n", "", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.fill_list": [[44, 50], ["len", "math.ceil"], "methods", ["None"], ["", "def", "fill_list", "(", "self", ",", "tmp_list", ")", ":", "\n", "        ", "length", "=", "len", "(", "tmp_list", ")", "\n", "if", "length", "%", "self", ".", "opt", ".", "batchSize", "!=", "0", ":", "\n", "            ", "end", "=", "math", ".", "ceil", "(", "length", "/", "self", ".", "opt", ".", "batchSize", ")", "*", "self", ".", "opt", ".", "batchSize", "\n", "tmp_list", "=", "tmp_list", "+", "tmp_list", "[", "-", "1", "*", "(", "end", "-", "length", ")", ":", "]", "\n", "", "return", "tmp_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.frame2audio_indexs": [[51, 56], ["None"], "methods", ["None"], ["", "def", "frame2audio_indexs", "(", "self", ",", "frame_inds", ")", ":", "\n", "        ", "start_frame_ind", "=", "frame_inds", "-", "self", ".", "audio", ".", "num_frames_per_clip", "//", "2", "\n", "\n", "start_audio_inds", "=", "start_frame_ind", "*", "self", ".", "audio", ".", "num_bins_per_frame", "\n", "return", "start_audio_inds", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.initialize": [[57, 129], ["config.AudioConfig.AudioConfig", "opt.path_label.split", "os.path.join", "os.path.isdir", "int", "numpy.arange", "voxtest_dataset.VOXTestDataset.frame2audio_indexs", "len", "random.shuffle", "min", "enumerate", "torch.stack", "len", "os.path.isdir", "pose_frame_path.split", "str", "str", "str", "os.path.exists", "os.makedirs", "os.path.isfile", "voxtest_dataset.VOXTestDataset.audio.read_audio", "voxtest_dataset.VOXTestDataset.audio.audio_to_spectrogram", "numpy.load", "glob.glob", "glob.glob", "len", "voxtest_dataset.VOXTestDataset.to_Tensor", "shutil.copyfile", "opt.path_label.split", "id_path.split", "[].split", "os.path.join", "os.path.join", "voxtest_dataset.VOXTestDataset.load_img", "os.path.join", "os.path.basename", "len", "audio_path.split"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.frame2audio_indexs", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.read_audio", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.config.AudioConfig.AudioConfig.audio_to_spectrogram", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.to_Tensor", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_img"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "path_label", "=", "opt", ".", "path_label", "\n", "self", ".", "clip_len", "=", "opt", ".", "clip_len", "\n", "self", ".", "frame_interval", "=", "opt", ".", "frame_interval", "\n", "self", ".", "num_clips", "=", "opt", ".", "num_clips", "\n", "self", ".", "frame_rate", "=", "opt", ".", "frame_rate", "\n", "self", ".", "num_inputs", "=", "opt", ".", "num_inputs", "\n", "self", ".", "filename_tmpl", "=", "opt", ".", "filename_tmpl", "\n", "\n", "self", ".", "mouth_num_frames", "=", "None", "\n", "self", ".", "mouth_frame_path", "=", "None", "\n", "self", ".", "pose_num_frames", "=", "None", "\n", "\n", "self", ".", "audio", "=", "AudioConfig", ".", "AudioConfig", "(", "num_frames_per_clip", "=", "opt", ".", "num_frames_per_clip", ",", "hop_size", "=", "opt", ".", "hop_size", ")", "\n", "self", ".", "num_audio_bins", "=", "self", ".", "audio", ".", "num_frames_per_clip", "*", "self", ".", "audio", ".", "num_bins_per_frame", "\n", "\n", "\n", "assert", "len", "(", "opt", ".", "path_label", ".", "split", "(", ")", ")", "==", "8", ",", "opt", ".", "path_label", "\n", "id_path", ",", "ref_num", ",", "pose_frame_path", ",", "pose_num_frames", ",", "audio_path", ",", "mouth_frame_path", ",", "mouth_num_frames", ",", "spectrogram_path", "=", "opt", ".", "path_label", ".", "split", "(", ")", "\n", "\n", "\n", "id_idx", ",", "mouth_idx", "=", "id_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ",", "audio_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "pose_frame_path", ")", ":", "\n", "            ", "pose_frame_path", "=", "id_path", "\n", "pose_num_frames", "=", "1", "\n", "\n", "", "pose_idx", "=", "pose_frame_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "id_idx", ",", "pose_idx", ",", "mouth_idx", "=", "str", "(", "id_idx", ")", ",", "str", "(", "pose_idx", ")", ",", "str", "(", "mouth_idx", ")", "\n", "\n", "self", ".", "processed_file_savepath", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "'id_'", "+", "id_idx", "+", "'_pose_'", "+", "pose_idx", "+", "\n", "'_audio_'", "+", "os", ".", "path", ".", "basename", "(", "audio_path", ")", "[", ":", "-", "4", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "processed_file_savepath", ")", ":", "os", ".", "makedirs", "(", "self", ".", "processed_file_savepath", ")", "\n", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "spectrogram_path", ")", ":", "\n", "            ", "wav", "=", "self", ".", "audio", ".", "read_audio", "(", "audio_path", ")", "\n", "self", ".", "spectrogram", "=", "self", ".", "audio", ".", "audio_to_spectrogram", "(", "wav", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "spectrogram", "=", "np", ".", "load", "(", "spectrogram_path", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "mouth_frame_path", ")", ":", "\n", "            ", "self", ".", "mouth_frame_path", "=", "mouth_frame_path", "\n", "self", ".", "mouth_num_frames", "=", "mouth_num_frames", "\n", "\n", "", "self", ".", "pose_num_frames", "=", "int", "(", "pose_num_frames", ")", "\n", "\n", "self", ".", "target_frame_inds", "=", "np", ".", "arange", "(", "2", ",", "len", "(", "self", ".", "spectrogram", ")", "//", "self", ".", "audio", ".", "num_bins_per_frame", "-", "2", ")", "\n", "self", ".", "audio_inds", "=", "self", ".", "frame2audio_indexs", "(", "self", ".", "target_frame_inds", ")", "\n", "\n", "self", ".", "dataset_size", "=", "len", "(", "self", ".", "target_frame_inds", ")", "\n", "\n", "id_img_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "id_path", ",", "'*.jpg'", ")", ")", "+", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "id_path", ",", "'*.png'", ")", ")", "\n", "random", ".", "shuffle", "(", "id_img_paths", ")", "\n", "opt", ".", "num_inputs", "=", "min", "(", "len", "(", "id_img_paths", ")", ",", "opt", ".", "num_inputs", ")", "\n", "id_img_tensors", "=", "[", "]", "\n", "\n", "for", "i", ",", "image_path", "in", "enumerate", "(", "id_img_paths", ")", ":", "\n", "            ", "id_img_tensor", "=", "self", ".", "to_Tensor", "(", "self", ".", "load_img", "(", "image_path", ")", ")", "\n", "id_img_tensors", "+=", "[", "id_img_tensor", "]", "\n", "shutil", ".", "copyfile", "(", "image_path", ",", "os", ".", "path", ".", "join", "(", "self", ".", "processed_file_savepath", ",", "'ref_id_{}.jpg'", ".", "format", "(", "i", ")", ")", ")", "\n", "if", "i", "==", "(", "opt", ".", "num_inputs", "-", "1", ")", ":", "\n", "                ", "break", "\n", "", "", "self", ".", "id_img_tensor", "=", "torch", ".", "stack", "(", "id_img_tensors", ")", "\n", "self", ".", "pose_frame_path", "=", "pose_frame_path", "\n", "self", ".", "audio_path", "=", "audio_path", "\n", "self", ".", "id_path", "=", "id_path", "\n", "self", ".", "mouth_frame_path", "=", "mouth_frame_path", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.paths_match": [[131, 135], ["os.path.splitext", "os.path.splitext", "os.path.basename", "os.path.basename"], "methods", ["None"], ["", "def", "paths_match", "(", "self", ",", "path1", ",", "path2", ")", ":", "\n", "        ", "filename1_without_ext", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path1", ")", "[", "-", "10", ":", "]", ")", "[", "0", "]", "\n", "filename2_without_ext", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path2", ")", "[", "-", "10", ":", "]", ")", "[", "0", "]", "\n", "return", "filename1_without_ext", "==", "filename2_without_ext", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_one_frame": [[136, 141], ["os.path.join", "voxtest_dataset.VOXTestDataset.load_img", "voxtest_dataset.VOXTestDataset.to_Tensor", "voxtest_dataset.VOXTestDataset.filename_tmpl.format"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_img", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.to_Tensor"], ["", "def", "load_one_frame", "(", "self", ",", "frame_ind", ",", "video_path", ",", "M", "=", "None", ",", "crop", "=", "True", ")", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "self", ".", "filename_tmpl", ".", "format", "(", "frame_ind", ")", ")", "\n", "img", "=", "self", ".", "load_img", "(", "filepath", ",", "M", "=", "M", ",", "crop", "=", "crop", ")", "\n", "img", "=", "self", ".", "to_Tensor", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_spectrogram": [[142, 160], ["torch.from_numpy", "numpy.zeros().astype().astype.unsqueeze", "numpy.zeros().astype().astype.transpose", "numpy.array().astype", "print", "numpy.array().astype", "numpy.zeros().astype().astype", "numpy.array", "numpy.array", "numpy.zeros().astype", "numpy.zeros"], "methods", ["None"], ["", "def", "load_spectrogram", "(", "self", ",", "audio_ind", ")", ":", "\n", "        ", "mel_shape", "=", "self", ".", "spectrogram", ".", "shape", "\n", "\n", "if", "(", "audio_ind", "+", "self", ".", "num_audio_bins", ")", "<=", "mel_shape", "[", "0", "]", "and", "audio_ind", ">=", "0", ":", "\n", "            ", "spectrogram", "=", "np", ".", "array", "(", "self", ".", "spectrogram", "[", "audio_ind", ":", "audio_ind", "+", "self", ".", "num_audio_bins", ",", ":", "]", ")", ".", "astype", "(", "'float32'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'(audio_ind {} + opt.num_audio_bins {}) > mel_shape[0] {} '", ".", "format", "(", "audio_ind", ",", "self", ".", "num_audio_bins", ",", "\n", "mel_shape", "[", "0", "]", ")", ")", "\n", "if", "audio_ind", ">", "0", ":", "\n", "                ", "spectrogram", "=", "np", ".", "array", "(", "self", ".", "spectrogram", "[", "audio_ind", ":", "audio_ind", "+", "self", ".", "num_audio_bins", ",", ":", "]", ")", ".", "astype", "(", "'float32'", ")", "\n", "", "else", ":", "\n", "                ", "spectrogram", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_audio_bins", ",", "mel_shape", "[", "1", "]", ")", ")", ".", "astype", "(", "np", ".", "float16", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "", "spectrogram", "=", "torch", ".", "from_numpy", "(", "spectrogram", ")", "\n", "spectrogram", "=", "spectrogram", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "spectrogram", "=", "spectrogram", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", "\n", "return", "spectrogram", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.__getitem__": [[161, 191], ["util.calc_loop_idx", "voxtest_dataset.VOXTestDataset.load_one_frame", "os.path.isdir", "voxtest_dataset.VOXTestDataset.load_spectrogram", "voxtest_dataset.VOXTestDataset.postprocess", "voxtest_dataset.VOXTestDataset.load_one_frame", "torch.zeros_like", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.util.util.calc_loop_idx", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_one_frame", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_spectrogram", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.postprocess", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.load_one_frame"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "img_index", "=", "self", ".", "target_frame_inds", "[", "index", "]", "\n", "mel_index", "=", "self", ".", "audio_inds", "[", "index", "]", "\n", "\n", "pose_index", "=", "util", ".", "calc_loop_idx", "(", "img_index", ",", "self", ".", "pose_num_frames", ")", "\n", "\n", "pose_frame", "=", "self", ".", "load_one_frame", "(", "pose_index", ",", "self", ".", "pose_frame_path", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "self", ".", "mouth_frame_path", ")", ":", "\n", "            ", "mouth_frame", "=", "self", ".", "load_one_frame", "(", "img_index", ",", "self", ".", "mouth_frame_path", ")", "\n", "", "else", ":", "\n", "            ", "mouth_frame", "=", "torch", ".", "zeros_like", "(", "pose_frame", ")", "\n", "\n", "", "spectrograms", "=", "self", ".", "load_spectrogram", "(", "mel_index", ")", "\n", "\n", "input_dict", "=", "{", "\n", "'input'", ":", "self", ".", "id_img_tensor", ",", "\n", "'target'", ":", "mouth_frame", ",", "\n", "'driving_pose_frames'", ":", "pose_frame", ",", "\n", "'augmented'", ":", "pose_frame", ",", "\n", "'label'", ":", "torch", ".", "zeros", "(", "1", ")", ",", "\n", "}", "\n", "if", "self", ".", "opt", ".", "use_audio", ":", "\n", "            ", "input_dict", "[", "'spectrograms'", "]", "=", "spectrograms", "\n", "\n", "# Give subclasses a chance to modify the final output", "\n", "", "self", ".", "postprocess", "(", "input_dict", ")", "\n", "\n", "return", "input_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.postprocess": [[192, 194], ["None"], "methods", ["None"], ["", "def", "postprocess", "(", "self", ",", "input_dict", ")", ":", "\n", "        ", "return", "input_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.__len__": [[195, 197], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.voxtest_dataset.VOXTestDataset.get_processed_file_savepath": [[198, 200], ["None"], "methods", ["None"], ["", "def", "get_processed_file_savepath", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "processed_file_savepath", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.__init__": [[9, 11], ["torch.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.modify_commandline_options": [[12, 15], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.initialize": [[16, 18], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.to_Tensor": [[19, 29], ["torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "img.transpose", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "img.transpose"], "methods", ["None"], ["", "def", "to_Tensor", "(", "self", ",", "img", ")", ":", "\n", "        ", "if", "img", ".", "ndim", "==", "3", ":", "\n", "            ", "wrapped_img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "/", "255.0", "\n", "", "elif", "img", ".", "ndim", "==", "4", ":", "\n", "            ", "wrapped_img", "=", "img", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", "/", "255.0", "\n", "", "else", ":", "\n", "            ", "wrapped_img", "=", "img", "/", "255.0", "\n", "", "wrapped_img", "=", "torch", ".", "from_numpy", "(", "wrapped_img", ")", ".", "float", "(", ")", "\n", "\n", "return", "wrapped_img", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.face_augmentation": [[30, 35], ["base_dataset.BaseDataset._color_transfer", "base_dataset.BaseDataset._reshape", "base_dataset.BaseDataset._blur_and_sharp"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._color_transfer", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._reshape", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._blur_and_sharp"], ["", "def", "face_augmentation", "(", "self", ",", "img", ",", "crop_size", ")", ":", "\n", "        ", "img", "=", "self", ".", "_color_transfer", "(", "img", ")", "\n", "img", "=", "self", ".", "_reshape", "(", "img", ",", "crop_size", ")", "\n", "img", "=", "self", ".", "_blur_and_sharp", "(", "img", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._blur_and_sharp": [[36, 49], ["numpy.random.randint", "img.copy", "range", "numpy.stack", "len", "numpy.random.choice", "numpy.stack.append", "numpy.array", "numpy.stack.append", "cv2.medianBlur", "cv2.filter2D"], "methods", ["None"], ["", "def", "_blur_and_sharp", "(", "self", ",", "img", ")", ":", "\n", "        ", "blur", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", "\n", "img2", "=", "img", ".", "copy", "(", ")", "\n", "output", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "img2", ")", ")", ":", "\n", "            ", "if", "blur", ":", "\n", "                ", "ksize", "=", "np", ".", "random", ".", "choice", "(", "[", "3", ",", "5", ",", "7", ",", "9", "]", ")", "\n", "output", ".", "append", "(", "cv2", ".", "medianBlur", "(", "img2", "[", "i", "]", ",", "ksize", ")", ")", "\n", "", "else", ":", "\n", "                ", "kernel", "=", "np", ".", "array", "(", "[", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", ",", "[", "-", "1", ",", "9", ",", "-", "1", "]", ",", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", "]", ")", "\n", "output", ".", "append", "(", "cv2", ".", "filter2D", "(", "img2", "[", "i", "]", ",", "-", "1", ",", "kernel", ")", ")", "\n", "", "", "output", "=", "np", ".", "stack", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._color_transfer": [[50, 62], ["numpy.random.uniform", "numpy.random.randint", "numpy.random.randint", "img.copy", "numpy.minimum", "numpy.maximum", "numpy.zeros", "numpy.ones"], "methods", ["None"], ["", "def", "_color_transfer", "(", "self", ",", "img", ")", ":", "\n", "\n", "        ", "transfer_c", "=", "np", ".", "random", ".", "uniform", "(", "0.3", ",", "1.6", ")", "\n", "\n", "start_channel", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", "\n", "end_channel", "=", "np", ".", "random", ".", "randint", "(", "start_channel", "+", "1", ",", "4", ")", "\n", "\n", "img2", "=", "img", ".", "copy", "(", ")", "\n", "\n", "img2", "[", ":", ",", ":", ",", ":", ",", "start_channel", ":", "end_channel", "]", "=", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "img", "[", ":", ",", ":", ",", ":", ",", "start_channel", ":", "end_channel", "]", "*", "transfer_c", ",", "np", ".", "zeros", "(", "img", "[", ":", ",", ":", ",", ":", ",", "start_channel", ":", "end_channel", "]", ".", "shape", ")", ")", ",", "\n", "np", ".", "ones", "(", "img", "[", ":", ",", ":", ",", ":", ",", "start_channel", ":", "end_channel", "]", ".", "shape", ")", "*", "255", ")", "\n", "return", "img2", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.perspective_transform": [[63, 75], ["numpy.array", "numpy.array().astype", "cv2.getPerspectiveTransform", "cv2.warpPerspective", "numpy.float32", "numpy.array"], "methods", ["None"], ["", "def", "perspective_transform", "(", "self", ",", "img", ",", "crop_size", "=", "224", ",", "pers_size", "=", "10", ",", "enlarge_size", "=", "-", "10", ")", ":", "\n", "        ", "h", ",", "w", ",", "c", "=", "img", ".", "shape", "\n", "dst", "=", "np", ".", "array", "(", "[", "\n", "[", "-", "enlarge_size", ",", "-", "enlarge_size", "]", ",", "\n", "[", "-", "enlarge_size", "+", "pers_size", ",", "w", "+", "enlarge_size", "]", ",", "\n", "[", "h", "+", "enlarge_size", ",", "-", "enlarge_size", "]", ",", "\n", "[", "h", "+", "enlarge_size", "-", "pers_size", ",", "w", "+", "enlarge_size", "]", ",", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "src", "=", "np", ".", "array", "(", "[", "[", "-", "enlarge_size", ",", "-", "enlarge_size", "]", ",", "[", "-", "enlarge_size", ",", "w", "+", "enlarge_size", "]", ",", "\n", "[", "h", "+", "enlarge_size", ",", "-", "enlarge_size", "]", ",", "[", "h", "+", "enlarge_size", ",", "w", "+", "enlarge_size", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", "(", ")", ")", "\n", "M", "=", "cv2", ".", "getPerspectiveTransform", "(", "src", ",", "dst", ")", "\n", "warped", "=", "cv2", ".", "warpPerspective", "(", "img", ",", "M", ",", "(", "crop_size", ",", "crop_size", ")", ",", "borderMode", "=", "cv2", ".", "BORDER_REPLICATE", ")", "\n", "return", "warped", ",", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset._reshape": [[76, 101], ["numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "img.copy", "range", "numpy.stack", "numpy.random.randint", "pow", "numpy.random.randint", "pow", "len", "numpy.random.randint", "numpy.random.randint", "cv2.resize", "cv2.copyMakeBorder", "base_dataset.BaseDataset.perspective_transform", "numpy.stack.append", "cv2.resize", "cv2.copyMakeBorder", "base_dataset.BaseDataset.perspective_transform", "numpy.stack.append"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.perspective_transform", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.base_dataset.BaseDataset.perspective_transform"], ["", "def", "_reshape", "(", "self", ",", "img", ",", "crop_size", ")", ":", "\n", "        ", "reshape", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", "\n", "reshape_size", "=", "np", ".", "random", ".", "randint", "(", "15", ",", "25", ")", "\n", "extra_padding_size", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "reshape_size", "//", "2", ")", "\n", "pers_size", "=", "np", ".", "random", ".", "randint", "(", "20", ",", "30", ")", "*", "pow", "(", "-", "1", ",", "np", ".", "random", ".", "randint", "(", "2", ")", ")", "\n", "\n", "enlarge_size", "=", "np", ".", "random", ".", "randint", "(", "20", ",", "40", ")", "*", "pow", "(", "-", "1", ",", "np", ".", "random", ".", "randint", "(", "2", ")", ")", "\n", "shape", "=", "img", "[", "0", "]", ".", "shape", "\n", "img2", "=", "img", ".", "copy", "(", ")", "\n", "output", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "img2", ")", ")", ":", "\n", "            ", "if", "reshape", ":", "\n", "                ", "im", "=", "cv2", ".", "resize", "(", "img2", "[", "i", "]", ",", "(", "shape", "[", "0", "]", "-", "reshape_size", "*", "2", ",", "shape", "[", "1", "]", "+", "reshape_size", "*", "2", ")", ")", "\n", "im", "=", "cv2", ".", "copyMakeBorder", "(", "im", ",", "0", ",", "0", ",", "reshape_size", "+", "extra_padding_size", ",", "reshape_size", "+", "extra_padding_size", ",", "cv2", ".", "cv2", ".", "BORDER_REFLECT", ")", "\n", "im", "=", "im", "[", "reshape_size", "-", "extra_padding_size", ":", "shape", "[", "0", "]", "+", "reshape_size", "+", "extra_padding_size", ",", ":", ",", ":", "]", "\n", "im", ",", "_", "=", "self", ".", "perspective_transform", "(", "im", ",", "crop_size", "=", "crop_size", ",", "pers_size", "=", "pers_size", ",", "enlarge_size", "=", "enlarge_size", ")", "\n", "output", ".", "append", "(", "im", ")", "\n", "", "else", ":", "\n", "                ", "im", "=", "cv2", ".", "resize", "(", "img2", "[", "i", "]", ",", "(", "shape", "[", "0", "]", "+", "reshape_size", "*", "2", ",", "shape", "[", "1", "]", "-", "reshape_size", "*", "2", ")", ")", "\n", "im", "=", "cv2", ".", "copyMakeBorder", "(", "im", ",", "reshape_size", "+", "extra_padding_size", ",", "reshape_size", "+", "extra_padding_size", ",", "0", ",", "0", ",", "cv2", ".", "cv2", ".", "BORDER_REFLECT", ")", "\n", "im", "=", "im", "[", ":", ",", "reshape_size", "-", "extra_padding_size", ":", "shape", "[", "0", "]", "+", "reshape_size", "+", "extra_padding_size", ",", ":", "]", "\n", "im", ",", "_", "=", "self", ".", "perspective_transform", "(", "im", ",", "crop_size", "=", "crop_size", ",", "pers_size", "=", "pers_size", ",", "enlarge_size", "=", "enlarge_size", ")", "\n", "output", ".", "append", "(", "im", ")", "\n", "", "", "output", "=", "np", ".", "stack", "(", "output", ")", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.find_dataset_using_name": [[6, 29], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "ValueError", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.get_option_setter": [[31, 34], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.create_dataloader": [[36, 78], ["opt.dataset_mode.split", "len", "__init__.find_dataset_using_name", "find_dataset_using_name.", "dataset.initialize", "print", "torch.utils.data.DataLoader", "__init__.find_dataset_using_name", "find_dataset_using_name.", "dataset.initialize", "print", "torch.utils.data.DataLoader", "int", "len", "int", "type", "len", "type"], "function", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.find_dataset_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.find_dataset_using_name", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize"], []], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.test_options.TestOptions.initialize": [[5, 31], ["base_options.BaseOptions.initialize", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.set_defaults", "parser.set_defaults", "float", "float"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize"], ["    ", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_path'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints/results/input_path'", ",", "help", "=", "'defined input path.'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_path_vox'", ",", "type", "=", "str", ",", "default", "=", "'./misc/demo.csv'", ",", "help", "=", "'the meta data path'", ")", "\n", "parser", ".", "add_argument", "(", "'--driving_pose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'driven pose to generate a talking face'", ")", "\n", "parser", ".", "add_argument", "(", "'--list_num'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'list num'", ")", "\n", "parser", ".", "add_argument", "(", "'--fitting_iterations'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'The iterarions for fit testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--which_epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--how_many'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'how many test images to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_ind'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'the start id for defined driven'", ")", "\n", "parser", ".", "add_argument", "(", "'--list_start'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'which num in the list to start'", ")", "\n", "parser", ".", "add_argument", "(", "'--list_end'", ",", "type", "=", "int", ",", "default", "=", "float", "(", "\"inf\"", ")", ",", "help", "=", "'how many test images to run'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'where to save data'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi_gpu'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use multi gpus'", ")", "\n", "parser", ".", "add_argument", "(", "'--defined_driven'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use defined driven'", ")", "\n", "parser", ".", "add_argument", "(", "'--gen_video'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to generate videos'", ")", "\n", "parser", ".", "add_argument", "(", "'--onnx'", ",", "action", "=", "'store_true'", ",", "help", "=", "'for tddfa'", ")", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'cpu'", ",", "help", "=", "'gpu or cpu mode'", ")", "\n", "\n", "# parser.set_defaults(preprocess_mode='scale_width_and_crop', crop_size=256, load_size=256, display_winsize=256)", "\n", "# parser.set_defaults(serial_batches=True)", "\n", "parser", ".", "set_defaults", "(", "no_flip", "=", "True", ")", "\n", "parser", ".", "set_defaults", "(", "phase", "=", "'test'", ")", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.train_options.TrainOptions.initialize": [[5, 57], ["base_options.BaseOptions.initialize", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize"], ["    ", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "# for displays", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_epoch_freq'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'frequency of saving checkpoints at the end of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_html'", ",", "action", "=", "'store_true'", ",", "help", "=", "'do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "help", "=", "'only do one epoch and displays at each iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--tf_log'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use tensorboard logging. Requires tensorflow installed'", ")", "\n", "parser", ".", "add_argument", "(", "'--tensorboard'", ",", "default", "=", "True", ",", "help", "=", "'if specified, use tensorboard logging. Requires tensorflow installed'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_pretrain'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'load the pretrained model from the specified location'", ")", "\n", "\n", "# for training", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "action", "=", "'store_true'", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--recognition'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train only recognition'", ")", "\n", "parser", ".", "add_argument", "(", "'--which_epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--noload_D'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to load D when continue training'", ")", "\n", "parser", ".", "add_argument", "(", "'--pose_noise'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use pose noise training'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_separately'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to continue train by loading separate models'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'# of iter at starting learning rate. This is NOT the total #epochs. Totla #epochs is niter + niter_decay'", ")", "\n", "parser", ".", "add_argument", "(", "'--niter_decay'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'# of iter to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--D_steps_per_G'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of discriminator iterations per generator iterations.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--G_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints/100_net_G.pth'", ",", "help", "=", "'G pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--D_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'D pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--E_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'E pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--V_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'V pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--A_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'E pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--A_sync_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'E pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--netE_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'E pretrain path'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fix_netV'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net V'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netE'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net E'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netE_mouth'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net E mapper, fc and mapper'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netE_mouth_embed'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net E mapper, fc and mapper'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netE_headpose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net E headpose'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netA_sync'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified fix net A_sync'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netG'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net G'", ")", "\n", "parser", ".", "add_argument", "(", "'--fix_netD'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, fix net D'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_cross_modal'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use cls loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--softmax_contrastive'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use contrastive loss for img and audio embed'", ")", "\n", "# for discriminators", "\n", "\n", "parser", ".", "add_argument", "(", "'--baseline_sync'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train baseline sync'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_feature_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'to use style feature loss'", ")", "\n", "# parser.add_argument('--vggface_checkpoint', type=str, default='', help='pth to vggface ckpt')", "\n", "parser", ".", "add_argument", "(", "'--pretrain'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use outsider pretrain'", ")", "\n", "parser", ".", "add_argument", "(", "'--disentangle'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use disentangle loss'", ")", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize": [[16, 149], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "# experiment specifics", "\n", "        ", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'demo'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--filename_tmpl'", ",", "type", "=", "str", ",", "default", "=", "'{:06}.jpg'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "type", "=", "str", ",", "default", "=", "'/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv'", ",", "help", "=", "'where to load voxceleb train data'", ")", "\n", "parser", ".", "add_argument", "(", "'--lrw_data_path'", ",", "type", "=", "str", ",", "\n", "default", "=", "'/home/SENSETIME/zhouhang1/Downloads/VoxCeleb2/voxceleb2_train.csv'", ",", "\n", "help", "=", "'where to load lrw train data'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_classes'", ",", "type", "=", "int", ",", "default", "=", "5830", ",", "help", "=", "'num classes'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'./checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'av'", ",", "help", "=", "'which model to use, rotate|rotatespade'", ")", "\n", "parser", ".", "add_argument", "(", "'--trainer'", ",", "type", "=", "str", ",", "default", "=", "'audio'", ",", "help", "=", "'which trainer to use, rotate|rotatespade'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_G'", ",", "type", "=", "str", ",", "default", "=", "'spectralinstance'", ",", "help", "=", "'instance normalization or batch normalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_D'", ",", "type", "=", "str", ",", "default", "=", "'spectralinstance'", ",", "help", "=", "'instance normalization or batch normalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_E'", ",", "type", "=", "str", ",", "default", "=", "'spectralinstance'", ",", "help", "=", "'instance normalization or batch normalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--norm_A'", ",", "type", "=", "str", ",", "default", "=", "'spectralinstance'", ",", "help", "=", "'instance normalization or batch normalization'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "# input/output sizes", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--preprocess_mode'", ",", "type", "=", "str", ",", "default", "=", "'resize_and_crop'", ",", "help", "=", "'scaling and cropping of images at load time.'", ",", "choices", "=", "(", "\"resize_and_crop\"", ",", "\"crop\"", ",", "\"scale_width\"", ",", "\"scale_width_and_crop\"", ",", "\"scale_shortside\"", ",", "\"scale_shortside_and_crop\"", ",", "\"fixed\"", ",", "\"none\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "224", ",", "help", "=", "'Crop to the width of crop_size (after initially scaling the images to load_size.)'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_len'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'Crop len'", ")", "\n", "parser", ".", "add_argument", "(", "'--target_crop_len'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Crop len'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to crop the image'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_len'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'num of imgs to process'", ")", "\n", "parser", ".", "add_argument", "(", "'--pose_dim'", ",", "type", "=", "int", ",", "default", "=", "12", ",", "help", "=", "'num of imgs to process'", ")", "\n", "parser", ".", "add_argument", "(", "'--frame_interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'the interval of frams'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_clips'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'num of clips to process'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_inputs'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'num of inputs to the network'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_encoded_dim'", ",", "type", "=", "int", ",", "default", "=", "2560", ",", "help", "=", "'dim of reduced id feature'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--aspect_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'The ratio width/height. The final height of the load image will be crop_size/aspect_ratio'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'# of output image channels'", ")", "\n", "parser", ".", "add_argument", "(", "'--audio_nc'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'# of output audio channels'", ")", "\n", "parser", ".", "add_argument", "(", "'--frame_rate'", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "'fps'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_frames_per_clip'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'num of frames one audio bin'", ")", "\n", "parser", ".", "add_argument", "(", "'--hop_size'", ",", "type", "=", "int", ",", "default", "=", "160", ",", "help", "=", "'audio hop size'", ")", "\n", "parser", ".", "add_argument", "(", "'--generate_interval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'select frames to generate'", ")", "\n", "parser", ".", "add_argument", "(", "'--dis_feat_rec'", ",", "action", "=", "'store_true'", ",", "help", "=", "'select frames to generate'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--train_recognition'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train recognition only'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_sync'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train sync only'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_word'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train word only'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_dis_pose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'train dis pose'", ")", "\n", "parser", ".", "add_argument", "(", "'--generate_from_audio_only'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, generate only from audio features'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_pose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'noise pose to generate a talking face'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_feature_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'style_feature_loss'", ")", "\n", "\n", "# for setting inputsf", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'voxtest'", ")", "\n", "parser", ".", "add_argument", "(", "'--landmark_align'", ",", "action", "=", "'store_true'", ",", "help", "=", "'wether there is landmark_align'", ")", "\n", "parser", ".", "add_argument", "(", "'--serial_batches'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if true, takes images in order to make batches, otherwise takes them randomly'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_flip'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do not flip the images for data argumentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--nThreads'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_mel_T'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_bins_per_frame'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'n_melT'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max_dataset_size'", ",", "type", "=", "int", ",", "default", "=", "sys", ".", "maxsize", ",", "help", "=", "'Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_from_opt_file'", ",", "action", "=", "'store_true'", ",", "help", "=", "'load the options from checkpoints and use that as default'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_audio'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'use audio as driven input'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_audio_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'use audio id'", ")", "\n", "parser", ".", "add_argument", "(", "'--augment_target'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'just add'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--display_winsize'", ",", "type", "=", "int", ",", "default", "=", "224", ",", "help", "=", "'display window size'", ")", "\n", "\n", "# for generator", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'modulate'", ",", "help", "=", "'selects model to use for netG (modulate)'", ")", "\n", "parser", ".", "add_argument", "(", "'--netA'", ",", "type", "=", "str", ",", "default", "=", "'resseaudio'", ",", "help", "=", "'selects model to use for netA (audio | spade)'", ")", "\n", "parser", ".", "add_argument", "(", "'--netA_sync'", ",", "type", "=", "str", ",", "default", "=", "'ressesync'", ",", "help", "=", "'selects model to use for netA (audio | spade)'", ")", "\n", "parser", ".", "add_argument", "(", "'--netV'", ",", "type", "=", "str", ",", "default", "=", "'resnext'", ",", "help", "=", "'selects model to use for netV (mobile | id)'", ")", "\n", "parser", ".", "add_argument", "(", "'--netE'", ",", "type", "=", "str", ",", "default", "=", "'fan'", ",", "help", "=", "'selects model to use for netV (mobile | fan)'", ")", "\n", "parser", ".", "add_argument", "(", "'--netD'", ",", "type", "=", "str", ",", "default", "=", "'multiscale'", ",", "help", "=", "'(n_layers|multiscale|image|projection)'", ")", "\n", "parser", ".", "add_argument", "(", "'--D_input'", ",", "type", "=", "str", ",", "default", "=", "'single'", ",", "help", "=", "'(concat|single|hinge)'", ")", "\n", "parser", ".", "add_argument", "(", "'--driven_type'", ",", "type", "=", "str", ",", "default", "=", "'face'", ",", "help", "=", "'selects model to use for netV (heatmap | face)'", ")", "\n", "parser", ".", "add_argument", "(", "'--landmark_type'", ",", "type", "=", "str", ",", "default", "=", "'min'", ",", "help", "=", "'selects model to use for netV (mobile | fan)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of gen filters in first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'xavier'", ",", "help", "=", "'network initialization [normal|xavier|kaiming|orthogonal]'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_fusion'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "help", "=", "'style fusion method'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_variance'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'variance of the initialization distribution'", ")", "\n", "\n", "# for instance-wise features", "\n", "parser", ".", "add_argument", "(", "'--no_instance'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* add instance map as input'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_id_feature'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use id feature as style gan input'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_landmark'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, load landmarks'", ")", "\n", "parser", ".", "add_argument", "(", "'--nef'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'# of encoder filters in the first conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--style_dim'", ",", "type", "=", "int", ",", "default", "=", "2580", ",", "help", "=", "'# of encoder filters in the first conv layer'", ")", "\n", "\n", "####################### weight settings ###################################################################", "\n", "\n", "parser", ".", "add_argument", "(", "'--vgg_face'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, use VGG feature matching loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--VGGFace_pretrain_path'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'VGGFace pretrain path'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_feat'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for feature matching loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_image'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for image reconstruction'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_vgg'", ",", "type", "=", "float", ",", "default", "=", "10.0", ",", "help", "=", "'weight for vgg loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_vggface'", ",", "type", "=", "float", ",", "default", "=", "5.0", ",", "help", "=", "'weight for vggface loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_rotate_D'", ",", "type", "=", "float", ",", "default", "=", "'0.1'", ",", "\n", "help", "=", "'rotated D loss weight'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_D'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n", "help", "=", "'D loss weight'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_softmax'", ",", "type", "=", "float", ",", "default", "=", "1000000", ",", "help", "=", "'weight for softmax loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_crossmodal'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "'weight for softmax loss'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lambda_contrastive'", ",", "type", "=", "float", ",", "default", "=", "100", ",", "help", "=", "'if specified, use contrastive loss for img and audio embed'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'# of discrim filters in first conv layer'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no_ganFeat_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use discriminator feature matching loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_vgg_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use VGG feature matching loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_id_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use cls loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--word_loss'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use cls loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_spectrogram'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, do *not* use mel spectrogram, use mfcc'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gan_mode'", ",", "type", "=", "str", ",", "default", "=", "'hinge'", ",", "help", "=", "'(ls|original|hinge)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_TTUR'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use TTUR training scheme'", ")", "\n", "\n", "############################## optimizer #############################", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--no_gaussian_landmark'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use no_gaussian_landmark (1.0 landmark) for rotatespade model'", ")", "\n", "parser", ".", "add_argument", "(", "'--label_mask'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use face mask'", ")", "\n", "parser", ".", "add_argument", "(", "'--positional_encode'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use positional encode'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_transformer'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use transformer'", ")", "\n", "parser", ".", "add_argument", "(", "'--has_mask'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to use mask in transformer'", ")", "\n", "parser", ".", "add_argument", "(", "'--heatmap_size'", ",", "type", "=", "float", ",", "default", "=", "3", ",", "help", "=", "'the size of the heatmap, used in rotatespade model'", ")", "\n", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.gather_options": [[150, 187], ["data.get_option_setter.parse_known_args", "models.get_option_setter", "models.get_option_setter.", "dataset_option_setter.parse_args.dataset_mode.split", "data.get_option_setter.parse_known_args", "data.get_option_setter.parse_args", "argparse.ArgumentParser", "base_options.BaseOptions.initialize", "len", "data.get_option_setter", "data.get_option_setter.", "base_options.BaseOptions.update_options_from_file", "data.get_option_setter", "data.get_option_setter."], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.initialize", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.update_options_from_file", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.data.__init__.get_option_setter"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "# initialize parser with basic options", "\n", "        ", "if", "not", "self", ".", "initialized", ":", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "opt", ",", "unknown", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# modify model-related parser options", "\n", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "# modify dataset-related parser options", "\n", "dataset_mode", "=", "opt", ".", "dataset_mode", "\n", "dataset_modes", "=", "opt", ".", "dataset_mode", ".", "split", "(", "','", ")", "\n", "\n", "if", "len", "(", "dataset_modes", ")", "==", "1", ":", "\n", "            ", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_mode", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "", "else", ":", "\n", "            ", "for", "dm", "in", "dataset_modes", ":", "\n", "                ", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dm", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "", "", "opt", ",", "unknown", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "# if there is opt_file, load it.", "\n", "# lt options will be overwritten", "\n", "if", "opt", ".", "load_from_opt_file", ":", "\n", "            ", "parser", "=", "self", ".", "update_options_from_file", "(", "parser", ",", "opt", ")", "\n", "\n", "", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "self", ".", "parser", "=", "parser", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.print_options": [[188, 199], ["sorted", "print", "vars().items", "base_options.BaseOptions.parser.get_default", "str", "str", "vars", "str"], "methods", ["None"], ["", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.option_file_path": [[200, 206], ["os.path.join", "os.path.join", "util.util.util.mkdirs"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.networks.util.mkdirs"], ["", "def", "option_file_path", "(", "self", ",", "opt", ",", "makedir", "=", "False", ")", ":", "\n", "        ", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "if", "makedir", ":", "\n", "            ", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'opt'", ")", "\n", "return", "file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.save_options": [[207, 219], ["base_options.BaseOptions.option_file_path", "open", "sorted", "open", "pickle.dump", "vars().items", "base_options.BaseOptions.parser.get_default", "opt_file.write", "vars", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.option_file_path"], ["", "def", "save_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "file_name", "=", "self", ".", "option_file_path", "(", "opt", ",", "makedir", "=", "True", ")", "\n", "with", "open", "(", "file_name", "+", "'.txt'", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "            ", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "                ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                    ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "opt_file", ".", "write", "(", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", ")", "\n", "\n", "", "", "with", "open", "(", "file_name", "+", "'.pkl'", ",", "'wb'", ")", "as", "opt_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "opt", ",", "opt_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.update_options_from_file": [[220, 227], ["base_options.BaseOptions.load_options", "sorted", "vars().items", "hasattr", "getattr", "parser.set_defaults", "vars", "getattr"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.load_options"], ["", "", "def", "update_options_from_file", "(", "self", ",", "parser", ",", "opt", ")", ":", "\n", "        ", "new_opt", "=", "self", ".", "load_options", "(", "opt", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "new_opt", ",", "k", ")", "and", "v", "!=", "getattr", "(", "new_opt", ",", "k", ")", ":", "\n", "                ", "new_val", "=", "getattr", "(", "new_opt", ",", "k", ")", "\n", "parser", ".", "set_defaults", "(", "**", "{", "k", ":", "new_val", "}", ")", "\n", "", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.load_options": [[228, 232], ["base_options.BaseOptions.option_file_path", "pickle.load", "open"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.option_file_path"], ["", "def", "load_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "file_name", "=", "self", ".", "option_file_path", "(", "opt", ",", "makedir", "=", "False", ")", "\n", "new_opt", "=", "pickle", ".", "load", "(", "open", "(", "file_name", "+", "'.pkl'", ",", "'rb'", ")", ")", "\n", "return", "new_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.parse": [[233, 256], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "base_options.BaseOptions.save_options", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.gpu_ids.append"], "methods", ["home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.print_options", "home.repos.pwc.inspect_result.Hangz-nju-cuhk_Talking-Face_PC-AVS.options.base_options.BaseOptions.save_options"], ["", "def", "parse", "(", "self", ",", "save", "=", "False", ")", ":", "\n", "\n", "        ", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "self", ".", "print_options", "(", "opt", ")", "\n", "if", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "save_options", "(", "opt", ")", "\n", "# Set semantic_nc based on the option.", "\n", "# This will be convenient in many places", "\n", "# set gpu ids", "\n", "", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "            ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "\n", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}