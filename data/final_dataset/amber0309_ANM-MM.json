{"home.repos.pwc.inspect_result.amber0309_ANM-MM.None.HSIC.rbf_dot": [[27, 42], ["numpy.sum().reshape", "numpy.sum().reshape", "numpy.tile", "numpy.tile", "numpy.exp", "numpy.sum", "numpy.sum", "numpy.dot"], "function", ["None"], ["def", "rbf_dot", "(", "pattern1", ",", "pattern2", ",", "deg", ")", ":", "\n", "\t", "size1", "=", "pattern1", ".", "shape", "\n", "size2", "=", "pattern2", ".", "shape", "\n", "\n", "G", "=", "np", ".", "sum", "(", "pattern1", "*", "pattern1", ",", "1", ")", ".", "reshape", "(", "size1", "[", "0", "]", ",", "1", ")", "\n", "H", "=", "np", ".", "sum", "(", "pattern2", "*", "pattern2", ",", "1", ")", ".", "reshape", "(", "size2", "[", "0", "]", ",", "1", ")", "\n", "\n", "Q", "=", "np", ".", "tile", "(", "G", ",", "(", "1", ",", "size2", "[", "0", "]", ")", ")", "\n", "R", "=", "np", ".", "tile", "(", "H", ".", "T", ",", "(", "size1", "[", "0", "]", ",", "1", ")", ")", "\n", "\n", "H", "=", "Q", "+", "R", "-", "2", "*", "np", ".", "dot", "(", "pattern1", ",", "pattern2", ".", "T", ")", "\n", "\n", "H", "=", "np", ".", "exp", "(", "-", "H", "/", "2", "/", "(", "deg", "**", "2", ")", ")", "\n", "\n", "return", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.HSIC.hsic_gam": [[44, 111], ["numpy.sum().reshape", "numpy.tile", "numpy.tile", "dists.reshape.reshape", "numpy.sqrt", "numpy.sum().reshape", "numpy.tile", "numpy.tile", "dists.reshape.reshape", "numpy.sqrt", "numpy.ones", "HSIC.rbf_dot", "HSIC.rbf_dot", "numpy.dot", "numpy.dot", "numpy.tril", "numpy.tril", "numpy.identity", "numpy.dot", "numpy.dot", "numpy.sum", "numpy.diag", "numpy.diag", "numpy.sum", "numpy.dot", "numpy.median", "numpy.sum", "numpy.dot", "numpy.median", "numpy.ones", "numpy.diag", "numpy.diag", "numpy.dot", "numpy.dot", "scipy.stats.gamma.ppf", "numpy.sum", "numpy.trace", "numpy.dot", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.HSIC.rbf_dot", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.HSIC.rbf_dot"], ["", "def", "hsic_gam", "(", "X", ",", "Y", ",", "alph", ")", ":", "\n", "\t", "\"\"\"\n\tX, Y are numpy vectors with row - sample, col - dim\n\talph is the significance level\n\tauto choose median to be the kernel width\n\t\"\"\"", "\n", "n", "=", "X", ".", "shape", "[", "0", "]", "\n", "\n", "# ----- width of X -----", "\n", "Xmed", "=", "X", "\n", "\n", "G", "=", "np", ".", "sum", "(", "Xmed", "*", "Xmed", ",", "1", ")", ".", "reshape", "(", "n", ",", "1", ")", "\n", "Q", "=", "np", ".", "tile", "(", "G", ",", "(", "1", ",", "n", ")", ")", "\n", "R", "=", "np", ".", "tile", "(", "G", ".", "T", ",", "(", "n", ",", "1", ")", ")", "\n", "\n", "dists", "=", "Q", "+", "R", "-", "2", "*", "np", ".", "dot", "(", "Xmed", ",", "Xmed", ".", "T", ")", "\n", "dists", "=", "dists", "-", "np", ".", "tril", "(", "dists", ")", "\n", "dists", "=", "dists", ".", "reshape", "(", "n", "**", "2", ",", "1", ")", "\n", "\n", "width_x", "=", "np", ".", "sqrt", "(", "0.5", "*", "np", ".", "median", "(", "dists", "[", "dists", ">", "0", "]", ")", ")", "\n", "# ----- -----", "\n", "\n", "# ----- width of X -----", "\n", "Ymed", "=", "Y", "\n", "\n", "G", "=", "np", ".", "sum", "(", "Ymed", "*", "Ymed", ",", "1", ")", ".", "reshape", "(", "n", ",", "1", ")", "\n", "Q", "=", "np", ".", "tile", "(", "G", ",", "(", "1", ",", "n", ")", ")", "\n", "R", "=", "np", ".", "tile", "(", "G", ".", "T", ",", "(", "n", ",", "1", ")", ")", "\n", "\n", "dists", "=", "Q", "+", "R", "-", "2", "*", "np", ".", "dot", "(", "Ymed", ",", "Ymed", ".", "T", ")", "\n", "dists", "=", "dists", "-", "np", ".", "tril", "(", "dists", ")", "\n", "dists", "=", "dists", ".", "reshape", "(", "n", "**", "2", ",", "1", ")", "\n", "\n", "width_y", "=", "np", ".", "sqrt", "(", "0.5", "*", "np", ".", "median", "(", "dists", "[", "dists", ">", "0", "]", ")", ")", "\n", "# ----- -----", "\n", "\n", "bone", "=", "np", ".", "ones", "(", "(", "n", ",", "1", ")", ",", "dtype", "=", "float", ")", "\n", "H", "=", "np", ".", "identity", "(", "n", ")", "-", "np", ".", "ones", "(", "(", "n", ",", "n", ")", ",", "dtype", "=", "float", ")", "/", "n", "\n", "\n", "K", "=", "rbf_dot", "(", "X", ",", "X", ",", "width_x", ")", "\n", "L", "=", "rbf_dot", "(", "Y", ",", "Y", ",", "width_y", ")", "\n", "\n", "Kc", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "H", ",", "K", ")", ",", "H", ")", "\n", "Lc", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "H", ",", "L", ")", ",", "H", ")", "\n", "\n", "testStat", "=", "np", ".", "sum", "(", "Kc", ".", "T", "*", "Lc", ")", "/", "n", "\n", "\n", "varHSIC", "=", "(", "Kc", "*", "Lc", "/", "6", ")", "**", "2", "\n", "\n", "varHSIC", "=", "(", "np", ".", "sum", "(", "varHSIC", ")", "-", "np", ".", "trace", "(", "varHSIC", ")", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "\n", "varHSIC", "=", "varHSIC", "*", "72", "*", "(", "n", "-", "4", ")", "*", "(", "n", "-", "5", ")", "/", "n", "/", "(", "n", "-", "1", ")", "/", "(", "n", "-", "2", ")", "/", "(", "n", "-", "3", ")", "\n", "\n", "K", "=", "K", "-", "np", ".", "diag", "(", "np", ".", "diag", "(", "K", ")", ")", "\n", "L", "=", "L", "-", "np", ".", "diag", "(", "np", ".", "diag", "(", "L", ")", ")", "\n", "\n", "muX", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "bone", ".", "T", ",", "K", ")", ",", "bone", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "muY", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "bone", ".", "T", ",", "L", ")", ",", "bone", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "\n", "mHSIC", "=", "(", "1", "+", "muX", "*", "muY", "-", "muX", "-", "muY", ")", "/", "n", "\n", "\n", "al", "=", "mHSIC", "**", "2", "/", "varHSIC", "\n", "bet", "=", "varHSIC", "*", "n", "/", "mHSIC", "\n", "\n", "thresh", "=", "gamma", ".", "ppf", "(", "1", "-", "alph", ",", "al", ",", "scale", "=", "bet", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "return", "(", "testStat", ",", "thresh", ")", "", "", ""]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.__init__": [[19, 23], ["numpy.exp", "numpy.exp"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "gamma", ")", ":", "\n", "\t\t", "self", ".", "alpha", "=", "np", ".", "exp", "(", "alpha", ")", "\n", "self", ".", "gamma", "=", "np", ".", "exp", "(", "gamma", ")", "\n", "self", ".", "nparams", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.set_params": [[24, 27], ["numpy.exp().copy().flatten", "numpy.exp().copy", "numpy.exp"], "methods", ["None"], ["", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n", "\t\t", "assert", "new_params", ".", "size", "==", "self", ".", "nparams", "\n", "self", ".", "alpha", ",", "self", ".", "gamma", "=", "np", ".", "exp", "(", "new_params", ")", ".", "copy", "(", ")", ".", "flatten", "(", ")", "#try to unpack np array safely.  ", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.get_params": [[28, 31], ["numpy.log", "numpy.array"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "#return np.array([self.alpha, self.gamma])", "\n", "\t\t", "return", "np", ".", "log", "(", "np", ".", "array", "(", "[", "self", ".", "alpha", ",", "self", ".", "gamma", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.__call__": [[32, 41], ["x1.reshape", "x2.reshape", "numpy.exp", "numpy.sum", "numpy.square"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "N2", ",", "D2", "=", "x2", ".", "shape", "\n", "assert", "D1", "==", "D2", ",", "\"Vectors must be of matching dimension\"", "\n", "#use broadcasting to avoid for loops. ", "\n", "#should be uber fast", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x2", ".", "reshape", "(", "1", ",", "N2", ",", "D2", ")", "\n", "diff", "=", "self", ".", "alpha", "*", "np", ".", "exp", "(", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", ",", "-", "1", ")", "*", "self", ".", "gamma", ")", "\n", "return", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.gradients": [[42, 52], ["numpy.sum", "x1.reshape", "x1.reshape", "numpy.square", "numpy.exp", "numpy.exp"], "methods", ["None"], ["", "def", "gradients", "(", "self", ",", "x1", ")", ":", "\n", "\t\t", "\"\"\"Calculate the gradient of the matrix K wrt the (log of the) free parameters\"\"\"", "\n", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x1", ".", "reshape", "(", "1", ",", "N1", ",", "D1", ")", "\n", "diff", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", ",", "-", "1", ")", "\n", "#dalpha = np.exp(-diff*self.gamma)", "\n", "dalpha", "=", "self", ".", "alpha", "*", "np", ".", "exp", "(", "-", "diff", "*", "self", ".", "gamma", ")", "\n", "#dgamma = -self.alpha*diff*np.exp(-diff*self.gamma)", "\n", "dgamma", "=", "-", "self", ".", "alpha", "*", "self", ".", "gamma", "*", "diff", "*", "np", ".", "exp", "(", "-", "diff", "*", "self", ".", "gamma", ")", "\n", "return", "(", "dalpha", ",", "dgamma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF.gradients_wrt_data": [[53, 75], ["numpy.sum", "numpy.exp", "x1.reshape", "x1.reshape", "numpy.square", "range", "numpy.zeros", "range", "numpy.zeros", "rets.append", "numpy.zeros.copy"], "methods", ["None"], ["", "def", "gradients_wrt_data", "(", "self", ",", "x1", ",", "indexn", "=", "None", ",", "indexd", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"compute the derivative matrix of the kernel wrt the _data_. Crazy\n\t\tThis returns a list of matices: each matrix is NxN, and there are N*D of them!\"\"\"", "\n", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x1", ".", "reshape", "(", "1", ",", "N1", ",", "D1", ")", "\n", "diff", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", ",", "-", "1", ")", "\n", "expdiff", "=", "np", ".", "exp", "(", "-", "self", ".", "gamma", "*", "diff", ")", "\n", "\n", "if", "(", "indexn", "==", "None", ")", "and", "(", "indexd", "==", "None", ")", ":", "#calculate all gradients", "\n", "\t\t\t", "rets", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "N1", ")", ":", "\n", "\t\t\t\t", "for", "d", "in", "range", "(", "D1", ")", ":", "\n", "\t\t\t\t\t", "K", "=", "np", ".", "zeros", "(", "(", "N1", ",", "N1", ")", ")", "\n", "K", "[", "n", ",", ":", "]", "=", "-", "2", "*", "self", ".", "alpha", "*", "self", ".", "gamma", "*", "(", "x1", "[", "n", ",", "d", "]", "-", "x1", "[", ":", ",", "d", "]", ")", "*", "expdiff", "[", "n", ",", ":", "]", "\n", "K", "[", ":", ",", "n", "]", "=", "K", "[", "n", ",", ":", "]", "\n", "rets", ".", "append", "(", "K", ".", "copy", "(", ")", ")", "\n", "", "", "return", "rets", "\n", "", "else", ":", "\n", "\t\t\t", "K", "=", "np", ".", "zeros", "(", "(", "N1", ",", "N1", ")", ")", "\n", "K", "[", "indexn", ",", ":", "]", "=", "-", "2", "*", "self", ".", "alpha", "*", "self", ".", "gamma", "*", "(", "x1", "[", "indexn", ",", "indexd", "]", "-", "x1", "[", ":", ",", "indexd", "]", ")", "*", "expdiff", "[", "indexn", ",", ":", "]", "\n", "K", "[", ":", ",", "indexn", "]", "=", "K", "[", "indexn", ",", ":", "]", "\n", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.__init__": [[77, 82], ["numpy.exp", "numpy.exp", "gammas.flatten"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "alpha", ",", "gammas", ")", ":", "\n", "\t\t", "self", ".", "gammas", "=", "np", ".", "exp", "(", "gammas", ".", "flatten", "(", ")", ")", "\n", "self", ".", "dim", "=", "gammas", ".", "size", "\n", "self", ".", "alpha", "=", "np", ".", "exp", "(", "alpha", ")", "\n", "self", ".", "nparams", "=", "self", ".", "dim", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.set_params": [[83, 87], ["numpy.exp", "numpy.exp", "params.flatten", "params.flatten"], "methods", ["None"], ["", "def", "set_params", "(", "self", ",", "params", ")", ":", "\n", "\t\t", "assert", "params", ".", "size", "==", "self", ".", "nparams", "\n", "self", ".", "alpha", "=", "np", ".", "exp", "(", "params", ".", "flatten", "(", ")", "[", "0", "]", ")", "\n", "self", ".", "gammas", "=", "np", ".", "exp", "(", "params", ".", "flatten", "(", ")", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.get_params": [[88, 90], ["numpy.log", "numpy.hstack"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "\t\t", "return", "np", ".", "log", "(", "np", ".", "hstack", "(", "(", "self", ".", "alpha", ",", "self", ".", "gammas", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.__call__": [[91, 99], ["x1.reshape", "x2.reshape", "numpy.exp", "numpy.sum", "numpy.square"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "N2", ",", "D2", "=", "x2", ".", "shape", "\n", "assert", "D1", "==", "D2", ",", "\"Vectors must be of matching dimension\"", "\n", "assert", "D1", "==", "self", ".", "dim", ",", "\"That data does not match the dimensionality of this kernel\"", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x2", ".", "reshape", "(", "1", ",", "N2", ",", "D2", ")", "\n", "diff", "=", "self", ".", "alpha", "*", "np", ".", "exp", "(", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", "*", "self", ".", "gammas", ",", "-", "1", ")", ")", "\n", "return", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.gradients": [[100, 109], ["numpy.sum", "numpy.exp", "grads.insert", "x1.reshape", "x1.reshape", "numpy.square", "enumerate", "numpy.square"], "methods", ["None"], ["", "def", "gradients", "(", "self", ",", "x1", ")", ":", "\n", "\t\t", "\"\"\"Calculate the gradient of the matrix K wrt the (log of the) free parameters\"\"\"", "\n", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x1", ".", "reshape", "(", "1", ",", "N1", ",", "D1", ")", "\n", "sqdiff", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", "*", "self", ".", "gammas", ",", "-", "1", ")", "\n", "expdiff", "=", "np", ".", "exp", "(", "-", "sqdiff", ")", "\n", "grads", "=", "[", "-", "g", "*", "np", ".", "square", "(", "diff", "[", ":", ",", ":", ",", "i", "]", ")", "*", "self", ".", "alpha", "*", "expdiff", "for", "i", ",", "g", "in", "enumerate", "(", "self", ".", "gammas", ")", "]", "\n", "grads", ".", "insert", "(", "0", ",", "self", ".", "alpha", "*", "expdiff", ")", "\n", "return", "grads", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.RBF_full.gradients_wrt_data": [[110, 132], ["numpy.sum", "numpy.exp", "x1.reshape", "x1.reshape", "range", "numpy.zeros", "numpy.zeros.copy", "numpy.square", "range", "numpy.zeros", "rets.append", "numpy.zeros.copy"], "methods", ["None"], ["", "def", "gradients_wrt_data", "(", "self", ",", "x1", ",", "indexn", "=", "None", ",", "indexd", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"compute the derivative matrix of the kernel wrt the _data_. Crazy\n\t\tThis returns a list of matices: each matrix is NxN, and there are N*D of them!\"\"\"", "\n", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "diff", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "-", "x1", ".", "reshape", "(", "1", ",", "N1", ",", "D1", ")", "\n", "sqdiff", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "diff", ")", "*", "self", ".", "gammas", ",", "-", "1", ")", "\n", "expdiff", "=", "np", ".", "exp", "(", "-", "sqdiff", ")", "\n", "\n", "if", "(", "indexn", "==", "None", ")", "and", "(", "indexd", "==", "None", ")", ":", "#calculate all gradients", "\n", "\t\t\t", "rets", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "N1", ")", ":", "\n", "\t\t\t\t", "for", "d", "in", "range", "(", "D1", ")", ":", "\n", "\t\t\t\t\t", "K", "=", "np", ".", "zeros", "(", "(", "N1", ",", "N1", ")", ")", "\n", "K", "[", "n", ",", ":", "]", "=", "-", "2", "*", "self", ".", "alpha", "*", "self", ".", "gammas", "[", "d", "]", "*", "(", "x1", "[", "n", ",", "d", "]", "-", "x1", "[", ":", ",", "d", "]", ")", "*", "expdiff", "[", "n", ",", ":", "]", "\n", "K", "[", ":", ",", "n", "]", "=", "K", "[", "n", ",", ":", "]", "\n", "rets", ".", "append", "(", "K", ".", "copy", "(", ")", ")", "\n", "", "", "return", "rets", "\n", "", "else", ":", "\n", "\t\t\t", "K", "=", "np", ".", "zeros", "(", "(", "N1", ",", "N1", ")", ")", "\n", "K", "[", "indexn", ",", ":", "]", "=", "-", "2", "*", "self", ".", "alpha", "*", "self", ".", "gammas", "[", "indexd", "]", "*", "(", "x1", "[", "indexn", ",", "indexd", "]", "-", "x1", "[", ":", ",", "indexd", "]", ")", "*", "expdiff", "[", "indexn", ",", ":", "]", "\n", "K", "[", ":", ",", "indexn", "]", "=", "K", "[", "indexn", ",", ":", "]", "\n", "return", "K", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.linear.__init__": [[139, 143], ["numpy.exp", "numpy.exp"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha", ",", "bias", ")", ":", "\n", "\t\t", "self", ".", "alpha", "=", "np", ".", "exp", "(", "alpha", ")", "\n", "self", ".", "bias", "=", "np", ".", "exp", "(", "bias", ")", "\n", "self", ".", "nparams", "=", "2", "\n", "", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.linear.set_params": [[143, 146], ["numpy.exp().flatten", "numpy.exp"], "methods", ["None"], ["", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n", "\t\t", "assert", "new_params", ".", "size", "==", "self", ".", "nparams", "\n", "self", ".", "alpha", ",", "self", ".", "bias", "=", "np", ".", "exp", "(", "new_params", ")", ".", "flatten", "(", ")", "#try to unpack np array safely.  ", "\n", "", "def", "get_params", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.linear.get_params": [[146, 148], ["numpy.log", "numpy.array"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "\t\t", "return", "np", ".", "log", "(", "np", ".", "array", "(", "[", "self", ".", "alpha", ",", "self", ".", "bias", "]", ")", ")", "\n", "", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.linear.__call__": [[148, 156], ["x1.reshape", "x2.reshape", "numpy.sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "N2", ",", "D2", "=", "x2", ".", "shape", "\n", "assert", "D1", "==", "D2", ",", "\"Vectors must be of matching dimension\"", "\n", "prod", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "*", "x2", ".", "reshape", "(", "1", ",", "N2", ",", "D2", ")", "\n", "prod", "=", "self", ".", "alpha", "*", "np", ".", "sum", "(", "prod", ",", "-", "1", ")", "+", "self", ".", "bias", "\n", "#diff = self.alpha*np.sqrt(np.square(np.sum(diff,-1)))", "\n", "return", "prod", "\n", "", "def", "gradients", "(", "self", ",", "x1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.linear.gradients": [[156, 161], ["kernels.linear.", "numpy.ones"], "methods", ["None"], ["", "def", "gradients", "(", "self", ",", "x1", ")", ":", "\n", "\t\t", "\"\"\"Calculate the gradient of the kernel matrix wrt the (log of the) parameters\"\"\"", "\n", "dalpha", "=", "self", "(", "x1", ",", "x1", ")", "-", "self", ".", "bias", "\n", "dbias", "=", "np", ".", "ones", "(", "(", "x1", ".", "shape", "[", "0", "]", ",", "x1", ".", "shape", "[", "0", "]", ")", ")", "*", "self", ".", "bias", "\n", "return", "dalpha", ",", "dbias", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.combined.__init__": [[166, 170], ["kernels.linear", "kernels.RBF"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "alpha_x", ",", "alpha_y", ",", "gamma", ",", "bias", ")", ":", "\n", "\t\t", "self", ".", "linear_kernel", "=", "linear", "(", "alpha_x", ",", "bias", ")", "\n", "self", ".", "RBF_kernel", "=", "RBF", "(", "alpha_y", ",", "gamma", ")", "\n", "self", ".", "nparams", "=", "4", "\n", "", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.combined.set_params": [[170, 174], ["kernels.combined.linear_kernel.set_params", "kernels.combined.RBF_kernel.set_params"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.polynomial.set_params", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.polynomial.set_params"], ["", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n", "\t\t", "assert", "new_params", ".", "size", "==", "self", ".", "nparams", "\n", "self", ".", "linear_kernel", ".", "set_params", "(", "new_params", "[", ":", "2", "]", ")", "\n", "self", ".", "RBF_kernel", ".", "set_params", "(", "new_params", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.combined.__call__": [[175, 180], ["kernels.combined.linear_kernel", "kernels.combined.RBF_kernel"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "N2", ",", "D2", "=", "x2", ".", "shape", "\n", "assert", "D1", "==", "D2", ",", "\"Vectors must be of matching dimension\"", "\n", "return", "self", ".", "linear_kernel", "(", "x1", "[", ":", ",", "0", ":", "1", "]", ",", "x2", "[", ":", ",", "0", ":", "1", "]", ")", "*", "self", ".", "RBF_kernel", "(", "x1", "[", ":", ",", "1", ":", "]", ",", "x2", "[", ":", ",", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.polynomial.__init__": [[182, 187], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "alpha", ",", "order", ")", ":", "\n", "\t\t", "\"\"\"Order of the polynomila is considered fixed...TODO: make the order optimisable...\"\"\"", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "order", "=", "order", "\n", "self", ".", "nparams", "=", "1", "\n", "", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.polynomial.set_params": [[187, 190], ["new_params.flatten"], "methods", ["None"], ["", "def", "set_params", "(", "self", ",", "new_params", ")", ":", "\n", "\t\t", "assert", "new_params", ".", "size", "==", "self", ".", "nparams", "\n", "self", ".", "alpha", ",", "=", "new_params", ".", "flatten", "(", ")", "\n", "", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.kernels.polynomial.__call__": [[190, 197], ["x1.reshape", "x2.reshape", "numpy.power", "numpy.sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x1", ",", "x2", ")", ":", "\n", "\t\t", "N1", ",", "D1", "=", "x1", ".", "shape", "\n", "N2", ",", "D2", "=", "x2", ".", "shape", "\n", "assert", "D1", "==", "D2", ",", "\"Vectors must be of matching dimension\"", "\n", "prod", "=", "x1", ".", "reshape", "(", "N1", ",", "1", ",", "D1", ")", "*", "x2", ".", "reshape", "(", "1", ",", "N2", ",", "D2", ")", "\n", "prod", "=", "self", ".", "alpha", "*", "np", ".", "power", "(", "np", ".", "sum", "(", "prod", ",", "-", "1", ")", "+", "1", ",", "self", ".", "order", ")", "\n", "return", "prod", "\n", "", "", ""]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.__init__": [[17, 28], ["MLP.MLP.initialise", "len", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.initialise"], ["\t", "def", "__init__", "(", "self", ",", "structure", ",", "output", "=", "'linear'", ",", "alpha", "=", "1", ")", ":", "\n", "\t\t", "assert", "len", "(", "structure", ")", "==", "3", "\n", "self", ".", "structure", "=", "structure", "\n", "self", ".", "alpha", "=", "alpha", "# regulariser/prior on weights", "\n", "self", ".", "nweights", "=", "(", "structure", "[", "0", "]", "+", "1", ")", "*", "structure", "[", "1", "]", "+", "(", "structure", "[", "1", "]", "+", "1", ")", "*", "structure", "[", "2", "]", "\n", "\n", "self", ".", "initialise", "(", ")", "\n", "\n", "if", "output", "==", "'linear'", ":", "\n", "\t\t\t", "self", ".", "output_fn", "=", "lambda", "x", ":", "x", "\n", "self", ".", "error_fn", "=", "lambda", "y", ",", "t", ":", "0.5", "*", "np", ".", "sum", "(", "np", ".", "square", "(", "y", "-", "t", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.initialise": [[29, 37], ["numpy.sqrt", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn"], "methods", ["None"], ["", "", "def", "initialise", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"Initialise the weights of the network by sampling from the (Gaussian) prior\"\"\"", "\n", "nin", ",", "nhid", ",", "nout", "=", "self", ".", "structure", "\n", "s", "=", "1.", "/", "np", ".", "sqrt", "(", "self", ".", "alpha", ")", "\n", "self", ".", "w1", "=", "np", ".", "random", ".", "randn", "(", "nin", ",", "nhid", ")", "*", "s", "\n", "self", ".", "b1", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "nhid", ")", "*", "s", "\n", "self", ".", "w2", "=", "np", ".", "random", ".", "randn", "(", "nhid", ",", "nout", ")", "*", "s", "\n", "self", ".", "b2", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "nout", ")", "*", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.forward": [[38, 53], ["MLP.MLP.output_fn", "numpy.dot", "numpy.exp", "numpy.ones", "numpy.dot", "numpy.ones"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "\"\"\"calculate the outputs of the network given a set of inputs x\"\"\"", "\n", "n", ",", "d", "=", "x", ".", "shape", "\n", "assert", "d", "==", "self", ".", "structure", "[", "0", "]", ",", "\"Input dimension does not match this network\"", "\n", "\n", "## {{diff activation function (output of the hidden layer)", "\n", "## ReLu", "\n", "# self.activations = np.maximum(0, np.dot(x,self.w1) + np.ones((n,1))*self.b1)", "\n", "# tanh", "\n", "# self.activations = np.tanh(np.dot(x,self.w1) + np.ones((n,1))*self.b1)", "\n", "# logistic", "\n", "self", ".", "activations", "=", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "(", "np", ".", "dot", "(", "x", ",", "self", ".", "w1", ")", "+", "np", ".", "ones", "(", "(", "n", ",", "1", ")", ")", "*", "self", ".", "b1", ")", ")", ")", "\n", "## }}", "\n", "self", ".", "out", "=", "np", ".", "dot", "(", "self", ".", "activations", ",", "self", ".", "w2", ")", "+", "np", ".", "ones", "(", "(", "n", ",", "1", ")", ")", "*", "self", ".", "b2", "\n", "return", "self", ".", "output_fn", "(", "self", ".", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.prior": [[54, 57], ["numpy.sum", "numpy.square", "MLP.MLP.pack"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.pack"], ["", "def", "prior", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"evaluate the current set of weights under the prior = return the log value\"\"\"", "\n", "return", "-", "0.5", "*", "self", ".", "alpha", "*", "np", ".", "sum", "(", "np", ".", "square", "(", "self", ".", "pack", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.prior_grad": [[58, 61], ["MLP.MLP.pack"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.pack"], ["", "def", "prior_grad", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"evaluate the gradient of the prior at the current set of weights\"\"\"", "\n", "return", "-", "self", ".", "alpha", "*", "self", ".", "pack", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.gradient": [[62, 68], ["MLP.MLP.unpack", "MLP.MLP.forward", "MLP.MLP.backpropagate", "MLP.MLP.prior_grad"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.unpack", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.forward", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.backpropagate", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.prior_grad"], ["", "def", "gradient", "(", "self", ",", "weights", ",", "x", ",", "t", ")", ":", "\n", "\t\t", "\"\"\"used for training\"\"\"", "\n", "self", ".", "unpack", "(", "weights", ")", "\n", "y", "=", "self", ".", "forward", "(", "x", ")", "\n", "delta_out", "=", "y", "-", "t", "#gradient of the error wrt output, y", "\n", "return", "self", ".", "backpropagate", "(", "x", ",", "delta_out", ")", "-", "self", ".", "prior_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.backpropagate": [[69, 100], ["numpy.dot", "numpy.sum", "numpy.dot", "numpy.dot", "numpy.sum", "numpy.hstack", "e.flatten"], "methods", ["None"], ["", "def", "backpropagate", "(", "self", ",", "x", ",", "delta_out", ")", ":", "\n", "\t\t", "\"\"\"'backpropagate' the gradeint of the error wrt to the output of the network to the gradient of the error wrt the weights\n\t\tEssentially doing de/dw = de/dy*dy/dw\"\"\"", "\n", "\n", "#Evaluate second-layer gradients.", "\n", "gw2", "=", "np", ".", "dot", "(", "self", ".", "activations", ".", "T", ",", "delta_out", ")", "\n", "gb2", "=", "np", ".", "sum", "(", "delta_out", ",", "0", ")", "\n", "\n", "# Backpropagation to hidden layer.", "\n", "delta_hid", "=", "np", ".", "dot", "(", "delta_out", ",", "self", ".", "w2", ".", "T", ")", "#de/dy * dy/d_acti", "\n", "# print delta_hid.shape", "\n", "\n", "##  {{", "\n", "# for tanh activation", "\n", "# delta_hid *= (1.0 - self.activations**2)", "\n", "\n", "# for ReLu activation", "\n", "# dzdsum = self.activations", "\n", "# dzdsum[dzdsum > 0] = 1", "\n", "# dzdsum[dzdsum < 0] = 0", "\n", "# delta_hid *= dzdsum", "\n", "\n", "## for logistic activation", "\n", "delta_hid", "*=", "(", "1.0", "-", "self", ".", "activations", ")", "*", "self", ".", "activations", "\n", "## }}", "\n", "\n", "# Finally, evaluate the first-layer gradients.", "\n", "gw1", "=", "np", ".", "dot", "(", "x", ".", "T", ",", "delta_hid", ")", "\n", "gb1", "=", "np", ".", "sum", "(", "delta_hid", ",", "0", ")", "\n", "\n", "return", "np", ".", "hstack", "(", "[", "e", ".", "flatten", "(", ")", "for", "e", "in", "[", "gw1", ",", "gb1", ",", "gw2", ",", "gb2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.error": [[101, 106], ["MLP.MLP.unpack", "MLP.MLP.forward", "MLP.MLP.error_fn", "MLP.MLP.prior"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.unpack", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.forward", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.prior"], ["", "def", "error", "(", "self", ",", "weights", ",", "x", ",", "t", ")", ":", "\n", "\t\t", "\"The thing to be optimised in training\"", "\"\"", "\n", "self", ".", "unpack", "(", "weights", ")", "\n", "y", "=", "self", ".", "forward", "(", "x", ")", "\n", "return", "self", ".", "error_fn", "(", "y", ",", "t", ")", "-", "self", ".", "prior", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.train": [[107, 110], ["scipy.optimize.fmin_cg", "MLP.MLP.unpack", "MLP.MLP.pack"], "methods", ["home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.unpack", "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.pack"], ["", "def", "train", "(", "self", ",", "x", ",", "t", ")", ":", "\n", "\t\t", "w", "=", "optimize", ".", "fmin_cg", "(", "self", ".", "error", ",", "self", ".", "pack", "(", ")", ",", "fprime", "=", "self", ".", "gradient", ",", "args", "=", "(", "x", ",", "t", ")", ",", "disp", "=", "0", ")", "\n", "self", ".", "unpack", "(", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.unpack": [[111, 118], ["weights.flatten.flatten.flatten", "weights[].reshape", "weights[].reshape", "weights[].reshape", "weights[].reshape"], "methods", ["None"], ["", "def", "unpack", "(", "self", ",", "weights", ")", ":", "\n", "\t\t", "\"\"\"take a np array and assign it to self.w1 etc.\"\"\"", "\n", "weights", "=", "weights", ".", "flatten", "(", ")", "\n", "self", ".", "w1", "=", "weights", "[", ":", "self", ".", "w1", ".", "size", "]", ".", "reshape", "(", "self", ".", "w1", ".", "shape", ")", "\n", "self", ".", "b1", "=", "weights", "[", "self", ".", "w1", ".", "size", ":", "self", ".", "w1", ".", "size", "+", "self", ".", "b1", ".", "size", "]", ".", "reshape", "(", "self", ".", "b1", ".", "shape", ")", "\n", "self", ".", "w2", "=", "weights", "[", "self", ".", "w1", ".", "size", "+", "self", ".", "b1", ".", "size", ":", "self", ".", "w1", ".", "size", "+", "self", ".", "b1", ".", "size", "+", "self", ".", "w2", ".", "size", "]", ".", "reshape", "(", "self", ".", "w2", ".", "shape", ")", "\n", "self", ".", "b2", "=", "weights", "[", "-", "self", ".", "b2", ".", "size", ":", "]", ".", "reshape", "(", "self", ".", "b2", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.amber0309_ANM-MM.None.MLP.MLP.pack": [[119, 122], ["numpy.hstack", "e.flatten"], "methods", ["None"], ["", "def", "pack", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" 'Pack up' the weights and biases into a vector\"\"\"", "\n", "return", "np", ".", "hstack", "(", "[", "e", ".", "flatten", "(", ")", "for", "e", "in", "[", "self", ".", "w1", ",", "self", ".", "b1", ",", "self", ".", "w2", ",", "self", ".", "b2", "]", "]", ")", "\n", "\n"]]}