{"home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.LabelSmoothingLoss.__init__": [[124, 131], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "label_smoothing", ",", "tgt_vocab_size", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "        ", "assert", "0.0", "<", "label_smoothing", "<=", "1.0", "\n", "super", "(", "LabelSmoothingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "eps", "=", "label_smoothing", "\n", "self", ".", "num_classes", "=", "tgt_vocab_size", "\n", "self", ".", "ignore_index", "=", "ignore_index", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.LabelSmoothingLoss.forward": [[132, 148], ["target.ne().float", "torch.one_hot().float", "torch.one_hot().float", "torch.one_hot().float", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "target.ne", "target.eq", "torch.one_hot", "torch.one_hot", "torch.one_hot"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        output (FloatTensor): (batch_size) x n_classes\n        target (LongTensor): batch_size\n        \"\"\"", "\n", "\n", "non_pad_mask", "=", "target", ".", "ne", "(", "self", ".", "ignore_index", ")", ".", "float", "(", ")", "\n", "\n", "target", "[", "target", ".", "eq", "(", "self", ".", "ignore_index", ")", "]", "=", "0", "\n", "one_hot", "=", "F", ".", "one_hot", "(", "target", ",", "num_classes", "=", "self", ".", "num_classes", ")", ".", "float", "(", ")", "\n", "one_hot", "=", "one_hot", "*", "(", "1", "-", "self", ".", "eps", ")", "+", "(", "1", "-", "one_hot", ")", "*", "self", ".", "eps", "/", "self", ".", "num_classes", "\n", "\n", "log_prb", "=", "F", ".", "log_softmax", "(", "output", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "-", "(", "one_hot", "*", "log_prb", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "loss", "=", "loss", "*", "non_pad_mask", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.softplus": [[9, 14], ["torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["def", "softplus", "(", "x", ",", "beta", ")", ":", "\n", "# hard thresholding at 20", "\n", "    ", "temp", "=", "beta", "*", "x", "\n", "temp", "[", "temp", ">", "20", "]", "=", "20", "\n", "return", "1.0", "/", "beta", "*", "torch", ".", "log", "(", "1", "+", "torch", ".", "exp", "(", "temp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.compute_event": [[16, 25], ["math.pow", "event.masked_fill_", "torch.log", "torch.log", "torch.log", "non_pad_mask.bool"], "function", ["None"], ["", "def", "compute_event", "(", "event", ",", "non_pad_mask", ")", ":", "\n", "    ", "\"\"\" Log-likelihood of events. \"\"\"", "\n", "\n", "# add 1e-9 in case some events have 0 likelihood", "\n", "event", "+=", "math", ".", "pow", "(", "10", ",", "-", "9", ")", "\n", "event", ".", "masked_fill_", "(", "~", "non_pad_mask", ".", "bool", "(", ")", ",", "1.0", ")", "\n", "\n", "result", "=", "torch", ".", "log", "(", "event", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.compute_integral_biased": [[27, 36], ["None"], "function", ["None"], ["", "def", "compute_integral_biased", "(", "all_lambda", ",", "time", ",", "non_pad_mask", ")", ":", "\n", "    ", "\"\"\" Log-likelihood of non-events, using linear interpolation. \"\"\"", "\n", "\n", "diff_time", "=", "(", "time", "[", ":", ",", "1", ":", "]", "-", "time", "[", ":", ",", ":", "-", "1", "]", ")", "*", "non_pad_mask", "[", ":", ",", "1", ":", "]", "\n", "diff_lambda", "=", "(", "all_lambda", "[", ":", ",", "1", ":", "]", "+", "all_lambda", "[", ":", ",", ":", "-", "1", "]", ")", "*", "non_pad_mask", "[", ":", ",", "1", ":", "]", "\n", "\n", "biased_integral", "=", "diff_lambda", "*", "diff_time", "\n", "result", "=", "0.5", "*", "biased_integral", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.compute_integral_unbiased": [[38, 56], ["torch.sum", "torch.sum", "torch.sum", "Utils.softplus", "diff_time.unsqueeze", "torch.rand", "torch.rand", "torch.rand", "model.linear", "torch.sum", "torch.sum", "torch.sum", "diff_time.size"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.softplus"], ["", "def", "compute_integral_unbiased", "(", "model", ",", "data", ",", "time", ",", "non_pad_mask", ",", "type_mask", ")", ":", "\n", "    ", "\"\"\" Log-likelihood of non-events, using Monte Carlo integration. \"\"\"", "\n", "\n", "num_samples", "=", "100", "\n", "\n", "diff_time", "=", "(", "time", "[", ":", ",", "1", ":", "]", "-", "time", "[", ":", ",", ":", "-", "1", "]", ")", "*", "non_pad_mask", "[", ":", ",", "1", ":", "]", "\n", "temp_time", "=", "diff_time", ".", "unsqueeze", "(", "2", ")", "*", "torch", ".", "rand", "(", "[", "*", "diff_time", ".", "size", "(", ")", ",", "num_samples", "]", ",", "device", "=", "data", ".", "device", ")", "\n", "temp_time", "/=", "(", "time", "[", ":", ",", ":", "-", "1", "]", "+", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "temp_hid", "=", "model", ".", "linear", "(", "data", ")", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "temp_hid", "=", "torch", ".", "sum", "(", "temp_hid", "*", "type_mask", "[", ":", ",", "1", ":", ",", ":", "]", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "\n", "all_lambda", "=", "softplus", "(", "temp_hid", "+", "model", ".", "alpha", "*", "temp_time", ",", "model", ".", "beta", ")", "\n", "all_lambda", "=", "torch", ".", "sum", "(", "all_lambda", ",", "dim", "=", "2", ")", "/", "num_samples", "\n", "\n", "unbiased_integral", "=", "all_lambda", "*", "diff_time", "\n", "return", "unbiased_integral", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.log_likelihood": [[58, 81], ["transformer.Models.get_non_pad_mask().squeeze", "torch.zeros", "torch.zeros", "torch.zeros", "range", "model.linear", "Utils.softplus", "torch.sum", "torch.sum", "torch.sum", "Utils.compute_event", "torch.sum", "torch.sum", "torch.sum", "Utils.compute_integral_unbiased", "torch.sum", "torch.sum", "torch.sum", "transformer.Models.get_non_pad_mask", "types.size"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.softplus", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.compute_event", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.compute_integral_unbiased", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_non_pad_mask"], ["", "def", "log_likelihood", "(", "model", ",", "data", ",", "time", ",", "types", ")", ":", "\n", "    ", "\"\"\" Log-likelihood of sequence. \"\"\"", "\n", "\n", "non_pad_mask", "=", "get_non_pad_mask", "(", "types", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "type_mask", "=", "torch", ".", "zeros", "(", "[", "*", "types", ".", "size", "(", ")", ",", "model", ".", "num_types", "]", ",", "device", "=", "data", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "model", ".", "num_types", ")", ":", "\n", "        ", "type_mask", "[", ":", ",", ":", ",", "i", "]", "=", "(", "types", "==", "i", "+", "1", ")", ".", "bool", "(", ")", ".", "to", "(", "data", ".", "device", ")", "\n", "\n", "", "all_hid", "=", "model", ".", "linear", "(", "data", ")", "\n", "all_lambda", "=", "softplus", "(", "all_hid", ",", "model", ".", "beta", ")", "\n", "type_lambda", "=", "torch", ".", "sum", "(", "all_lambda", "*", "type_mask", ",", "dim", "=", "2", ")", "\n", "\n", "# event log-likelihood", "\n", "event_ll", "=", "compute_event", "(", "type_lambda", ",", "non_pad_mask", ")", "\n", "event_ll", "=", "torch", ".", "sum", "(", "event_ll", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# non-event log-likelihood, either numerical integration or MC integration", "\n", "# non_event_ll = compute_integral_biased(type_lambda, time, non_pad_mask)", "\n", "non_event_ll", "=", "compute_integral_unbiased", "(", "model", ",", "data", ",", "time", ",", "non_pad_mask", ",", "type_mask", ")", "\n", "non_event_ll", "=", "torch", ".", "sum", "(", "non_event_ll", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "event_ll", ",", "non_event_ll", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.type_loss": [[83, 101], ["torch.sum", "torch.sum", "torch.sum", "isinstance", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "loss_func", "loss_func", "prediction.transpose"], "function", ["None"], ["", "def", "type_loss", "(", "prediction", ",", "types", ",", "loss_func", ")", ":", "\n", "    ", "\"\"\" Event prediction loss, cross entropy or label smoothing. \"\"\"", "\n", "\n", "# convert [1,2,3] based types to [0,1,2]; also convert padding events to -1", "\n", "truth", "=", "types", "[", ":", ",", "1", ":", "]", "-", "1", "\n", "prediction", "=", "prediction", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "\n", "pred_type", "=", "torch", ".", "max", "(", "prediction", ",", "dim", "=", "-", "1", ")", "[", "1", "]", "\n", "correct_num", "=", "torch", ".", "sum", "(", "pred_type", "==", "truth", ")", "\n", "\n", "# compute cross entropy loss", "\n", "if", "isinstance", "(", "loss_func", ",", "LabelSmoothingLoss", ")", ":", "\n", "        ", "loss", "=", "loss_func", "(", "prediction", ",", "truth", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "loss_func", "(", "prediction", ".", "transpose", "(", "1", ",", "2", ")", ",", "truth", ")", "\n", "\n", "", "loss", "=", "torch", ".", "sum", "(", "loss", ")", "\n", "return", "loss", ",", "correct_num", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.time_loss": [[103, 115], ["prediction.squeeze_", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "time_loss", "(", "prediction", ",", "event_time", ")", ":", "\n", "    ", "\"\"\" Time prediction loss. \"\"\"", "\n", "\n", "prediction", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "true", "=", "event_time", "[", ":", ",", "1", ":", "]", "-", "event_time", "[", ":", ",", ":", "-", "1", "]", "\n", "prediction", "=", "prediction", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# event time gap prediction", "\n", "diff", "=", "prediction", "-", "true", "\n", "se", "=", "torch", ".", "sum", "(", "diff", "*", "diff", ")", "\n", "return", "se", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.prepare_dataloader": [[17, 37], ["print", "Main.prepare_dataloader.load_data"], "function", ["None"], ["def", "prepare_dataloader", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Load data and prepare dataloader. \"\"\"", "\n", "\n", "def", "load_data", "(", "name", ",", "dict_name", ")", ":", "\n", "        ", "with", "open", "(", "name", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin-1'", ")", "\n", "num_types", "=", "data", "[", "'dim_process'", "]", "\n", "data", "=", "data", "[", "dict_name", "]", "\n", "return", "data", ",", "int", "(", "num_types", ")", "\n", "\n", "", "", "print", "(", "'[Info] Loading train data...'", ")", "\n", "train_data", ",", "num_types", "=", "load_data", "(", "opt", ".", "data", "+", "'train.pkl'", ",", "'train'", ")", "\n", "print", "(", "'[Info] Loading dev data...'", ")", "\n", "dev_data", ",", "_", "=", "load_data", "(", "opt", ".", "data", "+", "'dev.pkl'", ",", "'dev'", ")", "\n", "print", "(", "'[Info] Loading test data...'", ")", "\n", "test_data", ",", "_", "=", "load_data", "(", "opt", ".", "data", "+", "'test.pkl'", ",", "'test'", ")", "\n", "\n", "trainloader", "=", "get_dataloader", "(", "train_data", ",", "opt", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "testloader", "=", "get_dataloader", "(", "test_data", ",", "opt", ".", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "return", "trainloader", ",", "testloader", ",", "num_types", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.train_epoch": [[39, 88], ["model.train", "tqdm.tqdm", "numpy.sqrt", "map", "optimizer.zero_grad", "model", "Utils.log_likelihood", "Utils.type_loss", "Utils.time_loss", "loss.backward", "optimizer.step", "Utils.time_loss.item", "pred_num_event.item", "event_type.ne().sum().item", "torch.sum", "torch.sum", "torch.sum", "event_loss.item", "event_type.ne().sum().item", "x.to", "event_type.ne().sum", "event_type.ne().sum", "event_type.ne", "event_type.ne"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.train", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.log_likelihood", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.type_loss", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.time_loss"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "pred_loss_func", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Epoch operation in training phase. \"\"\"", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "total_event_ll", "=", "0", "# cumulative event log-likelihood", "\n", "total_time_se", "=", "0", "# cumulative time prediction squared-error", "\n", "total_event_rate", "=", "0", "# cumulative number of correct prediction", "\n", "total_num_event", "=", "0", "# number of total events", "\n", "total_num_pred", "=", "0", "# number of predictions", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "\n", "desc", "=", "'  - (Training)   '", ",", "leave", "=", "False", ")", ":", "\n", "        ", "\"\"\" prepare data \"\"\"", "\n", "event_time", ",", "time_gap", ",", "event_type", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "opt", ".", "device", ")", ",", "batch", ")", "\n", "\n", "\"\"\" forward \"\"\"", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "enc_out", ",", "prediction", "=", "model", "(", "event_type", ",", "event_time", ")", "\n", "\n", "\"\"\" backward \"\"\"", "\n", "# negative log-likelihood", "\n", "event_ll", ",", "non_event_ll", "=", "Utils", ".", "log_likelihood", "(", "model", ",", "enc_out", ",", "event_time", ",", "event_type", ")", "\n", "event_loss", "=", "-", "torch", ".", "sum", "(", "event_ll", "-", "non_event_ll", ")", "\n", "\n", "# type prediction", "\n", "pred_loss", ",", "pred_num_event", "=", "Utils", ".", "type_loss", "(", "prediction", "[", "0", "]", ",", "event_type", ",", "pred_loss_func", ")", "\n", "\n", "# time prediction", "\n", "se", "=", "Utils", ".", "time_loss", "(", "prediction", "[", "1", "]", ",", "event_time", ")", "\n", "\n", "# SE is usually large, scale it to stabilize training", "\n", "scale_time_loss", "=", "100", "\n", "loss", "=", "event_loss", "+", "pred_loss", "+", "se", "/", "scale_time_loss", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "\"\"\" update parameters \"\"\"", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "\"\"\" note keeping \"\"\"", "\n", "total_event_ll", "+=", "-", "event_loss", ".", "item", "(", ")", "\n", "total_time_se", "+=", "se", ".", "item", "(", ")", "\n", "total_event_rate", "+=", "pred_num_event", ".", "item", "(", ")", "\n", "total_num_event", "+=", "event_type", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# we do not predict the first event", "\n", "total_num_pred", "+=", "event_type", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "-", "event_time", ".", "shape", "[", "0", "]", "\n", "\n", "", "rmse", "=", "np", ".", "sqrt", "(", "total_time_se", "/", "total_num_pred", ")", "\n", "return", "total_event_ll", "/", "total_num_event", ",", "total_event_rate", "/", "total_num_pred", ",", "rmse", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.eval_epoch": [[90, 124], ["model.eval", "numpy.sqrt", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "Utils.log_likelihood", "Utils.type_loss", "Utils.time_loss", "Utils.time_loss.item", "pred_num.item", "event_type.ne().sum().item", "torch.sum", "torch.sum", "torch.sum", "event_loss.item", "event_type.ne().sum().item", "x.to", "event_type.ne().sum", "event_type.ne().sum", "event_type.ne", "event_type.ne"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.log_likelihood", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.type_loss", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Utils.time_loss"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "pred_loss_func", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Epoch operation in evaluation phase. \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "total_event_ll", "=", "0", "# cumulative event log-likelihood", "\n", "total_time_se", "=", "0", "# cumulative time prediction squared-error", "\n", "total_event_rate", "=", "0", "# cumulative number of correct prediction", "\n", "total_num_event", "=", "0", "# number of total events", "\n", "total_num_pred", "=", "0", "# number of predictions", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "\n", "desc", "=", "'  - (Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "            ", "\"\"\" prepare data \"\"\"", "\n", "event_time", ",", "time_gap", ",", "event_type", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "opt", ".", "device", ")", ",", "batch", ")", "\n", "\n", "\"\"\" forward \"\"\"", "\n", "enc_out", ",", "prediction", "=", "model", "(", "event_type", ",", "event_time", ")", "\n", "\n", "\"\"\" compute loss \"\"\"", "\n", "event_ll", ",", "non_event_ll", "=", "Utils", ".", "log_likelihood", "(", "model", ",", "enc_out", ",", "event_time", ",", "event_type", ")", "\n", "event_loss", "=", "-", "torch", ".", "sum", "(", "event_ll", "-", "non_event_ll", ")", "\n", "_", ",", "pred_num", "=", "Utils", ".", "type_loss", "(", "prediction", "[", "0", "]", ",", "event_type", ",", "pred_loss_func", ")", "\n", "se", "=", "Utils", ".", "time_loss", "(", "prediction", "[", "1", "]", ",", "event_time", ")", "\n", "\n", "\"\"\" note keeping \"\"\"", "\n", "total_event_ll", "+=", "-", "event_loss", ".", "item", "(", ")", "\n", "total_time_se", "+=", "se", ".", "item", "(", ")", "\n", "total_event_rate", "+=", "pred_num", ".", "item", "(", ")", "\n", "total_num_event", "+=", "event_type", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "total_num_pred", "+=", "event_type", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "-", "event_time", ".", "shape", "[", "0", "]", "\n", "\n", "", "", "rmse", "=", "np", ".", "sqrt", "(", "total_time_se", "/", "total_num_pred", ")", "\n", "return", "total_event_ll", "/", "total_num_event", ",", "total_event_rate", "/", "total_num_pred", ",", "rmse", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.train": [[126, 163], ["range", "print", "time.time", "Main.train_epoch", "print", "time.time", "Main.eval_epoch", "print", "print", "scheduler.step", "open", "f.write", "max", "max", "min", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.train_epoch", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.eval_epoch"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "pred_loss_func", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Start training. \"\"\"", "\n", "\n", "valid_event_losses", "=", "[", "]", "# validation log-likelihood", "\n", "valid_pred_losses", "=", "[", "]", "# validation event type prediction accuracy", "\n", "valid_rmse", "=", "[", "]", "# validation event time prediction RMSE", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "epoch", "=", "epoch_i", "+", "1", "\n", "print", "(", "'[ Epoch'", ",", "epoch", ",", "']'", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_event", ",", "train_type", ",", "train_time", "=", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "pred_loss_func", ",", "opt", ")", "\n", "print", "(", "'  - (Training)    loglikelihood: {ll: 8.5f}, '", "\n", "'accuracy: {type: 8.5f}, RMSE: {rmse: 8.5f}, '", "\n", "'elapse: {elapse:3.3f} min'", "\n", ".", "format", "(", "ll", "=", "train_event", ",", "type", "=", "train_type", ",", "rmse", "=", "train_time", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_event", ",", "valid_type", ",", "valid_time", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "pred_loss_func", ",", "opt", ")", "\n", "print", "(", "'  - (Testing)     loglikelihood: {ll: 8.5f}, '", "\n", "'accuracy: {type: 8.5f}, RMSE: {rmse: 8.5f}, '", "\n", "'elapse: {elapse:3.3f} min'", "\n", ".", "format", "(", "ll", "=", "valid_event", ",", "type", "=", "valid_type", ",", "rmse", "=", "valid_time", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "\n", "valid_event_losses", "+=", "[", "valid_event", "]", "\n", "valid_pred_losses", "+=", "[", "valid_type", "]", "\n", "valid_rmse", "+=", "[", "valid_time", "]", "\n", "print", "(", "'  - [Info] Maximum ll: {event: 8.5f}, '", "\n", "'Maximum accuracy: {pred: 8.5f}, Minimum RMSE: {rmse: 8.5f}'", "\n", ".", "format", "(", "event", "=", "max", "(", "valid_event_losses", ")", ",", "pred", "=", "max", "(", "valid_pred_losses", ")", ",", "rmse", "=", "min", "(", "valid_rmse", ")", ")", ")", "\n", "\n", "# logging", "\n", "with", "open", "(", "opt", ".", "log", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'{epoch}, {ll: 8.5f}, {acc: 8.5f}, {rmse: 8.5f}\\n'", "\n", ".", "format", "(", "epoch", "=", "epoch", ",", "ll", "=", "valid_event", ",", "acc", "=", "valid_type", ",", "rmse", "=", "valid_time", ")", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.main": [[165, 235], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "torch.device", "torch.device", "print", "Main.prepare_dataloader", "transformer.Models.Transformer", "transformer.Models.Transformer.to", "torch.Adam", "torch.lr_scheduler.StepLR", "sum", "print", "Main.train", "open", "f.write", "filter", "Utils.LabelSmoothingLoss", "torch.CrossEntropyLoss", "transformer.Models.Transformer.parameters", "p.numel", "transformer.Models.Transformer.parameters"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.prepare_dataloader", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.None.Main.train"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "\"\"\" Main function. \"\"\"", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "30", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-d_model'", ",", "type", "=", "int", ",", "default", "=", "64", ")", "\n", "parser", ".", "add_argument", "(", "'-d_rnn'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'-d_inner_hid'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-d_k'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "parser", ".", "add_argument", "(", "'-d_v'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_head'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'-n_layers'", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "'-lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ")", "\n", "parser", ".", "add_argument", "(", "'-smooth'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "type", "=", "str", ",", "default", "=", "'log.txt'", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# default device is CUDA", "\n", "opt", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# setup the log file", "\n", "with", "open", "(", "opt", ".", "log", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "'Epoch, Log-likelihood, Accuracy, RMSE\\n'", ")", "\n", "\n", "", "print", "(", "'[Info] parameters: {}'", ".", "format", "(", "opt", ")", ")", "\n", "\n", "\"\"\" prepare dataloader \"\"\"", "\n", "trainloader", ",", "testloader", ",", "num_types", "=", "prepare_dataloader", "(", "opt", ")", "\n", "\n", "\"\"\" prepare model \"\"\"", "\n", "model", "=", "Transformer", "(", "\n", "num_types", "=", "num_types", ",", "\n", "d_model", "=", "opt", ".", "d_model", ",", "\n", "d_rnn", "=", "opt", ".", "d_rnn", ",", "\n", "d_inner", "=", "opt", ".", "d_inner_hid", ",", "\n", "n_layers", "=", "opt", ".", "n_layers", ",", "\n", "n_head", "=", "opt", ".", "n_head", ",", "\n", "d_k", "=", "opt", ".", "d_k", ",", "\n", "d_v", "=", "opt", ".", "d_v", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", ")", "\n", "model", ".", "to", "(", "opt", ".", "device", ")", "\n", "\n", "\"\"\" optimizer and scheduler \"\"\"", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "\n", "opt", ".", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-05", ")", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "10", ",", "gamma", "=", "0.5", ")", "\n", "\n", "\"\"\" prediction loss function, either cross entropy or label smoothing \"\"\"", "\n", "if", "opt", ".", "smooth", ">", "0", ":", "\n", "        ", "pred_loss_func", "=", "Utils", ".", "LabelSmoothingLoss", "(", "opt", ".", "smooth", ",", "num_types", ",", "ignore_index", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "pred_loss_func", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ",", "reduction", "=", "'none'", ")", "\n", "\n", "", "\"\"\" number of parameters \"\"\"", "\n", "num_params", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "print", "(", "'[Info] Number of parameters: {}'", ".", "format", "(", "num_params", ")", ")", "\n", "\n", "\"\"\" train the model \"\"\"", "\n", "train", "(", "model", ",", "trainloader", ",", "testloader", ",", "optimizer", ",", "scheduler", ",", "pred_loss_func", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Modules.ScaledDotProductAttention.__init__": [[9, 14], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "temperature", ",", "attn_dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Modules.ScaledDotProductAttention.forward": [[15, 25], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "Modules.ScaledDotProductAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "k.transpose", "attn.masked_fill.masked_fill.masked_fill", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "        ", "attn", "=", "torch", ".", "matmul", "(", "q", "/", "self", ".", "temperature", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", ",", "-", "1e9", ")", "\n", "\n", "", "attn", "=", "self", ".", "dropout", "(", "F", ".", "softmax", "(", "attn", ",", "dim", "=", "-", "1", ")", ")", "\n", "output", "=", "torch", ".", "matmul", "(", "attn", ",", "v", ")", "\n", "\n", "return", "output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Layers.EncoderLayer.__init__": [[9, 15], ["torch.Module.__init__", "transformer.SubLayers.MultiHeadAttention", "transformer.SubLayers.PositionwiseFeedForward"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "normalize_before", "=", "True", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "slf_attn", "=", "MultiHeadAttention", "(", "\n", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ",", "normalize_before", "=", "normalize_before", ")", "\n", "self", ".", "pos_ffn", "=", "PositionwiseFeedForward", "(", "\n", "d_model", ",", "d_inner", ",", "dropout", "=", "dropout", ",", "normalize_before", "=", "normalize_before", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Layers.EncoderLayer.forward": [[16, 25], ["Layers.EncoderLayer.slf_attn", "Layers.EncoderLayer.pos_ffn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "enc_input", ",", "non_pad_mask", "=", "None", ",", "slf_attn_mask", "=", "None", ")", ":", "\n", "        ", "enc_output", ",", "enc_slf_attn", "=", "self", ".", "slf_attn", "(", "\n", "enc_input", ",", "enc_input", ",", "enc_input", ",", "mask", "=", "slf_attn_mask", ")", "\n", "enc_output", "*=", "non_pad_mask", "\n", "\n", "enc_output", "=", "self", ".", "pos_ffn", "(", "enc_output", ")", "\n", "enc_output", "*=", "non_pad_mask", "\n", "\n", "return", "enc_output", ",", "enc_slf_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Encoder.__init__": [[41, 60], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "math.pow", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "transformer.Layers.EncoderLayer", "range", "range"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_types", ",", "d_model", ",", "d_inner", ",", "\n", "n_layers", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n", "# position vector, used for temporal encoding", "\n", "self", ".", "position_vec", "=", "torch", ".", "tensor", "(", "\n", "[", "math", ".", "pow", "(", "10000.0", ",", "2.0", "*", "(", "i", "//", "2", ")", "/", "d_model", ")", "for", "i", "in", "range", "(", "d_model", ")", "]", ",", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "\n", "# event type embedding", "\n", "self", ".", "event_emb", "=", "nn", ".", "Embedding", "(", "num_types", "+", "1", ",", "d_model", ",", "padding_idx", "=", "Constants", ".", "PAD", ")", "\n", "\n", "self", ".", "layer_stack", "=", "nn", ".", "ModuleList", "(", "[", "\n", "EncoderLayer", "(", "d_model", ",", "d_inner", ",", "n_head", ",", "d_k", ",", "d_v", ",", "dropout", "=", "dropout", ",", "normalize_before", "=", "False", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Encoder.temporal_enc": [[61, 71], ["torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "time.unsqueeze"], "methods", ["None"], ["", "def", "temporal_enc", "(", "self", ",", "time", ",", "non_pad_mask", ")", ":", "\n", "        ", "\"\"\"\n        Input: batch*seq_len.\n        Output: batch*seq_len*d_model.\n        \"\"\"", "\n", "\n", "result", "=", "time", ".", "unsqueeze", "(", "-", "1", ")", "/", "self", ".", "position_vec", "\n", "result", "[", ":", ",", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "result", "[", ":", ",", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "result", "[", ":", ",", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "result", "[", ":", ",", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "return", "result", "*", "non_pad_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Encoder.forward": [[72, 92], ["Models.get_subsequent_mask", "Models.get_attn_key_pad_mask", "slf_attn_mask_keypad.type_as.type_as.type_as", "Models.Encoder.temporal_enc", "Models.Encoder.event_emb", "enc_layer"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_subsequent_mask", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_attn_key_pad_mask", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Encoder.temporal_enc"], ["", "def", "forward", "(", "self", ",", "event_type", ",", "event_time", ",", "non_pad_mask", ")", ":", "\n", "        ", "\"\"\" Encode event sequences via masked self-attention. \"\"\"", "\n", "\n", "# prepare attention masks", "\n", "# slf_attn_mask is where we cannot look, i.e., the future and the padding", "\n", "slf_attn_mask_subseq", "=", "get_subsequent_mask", "(", "event_type", ")", "\n", "slf_attn_mask_keypad", "=", "get_attn_key_pad_mask", "(", "seq_k", "=", "event_type", ",", "seq_q", "=", "event_type", ")", "\n", "slf_attn_mask_keypad", "=", "slf_attn_mask_keypad", ".", "type_as", "(", "slf_attn_mask_subseq", ")", "\n", "slf_attn_mask", "=", "(", "slf_attn_mask_keypad", "+", "slf_attn_mask_subseq", ")", ".", "gt", "(", "0", ")", "\n", "\n", "tem_enc", "=", "self", ".", "temporal_enc", "(", "event_time", ",", "non_pad_mask", ")", "\n", "enc_output", "=", "self", ".", "event_emb", "(", "event_type", ")", "\n", "\n", "for", "enc_layer", "in", "self", ".", "layer_stack", ":", "\n", "            ", "enc_output", "+=", "tem_enc", "\n", "enc_output", ",", "_", "=", "enc_layer", "(", "\n", "enc_output", ",", "\n", "non_pad_mask", "=", "non_pad_mask", ",", "\n", "slf_attn_mask", "=", "slf_attn_mask", ")", "\n", "", "return", "enc_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Predictor.__init__": [[97, 102], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "num_types", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "dim", ",", "num_types", ",", "bias", "=", "False", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "linear", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Predictor.forward": [[103, 107], ["Models.Predictor.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "data", ",", "non_pad_mask", ")", ":", "\n", "        ", "out", "=", "self", ".", "linear", "(", "data", ")", "\n", "out", "=", "out", "*", "non_pad_mask", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.RNN_layers.__init__": [[115, 120], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_rnn", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "d_model", ",", "d_rnn", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "projection", "=", "nn", ".", "Linear", "(", "d_rnn", ",", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.RNN_layers.forward": [[121, 130], ["non_pad_mask.squeeze().long().sum().cpu", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "Models.RNN_layers.projection", "Models.RNN_layers.rnn", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "non_pad_mask.squeeze().long().sum", "non_pad_mask.squeeze().long", "non_pad_mask.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "data", ",", "non_pad_mask", ")", ":", "\n", "        ", "lengths", "=", "non_pad_mask", ".", "squeeze", "(", "2", ")", ".", "long", "(", ")", ".", "sum", "(", "1", ")", ".", "cpu", "(", ")", "\n", "pack_enc_output", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "\n", "data", ",", "lengths", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", ")", "\n", "temp", "=", "self", ".", "rnn", "(", "pack_enc_output", ")", "[", "0", "]", "\n", "out", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "temp", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "\n", "out", "=", "self", ".", "projection", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Transformer.__init__": [[135, 171], ["torch.Module.__init__", "Models.Encoder", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "Models.RNN_layers", "Models.Predictor", "Models.Predictor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_types", ",", "d_model", "=", "256", ",", "d_rnn", "=", "128", ",", "d_inner", "=", "1024", ",", "\n", "n_layers", "=", "4", ",", "n_head", "=", "4", ",", "d_k", "=", "64", ",", "d_v", "=", "64", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "Encoder", "(", "\n", "num_types", "=", "num_types", ",", "\n", "d_model", "=", "d_model", ",", "\n", "d_inner", "=", "d_inner", ",", "\n", "n_layers", "=", "n_layers", ",", "\n", "n_head", "=", "n_head", ",", "\n", "d_k", "=", "d_k", ",", "\n", "d_v", "=", "d_v", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "\n", "self", ".", "num_types", "=", "num_types", "\n", "\n", "# convert hidden vectors into a scalar", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "d_model", ",", "num_types", ")", "\n", "\n", "# parameter for the weight of time difference", "\n", "self", ".", "alpha", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "-", "0.1", ")", ")", "\n", "\n", "# parameter for the softplus function", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "\n", "# OPTIONAL recurrent layer, this sometimes helps", "\n", "self", ".", "rnn", "=", "RNN_layers", "(", "d_model", ",", "d_rnn", ")", "\n", "\n", "# prediction of next time stamp", "\n", "self", ".", "time_predictor", "=", "Predictor", "(", "d_model", ",", "1", ")", "\n", "\n", "# prediction of next event type", "\n", "self", ".", "type_predictor", "=", "Predictor", "(", "d_model", ",", "num_types", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.Transformer.forward": [[172, 193], ["Models.get_non_pad_mask", "Models.Transformer.encoder", "Models.Transformer.rnn", "Models.Transformer.time_predictor", "Models.Transformer.type_predictor"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_non_pad_mask"], ["", "def", "forward", "(", "self", ",", "event_type", ",", "event_time", ")", ":", "\n", "        ", "\"\"\"\n        Return the hidden representations and predictions.\n        For a sequence (l_1, l_2, ..., l_N), we predict (l_2, ..., l_N, l_{N+1}).\n        Input: event_type: batch*seq_len;\n               event_time: batch*seq_len.\n        Output: enc_output: batch*seq_len*model_dim;\n                type_prediction: batch*seq_len*num_classes (not normalized);\n                time_prediction: batch*seq_len.\n        \"\"\"", "\n", "\n", "non_pad_mask", "=", "get_non_pad_mask", "(", "event_type", ")", "\n", "\n", "enc_output", "=", "self", ".", "encoder", "(", "event_type", ",", "event_time", ",", "non_pad_mask", ")", "\n", "enc_output", "=", "self", ".", "rnn", "(", "enc_output", ",", "non_pad_mask", ")", "\n", "\n", "time_prediction", "=", "self", ".", "time_predictor", "(", "enc_output", ",", "non_pad_mask", ")", "\n", "\n", "type_prediction", "=", "self", ".", "type_predictor", "(", "enc_output", ",", "non_pad_mask", ")", "\n", "\n", "return", "enc_output", ",", "(", "type_prediction", ",", "time_prediction", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_non_pad_mask": [[11, 16], ["seq.ne().type().unsqueeze", "seq.dim", "seq.ne().type", "seq.ne"], "function", ["None"], ["def", "get_non_pad_mask", "(", "seq", ")", ":", "\n", "    ", "\"\"\" Get the non-padding positions. \"\"\"", "\n", "\n", "assert", "seq", ".", "dim", "(", ")", "==", "2", "\n", "return", "seq", ".", "ne", "(", "Constants", ".", "PAD", ")", ".", "type", "(", "torch", ".", "float", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_attn_key_pad_mask": [[18, 26], ["seq_q.size", "seq_k.eq", "padding_mask.unsqueeze().expand.unsqueeze().expand", "padding_mask.unsqueeze().expand.unsqueeze"], "function", ["None"], ["", "def", "get_attn_key_pad_mask", "(", "seq_k", ",", "seq_q", ")", ":", "\n", "    ", "\"\"\" For masking out the padding part of key sequence. \"\"\"", "\n", "\n", "# expand to fit the shape of key query attention matrix", "\n", "len_q", "=", "seq_q", ".", "size", "(", "1", ")", "\n", "padding_mask", "=", "seq_k", ".", "eq", "(", "Constants", ".", "PAD", ")", "\n", "padding_mask", "=", "padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "len_q", ",", "-", "1", ")", "# b x lq x lk", "\n", "return", "padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.Models.get_subsequent_mask": [[28, 36], ["seq.size", "torch.triu", "torch.triu", "torch.triu", "subsequent_mask.unsqueeze().expand.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "subsequent_mask.unsqueeze().expand.unsqueeze"], "function", ["None"], ["", "def", "get_subsequent_mask", "(", "seq", ")", ":", "\n", "    ", "\"\"\" For masking out the subsequent info, i.e., masked self-attention. \"\"\"", "\n", "\n", "sz_b", ",", "len_s", "=", "seq", ".", "size", "(", ")", "\n", "subsequent_mask", "=", "torch", ".", "triu", "(", "\n", "torch", ".", "ones", "(", "(", "len_s", ",", "len_s", ")", ",", "device", "=", "seq", ".", "device", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "diagonal", "=", "1", ")", "\n", "subsequent_mask", "=", "subsequent_mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "sz_b", ",", "-", "1", ",", "-", "1", ")", "# b x ls x ls", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.SubLayers.MultiHeadAttention.__init__": [[13, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "transformer.Modules.ScaledDotProductAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_k", ",", "d_v", ",", "dropout", "=", "0.1", ",", "normalize_before", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "normalize_before", "=", "normalize_before", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_k", "=", "d_k", "\n", "self", ".", "d_v", "=", "d_v", "\n", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_k", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_vs", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_v", ",", "bias", "=", "False", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "w_qs", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "w_ks", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "w_vs", ".", "weight", ")", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "d_v", "*", "n_head", ",", "d_model", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "fc", ".", "weight", ")", "\n", "\n", "self", ".", "attention", "=", "ScaledDotProductAttention", "(", "temperature", "=", "d_k", "**", "0.5", ",", "attn_dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.SubLayers.MultiHeadAttention.forward": [[36, 67], ["SubLayers.MultiHeadAttention.w_qs().view", "SubLayers.MultiHeadAttention.w_ks().view", "SubLayers.MultiHeadAttention.w_vs().view", "SubLayers.MultiHeadAttention.attention", "SubLayers.MultiHeadAttention.transpose().contiguous().view", "SubLayers.MultiHeadAttention.dropout", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.size", "SubLayers.MultiHeadAttention.layer_norm", "SubLayers.MultiHeadAttention.transpose", "SubLayers.MultiHeadAttention.transpose", "SubLayers.MultiHeadAttention.transpose", "mask.unsqueeze.unsqueeze.unsqueeze", "SubLayers.MultiHeadAttention.fc", "SubLayers.MultiHeadAttention.layer_norm", "SubLayers.MultiHeadAttention.w_qs", "SubLayers.MultiHeadAttention.w_ks", "SubLayers.MultiHeadAttention.w_vs", "SubLayers.MultiHeadAttention.transpose().contiguous", "SubLayers.MultiHeadAttention.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "        ", "d_k", ",", "d_v", ",", "n_head", "=", "self", ".", "d_k", ",", "self", ".", "d_v", ",", "self", ".", "n_head", "\n", "sz_b", ",", "len_q", ",", "len_k", ",", "len_v", "=", "q", ".", "size", "(", "0", ")", ",", "q", ".", "size", "(", "1", ")", ",", "k", ".", "size", "(", "1", ")", ",", "v", ".", "size", "(", "1", ")", "\n", "\n", "residual", "=", "q", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "q", "=", "self", ".", "layer_norm", "(", "q", ")", "\n", "\n", "# Pass through the pre-attention projection: b x lq x (n*dv)", "\n", "# Separate different heads: b x lq x n x dv", "\n", "", "q", "=", "self", ".", "w_qs", "(", "q", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "n_head", ",", "d_k", ")", "\n", "k", "=", "self", ".", "w_ks", "(", "k", ")", ".", "view", "(", "sz_b", ",", "len_k", ",", "n_head", ",", "d_k", ")", "\n", "v", "=", "self", ".", "w_vs", "(", "v", ")", ".", "view", "(", "sz_b", ",", "len_v", ",", "n_head", ",", "d_v", ")", "\n", "\n", "# Transpose for attention dot product: b x n x lq x dv", "\n", "q", ",", "k", ",", "v", "=", "q", ".", "transpose", "(", "1", ",", "2", ")", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# For head axis broadcasting.", "\n", "\n", "", "output", ",", "attn", "=", "self", ".", "attention", "(", "q", ",", "k", ",", "v", ",", "mask", "=", "mask", ")", "\n", "\n", "# Transpose to move the head dimension back: b x lq x n x dv", "\n", "# Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)", "\n", "output", "=", "output", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "sz_b", ",", "len_q", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "dropout", "(", "self", ".", "fc", "(", "output", ")", ")", "\n", "output", "+=", "residual", "\n", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "", "return", "output", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.SubLayers.PositionwiseFeedForward.__init__": [[72, 82], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__"], ["def", "__init__", "(", "self", ",", "d_in", ",", "d_hid", ",", "dropout", "=", "0.1", ",", "normalize_before", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "normalize_before", "=", "normalize_before", "\n", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_in", ",", "d_hid", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_hid", ",", "d_in", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_in", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.transformer.SubLayers.PositionwiseFeedForward.forward": [[83, 97], ["torch.gelu", "torch.gelu", "torch.gelu", "SubLayers.PositionwiseFeedForward.dropout", "SubLayers.PositionwiseFeedForward.w_2", "SubLayers.PositionwiseFeedForward.dropout", "SubLayers.PositionwiseFeedForward.layer_norm", "SubLayers.PositionwiseFeedForward.w_1", "SubLayers.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "if", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "", "x", "=", "F", ".", "gelu", "(", "self", ".", "w_1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "w_2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "x", "+", "residual", "\n", "\n", "if", "not", "self", ".", "normalize_before", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__init__": [[11, 22], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Data should be a list of event streams; each event stream is a list of dictionaries;\n        each dictionary contains: time_since_start, time_since_last_event, type_event\n        \"\"\"", "\n", "self", ".", "time", "=", "[", "[", "elem", "[", "'time_since_start'", "]", "for", "elem", "in", "inst", "]", "for", "inst", "in", "data", "]", "\n", "self", ".", "time_gap", "=", "[", "[", "elem", "[", "'time_since_last_event'", "]", "for", "elem", "in", "inst", "]", "for", "inst", "in", "data", "]", "\n", "# plus 1 since there could be event type 0, but we use 0 as padding", "\n", "self", ".", "event_type", "=", "[", "[", "elem", "[", "'type_event'", "]", "+", "1", "for", "elem", "in", "inst", "]", "for", "inst", "in", "data", "]", "\n", "\n", "self", ".", "length", "=", "len", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__len__": [[23, 25], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.EventData.__getitem__": [[26, 29], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\" Each returned element is a list, which represents an event stream \"\"\"", "\n", "return", "self", ".", "time", "[", "idx", "]", ",", "self", ".", "time_gap", "[", "idx", "]", ",", "self", ".", "event_type", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.pad_time": [[31, 41], ["max", "numpy.array", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "", "def", "pad_time", "(", "insts", ")", ":", "\n", "    ", "\"\"\" Pad the instance to the max seq length in batch. \"\"\"", "\n", "\n", "max_len", "=", "max", "(", "len", "(", "inst", ")", "for", "inst", "in", "insts", ")", "\n", "\n", "batch_seq", "=", "np", ".", "array", "(", "[", "\n", "inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "inst", ")", ")", "\n", "for", "inst", "in", "insts", "]", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "batch_seq", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.pad_type": [[43, 53], ["max", "numpy.array", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "def", "pad_type", "(", "insts", ")", ":", "\n", "    ", "\"\"\" Pad the instance to the max seq length in batch. \"\"\"", "\n", "\n", "max_len", "=", "max", "(", "len", "(", "inst", ")", "for", "inst", "in", "insts", ")", "\n", "\n", "batch_seq", "=", "np", ".", "array", "(", "[", "\n", "inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "inst", ")", ")", "\n", "for", "inst", "in", "insts", "]", ")", "\n", "\n", "return", "torch", ".", "tensor", "(", "batch_seq", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.collate_fn": [[55, 63], ["list", "Dataset.pad_time", "Dataset.pad_time", "Dataset.pad_type", "zip"], "function", ["home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.pad_time", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.pad_time", "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.pad_type"], ["", "def", "collate_fn", "(", "insts", ")", ":", "\n", "    ", "\"\"\" Collate function, as required by PyTorch. \"\"\"", "\n", "\n", "time", ",", "time_gap", ",", "event_type", "=", "list", "(", "zip", "(", "*", "insts", ")", ")", "\n", "time", "=", "pad_time", "(", "time", ")", "\n", "time_gap", "=", "pad_time", "(", "time_gap", ")", "\n", "event_type", "=", "pad_type", "(", "event_type", ")", "\n", "return", "time", ",", "time_gap", ",", "event_type", "\n", "\n"]], "home.repos.pwc.inspect_result.SimiaoZuo_Transformer-Hawkes-Process.preprocess.Dataset.get_dataloader": [[65, 77], ["Dataset.EventData", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_dataloader", "(", "data", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "\"\"\" Prepare dataloader. \"\"\"", "\n", "\n", "ds", "=", "EventData", "(", "data", ")", "\n", "dl", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "ds", ",", "\n", "num_workers", "=", "2", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "shuffle", "\n", ")", "\n", "return", "dl", "\n", "", ""]]}