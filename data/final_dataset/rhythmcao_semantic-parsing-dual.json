{"home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.read_data": [[11, 23], ["open", "line.strip.strip", "line.strip.split", "ex_list.append", "each.strip", "each.strip", "q.strip().split", "lf.strip().split", "each.strip", "each.strip", "q.strip", "lf.strip"], "function", ["None"], ["def", "read_data", "(", "path", ")", ":", "\n", "    ", "ex_list", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "infile", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                ", "continue", "\n", "", "q", ",", "lf", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "q", "=", "[", "each", ".", "strip", "(", ")", "for", "each", "in", "q", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "if", "each", ".", "strip", "(", ")", "!=", "''", "]", "\n", "lf", "=", "[", "each", ".", "strip", "(", ")", "for", "each", "in", "lf", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "if", "each", ".", "strip", "(", ")", "!=", "''", "]", "\n", "ex_list", ".", "append", "(", "(", "q", ",", "lf", ")", ")", "\n", "", "", "return", "ex_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.save_vocab": [[24, 28], ["open", "range", "len", "f.write"], "function", ["None"], ["", "def", "save_vocab", "(", "idx2word", ",", "vocab_path", ")", ":", "\n", "    ", "with", "open", "(", "vocab_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "idx", "in", "range", "(", "len", "(", "idx2word", ")", ")", ":", "\n", "            ", "f", ".", "write", "(", "idx2word", "[", "idx", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.construct_vocab": [[29, 67], ["sorted", "vocab.items", "len", "idx2word.append", "type", "operator.itemgetter"], "function", ["None"], ["", "", "", "def", "construct_vocab", "(", "input_seqs", ",", "mwf", "=", "1", ")", ":", "\n", "    ", "'''\n        Construct vocabulary given input_seqs\n        @params:\n            1. input_seqs: a list of seqs, e.g.\n                [ ['what', 'flight'] , ['which', 'flight'] ]\n            2. mwf: minimum word frequency\n        @return:\n            1. word2idx(dict)\n            2. idx2word(dict)\n    '''", "\n", "vocab", ",", "word2idx", ",", "idx2word", "=", "{", "}", ",", "{", "}", ",", "[", "]", "\n", "for", "seq", "in", "input_seqs", ":", "\n", "        ", "if", "type", "(", "seq", ")", "in", "[", "tuple", ",", "list", "]", ":", "\n", "            ", "for", "word", "in", "seq", ":", "\n", "                ", "if", "word", "not", "in", "vocab", ":", "\n", "                    ", "vocab", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "vocab", "[", "word", "]", "+=", "1", "\n", "", "", "", "else", ":", "\n", "            ", "if", "seq", "not", "in", "vocab", ":", "\n", "                ", "vocab", "[", "seq", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "vocab", "[", "seq", "]", "+=", "1", "\n", "\n", "# Discard those special tokens if already exist", "\n", "", "", "", "if", "PAD", "in", "vocab", ":", "del", "vocab", "[", "PAD", "]", "\n", "if", "UNK", "in", "vocab", ":", "del", "vocab", "[", "UNK", "]", "\n", "if", "BOS", "in", "vocab", ":", "del", "vocab", "[", "BOS", "]", "\n", "if", "EOS", "in", "vocab", ":", "del", "vocab", "[", "EOS", "]", "\n", "\n", "sorted_words", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "\n", "sorted_words", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_words", "if", "x", "[", "1", "]", ">=", "mwf", "]", "\n", "for", "word", "in", "sorted_words", ":", "\n", "        ", "idx", "=", "len", "(", "word2idx", ")", "\n", "word2idx", "[", "word", "]", "=", "idx", "\n", "idx2word", ".", "append", "(", "word", ")", "\n", "", "return", "word2idx", ",", "idx2word", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.main": [[68, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "sorted", "statistics.read_data", "list", "statistics.construct_vocab", "statistics.construct_vocab", "statistics.construct_vocab", "statistics.save_vocab", "statistics.save_vocab", "statistics.save_vocab", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "list", "zip", "utils.lexicon.Lexicon"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.read_data", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.construct_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.construct_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.construct_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.save_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.save_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.statistics.save_vocab"], ["", "def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "\"\"\"\n        Construct vocabulary for each dataset\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'all'", ",", "help", "=", "'dataset name'", ")", "\n", "parser", ".", "add_argument", "(", "'--mwf'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'minimum word frequency, if less than this int, not included'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "all_dataset", "=", "[", "opt", ".", "dataset", "]", "if", "opt", ".", "dataset", "!=", "'all'", "else", "[", "'atis'", ",", "'geo'", ",", "'basketball'", ",", "'blocks'", ",", "'calendar'", ",", "'housing'", ",", "'publications'", ",", "'recipes'", ",", "'restaurants'", ",", "'socialnetwork'", "]", "\n", "\n", "for", "dataset", "in", "all_dataset", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ")", "if", "dataset", "!=", "'atis'", "and", "dataset", "!=", "'geo'", "else", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_train.tsv'", ")", "\n", "word_vocab_path", ",", "lf_vocab_path", ",", "copy_vocab_path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.word'", ")", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.lf'", ")", ",", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.copy'", ")", "\n", "lexicon_words", "=", "sorted", "(", "list", "(", "Lexicon", "(", "dataset", ")", ".", "seen_words", ")", ")", "\n", "\n", "ex_list", "=", "read_data", "(", "file_path", ")", "\n", "questions", ",", "logical_forms", "=", "list", "(", "zip", "(", "*", "ex_list", ")", ")", "\n", "_", ",", "id2word", "=", "construct_vocab", "(", "questions", ",", "mwf", "=", "opt", ".", "mwf", ")", "\n", "_", ",", "id2lf", "=", "construct_vocab", "(", "logical_forms", ",", "mwf", "=", "opt", ".", "mwf", ")", "\n", "_", ",", "id2copy", "=", "construct_vocab", "(", "lexicon_words", ",", "mwf", "=", "opt", ".", "mwf", ")", "\n", "save_vocab", "(", "id2word", ",", "word_vocab_path", ")", "\n", "save_vocab", "(", "id2lf", ",", "lf_vocab_path", ")", "\n", "save_vocab", "(", "id2copy", ",", "copy_vocab_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.word2vec.read_pretrained_vectors": [[10, 24], ["open", "line.strip.strip", "torch.tensor", "line.strip.index", "numpy.fromstring", "line.strip.index"], "function", ["None"], ["def", "read_pretrained_vectors", "(", "filename", ",", "vocab", ",", "device", ")", ":", "\n", "    ", "word2vec", ",", "mapping", "=", "{", "}", ",", "{", "}", "\n", "mapping", "[", "'bos'", "]", ",", "mapping", "[", "'eos'", "]", ",", "mapping", "[", "'padding'", "]", ",", "mapping", "[", "'unknown'", "]", "=", "BOS", ",", "EOS", ",", "PAD", ",", "UNK", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "infile", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                ", "continue", "\n", "", "word", "=", "line", "[", ":", "line", ".", "index", "(", "' '", ")", "]", "\n", "word", "=", "mapping", "[", "word", "]", "if", "word", "in", "mapping", "else", "word", "\n", "if", "word", "in", "vocab", ":", "\n", "                ", "values", "=", "line", "[", "line", ".", "index", "(", "' '", ")", "+", "1", ":", "]", "\n", "word2vec", "[", "word", "]", "=", "torch", ".", "tensor", "(", "np", ".", "fromstring", "(", "values", ",", "sep", "=", "' '", ",", "dtype", "=", "np", ".", "float", ")", ",", "device", "=", "device", ")", "\n", "", "", "", "return", "word2vec", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.word2vec.load_embeddings": [[25, 35], ["module.weight.data.size", "utils.constants.VECTORCACHE", "word2vec.read_pretrained_vectors", "print", "len", "float", "len"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.word2vec.read_pretrained_vectors"], ["", "def", "load_embeddings", "(", "module", ",", "word2id", ",", "device", "=", "None", ")", ":", "\n", "    ", "emb_dim", "=", "module", ".", "weight", ".", "data", ".", "size", "(", "-", "1", ")", "\n", "if", "emb_dim", "not", "in", "[", "50", ",", "100", ",", "200", ",", "300", "]", ":", "\n", "        ", "print", "(", "'Not use pretrained glove6B embeddings ...'", ")", "\n", "return", "0.0", "\n", "", "word2vec_file", "=", "VECTORCACHE", "(", "emb_dim", ")", "\n", "pretrained_vectors", "=", "read_pretrained_vectors", "(", "word2vec_file", ",", "word2id", ",", "device", ")", "\n", "for", "word", "in", "pretrained_vectors", ":", "\n", "        ", "module", ".", "weight", ".", "data", "[", "word2id", "[", "word", "]", "]", "=", "pretrained_vectors", "[", "word", "]", "\n", "", "return", "len", "(", "pretrained_vectors", ")", "/", "float", "(", "len", "(", "word2id", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch": [[6, 10], ["len"], "function", ["None"], ["def", "get_minibatch", "(", "data_list", ",", "vocab", ",", "task", "=", "'semantic_parsing'", ",", "data_index", "=", "None", ",", "index", "=", "0", ",", "batch_size", "=", "16", ",", "device", "=", "None", ",", "**", "kargs", ")", ":", "\n", "    ", "index", "=", "index", "%", "len", "(", "data_list", ")", "\n", "batch_data_list", "=", "[", "data_list", "[", "idx", "]", "for", "idx", "in", "data_index", "[", "index", ":", "index", "+", "batch_size", "]", "]", "\n", "return", "BATCH_FUNC", "[", "task", "]", "(", "batch_data_list", ",", "vocab", ",", "device", ",", "**", "kargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_sp": [[11, 72], ["torch.tensor", "max", "torch.tensor", "max", "torch.tensor", "torch.tensor", "len", "len", "torch.stack().to", "torch.tensor", "enumerate", "oov_list.append", "copy_inputs.append", "torch.cat", "tmp_copy_inputs.append", "torch.stack", "enumerate", "len", "len", "tmp_oov_list.append", "len", "torch.zeros().scatter_", "torch.zeros", "len", "vocab.lf2id.get", "torch.tensor().unsqueeze", "vocab.lf2id.get", "len", "len", "tmp_oov_list.index", "torch.zeros", "len", "len", "len", "oov_list[].index", "len", "torch.tensor", "len"], "function", ["None"], ["", "def", "get_minibatch_sp", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "inputs", "=", "[", "ex", ".", "question", "for", "ex", "in", "ex_list", "]", "\n", "lens", "=", "[", "len", "(", "ex", ")", "for", "ex", "in", "inputs", "]", "\n", "lens_tensor", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "padded_inputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "inputs", "]", "\n", "inputs_idx", "=", "[", "[", "vocab", ".", "word2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "word2id", "else", "vocab", ".", "word2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_inputs", "]", "\n", "inputs_tensor", "=", "torch", ".", "tensor", "(", "inputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "outputs", "=", "[", "ex", ".", "logical_form", "for", "ex", "in", "ex_list", "]", "\n", "bos_eos_outputs", "=", "[", "[", "BOS", "]", "+", "sent", "+", "[", "EOS", "]", "for", "sent", "in", "outputs", "]", "\n", "out_lens", "=", "[", "len", "(", "each", ")", "for", "each", "in", "bos_eos_outputs", "]", "\n", "max_out_len", "=", "max", "(", "out_lens", ")", "\n", "padded_outputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_out_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "bos_eos_outputs", "]", "\n", "outputs_idx", "=", "[", "[", "vocab", ".", "lf2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "lf2id", "else", "vocab", ".", "lf2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_outputs", "]", "\n", "outputs_tensor", "=", "torch", ".", "tensor", "(", "outputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "out_lens_tensor", "=", "torch", ".", "tensor", "(", "out_lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "if", "copy", ":", "# pointer network need additional information", "\n", "        ", "mapped_inputs", "=", "[", "ex", ".", "mapped_question", "for", "ex", "in", "ex_list", "]", "\n", "oov_list", ",", "copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "mapped_inputs", ":", "\n", "            ", "tmp_oov_list", ",", "tmp_copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                ", "if", "word", "not", "in", "vocab", ".", "lf2id", "and", "word", "not", "in", "tmp_oov_list", "and", "len", "(", "tmp_oov_list", ")", "<", "MAX_OOV_NUM", ":", "\n", "                    ", "tmp_oov_list", ".", "append", "(", "word", ")", "\n", "", "tmp_copy_inputs", ".", "append", "(", "\n", "(", "\n", "vocab", ".", "lf2id", ".", "get", "(", "word", ",", "vocab", ".", "lf2id", "[", "UNK", "]", ")", "if", "word", "in", "vocab", ".", "lf2id", "or", "word", "not", "in", "tmp_oov_list", "else", "len", "(", "vocab", ".", "lf2id", ")", "+", "tmp_oov_list", ".", "index", "(", "word", ")", "# tgt_vocab_size + oov_id", "\n", ")", "\n", ")", "\n", "", "tmp_oov_list", "+=", "[", "UNK", "]", "*", "(", "MAX_OOV_NUM", "-", "len", "(", "tmp_oov_list", ")", ")", "\n", "oov_list", ".", "append", "(", "tmp_oov_list", ")", "\n", "copy_inputs", ".", "append", "(", "tmp_copy_inputs", ")", "\n", "\n", "", "copy_tokens", "=", "[", "\n", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros", "(", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "lf2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", ".", "scatter_", "(", "-", "1", ",", "torch", ".", "tensor", "(", "each", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "1.0", ")", ",", "\n", "torch", ".", "zeros", "(", "max_len", "-", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "lf2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "for", "each", "in", "copy_inputs", "\n", "]", "\n", "copy_tokens", "=", "torch", ".", "stack", "(", "copy_tokens", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "# bsize x src_len x (tgt_vocab + MAX_OOV_NUM)", "\n", "\n", "dec_outputs", "=", "[", "\n", "[", "\n", "len", "(", "vocab", ".", "lf2id", ")", "+", "oov_list", "[", "idx", "]", ".", "index", "(", "tok", ")", "\n", "if", "tok", "not", "in", "vocab", ".", "lf2id", "and", "tok", "in", "oov_list", "[", "idx", "]", "else", "vocab", ".", "lf2id", ".", "get", "(", "tok", ",", "vocab", ".", "lf2id", "[", "UNK", "]", ")", "\n", "for", "tok", "in", "sent", "\n", "]", "+", "[", "vocab", ".", "lf2id", "[", "PAD", "]", "]", "*", "(", "max_out_len", "-", "len", "(", "sent", ")", ")", "\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "bos_eos_outputs", ")", "\n", "]", "\n", "dec_outputs_tensor", "=", "torch", ".", "tensor", "(", "dec_outputs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "dec_outputs_tensor", ",", "copy_tokens", ",", "oov_list", "=", "outputs_tensor", ",", "None", ",", "[", "]", "\n", "\n", "", "return", "inputs_tensor", ",", "lens_tensor", ",", "outputs_tensor", ",", "dec_outputs_tensor", ",", "out_lens_tensor", ",", "copy_tokens", ",", "oov_list", ",", "(", "inputs", ",", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_qg": [[73, 134], ["torch.tensor", "max", "torch.tensor", "max", "torch.tensor", "torch.tensor", "len", "len", "torch.stack().to", "torch.tensor", "enumerate", "oov_list.append", "copy_inputs.append", "torch.cat", "tmp_copy_inputs.append", "torch.stack", "enumerate", "len", "len", "tmp_oov_list.append", "len", "torch.zeros().scatter_", "torch.zeros", "len", "vocab.word2id.get", "torch.tensor().unsqueeze", "vocab.word2id.get", "len", "len", "tmp_oov_list.index", "torch.zeros", "len", "len", "len", "oov_list[].index", "len", "torch.tensor", "len"], "function", ["None"], ["", "def", "get_minibatch_qg", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "raw_inputs", "=", "[", "ex", ".", "logical_form", "for", "ex", "in", "ex_list", "]", "\n", "inputs", "=", "[", "ex", ".", "mapped_logical_form", "for", "ex", "in", "ex_list", "]", "if", "copy", "else", "raw_inputs", "\n", "lens", "=", "[", "len", "(", "ex", ")", "for", "ex", "in", "inputs", "]", "\n", "lens_tensor", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "padded_inputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "inputs", "]", "\n", "inputs_idx", "=", "[", "[", "vocab", ".", "lf2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "lf2id", "else", "vocab", ".", "lf2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_inputs", "]", "\n", "inputs_tensor", "=", "torch", ".", "tensor", "(", "inputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "outputs", "=", "[", "ex", ".", "question", "for", "ex", "in", "ex_list", "]", "\n", "bos_eos_outputs", "=", "[", "[", "BOS", "]", "+", "sent", "+", "[", "EOS", "]", "for", "sent", "in", "outputs", "]", "\n", "out_lens", "=", "[", "len", "(", "each", ")", "for", "each", "in", "bos_eos_outputs", "]", "\n", "max_out_len", "=", "max", "(", "out_lens", ")", "\n", "padded_outputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_out_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "bos_eos_outputs", "]", "\n", "outputs_idx", "=", "[", "[", "vocab", ".", "word2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "word2id", "else", "vocab", ".", "word2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_outputs", "]", "\n", "outputs_tensor", "=", "torch", ".", "tensor", "(", "outputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "out_lens_tensor", "=", "torch", ".", "tensor", "(", "out_lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "if", "copy", ":", "# pointer network need additional information", "\n", "        ", "oov_list", ",", "copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "inputs", ":", "\n", "            ", "tmp_oov_list", ",", "tmp_copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                ", "if", "word", "not", "in", "vocab", ".", "word2id", "and", "word", "not", "in", "tmp_oov_list", "and", "len", "(", "tmp_oov_list", ")", "<", "MAX_OOV_NUM", ":", "\n", "                    ", "tmp_oov_list", ".", "append", "(", "word", ")", "\n", "", "tmp_copy_inputs", ".", "append", "(", "\n", "(", "\n", "vocab", ".", "word2id", ".", "get", "(", "word", ",", "vocab", ".", "word2id", "[", "UNK", "]", ")", "if", "word", "in", "vocab", ".", "word2id", "or", "word", "not", "in", "tmp_oov_list", "else", "len", "(", "vocab", ".", "word2id", ")", "+", "tmp_oov_list", ".", "index", "(", "word", ")", "# tgt_vocab_size + oov_id", "\n", ")", "\n", ")", "\n", "", "tmp_oov_list", "+=", "[", "UNK", "]", "*", "(", "MAX_OOV_NUM", "-", "len", "(", "tmp_oov_list", ")", ")", "\n", "oov_list", ".", "append", "(", "tmp_oov_list", ")", "\n", "copy_inputs", ".", "append", "(", "tmp_copy_inputs", ")", "\n", "\n", "", "copy_tokens", "=", "[", "\n", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros", "(", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "word2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", ".", "scatter_", "(", "-", "1", ",", "torch", ".", "tensor", "(", "each", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "1.0", ")", ",", "\n", "torch", ".", "zeros", "(", "max_len", "-", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "word2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "for", "each", "in", "copy_inputs", "\n", "]", "\n", "copy_tokens", "=", "torch", ".", "stack", "(", "copy_tokens", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "# bsize x src_len x (tgt_vocab + MAX_OOV_NUM)", "\n", "\n", "dec_outputs", "=", "[", "\n", "[", "\n", "len", "(", "vocab", ".", "word2id", ")", "+", "oov_list", "[", "idx", "]", ".", "index", "(", "tok", ")", "\n", "if", "tok", "not", "in", "vocab", ".", "word2id", "and", "tok", "in", "oov_list", "[", "idx", "]", "else", "vocab", ".", "word2id", ".", "get", "(", "tok", ",", "vocab", ".", "word2id", "[", "UNK", "]", ")", "\n", "for", "tok", "in", "sent", "\n", "]", "+", "[", "vocab", ".", "word2id", "[", "PAD", "]", "]", "*", "(", "max_out_len", "-", "len", "(", "sent", ")", ")", "\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "bos_eos_outputs", ")", "\n", "]", "\n", "dec_outputs_tensor", "=", "torch", ".", "tensor", "(", "dec_outputs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "dec_outputs_tensor", ",", "copy_tokens", ",", "oov_list", "=", "outputs_tensor", ",", "None", ",", "[", "]", "\n", "\n", "", "return", "inputs_tensor", ",", "lens_tensor", ",", "outputs_tensor", ",", "dec_outputs_tensor", ",", "out_lens_tensor", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_unlabeled_sp": [[135, 176], ["torch.tensor", "max", "torch.tensor", "len", "torch.stack().to", "enumerate", "oov_list.append", "copy_inputs.append", "torch.cat", "tmp_copy_inputs.append", "torch.stack", "len", "tmp_oov_list.append", "len", "torch.zeros().scatter_", "torch.zeros", "len", "vocab.lf2id.get", "torch.tensor().unsqueeze", "len", "tmp_oov_list.index", "torch.zeros", "len", "len", "len", "torch.tensor", "len"], "function", ["None"], ["", "def", "get_minibatch_unlabeled_sp", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "inputs", "=", "[", "ex", ".", "question", "for", "ex", "in", "ex_list", "]", "\n", "lens", "=", "[", "len", "(", "ex", ")", "for", "ex", "in", "inputs", "]", "\n", "lens_tensor", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "padded_inputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "inputs", "]", "\n", "inputs_idx", "=", "[", "[", "vocab", ".", "word2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "word2id", "else", "vocab", ".", "word2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_inputs", "]", "\n", "inputs_tensor", "=", "torch", ".", "tensor", "(", "inputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "if", "copy", ":", "# pointer network need additional information", "\n", "        ", "mapped_inputs", "=", "[", "ex", ".", "mapped_question", "for", "ex", "in", "ex_list", "]", "\n", "oov_list", ",", "copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "mapped_inputs", ":", "\n", "            ", "tmp_oov_list", ",", "tmp_copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                ", "if", "word", "not", "in", "vocab", ".", "lf2id", "and", "word", "not", "in", "tmp_oov_list", "and", "len", "(", "tmp_oov_list", ")", "<", "MAX_OOV_NUM", ":", "\n", "                    ", "tmp_oov_list", ".", "append", "(", "word", ")", "\n", "", "tmp_copy_inputs", ".", "append", "(", "\n", "(", "\n", "vocab", ".", "lf2id", ".", "get", "(", "word", ",", "vocab", ".", "lf2id", "[", "UNK", "]", ")", "if", "word", "in", "vocab", ".", "lf2id", "or", "word", "not", "in", "tmp_oov_list", "else", "len", "(", "vocab", ".", "lf2id", ")", "+", "tmp_oov_list", ".", "index", "(", "word", ")", "# tgt_vocab_size + oov_id", "\n", ")", "\n", ")", "\n", "", "tmp_oov_list", "+=", "[", "UNK", "]", "*", "(", "MAX_OOV_NUM", "-", "len", "(", "tmp_oov_list", ")", ")", "\n", "oov_list", ".", "append", "(", "tmp_oov_list", ")", "\n", "copy_inputs", ".", "append", "(", "tmp_copy_inputs", ")", "\n", "\n", "", "copy_tokens", "=", "[", "\n", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros", "(", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "lf2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", ".", "scatter_", "(", "-", "1", ",", "torch", ".", "tensor", "(", "each", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "1.0", ")", ",", "\n", "torch", ".", "zeros", "(", "max_len", "-", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "lf2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "for", "each", "in", "copy_inputs", "\n", "]", "\n", "copy_tokens", "=", "torch", ".", "stack", "(", "copy_tokens", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "# bsize x src_len x (tgt_vocab + MAX_OOV_NUM)", "\n", "", "else", ":", "\n", "        ", "copy_tokens", ",", "oov_list", "=", "None", ",", "[", "]", "\n", "\n", "", "return", "inputs_tensor", ",", "lens_tensor", ",", "copy_tokens", ",", "oov_list", ",", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_unlabeled_qg": [[177, 218], ["torch.tensor", "max", "torch.tensor", "len", "torch.stack().to", "enumerate", "oov_list.append", "copy_inputs.append", "torch.cat", "tmp_copy_inputs.append", "torch.stack", "len", "tmp_oov_list.append", "len", "torch.zeros().scatter_", "torch.zeros", "len", "vocab.word2id.get", "torch.tensor().unsqueeze", "len", "tmp_oov_list.index", "torch.zeros", "len", "len", "len", "torch.tensor", "len"], "function", ["None"], ["", "def", "get_minibatch_unlabeled_qg", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "raw_inputs", "=", "[", "ex", ".", "logical_form", "for", "ex", "in", "ex_list", "]", "\n", "inputs", "=", "[", "ex", ".", "mapped_logical_form", "for", "ex", "in", "ex_list", "]", "if", "copy", "else", "raw_inputs", "\n", "lens", "=", "[", "len", "(", "ex", ")", "for", "ex", "in", "inputs", "]", "\n", "lens_tensor", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "padded_inputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "inputs", "]", "\n", "inputs_idx", "=", "[", "[", "vocab", ".", "lf2id", "[", "w", "]", "if", "w", "in", "vocab", ".", "lf2id", "else", "vocab", ".", "lf2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_inputs", "]", "\n", "inputs_tensor", "=", "torch", ".", "tensor", "(", "inputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "if", "copy", ":", "# pointer network need additional information", "\n", "        ", "oov_list", ",", "copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "sent", "in", "inputs", ":", "\n", "            ", "tmp_oov_list", ",", "tmp_copy_inputs", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "sent", ")", ":", "\n", "                ", "if", "word", "not", "in", "vocab", ".", "word2id", "and", "word", "not", "in", "tmp_oov_list", "and", "len", "(", "tmp_oov_list", ")", "<", "MAX_OOV_NUM", ":", "\n", "                    ", "tmp_oov_list", ".", "append", "(", "word", ")", "\n", "", "tmp_copy_inputs", ".", "append", "(", "\n", "(", "\n", "vocab", ".", "word2id", ".", "get", "(", "word", ",", "vocab", ".", "word2id", "[", "UNK", "]", ")", "if", "word", "in", "vocab", ".", "word2id", "or", "word", "not", "in", "tmp_oov_list", "else", "len", "(", "vocab", ".", "word2id", ")", "+", "tmp_oov_list", ".", "index", "(", "word", ")", "# tgt_vocab_size + oov_id", "\n", ")", "\n", ")", "\n", "", "tmp_oov_list", "+=", "[", "UNK", "]", "*", "(", "MAX_OOV_NUM", "-", "len", "(", "tmp_oov_list", ")", ")", "\n", "oov_list", ".", "append", "(", "tmp_oov_list", ")", "\n", "copy_inputs", ".", "append", "(", "tmp_copy_inputs", ")", "\n", "\n", "", "copy_tokens", "=", "[", "\n", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "zeros", "(", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "word2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", ".", "scatter_", "(", "-", "1", ",", "torch", ".", "tensor", "(", "each", ",", "dtype", "=", "torch", ".", "long", ")", ".", "unsqueeze", "(", "-", "1", ")", ",", "1.0", ")", ",", "\n", "torch", ".", "zeros", "(", "max_len", "-", "len", "(", "each", ")", ",", "len", "(", "vocab", ".", "word2id", ")", "+", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "]", ",", "dim", "=", "0", ")", "\n", "for", "each", "in", "copy_inputs", "\n", "]", "\n", "copy_tokens", "=", "torch", ".", "stack", "(", "copy_tokens", ",", "dim", "=", "0", ")", ".", "to", "(", "device", ")", "# bsize x src_len x (tgt_vocab + MAX_OOV_NUM)", "\n", "", "else", ":", "\n", "        ", "copy_tokens", ",", "oov_list", "=", "None", ",", "[", "]", "\n", "\n", "", "return", "inputs_tensor", ",", "lens_tensor", ",", "copy_tokens", ",", "oov_list", ",", "raw_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_pseudo_sp": [[219, 223], ["batch.get_minibatch_sp", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_sp"], ["", "def", "get_minibatch_pseudo_sp", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "inputs", ",", "lens", ",", "outputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch_sp", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "copy", ",", "**", "kargs", ")", "\n", "conf", "=", "torch", ".", "tensor", "(", "[", "ex", ".", "conf", "for", "ex", "in", "ex_list", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "return", "inputs", ",", "lens", ",", "outputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_pseudo_qg": [[224, 228], ["batch.get_minibatch_qg", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_qg"], ["", "def", "get_minibatch_pseudo_qg", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "False", ",", "**", "kargs", ")", ":", "\n", "    ", "inputs", ",", "lens", ",", "outputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch_qg", "(", "ex_list", ",", "vocab", ",", "device", ",", "copy", "=", "copy", ",", "**", "kargs", ")", "\n", "conf", "=", "torch", ".", "tensor", "(", "[", "ex", ".", "conf", "for", "ex", "in", "ex_list", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "return", "inputs", ",", "lens", ",", "outputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_lm": [[229, 244], ["max", "torch.tensor", "torch.tensor", "len", "len"], "function", ["None"], ["", "def", "get_minibatch_lm", "(", "ex_list", ",", "vocab", ",", "device", ",", "side", "=", "'question'", ",", "**", "kargs", ")", ":", "\n", "    ", "if", "side", "==", "'question'", ":", "\n", "        ", "word2id", "=", "vocab", ".", "word2id", "\n", "inputs", "=", "[", "ex", ".", "question", "for", "ex", "in", "ex_list", "]", "\n", "", "else", ":", "\n", "        ", "word2id", "=", "vocab", ".", "lf2id", "\n", "inputs", "=", "[", "ex", ".", "logical_form", "for", "ex", "in", "ex_list", "]", "\n", "", "bos_eos_inputs", "=", "[", "[", "BOS", "]", "+", "sent", "+", "[", "EOS", "]", "for", "sent", "in", "inputs", "]", "\n", "lens", "=", "[", "len", "(", "each", ")", "for", "each", "in", "bos_eos_inputs", "]", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "padded_inputs", "=", "[", "sent", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "bos_eos_inputs", "]", "\n", "inputs_idx", "=", "[", "[", "word2id", "[", "w", "]", "if", "w", "in", "word2id", "else", "word2id", "[", "UNK", "]", "for", "w", "in", "sent", "]", "for", "sent", "in", "padded_inputs", "]", "\n", "inputs_tensor", "=", "torch", ".", "tensor", "(", "inputs_idx", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "lens", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "return", "inputs_tensor", ",", "lens", ",", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon.__init__": [[22, 28], ["super().__init__", "collections.OrderedDict", "collections.OrderedDict", "set", "lexicon.Lexicon._load_lexicon"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon._load_lexicon"], ["def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "super", "(", "Lexicon", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "phrase2entity", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "entity2phrase", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "seen_words", "=", "set", "(", ")", "\n", "self", ".", "_load_lexicon", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon._load_lexicon": [[29, 43], ["print", "lexicon.Lexicon._add_entries", "os.path.join", "os.path.join", "open", "line.strip.strip.strip", "line.strip.strip.split", "entries.append", "x.strip", "y.strip"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon._add_entries"], ["", "def", "_load_lexicon", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "entries", "=", "[", "]", "\n", "if", "dataset", "in", "[", "'atis'", ",", "'geo'", "]", ":", "\n", "            ", "lexicon_path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ",", "dataset", "+", "'_lexicon.txt'", ")", "\n", "", "else", ":", "\n", "            ", "lexicon_path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ",", "dataset", "+", "'_lexicon.txt'", ")", "\n", "", "print", "(", "'Start load lexicon from file %s ...'", "%", "(", "lexicon_path", ")", ")", "\n", "with", "open", "(", "lexicon_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "continue", "\n", "x", ",", "y", "=", "line", ".", "split", "(", "' :- NP : '", ")", "\n", "entries", ".", "append", "(", "(", "x", ".", "strip", "(", ")", ",", "y", ".", "strip", "(", ")", ")", ")", "\n", "", "", "self", ".", "_add_entries", "(", "entries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon._add_entries": [[44, 60], ["name.split", "sorted", "lexicon.Lexicon.seen_words.add", "lexicon.Lexicon.entity2phrase[].append", "print", "len"], "methods", ["None"], ["", "def", "_add_entries", "(", "self", ",", "entries", ")", ":", "\n", "        ", "for", "name", ",", "entity", "in", "entries", ":", "\n", "            ", "if", "entity", "not", "in", "self", ".", "entity2phrase", ":", "\n", "                ", "self", ".", "entity2phrase", "[", "entity", "]", "=", "[", "name", "]", "\n", "", "elif", "name", "not", "in", "self", ".", "entity2phrase", "[", "entity", "]", ":", "\n", "                ", "self", ".", "entity2phrase", "[", "entity", "]", ".", "append", "(", "name", ")", "\n", "", "if", "name", "in", "self", ".", "phrase2entity", ":", "\n", "                ", "if", "self", ".", "phrase2entity", "[", "name", "]", "!=", "entity", ":", "# we do not handle entity disambiguation", "\n", "                    ", "print", "(", "'Collision detected: %s -> %s, %s'", "%", "(", "name", ",", "self", ".", "entries", "[", "name", "]", ",", "entity", ")", ")", "\n", "", "continue", "\n", "# Update self.seen_words", "\n", "", "for", "w", "in", "name", ".", "split", "(", "' '", ")", ":", "\n", "                ", "self", ".", "seen_words", ".", "add", "(", "w", ")", "\n", "", "self", ".", "phrase2entity", "[", "name", "]", "=", "entity", "\n", "", "for", "entity", "in", "self", ".", "entity2phrase", ":", "# sorted according to length of noun phrases", "\n", "            ", "self", ".", "entity2phrase", "[", "entity", "]", "=", "sorted", "(", "self", ".", "entity2phrase", "[", "entity", "]", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ",", "reverse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon.entity_mapping": [[61, 84], ["sorted", "list", "any", "range", "itertools.combinations", "range", "ret_entries.append", "enumerate", "len", "range", "len"], "methods", ["None"], ["", "", "def", "entity_mapping", "(", "self", ",", "words", ")", ":", "\n", "        ", "\"\"\"\n            @args:\n                words: a list of words\n            @return:\n                mapped_words: a list of words, where words[i] is replaced with entity if available\n        \"\"\"", "\n", "entities", "=", "[", "''", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", "]", "\n", "index_pairs", "=", "sorted", "(", "list", "(", "itertools", ".", "combinations", "(", "range", "(", "len", "(", "words", ")", "+", "1", ")", ",", "2", ")", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", "-", "x", "[", "1", "]", ")", "\n", "ret_entries", "=", "[", "]", "\n", "\n", "for", "i", ",", "j", "in", "index_pairs", ":", "\n", "# Longest match first", "\n", "            ", "if", "any", "(", "x", "for", "x", "in", "entities", "[", "i", ":", "j", "]", ")", ":", "continue", "\n", "span", "=", "' '", ".", "join", "(", "words", "[", "i", ":", "j", "]", ")", "\n", "if", "span", "in", "self", ".", "phrase2entity", ":", "\n", "                ", "entity", "=", "self", ".", "phrase2entity", "[", "span", "]", "\n", "for", "k", "in", "range", "(", "i", ",", "j", ")", ":", "\n", "                    ", "entities", "[", "k", "]", "=", "entity", "\n", "", "ret_entries", ".", "append", "(", "(", "(", "i", ",", "j", ")", ",", "entity", ")", ")", "\n", "", "", "mapped_words", "=", "[", "words", "[", "idx", "]", "if", "not", "item", "else", "item", "for", "idx", ",", "item", "in", "enumerate", "(", "entities", ")", "]", "\n", "return", "mapped_words", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon.reverse_entity_mapping": [[85, 109], ["enumerate", "enumerate", "list", "random.choice", "filter", "len", "random.choice"], "methods", ["None"], ["", "def", "reverse_entity_mapping", "(", "self", ",", "tokens", ",", "words", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            @args:\n                tokens: a list of logical form tokens\n                words: a list of words if available\n            @return:\n                mapped_tokens: a list of tokens, where tokens[i] is replaced with noun phrases if available,\n                    prefer to use raw noun phrase in words if available\n        \"\"\"", "\n", "entities", "=", "[", "''", "for", "each", "in", "tokens", "]", "\n", "words", "=", "' '", ".", "join", "(", "words", ")", "if", "words", "and", "words", "!=", "[", "'none'", "]", "else", "None", "\n", "for", "idx", ",", "tok", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "if", "tok", "in", "self", ".", "entity2phrase", ":", "\n", "                ", "if", "words", ":", "\n", "                    ", "choices", "=", "self", ".", "entity2phrase", "[", "tok", "]", "\n", "among_words", "=", "list", "(", "filter", "(", "lambda", "item", ":", "item", "in", "words", ",", "choices", ")", ")", "\n", "if", "len", "(", "among_words", ")", ">", "0", ":", "\n", "                        ", "entities", "[", "idx", "]", "=", "among_words", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "entities", "[", "idx", "]", "=", "random", ".", "choice", "(", "self", ".", "entity2phrase", "[", "tok", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "entities", "[", "idx", "]", "=", "random", ".", "choice", "(", "self", ".", "entity2phrase", "[", "tok", "]", ")", "\n", "", "", "", "mapped_words", "=", "[", "tokens", "[", "idx", "]", "if", "not", "item", "else", "item", "for", "idx", ",", "item", "in", "enumerate", "(", "entities", ")", "]", "\n", "return", "' '", ".", "join", "(", "mapped_words", ")", ".", "split", "(", "' '", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.set_domain": [[21, 39], ["utils.lexicon.Lexicon", "utils.domain.domain_base.Domain.from_dataset", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.from_dataset"], ["@", "classmethod", "\n", "def", "set_domain", "(", "cls", ",", "dataset", ")", ":", "\n", "        ", "cls", ".", "dataset", "=", "dataset", "# dataset name", "\n", "cls", ".", "db", "=", "Lexicon", "(", "dataset", ")", "\n", "cls", ".", "domain", "=", "Domain", ".", "from_dataset", "(", "dataset", ")", "# class Domain object", "\n", "if", "dataset", "in", "[", "'geo'", ",", "'atis'", "]", ":", "\n", "            ", "cls", ".", "file_paths", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ",", "dataset", "+", "'_train.tsv'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ",", "dataset", "+", "'_dev.tsv'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ",", "dataset", "+", "'_test.tsv'", ")", "\n", "]", "\n", "cls", ".", "extra_path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ",", "dataset", "+", "'_extra.tsv'", ")", "\n", "", "else", ":", "#Overnight", "\n", "            ", "cls", ".", "file_paths", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ",", "dataset", "+", "'_train.tsv'", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ",", "dataset", "+", "'_test.tsv'", ")", "\n", "]", "\n", "cls", ".", "extra_path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ",", "dataset", "+", "'_extra.tsv'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.__init__": [[40, 47], ["super().__init__", "Example.db.entity_mapping", "Example.db.reverse_entity_mapping", "question.split", "logical_form.split"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon.entity_mapping", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.lexicon.Lexicon.reverse_entity_mapping"], ["", "", "def", "__init__", "(", "self", ",", "question", "=", "''", ",", "logical_form", "=", "''", ",", "conf", "=", "1.0", ")", ":", "\n", "        ", "super", "(", "Example", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "question", "=", "[", "each", "for", "each", "in", "question", ".", "split", "(", "' '", ")", "if", "each", "!=", "''", "]", "\n", "self", ".", "logical_form", "=", "[", "each", "for", "each", "in", "logical_form", ".", "split", "(", "' '", ")", "if", "each", "!=", "''", "]", "\n", "self", ".", "mapped_question", "=", "Example", ".", "db", ".", "entity_mapping", "(", "self", ".", "question", ")", "\n", "self", ".", "mapped_logical_form", "=", "Example", ".", "db", ".", "reverse_entity_mapping", "(", "self", ".", "logical_form", ",", "self", ".", "question", ")", "\n", "self", ".", "conf", "=", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset": [[48, 69], ["len", "cls.load_dataset_from_file", "example.split_dataset", "cls.load_dataset_from_file", "cls.load_dataset_from_file", "cls.load_dataset_from_file", "cls.load_dataset_from_file", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.split_dataset", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file"], ["", "@", "classmethod", "\n", "def", "load_dataset", "(", "cls", ",", "choice", "=", "'train'", ")", ":", "\n", "        ", "\"\"\"\n            return example list of train, test or extra\n        \"\"\"", "\n", "if", "choice", "==", "'train'", ":", "\n", "            ", "if", "len", "(", "cls", ".", "file_paths", ")", "==", "2", ":", "\n", "# no dev dataset, split train dataset", "\n", "                ", "train_dataset", "=", "cls", ".", "load_dataset_from_file", "(", "cls", ".", "file_paths", "[", "0", "]", ")", "\n", "train_dataset", ",", "dev_dataset", "=", "split_dataset", "(", "train_dataset", ",", "split_ratio", "=", "0.8", ")", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "cls", ".", "file_paths", ")", "==", "3", "\n", "train_dataset", "=", "cls", ".", "load_dataset_from_file", "(", "cls", ".", "file_paths", "[", "0", "]", ")", "\n", "dev_dataset", "=", "cls", ".", "load_dataset_from_file", "(", "cls", ".", "file_paths", "[", "1", "]", ")", "\n", "", "return", "train_dataset", ",", "dev_dataset", "\n", "", "elif", "choice", "==", "'test'", ":", "\n", "            ", "test_dataset", "=", "cls", ".", "load_dataset_from_file", "(", "cls", ".", "file_paths", "[", "-", "1", "]", ")", "\n", "return", "test_dataset", "\n", "", "else", ":", "\n", "            ", "extra_dataset", "=", "cls", ".", "load_dataset_from_file", "(", "cls", ".", "extra_path", ")", "\n", "return", "extra_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.Example.load_dataset_from_file": [[70, 80], ["open", "line.strip.strip.strip", "line.strip.strip.split", "ex_list.append", "cls", "q.strip", "lf.strip"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "load_dataset_from_file", "(", "cls", ",", "path", ")", ":", "\n", "        ", "ex_list", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "infile", ":", "\n", "            ", "for", "line", "in", "infile", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "continue", "\n", "q", ",", "lf", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "ex_list", ".", "append", "(", "cls", "(", "q", ".", "strip", "(", ")", ",", "lf", ".", "strip", "(", ")", ")", ")", "\n", "", "", "return", "ex_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.example.split_dataset": [[8, 16], ["numpy.arange", "numpy.random.shuffle", "int", "len", "len"], "function", ["None"], ["def", "split_dataset", "(", "dataset", ",", "split_ratio", "=", "1.0", ")", ":", "\n", "    ", "assert", "split_ratio", ">=", "0.", "and", "split_ratio", "<=", "1.0", "\n", "index", "=", "np", ".", "arange", "(", "len", "(", "dataset", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "index", ")", "\n", "splt", "=", "int", "(", "len", "(", "dataset", ")", "*", "split_ratio", ")", "\n", "first", "=", "[", "dataset", "[", "idx", "]", "for", "idx", "in", "index", "[", ":", "splt", "]", "]", "\n", "second", "=", "[", "dataset", "[", "idx", "]", "for", "idx", "in", "index", "[", "splt", ":", "]", "]", "\n", "return", "first", ",", "second", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.bleu.get_bleu_score": [[7, 35], ["nltk.translate.bleu_score.SmoothingFunction", "len", "ValueError", "type", "nltk.translate.bleu_score.sentence_bleu", "nltk.translate.bleu_score.corpus_bleu", "eval", "eval", "str", "str"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval"], ["def", "get_bleu_score", "(", "candidate_list", ",", "references_list", ",", "method", "=", "0", ",", "weights", "=", "(", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", ")", ")", ":", "\n", "    ", "'''\n        @args:\n        if candidate_list is words list, e.g. ['which','flight']\n            references_list is list of words list, e.g. [ ['which','flight'] , ['what','flight'] ]\n            calculate bleu score of one sentence\n        if candidate_list is list of words list, e.g. [ ['which','flight'] , ['when','to','flight'] ]\n            references_list is list of list of words list, e.g.\n            [   [ ['which','flight'] , ['what','flight'] ]   ,   [ ['when','to','flight'] , ['when','to','go'] ]   ]\n            calculate bleu score of multiple sentences, a whole corpus\n        method(int): chencherry smoothing methods choice\n    '''", "\n", "chencherry", "=", "SmoothingFunction", "(", ")", "\n", "if", "len", "(", "candidate_list", ")", "==", "0", ":", "\n", "        ", "raise", "ValueError", "(", "'[Error]: there is no candidate sentence!'", ")", "\n", "", "if", "type", "(", "candidate_list", "[", "0", "]", ")", "==", "str", ":", "\n", "        ", "return", "sentence_bleu", "(", "\n", "references_list", ",", "\n", "candidate_list", ",", "\n", "weights", ",", "\n", "eval", "(", "'chencherry.method'", "+", "str", "(", "method", ")", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "corpus_bleu", "(", "\n", "references_list", ",", "\n", "candidate_list", ",", "\n", "weights", ",", "\n", "eval", "(", "'chencherry.method'", "+", "str", "(", "method", ")", ")", "\n", ")", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.logger.set_logger": [[4, 18], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.FileHandler", "logging.FileHandler"], "function", ["None"], ["def", "set_logger", "(", "exp_path", ",", "testing", "=", "False", ")", ":", "\n", "    ", "logFormatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(message)s'", ")", "#('%(asctime)s - %(levelname)s - %(message)s')", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'mylogger'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "if", "testing", ":", "\n", "        ", "fileHandler", "=", "logging", ".", "FileHandler", "(", "'%s/log_test.txt'", "%", "(", "exp_path", ")", ",", "mode", "=", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "fileHandler", "=", "logging", ".", "FileHandler", "(", "'%s/log_train.txt'", "%", "(", "exp_path", ")", ",", "mode", "=", "'w'", ")", "\n", "", "fileHandler", ".", "setFormatter", "(", "logFormatter", ")", "\n", "logger", ".", "addHandler", "(", "fileHandler", ")", "\n", "consoleHandler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "consoleHandler", ".", "setFormatter", "(", "logFormatter", ")", "\n", "logger", ".", "addHandler", "(", "consoleHandler", ")", "\n", "return", "logger", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.loss.MyNLLLoss.__init__": [[14, 19], ["torch.Module.__init__", "kargs.pop", "torch.NLLLoss", "torch.NLLLoss"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "MyNLLLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "real_reduction", "=", "kargs", ".", "pop", "(", "'reduction'", ",", "'sum'", ")", "\n", "kargs", "[", "'reduction'", "]", "=", "'none'", "\n", "self", ".", "loss_function", "=", "nn", ".", "NLLLoss", "(", "*", "args", ",", "**", "kargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.loss.MyNLLLoss.forward": [[20, 29], ["list", "loss.contiguous().view().sum.MyNLLLoss.loss_function", "loss.contiguous().view().sum.contiguous().view().sum.contiguous().view().sum", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "inputs.size", "inputs.contiguous().view", "targets.contiguous().view", "loss.contiguous().view().sum.contiguous().view().sum.contiguous().view", "lens.float", "torch.ones().to.sum", "torch.ones().to.sum", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "inputs.contiguous", "targets.contiguous", "inputs.size", "loss.contiguous().view().sum.contiguous().view().sum.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ",", "lens", "=", "None", ",", "conf", "=", "None", ")", ":", "\n", "        ", "if", "conf", "is", "None", ":", "\n", "            ", "conf", "=", "torch", ".", "ones", "(", "inputs", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "inputs", ".", "device", ")", "\n", "", "bsize", ",", "seq_len", ",", "voc_size", "=", "list", "(", "inputs", ".", "size", "(", ")", ")", "\n", "loss", "=", "self", ".", "loss_function", "(", "inputs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "voc_size", ")", ",", "targets", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "loss", ".", "contiguous", "(", ")", ".", "view", "(", "bsize", ",", "seq_len", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "loss", "=", "loss", "if", "self", ".", "real_reduction", "==", "'sum'", "else", "loss", "/", "lens", ".", "float", "(", ")", "\n", "loss", "=", "(", "loss", "*", "conf", ")", ".", "sum", "(", ")", "if", "self", ".", "real_reduction", "==", "'sum'", "else", "(", "loss", "*", "conf", ")", ".", "sum", "(", ")", "/", "conf", ".", "sum", "(", ")", "\n", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.loss.set_loss_function": [[8, 11], ["loss.MyNLLLoss"], "function", ["None"], ["def", "set_loss_function", "(", "reduction", "=", "'sum'", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "    ", "loss_function", "=", "MyNLLLoss", "(", "reduction", "=", "reduction", ",", "ignore_index", "=", "ignore_index", ")", "\n", "return", "loss_function", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.gpu.set_torch_device": [[10, 24], ["torch.device", "print", "torch.device", "print", "torch.cuda.device_count"], "function", ["None"], ["def", "set_torch_device", "(", "deviceId", ")", ":", "\n", "# Simplified version of gpu selection", "\n", "    ", "if", "deviceId", "<", "0", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "print", "(", "'Use CPU ...'", ")", "\n", "", "else", ":", "\n", "        ", "assert", "torch", ".", "cuda", ".", "device_count", "(", ")", ">=", "deviceId", "+", "1", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "(", "deviceId", ")", ")", "\n", "print", "(", "'Use GPU with index %d'", "%", "(", "deviceId", ")", ")", "\n", "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # used when debug", "\n", "## These two sentences are used to ensure reproducibility with cudnnbacken", "\n", "# torch.backends.cudnn.deterministic = True", "\n", "# torch.backends.cudnn.benchmark = False", "\n", "", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.hyperparam.hyperparam_seq2seq": [[9, 29], ["os.path.join"], "function", ["None"], ["def", "hyperparam_seq2seq", "(", "options", ")", ":", "\n", "    ", "\"\"\"Hyerparam string for semantic parsing and question generation.\"\"\"", "\n", "task_path", "=", "'task_%s'", "%", "(", "options", ".", "task", ")", "\n", "dataset_path", "=", "'dataset_%s'", "%", "(", "options", ".", "dataset", ")", "\n", "ratio", "=", "'labeled_%s'", "%", "(", "options", ".", "labeled", ")", "\n", "\n", "exp_name", "=", "'copy__'", "if", "options", ".", "copy", "else", "''", "\n", "exp_name", "+=", "'cell_%s__'", "%", "(", "options", ".", "cell", ")", "\n", "exp_name", "+=", "'emb_%s__'", "%", "(", "options", ".", "emb_size", ")", "\n", "exp_name", "+=", "'hidden_%s_x_%s__'", "%", "(", "options", ".", "hidden_dim", ",", "options", ".", "num_layers", ")", "\n", "exp_name", "+=", "'dropout_%s__'", "%", "(", "options", ".", "dropout", ")", "\n", "exp_name", "+=", "'reduce_%s__'", "%", "(", "options", ".", "reduction", ")", "\n", "exp_name", "+=", "'lr_%s__'", "%", "(", "options", ".", "lr", ")", "\n", "exp_name", "+=", "'mn_%s__'", "%", "(", "options", ".", "max_norm", ")", "\n", "exp_name", "+=", "'l2_%s__'", "%", "(", "options", ".", "l2", ")", "\n", "exp_name", "+=", "'bsize_%s__'", "%", "(", "options", ".", "batchSize", ")", "\n", "exp_name", "+=", "'me_%s__'", "%", "(", "options", ".", "max_epoch", ")", "\n", "exp_name", "+=", "'beam_%s__'", "%", "(", "options", ".", "beam", ")", "\n", "exp_name", "+=", "'nbest_%s'", "%", "(", "options", ".", "n_best", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "task_path", ",", "dataset_path", ",", "ratio", ",", "exp_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.hyperparam.hyperparam_lm": [[30, 48], ["os.path.join"], "function", ["None"], ["", "def", "hyperparam_lm", "(", "options", ")", ":", "\n", "    ", "task", "=", "'task_%s'", "%", "(", "options", ".", "task", ")", "\n", "dataset_path", "=", "'dataset_%s'", "%", "(", "options", ".", "dataset", ")", "\n", "ratio", "=", "'%s__labeled_%s'", "%", "(", "options", ".", "side", ",", "options", ".", "labeled", ")", "\n", "\n", "exp_name", "=", "''", "\n", "exp_name", "+=", "'cell_%s__'", "%", "(", "options", ".", "cell", ")", "\n", "exp_name", "+=", "'emb_%s__'", "%", "(", "options", ".", "emb_size", ")", "\n", "exp_name", "+=", "'hidden_%s_x_%s__'", "%", "(", "options", ".", "hidden_dim", ",", "options", ".", "num_layers", ")", "\n", "exp_name", "+=", "'dropout_%s__'", "%", "(", "options", ".", "dropout", ")", "\n", "exp_name", "+=", "'reduce_%s__'", "%", "(", "options", ".", "reduction", ")", "\n", "exp_name", "+=", "'lr_%s__'", "%", "(", "options", ".", "lr", ")", "\n", "exp_name", "+=", "'mn_%s__'", "%", "(", "options", ".", "max_norm", ")", "\n", "exp_name", "+=", "'l2_%s__'", "%", "(", "options", ".", "l2", ")", "\n", "exp_name", "+=", "'bsize_%s__'", "%", "(", "options", ".", "batchSize", ")", "\n", "exp_name", "+=", "'me_%s'", "%", "(", "options", ".", "max_epoch", ")", "\n", "exp_name", "+=", "'__decTied'", "if", "options", ".", "decoder_tied", "else", "''", "\n", "return", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "task", ",", "dataset_path", ",", "ratio", ",", "exp_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.hyperparam.hyperparam_pseudo_method": [[49, 74], ["os.path.join"], "function", ["None"], ["", "def", "hyperparam_pseudo_method", "(", "options", ")", ":", "\n", "    ", "task", "=", "'task_%s'", "%", "(", "options", ".", "task", ")", "\n", "dataset_path", "=", "'dataset_%s'", "%", "(", "options", ".", "dataset", ")", "\n", "ratio", "=", "'labeled_%s__unlabeled_%s'", "%", "(", "options", ".", "labeled", ",", "options", ".", "unlabeled", ")", "\n", "ratio", "+=", "'__extra'", "if", "options", ".", "extra", "else", "''", "\n", "\n", "exp_name", "=", "''", "\n", "if", "'copy__'", "in", "options", ".", "read_sp_model_path", ":", "\n", "        ", "exp_name", "+=", "'sp_attnptr__'", "\n", "", "else", ":", "\n", "        ", "exp_name", "+=", "'sp_attn__'", "\n", "", "if", "'copy__'", "in", "options", ".", "read_qg_model_path", ":", "\n", "        ", "exp_name", "+=", "'qg_attnptr__'", "\n", "", "else", ":", "\n", "        ", "exp_name", "+=", "'qg_attn__'", "\n", "", "exp_name", "+=", "'reduce_%s__'", "%", "(", "options", ".", "reduction", ")", "\n", "exp_name", "+=", "'lr_%s__'", "%", "(", "options", ".", "lr", ")", "\n", "exp_name", "+=", "'mn_%s__'", "%", "(", "options", ".", "max_norm", ")", "\n", "exp_name", "+=", "'l2_%s__'", "%", "(", "options", ".", "l2", ")", "\n", "exp_name", "+=", "'bsize_%s__'", "%", "(", "options", ".", "batchSize", ")", "\n", "exp_name", "+=", "'me_%s__'", "%", "(", "options", ".", "max_epoch", ")", "\n", "exp_name", "+=", "'beam_%s__'", "%", "(", "options", ".", "beam", ")", "\n", "exp_name", "+=", "'nbest_%s__'", "%", "(", "options", ".", "n_best", ")", "\n", "exp_name", "+=", "'discount_%s__method_%s'", "%", "(", "options", ".", "discount", ",", "options", ".", "method", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "task", ",", "dataset_path", ",", "ratio", ",", "exp_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.hyperparam.hyperparam_dual_learning": [[75, 101], ["os.path.join"], "function", ["None"], ["", "def", "hyperparam_dual_learning", "(", "options", ")", ":", "\n", "    ", "task", "=", "'task_%s'", "%", "(", "options", ".", "task", ")", "\n", "dataset_path", "=", "'dataset_%s'", "%", "(", "options", ".", "dataset", ")", "\n", "ratio", "=", "'labeled_%s__unlabeled_%s'", "%", "(", "options", ".", "labeled", ",", "options", ".", "unlabeled", ")", "\n", "ratio", "+=", "'__extra'", "if", "options", ".", "extra", "else", "''", "\n", "\n", "exp_name", "=", "''", "\n", "if", "'copy__'", "in", "options", ".", "read_sp_model_path", ":", "\n", "        ", "exp_name", "+=", "'sp_attnptr__'", "\n", "", "else", ":", "\n", "        ", "exp_name", "+=", "'sp_attn__'", "\n", "", "if", "'copy__'", "in", "options", ".", "read_qg_model_path", ":", "\n", "        ", "exp_name", "+=", "'qg_attnptr__'", "\n", "", "else", ":", "\n", "        ", "exp_name", "+=", "'qg_attn__'", "\n", "", "exp_name", "+=", "'reduce_%s__'", "%", "(", "options", ".", "reduction", ")", "\n", "exp_name", "+=", "'lr_%s__'", "%", "(", "options", ".", "lr", ")", "\n", "exp_name", "+=", "'mn_%s__'", "%", "(", "options", ".", "max_norm", ")", "\n", "exp_name", "+=", "'l2_%s__'", "%", "(", "options", ".", "l2", ")", "\n", "exp_name", "+=", "'bsize_%s__'", "%", "(", "options", ".", "batchSize", ")", "\n", "exp_name", "+=", "'me_%s__'", "%", "(", "options", ".", "max_epoch", ")", "\n", "exp_name", "+=", "'beam_%s__'", "%", "(", "options", ".", "beam", ")", "\n", "exp_name", "+=", "'nbest_%s__'", "%", "(", "options", ".", "n_best", ")", "\n", "exp_name", "+=", "'cycle_%s__'", "%", "(", "options", ".", "cycle", ")", "\n", "exp_name", "+=", "'sample_%s__alpha_%s__beta_%s'", "%", "(", "options", ".", "sample", ",", "options", ".", "alpha", ",", "options", ".", "beta", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "EXP_PATH", ",", "task", ",", "dataset_path", ",", "ratio", ",", "exp_name", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.seed.set_random_seed": [[5, 14], ["random.seed", "torch.manual_seed", "torch.cuda.is_available", "numpy.random.seed", "print", "torch.cuda.manual_seed"], "function", ["None"], ["def", "set_random_seed", "(", "random_seed", "=", "999", ",", "device", "=", "'cuda'", ")", ":", "\n", "    ", "random", ".", "seed", "(", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "random_seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "if", "device", "!=", "'cuda'", ":", "\n", "            ", "print", "(", "\"WARNING: You have a CUDA device, so you should probably run with --deviceId [1|2|3]\"", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "random_seed", ")", "\n", "", "", "np", ".", "random", ".", "seed", "(", "random_seed", ")", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.__init__": [[24, 27], ["kargs.pop", "torch.optim.Adam.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "self", ".", "max_norm", "=", "kargs", ".", "pop", "(", "'max_norm'", ",", "-", "1", ")", "\n", "super", "(", "MyAdam", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step": [[28, 33], ["super().step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step"], ["", "def", "step", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "if", "self", ".", "max_norm", ">", "0", ":", "\n", "            ", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "group", "[", "'params'", "]", ",", "self", ".", "max_norm", ")", "\n", "", "", "super", "(", "MyAdam", ",", "self", ")", ".", "step", "(", "*", "args", ",", "**", "kargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.set_optimizer": [[9, 19], ["optimizer.MyAdam", "list", "train_model.named_parameters", "list", "list", "set", "set"], "function", ["None"], ["def", "set_optimizer", "(", "*", "args", ",", "lr", "=", "1e-3", ",", "l2", "=", "1e-5", ",", "max_norm", "=", "5", ")", ":", "\n", "    ", "params", "=", "[", "]", "\n", "for", "train_model", "in", "args", ":", "\n", "        ", "params", "+=", "list", "(", "train_model", ".", "named_parameters", "(", ")", ")", "\n", "", "grouped_params", "=", "[", "\n", "{", "'params'", ":", "list", "(", "set", "(", "[", "p", "for", "n", ",", "p", "in", "params", "if", "p", ".", "requires_grad", "and", "'bias'", "not", "in", "n", "]", ")", ")", ",", "'weight_decay'", ":", "l2", "}", ",", "\n", "{", "'params'", ":", "list", "(", "set", "(", "[", "p", "for", "n", ",", "p", "in", "params", "if", "p", ".", "requires_grad", "and", "'bias'", "in", "n", "]", ")", ")", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "MyAdam", "(", "grouped_params", ",", "lr", "=", "lr", ",", "max_norm", "=", "max_norm", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.__init__": [[8, 29], ["super().__init__", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "vocab.Vocab.read_vocab", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "task", "=", "'semantic_parsing'", ",", "copy", "=", "False", ")", ":", "\n", "        ", "super", "(", "Vocab", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "dirname", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "'overnight'", ")", "if", "dataset", "!=", "'atis'", "and", "dataset", "!=", "'geo'", "else", "os", ".", "path", ".", "join", "(", "'data'", ",", "dataset", ")", "\n", "word_path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.word'", ")", "\n", "lf_path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.lf'", ")", "\n", "copy_path", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "dataset", "+", "'_vocab.copy'", ")", "\n", "if", "task", "==", "'semantic_parsing'", ":", "\n", "            ", "self", ".", "word2id", ",", "self", ".", "id2word", "=", "self", ".", "read_vocab", "(", "word_path", ",", "bos_eos", "=", "False", ")", "\n", "self", ".", "lf2id", ",", "self", ".", "id2lf", "=", "self", ".", "read_vocab", "(", "lf_path", ",", "bos_eos", "=", "True", ")", "\n", "", "elif", "task", "==", "'question_generation'", ":", "\n", "            ", "self", ".", "word2id", ",", "self", ".", "id2word", "=", "self", ".", "read_vocab", "(", "word_path", ",", "bos_eos", "=", "True", ")", "\n", "if", "copy", ":", "\n", "                ", "self", ".", "lf2id", ",", "self", ".", "id2lf", "=", "self", ".", "read_vocab", "(", "lf_path", ",", "copy_path", ",", "bos_eos", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "lf2id", ",", "self", ".", "id2lf", "=", "self", ".", "read_vocab", "(", "lf_path", ",", "bos_eos", "=", "False", ")", "\n", "", "", "elif", "task", "==", "'language_model'", ":", "\n", "            ", "self", ".", "word2id", ",", "self", ".", "id2word", "=", "self", ".", "read_vocab", "(", "word_path", ",", "bos_eos", "=", "True", ")", "\n", "self", ".", "lf2id", ",", "self", ".", "id2lf", "=", "self", ".", "read_vocab", "(", "lf_path", ",", "bos_eos", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'[Error]: unknown task !'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.vocab.Vocab.read_vocab": [[30, 58], ["len", "idx2word.append", "len", "idx2word.append", "len", "idx2word.append", "len", "idx2word.append", "open", "line.strip.strip.strip", "len", "line.strip.strip.split", "idx2word.append"], "methods", ["None"], ["", "", "def", "read_vocab", "(", "self", ",", "*", "args", ",", "bos_eos", "=", "True", ",", "pad", "=", "True", ",", "unk", "=", "True", ",", "separator", "=", "' : '", ")", ":", "\n", "        ", "word2idx", ",", "idx2word", "=", "{", "}", ",", "[", "]", "\n", "if", "pad", ":", "\n", "            ", "word2idx", "[", "PAD", "]", "=", "len", "(", "word2idx", ")", "\n", "idx2word", ".", "append", "(", "PAD", ")", "\n", "", "if", "unk", ":", "\n", "            ", "word2idx", "[", "UNK", "]", "=", "len", "(", "word2idx", ")", "\n", "idx2word", ".", "append", "(", "UNK", ")", "\n", "", "if", "bos_eos", ":", "\n", "            ", "word2idx", "[", "BOS", "]", "=", "len", "(", "word2idx", ")", "\n", "idx2word", ".", "append", "(", "BOS", ")", "\n", "word2idx", "[", "EOS", "]", "=", "len", "(", "word2idx", ")", "\n", "idx2word", ".", "append", "(", "EOS", ")", "\n", "", "for", "vocab_path", "in", "args", ":", "\n", "            ", "with", "open", "(", "vocab_path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                        ", "continue", "\n", "", "if", "separator", "in", "line", ":", "\n", "                        ", "word", ",", "_", "=", "line", ".", "split", "(", "separator", ")", "\n", "", "else", ":", "\n", "                        ", "word", "=", "line", "\n", "", "idx", "=", "len", "(", "word2idx", ")", "\n", "if", "word", "not", "in", "word2idx", ":", "\n", "                        ", "word2idx", "[", "word", "]", "=", "idx", "\n", "idx2word", ".", "append", "(", "word", ")", "\n", "", "", "", "", "return", "word2idx", ",", "idx2word", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.__init__": [[24, 43], ["atis_evaluator.ATISEvaluator._load_ontology"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator._load_ontology"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            entity: set of types, {'bool', 'flight', 'ci', 'ap', ... }\n            unary: dict of unary predicate, value of each key is a type set\n                \"oneway\": {\"flight\"}\n            binary: dict of binary predicate, value of each key is a type-tuple set\n                \"from\": {(\"flight\", \"ci\"), (\"flight\", \"ap\")}\n        \"\"\"", "\n", "self", ".", "entity", ",", "self", ".", "comparable", ",", "self", ".", "unary", ",", "self", ".", "binary", "=", "self", ".", "_load_ontology", "(", "'data/atis/atis_ontology.txt'", ")", "\n", "self", ".", "vars", "=", "[", "\"$0\"", ",", "\"$1\"", ",", "\"$2\"", ",", "\"$3\"", ",", "\"$4\"", "]", "# type must be consistent", "\n", "self", ".", "key_word_func", "=", "{", "\n", "\"lambda\"", ":", "self", ".", "check_arguments_of_lambda", ",", "\"exists\"", ":", "self", ".", "check_arguments_of_exists", ",", "\n", "\"and\"", ":", "self", ".", "check_arguments_of_and_or", ",", "\"or\"", ":", "self", ".", "check_arguments_of_and_or", ",", "\n", "\"max\"", ":", "self", ".", "check_arguments_of_max_min", ",", "\"min\"", ":", "self", ".", "check_arguments_of_max_min", ",", "\n", "\"argmax\"", ":", "self", ".", "check_arguments_of_argmax_argmin", ",", "\"argmin\"", ":", "self", ".", "check_arguments_of_argmax_argmin", ",", "\n", "\"sum\"", ":", "self", ".", "check_arguments_of_sum", ",", "\"count\"", ":", "self", ".", "check_arguments_of_count", ",", "\n", "\">\"", ":", "self", ".", "check_arguments_of_compare", ",", "\"<\"", ":", "self", ".", "check_arguments_of_compare", ",", "\n", "\"=\"", ":", "self", ".", "check_arguments_of_equal", ",", "\"the\"", ":", "self", ".", "check_arguments_of_the", ",", "\n", "\"not\"", ":", "self", ".", "check_arguments_of_not", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator._load_ontology": [[45, 89], ["set", "set", "open", "line.strip.strip.strip", "line.strip.strip.startswith", "entity.add", "line.strip.strip.startswith", "print", "print", "line.strip.strip.split", "comparable.add", "unary[].add", "line.strip.strip.startswith", "print", "line.strip.strip.split", "set", "unary[].add", "line.strip.strip.startswith", "line.strip.strip.split", "set", "binary[].add", "print", "len", "print", "line.strip.strip.split", "set", "line.strip.strip.split", "t1.index", "len", "t2.index", "len"], "methods", ["None"], ["", "def", "_load_ontology", "(", "self", ",", "path", ")", ":", "\n", "        ", "entity", ",", "comparable", ",", "unary", ",", "binary", "=", "set", "(", "{", "\"flight\"", ",", "\"bool\"", "}", ")", ",", "set", "(", ")", ",", "{", "}", ",", "{", "}", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "infile", ":", "\n", "            ", "for", "line", "in", "infile", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", ":", "continue", "\n", "if", "line", ".", "startswith", "(", "'entity'", ")", ":", "\n", "                    ", "ent", ",", "flag", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", ":", "3", "]", "\n", "entity", ".", "add", "(", "ent", ")", "\n", "if", "flag", "==", "'yes'", ":", "\n", "                        ", "comparable", ".", "add", "(", "ent", ")", "\n", "", "", "elif", "line", ".", "startswith", "(", "'unary'", ")", ":", "\n", "                    ", "u", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "\n", "if", "u", "not", "in", "unary", ":", "\n", "                        ", "unary", "[", "u", "]", "=", "set", "(", ")", "\n", "", "unary", "[", "u", "]", ".", "add", "(", "\"flight\"", ")", "\n", "", "elif", "line", ".", "startswith", "(", "\"cat\"", ")", ":", "\n", "                    ", "u", ",", "t", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", ":", "]", "\n", "if", "u", "not", "in", "unary", ":", "\n", "                        ", "unary", "[", "u", "]", "=", "set", "(", ")", "\n", "", "unary", "[", "u", "]", ".", "add", "(", "t", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'binary'", ")", ":", "\n", "                    ", "if", "len", "(", "line", ".", "split", "(", "'\\t'", ")", ")", "!=", "4", ":", "\n", "                        ", "print", "(", "line", ")", "\n", "", "t1", ",", "b", ",", "t2", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", ":", "]", "\n", "t1", ",", "t2", "=", "t1", "[", "t1", ".", "index", "(", "'type:'", ")", "+", "len", "(", "'type:'", ")", ":", "]", ",", "t2", "[", "t2", ".", "index", "(", "'type:'", ")", "+", "len", "(", "'type:'", ")", ":", "]", "\n", "if", "b", "not", "in", "binary", ":", "\n", "                        ", "binary", "[", "b", "]", "=", "set", "(", ")", "\n", "", "binary", "[", "b", "]", ".", "add", "(", "(", "t1", ",", "t2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "'[Warning]: unrecognized line while loading ontology %s'", "%", "(", "line", ")", ")", "\n", "", "", "", "for", "each", "in", "unary", ":", "\n", "            ", "types", "=", "unary", "[", "each", "]", "\n", "for", "t", "in", "types", ":", "\n", "                ", "if", "t", "not", "in", "entity", ":", "\n", "                    ", "print", "(", "'[Error]: args type %s of unary %s not recognized'", "%", "(", "t", ",", "each", ")", ")", "\n", "", "", "", "for", "each", "in", "binary", ":", "\n", "            ", "types", "=", "binary", "[", "each", "]", "\n", "for", "(", "t1", ",", "t2", ")", "in", "types", ":", "\n", "                ", "if", "t1", "not", "in", "entity", ":", "\n", "                    ", "print", "(", "'[Error]: 1st args type %s of binary %s not recognized'", "%", "(", "t1", ",", "each", ")", ")", "\n", "", "elif", "t2", "not", "in", "entity", ":", "\n", "                    ", "print", "(", "'[Error]: 2nd args type %s of binary %s not recognized'", "%", "(", "t2", ",", "each", ")", ")", "\n", "", "", "", "return", "entity", ",", "comparable", ",", "unary", ",", "binary", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval": [[90, 101], ["atis_evaluator.ATISEvaluator.check_type_consistency"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "eval", "(", "self", ",", "lf", ")", ":", "\n", "        ", "\"\"\"\n            lf(list): lisp tree of lambda calculus logical form, e.g.\n                ['lambda', '$0', 'e', ['flight', '$0']]\n            If type consistent, return 1.0, else 0.0\n        \"\"\"", "\n", "try", ":", "\n", "            ", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", ",", "{", "}", ")", "\n", "return", "1.0", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency": [[102, 113], ["type", "atis_evaluator.ATISEvaluator.get_entity_type", "atis_evaluator.ATISEvaluator.check_arguments_of_predicate", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.get_entity_type", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_predicate"], ["", "", "def", "check_type_consistency", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "type", "(", "lf", ")", "!=", "list", ":", "# entity", "\n", "            ", "t", ",", "variables", "=", "self", ".", "get_entity_type", "(", "lf", ",", "variables", ")", "\n", "return", "t", ",", "variables", "\n", "", "p", "=", "lf", "[", "0", "]", "\n", "if", "p", "in", "self", ".", "key_word_func", ":", "\n", "            ", "return", "self", ".", "key_word_func", "[", "p", "]", "(", "lf", ",", "variables", ")", "\n", "", "elif", "p", "in", "self", ".", "unary", "or", "p", "in", "self", ".", "binary", ":", "\n", "            ", "return", "self", ".", "check_arguments_of_predicate", "(", "lf", ",", "variables", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: not recognized predicate %s'", "%", "(", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_predicate": [[114, 142], ["atis_evaluator.ATISEvaluator.check_arguments_of_unary", "atis_evaluator.ATISEvaluator.check_arguments_of_binary", "atis_evaluator.merge_variables", "ValueError", "len", "atis_evaluator.ATISEvaluator.check_arguments_of_binary", "copy.deepcopy", "atis_evaluator.ATISEvaluator.check_arguments_of_unary", "atis_evaluator.ATISEvaluator.check_arguments_of_binary", "len", "ValueError", "t.pop", "set", "set", "len", "type", "set", "type", "set"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_unary", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_binary", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.merge_variables", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_binary", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_unary", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_binary"], ["", "", "def", "check_arguments_of_predicate", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "p", "=", "lf", "[", "0", "]", "\n", "if", "p", "in", "self", ".", "unary", "and", "p", "not", "in", "self", ".", "binary", ":", "\n", "            ", "return", "self", ".", "check_arguments_of_unary", "(", "lf", ",", "variables", ")", "\n", "", "elif", "p", "not", "in", "self", ".", "unary", "and", "p", "in", "self", ".", "binary", ":", "\n", "            ", "return", "self", ".", "check_arguments_of_binary", "(", "lf", ",", "variables", ")", "\n", "", "elif", "p", "in", "self", ".", "unary", "and", "p", "in", "self", ".", "binary", ":", "# ambiguous predicate", "\n", "            ", "if", "len", "(", "lf", ")", "==", "3", ":", "\n", "                ", "return", "self", ".", "check_arguments_of_binary", "(", "lf", ",", "variables", ")", "\n", "", "try", ":", "\n", "                ", "another_variables", "=", "copy", ".", "deepcopy", "(", "variables", ")", "\n", "u_t", ",", "u_variables", "=", "self", ".", "check_arguments_of_unary", "(", "lf", ",", "another_variables", ")", "\n", "u_t", "=", "set", "(", "[", "u_t", "]", ")", "if", "type", "(", "u_t", ")", "!=", "set", "else", "u_t", "\n", "", "except", ":", "\n", "                ", "u_t", ",", "u_variables", "=", "set", "(", ")", ",", "{", "}", "\n", "", "try", ":", "\n", "                ", "b_t", ",", "b_variables", "=", "self", ".", "check_arguments_of_binary", "(", "lf", ",", "variables", ")", "\n", "b_t", "=", "set", "(", "[", "b_t", "]", ")", "if", "type", "(", "b_t", ")", "!=", "set", "else", "b_t", "\n", "", "except", ":", "\n", "                ", "b_t", ",", "b_variables", "=", "set", "(", ")", ",", "{", "}", "\n", "", "t", "=", "u_t", "|", "b_t", "\n", "if", "len", "(", "t", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of predicate %s'", "%", "(", "p", ")", ")", "\n", "", "t", "=", "t", "if", "len", "(", "t", ")", ">", "1", "else", "t", ".", "pop", "(", ")", "\n", "variables", "=", "merge_variables", "(", "u_variables", ",", "b_variables", ")", "\n", "return", "t", ",", "variables", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: not recognized predicate %s'", "%", "(", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_unary": [[143, 160], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "type", "len", "ValueError", "ValueError", "t.pop", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "", "def", "check_arguments_of_unary", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: unary predicate %s only allow one argument'", "%", "(", "lf", "[", "0", "]", ")", ")", "\n", "", "p", ",", "args", "=", "lf", "[", "0", "]", ",", "lf", "[", "1", "]", "\n", "allowed_types", "=", "self", ".", "unary", "[", "p", "]", "\n", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "args", ",", "variables", ")", "\n", "if", "type", "(", "t", ")", "==", "set", ":", "\n", "            ", "t", "=", "t", "&", "allowed_types", "\n", "if", "len", "(", "t", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of unary predicate %s and argument %s'", "%", "(", "p", ",", "args", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "args", "in", "self", ".", "vars", ":", "# args must be vars ?", "\n", "                    ", "variables", "[", "args", "]", "=", "t", "if", "len", "(", "t", ")", ">", "1", "else", "t", ".", "pop", "(", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "t", "not", "in", "allowed_types", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of unary predicate %s and argument %s'", "%", "(", "p", ",", "args", ")", ")", "\n", "", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_binary": [[161, 203], ["len", "atis_evaluator.ATISEvaluator.check_type_consistency", "set", "type", "set", "set", "len", "ValueError", "set.pop", "len", "atis_evaluator.ATISEvaluator.check_type_consistency", "atis_evaluator.ATISEvaluator.check_type_consistency", "ValueError", "set", "type", "t1.pop", "len", "type", "set", "set", "len", "ValueError", "type", "set", "set", "len", "ValueError", "len", "set", "set", "type", "t1.pop", "type", "set.pop", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_binary", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "p", ",", "args", "=", "lf", "[", "0", "]", ",", "lf", "[", "1", ":", "]", "\n", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "            ", "allowed_types", "=", "self", ".", "binary", "[", "p", "]", "\n", "t1", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "args", "[", "0", "]", ",", "variables", ")", "\n", "if", "type", "(", "t1", ")", "==", "set", ":", "\n", "                ", "t1", "=", "t1", "&", "set", "(", "[", "i", "for", "i", ",", "_", "in", "allowed_types", "if", "i", "in", "t1", "]", ")", "\n", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "i", "in", "t1", "]", ")", "\n", "", "else", ":", "\n", "                ", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "i", "==", "t1", "]", ")", "\n", "", "if", "len", "(", "allowed_types", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of binary predicate %s and first argument %s'", "%", "(", "p", ",", "args", "[", "0", "]", ")", ")", "\n", "", "if", "type", "(", "t1", ")", "==", "set", "and", "args", "[", "0", "]", "in", "self", ".", "vars", ":", "\n", "                ", "variables", "[", "args", "[", "0", "]", "]", "=", "t1", "if", "len", "(", "t1", ")", ">", "1", "else", "t1", ".", "pop", "(", ")", "\n", "", "t2", "=", "set", "(", "[", "j", "for", "_", ",", "j", "in", "allowed_types", "]", ")", "\n", "t2", "=", "t2", "if", "len", "(", "t2", ")", ">", "1", "else", "t2", ".", "pop", "(", ")", "\n", "return", "t2", ",", "variables", "\n", "", "elif", "len", "(", "args", ")", "==", "2", ":", "\n", "            ", "allowed_types", "=", "self", ".", "binary", "[", "p", "]", "\n", "t1", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "args", "[", "0", "]", ",", "variables", ")", "\n", "if", "type", "(", "t1", ")", "==", "set", ":", "\n", "                ", "t1", "=", "t1", "&", "set", "(", "[", "i", "for", "i", ",", "_", "in", "allowed_types", "if", "i", "in", "t1", "]", ")", "\n", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "i", "in", "t1", "]", ")", "\n", "", "else", ":", "\n", "                ", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "i", "==", "t1", "]", ")", "\n", "", "if", "len", "(", "allowed_types", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of binary predicate %s and first argument %s'", "%", "(", "p", ",", "args", "[", "0", "]", ")", ")", "\n", "", "t2", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "args", "[", "1", "]", ",", "variables", ")", "\n", "if", "type", "(", "t2", ")", "==", "set", ":", "\n", "                ", "t2", "=", "t2", "&", "set", "(", "[", "j", "for", "_", ",", "j", "in", "allowed_types", "if", "j", "in", "t2", "]", ")", "\n", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "j", "in", "t2", "]", ")", "\n", "", "else", ":", "\n", "                ", "allowed_types", "=", "set", "(", "[", "(", "i", ",", "j", ")", "for", "i", ",", "j", "in", "allowed_types", "if", "j", "==", "t2", "]", ")", "\n", "", "if", "len", "(", "allowed_types", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: type inconsistency of binary predicate %s and second argument %s'", "%", "(", "p", ",", "args", "[", "1", "]", ")", ")", "\n", "", "if", "type", "(", "t1", ")", "==", "set", "and", "args", "[", "0", "]", "in", "self", ".", "vars", ":", "\n", "                ", "variables", "[", "args", "[", "0", "]", "]", "=", "t1", "if", "len", "(", "t1", ")", ">", "1", "else", "t1", ".", "pop", "(", ")", "\n", "", "if", "type", "(", "t2", ")", "==", "set", "and", "args", "[", "1", "]", "in", "self", ".", "vars", ":", "\n", "                ", "variables", "[", "args", "[", "1", "]", "]", "=", "t2", "if", "len", "(", "t2", ")", ">", "1", "else", "t2", ".", "pop", "(", ")", "\n", "", "return", "'bool'", ",", "variables", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: binary predicate %s only allow one or two arguments'", "%", "(", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.get_entity_type": [[204, 215], ["ValueError", "ent.endswith", "ent.startswith", "range", "str"], "methods", ["None"], ["", "", "def", "get_entity_type", "(", "self", ",", "ent", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "ent", "in", "self", ".", "vars", ":", "\n", "            ", "return", "variables", "[", "ent", "]", ",", "variables", "\n", "", "for", "e", "in", "self", ".", "entity", ":", "\n", "            ", "if", "ent", ".", "endswith", "(", "':'", "+", "e", ")", ":", "\n", "                ", "return", "e", ",", "variables", "\n", "", "elif", "ent", ".", "startswith", "(", "e", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "                    ", "if", "ent", "==", "e", "+", "str", "(", "i", ")", ":", "\n", "                        ", "return", "e", ",", "variables", "\n", "", "", "", "", "raise", "ValueError", "(", "'[ERROR]: not recoginized entity %s'", "%", "(", "ent", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_lambda": [[216, 232], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_lambda", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: lambda function %s must have three arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", "=", "lf", "[", "1", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of lambda function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "e", "=", "lf", "[", "2", "]", "\n", "if", "e", "not", "in", "[", "\"e\"", ",", "\"i\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of lambda function %s must be e or i'", "%", "(", "lf", ")", ")", "\n", "", "c", "=", "lf", "[", "3", "]", "\n", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: third argument of lambda function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_exists": [[233, 246], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_exists", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: exists function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", "=", "lf", "[", "1", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of exists function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "c", "=", "lf", "[", "2", "]", "\n", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of exists function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_and_or": [[247, 255], ["enumerate", "len", "ValueError", "atis_evaluator.ATISEvaluator.check_type_consistency", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_and_or", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "<", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: and/or function %s at least have one constraints'", "%", "(", "lf", ")", ")", "\n", "", "for", "idx", ",", "c", "in", "enumerate", "(", "lf", "[", "1", ":", "]", ")", ":", "\n", "            ", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: %s-th argument of and/or function %s must be bool constraint'", "%", "(", "idx", ",", "c", ")", ")", "\n", "", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_max_min": [[256, 268], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_max_min", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: max/min function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", ",", "c", "=", "lf", "[", "1", "]", ",", "lf", "[", "2", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of max/min function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "comparable", "# can be any comparable type", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of max/min function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "return", "variables", "[", "v", "]", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_argmax_argmin": [[269, 289], ["atis_evaluator.ATISEvaluator.check_type_consistency", "atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError", "type", "len", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_argmax_argmin", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: argmax/argmin function %s must have three arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", ",", "c", ",", "s", "=", "lf", "[", "1", "]", ",", "lf", "[", "2", "]", ",", "lf", "[", "3", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of argmax/argmin function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of argmin/argmax function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "s", ",", "variables", ")", "\n", "if", "type", "(", "t", ")", "==", "set", ":", "\n", "            ", "t", "=", "t", "&", "self", ".", "comparable", "\n", "if", "len", "(", "t", ")", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: third argument of argmin/argmax function %s must be comparable type'", "%", "(", "lf", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "t", "not", "in", "self", ".", "comparable", ":", "\n", "                ", "raise", "ValueError", "(", "'[ERROR]: third argument of argmin/argmax function %s must be comparable type'", "%", "(", "lf", ")", ")", "\n", "", "", "return", "variables", "[", "v", "]", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_sum": [[290, 306], ["atis_evaluator.ATISEvaluator.check_type_consistency", "atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError", "ValueError", "type"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_sum", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "4", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: sum function %s must have three arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", ",", "c", ",", "s", "=", "lf", "[", "1", "]", ",", "lf", "[", "2", "]", ",", "lf", "[", "3", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of sum function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of sum function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "s", ",", "variables", ")", "\n", "t", "=", "[", "t", "]", "if", "type", "(", "t", ")", "!=", "set", "else", "t", "\n", "if", "'i'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: third argument of sum function %s must be integer(i) type'", "%", "(", "lf", ")", ")", "\n", "", "return", "'i'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_count": [[307, 319], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_count", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: count function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", ",", "c", "=", "lf", "[", "1", "]", ",", "lf", "[", "2", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of count function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of count function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "return", "'i'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_compare": [[320, 337], ["atis_evaluator.ATISEvaluator.check_type_consistency", "atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "set", "set", "len", "ValueError", "type", "type", "len", "t.pop.pop.pop"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_compare", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: >/< function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "t1", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", "[", "1", "]", ",", "variables", ")", "\n", "t2", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", "[", "2", "]", ",", "variables", ")", "\n", "t1", "=", "set", "(", "[", "t1", "]", ")", "if", "type", "(", "t1", ")", "!=", "set", "else", "t1", "\n", "t2", "=", "set", "(", "[", "t2", "]", ")", "if", "type", "(", "t2", ")", "!=", "set", "else", "t2", "\n", "t", "=", "t1", "&", "t2", "&", "self", ".", "comparable", "\n", "if", "len", "(", "t", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: arguments of >/< function %s must be the same comparable type'", "%", "(", "lf", ")", ")", "\n", "", "elif", "len", "(", "t", ")", "==", "1", ":", "\n", "            ", "t", "=", "t", ".", "pop", "(", ")", "\n", "if", "lf", "[", "1", "]", "in", "self", ".", "vars", ":", "\n", "                ", "variables", "[", "lf", "[", "1", "]", "]", "=", "t", "\n", "", "if", "lf", "[", "2", "]", "in", "self", ".", "vars", ":", "\n", "                ", "variables", "[", "lf", "[", "2", "]", "]", "=", "t", "\n", "", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_equal": [[338, 355], ["atis_evaluator.ATISEvaluator.check_type_consistency", "atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "set", "set", "len", "ValueError", "type", "type", "len", "t.pop.pop.pop"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_equal", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: = function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "t1", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", "[", "1", "]", ",", "variables", ")", "\n", "t2", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", "[", "2", "]", ",", "variables", ")", "\n", "t1", "=", "set", "(", "[", "t1", "]", ")", "if", "type", "(", "t1", ")", "!=", "set", "else", "t1", "\n", "t2", "=", "set", "(", "[", "t2", "]", ")", "if", "type", "(", "t2", ")", "!=", "set", "else", "t2", "\n", "t", "=", "t1", "&", "t2", "\n", "if", "len", "(", "t", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: arguments of = function %s must be the same type'", "%", "(", "lf", ")", ")", "\n", "", "elif", "len", "(", "t", ")", "==", "1", ":", "\n", "            ", "t", "=", "t", ".", "pop", "(", ")", "\n", "", "if", "lf", "[", "1", "]", "in", "self", ".", "vars", ":", "\n", "            ", "variables", "[", "lf", "[", "1", "]", "]", "=", "t", "\n", "", "if", "lf", "[", "2", "]", "in", "self", ".", "vars", ":", "\n", "            ", "variables", "[", "lf", "[", "2", "]", "]", "=", "t", "\n", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_not": [[356, 363], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_not", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: not function %s only allow one argument'", "%", "(", "lf", ")", ")", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "lf", "[", "1", "]", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: argument of not function must be bool type'", "%", "(", "lf", ")", ")", "\n", "", "return", "'bool'", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_arguments_of_the": [[364, 376], ["atis_evaluator.ATISEvaluator.check_type_consistency", "len", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.check_type_consistency"], ["", "def", "check_arguments_of_the", "(", "self", ",", "lf", ",", "variables", "=", "{", "}", ")", ":", "\n", "        ", "if", "len", "(", "lf", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: the function %s must have two arguments'", "%", "(", "lf", ")", ")", "\n", "", "v", ",", "c", "=", "lf", "[", "1", "]", ",", "lf", "[", "2", "]", "\n", "if", "v", "not", "in", "self", ".", "vars", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: first argument of the function %s must be in the form $\\{number\\}'", "%", "(", "lf", ")", ")", "\n", "", "if", "v", "not", "in", "variables", ":", "\n", "            ", "variables", "[", "v", "]", "=", "self", ".", "entity", "# can be any type", "\n", "", "t", ",", "variables", "=", "self", ".", "check_type_consistency", "(", "c", ",", "variables", ")", "\n", "if", "t", "!=", "'bool'", "and", "'bool'", "not", "in", "t", ":", "\n", "            ", "raise", "ValueError", "(", "'[ERROR]: second argument of the function %s must be bool constraint'", "%", "(", "lf", ")", ")", "\n", "", "return", "variables", "[", "v", "]", ",", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.merge_variables": [[6, 21], ["set", "set", "v1.keys", "v2.keys", "set", "set", "merged_v[].pop", "set", "set", "len", "type", "type"], "function", ["None"], ["def", "merge_variables", "(", "v1", ",", "v2", ")", ":", "\n", "    ", "keys", "=", "set", "(", "v1", ".", "keys", "(", ")", ")", "|", "set", "(", "v2", ".", "keys", "(", ")", ")", "\n", "merged_v", "=", "{", "}", "\n", "for", "k", "in", "keys", ":", "\n", "        ", "if", "k", "in", "v1", ":", "\n", "            ", "value1", "=", "v1", "[", "k", "]", "if", "type", "(", "v1", "[", "k", "]", ")", "==", "set", "else", "set", "(", "[", "v1", "[", "k", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "value1", "=", "set", "(", ")", "\n", "", "if", "k", "in", "v2", ":", "\n", "            ", "value2", "=", "v2", "[", "k", "]", "if", "type", "(", "v2", "[", "k", "]", ")", "==", "set", "else", "set", "(", "[", "v2", "[", "k", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "value2", "=", "set", "(", ")", "\n", "", "merged_v", "[", "k", "]", "=", "value1", "|", "value2", "\n", "merged_v", "[", "k", "]", "=", "merged_v", "[", "k", "]", "if", "len", "(", "merged_v", "[", "k", "]", ")", ">", "1", "else", "merged_v", "[", "k", "]", ".", "pop", "(", ")", "\n", "", "return", "merged_v", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_overnight.OvernightDomain.__init__": [[11, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "denotation", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_overnight.OvernightDomain.normalize": [[15, 32], ["re.sub", "lf.replace.replace.strip", "domain_overnight.OvernightDomain.normalize.format_overnight"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "lf_list", "=", "[", "' '", ".", "join", "(", "lf", ")", "for", "lf", "in", "lf_list", "]", "\n", "\n", "def", "format_overnight", "(", "lf", ")", ":", "\n", "            ", "replacements", "=", "[", "\n", "(", "'('", ",", "' ( '", ")", ",", "# make sure ( and ) must have blank space around", "\n", "(", "')'", ",", "' ) '", ")", ",", "\n", "(", "'! '", ",", "'!'", ")", ",", "\n", "(", "'SW'", ",", "'edu.stanford.nlp.sempre.overnight.SimpleWorld'", ")", ",", "\n", "]", "\n", "for", "a", ",", "b", "in", "replacements", ":", "\n", "                ", "lf", "=", "lf", ".", "replace", "(", "a", ",", "b", ")", "\n", "# remove redundant blank spaces", "\n", "", "lf", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "lf", ")", "\n", "return", "lf", ".", "strip", "(", ")", "\n", "\n", "", "return", "[", "format_overnight", "(", "lf", ")", "for", "lf", "in", "lf_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_overnight.OvernightDomain.obtain_denotations": [[33, 46], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.flush", "subprocess.check_output", "msg.decode.decode.decode", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile.write", "line.split", "msg.decode.decode.split", "line.startswith"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode"], ["", "def", "obtain_denotations", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "tf", "=", "tempfile", ".", "NamedTemporaryFile", "(", "'w+t'", ",", "encoding", "=", "'utf8'", ",", "suffix", "=", "'.examples'", ")", "\n", "for", "line", "in", "lf_list", ":", "\n", "            ", "tf", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "tf", ".", "flush", "(", ")", "\n", "msg", "=", "subprocess", ".", "check_output", "(", "[", "'evaluator/overnight'", ",", "self", ".", "dataset", ",", "tf", ".", "name", "]", ")", "\n", "msg", "=", "msg", ".", "decode", "(", "'utf8'", ")", "\n", "tf", ".", "close", "(", ")", "\n", "denotations", "=", "[", "\n", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "for", "line", "in", "msg", ".", "split", "(", "'\\n'", ")", "\n", "if", "line", ".", "startswith", "(", "'targetValue\\t'", ")", "\n", "]", "\n", "return", "denotations", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_overnight.OvernightDomain.is_valid": [[47, 49], ["list", "map"], "methods", ["None"], ["", "def", "is_valid", "(", "self", ",", "ans_list", ")", ":", "\n", "        ", "return", "list", "(", "map", "(", "lambda", "ans", ":", "0.0", "if", "'BADJAVA'", "in", "ans", "or", "'ERROR'", "in", "ans", "or", "ans", "==", "'null'", "else", "1.0", ",", "ans_list", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.__init__": [[9, 13], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Domain", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "denotation", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.from_dataset": [[14, 25], ["ATISDomain", "GEODomain", "OvernightDomain"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dataset", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "if", "dataset", "==", "'atis'", ":", "\n", "            ", "from", "utils", ".", "domain", ".", "domain_atis", "import", "ATISDomain", "\n", "return", "ATISDomain", "(", ")", "\n", "", "elif", "dataset", "==", "'geo'", ":", "\n", "            ", "from", "utils", ".", "domain", ".", "domain_geo", "import", "GEODomain", "\n", "return", "GEODomain", "(", ")", "\n", "", "else", ":", "\n", "            ", "from", "utils", ".", "domain", ".", "domain_overnight", "import", "OvernightDomain", "\n", "return", "OvernightDomain", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse": [[26, 63], ["vocab.index", "domain_base.Domain.reverse.trim"], "methods", ["None"], ["", "", "def", "reverse", "(", "self", ",", "idx_list", ",", "vocab", ",", "end_mask", "=", "EOS", ",", "oov_list", "=", "[", "]", ",", "\n", "special_list", "=", "[", "BOS", ",", "EOS", ",", "PAD", "]", ")", ":", "\n", "        ", "''' \n        Change idx list to token list without special tokens.\n        @args:\n            1. idx_list: list of idx list, not tensor\n            2. vocab: idx to token list\n            3. end_mask: stop parsing when meets this token\n            4. oov_list: out of tgt vocab words, but in src inputs\n            5. special_list: remove these tokens in sequence, list of symbols\n        @return:\n            token list\n        '''", "\n", "unk_index", "=", "vocab", ".", "index", "(", "UNK", ")", "\n", "n_best", "=", "len", "(", "idx_list", ")", "/", "len", "(", "oov_list", ")", "if", "oov_list", "else", "None", "\n", "seq", "=", "[", "\n", "[", "\n", "oov_list", "[", "int", "(", "idx", "/", "n_best", ")", "]", "[", "tok", "-", "len", "(", "vocab", ")", "]", "if", "tok", ">=", "len", "(", "vocab", ")", "else", "vocab", "[", "tok", "]", "for", "tok", "in", "tokens", "\n", "]", "\n", "for", "idx", ",", "tokens", "in", "enumerate", "(", "idx_list", ")", "\n", "]", "if", "oov_list", "else", "[", "[", "vocab", "[", "tok", "]", "if", "tok", "<", "len", "(", "vocab", ")", "else", "UNK", "for", "tok", "in", "tokens", "]", "for", "tokens", "in", "idx_list", "]", "\n", "\n", "def", "trim", "(", "s", ",", "t", ")", ":", "\n", "            ", "sentence", "=", "[", "]", "\n", "for", "w", "in", "s", ":", "\n", "                ", "if", "w", "==", "t", ":", "\n", "                    ", "break", "\n", "", "sentence", ".", "append", "(", "w", ")", "\n", "", "return", "sentence", "\n", "\n", "", "result", "=", "[", "trim", "(", "ex", ",", "end_mask", ")", "for", "ex", "in", "seq", "]", "\n", "\n", "def", "filter_special", "(", "tok", ")", ":", "\n", "            ", "return", "tok", "not", "in", "special_list", "\n", "\n", "", "result", "=", "[", "list", "(", "filter", "(", "filter_special", ",", "ex", ")", ")", "for", "ex", "in", "result", "]", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_question": [[64, 72], ["int", "list", "map", "len", "len", "range"], "methods", ["None"], ["", "def", "compare_question", "(", "self", ",", "predictions", ",", "references", ")", ":", "\n", "        ", "\"\"\"\n            predictions and references should be list of token list\n        \"\"\"", "\n", "n_best", "=", "int", "(", "len", "(", "predictions", ")", "/", "len", "(", "references", ")", ")", "\n", "references", "=", "[", "[", "ref", "]", "for", "ref", "in", "references", "for", "_", "in", "range", "(", "n_best", ")", "]", "\n", "bleu_list", "=", "list", "(", "map", "(", "get_bleu_score", ",", "predictions", ",", "references", ")", ")", "# sentence-level bleu score", "\n", "return", "bleu_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_logical_form": [[73, 90], ["domain_base.Domain.normalize", "domain_base.Domain.normalize", "int", "list", "domain_base.Domain.obtain_denotations", "domain_base.Domain.pick_predictions", "map", "len", "len", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.normalize", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.normalize", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.obtain_denotations", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.pick_predictions"], ["", "def", "compare_logical_form", "(", "self", ",", "predictions", ",", "references", ",", "pick", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n            predictions and references should be list of token list\n            pick(bool): pick the first prediction without syntax or execution error if n_best > 1\n        \"\"\"", "\n", "predictions", "=", "self", ".", "normalize", "(", "predictions", ")", "\n", "references", "=", "self", ".", "normalize", "(", "references", ")", "\n", "n_best", "=", "int", "(", "len", "(", "predictions", ")", "/", "len", "(", "references", ")", ")", "\n", "if", "self", ".", "denotation", ":", "\n", "            ", "all_lf", "=", "predictions", "+", "references", "\n", "denotations", "=", "self", ".", "obtain_denotations", "(", "all_lf", ")", "\n", "predictions", ",", "references", "=", "denotations", "[", ":", "len", "(", "predictions", ")", "]", ",", "denotations", "[", "len", "(", "predictions", ")", ":", "]", "\n", "", "if", "pick", ":", "\n", "            ", "predictions", ",", "_", "=", "self", ".", "pick_predictions", "(", "predictions", ",", "n_best", ")", "\n", "", "else", ":", "\n", "            ", "references", "=", "[", "each", "for", "each", "in", "references", "for", "_", "in", "range", "(", "n_best", ")", "]", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ",", "y", ":", "1.0", "if", "x", "==", "y", "else", "0.0", ",", "predictions", ",", "references", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.normalize": [[91, 96], ["None"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "\"\"\"\n            Normalize each logical form, at least changes token list into string list\n        \"\"\"", "\n", "return", "[", "' '", ".", "join", "(", "lf", ")", "for", "lf", "in", "lf_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.obtain_denotations": [[97, 102], ["None"], "methods", ["None"], ["", "def", "obtain_denotations", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "\"\"\"\n            Obtain denotations for each logical form\n        \"\"\"", "\n", "return", "lf_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.pick_predictions": [[103, 119], ["domain_base.Domain.is_valid", "int", "range", "range", "len", "return_ans.append", "return_idx.append", "int", "return_ans.append", "return_idx.append", "range", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.is_valid"], ["", "def", "pick_predictions", "(", "self", ",", "pred_ans", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "if", "n_best", "==", "1", ":", "\n", "            ", "return", "pred_ans", ",", "[", "i", "for", "i", "in", "range", "(", "len", "(", "pred_ans", ")", ")", "]", "\n", "", "flags", "=", "self", ".", "is_valid", "(", "pred_ans", ")", "\n", "batches", "=", "int", "(", "len", "(", "pred_ans", ")", "/", "n_best", ")", "\n", "return_ans", ",", "return_idx", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", "in", "range", "(", "batches", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "n_best", ")", ":", "\n", "                ", "if", "int", "(", "flags", "[", "idx", "*", "n_best", "+", "j", "]", ")", "==", "1", ":", "\n", "                    ", "return_ans", ".", "append", "(", "pred_ans", "[", "idx", "*", "n_best", "+", "j", "]", ")", "\n", "return_idx", ".", "append", "(", "idx", "*", "n_best", "+", "j", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "return_ans", ".", "append", "(", "pred_ans", "[", "idx", "*", "n_best", "]", ")", "\n", "return_idx", ".", "append", "(", "idx", "*", "n_best", ")", "\n", "", "", "return", "return_ans", ",", "return_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.is_valid": [[120, 126], ["range", "len"], "methods", ["None"], ["", "def", "is_valid", "(", "self", ",", "ans_list", ")", ":", "\n", "        ", "\"\"\"\n            Check whether ans is syntax or semantic invalid\n            ans_list(str list): denotation list or logical form list\n        \"\"\"", "\n", "raise", "[", "1.0", "for", "_", "in", "range", "(", "len", "(", "ans_list", ")", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.__init__": [[11, 14], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "'geo'", "\n", "self", ".", "denotation", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.normalize": [[15, 41], ["domain_geo.GEODomain.normalize.format_geo"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "def", "format_geo", "(", "lf", ")", ":", "\n", "            ", "\"\"\"\n                lf is token list\n                1. for entity longer than one word, add double quotes\n                2. remove underline _ for predicates\n                3. remove unnecessary space, except spaces in entities\n            \"\"\"", "\n", "toks", ",", "quoted_toks", ",", "in_quotes", "=", "[", "]", ",", "[", "]", ",", "False", "\n", "for", "t", "in", "lf", ":", "\n", "                ", "if", "in_quotes", ":", "\n", "                    ", "if", "t", "==", "\"'\"", ":", "# entity ending", "\n", "                        ", "toks", ".", "append", "(", "'\"%s\"'", "%", "' '", ".", "join", "(", "quoted_toks", ")", ")", "\n", "in_quotes", ",", "quoted_toks", "=", "False", ",", "[", "]", "\n", "", "else", ":", "\n", "                        ", "quoted_toks", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "if", "t", "==", "\"'\"", ":", "# entity start", "\n", "                        ", "in_quotes", "=", "True", "\n", "", "else", ":", "\n", "                        ", "if", "len", "(", "t", ")", ">", "1", "and", "t", ".", "startswith", "(", "'_'", ")", ":", "# predicate remove prefix _", "\n", "                            ", "toks", ".", "append", "(", "t", "[", "1", ":", "]", ")", "\n", "", "else", ":", "\n", "                            ", "toks", ".", "append", "(", "t", ")", "\n", "", "", "", "", "return", "''", ".", "join", "(", "toks", ")", "\n", "", "return", "[", "format_geo", "(", "lf", ")", "for", "lf", "in", "lf_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.obtain_denotations": [[42, 65], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.flush", "subprocess.check_output", "msg.decode.decode.decode", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile.write", "re.search", "domain_geo.GEODomain.obtain_denotations.get_denotation"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode"], ["", "def", "obtain_denotations", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "tf", "=", "tempfile", ".", "NamedTemporaryFile", "(", "'w+t'", ",", "encoding", "=", "'utf8'", ",", "suffix", "=", "'.dlog'", ")", "\n", "tf_lines", "=", "[", "'_parse([query], %s).'", "%", "lf", "for", "lf", "in", "lf_list", "]", "\n", "for", "line", "in", "tf_lines", ":", "\n", "            ", "tf", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "", "tf", ".", "flush", "(", ")", "\n", "msg", "=", "subprocess", ".", "check_output", "(", "[", "'evaluator/geoquery'", ",", "tf", ".", "name", "]", ")", "\n", "msg", "=", "msg", ".", "decode", "(", "'utf8'", ")", "\n", "tf", ".", "close", "(", ")", "\n", "\n", "def", "get_denotation", "(", "line", ")", ":", "\n", "            ", "m", "=", "re", ".", "search", "(", "'\\{[^}]*\\}'", ",", "line", ")", "\n", "if", "m", ":", "\n", "                ", "return", "m", ".", "group", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "return", "line", ".", "strip", "(", ")", "\n", "\n", "", "", "denotations", "=", "[", "\n", "get_denotation", "(", "line", ")", "\n", "for", "line", "in", "msg", ".", "split", "(", "'\\n'", ")", "\n", "if", "line", ".", "startswith", "(", "'        Example'", ")", "\n", "]", "\n", "return", "denotations", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.is_valid": [[66, 68], ["list", "map"], "methods", ["None"], ["", "def", "is_valid", "(", "self", ",", "ans_list", ")", ":", "\n", "        ", "return", "list", "(", "map", "(", "lambda", "ans", ":", "0.0", "if", "'FAILED'", "in", "ans", "or", "'Join failed syntactically'", "in", "ans", "else", "1.0", ",", "ans_list", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.__init__": [[9, 14], ["utils.domain.atis_evaluator.ATISEvaluator"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "dataset", "=", "'atis'", "\n", "self", ".", "denotation", "=", "False", "\n", "self", ".", "evaluator", "=", "ATISEvaluator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.to_lisp_tree": [[15, 37], ["domain_atis.ATISDomain.to_lisp_tree.recurse"], "methods", ["None"], ["", "def", "to_lisp_tree", "(", "self", ",", "toks", ")", ":", "\n", "        ", "'''\n            input(list): ['lambda', '$0', 'e', '(', 'flight', '$0', ')']\n            return(recursive list): ['lambda', '$0', 'e', ['flight', '$0']]\n        '''", "\n", "def", "recurse", "(", "i", ")", ":", "\n", "            ", "if", "toks", "[", "i", "]", "==", "'('", ":", "\n", "                ", "subtrees", "=", "[", "]", "\n", "j", "=", "i", "+", "1", "\n", "while", "True", ":", "\n", "                    ", "subtree", ",", "j", "=", "recurse", "(", "j", ")", "\n", "subtrees", ".", "append", "(", "subtree", ")", "\n", "if", "toks", "[", "j", "]", "==", "')'", ":", "\n", "                        ", "return", "subtrees", ",", "j", "+", "1", "\n", "", "", "", "else", ":", "\n", "                ", "return", "toks", "[", "i", "]", ",", "i", "+", "1", "\n", "\n", "", "", "try", ":", "\n", "            ", "lisp_tree", ",", "final_ind", "=", "recurse", "(", "0", ")", "\n", "return", "lisp_tree", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.sort_args": [[38, 60], ["domain_atis.ATISDomain.to_lisp_tree", "domain_atis.ATISDomain.to_lisp_tree.recurse"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.to_lisp_tree"], ["", "", "def", "sort_args", "(", "self", ",", "lf", ")", ":", "\n", "        ", "lisp_tree", "=", "self", ".", "to_lisp_tree", "(", "lf", ")", "\n", "if", "lisp_tree", "is", "None", ":", "# failed to convert to logical tree", "\n", "            ", "return", "' '", ".", "join", "(", "lf", ")", "\n", "\n", "", "def", "recurse", "(", "node", ")", ":", "# Post-order traversal, sort and/or subtrees", "\n", "            ", "if", "isinstance", "(", "node", ",", "str", ")", ":", "\n", "                ", "return", "\n", "", "for", "child", "in", "node", ":", "\n", "                ", "recurse", "(", "child", ")", "\n", "", "if", "node", "[", "0", "]", "in", "(", "'_and'", ",", "'_or'", ",", "'and'", ",", "'or'", ")", ":", "\n", "                ", "node", "[", "1", ":", "]", "=", "sorted", "(", "node", "[", "1", ":", "]", ",", "key", "=", "lambda", "x", ":", "str", "(", "x", ")", ")", "\n", "\n", "", "", "recurse", "(", "lisp_tree", ")", "\n", "\n", "def", "tree_to_str", "(", "node", ")", ":", "\n", "            ", "if", "isinstance", "(", "node", ",", "str", ")", ":", "\n", "                ", "return", "node", "\n", "", "else", ":", "\n", "                ", "return", "'( %s )'", "%", "' '", ".", "join", "(", "tree_to_str", "(", "child", ")", "for", "child", "in", "node", ")", "\n", "\n", "", "", "return", "tree_to_str", "(", "lisp_tree", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.normalize": [[61, 64], ["domain_atis.ATISDomain.sort_args"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.sort_args"], ["", "def", "normalize", "(", "self", ",", "lf_list", ")", ":", "\n", "        ", "sorted_lf_list", "=", "[", "self", ".", "sort_args", "(", "lf", ")", "for", "lf", "in", "lf_list", "]", "\n", "return", "sorted_lf_list", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.is_valid": [[65, 83], ["list", "list", "map", "map", "i.strip", "domain_atis.ATISDomain.to_lisp_tree", "enumerate", "domain_atis.ATISDomain.evaluator.eval", "lf.split", "i.strip"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.to_lisp_tree", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval"], ["", "def", "is_valid", "(", "self", ",", "ans_list", ")", ":", "\n", "\n", "        ", "def", "bracket_matching", "(", "lf", ")", ":", "\n", "            ", "left", "=", "0", "\n", "for", "each", "in", "lf", ":", "\n", "                ", "if", "each", "==", "'('", ":", "\n", "                    ", "left", "+=", "1", "\n", "", "elif", "each", "==", "')'", ":", "\n", "                    ", "left", "-=", "1", "\n", "", "if", "left", "<", "0", ":", "\n", "                    ", "return", "0.0", "\n", "", "", "return", "1.0", "if", "left", "==", "0", "else", "0.0", "\n", "\n", "", "ans_list", "=", "[", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "lf", ".", "split", "(", "' '", ")", "if", "i", ".", "strip", "(", ")", "!=", "''", "]", "for", "lf", "in", "ans_list", "]", "\n", "bracket_signal", "=", "list", "(", "map", "(", "bracket_matching", ",", "ans_list", ")", ")", "\n", "lisp_trees", "=", "[", "self", ".", "to_lisp_tree", "(", "each", ")", "if", "bracket_signal", "[", "idx", "]", "==", "1.0", "else", "None", "for", "idx", ",", "each", "in", "enumerate", "(", "ans_list", ")", "]", "\n", "type_consistency", "=", "[", "self", ".", "evaluator", ".", "eval", "(", "each", ")", "if", "each", "is", "not", "None", "else", "0.0", "for", "each", "in", "lisp_trees", "]", "\n", "return", "list", "(", "map", "(", "lambda", "x", ",", "y", ":", "(", "0.5", "if", "x", "is", "not", "None", "else", "0.0", ")", "+", "0.5", "*", "y", ",", "lisp_trees", ",", "type_consistency", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_semantic_parsing.SPSolver.__init__": [[11, 14], ["utils.solver.solver_base.Solver.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "SPSolver", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "best_result", "=", "{", "\"losses\"", ":", "[", "]", ",", "\"iter\"", ":", "0", ",", "\"dev_acc\"", ":", "0.", ",", "\"test_acc\"", ":", "0.", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_semantic_parsing.SPSolver.decode": [[15, 44], ["numpy.arange", "solver_semantic_parsing.SPSolver.model.eval", "len", "len", "open", "range", "of.write", "utils.batch.get_minibatch", "domain.compare_logical_form", "total.extend", "range", "sum", "float", "torch.no_grad", "solver_semantic_parsing.SPSolver.model.decode_batch", "domain.reverse", "len", "of.write", "of.write", "range", "of.write", "len", "of.write", "str"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_logical_form", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "data_index", "=", "np", ".", "arange", "(", "len", "(", "data_inputs", ")", ")", "\n", "nsentences", ",", "total", "=", "len", "(", "data_index", ")", ",", "[", "]", "\n", "domain", "=", "Example", ".", "domain", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "of", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "dec_inputs", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", ",", "task", "=", "'semantic_parsing'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", ",", "copy", "=", "self", ".", "model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", ".", "lf2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "pred", "for", "each", "in", "predictions", "for", "pred", "in", "each", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", ".", "id2lf", ",", "oov_list", "=", "oov_list", ")", "\n", "", "accuracy", "=", "domain", ".", "compare_logical_form", "(", "predictions", ",", "raw_outputs", ",", "pick", "=", "True", ")", "\n", "total", ".", "extend", "(", "accuracy", ")", "\n", "############################ Write result to file ############################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"Utterance: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n_best", ")", ":", "\n", "                        ", "of", ".", "write", "(", "\"Pred\"", "+", "str", "(", "i", ")", "+", "\": \"", "+", "' '", ".", "join", "(", "predictions", "[", "n_best", "*", "idx", "+", "i", "]", ")", "+", "'\\n'", ")", "\n", "", "of", ".", "write", "(", "\"Correct: \"", "+", "(", "\"True\"", "if", "accuracy", "[", "idx", "]", "==", "1", "else", "\"False\"", ")", "+", "'\\n\\n'", ")", "\n", "", "", "acc", "=", "sum", "(", "total", ")", "/", "float", "(", "len", "(", "total", ")", ")", "\n", "of", ".", "write", "(", "'Overall accuracy is %.4f'", "%", "(", "acc", ")", ")", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_semantic_parsing.SPSolver.train_and_decode": [[45, 105], ["numpy.arange", "len", "range", "solver_semantic_parsing.SPSolver.logger.info", "solver_semantic_parsing.SPSolver.model.load_model", "len", "time.time", "numpy.random.shuffle", "solver_semantic_parsing.SPSolver.model.train", "range", "print", "numpy.sum", "solver_semantic_parsing.SPSolver.best_result[].append", "solver_semantic_parsing.SPSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "time.time", "solver_semantic_parsing.SPSolver.decode", "solver_semantic_parsing.SPSolver.logger.info", "time.time", "solver_semantic_parsing.SPSolver.decode", "solver_semantic_parsing.SPSolver.logger.info", "os.path.join", "utils.batch.get_minibatch", "solver_semantic_parsing.SPSolver.model.zero_grad", "solver_semantic_parsing.SPSolver.model", "solver_semantic_parsing.SPSolver.loss_function", "losses.append", "solver_semantic_parsing.SPSolver.backward", "solver_semantic_parsing.SPSolver.model.pad_embedding_grad_zero", "solver_semantic_parsing.SPSolver.optimizer.step", "os.path.join", "os.path.join", "solver_semantic_parsing.SPSolver.model.save_model", "solver_semantic_parsing.SPSolver.logger.info", "solver_semantic_parsing.SPSolver.item", "os.path.join", "time.time", "str", "str", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model"], ["", "def", "train_and_decode", "(", "self", ",", "train_dataset", ",", "dev_dataset", ",", "test_dataset", ",", "batchSize", "=", "16", ",", "test_batchSize", "=", "128", ",", "\n", "max_epoch", "=", "100", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "train_data_index", "=", "np", ".", "arange", "(", "len", "(", "train_dataset", ")", ")", "\n", "nsentences", "=", "len", "(", "train_data_index", ")", "\n", "for", "i", "in", "range", "(", "max_epoch", ")", ":", "\n", "########################### Training Phase ############################", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_data_index", ")", "\n", "losses", "=", "[", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch", "(", "\n", "train_dataset", ",", "self", ".", "vocab", ",", "task", "=", "'semantic_parsing'", ",", "data_index", "=", "train_data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", ",", "copy", "=", "self", ".", "model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "batch_scores", "=", "self", ".", "model", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "############################ Loss Calculation #########################", "\n", "batch_loss", "=", "self", ".", "loss_function", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ")", "\n", "losses", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "########################### Backward and Optimize ######################", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "self", ".", "model", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "print", "(", "'[learning] epoch %i >> %3.2f%%'", "%", "(", "i", ",", "100", ")", ",", "'completed in %.2f (sec) <<'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "epoch_loss", "=", "np", ".", "sum", "(", "losses", ",", "axis", "=", "0", ")", "\n", "self", ".", "best_result", "[", "'losses'", "]", ".", "append", "(", "epoch_loss", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\t Loss: %.5f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "epoch_loss", ")", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "if", "i", "<", "10", ":", "\n", "                ", "continue", "\n", "\n", "########################### Evaluation Phase ############################", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "dev_acc", "=", "self", ".", "decode", "(", "dev_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Dev Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tAcc : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "dev_acc", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_acc", "=", "self", ".", "decode", "(", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Test Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tAcc : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "test_acc", ")", ")", "\n", "\n", "######################## Pick best result on dev and save #####################", "\n", "if", "dev_acc", ">=", "self", ".", "best_result", "[", "'dev_acc'", "]", ":", "\n", "                ", "self", ".", "model", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", "=", "dev_acc", ",", "test_acc", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST:\\tEpoch : %d\\tBest Valid Acc : %.4f;\\tBest Test Acc : %.4f'", "%", "(", "i", ",", "dev_acc", ",", "test_acc", ")", ")", "\n", "\n", "######################## Reload best model for later usage #####################", "\n", "", "", "self", ".", "logger", ".", "info", "(", "'FINAL BEST RESULT: \\tEpoch : %d\\tBest Valid (Acc : %.4f)\\tBest Test (Acc : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter'", "]", ",", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", ")", ")", "\n", "self", ".", "model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_pseduo_method.PseudoSolver.__init__": [[15, 22], ["kargs.pop", "kargs.pop", "utils.solver.solver_base.Solver.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "self", ".", "discount", "=", "kargs", ".", "pop", "(", "'discount'", ",", "0.5", ")", "\n", "self", ".", "method", "=", "kargs", ".", "pop", "(", "'method'", ",", "'constant'", ")", "\n", "super", "(", "PseudoSolver", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "best_result", "=", "{", "\n", "\"iter_sp\"", ":", "0", ",", "\"dev_acc\"", ":", "0.", ",", "\"test_acc\"", ":", "0.", ",", "\n", "\"iter_qg\"", ":", "0", ",", "\"dev_bleu\"", ":", "0.", ",", "\"test_bleu\"", ":", "0.", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_pseduo_method.PseudoSolver.decode": [[24, 81], ["numpy.arange", "len", "len", "open", "solver_pseduo_method.PseudoSolver.model[].eval", "range", "of.write", "solver_pseduo_method.PseudoSolver.model[].eval", "range", "utils.bleu.get_bleu_score", "of.write", "utils.batch.get_minibatch", "domain.compare_logical_form", "total.extend", "range", "utils.batch.get_minibatch", "domain.compare_question", "candidate_list.extend", "references_list.extend", "range", "sum", "float", "torch.no_grad", "solver_pseduo_method.PseudoSolver.model[].decode_batch", "domain.reverse", "len", "of.write", "of.write", "range", "of.write", "torch.no_grad", "solver_pseduo_method.PseudoSolver.model[].decode_batch", "domain.reverse", "len", "of.write", "of.write", "of.write", "of.write", "len", "of.write", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.bleu.get_bleu_score", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_logical_form", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_question", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "data_index", "=", "np", ".", "arange", "(", "len", "(", "data_inputs", ")", ")", "\n", "nsentences", "=", "len", "(", "data_index", ")", "\n", "domain", "=", "Example", ".", "domain", "\n", "total", ",", "candidate_list", ",", "references_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "########################### Evaluation Phase ############################", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "of", ":", "\n", "            ", "self", ".", "model", "[", "'sp'", "]", ".", "eval", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "_", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "task", "=", "'semantic_parsing'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", "[", "'sp'", "]", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", "[", "'sp'", "]", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "lf2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "pred", "for", "each", "in", "predictions", "for", "pred", "in", "each", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "id2lf", ",", "oov_list", "=", "oov_list", ")", "\n", "", "accuracy", "=", "domain", ".", "compare_logical_form", "(", "predictions", ",", "raw_outputs", ",", "pick", "=", "True", ")", "\n", "total", ".", "extend", "(", "accuracy", ")", "\n", "############################ Write result to file ############################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"Utterance: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n_best", ")", ":", "\n", "                        ", "of", ".", "write", "(", "\"Pred\"", "+", "str", "(", "i", ")", "+", "\": \"", "+", "' '", ".", "join", "(", "predictions", "[", "n_best", "*", "idx", "+", "i", "]", ")", "+", "'\\n'", ")", "\n", "", "of", ".", "write", "(", "\"Correct: \"", "+", "(", "\"True\"", "if", "accuracy", "[", "idx", "]", "==", "1", "else", "\"False\"", ")", "+", "'\\n\\n'", ")", "\n", "\n", "", "", "of", ".", "write", "(", "'='", "*", "50", "+", "'\\n'", "+", "'='", "*", "50", "+", "'\\n\\n'", ")", "\n", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "eval", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "_", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "task", "=", "'question_generation'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", "[", "'qg'", "]", ".", "copy", ")", "\n", "########################## Beam Search/Greed Decode #######################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", "[", "'qg'", "]", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "word2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "each", "[", "0", "]", "for", "each", "in", "predictions", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "id2word", ",", "oov_list", "=", "oov_list", ")", "\n", "", "bleu_scores", "=", "domain", ".", "compare_question", "(", "predictions", ",", "raw_outputs", ")", "\n", "candidate_list", ".", "extend", "(", "predictions", ")", "\n", "references_list", ".", "extend", "(", "[", "[", "ref", "]", "for", "ref", "in", "raw_outputs", "]", ")", "\n", "############################# Writing Result to File ###########################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"LogicalForm: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Pred0: \"", "+", "' '", ".", "join", "(", "predictions", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Bleu: \"", "+", "str", "(", "bleu_scores", "[", "idx", "]", ")", "+", "'\\n\\n'", ")", "\n", "########################### Calculate accuracy ###########################", "\n", "", "", "acc", "=", "sum", "(", "total", ")", "/", "float", "(", "len", "(", "total", ")", ")", "\n", "avg_bleu", "=", "get_bleu_score", "(", "candidate_list", ",", "references_list", ")", "\n", "of", ".", "write", "(", "'Overall accuracy: %.4f | Overall bleu score: %.4f'", "%", "(", "acc", ",", "avg_bleu", ")", ")", "\n", "", "return", "acc", ",", "avg_bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_pseduo_method.PseudoSolver.generate_pseudo_samples": [[82, 116], ["len", "numpy.arange", "solver_pseduo_method.PseudoSolver.model[].eval", "range", "len", "numpy.arange", "solver_pseduo_method.PseudoSolver.model[].eval", "range", "utils.batch.get_minibatch", "pseudo_samples.extend", "utils.batch.get_minibatch", "pseudo_samples.extend", "torch.no_grad", "solver_pseduo_method.PseudoSolver.model[].decode_batch", "domain.reverse", "domain.pick_predictions", "torch.no_grad", "solver_pseduo_method.PseudoSolver.model[].decode_batch", "domain.reverse", "domain.obtain_denotations", "utils.example.Example", "utils.example.Example", "domain.normalize", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.pick_predictions", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.obtain_denotations", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.normalize"], ["", "def", "generate_pseudo_samples", "(", "self", ",", "conf", ",", "test_batchSize", ",", "beam", ",", "sp_samples", "=", "None", ",", "qg_samples", "=", "None", ")", ":", "\n", "        ", "domain", "=", "Example", ".", "domain", "\n", "pseudo_samples", "=", "[", "]", "\n", "if", "sp_samples", ":", "\n", "            ", "nsentences", "=", "len", "(", "sp_samples", ")", "\n", "data_index", "=", "np", ".", "arange", "(", "nsentences", ")", "\n", "self", ".", "model", "[", "'sp'", "]", ".", "eval", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "                ", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_inputs", "=", "get_minibatch", "(", "sp_samples", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "\n", "task", "=", "'unlabeled_semantic_parsing'", ",", "data_index", "=", "data_index", ",", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "\n", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", "[", "'sp'", "]", ".", "copy", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", "[", "'sp'", "]", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "lf2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "beam", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "pred", "for", "each", "in", "predictions", "for", "pred", "in", "each", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "id2lf", ",", "oov_list", "=", "oov_list", ")", "\n", "_", ",", "idxs", "=", "domain", ".", "pick_predictions", "(", "domain", ".", "obtain_denotations", "(", "domain", ".", "normalize", "(", "predictions", ")", ")", ",", "n_best", "=", "beam", ")", "\n", "predictions", "=", "[", "predictions", "[", "each", "]", "for", "each", "in", "idxs", "]", "\n", "", "pseudo_samples", ".", "extend", "(", "[", "Example", "(", "' '", ".", "join", "(", "words", ")", ",", "' '", ".", "join", "(", "lfs", ")", ",", "conf", ")", "for", "words", ",", "lfs", "in", "zip", "(", "raw_inputs", ",", "predictions", ")", "]", ")", "\n", "", "", "if", "qg_samples", ":", "\n", "            ", "nsentences", "=", "len", "(", "qg_samples", ")", "\n", "data_index", "=", "np", ".", "arange", "(", "nsentences", ")", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "eval", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "                ", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_inputs", "=", "get_minibatch", "(", "qg_samples", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "\n", "task", "=", "'unlabeled_question_generation'", ",", "data_index", "=", "data_index", ",", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "\n", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", "[", "'qg'", "]", ".", "copy", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", "[", "'qg'", "]", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "word2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "beam", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "each", "[", "0", "]", "for", "each", "in", "predictions", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "id2word", ",", "oov_list", "=", "oov_list", ")", "\n", "", "pseudo_samples", ".", "extend", "(", "[", "Example", "(", "' '", ".", "join", "(", "words", ")", ",", "' '", ".", "join", "(", "lfs", ")", ",", "conf", ")", "for", "words", ",", "lfs", "in", "zip", "(", "predictions", ",", "raw_inputs", ")", "]", ")", "\n", "", "", "return", "pseudo_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_pseduo_method.PseudoSolver.train_and_decode": [[117, 205], ["range", "solver_pseduo_method.PseudoSolver.logger.info", "solver_pseduo_method.PseudoSolver.logger.info", "solver_pseduo_method.PseudoSolver.model[].load_model", "solver_pseduo_method.PseudoSolver.model[].load_model", "time.time", "solver_pseduo_method.PseudoSolver.generate_pseudo_samples", "solver_pseduo_method.PseudoSolver.logger.info", "len", "numpy.arange", "numpy.random.shuffle", "solver_pseduo_method.PseudoSolver.model[].train", "solver_pseduo_method.PseudoSolver.model[].train", "range", "print", "solver_pseduo_method.PseudoSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "time.time", "solver_pseduo_method.PseudoSolver.decode", "solver_pseduo_method.PseudoSolver.logger.info", "time.time", "solver_pseduo_method.PseudoSolver.decode", "solver_pseduo_method.PseudoSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "os.path.join", "os.path.join", "solver_pseduo_method.PseudoSolver.model[].zero_grad", "solver_pseduo_method.PseudoSolver.model[].zero_grad", "utils.batch.get_minibatch", "losses[].append", "batch_loss.backward", "utils.batch.get_minibatch", "losses[].append", "batch_loss.backward", "solver_pseduo_method.PseudoSolver.model[].pad_embedding_grad_zero", "solver_pseduo_method.PseudoSolver.model[].pad_embedding_grad_zero", "solver_pseduo_method.PseudoSolver.optimizer.step", "numpy.sum", "numpy.sum", "os.path.join", "os.path.join", "solver_pseduo_method.PseudoSolver.model[].save_model", "solver_pseduo_method.PseudoSolver.logger.info", "solver_pseduo_method.PseudoSolver.model[].save_model", "solver_pseduo_method.PseudoSolver.logger.info", "ValueError", "batch_loss.item", "batch_loss.item", "os.path.join", "os.path.join", "float", "len", "time.time", "str", "str", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_pseduo_method.PseudoSolver.generate_pseudo_samples", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model"], ["", "def", "train_and_decode", "(", "self", ",", "labeled_train_dataset", ",", "q_unlabeled_train_dataset", ",", "lf_unlabeled_train_dataset", ",", "dev_dataset", ",", "test_dataset", ",", "\n", "batchSize", ",", "test_batchSize", ",", "max_epoch", "=", "100", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "max_epoch", ")", ":", "\n", "########################### Training Phase ############################", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "method", "==", "'constant'", ":", "\n", "                ", "conf", "=", "self", ".", "discount", "\n", "", "elif", "self", ".", "method", "==", "'linear'", ":", "\n", "                ", "conf", "=", "self", ".", "discount", "*", "(", "i", "+", "1", ")", "/", "float", "(", "max_epoch", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"[Error]: not recognized method !\"", ")", "\n", "", "pseudo_samples", "=", "self", ".", "generate_pseudo_samples", "(", "conf", ",", "test_batchSize", ",", "beam", ",", "q_unlabeled_train_dataset", ",", "lf_unlabeled_train_dataset", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Generate %d new pseudo samples with confidence %.4f in epoch %d'", "%", "(", "len", "(", "pseudo_samples", ")", ",", "conf", ",", "i", ")", ")", "\n", "cur_train_dataset", "=", "labeled_train_dataset", "+", "pseudo_samples", "\n", "nsentences", "=", "len", "(", "cur_train_dataset", ")", "\n", "train_index", "=", "np", ".", "arange", "(", "nsentences", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_index", ")", "\n", "losses", "=", "{", "'sp'", ":", "[", "]", ",", "'qg'", ":", "[", "]", "}", "\n", "self", ".", "model", "[", "'sp'", "]", ".", "train", "(", ")", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "train", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "batchSize", ")", ":", "\n", "                ", "self", ".", "model", "[", "'sp'", "]", ".", "zero_grad", "(", ")", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "zero_grad", "(", ")", "\n", "###################### Obtain minibatch data ######################", "\n", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "conf", "=", "get_minibatch", "(", "\n", "cur_train_dataset", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "task", "=", "'pseudo_semantic_parsing'", ",", "\n", "data_index", "=", "train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", "[", "'sp'", "]", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "batch_scores", "=", "self", ".", "model", "[", "'sp'", "]", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "batch_loss", "=", "self", ".", "loss_function", "[", "'sp'", "]", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ",", "conf", ")", "\n", "losses", "[", "'sp'", "]", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "\n", "###################### Obtain minibatch data ######################", "\n", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "conf", "=", "get_minibatch", "(", "\n", "cur_train_dataset", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "task", "=", "'pseudo_question_generation'", ",", "\n", "data_index", "=", "train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", "[", "'qg'", "]", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "batch_scores", "=", "self", ".", "model", "[", "'qg'", "]", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "batch_loss", "=", "self", ".", "loss_function", "[", "'qg'", "]", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ",", "conf", ")", "\n", "losses", "[", "'qg'", "]", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "model", "[", "'sp'", "]", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "print", "(", "'[learning] epoch %i >> %3.2f%%'", "%", "(", "i", ",", "100", ")", ",", "'completed in %.2f (sec) <<'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "sp_loss", ",", "qg_loss", "=", "np", ".", "sum", "(", "losses", "[", "'sp'", "]", ")", ",", "np", ".", "sum", "(", "losses", "[", "'qg'", "]", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\tSemantic Parsing Loss (loss : %.4f) ; Question Generation Loss (loss : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "sp_loss", ",", "qg_loss", ")", ")", "\n", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "########################### Evaluation Phase ############################", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "dev_acc", ",", "dev_bleu", "=", "self", ".", "decode", "(", "dev_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ",", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Dev Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tSemantic Parsing (acc : %.4f)\\tQuestion Generation (bleu : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "dev_acc", ",", "dev_bleu", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_acc", ",", "test_bleu", "=", "self", ".", "decode", "(", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ",", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Test Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tSemantic Parsing (acc : %.4f)\\tQuestion Generation (bleu : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "test_acc", ",", "test_bleu", ")", ")", "\n", "\n", "######################## Pick best result and save #####################", "\n", "if", "dev_acc", ">", "self", ".", "best_result", "[", "'dev_acc'", "]", ":", "\n", "                ", "self", ".", "model", "[", "'sp'", "]", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'sp_model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter_sp'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", "=", "dev_acc", ",", "test_acc", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST Semantic Parsing:\\tEpoch : %d\\tBest Valid (acc : %.4f)\\tBest Test (acc : %.4f)'", "%", "(", "i", ",", "dev_acc", ",", "test_acc", ")", ")", "\n", "", "if", "dev_bleu", ">=", "self", ".", "best_result", "[", "'dev_bleu'", "]", ":", "\n", "                ", "self", ".", "model", "[", "'qg'", "]", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'qg_model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter_qg'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", "=", "dev_bleu", ",", "test_bleu", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST Question Generation:\\tEpoch : %d\\tBest Valid (bleu : %.4f)\\tBest Test (bleu : %.4f)'", "%", "(", "i", ",", "dev_bleu", ",", "test_bleu", ")", ")", "\n", "", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "######################## Reload best model for later usage #####################", "\n", "", "self", ".", "logger", ".", "info", "(", "'FINAL BEST Semantic Parsing RESULT: \\tEpoch : %d\\tBest Valid (acc : %.4f)\\tBest Test (acc : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter_sp'", "]", ",", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "'FINAL BEST Question Generation RESULT: \\tEpoch : %d\\tBest Valid (bleu : %.4f)\\tBest Test (bleu : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter_qg'", "]", ",", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", ")", ")", "\n", "self", ".", "model", "[", "'sp'", "]", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'sp_model.pkl'", ")", ")", "\n", "self", ".", "model", "[", "'qg'", "]", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'qg_model.pkl'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_base.Solver.__init__": [[5, 14], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "vocab", ",", "loss_function", ",", "optimizer", ",", "exp_path", ",", "logger", ",", "device", "=", "None", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "Solver", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "loss_function", "=", "loss_function", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "exp_path", "=", "exp_path", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_base.Solver.decode": [[15, 17], ["None"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ",", "beam_size", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_base.Solver.train_and_decode": [[18, 21], ["None"], "methods", ["None"], ["", "def", "train_and_decode", "(", "self", ",", "train_dataset", ",", "dev_dataset", ",", "test_dataset", ",", "batchSize", "=", "16", ",", "test_batchSize", "=", "128", ",", "\n", "max_epoch", "=", "100", ",", "beam_size", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_dual_learning.DualLearningSolver.__init__": [[15, 20], ["utils.solver.solver_base.Solver.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "DualLearningSolver", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "best_result", "=", "{", "\n", "\"iter_sp\"", ":", "0", ",", "\"dev_acc\"", ":", "0.", ",", "\"test_acc\"", ":", "0.", ",", "\n", "\"iter_qg\"", ":", "0", ",", "\"dev_bleu\"", ":", "0.", ",", "\"test_bleu\"", ":", "0.", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_dual_learning.DualLearningSolver.decode": [[22, 78], ["numpy.arange", "len", "len", "open", "solver_dual_learning.DualLearningSolver.model.eval", "range", "of.write", "range", "utils.bleu.get_bleu_score", "of.write", "utils.batch.get_minibatch", "domain.compare_logical_form", "total.extend", "range", "utils.batch.get_minibatch", "domain.compare_question", "candidate_list.extend", "references_list.extend", "range", "sum", "float", "torch.no_grad", "solver_dual_learning.DualLearningSolver.model.decode_batch", "domain.reverse", "len", "of.write", "of.write", "range", "of.write", "torch.no_grad", "solver_dual_learning.DualLearningSolver.model.decode_batch", "domain.reverse", "len", "of.write", "of.write", "of.write", "of.write", "len", "of.write", "str", "str"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.bleu.get_bleu_score", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_logical_form", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_question", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "data_index", "=", "np", ".", "arange", "(", "len", "(", "data_inputs", ")", ")", "\n", "nsentences", "=", "len", "(", "data_index", ")", "\n", "domain", "=", "Example", ".", "domain", "\n", "total", ",", "candidate_list", ",", "references_list", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "########################### Evaluation Phase ############################", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "of", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "_", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "task", "=", "'semantic_parsing'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", ".", "sp_model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "lf2id", ",", "copy_tokens", ",", "task", "=", "'semantic_parsing'", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "pred", "for", "each", "in", "predictions", "for", "pred", "in", "each", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'sp'", "]", ".", "id2lf", ",", "oov_list", "=", "oov_list", ")", "\n", "", "accuracy", "=", "domain", ".", "compare_logical_form", "(", "predictions", ",", "raw_outputs", ",", "pick", "=", "True", ")", "\n", "total", ".", "extend", "(", "accuracy", ")", "\n", "############################ Write result to file ############################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"Utterance: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "for", "i", "in", "range", "(", "n_best", ")", ":", "\n", "                        ", "of", ".", "write", "(", "\"Pred\"", "+", "str", "(", "i", ")", "+", "\": \"", "+", "' '", ".", "join", "(", "predictions", "[", "n_best", "*", "idx", "+", "i", "]", ")", "+", "'\\n'", ")", "\n", "", "of", ".", "write", "(", "\"Correct: \"", "+", "(", "\"True\"", "if", "accuracy", "[", "idx", "]", "==", "1", "else", "\"False\"", ")", "+", "'\\n\\n'", ")", "\n", "\n", "", "", "of", ".", "write", "(", "'='", "*", "50", "+", "'\\n'", "+", "'='", "*", "50", "+", "'\\n\\n'", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "_", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "task", "=", "'question_generation'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", ".", "qg_model", ".", "copy", ")", "\n", "########################## Beam Search/Greed Decode #######################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "word2id", ",", "copy_tokens", ",", "task", "=", "'question_generation'", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "each", "[", "0", "]", "for", "each", "in", "predictions", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", "[", "'qg'", "]", ".", "id2word", ",", "oov_list", "=", "oov_list", ")", "\n", "", "bleu_scores", "=", "domain", ".", "compare_question", "(", "predictions", ",", "raw_outputs", ")", "\n", "candidate_list", ".", "extend", "(", "predictions", ")", "\n", "references_list", ".", "extend", "(", "[", "[", "ref", "]", "for", "ref", "in", "raw_outputs", "]", ")", "\n", "############################# Writing Result to File ###########################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"LogicalForm: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Pred0: \"", "+", "' '", ".", "join", "(", "predictions", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Bleu: \"", "+", "str", "(", "bleu_scores", "[", "idx", "]", ")", "+", "'\\n\\n'", ")", "\n", "########################### Calculate accuracy ###########################", "\n", "", "", "acc", "=", "sum", "(", "total", ")", "/", "float", "(", "len", "(", "total", ")", ")", "\n", "avg_bleu", "=", "get_bleu_score", "(", "candidate_list", ",", "references_list", ")", "\n", "of", ".", "write", "(", "'Overall accuracy: %.4f | Overall bleu score: %.4f'", "%", "(", "acc", ",", "avg_bleu", ")", ")", "\n", "", "return", "acc", ",", "avg_bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_dual_learning.DualLearningSolver.train_and_decode": [[79, 186], ["numpy.arange", "numpy.arange", "numpy.arange", "max", "range", "solver_dual_learning.DualLearningSolver.logger.info", "solver_dual_learning.DualLearningSolver.logger.info", "solver_dual_learning.DualLearningSolver.model.load_model", "len", "len", "len", "time.time", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.random.shuffle", "solver_dual_learning.DualLearningSolver.model.train", "range", "print", "solver_dual_learning.DualLearningSolver.logger.info", "time.time", "solver_dual_learning.DualLearningSolver.decode", "solver_dual_learning.DualLearningSolver.logger.info", "time.time", "solver_dual_learning.DualLearningSolver.decode", "solver_dual_learning.DualLearningSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "os.path.join", "os.path.join", "len", "len", "len", "solver_dual_learning.DualLearningSolver.model.zero_grad", "solver_dual_learning.DualLearningSolver.model.pad_embedding_grad_zero", "solver_dual_learning.DualLearningSolver.optimizer.step", "gc.collect", "torch.cuda.empty_cache", "numpy.sum", "numpy.sum", "os.path.join", "os.path.join", "solver_dual_learning.DualLearningSolver.model.save_model", "solver_dual_learning.DualLearningSolver.logger.info", "solver_dual_learning.DualLearningSolver.model.save_model", "solver_dual_learning.DualLearningSolver.logger.info", "utils.batch.get_minibatch", "solver_dual_learning.DualLearningSolver.model", "losses[].append", "losses[].append", "sp_loss.backward", "qg_loss.backward", "utils.batch.get_minibatch", "solver_dual_learning.DualLearningSolver.model", "losses[].append", "losses[].append", "sp_loss.backward", "qg_loss.backward", "utils.batch.get_minibatch", "solver_dual_learning.DualLearningSolver.model.sp_model", "losses[].append", "batch_loss.backward", "utils.batch.get_minibatch", "solver_dual_learning.DualLearningSolver.model.qg_model", "losses[].append", "batch_loss.backward", "sp_loss.item", "qg_loss.item", "sp_loss.item", "qg_loss.item", "batch_loss.item", "batch_loss.item", "time.time", "str", "str", "os.path.join", "os.path.join", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch"], ["", "def", "train_and_decode", "(", "self", ",", "labeled_train_dataset", ",", "q_unlabeled_train_dataset", ",", "lf_unlabeled_train_dataset", ",", "dev_dataset", ",", "test_dataset", ",", "\n", "batchSize", ",", "test_batchSize", ",", "cycle", "=", "'sp+qg'", ",", "max_epoch", "=", "100", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "sp_unlabeled_train_index", "=", "np", ".", "arange", "(", "len", "(", "q_unlabeled_train_dataset", ")", ")", "\n", "qg_unlabeled_train_index", "=", "np", ".", "arange", "(", "len", "(", "lf_unlabeled_train_dataset", ")", ")", "\n", "labeled_train_index", "=", "np", ".", "arange", "(", "len", "(", "labeled_train_dataset", ")", ")", "\n", "nsentences", "=", "max", "(", "[", "len", "(", "q_unlabeled_train_dataset", ")", ",", "len", "(", "lf_unlabeled_train_dataset", ")", ",", "len", "(", "labeled_train_dataset", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "max_epoch", ")", ":", "\n", "########################### Training Phase ############################", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "sp_unlabeled_train_index", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "qg_unlabeled_train_index", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "labeled_train_index", ")", "\n", "losses", "=", "{", "'sp'", ":", "[", "]", ",", "'qg'", ":", "[", "]", "}", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "batchSize", ")", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "''' Cycle start from Semantic Parsing '''", "\n", "if", "'sp'", "in", "cycle", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                    ", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_in", "=", "get_minibatch", "(", "q_unlabeled_train_dataset", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "task", "=", "'unlabeled_semantic_parsing'", ",", "\n", "data_index", "=", "sp_unlabeled_train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", ".", "sp_model", ".", "copy", ")", "\n", "######################## Forward Model ##########################", "\n", "sp_loss", ",", "qg_loss", "=", "self", ".", "model", "(", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_in", ",", "start_from", "=", "'semantic_parsing'", ")", "\n", "losses", "[", "'sp'", "]", ".", "append", "(", "sp_loss", ".", "item", "(", ")", ")", "\n", "losses", "[", "'qg'", "]", ".", "append", "(", "qg_loss", ".", "item", "(", ")", ")", "\n", "sp_loss", ".", "backward", "(", ")", "\n", "qg_loss", ".", "backward", "(", ")", "\n", "\n", "", "''' Cycle start from Question Generation '''", "\n", "if", "'qg'", "in", "cycle", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                    ", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_in", "=", "get_minibatch", "(", "lf_unlabeled_train_dataset", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "task", "=", "'unlabeled_question_generation'", ",", "\n", "data_index", "=", "qg_unlabeled_train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", ".", "qg_model", ".", "copy", ")", "\n", "########################### Forward Model ########################", "\n", "sp_loss", ",", "qg_loss", "=", "self", ".", "model", "(", "inputs", ",", "lens", ",", "copy_tokens", ",", "oov_list", ",", "raw_in", ",", "start_from", "=", "'question_generation'", ")", "\n", "losses", "[", "'sp'", "]", ".", "append", "(", "sp_loss", ".", "item", "(", ")", ")", "\n", "losses", "[", "'qg'", "]", ".", "append", "(", "qg_loss", ".", "item", "(", ")", ")", "\n", "sp_loss", ".", "backward", "(", ")", "\n", "qg_loss", ".", "backward", "(", ")", "\n", "\n", "", "''' Supervised Training '''", "\n", "if", "True", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                    ", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch", "(", "\n", "labeled_train_dataset", ",", "self", ".", "vocab", "[", "'sp'", "]", ",", "task", "=", "'semantic_parsing'", ",", "\n", "data_index", "=", "labeled_train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'sp'", "]", ",", "copy", "=", "self", ".", "model", ".", "sp_model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "batch_scores", "=", "self", ".", "model", ".", "sp_model", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "batch_loss", "=", "self", ".", "loss_function", "[", "'sp'", "]", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ")", "\n", "losses", "[", "'sp'", "]", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "\n", "###################### Obtain minibatch data ######################", "\n", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch", "(", "\n", "labeled_train_dataset", ",", "self", ".", "vocab", "[", "'qg'", "]", ",", "task", "=", "'question_generation'", ",", "\n", "data_index", "=", "labeled_train_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", "[", "'qg'", "]", ",", "copy", "=", "self", ".", "model", ".", "qg_model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "batch_scores", "=", "self", ".", "model", ".", "qg_model", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "batch_loss", "=", "self", ".", "loss_function", "[", "'qg'", "]", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ")", "\n", "losses", "[", "'qg'", "]", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "\n", "", "self", ".", "model", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "print", "(", "'[learning] epoch %i >> %3.2f%%'", "%", "(", "i", ",", "100", ")", ",", "'completed in %.2f (sec) <<'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "sp_loss", ",", "qg_loss", "=", "np", ".", "sum", "(", "losses", "[", "'sp'", "]", ",", "axis", "=", "0", ")", ",", "np", ".", "sum", "(", "losses", "[", "'qg'", "]", ",", "axis", "=", "0", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\tLoss(sp loss : %.4f ; qg loss : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "sp_loss", ",", "qg_loss", ")", ")", "\n", "\n", "########################### Evaluation Phase ############################", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "dev_acc", ",", "dev_bleu", "=", "self", ".", "decode", "(", "dev_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tSemantic Parsing (acc : %.4f)\\tQuestion Generation (bleu : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "dev_acc", ",", "dev_bleu", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_acc", ",", "test_bleu", "=", "self", ".", "decode", "(", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tSemantic Parsing (acc : %.4f)\\tQuestion Generation (bleu : %.4f)'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "test_acc", ",", "test_bleu", ")", ")", "\n", "\n", "######################## Pick best result and save #####################", "\n", "if", "dev_acc", ">", "self", ".", "best_result", "[", "'dev_acc'", "]", ":", "\n", "                ", "self", ".", "model", ".", "save_model", "(", "sp_save_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'sp_model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter_sp'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", "=", "dev_acc", ",", "test_acc", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST Semantic Parsing:\\tEpoch : %d\\tBest Valid (acc : %.4f)\\tBest Test (acc : %.4f)'", "%", "(", "i", ",", "dev_acc", ",", "test_acc", ")", ")", "\n", "", "if", "dev_bleu", ">=", "self", ".", "best_result", "[", "'dev_bleu'", "]", ":", "\n", "                ", "self", ".", "model", ".", "save_model", "(", "qg_save_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'qg_model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter_qg'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", "=", "dev_bleu", ",", "test_bleu", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST Question Generation:\\tEpoch : %d\\tBest Valid (bleu : %.4f)\\tBest Test (bleu : %.4f)'", "%", "(", "i", ",", "dev_bleu", ",", "test_bleu", ")", ")", "\n", "", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "######################## Reload best model for later usage #####################", "\n", "", "self", ".", "logger", ".", "info", "(", "'FINAL BEST Semantic Parsing RESULT: \\tEpoch : %d\\tBest Valid (acc : %.4f)\\tBest Test (acc : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter_sp'", "]", ",", "self", ".", "best_result", "[", "'dev_acc'", "]", ",", "self", ".", "best_result", "[", "'test_acc'", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "'FINAL BEST Question Generation RESULT: \\tEpoch : %d\\tBest Valid (bleu : %.4f)\\tBest Test (bleu : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter_qg'", "]", ",", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", ")", ")", "\n", "self", ".", "model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'sp_model.pkl'", ")", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'qg_model.pkl'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_question_generation.QGSolver.__init__": [[12, 15], ["utils.solver.solver_base.Solver.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "QGSolver", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "best_result", "=", "{", "\"losses\"", ":", "[", "]", ",", "\"iter\"", ":", "0", ",", "\"dev_bleu\"", ":", "0.", ",", "\"test_bleu\"", ":", "0.", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_question_generation.QGSolver.decode": [[16, 45], ["numpy.arange", "solver_question_generation.QGSolver.model.eval", "len", "len", "open", "range", "utils.bleu.get_bleu_score", "of.write", "utils.batch.get_minibatch", "domain.compare_question", "candidate_list.extend", "references_list.extend", "range", "torch.no_grad", "solver_question_generation.QGSolver.model.decode_batch", "domain.reverse", "len", "of.write", "of.write", "of.write", "of.write", "str"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.bleu.get_bleu_score", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.compare_question", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "data_index", "=", "np", ".", "arange", "(", "len", "(", "data_inputs", ")", ")", "\n", "nsentences", ",", "candidate_list", ",", "references_list", "=", "len", "(", "data_index", ")", ",", "[", "]", ",", "[", "]", "\n", "domain", "=", "Example", ".", "domain", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "of", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "dec_inputs", ",", "_", ",", "_", ",", "copy_tokens", ",", "oov_list", ",", "(", "raw_inputs", ",", "raw_outputs", ")", "=", "get_minibatch", "(", "\n", "data_inputs", ",", "self", ".", "vocab", ",", "task", "=", "'question_generation'", ",", "data_index", "=", "data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", ",", "copy", "=", "self", ".", "model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "results", "=", "self", ".", "model", ".", "decode_batch", "(", "inputs", ",", "lens", ",", "self", ".", "vocab", ".", "word2id", ",", "copy_tokens", ",", "beam_size", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "predictions", "=", "results", "[", "\"predictions\"", "]", "\n", "predictions", "=", "[", "each", "[", "0", "]", "for", "each", "in", "predictions", "]", "\n", "predictions", "=", "domain", ".", "reverse", "(", "predictions", ",", "self", ".", "vocab", ".", "id2word", ",", "oov_list", "=", "oov_list", ")", "\n", "", "bleu_scores", "=", "domain", ".", "compare_question", "(", "predictions", ",", "raw_outputs", ")", "\n", "candidate_list", ".", "extend", "(", "predictions", ")", "\n", "references_list", ".", "extend", "(", "[", "[", "ref", "]", "for", "ref", "in", "raw_outputs", "]", ")", "\n", "############################ Write result to file ############################", "\n", "for", "idx", "in", "range", "(", "len", "(", "raw_inputs", ")", ")", ":", "\n", "                    ", "of", ".", "write", "(", "\"LogicalForm: \"", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Target: \"", "+", "' '", ".", "join", "(", "raw_outputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Pred0: \"", "+", "' '", ".", "join", "(", "predictions", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "of", ".", "write", "(", "\"Bleu: \"", "+", "str", "(", "bleu_scores", "[", "idx", "]", ")", "+", "'\\n\\n'", ")", "\n", "", "", "avg_bleu", "=", "get_bleu_score", "(", "candidate_list", ",", "references_list", ")", "\n", "of", ".", "write", "(", "'Overall bleu is %.4f'", "%", "(", "avg_bleu", ")", ")", "\n", "", "return", "avg_bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_question_generation.QGSolver.train_and_decode": [[46, 106], ["numpy.arange", "len", "range", "solver_question_generation.QGSolver.logger.info", "solver_question_generation.QGSolver.model.load_model", "len", "time.time", "numpy.random.shuffle", "solver_question_generation.QGSolver.model.train", "range", "print", "numpy.sum", "solver_question_generation.QGSolver.best_result[].append", "solver_question_generation.QGSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "time.time", "solver_question_generation.QGSolver.decode", "solver_question_generation.QGSolver.logger.info", "time.time", "solver_question_generation.QGSolver.decode", "solver_question_generation.QGSolver.logger.info", "os.path.join", "utils.batch.get_minibatch", "solver_question_generation.QGSolver.model.zero_grad", "solver_question_generation.QGSolver.model", "solver_question_generation.QGSolver.loss_function", "losses.append", "solver_question_generation.QGSolver.backward", "solver_question_generation.QGSolver.model.pad_embedding_grad_zero", "solver_question_generation.QGSolver.optimizer.step", "os.path.join", "os.path.join", "solver_question_generation.QGSolver.model.save_model", "solver_question_generation.QGSolver.logger.info", "solver_question_generation.QGSolver.item", "os.path.join", "time.time", "str", "str", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model"], ["", "def", "train_and_decode", "(", "self", ",", "train_dataset", ",", "dev_dataset", ",", "test_dataset", ",", "batchSize", "=", "16", ",", "test_batchSize", "=", "128", ",", "\n", "max_epoch", "=", "100", ",", "beam", "=", "5", ",", "n_best", "=", "1", ")", ":", "\n", "        ", "train_data_index", "=", "np", ".", "arange", "(", "len", "(", "train_dataset", ")", ")", "\n", "nsentences", "=", "len", "(", "train_data_index", ")", "\n", "for", "i", "in", "range", "(", "max_epoch", ")", ":", "\n", "########################### Training Phase ############################", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_data_index", ")", "\n", "losses", "=", "[", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "dec_inputs", ",", "dec_outputs", ",", "out_lens", ",", "copy_tokens", ",", "_", ",", "_", "=", "get_minibatch", "(", "\n", "train_dataset", ",", "self", ".", "vocab", ",", "task", "=", "'question_generation'", ",", "data_index", "=", "train_data_index", ",", "\n", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", ",", "copy", "=", "self", ".", "model", ".", "copy", ")", "\n", "############################ Forward Model ############################", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "batch_scores", "=", "self", ".", "model", "(", "inputs", ",", "lens", ",", "dec_inputs", "[", ":", ",", ":", "-", "1", "]", ",", "copy_tokens", ")", "\n", "############################ Loss Calculation #########################", "\n", "batch_loss", "=", "self", ".", "loss_function", "(", "batch_scores", ",", "dec_outputs", "[", ":", ",", "1", ":", "]", ",", "out_lens", "-", "1", ")", "\n", "losses", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "########################### Backward and Optimize ######################", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "self", ".", "model", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "print", "(", "'[learning] epoch %i >> %3.2f%%'", "%", "(", "i", ",", "100", ")", ",", "'completed in %.2f (sec) <<'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "epoch_loss", "=", "np", ".", "sum", "(", "losses", ",", "axis", "=", "0", ")", "\n", "self", ".", "best_result", "[", "'losses'", "]", ".", "append", "(", "epoch_loss", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\t Loss: %.5f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "epoch_loss", ")", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "if", "i", "<", "10", ":", "\n", "                ", "continue", "\n", "\n", "########################### Evaluation Phase ############################", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "dev_bleu", "=", "self", ".", "decode", "(", "dev_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Dev Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tBleu : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "dev_bleu", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_bleu", "=", "self", ".", "decode", "(", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ",", "\n", "test_batchSize", ",", "beam", "=", "beam", ",", "n_best", "=", "n_best", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Test Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tBleu : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "test_bleu", ")", ")", "\n", "\n", "######################## Pick best result on dev and save #####################", "\n", "if", "dev_bleu", ">=", "self", ".", "best_result", "[", "'dev_bleu'", "]", ":", "\n", "                ", "self", ".", "model", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", "=", "dev_bleu", ",", "test_bleu", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST:\\tEpoch : %d\\tBest Valid Bleu : %.4f;\\tBest Test Bleu : %.4f'", "%", "(", "i", ",", "dev_bleu", ",", "test_bleu", ")", ")", "\n", "\n", "######################## Reload best model for later usage #####################", "\n", "", "", "self", ".", "logger", ".", "info", "(", "'FINAL BEST RESULT: \\tEpoch : %d\\tBest Valid (Bleu : %.4f)\\tBest Test (Bleu : %.4f)'", "\n", "%", "(", "self", ".", "best_result", "[", "'iter'", "]", ",", "self", ".", "best_result", "[", "'dev_bleu'", "]", ",", "self", ".", "best_result", "[", "'test_bleu'", "]", ")", ")", "\n", "self", ".", "model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.__init__": [[12, 16], ["kargs.pop", "utils.solver.solver_base.Solver.__init__", "float", "float"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "self", ".", "side", "=", "kargs", ".", "pop", "(", "'side'", ",", "'question'", ")", "\n", "super", "(", "LMSolver", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "best_result", "=", "{", "\"losses\"", ":", "[", "]", ",", "\"iter\"", ":", "0", ",", "\"dev_ppl\"", ":", "float", "(", "'inf'", ")", ",", "\"test_ppl\"", ":", "float", "(", "'inf'", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode": [[17, 48], ["numpy.arange", "solver_language_model.LMSolver.model.eval", "len", "open", "range", "numpy.sum", "numpy.sum", "numpy.exp", "f.write", "len", "utils.batch.get_minibatch", "length_list.extend", "range", "torch.no_grad", "solver_language_model.LMSolver.model", "solver_language_model.LMSolver.loss_function().item", "numpy.sum.append", "solver_language_model.LMSolver.model.sent_logprobability().cpu().tolist", "len", "f.write", "f.write", "numpy.exp", "f.write", "solver_language_model.LMSolver.loss_function", "solver_language_model.LMSolver.model.sent_logprobability().cpu", "str", "str", "solver_language_model.LMSolver.model.sent_logprobability"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.sent_logprobability"], ["", "def", "decode", "(", "self", ",", "data_inputs", ",", "output_path", ",", "test_batchSize", ")", ":", "\n", "        ", "data_index", "=", "np", ".", "arange", "(", "len", "(", "data_inputs", ")", ")", "\n", "count", ",", "eval_loss", ",", "length_list", "=", "0", ",", "[", "]", ",", "[", "]", "\n", "########################### Evaluation Phase ############################", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "len", "(", "data_index", ")", ",", "test_batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "raw_inputs", "=", "get_minibatch", "(", "data_inputs", ",", "self", ".", "vocab", ",", "task", "=", "'language_model'", ",", "\n", "data_index", "=", "data_index", ",", "index", "=", "j", ",", "batch_size", "=", "test_batchSize", ",", "device", "=", "self", ".", "device", ",", "side", "=", "self", ".", "side", ")", "\n", "length_list", ".", "extend", "(", "(", "lens", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "########################## Calculate Sentence PPL #######################", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "scores", "=", "self", ".", "model", "(", "inputs", ",", "lens", ")", "# bsize, seq_len, voc_size", "\n", "batch_loss", "=", "self", ".", "loss_function", "(", "scores", ",", "inputs", "[", ":", ",", "1", ":", "]", ")", ".", "item", "(", ")", "\n", "eval_loss", ".", "append", "(", "batch_loss", ")", "\n", "norm_log_prob", "=", "self", ".", "model", ".", "sent_logprobability", "(", "inputs", ",", "lens", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "############################# Writing Result to File ###########################", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "                    ", "f", ".", "write", "(", "'Utterance: '", "+", "' '", ".", "join", "(", "raw_inputs", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'NormLogProb: '", "+", "str", "(", "norm_log_prob", "[", "idx", "]", ")", "+", "'\\n'", ")", "\n", "current_ppl", "=", "np", ".", "exp", "(", "-", "norm_log_prob", "[", "idx", "]", ")", "\n", "f", ".", "write", "(", "'PPL: '", "+", "str", "(", "current_ppl", ")", "+", "'\\n\\n'", ")", "\n", "\n", "########################### Calculate Corpus PPL ###########################", "\n", "", "", "word_count", "=", "np", ".", "sum", "(", "length_list", ",", "axis", "=", "0", ")", "\n", "eval_loss", "=", "np", ".", "sum", "(", "eval_loss", ",", "axis", "=", "0", ")", "\n", "final_ppl", "=", "np", ".", "exp", "(", "eval_loss", "/", "word_count", ")", "\n", "f", ".", "write", "(", "'Overall ppl: %.4f'", "%", "(", "final_ppl", ")", ")", "\n", "", "return", "final_ppl", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.train_and_decode": [[49, 104], ["numpy.arange", "len", "range", "solver_language_model.LMSolver.logger.info", "solver_language_model.LMSolver.model.load_model", "len", "time.time", "numpy.random.shuffle", "solver_language_model.LMSolver.model.train", "range", "print", "numpy.sum", "solver_language_model.LMSolver.best_result[].append", "solver_language_model.LMSolver.logger.info", "gc.collect", "torch.cuda.empty_cache", "time.time", "solver_language_model.LMSolver.decode", "solver_language_model.LMSolver.logger.info", "time.time", "solver_language_model.LMSolver.decode", "solver_language_model.LMSolver.logger.info", "os.path.join", "utils.batch.get_minibatch", "solver_language_model.LMSolver.optimizer.zero_grad", "solver_language_model.LMSolver.model", "solver_language_model.LMSolver.loss_function", "losses.append", "solver_language_model.LMSolver.backward", "solver_language_model.LMSolver.model.pad_embedding_grad_zero", "solver_language_model.LMSolver.optimizer.step", "os.path.join", "os.path.join", "solver_language_model.LMSolver.model.save_model", "solver_language_model.LMSolver.logger.info", "solver_language_model.LMSolver.item", "os.path.join", "time.time", "str", "str", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.solver.solver_language_model.LMSolver.decode", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.optimizer.MyAdam.step", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model"], ["", "def", "train_and_decode", "(", "self", ",", "train_inputs", ",", "dev_inputs", ",", "test_inputs", ",", "batchSize", "=", "16", ",", "test_batchSize", "=", "128", ",", "max_epoch", "=", "100", ")", ":", "\n", "        ", "train_data_index", "=", "np", ".", "arange", "(", "len", "(", "train_inputs", ")", ")", "\n", "nsentences", "=", "len", "(", "train_data_index", ")", "\n", "for", "i", "in", "range", "(", "max_epoch", ")", ":", "\n", "########################### Training Phase ############################", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_data_index", ")", "\n", "losses", "=", "[", "]", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "nsentences", ",", "batchSize", ")", ":", "\n", "###################### Obtain minibatch data ######################", "\n", "                ", "inputs", ",", "lens", ",", "_", "=", "get_minibatch", "(", "train_inputs", ",", "self", ".", "vocab", ",", "task", "=", "'language_model'", ",", "\n", "data_index", "=", "train_data_index", ",", "index", "=", "j", ",", "batch_size", "=", "batchSize", ",", "device", "=", "self", ".", "device", ",", "side", "=", "self", ".", "side", ")", "\n", "############################ Forward Model ############################", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "batch_scores", "=", "self", ".", "model", "(", "inputs", ",", "lens", ")", "\n", "############################ Loss Calculation #########################", "\n", "batch_loss", "=", "self", ".", "loss_function", "(", "batch_scores", ",", "inputs", "[", ":", ",", "1", ":", "]", ",", "lens", "-", "1", ")", "\n", "losses", ".", "append", "(", "batch_loss", ".", "item", "(", ")", ")", "\n", "########################### Backward and Optimize ######################", "\n", "batch_loss", ".", "backward", "(", ")", "\n", "self", ".", "model", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "print", "(", "'[learning] epoch %i >> %3.2f%%'", "%", "(", "i", ",", "100", ")", ",", "'completed in %.2f (sec) <<'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", "\n", "epoch_loss", "=", "np", ".", "sum", "(", "losses", ",", "axis", "=", "0", ")", "\n", "self", ".", "best_result", "[", "'losses'", "]", ".", "append", "(", "epoch_loss", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\t Loss of tgt : %.5f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "epoch_loss", ")", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# whether evaluate later after training for some epochs", "\n", "if", "i", "<", "10", ":", "\n", "                ", "continue", "\n", "\n", "########################### Evaluation Phase ############################", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "dev_ppl", "=", "self", ".", "decode", "(", "dev_inputs", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ",", "test_batchSize", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tppl : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "dev_ppl", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_ppl", "=", "self", ".", "decode", "(", "test_inputs", ",", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ",", "test_batchSize", ")", "\n", "self", ".", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tppl : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "test_ppl", ")", ")", "\n", "\n", "######################## Pick best result and save #####################", "\n", "if", "dev_ppl", "<", "self", ".", "best_result", "[", "'dev_ppl'", "]", ":", "\n", "                ", "self", ".", "model", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "self", ".", "best_result", "[", "'iter'", "]", "=", "i", "\n", "self", ".", "best_result", "[", "'dev_ppl'", "]", ",", "self", ".", "best_result", "[", "'test_ppl'", "]", "=", "dev_ppl", ",", "test_ppl", "\n", "self", ".", "logger", ".", "info", "(", "'NEW BEST:\\tEpoch : %d\\tBest Valid ppl : %.4f;\\tBest Test ppl : %.4f'", "%", "(", "i", ",", "dev_ppl", ",", "test_ppl", ")", ")", "\n", "\n", "######################## Reload best model for later usage #####################", "\n", "", "", "self", ".", "logger", ".", "info", "(", "'FINAL BEST RESULT: \\tEpoch : %d\\tBest Valid (ppl : %.4f)\\tBest Test (ppl : %.4f) '", "\n", "%", "(", "self", ".", "best_result", "[", "'iter'", "]", ",", "self", ".", "best_result", "[", "'dev_ppl'", "]", ",", "self", ".", "best_result", "[", "'test_ppl'", "]", ")", ")", "\n", "self", ".", "model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exp_path", ",", "'model.pkl'", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.scripts.question_generation.main": [[19, 52], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "type", "=", "str", ",", "default", "=", "'question_generation'", ",", "help", "=", "'question generation'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiment on'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "# pretrained models", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "required", "=", "False", ",", "help", "=", "'Read model and hyperparams from this path'", ")", "\n", "# model paras", "\n", "parser", ".", "add_argument", "(", "'--copy'", ",", "action", "=", "'store_true'", ",", "help", "=", "'attn model or attnptr model'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'embedding size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'hidden layer dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of hidden layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--cell'", ",", "default", "=", "'lstm'", ",", "choices", "=", "[", "'lstm'", ",", "'gru'", "]", ",", "help", "=", "'rnn cell choice'", ")", "\n", "# training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "default", "=", "'sum'", ",", "choices", "=", "[", "'mean'", ",", "'sum'", "]", ",", "help", "=", "'loss function argument'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout rate at each non-recurrent layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_weight'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'all weights will be set to [-init_weight, init_weight] during initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'beam search size'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_best'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'return n best results'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'training use only this propotion of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'train model on ith gpu. -1: cpu, o.w. gpu index'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "if", "opt", ".", "testing", ":", "\n", "        ", "assert", "opt", ".", "read_model_path", "\n", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.scripts.dual_learning.main": [[21, 58], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "required", "=", "True", ",", "help", "=", "'pseudo method for semantic parsing'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiment on'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "help", "=", "'Testing mode, load sp and qg model path'", ")", "\n", "# model params", "\n", "parser", ".", "add_argument", "(", "'--read_sp_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained sp model'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_qg_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained qg model path'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_qlm_path'", ",", "required", "=", "True", ",", "help", "=", "'language model for natural language questions'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_lflm_path'", ",", "required", "=", "True", ",", "help", "=", "'language model for logical form'", ")", "\n", "# pseudo training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "choices", "=", "[", "'sum'", ",", "'mean'", "]", ",", "default", "=", "'sum'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--sample'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'size of sampling during training in dual learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_best'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'coefficient which combines sp valid and reconstruction reward'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'coefficient which combines qg valid and reconstruction reward'", ")", "\n", "parser", ".", "add_argument", "(", "'--cycle'", ",", "choices", "=", "[", "'sp'", ",", "'qg'", ",", "'sp+qg'", "]", ",", "default", "=", "'sp+qg'", ",", "help", "=", "'whether use cycle starts from sp/qg'", ")", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of labeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--unlabeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of unlabeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "nargs", "=", "2", ",", "default", "=", "[", "-", "1", ",", "-", "1", "]", ",", "help", "=", "'device for semantic parsing and question generation model respectively'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--extra'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether use synthesized logical forms'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n", "# Some Arguments Check", "\n", "assert", "opt", ".", "labeled", ">", "0.", "\n", "assert", "opt", ".", "unlabeled", ">=", "0.", "and", "opt", ".", "unlabeled", "<=", "1.0", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.scripts.semantic_parsing.main": [[19, 52], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "type", "=", "str", ",", "default", "=", "'semantic_parsing'", ",", "help", "=", "'semantic parsing'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiment on'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "# pretrained models", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "required", "=", "False", ",", "help", "=", "'Read model and hyperparams from this path'", ")", "\n", "# model paras", "\n", "parser", ".", "add_argument", "(", "'--copy'", ",", "action", "=", "'store_true'", ",", "help", "=", "'attn model or attnptr model'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'embedding size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'hidden layer dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of hidden layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--cell'", ",", "default", "=", "'lstm'", ",", "choices", "=", "[", "'lstm'", ",", "'gru'", "]", ",", "help", "=", "'rnn cell choice'", ")", "\n", "# training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "default", "=", "'sum'", ",", "choices", "=", "[", "'mean'", ",", "'sum'", "]", ",", "help", "=", "'loss function argument'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout rate at each non-recurrent layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_weight'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'all weights will be set to [-init_weight, init_weight] during initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'beam search size'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_best'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'return n best results'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'training use only this propotion of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'train model on ith gpu. -1: cpu, o.w. gpu index'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "if", "opt", ".", "testing", ":", "\n", "        ", "assert", "opt", ".", "read_model_path", "\n", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.scripts.pseudo_method.main": [[18, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "required", "=", "True", ",", "help", "=", "'pseudo method for semantic parsing'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiment on'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "help", "=", "'Testing mode, load sp and qg model path'", ")", "\n", "# model params", "\n", "parser", ".", "add_argument", "(", "'--read_sp_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained sp model'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_qg_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained qg model path'", ")", "\n", "# pseudo training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "choices", "=", "[", "'sum'", ",", "'mean'", "]", ",", "default", "=", "'sum'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_best'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of labeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--unlabeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of unlabeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--method'", ",", "choices", "=", "[", "'constant'", ",", "'linear'", "]", ",", "help", "=", "'how to change confidence during training'", ")", "\n", "parser", ".", "add_argument", "(", "'--discount'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "\"final confidence for pseudo examples\"", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "nargs", "=", "2", ",", "default", "=", "[", "-", "1", ",", "-", "1", "]", ",", "help", "=", "'gpu indexes for slu and nlg models respectively, -1:cpu'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--extra'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether use synthesized logical forms'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n", "# Some Arguments Check", "\n", "assert", "opt", ".", "labeled", ">", "0.", "and", "opt", ".", "labeled", "<", "1.0", "\n", "assert", "opt", ".", "unlabeled", ">", "0.", "and", "opt", ".", "unlabeled", "<=", "1.0", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.scripts.language_model.main": [[19, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "type", "=", "str", ",", "default", "=", "'language_model'", ",", "help", "=", "'language model'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiemnt on'", ")", "\n", "parser", ".", "add_argument", "(", "'--side'", ",", "choices", "=", "[", "'question'", ",", "'logical_form'", "]", ",", "help", "=", "'which side to build language model'", ")", "\n", "# pretrained models", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "required", "=", "False", ",", "help", "=", "'Read model and hyperparams from this path'", ")", "\n", "# model paras", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'embedding size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'hidden layer dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of hidden layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--cell'", ",", "default", "=", "'lstm'", ",", "choices", "=", "[", "'lstm'", ",", "'gru'", "]", ",", "help", "=", "'rnn cell choice'", ")", "\n", "# training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "default", "=", "'sum'", ",", "choices", "=", "[", "'mean'", ",", "'sum'", "]", ",", "help", "=", "'loss function argument'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout rate at each non-recurrent layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_weight'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'all weights will be set to [-init_weight, init_weight] during initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--decoder_tied'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether use the same embedding weights and output matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'training use only this propotion of dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'train model on ith gpu. -1:cpu'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "if", "opt", ".", "testing", ":", "\n", "        ", "assert", "opt", ".", "read_model_path", "\n", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.construct_models.construct_model": [[16, 22], ["kargs.pop", "construct_models.construct_attnptr", "construct_models.construct_attn"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.construct_models.construct_attnptr", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.construct_models.construct_attn"], ["def", "construct_model", "(", "*", "args", ",", "**", "kargs", ")", ":", "\n", "    ", "copy", "=", "kargs", ".", "pop", "(", "'copy'", ",", "True", ")", "\n", "if", "copy", ":", "\n", "        ", "return", "construct_attnptr", "(", "*", "args", ",", "**", "kargs", ")", "\n", "", "else", ":", "\n", "        ", "return", "construct_attn", "(", "*", "args", ",", "**", "kargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.construct_models.construct_attn": [[23, 49], ["models.enc2dec.state_transition.StateTransition", "models.attention.attention_rnn.Attention", "models.embedding.embedding_rnn.RNNEmbeddings", "models.encoder.encoder_rnn.RNNEncoder", "models.embedding.embedding_rnn.RNNEmbeddings", "models.decoder.decoder_rnn.RNNDecoder", "models.generator.generator_naive.Generator", "models.model_attn.AttnModel", "models.model_attn.AttnModel.parameters", "p.data.uniform_", "models.model_attn.AttnModel.src_embed.embed.weight.data[].zero_", "models.model_attn.AttnModel.tgt_embed.embed.weight.data[].zero_"], "function", ["None"], ["", "", "def", "construct_attn", "(", "\n", "src_vocab", "=", "None", ",", "tgt_vocab", "=", "None", ",", "src_unk_idx", "=", "1", ",", "tgt_unk_idx", "=", "1", ",", "pad_src_idxs", "=", "[", "0", "]", ",", "pad_tgt_idxs", "=", "[", "0", "]", ",", "\n", "src_emb_size", "=", "100", ",", "tgt_emb_size", "=", "100", ",", "hidden_dim", "=", "200", ",", "num_layers", "=", "1", ",", "bidirectional", "=", "True", ",", "\n", "cell", "=", "'lstm'", ",", "dropout", "=", "0.5", ",", "init", "=", "None", ",", "**", "kargs", "\n", ")", ":", "\n", "    ", "\"\"\"\n        Construct Seq2Seq model with attention mechanism\n    \"\"\"", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "enc2dec_model", "=", "StateTransition", "(", "num_layers", ",", "cell", "=", "cell", ",", "bidirectional", "=", "bidirectional", ",", "hidden_dim", "=", "hidden_dim", ")", "\n", "attn_model", "=", "Attention", "(", "hidden_dim", "*", "num_directions", ",", "hidden_dim", ")", "\n", "src_embeddings", "=", "RNNEmbeddings", "(", "src_emb_size", ",", "src_vocab", ",", "src_unk_idx", ",", "pad_token_idxs", "=", "pad_src_idxs", ",", "dropout", "=", "dropout", ")", "\n", "encoder", "=", "RNNEncoder", "(", "src_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "cell", "=", "cell", ",", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "dropout", ")", "\n", "tgt_embeddings", "=", "RNNEmbeddings", "(", "tgt_emb_size", ",", "tgt_vocab", ",", "tgt_unk_idx", ",", "pad_token_idxs", "=", "pad_tgt_idxs", ",", "dropout", "=", "dropout", ")", "\n", "decoder", "=", "RNNDecoder", "(", "tgt_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "attn", "=", "attn_model", ",", "cell", "=", "cell", ",", "dropout", "=", "dropout", ")", "\n", "generator_model", "=", "Generator", "(", "tgt_emb_size", ",", "tgt_vocab", ",", "dropout", "=", "dropout", ")", "\n", "model", "=", "AttnModel", "(", "src_embeddings", ",", "encoder", ",", "tgt_embeddings", ",", "decoder", ",", "enc2dec_model", ",", "generator_model", ")", "\n", "\n", "if", "init", ":", "\n", "        ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "", "for", "pad_token_idx", "in", "pad_src_idxs", ":", "\n", "            ", "model", ".", "src_embed", ".", "embed", ".", "weight", ".", "data", "[", "pad_token_idx", "]", ".", "zero_", "(", ")", "\n", "", "for", "pad_token_idx", "in", "pad_tgt_idxs", ":", "\n", "            ", "model", ".", "tgt_embed", ".", "embed", ".", "weight", ".", "data", "[", "pad_token_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.construct_models.construct_attnptr": [[50, 76], ["models.enc2dec.state_transition.StateTransition", "models.attention.attention_rnn.Attention", "models.embedding.embedding_rnn.RNNEmbeddings", "models.encoder.encoder_rnn.RNNEncoder", "models.embedding.embedding_rnn.RNNEmbeddings", "models.decoder.decoder_rnn_pointer.RNNDecoderPointer", "models.generator.generator_pointer.GeneratorPointer", "models.model_attnptr.AttnPtrModel", "models.model_attnptr.AttnPtrModel.parameters", "p.data.uniform_", "models.model_attnptr.AttnPtrModel.src_embed.embed.weight.data[].zero_", "models.model_attnptr.AttnPtrModel.tgt_embed.embed.weight.data[].zero_"], "function", ["None"], ["", "def", "construct_attnptr", "(", "\n", "src_vocab", "=", "None", ",", "tgt_vocab", "=", "None", ",", "src_unk_idx", "=", "1", ",", "tgt_unk_idx", "=", "1", ",", "pad_src_idxs", "=", "[", "0", "]", ",", "pad_tgt_idxs", "=", "[", "0", "]", ",", "\n", "src_emb_size", "=", "100", ",", "tgt_emb_size", "=", "100", ",", "hidden_dim", "=", "200", ",", "bidirectional", "=", "True", ",", "num_layers", "=", "1", ",", "\n", "cell", "=", "'lstm'", ",", "dropout", "=", "0.5", ",", "init", "=", "None", ",", "**", "kargs", "\n", ")", ":", "\n", "    ", "\"\"\"\n        Construct Seq2Seq model with attention mechanism and pointer network\n    \"\"\"", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "enc2dec_model", "=", "StateTransition", "(", "num_layers", ",", "cell", "=", "cell", ",", "bidirectional", "=", "bidirectional", ",", "hidden_dim", "=", "hidden_dim", ")", "\n", "attn_model", "=", "Attention", "(", "hidden_dim", "*", "num_directions", ",", "hidden_dim", ")", "\n", "src_embeddings", "=", "RNNEmbeddings", "(", "src_emb_size", ",", "src_vocab", ",", "src_unk_idx", ",", "pad_token_idxs", "=", "pad_src_idxs", ",", "dropout", "=", "dropout", ")", "\n", "encoder", "=", "RNNEncoder", "(", "src_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "cell", "=", "cell", ",", "bidirectional", "=", "bidirectional", ",", "dropout", "=", "dropout", ")", "\n", "tgt_embeddings", "=", "RNNEmbeddings", "(", "tgt_emb_size", ",", "tgt_vocab", ",", "tgt_unk_idx", ",", "pad_token_idxs", "=", "pad_tgt_idxs", ",", "dropout", "=", "dropout", ")", "\n", "decoder", "=", "RNNDecoderPointer", "(", "tgt_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "attn", "=", "attn_model", ",", "cell", "=", "cell", ",", "dropout", "=", "dropout", ")", "\n", "generator_model", "=", "GeneratorPointer", "(", "tgt_emb_size", ",", "tgt_vocab", ",", "dropout", "=", "dropout", ")", "\n", "model", "=", "AttnPtrModel", "(", "src_embeddings", ",", "encoder", ",", "tgt_embeddings", ",", "decoder", ",", "enc2dec_model", ",", "generator_model", ")", "\n", "\n", "if", "init", ":", "\n", "        ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "", "for", "pad_token_idx", "in", "pad_src_idxs", ":", "\n", "            ", "model", ".", "src_embed", ".", "embed", ".", "weight", ".", "data", "[", "pad_token_idx", "]", ".", "zero_", "(", ")", "\n", "", "for", "pad_token_idx", "in", "pad_tgt_idxs", ":", "\n", "            ", "model", ".", "tgt_embed", ".", "embed", ".", "weight", ".", "data", "[", "pad_token_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.__init__": [[11, 14], ["models.encoder_decoder.EncoderDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "AttnModel", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "copy", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.forward": [[18, 28], ["model_attn.AttnModel.encoder", "model_attn.AttnModel.enc2dec", "models.model_utils.lens2mask", "model_attn.AttnModel.decoder", "model_attn.AttnModel.generator", "model_attn.AttnModel.src_embed", "model_attn.AttnModel.tgt_embed"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask"], ["def", "forward", "(", "self", ",", "src_inputs", ",", "src_lens", ",", "tgt_inputs", ",", "copy_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Used during training time.\n        \"\"\"", "\n", "enc_out", ",", "hidden_states", "=", "self", ".", "encoder", "(", "self", ".", "src_embed", "(", "src_inputs", ")", ",", "src_lens", ")", "\n", "hidden_states", "=", "self", ".", "enc2dec", "(", "hidden_states", ")", "\n", "src_mask", "=", "lens2mask", "(", "src_lens", ")", "\n", "dec_out", ",", "_", "=", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "tgt_inputs", ")", ",", "hidden_states", ",", "enc_out", ",", "src_mask", ",", "copy_tokens", ")", "\n", "out", "=", "self", ".", "generator", "(", "dec_out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.decode_batch": [[29, 39], ["model_attn.AttnModel.encoder", "model_attn.AttnModel.enc2dec", "models.model_utils.lens2mask", "model_attn.AttnModel.src_embed", "model_attn.AttnModel.decode_greed", "model_attn.AttnModel.decode_beam_search"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_greed", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_beam_search"], ["", "def", "decode_batch", "(", "self", ",", "src_inputs", ",", "src_lens", ",", "vocab", ",", "copy_tokens", "=", "None", ",", "\n", "beam_size", "=", "5", ",", "n_best", "=", "1", ",", "alpha", "=", "0.6", ",", "length_pen", "=", "'avg'", ")", ":", "\n", "        ", "enc_out", ",", "hidden_states", "=", "self", ".", "encoder", "(", "self", ".", "src_embed", "(", "src_inputs", ")", ",", "src_lens", ")", "\n", "hidden_states", "=", "self", ".", "enc2dec", "(", "hidden_states", ")", "\n", "src_mask", "=", "lens2mask", "(", "src_lens", ")", "\n", "if", "beam_size", "==", "1", ":", "\n", "            ", "return", "self", ".", "decode_greed", "(", "hidden_states", ",", "enc_out", ",", "src_mask", ",", "vocab", ",", "copy_tokens", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "decode_beam_search", "(", "hidden_states", ",", "enc_out", ",", "src_mask", ",", "vocab", ",", "copy_tokens", ",", "\n", "beam_size", "=", "beam_size", ",", "n_best", "=", "n_best", ",", "alpha", "=", "alpha", ",", "length_pen", "=", "length_pen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.decode_greed": [[40, 70], ["memory.size", "torch.ones().fill_().to", "torch.ones().fill_().to", "torch.ones().fill_().to", "torch.ones().fill_().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "model_attn.AttnModel.decode_one_step", "torch.max", "torch.max", "torch.max", "torch.max", "range", "torch.tensor.all", "torch.tensor.all", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "torch.ones().fill_", "range", "torch.ones().fill_().to.squeeze", "torch.ones().fill_().to.squeeze", "predictions[].append", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.cat().tolist", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attnptr.AttnPtrModel.decode_one_step"], ["", "", "def", "decode_greed", "(", "self", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "vocab", ",", "copy_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            hidden_states: hidden_states from encoder\n            memory: encoder output, bsize x src_len x enc_dim\n            src_mask: ByteTensor, bsize x max_src_len\n            vocab: tgt word2idx dict containing BOS, EOS\n        \"\"\"", "\n", "results", "=", "{", "\"scores\"", ":", "[", "]", ",", "\"predictions\"", ":", "[", "]", "}", "\n", "\n", "# first target token is BOS", "\n", "batches", "=", "memory", ".", "size", "(", "0", ")", "\n", "ys", "=", "torch", ".", "ones", "(", "batches", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", ".", "fill_", "(", "vocab", "[", "BOS", "]", ")", ".", "to", "(", "memory", ".", "device", ")", "\n", "# record whether each sample is finished", "\n", "all_done", "=", "torch", ".", "tensor", "(", "[", "False", "]", "*", "batches", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "memory", ".", "device", ")", "\n", "scores", "=", "torch", ".", "zeros", "(", "batches", ",", "1", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "memory", ".", "device", ")", "\n", "predictions", "=", "[", "[", "]", "for", "i", "in", "range", "(", "batches", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "MAX_DECODE_LENGTH", ")", ":", "\n", "            ", "logprob", ",", "hidden_states", "=", "self", ".", "decode_one_step", "(", "ys", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", ")", "\n", "maxprob", ",", "ys", "=", "torch", ".", "max", "(", "logprob", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "batches", ")", ":", "\n", "                ", "if", "not", "all_done", "[", "i", "]", ":", "\n", "                    ", "scores", "[", "i", "]", "+=", "maxprob", "[", "i", "]", "\n", "predictions", "[", "i", "]", ".", "append", "(", "ys", "[", "i", "]", ")", "\n", "", "", "done", "=", "ys", ".", "squeeze", "(", "dim", "=", "1", ")", "==", "vocab", "[", "EOS", "]", "\n", "all_done", "|=", "done", "\n", "if", "all_done", ".", "all", "(", ")", ":", "\n", "                ", "break", "\n", "", "", "results", "[", "\"predictions\"", "]", ",", "results", "[", "\"scores\"", "]", "=", "[", "[", "torch", ".", "cat", "(", "pred", ")", ".", "tolist", "(", ")", "]", "for", "pred", "in", "predictions", "]", ",", "scores", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.decode_one_step": [[71, 78], ["model_attn.AttnModel.decoder", "model_attn.AttnModel.generator", "model_attn.AttnModel.tgt_embed", "model_attn.AttnModel.squeeze"], "methods", ["None"], ["", "def", "decode_one_step", "(", "self", ",", "ys", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            ys: bsize x 1\n        \"\"\"", "\n", "dec_out", ",", "hidden_states", "=", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "ys", ")", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", ")", "\n", "out", "=", "self", ".", "generator", "(", "dec_out", ")", "\n", "return", "out", ".", "squeeze", "(", "dim", "=", "1", ")", ",", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attn.AttnModel.decode_beam_search": [[79, 159], ["update_active.size", "models.Beam.GNMTGlobalScorer", "models.model_utils.tile", "models.model_utils.tile", "list", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "models.Beam.Beam", "type", "range", "torch.stack().contiguous().view", "torch.stack().contiguous().view", "torch.stack().contiguous().view", "torch.stack().contiguous().view", "model_attn.AttnModel.decode_one_step", "out.contiguous().view.contiguous().view.contiguous().view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model_attn.AttnModel.decode_beam_search.update_active"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.tile", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.tile", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attnptr.AttnPtrModel.decode_one_step"], ["", "def", "decode_beam_search", "(", "self", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "vocab", ",", "copy_tokens", "=", "None", ",", "\n", "beam_size", "=", "5", ",", "n_best", "=", "1", ",", "alpha", "=", "0.6", ",", "length_pen", "=", "'avg'", ")", ":", "\n", "        ", "\"\"\"\n            Beam search decoding\n        \"\"\"", "\n", "results", "=", "{", "\"scores\"", ":", "[", "]", ",", "\"predictions\"", ":", "[", "]", "}", "\n", "\n", "# Construct beams, we donot use stepwise coverage penalty nor ngrams block", "\n", "remaining_sents", "=", "memory", ".", "size", "(", "0", ")", "\n", "global_scorer", "=", "GNMTGlobalScorer", "(", "alpha", ",", "length_pen", ")", "\n", "beam", "=", "[", "Beam", "(", "beam_size", ",", "vocab", ",", "global_scorer", "=", "global_scorer", ",", "device", "=", "memory", ".", "device", ")", "\n", "for", "_", "in", "range", "(", "remaining_sents", ")", "]", "\n", "\n", "# repeat beam_size times", "\n", "memory", ",", "src_mask", ",", "copy_tokens", "=", "tile", "(", "[", "memory", ",", "src_mask", ",", "copy_tokens", "]", ",", "beam_size", ",", "dim", "=", "0", ")", "\n", "hidden_states", "=", "tile", "(", "hidden_states", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "h_c", "=", "type", "(", "hidden_states", ")", "in", "[", "list", ",", "tuple", "]", "\n", "batch_idx", "=", "list", "(", "range", "(", "remaining_sents", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "MAX_DECODE_LENGTH", ")", ":", "\n", "# (a) construct beamsize * remaining_sents next words", "\n", "            ", "ys", "=", "torch", ".", "stack", "(", "[", "b", ".", "get_current_state", "(", ")", "for", "b", "in", "beam", "if", "not", "b", ".", "done", "(", ")", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "# (b) pass through the decoder network", "\n", "out", ",", "hidden_states", "=", "self", ".", "decode_one_step", "(", "ys", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", ")", "\n", "out", "=", "out", ".", "contiguous", "(", ")", ".", "view", "(", "remaining_sents", ",", "beam_size", ",", "-", "1", ")", "\n", "\n", "# (c) advance each beam", "\n", "active", ",", "select_indices_array", "=", "[", "]", ",", "[", "]", "\n", "# Loop over the remaining_batch number of beam", "\n", "for", "b", "in", "range", "(", "remaining_sents", ")", ":", "\n", "                ", "idx", "=", "batch_idx", "[", "b", "]", "# idx represent the original order in minibatch_size", "\n", "beam", "[", "idx", "]", ".", "advance", "(", "out", "[", "b", "]", ")", "\n", "if", "not", "beam", "[", "idx", "]", ".", "done", "(", ")", ":", "\n", "                    ", "active", ".", "append", "(", "(", "idx", ",", "b", ")", ")", "\n", "", "select_indices_array", ".", "append", "(", "beam", "[", "idx", "]", ".", "get_current_origin", "(", ")", "+", "b", "*", "beam_size", ")", "\n", "\n", "# (d) update hidden_states history", "\n", "", "select_indices_array", "=", "torch", ".", "cat", "(", "select_indices_array", ",", "dim", "=", "0", ")", "\n", "if", "h_c", ":", "\n", "                ", "hidden_states", "=", "(", "hidden_states", "[", "0", "]", ".", "index_select", "(", "1", ",", "select_indices_array", ")", ",", "hidden_states", "[", "1", "]", ".", "index_select", "(", "1", ",", "select_indices_array", ")", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "hidden_states", ".", "index_select", "(", "1", ",", "select_indices_array", ")", "\n", "\n", "", "if", "not", "active", ":", "\n", "                ", "break", "\n", "\n", "# (e) reserve un-finished batches", "\n", "", "active_idx", "=", "torch", ".", "tensor", "(", "[", "item", "[", "1", "]", "for", "item", "in", "active", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "memory", ".", "device", ")", "# original order in remaining batch", "\n", "batch_idx", "=", "{", "idx", ":", "item", "[", "0", "]", "for", "idx", ",", "item", "in", "enumerate", "(", "active", ")", "}", "# order for next remaining batch", "\n", "\n", "def", "update_active", "(", "t", ")", ":", "\n", "                ", "if", "t", "is", "None", ":", "return", "t", "\n", "t_reshape", "=", "t", ".", "contiguous", "(", ")", ".", "view", "(", "remaining_sents", ",", "beam_size", ",", "-", "1", ")", "\n", "new_size", "=", "list", "(", "t", ".", "size", "(", ")", ")", "\n", "new_size", "[", "0", "]", "=", "-", "1", "\n", "return", "t_reshape", ".", "index_select", "(", "0", ",", "active_idx", ")", ".", "view", "(", "*", "new_size", ")", "\n", "\n", "", "if", "h_c", ":", "\n", "                ", "hidden_states", "=", "(", "\n", "update_active", "(", "hidden_states", "[", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "update_active", "(", "hidden_states", "[", "1", "]", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "update_active", "(", "hidden_states", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "memory", "=", "update_active", "(", "memory", ")", "\n", "src_mask", "=", "update_active", "(", "src_mask", ")", "\n", "copy_tokens", "=", "update_active", "(", "copy_tokens", ")", "\n", "remaining_sents", "=", "len", "(", "active", ")", "\n", "\n", "", "for", "b", "in", "beam", ":", "\n", "            ", "scores", ",", "ks", "=", "b", ".", "sort_finished", "(", "minimum", "=", "n_best", ")", "\n", "hyps", "=", "[", "]", "\n", "for", "i", ",", "(", "times", ",", "k", ")", "in", "enumerate", "(", "ks", "[", ":", "n_best", "]", ")", ":", "\n", "                ", "hyp", "=", "b", ".", "get_hyp", "(", "times", ",", "k", ")", "\n", "hyps", ".", "append", "(", "hyp", ".", "tolist", "(", ")", ")", "# hyp contains </s> but does not contain <s>", "\n", "", "results", "[", "\"predictions\"", "]", ".", "append", "(", "hyps", ")", "# batch list of variable_tgt_len", "\n", "results", "[", "\"scores\"", "]", ".", "append", "(", "torch", ".", "stack", "(", "scores", ")", "[", ":", "n_best", "]", ")", "# list of [n_best], torch.FloatTensor", "\n", "", "results", "[", "\"scores\"", "]", "=", "torch", ".", "stack", "(", "results", "[", "\"scores\"", "]", ")", "\n", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.tile": [[6, 34], ["type", "list", "list", "x.permute().contiguous.size", "x.permute().contiguous.contiguous().view().transpose().repeat().transpose().contiguous().view", "type", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "model_utils.tile", "len", "x.permute().contiguous.contiguous().view().transpose().repeat().transpose().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute", "x.permute().contiguous.contiguous().view().transpose().repeat().transpose", "x.permute().contiguous.contiguous().view().transpose().repeat", "x.permute().contiguous.contiguous().view().transpose", "x.permute().contiguous.contiguous().view", "x.permute().contiguous.contiguous"], "function", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.tile"], ["def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n        Tiles x on dimension dim count times.\n        E.g. [1, 2, 3], count=2 ==> [1, 1, 2, 2, 3, 3]\n            [[1, 2], [3, 4]], count=3, dim=1 ==> [[1, 1, 1, 2, 2, 2], [3, 3, 3, 4, 4, 4]]\n        Different from torch.repeat\n    \"\"\"", "\n", "if", "x", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "elif", "type", "(", "x", ")", "in", "[", "list", ",", "tuple", "]", ":", "\n", "        ", "return", "type", "(", "x", ")", "(", "[", "tile", "(", "each", ",", "count", ",", "dim", ")", "for", "each", "in", "x", "]", ")", "\n", "", "else", ":", "\n", "        ", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "            ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "batch", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "count", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask": [[35, 41], ["lens.numel", "lens.max", "torch.arange().type_as().to().repeat().lt", "torch.arange().type_as().to().repeat().lt", "torch.arange().type_as().to().repeat().lt", "lens.unsqueeze", "torch.arange().type_as().to().repeat", "torch.arange().type_as().to().repeat", "torch.arange().type_as().to().repeat", "torch.arange().type_as().to", "torch.arange().type_as().to", "torch.arange().type_as().to", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "", "def", "lens2mask", "(", "lens", ")", ":", "\n", "    ", "bsize", "=", "lens", ".", "numel", "(", ")", "\n", "max_len", "=", "lens", ".", "max", "(", ")", "\n", "masks", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "type_as", "(", "lens", ")", ".", "to", "(", "lens", ".", "device", ")", ".", "repeat", "(", "bsize", ",", "1", ")", ".", "lt", "(", "lens", ".", "unsqueeze", "(", "1", ")", ")", "\n", "masks", ".", "requires_grad", "=", "False", "\n", "return", "masks", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.rnn_wrapper": [[42, 79], ["torch.sort", "torch.sort", "torch.sort", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.index_select", "torch.index_select", "torch.index_select", "torch.pack_padded_sequence", "encoder", "torch.pad_packed_sequence", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.cat", "torch.cat", "torch.cat", "list", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "list", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "sorted_lens[].tolist", "cell.upper", "cell.upper", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.zeros().type_as().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "sort_key.unsqueeze().unsqueeze().expand", "torch.cat.size", "sort_key.unsqueeze().unsqueeze().expand", "cell.upper", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_", "torch.zeros_like().type_as().to().scatter_.contiguous", "torch.sum", "torch.sum", "torch.sum", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "sort_key.unsqueeze().unsqueeze().expand", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "sort_key.unsqueeze().unsqueeze", "sort_key.unsqueeze().unsqueeze", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to", "torch.zeros_like().type_as().to().scatter_.contiguous", "torch.zeros_like().type_as().to().scatter_.contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "sort_key.unsqueeze().unsqueeze", "torch.zeros_like().type_as().to().scatter_.size", "torch.zeros_like().type_as().to().scatter_.size", "h.size", "h.size", "torch.zeros", "torch.zeros", "torch.zeros", "sort_key.unsqueeze", "sort_key.unsqueeze", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "torch.zeros_like().type_as", "sorted_lens.size", "torch.zeros_like().type_as().to().scatter_.size", "sorted_lens.size", "h.size", "c.size", "c.size", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "sort_key.unsqueeze", "sorted_lens.size", "c.size", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["", "def", "rnn_wrapper", "(", "encoder", ",", "inputs", ",", "lens", ",", "cell", "=", "'lstm'", ")", ":", "\n", "    ", "\"\"\"\n        @args:\n            encoder(nn.Module): rnn series bidirectional encoder, batch_first=True\n            inputs(torch.FloatTensor): rnn inputs, bsize x max_seq_len x in_dim\n            lens(torch.LongTensor): seq len for each sample, bsize\n        @return:\n            out(torch.FloatTensor): output of encoder, bsize x max_seq_len x hidden_dim*2\n            hidden_states(tuple or torch.FloatTensor): final hidden states, num_layers*2 x bsize x hidden_dim\n    \"\"\"", "\n", "# rerank according to lens and temporarily remove empty inputs", "\n", "sorted_lens", ",", "sort_key", "=", "torch", ".", "sort", "(", "lens", ",", "descending", "=", "True", ")", "\n", "nonzero_index", "=", "torch", ".", "sum", "(", "sorted_lens", ">", "0", ")", ".", "item", "(", ")", "\n", "sorted_inputs", "=", "torch", ".", "index_select", "(", "inputs", ",", "dim", "=", "0", ",", "index", "=", "sort_key", "[", ":", "nonzero_index", "]", ")", "\n", "# forward non empty inputs    ", "\n", "packed_inputs", "=", "rnn_utils", ".", "pack_padded_sequence", "(", "sorted_inputs", ",", "sorted_lens", "[", ":", "nonzero_index", "]", ".", "tolist", "(", ")", ",", "batch_first", "=", "True", ")", "\n", "packed_out", ",", "h", "=", "encoder", "(", "packed_inputs", ")", "# bsize x srclen x dim", "\n", "out", ",", "_", "=", "rnn_utils", ".", "pad_packed_sequence", "(", "packed_out", ",", "batch_first", "=", "True", ")", "\n", "if", "cell", ".", "upper", "(", ")", "==", "'LSTM'", ":", "\n", "        ", "h", ",", "c", "=", "h", "\n", "# pad zeros due to empty inputs", "\n", "", "pad_zeros", "=", "torch", ".", "zeros", "(", "sorted_lens", ".", "size", "(", "0", ")", "-", "out", ".", "size", "(", "0", ")", ",", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ")", ".", "type_as", "(", "out", ")", ".", "to", "(", "out", ".", "device", ")", "\n", "sorted_out", "=", "torch", ".", "cat", "(", "[", "out", ",", "pad_zeros", "]", ",", "dim", "=", "0", ")", "\n", "pad_hiddens", "=", "torch", ".", "zeros", "(", "h", ".", "size", "(", "0", ")", ",", "sorted_lens", ".", "size", "(", "0", ")", "-", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", ")", ".", "type_as", "(", "h", ")", ".", "to", "(", "h", ".", "device", ")", "\n", "sorted_hiddens", "=", "torch", ".", "cat", "(", "[", "h", ",", "pad_hiddens", "]", ",", "dim", "=", "1", ")", "\n", "if", "cell", ".", "upper", "(", ")", "==", "'LSTM'", ":", "\n", "        ", "pad_cells", "=", "torch", ".", "zeros", "(", "c", ".", "size", "(", "0", ")", ",", "sorted_lens", ".", "size", "(", "0", ")", "-", "c", ".", "size", "(", "1", ")", ",", "c", ".", "size", "(", "2", ")", ")", ".", "type_as", "(", "c", ")", ".", "to", "(", "c", ".", "device", ")", "\n", "sorted_cells", "=", "torch", ".", "cat", "(", "[", "c", ",", "pad_cells", "]", ",", "dim", "=", "1", ")", "\n", "# rerank according to sort_key", "\n", "", "shape", "=", "list", "(", "sorted_out", ".", "size", "(", ")", ")", "\n", "out", "=", "torch", ".", "zeros_like", "(", "sorted_out", ")", ".", "type_as", "(", "sorted_out", ")", ".", "to", "(", "sorted_out", ".", "device", ")", ".", "scatter_", "(", "0", ",", "sort_key", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "*", "shape", ")", ",", "sorted_out", ")", "\n", "shape", "=", "list", "(", "sorted_hiddens", ".", "size", "(", ")", ")", "\n", "hiddens", "=", "torch", ".", "zeros_like", "(", "sorted_hiddens", ")", ".", "type_as", "(", "sorted_hiddens", ")", ".", "to", "(", "sorted_hiddens", ".", "device", ")", ".", "scatter_", "(", "1", ",", "sort_key", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "*", "shape", ")", ",", "sorted_hiddens", ")", "\n", "if", "cell", ".", "upper", "(", ")", "==", "'LSTM'", ":", "\n", "        ", "cells", "=", "torch", ".", "zeros_like", "(", "sorted_cells", ")", ".", "type_as", "(", "sorted_cells", ")", ".", "to", "(", "sorted_cells", ".", "device", ")", ".", "scatter_", "(", "1", ",", "sort_key", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "*", "shape", ")", ",", "sorted_cells", ")", "\n", "return", "out", ",", "(", "hiddens", ".", "contiguous", "(", ")", ",", "cells", ".", "contiguous", "(", ")", ")", "\n", "", "return", "out", ",", "hiddens", ".", "contiguous", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.__init__": [[11, 29], ["torch.Module.__init__", "sp_model.to", "qg_model.to"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["from", "utils", ".", "constants", "import", "*", "\n", "from", "utils", ".", "solver", ".", "solver_dual_learning", "import", "DualLearningSolver", "\n", "from", "utils", ".", "hyperparam", "import", "hyperparam_dual_learning", "\n", "from", "models", ".", "construct_models", "import", "construct_model", "as", "model", "\n", "from", "models", ".", "dual_learning", "import", "DualLearning", "\n", "from", "models", ".", "reward", "import", "RewardModel", "\n", "from", "models", ".", "language_model", "import", "LanguageModel", "\n", "\n", "############################### Arguments parsing and Preparations ##############################", "\n", "\n", "def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "required", "=", "True", ",", "help", "=", "'pseudo method for semantic parsing'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiment on'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "help", "=", "'Testing mode, load sp and qg model path'", ")", "\n", "# model params", "\n", "parser", ".", "add_argument", "(", "'--read_sp_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained sp model'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_qg_model_path'", ",", "required", "=", "True", ",", "help", "=", "'pretrained qg model path'", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.forward": [[30, 42], ["dual_learning.DualLearning.cycle_start_from_sp", "dual_learning.DualLearning.cycle_start_from_qg", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.cycle_start_from_sp", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.cycle_start_from_qg"], ["parser", ".", "add_argument", "(", "'--read_qlm_path'", ",", "required", "=", "True", ",", "help", "=", "'language model for natural language questions'", ")", "\n", "parser", ".", "add_argument", "(", "'--read_lflm_path'", ",", "required", "=", "True", ",", "help", "=", "'language model for logical form'", ")", "\n", "# pseudo training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "choices", "=", "[", "'sum'", ",", "'mean'", "]", ",", "default", "=", "'sum'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--sample'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'size of sampling during training in dual learning'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.cycle_start_from_sp": [[43, 74], ["dual_learning.DualLearning.sp_model.decode_batch", "domain.reverse", "dual_learning.DualLearning.reward_model().contiguous().view", "dual_learning.DualLearning.mean", "dual_learning.DualLearning.sp2qg", "dual_learning.DualLearning.qg_model", "dual_learning.DualLearning.reward_model().contiguous().view", "dual_learning.DualLearning.detach().cpu", "dual_learning.DualLearning.detach().cpu.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "dual_learning.DualLearning.reward_model().contiguous", "dual_learning.DualLearning.reward_model().contiguous", "dual_learning.DualLearning.detach", "total_reward.to", "dual_learning.DualLearning.reward_model", "dual_learning.DualLearning.reward_model"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.sp2qg"], ["parser", ".", "add_argument", "(", "'--n_best'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'used during decoding time'", ")", "\n", "parser", ".", "add_argument", "(", "'--alpha'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'coefficient which combines sp valid and reconstruction reward'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'coefficient which combines qg valid and reconstruction reward'", ")", "\n", "parser", ".", "add_argument", "(", "'--cycle'", ",", "choices", "=", "[", "'sp'", ",", "'qg'", ",", "'sp+qg'", "]", ",", "default", "=", "'sp+qg'", ",", "help", "=", "'whether use cycle starts from sp/qg'", ")", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of labeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--unlabeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'ratio of unlabeled samples'", ")", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "nargs", "=", "2", ",", "default", "=", "[", "-", "1", ",", "-", "1", "]", ",", "help", "=", "'device for semantic parsing and question generation model respectively'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--extra'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether use synthesized logical forms'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "\n", "# Some Arguments Check", "\n", "assert", "opt", ".", "labeled", ">", "0.", "\n", "assert", "opt", ".", "unlabeled", ">=", "0.", "and", "opt", ".", "unlabeled", "<=", "1.0", "\n", "return", "opt", "\n", "\n", "", "opt", "=", "main", "(", ")", "\n", "\n", "####################### Output path, logger, device and random seed configuration #################", "\n", "\n", "exp_path", "=", "opt", ".", "read_model_path", "if", "opt", ".", "testing", "else", "hyperparam_dual_learning", "(", "opt", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "exp_path", ")", "\n", "\n", "", "logger", "=", "set_logger", "(", "exp_path", ",", "testing", "=", "opt", ".", "testing", ")", "\n", "logger", ".", "info", "(", "\"Parameters: \"", "+", "str", "(", "json", ".", "dumps", "(", "vars", "(", "opt", ")", ",", "indent", "=", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Experiment path: %s\"", "%", "(", "exp_path", ")", ")", "\n", "sp_device", ",", "qg_device", "=", "set_torch_device", "(", "opt", ".", "deviceId", "[", "0", "]", ")", ",", "set_torch_device", "(", "opt", ".", "deviceId", "[", "1", "]", ")", "\n", "set_random_seed", "(", "opt", ".", "seed", ",", "device", "=", "'cuda'", ")", "\n", "\n", "################################ Vocab and Data Reader ###########################", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.sp2qg": [[75, 80], ["utils.batch.get_minibatch_qg", "utils.example.Example", "zip"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_qg"], ["sp_copy", ",", "qg_copy", "=", "'copy__'", "in", "opt", ".", "read_sp_model_path", ",", "'copy__'", "in", "opt", ".", "read_qg_model_path", "\n", "sp_vocab", ",", "qg_vocab", "=", "Vocab", "(", "opt", ".", "dataset", ",", "task", "=", "'semantic_parsing'", ",", "copy", "=", "sp_copy", ")", ",", "Vocab", "(", "opt", ".", "dataset", ",", "task", "=", "'question_generation'", ",", "copy", "=", "qg_copy", ")", "\n", "lm_vocab", "=", "Vocab", "(", "opt", ".", "dataset", ",", "task", "=", "'language_model'", ")", "\n", "logger", ".", "info", "(", "\"Semantic Parsing model vocabulary ...\"", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for input natural language sentence is: %s\"", "%", "(", "len", "(", "sp_vocab", ".", "word2id", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for output logical form is: %s\"", "%", "(", "len", "(", "sp_vocab", ".", "lf2id", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.cycle_start_from_qg": [[81, 112], ["dual_learning.DualLearning.qg_model.decode_batch", "domain.reverse", "dual_learning.DualLearning.reward_model().contiguous().view", "dual_learning.DualLearning.mean", "dual_learning.DualLearning.qg2sp", "dual_learning.DualLearning.sp_model", "dual_learning.DualLearning.reward_model().contiguous().view", "dual_learning.DualLearning.detach().cpu", "dual_learning.DualLearning.detach().cpu.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "dual_learning.DualLearning.reward_model().contiguous", "dual_learning.DualLearning.reward_model().contiguous", "dual_learning.DualLearning.detach", "total_reward.to", "dual_learning.DualLearning.reward_model", "dual_learning.DualLearning.reward_model"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_base.Domain.reverse", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.qg2sp"], ["\n", "logger", ".", "info", "(", "\"Question Generation model vocabulary ...\"", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for input logical form is: %s\"", "%", "(", "len", "(", "qg_vocab", ".", "lf2id", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for output natural language sentence is: %s\"", "%", "(", "len", "(", "qg_vocab", ".", "word2id", ")", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Language model vocabulary ...\"", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for question language model is: %s\"", "%", "(", "len", "(", "lm_vocab", ".", "word2id", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Vocab size for logical form language model is: %s\"", "%", "(", "len", "(", "lm_vocab", ".", "lf2id", ")", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Read dataset starts at %s\"", "%", "(", "time", ".", "asctime", "(", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ")", ")", "\n", "Example", ".", "set_domain", "(", "opt", ".", "dataset", ")", "\n", "if", "not", "opt", ".", "testing", ":", "\n", "    ", "train_dataset", ",", "dev_dataset", "=", "Example", ".", "load_dataset", "(", "choice", "=", "'train'", ")", "\n", "labeled_train_dataset", ",", "unlabeled_train_dataset", "=", "split_dataset", "(", "train_dataset", ",", "opt", ".", "labeled", ")", "\n", "unlabeled_train_dataset", ",", "_", "=", "split_dataset", "(", "unlabeled_train_dataset", ",", "opt", ".", "unlabeled", ")", "\n", "unlabeled_train_dataset", "+=", "labeled_train_dataset", "\n", "if", "opt", ".", "extra", ":", "\n", "        ", "q_unlabeled_train_dataset", "=", "unlabeled_train_dataset", "\n", "lf_unlabeled_train_dataset", "=", "unlabeled_train_dataset", "+", "Example", ".", "load_dataset", "(", "choice", "=", "'extra'", ")", "\n", "", "else", ":", "\n", "        ", "q_unlabeled_train_dataset", ",", "lf_unlabeled_train_dataset", "=", "unlabeled_train_dataset", ",", "unlabeled_train_dataset", "\n", "", "logger", ".", "info", "(", "\"Labeled/Unlabeled train dataset size is: %s and %s\"", "%", "(", "len", "(", "labeled_train_dataset", ")", ",", "len", "(", "lf_unlabeled_train_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Dev dataset size is: %s\"", "%", "(", "len", "(", "dev_dataset", ")", ")", ")", "\n", "", "test_dataset", "=", "Example", ".", "load_dataset", "(", "choice", "=", "'test'", ")", "\n", "logger", ".", "info", "(", "\"Test dataset size is: %s\"", "%", "(", "len", "(", "test_dataset", ")", ")", ")", "\n", "\n", "###################################### Model Construction ########################################", "\n", "\n", "if", "not", "opt", ".", "testing", ":", "\n", "    ", "params", "=", "{", "\n", "\"read_sp_model_path\"", ":", "opt", ".", "read_sp_model_path", ",", "\"read_qg_model_path\"", ":", "opt", ".", "read_qg_model_path", ",", "\n", "\"read_qlm_path\"", ":", "opt", ".", "read_qlm_path", ",", "\"read_lflm_path\"", ":", "opt", ".", "read_lflm_path", ",", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.qg2sp": [[113, 118], ["utils.batch.get_minibatch_sp", "utils.example.Example", "zip"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.utils.batch.get_minibatch_sp"], ["\"sample\"", ":", "opt", ".", "sample", ",", "\"alpha\"", ":", "opt", ".", "alpha", ",", "\"beta\"", ":", "opt", ".", "beta", ",", "\"reduction\"", ":", "opt", ".", "reduction", "\n", "}", "\n", "json", ".", "dump", "(", "params", ",", "open", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'params.json'", ")", ",", "'w'", ")", ",", "indent", "=", "4", ")", "\n", "", "else", ":", "\n", "    ", "params", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "\"params.json\"", ")", ",", "'r'", ")", ")", "\n", "", "sp_params", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_sp_model_path'", "]", ",", "'params.json'", ")", ",", "'r'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.decode_batch": [[119, 126], ["dual_learning.DualLearning.sp_model.decode_batch", "dual_learning.DualLearning.qg_model.decode_batch", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch"], ["sp_model", "=", "model", "(", "**", "sp_params", ")", "\n", "qg_params", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_qg_model_path'", "]", ",", "'params.json'", ")", ",", "'r'", ")", ")", "\n", "qg_model", "=", "model", "(", "**", "qg_params", ")", "\n", "if", "not", "opt", ".", "testing", ":", "\n", "    ", "sp_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_sp_model_path'", "]", ",", "'model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Semantic Parsing model from path %s\"", "%", "(", "params", "[", "'read_sp_model_path'", "]", ")", ")", "\n", "qg_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_qg_model_path'", "]", ",", "'model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Question Generation model from path %s\"", "%", "(", "params", "[", "'read_qg_model_path'", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.pad_embedding_grad_zero": [[127, 130], ["dual_learning.DualLearning.sp_model.pad_embedding_grad_zero", "dual_learning.DualLearning.qg_model.pad_embedding_grad_zero"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero"], ["qlm_params", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_qlm_path'", "]", ",", "'params.json'", ")", ",", "'r'", ")", ")", "\n", "qlm_model", "=", "LanguageModel", "(", "**", "qlm_params", ")", "\n", "qlm_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_qlm_path'", "]", ",", "'model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Question Language Model from path %s\"", "%", "(", "params", "[", "'read_qlm_path'", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.load_model": [[131, 136], ["dual_learning.DualLearning.sp_model.load_model", "dual_learning.DualLearning.qg_model.load_model"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model"], ["lflm_params", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_lflm_path'", "]", ",", "'params.json'", ")", ",", "'r'", ")", ")", "\n", "lflm_model", "=", "LanguageModel", "(", "**", "lflm_params", ")", "\n", "lflm_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'read_lflm_path'", "]", ",", "'model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Logical Form Language Model from path %s\"", "%", "(", "params", "[", "'read_lflm_path'", "]", ")", ")", "\n", "reward_model", "=", "RewardModel", "(", "opt", ".", "dataset", ",", "qlm_model", ",", "lflm_model", ",", "lm_vocab", ",", "sp_device", "=", "sp_device", ",", "qg_device", "=", "qg_device", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.dual_learning.DualLearning.save_model": [[137, 142], ["dual_learning.DualLearning.sp_model.save_model", "dual_learning.DualLearning.qg_model.save_model"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model"], ["    ", "sp_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'sp_model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Semantic Parsing model from path %s\"", "%", "(", "exp_path", ")", ")", "\n", "qg_model", ".", "load_model", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'qg_model.pkl'", ")", ")", "\n", "logger", ".", "info", "(", "\"Load Question Generation model from path %s\"", "%", "(", "exp_path", ")", ")", "\n", "reward_model", "=", "None", "\n", "", "train_model", "=", "DualLearning", "(", "sp_model", ",", "qg_model", ",", "reward_model", ",", "sp_vocab", ",", "qg_vocab", ",", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.__init__": [[10, 18], ["super().__init__", "qlm.to", "lflm.to"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "qlm", ",", "lflm", ",", "lm_vocab", ",", "sp_device", "=", "'cpu'", ",", "qg_device", "=", "'cpu'", ")", ":", "\n", "        ", "super", "(", "RewardModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "qlm", "=", "qlm", ".", "to", "(", "sp_device", ")", "\n", "self", ".", "lflm", "=", "lflm", ".", "to", "(", "qg_device", ")", "\n", "self", ".", "vocab", "=", "lm_vocab", "\n", "self", ".", "sp_device", "=", "sp_device", "\n", "self", ".", "qg_device", "=", "qg_device", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.forward": [[19, 28], ["reward.RewardModel.sp_validity_reward", "reward.RewardModel.qg_validity_reward", "reward.RewardModel.reconstruction_reward", "ValueError"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.sp_validity_reward", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.qg_validity_reward", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.reconstruction_reward"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "choice", "=", "'sp_val'", ")", ":", "\n", "        ", "if", "choice", "==", "'sp_val'", ":", "\n", "            ", "return", "self", ".", "sp_validity_reward", "(", "*", "args", ")", "\n", "", "elif", "choice", "==", "'qg_val'", ":", "\n", "            ", "return", "self", ".", "qg_validity_reward", "(", "*", "args", ")", "\n", "", "elif", "'rec'", "in", "choice", ":", "\n", "            ", "return", "self", ".", "reconstruction_reward", "(", "*", "args", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'[Error]: unknown reward choice !'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.sp_validity_reward": [[29, 46], ["max", "torch.tensor", "torch.tensor", "reward.RewardModel.lflm.eval", "domain.is_valid", "torch.tensor", "len", "torch.no_grad", "reward.RewardModel.lflm.sent_logprobability().cpu", "domain.obtain_denotations", "domain.normalize", "reward.RewardModel.lflm.sent_logprobability", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.is_valid", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_geo.GEODomain.obtain_denotations", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.domain_atis.ATISDomain.normalize", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.sent_logprobability"], ["", "", "def", "sp_validity_reward", "(", "self", ",", "lf_list", ")", ":", "\n", "# calculate logical form language model length normalized log probability", "\n", "        ", "input_idxs", "=", "[", "[", "self", ".", "vocab", ".", "lf2id", "[", "BOS", "]", "]", "+", "[", "self", ".", "vocab", ".", "lf2id", "[", "word", "]", "if", "word", "in", "self", ".", "vocab", ".", "lf2id", "else", "self", ".", "vocab", ".", "lf2id", "[", "UNK", "]", "for", "word", "in", "sent", "]", "+", "[", "self", ".", "vocab", ".", "word2id", "[", "EOS", "]", "]", "for", "sent", "in", "lf_list", "]", "\n", "lens", "=", "[", "len", "(", "each", ")", "for", "each", "in", "input_idxs", "]", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "input_idxs", "=", "[", "sent", "+", "[", "self", ".", "vocab", ".", "lf2id", "[", "PAD", "]", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "input_idxs", "]", "\n", "input_tensor", "=", "torch", ".", "tensor", "(", "input_idxs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "qg_device", ")", "\n", "lens", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "qg_device", ")", "\n", "self", ".", "lflm", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logprob", "=", "self", ".", "lflm", ".", "sent_logprobability", "(", "input_tensor", ",", "lens", ")", ".", "cpu", "(", ")", "\n", "# grammar check", "\n", "", "domain", "=", "Example", ".", "domain", "\n", "ans", "=", "domain", ".", "is_valid", "(", "domain", ".", "obtain_denotations", "(", "domain", ".", "normalize", "(", "lf_list", ")", ")", ")", "\n", "grammar", "=", "torch", ".", "tensor", "(", "ans", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ")", "\n", "val_reward", "=", "0.5", "*", "logprob", "+", "0.5", "*", "grammar", "\n", "return", "val_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.qg_validity_reward": [[47, 59], ["max", "torch.tensor", "torch.tensor", "reward.RewardModel.qlm.eval", "len", "torch.no_grad", "reward.RewardModel.qlm.sent_logprobability().cpu", "reward.RewardModel.qlm.sent_logprobability", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.domain.atis_evaluator.ATISEvaluator.eval", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.sent_logprobability"], ["", "def", "qg_validity_reward", "(", "self", ",", "utterances", ")", ":", "\n", "# calculate language model length normalized log probability", "\n", "        ", "input_idxs", "=", "[", "[", "self", ".", "vocab", ".", "word2id", "[", "BOS", "]", "]", "+", "[", "self", ".", "vocab", ".", "word2id", "[", "word", "]", "if", "word", "in", "self", ".", "vocab", ".", "word2id", "else", "self", ".", "vocab", ".", "word2id", "[", "UNK", "]", "for", "word", "in", "sent", "]", "+", "[", "self", ".", "vocab", ".", "word2id", "[", "EOS", "]", "]", "for", "sent", "in", "utterances", "]", "\n", "lens", "=", "[", "len", "(", "each", ")", "for", "each", "in", "input_idxs", "]", "\n", "max_len", "=", "max", "(", "lens", ")", "\n", "input_idxs", "=", "[", "sent", "+", "[", "self", ".", "vocab", ".", "word2id", "[", "PAD", "]", "]", "*", "(", "max_len", "-", "len", "(", "sent", ")", ")", "for", "sent", "in", "input_idxs", "]", "\n", "input_tensor", "=", "torch", ".", "tensor", "(", "input_idxs", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "sp_device", ")", "\n", "lens", "=", "torch", ".", "tensor", "(", "lens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "sp_device", ")", "\n", "self", ".", "qlm", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "logprob", "=", "self", ".", "qlm", ".", "sent_logprobability", "(", "input_tensor", ",", "lens", ")", ".", "cpu", "(", ")", "\n", "", "return", "logprob", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.reconstruction_reward": [[60, 71], ["models.model_utils.lens2mask", "torch.gather().squeeze", "masked_score.sum", "models.model_utils.lens2mask.float", "torch.gather", "references.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask"], ["", "def", "reconstruction_reward", "(", "self", ",", "logscores", ",", "references", ",", "lens", ")", ":", "\n", "        ", "\"\"\"\n            logscores: bsize x max_out_len x vocab_size[ + MAX_OOV_NUM]\n            references: bsize x max_out_len\n            lens: len for each sample\n        \"\"\"", "\n", "mask", "=", "lens2mask", "(", "lens", ")", "\n", "pick_score", "=", "torch", ".", "gather", "(", "logscores", ",", "dim", "=", "-", "1", ",", "index", "=", "references", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "masked_score", "=", "mask", ".", "float", "(", ")", "*", "pick_score", "\n", "reward", "=", "masked_score", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.reward.RewardModel.__call__": [[72, 74], ["reward.RewardModel.forward"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.forward"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "*", "args", ",", "**", "kargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.__init__": [[10, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "src_embed", ",", "encoder", ",", "tgt_embed", ",", "decoder", ",", "enc2dec", ",", "generator", ")", ":", "\n", "        ", "\"\"\"\n            All the arguments are of type nn.Module\n        \"\"\"", "\n", "super", "(", "EncoderDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_embed", "=", "src_embed", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "enc2dec", "=", "enc2dec", "\n", "self", ".", "tgt_embed", "=", "tgt_embed", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "generator", "=", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.forward": [[22, 24], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_batch": [[25, 27], ["None"], "methods", ["None"], ["", "def", "decode_batch", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_greed": [[28, 30], ["None"], "methods", ["None"], ["", "def", "decode_greed", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.decode_beam_search": [[31, 33], ["None"], "methods", ["None"], ["", "def", "decode_beam_search", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.pad_embedding_grad_zero": [[34, 37], ["encoder_decoder.EncoderDecoder.src_embed.pad_embedding_grad_zero", "encoder_decoder.EncoderDecoder.tgt_embed.pad_embedding_grad_zero"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero"], ["", "def", "pad_embedding_grad_zero", "(", "self", ")", ":", "\n", "        ", "self", ".", "src_embed", ".", "pad_embedding_grad_zero", "(", ")", "\n", "self", ".", "tgt_embed", ".", "pad_embedding_grad_zero", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.load_model": [[38, 40], ["encoder_decoder.EncoderDecoder.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "open"], "methods", ["None"], ["", "def", "load_model", "(", "self", ",", "load_dir", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "open", "(", "load_dir", ",", "'rb'", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.encoder_decoder.EncoderDecoder.save_model": [[41, 43], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "encoder_decoder.EncoderDecoder.state_dict", "open"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "open", "(", "save_dir", ",", "'wb'", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.__init__": [[12, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "length_pen", "=", "length_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_penalty": [[15, 22], ["None"], "methods", ["None"], ["", "def", "length_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "self", ".", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_wu": [[27, 36], ["len"], "methods", ["None"], ["def", "length_wu", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT length re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "modifier", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "next_ys", ")", ")", "**", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "modifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_average": [[37, 42], ["len"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns the average probability of tokens in a sequence.\n        \"\"\"", "\n", "return", "logprobs", "/", "len", "(", "beam", ".", "next_ys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_none": [[43, 48], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns unmodified scores.\n        \"\"\"", "\n", "return", "logprobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.__init__": [[14, 40], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "torch.Embedding", "cell.upper", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "list", "getattr", "language_model.LanguageModel.parameters", "p.data.uniform_", "language_model.LanguageModel.encoder.weight.data[].zero_"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["from", "utils", ".", "hyperparam", "import", "hyperparam_lm", "\n", "from", "models", ".", "language_model", "import", "LanguageModel", "as", "model", "\n", "\n", "############################### Arguments parsing and Preparations ##############################", "\n", "\n", "def", "main", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task'", ",", "type", "=", "str", ",", "default", "=", "'language_model'", ",", "help", "=", "'language model'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "required", "=", "True", ",", "help", "=", "'which dataset to experiemnt on'", ")", "\n", "parser", ".", "add_argument", "(", "'--side'", ",", "choices", "=", "[", "'question'", ",", "'logical_form'", "]", ",", "help", "=", "'which side to build language model'", ")", "\n", "# pretrained models", "\n", "parser", ".", "add_argument", "(", "'--read_model_path'", ",", "required", "=", "False", ",", "help", "=", "'Read model and hyperparams from this path'", ")", "\n", "# model paras", "\n", "parser", ".", "add_argument", "(", "'--emb_size'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'embedding size'", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'hidden layer dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of hidden layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--cell'", ",", "default", "=", "'lstm'", ",", "choices", "=", "[", "'lstm'", ",", "'gru'", "]", ",", "help", "=", "'rnn cell choice'", ")", "\n", "# training paras", "\n", "parser", ".", "add_argument", "(", "'--reduction'", ",", "default", "=", "'sum'", ",", "choices", "=", "[", "'mean'", ",", "'sum'", "]", ",", "help", "=", "'loss function argument'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'weight decay (L2 penalty)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'dropout rate at each non-recurrent layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_weight'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'all weights will be set to [-init_weight, init_weight] during initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.pad_embedding_grad_zero": [[41, 44], ["language_model.LanguageModel.encoder.weight.grad[].zero_"], "methods", ["None"], ["parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "# special paras", "\n", "parser", ".", "add_argument", "(", "'--decoder_tied'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether use the same embedding weights and output matrix'", ")", "\n", "parser", ".", "add_argument", "(", "'--labeled'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'training use only this propotion of dataset'", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.forward": [[45, 52], ["language_model.LanguageModel.dropout_layer", "models.model_utils.rnn_wrapper", "language_model.LanguageModel.decoder", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "language_model.LanguageModel.encoder", "language_model.LanguageModel.affine", "language_model.LanguageModel.dropout_layer"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.rnn_wrapper"], ["parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'train model on ith gpu. -1:cpu'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", "args", ")", "\n", "if", "opt", ".", "testing", ":", "\n", "        ", "assert", "opt", ".", "read_model_path", "\n", "", "return", "opt", "\n", "\n", "", "opt", "=", "main", "(", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.sent_logprobability": [[53, 68], ["language_model.LanguageModel.dropout_layer", "models.model_utils.rnn_wrapper", "language_model.LanguageModel.decoder", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.gather().contiguous().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "language_model.LanguageModel.encoder", "language_model.LanguageModel.affine", "output.size", "output.size", "lens.float", "language_model.LanguageModel.dropout_layer", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "torch.gather().contiguous", "models.model_utils.lens2mask().float", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "models.model_utils.lens2mask", "output_feats.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.rnn_wrapper", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask"], ["\n", "####################### Output path, logger, device and random seed configuration #################", "\n", "\n", "exp_path", "=", "opt", ".", "read_model_path", "if", "opt", ".", "testing", "else", "hyperparam_lm", "(", "opt", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "exp_path", ")", "\n", "\n", "", "logger", "=", "set_logger", "(", "exp_path", ",", "testing", "=", "opt", ".", "testing", ")", "\n", "logger", ".", "info", "(", "\"Parameters: \"", "+", "str", "(", "json", ".", "dumps", "(", "vars", "(", "opt", ")", ",", "indent", "=", "4", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Experiment path: %s\"", "%", "(", "exp_path", ")", ")", "\n", "opt", ".", "device", "=", "set_torch_device", "(", "opt", ".", "deviceId", ")", "\n", "set_random_seed", "(", "opt", ".", "seed", ",", "device", "=", "opt", ".", "device", ".", "type", ")", "\n", "\n", "################################ Vocab and Data Reader ###########################", "\n", "\n", "lm_vocab", "=", "Vocab", "(", "opt", ".", "dataset", ",", "task", "=", "'language_model'", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.load_model": [[69, 71], ["language_model.LanguageModel.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "open"], "methods", ["None"], ["if", "opt", ".", "side", "==", "'question'", ":", "\n", "    ", "word2id", "=", "lm_vocab", ".", "word2id", "\n", "logger", ".", "info", "(", "\"Vocab size for natural language sentence is: %s\"", "%", "(", "len", "(", "word2id", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.language_model.LanguageModel.save_model": [[72, 74], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "language_model.LanguageModel.state_dict", "open"], "methods", ["None"], ["", "else", ":", "\n", "    ", "word2id", "=", "lm_vocab", ".", "lf2id", "\n", "logger", ".", "info", "(", "\"Vocab size for logical form is: %s\"", "%", "(", "len", "(", "word2id", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.__init__": [[18, 49], ["torch.zeros", "torch.zeros().fill_", "torch.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "vocab", ",", "min_length", "=", "2", ",", "\n", "global_scorer", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "device", "=", "device", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "torch", ".", "zeros", "(", "size", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "torch", ".", "zeros", "(", "size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", ".", "fill_", "(", "vocab", "[", "PAD", "]", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "vocab", "[", "BOS", "]", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "vocab", "[", "EOS", "]", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# Other special symbols", "\n", "self", ".", "_bos", "=", "vocab", "[", "BOS", "]", "\n", "self", ".", "_pad", "=", "vocab", "[", "PAD", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.get_current_state": [[50, 53], ["None"], "methods", ["None"], ["", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.get_current_origin": [[54, 57], ["None"], "methods", ["None"], ["", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.advance": [[58, 111], ["word_probs.size", "len", "torch.zeros", "beam_scores.contiguous().view", "beam_scores.contiguous().view.topk", "Beam.Beam.prev_ks.append", "Beam.Beam.next_ys.append", "range", "Beam.Beam.done", "word_probs.size", "len", "torch.zeros", "range", "Beam.Beam.next_ys[].size", "Beam.Beam.scores.unsqueeze", "beam_scores.size", "Beam.Beam.next_ys[].size", "beam_scores.contiguous", "Beam.Beam.global_scorer.score", "Beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.done", "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.GNMTGlobalScorer.score"], ["", "def", "advance", "(", "self", ",", "word_probs", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `K x vocab` and update the beam.\n\n        Parameters:\n\n        * `word_probs`- probs of advancing from the last step (K x words)\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "# force the output to be longer than self.min_length", "\n", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "masks", "=", "torch", ".", "zeros", "(", "word_probs", ".", "size", "(", ")", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "masks", "[", ":", ",", "self", ".", "_bos", "]", "=", "1e20", "\n", "masks", "[", ":", ",", "self", ".", "_pad", "]", "=", "1e20", "# prevent generate <s> <pad> symbol", "\n", "if", "cur_len", "<", "self", ".", "min_length", ":", "\n", "            ", "masks", "[", ":", ",", "self", ".", "_eos", "]", "=", "1e20", "# prevent terminate too early", "\n", "", "word_probs", "=", "word_probs", "-", "masks", "\n", "\n", "# Sum the previous scores.", "\n", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", "\n", "# Don't let EOS have children.", "\n", "masks", "=", "torch", ".", "zeros", "(", "beam_scores", ".", "size", "(", ")", ",", "requires_grad", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "self", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "masks", "[", "i", "]", "=", "1e20", "\n", "", "", "beam_scores", "=", "beam_scores", "-", "masks", "\n", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "# only start from <s>, not <pad>", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "True", ",", "True", ")", "\n", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "\n", "# check whether some sequence has terminated", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "# normalize score by length penalty", "\n", "rank_s", ",", "s", "=", "global_scores", "[", "i", "]", ",", "self", ".", "scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "[", "rank_s", ",", "s", "]", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "eos_top", "=", "True", "\n", "", "return", "self", ".", "done", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.done": [[112, 114], ["len"], "methods", ["None"], ["", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.sort_best": [[115, 120], ["torch.sort"], "methods", ["None"], ["", "def", "sort_best", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            Sort the current beam.\n        \"\"\"", "\n", "return", "torch", ".", "sort", "(", "self", ".", "scores", ",", "0", ",", "True", ")", "# beam size", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.sort_finished": [[121, 135], ["Beam.Beam.finished.sort", "len", "Beam.Beam.global_scorer.score", "Beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.GNMTGlobalScorer.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "rank_s", ",", "s", "=", "global_scores", "[", "i", "]", ",", "self", ".", "scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "[", "rank_s", ",", "s", "]", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "[", "1", "]", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.get_temporary_hyp": [[136, 145], ["range", "torch.stack", "hyp.append", "len"], "methods", ["None"], ["", "def", "get_temporary_hyp", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n            Get current hypotheses of rank k ( 0 <= rank <= beam_size-1 ). \n        \"\"\"", "\n", "hyp", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "torch", ".", "stack", "(", "hyp", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.Beam.get_hyp": [[146, 158], ["range", "torch.stack", "hyp.append", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\" \n            Walk back to construct the full hypothesis. \n            hyp contains </s> but does not contain <s>\n            @return:\n                hyp: LongTensor of size tgt_len\n        \"\"\"", "\n", "hyp", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "torch", ".", "stack", "(", "hyp", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.GNMTGlobalScorer.__init__": [[168, 173], ["models.penalties.PenaltyBuilder", "models.penalties.PenaltyBuilder.length_penalty"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_penalty"], ["def", "__init__", "(", "self", ",", "alpha", ",", "len_penalty", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "len_penalty", ")", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.Beam.GNMTGlobalScorer.score": [[174, 180], ["Beam.GNMTGlobalScorer.length_penalty"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.penalties.PenaltyBuilder.length_penalty"], ["", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Rescores a prediction based on penalty functions\n        \"\"\"", "\n", "normalized_probs", "=", "self", ".", "length_penalty", "(", "beam", ",", "logprobs", ",", "self", ".", "alpha", ")", "\n", "return", "normalized_probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attnptr.AttnPtrModel.__init__": [[7, 10], ["models.model_attn.AttnModel.__init__"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kargs", ")", ":", "\n", "        ", "super", "(", "AttnPtrModel", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kargs", ")", "\n", "self", ".", "copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attnptr.AttnPtrModel.forward": [[11, 21], ["model_attnptr.AttnPtrModel.encoder", "model_attnptr.AttnPtrModel.enc2dec", "models.model_utils.lens2mask", "model_attnptr.AttnPtrModel.decoder", "model_attnptr.AttnPtrModel.generator", "model_attnptr.AttnPtrModel.src_embed", "model_attnptr.AttnPtrModel.tgt_embed"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.lens2mask"], ["", "def", "forward", "(", "self", ",", "src_inputs", ",", "src_lens", ",", "tgt_inputs", ",", "copy_tokens", ")", ":", "\n", "        ", "\"\"\"\n            Used during training time.\n        \"\"\"", "\n", "enc_out", ",", "hidden_states", "=", "self", ".", "encoder", "(", "self", ".", "src_embed", "(", "src_inputs", ")", ",", "src_lens", ")", "\n", "hidden_states", "=", "self", ".", "enc2dec", "(", "hidden_states", ")", "\n", "src_mask", "=", "lens2mask", "(", "src_lens", ")", "\n", "dec_out", ",", "_", ",", "copy_dist", ",", "gates", "=", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "tgt_inputs", ")", ",", "hidden_states", ",", "enc_out", ",", "src_mask", ",", "copy_tokens", ")", "\n", "out", "=", "self", ".", "generator", "(", "dec_out", ",", "copy_dist", ",", "gates", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_attnptr.AttnPtrModel.decode_one_step": [[22, 26], ["model_attnptr.AttnPtrModel.decoder", "model_attnptr.AttnPtrModel.generator().squeeze", "model_attnptr.AttnPtrModel.tgt_embed", "model_attnptr.AttnPtrModel.generator"], "methods", ["None"], ["", "def", "decode_one_step", "(", "self", ",", "ys", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", ")", ":", "\n", "        ", "dec_out", ",", "hidden_states", ",", "copy_dist", ",", "gates", "=", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "ys", ")", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", ")", "\n", "out", "=", "self", ".", "generator", "(", "dec_out", ",", "copy_dist", ",", "gates", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "return", "out", ",", "hidden_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.encoder.encoder_rnn.RNNEncoder.__init__": [[10, 21], ["torch.Module.__init__", "cell.upper", "getattr"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "src_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "cell", "=", "\"lstm\"", ",", "bidirectional", "=", "True", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_emb_size", "=", "src_emb_size", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "dropout", "=", "dropout", "if", "self", ".", "num_layers", ">", "1", "else", "0", "\n", "self", ".", "cell", "=", "cell", ".", "upper", "(", ")", "\n", "self", ".", "rnn_encoder", "=", "getattr", "(", "nn", ",", "self", ".", "cell", ")", "(", "self", ".", "src_emb_size", ",", "self", ".", "hidden_dim", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "bidirectional", "=", "self", ".", "bidirectional", ",", "\n", "batch_first", "=", "True", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.encoder.encoder_rnn.RNNEncoder.forward": [[22, 28], ["models.model_utils.rnn_wrapper"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.models.model_utils.rnn_wrapper"], ["", "def", "forward", "(", "self", ",", "x", ",", "lens", ")", ":", "\n", "        ", "\"\"\"\n            Pass the x and lens through each RNN layer.\n        \"\"\"", "\n", "out", ",", "hidden_states", "=", "rnn_wrapper", "(", "self", ".", "rnn_encoder", ",", "x", ",", "lens", ",", "cell", "=", "self", ".", "cell", ")", "# bsize x srclen x dim", "\n", "return", "out", ",", "hidden_states", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.__init__": [[6, 14], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "emb_size", ",", "vocab", ",", "unk_idx", "=", "1", ",", "pad_token_idxs", "=", "[", "0", "]", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RNNEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "vocab", ",", "emb_size", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "pad_token_idxs", "=", "pad_token_idxs", "\n", "self", ".", "unk_idx", "=", "unk_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.forward": [[15, 20], ["token_mask.any", "embedding_rnn.RNNEmbeddings.dropout_layer", "x.masked_fill_.masked_fill_.masked_fill_", "embedding_rnn.RNNEmbeddings.embed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "token_mask", "=", "x", ">=", "self", ".", "vocab", "\n", "if", "token_mask", ".", "any", "(", ")", ":", "\n", "            ", "x", "=", "x", ".", "masked_fill_", "(", "token_mask", ",", "self", ".", "unk_idx", ")", "\n", "", "return", "self", ".", "dropout_layer", "(", "self", ".", "embed", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.embedding.embedding_rnn.RNNEmbeddings.pad_embedding_grad_zero": [[21, 24], ["embedding_rnn.RNNEmbeddings.embed.weight.grad[].zero_"], "methods", ["None"], ["", "def", "pad_embedding_grad_zero", "(", "self", ")", ":", "\n", "        ", "for", "pad_token_idx", "in", "self", ".", "pad_token_idxs", ":", "\n", "            ", "self", ".", "embed", ".", "weight", ".", "grad", "[", "pad_token_idx", "]", ".", "zero_", "(", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.decoder.decoder_rnn.RNNDecoder.__init__": [[9, 21], ["torch.Module.__init__", "cell.upper", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "getattr"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "tgt_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "attn", ",", "cell", "=", "\"lstm\"", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tgt_emb_size", "=", "tgt_emb_size", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "if", "self", ".", "num_layers", ">", "1", "else", "0", "\n", "self", ".", "cell", "=", "cell", ".", "upper", "(", ")", "\n", "self", ".", "rnn_decoder", "=", "getattr", "(", "nn", ",", "self", ".", "cell", ")", "(", "self", ".", "tgt_emb_size", ",", "self", ".", "hidden_dim", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "affine", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", "+", "self", ".", "attn", ".", "enc_dim", ",", "self", ".", "tgt_emb_size", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.decoder.decoder_rnn.RNNDecoder.forward": [[22, 39], ["decoder_rnn.RNNDecoder.rnn_decoder", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_rnn.RNNDecoder.affine", "out.size", "decoder_rnn.RNNDecoder.attn", "torch.cat.append", "torch.cat.append", "decoder_rnn.RNNDecoder.dropout_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            x: decoder input embeddings, bsize x tgt_len x emb_size\n            hidden_states: previous decoder state\n            memory: encoder output, bsize x src_len x hidden_dim*2\n            src_mask: bsize x src_lens\n            copy_tokens: to be compatible with pointer network\n        \"\"\"", "\n", "out", ",", "hidden_states", "=", "self", ".", "rnn_decoder", "(", "x", ",", "hidden_states", ")", "\n", "context", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "out", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "tmp_context", ",", "_", "=", "self", ".", "attn", "(", "memory", ",", "out", "[", ":", ",", "i", ",", ":", "]", ",", "src_mask", ")", "\n", "context", ".", "append", "(", "tmp_context", ")", "\n", "", "context", "=", "torch", ".", "cat", "(", "context", ",", "dim", "=", "1", ")", "\n", "feats", "=", "torch", ".", "cat", "(", "[", "out", ",", "context", "]", ",", "dim", "=", "-", "1", ")", "\n", "feats", "=", "self", ".", "affine", "(", "self", ".", "dropout_layer", "(", "feats", ")", ")", "\n", "return", "feats", ",", "hidden_states", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.decoder.decoder_rnn_pointer.RNNDecoderPointer.__init__": [[9, 22], ["torch.Module.__init__", "cell.upper", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "getattr"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "tgt_emb_size", ",", "hidden_dim", ",", "num_layers", ",", "attn", ",", "cell", "=", "\"lstm\"", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "RNNDecoderPointer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "tgt_emb_size", "=", "tgt_emb_size", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "if", "self", ".", "num_layers", ">", "1", "else", "0", "\n", "self", ".", "cell", "=", "cell", ".", "upper", "(", ")", "\n", "self", ".", "rnn_decoder", "=", "getattr", "(", "nn", ",", "self", ".", "cell", ")", "(", "self", ".", "tgt_emb_size", ",", "self", ".", "hidden_dim", ",", "\n", "num_layers", "=", "self", ".", "num_layers", ",", "bidirectional", "=", "False", ",", "batch_first", "=", "True", ",", "dropout", "=", "self", ".", "dropout", ")", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", "+", "self", ".", "attn", ".", "enc_dim", "+", "self", ".", "tgt_emb_size", ",", "1", ")", "\n", "self", ".", "affine", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", "+", "self", ".", "attn", ".", "enc_dim", ",", "self", ".", "tgt_emb_size", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.decoder.decoder_rnn_pointer.RNNDecoderPointer.forward": [[23, 47], ["decoder_rnn_pointer.RNNDecoderPointer.rnn_decoder", "range", "decoder_rnn_pointer.RNNDecoderPointer.dropout_layer", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "decoder_rnn_pointer.RNNDecoderPointer.affine", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.size", "decoder_rnn_pointer.RNNDecoderPointer.attn", "context.append", "pointer.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_rnn_pointer.RNNDecoderPointer.gate", "tmp_ptr.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hidden_states", ",", "memory", ",", "src_mask", ",", "copy_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            x: decoder input embeddings, bsize x tgt_len x emb_size\n            hidden_states: previous decoder state\n            memory: memory and hidden_states\n            src_mask: mask on src input, bsize x src_lens\n            copy_tokens: bsize x src_lens x vocab_size\n            @return:\n                feats: bsize x tgt_lens x (dec_dim + enc_dim)\n                copy_distribution: bsize x tgt_lens x (vocab_size + MAX_OOV_NUM)\n                gate_scores: bsize x tgt_lens x 1\n        \"\"\"", "\n", "out", ",", "hidden_states", "=", "self", ".", "rnn_decoder", "(", "x", ",", "hidden_states", ")", "\n", "context", ",", "pointer", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "out", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "tmp_context", ",", "tmp_ptr", "=", "self", ".", "attn", "(", "memory", ",", "out", "[", ":", ",", "i", ",", ":", "]", ",", "src_mask", ")", "\n", "context", ".", "append", "(", "tmp_context", ")", "\n", "pointer", ".", "append", "(", "tmp_ptr", ".", "unsqueeze", "(", "dim", "=", "1", ")", ")", "\n", "", "context", ",", "pointer", "=", "torch", ".", "cat", "(", "context", ",", "dim", "=", "1", ")", ",", "torch", ".", "cat", "(", "pointer", ",", "dim", "=", "1", ")", "\n", "feats", "=", "self", ".", "dropout_layer", "(", "torch", ".", "cat", "(", "[", "out", ",", "context", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "gate_scores", "=", "torch", ".", "sigmoid", "(", "self", ".", "gate", "(", "torch", ".", "cat", "(", "[", "feats", ",", "x", "]", ",", "dim", "=", "-", "1", ")", ")", ")", "\n", "feats", "=", "self", ".", "affine", "(", "feats", ")", "\n", "copy_distribution", "=", "torch", ".", "bmm", "(", "pointer", ",", "copy_tokens", ")", "\n", "return", "feats", ",", "hidden_states", ",", "copy_distribution", ",", "gate_scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.generator.generator_naive.Generator.__init__": [[10, 14], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "feats", ",", "vocab", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "feats", ",", "vocab", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.generator.generator_naive.Generator.forward": [[15, 17], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "generator_naive.Generator.proj", "generator_naive.Generator.dropout_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "self", ".", "proj", "(", "self", ".", "dropout_layer", "(", "x", ")", ")", ",", "dim", "=", "-", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.generator.generator_pointer.GeneratorPointer.__init__": [[11, 15], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "feats", ",", "vocab", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "super", "(", "GeneratorPointer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "feats", ",", "vocab", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.generator.generator_pointer.GeneratorPointer.forward": [[16, 27], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "generator_pointer.GeneratorPointer.proj", "x.size", "x.size", "generator_pointer.GeneratorPointer.dropout_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "copy_distribution", ",", "gate_scores", ")", ":", "\n", "        ", "\"\"\"\n            x: bsize x tgt_lens x (dec_dim + enc_dim)\n            copy_distribution: bsize x tgt_lens x (vocab_size + MAX_OOV_NUM)\n            gate_scores: bsize x tgt_lens x 1\n        \"\"\"", "\n", "out", "=", "F", ".", "softmax", "(", "self", ".", "proj", "(", "self", ".", "dropout_layer", "(", "x", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "extra_zeros", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "MAX_OOV_NUM", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "x", ".", "device", ")", "\n", "generate_distribution", "=", "torch", ".", "cat", "(", "[", "out", ",", "extra_zeros", "]", ",", "dim", "=", "-", "1", ")", "\n", "final_scores", "=", "torch", ".", "log", "(", "gate_scores", "*", "generate_distribution", "+", "(", "1", "-", "gate_scores", ")", "*", "copy_distribution", "+", "1e-20", ")", "\n", "return", "final_scores", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.attention.attention_rnn.Attention.__init__": [[9, 20], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "enc_dim", ",", "dec_dim", ",", "method", "=", "'feedforward'", ")", ":", "\n", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "enc_dim", ",", "self", ".", "dec_dim", "=", "enc_dim", ",", "dec_dim", "\n", "assert", "method", "in", "Attention", ".", "METHODS", "\n", "self", ".", "method", "=", "method", "\n", "if", "self", ".", "method", "==", "'general'", ":", "\n", "            ", "self", ".", "Wa", "=", "nn", ".", "Linear", "(", "self", ".", "enc_dim", ",", "self", ".", "dec_dim", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "Wa", "=", "nn", ".", "Linear", "(", "self", ".", "enc_dim", "+", "self", ".", "dec_dim", ",", "self", ".", "dec_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Va", "=", "nn", ".", "Linear", "(", "self", ".", "dec_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.attention.attention_rnn.Attention.forward": [[21, 41], ["attention_rnn.Attention.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "attention_rnn.Attention.Wa", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "decoder_state.unsqueeze().repeat", "attention_rnn.Attention.Wa", "attention_rnn.Attention.Va().squeeze", "torch.softmax.unsqueeze", "hiddens.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "float", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "decoder_state.unsqueeze", "attention_rnn.Attention.Va", "decoder_state.unsqueeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hiddens", ",", "decoder_state", ",", "masks", ")", ":", "\n", "        ", "'''\n            hiddens : bsize x src_lens x enc_dim\n            decoder_state : bsize x dec_dim\n            masks : bsize x src_lens, ByteTensor\n            @return: \n                context : bsize x 1 x enc_dim\n                a : normalized coefficient, bsize x src_lens\n        '''", "\n", "if", "self", ".", "method", "==", "'general'", ":", "\n", "            ", "m", "=", "self", ".", "Wa", "(", "hiddens", ")", "# bsize x src_len x dec_dim", "\n", "e", "=", "torch", ".", "bmm", "(", "m", ",", "decoder_state", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "# bsize x src_len", "\n", "", "else", ":", "\n", "            ", "d", "=", "decoder_state", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "repeat", "(", "1", ",", "hiddens", ".", "size", "(", "1", ")", ",", "1", ")", "\n", "e", "=", "self", ".", "Wa", "(", "torch", ".", "cat", "(", "[", "d", ",", "hiddens", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "e", "=", "self", ".", "Va", "(", "torch", ".", "tanh", "(", "e", ")", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "", "e", ".", "masked_fill_", "(", "masks", "==", "0", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "a", "=", "F", ".", "softmax", "(", "e", ",", "dim", "=", "1", ")", "\n", "context", "=", "torch", ".", "bmm", "(", "a", ".", "unsqueeze", "(", "1", ")", ",", "hiddens", ")", "\n", "return", "context", ",", "a", "", "", "", ""]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__": [[9, 24], ["torch.Module.__init__", "cell.upper", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "cell", "=", "'lstm'", ",", "bidirectional", "=", "True", ",", "hidden_dim", "=", "None", ",", "method", "=", "'empty'", ")", ":", "\n", "        ", "\"\"\"\n            Transform encoder final hidden states to decoder initial hidden states\n        \"\"\"", "\n", "super", "(", "StateTransition", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cell", "=", "cell", ".", "upper", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "method", "in", "StateTransition", ".", "METHODS", "\n", "self", ".", "method", "=", "method", "\n", "if", "'affine'", "in", "self", ".", "method", ":", "\n", "            ", "assert", "hidden_dim", "\n", "self", ".", "h_affine", "=", "nn", ".", "Linear", "(", "hidden_dim", "*", "self", ".", "num_directions", ",", "hidden_dim", ")", "\n", "if", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "                ", "self", ".", "c_affine", "=", "nn", ".", "Linear", "(", "hidden_dim", "*", "self", ".", "num_directions", ",", "hidden_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rhythmcao_semantic-parsing-dual.enc2dec.state_transition.StateTransition.forward": [[25, 70], ["enc_h.new_zeros", "enc_c.new_zeros", "enc_h.new_zeros", "enc_h.size", "enc_h.size", "enc_c.size", "enc_c.size", "enc_h.size", "enc_h.size", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "enc_h.size", "state_transition.StateTransition.h_affine", "state_transition.StateTransition.c_affine", "torch.tanh.contiguous().view().transpose().contiguous", "torch.tanh.contiguous().view().transpose().contiguous", "torch.index_select.contiguous().view().transpose().contiguous", "torch.index_select.contiguous().view().transpose().contiguous", "state_transition.StateTransition.h_affine", "torch.tanh.contiguous().view().transpose().contiguous", "torch.tanh.contiguous().view().transpose().contiguous", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.tanh.contiguous", "torch.tanh.contiguous", "enc_h.transpose().contiguous().view", "enc_c.transpose().contiguous().view", "torch.tanh.contiguous.size", "enc_h.transpose().contiguous().view", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "range", "torch.tanh.contiguous", "torch.tanh.contiguous", "torch.index_select.contiguous", "torch.index_select.contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.contiguous().view().transpose", "torch.tanh.contiguous().view().transpose", "torch.index_select.contiguous().view().transpose", "torch.index_select.contiguous().view().transpose", "torch.tanh.contiguous().view().transpose", "torch.tanh.contiguous().view().transpose", "enc_h.transpose().contiguous", "enc_c.transpose().contiguous", "enc_h.transpose().contiguous", "torch.tanh.contiguous().view", "torch.tanh.contiguous().view", "torch.index_select.contiguous().view", "torch.index_select.contiguous().view", "torch.tanh.contiguous().view", "torch.tanh.contiguous().view", "enc_h.transpose", "enc_c.transpose", "enc_h.transpose", "torch.tanh.contiguous", "torch.tanh.contiguous", "torch.index_select.contiguous", "torch.index_select.contiguous", "torch.tanh.contiguous", "torch.tanh.contiguous"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "if", "self", ".", "method", "==", "'empty'", ":", "\n", "            ", "if", "'LSTM'", "in", "self", ".", "cell", ":", "\n", "                ", "enc_h", ",", "enc_c", "=", "hidden_states", "\n", "dec_h", "=", "enc_h", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "enc_h", ".", "size", "(", "1", ")", ",", "enc_h", ".", "size", "(", "2", ")", ")", "\n", "dec_c", "=", "enc_c", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "enc_c", ".", "size", "(", "1", ")", ",", "enc_c", ".", "size", "(", "2", ")", ")", "\n", "hidden_states", "=", "(", "dec_h", ",", "dec_c", ")", "\n", "", "else", ":", "\n", "                ", "enc_h", "=", "hidden_states", "\n", "dec_h", "=", "enc_h", ".", "new_zeros", "(", "self", ".", "num_layers", ",", "enc_h", ".", "size", "(", "1", ")", ",", "enc_h", ".", "size", "(", "2", ")", ")", "\n", "hidden_states", "=", "dec_h", "\n", "", "", "elif", "self", ".", "method", "==", "'reverse'", ":", "\n", "            ", "if", "self", ".", "num_directions", "==", "2", ":", "\n", "                ", "index_slices", "=", "[", "2", "*", "i", "+", "1", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", "]", "# from reversed path", "\n", "index_slices", "=", "torch", ".", "tensor", "(", "index_slices", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", "[", "0", "]", ".", "device", ")", "\n", "if", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "                    ", "enc_h", ",", "enc_c", "=", "hidden_states", "\n", "dec_h", "=", "torch", ".", "index_select", "(", "enc_h", ",", "0", ",", "index_slices", ")", "\n", "dec_c", "=", "torch", ".", "index_select", "(", "enc_c", ",", "0", ",", "index_slices", ")", "\n", "hidden_states", "=", "(", "dec_h", ".", "contiguous", "(", ")", ",", "dec_c", ".", "contiguous", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "enc_h", "=", "hidden_states", "\n", "dec_h", "=", "torch", ".", "index_select", "(", "enc_h", ",", "0", ",", "index_slices", ")", "\n", "hidden_states", "=", "dec_h", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "pass", "# do nothing, pass states directly", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "cell", "==", "'LSTM'", ":", "\n", "                ", "enc_h", ",", "enc_c", "=", "hidden_states", "\n", "batches", "=", "enc_h", ".", "size", "(", "1", ")", "\n", "dec_h", "=", "self", ".", "h_affine", "(", "enc_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batches", "*", "self", ".", "num_layers", ",", "-", "1", ")", ")", "\n", "dec_c", "=", "self", ".", "c_affine", "(", "enc_c", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batches", "*", "self", ".", "num_layers", ",", "-", "1", ")", ")", "\n", "if", "\"tanh\"", "in", "self", ".", "method", ":", "\n", "                    ", "dec_h", ",", "dec_c", "=", "torch", ".", "tanh", "(", "dec_h", ")", ",", "torch", ".", "tanh", "(", "dec_c", ")", "\n", "", "dec_h", "=", "dec_h", ".", "contiguous", "(", ")", ".", "view", "(", "batches", ",", "self", ".", "num_layers", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "dec_c", "=", "dec_c", ".", "contiguous", "(", ")", ".", "view", "(", "batches", ",", "self", ".", "num_layers", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "hidden_states", "=", "(", "dec_h", ",", "dec_c", ")", "\n", "", "else", ":", "\n", "                ", "enc_h", ",", "batches", "=", "hidden_states", ",", "hidden_states", ".", "size", "(", "1", ")", "\n", "dec_h", "=", "self", ".", "h_affine", "(", "enc_h", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batches", "*", "self", ".", "num_layers", ",", "-", "1", ")", ")", "\n", "if", "\"tanh\"", "in", "self", ".", "method", ":", "\n", "                    ", "dec_h", "=", "torch", ".", "tanh", "(", "dec_h", ")", "\n", "", "dec_h", "=", "dec_h", ".", "contiguous", "(", ")", ".", "view", "(", "batches", ",", "self", ".", "num_layers", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "hidden_states", "=", "dec_h", "\n", "", "", "return", "hidden_states", "\n", "", "", ""]]}