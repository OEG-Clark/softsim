{"home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.AvastConv.__init__": [[53, 74], ["LowMemConv.LowMemConvBase.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "range", "AvastStyleConv.AvastConv.embd.parameters", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "AvastStyleConv.vec_bin_array", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.vec_bin_array"], ["    ", "def", "__init__", "(", "self", ",", "out_size", "=", "2", ",", "channels", "=", "48", ",", "window_size", "=", "32", ",", "stride", "=", "4", ")", ":", "\n", "        ", "super", "(", "AvastConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embd", "=", "nn", ".", "Embedding", "(", "257", ",", "embd_size", ",", "padding_idx", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "257", ")", ":", "\n", "            ", "self", ".", "embd", ".", "weight", ".", "data", "[", "i", ",", ":", "]", "=", "torch", ".", "tensor", "(", "vec_bin_array", "(", "np", ".", "asarray", "(", "[", "i", "]", ")", ")", ")", "\n", "", "for", "param", "in", "self", ".", "embd", ".", "parameters", "(", ")", ":", "\n", "             ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "self", ".", "conv_1", "=", "nn", ".", "Conv1d", "(", "8", ",", "channels", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv_2", "=", "nn", ".", "Conv1d", "(", "channels", ",", "channels", "*", "2", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool1d", "(", "4", ")", "\n", "self", ".", "conv_3", "=", "nn", ".", "Conv1d", "(", "channels", "*", "2", ",", "channels", "*", "3", ",", "window_size", "//", "2", ",", "stride", "=", "stride", "*", "2", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv_4", "=", "nn", ".", "Conv1d", "(", "channels", "*", "3", ",", "channels", "*", "4", ",", "window_size", "//", "2", ",", "stride", "=", "stride", "*", "2", ",", "bias", "=", "True", ")", "\n", "\n", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "channels", "*", "4", ",", "channels", "*", "4", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "channels", "*", "4", ",", "channels", "*", "3", ")", "\n", "self", ".", "fc_3", "=", "nn", ".", "Linear", "(", "channels", "*", "3", ",", "channels", "*", "2", ")", "\n", "self", ".", "fc_4", "=", "nn", ".", "Linear", "(", "channels", "*", "2", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.AvastConv.processRange": [[76, 92], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "AvastStyleConv.AvastConv.pool", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "AvastStyleConv.AvastConv.embd", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "AvastStyleConv.AvastConv.conv_1", "AvastStyleConv.AvastConv.conv_2", "AvastStyleConv.AvastConv.conv_3", "AvastStyleConv.AvastConv.conv_4"], "methods", ["None"], ["", "def", "processRange", "(", "self", ",", "x", ")", ":", "\n", "#Fixed embedding", "\n", "#         cur_device = next(self.conv_1.parameters()).device", "\n", "#         x = torch.tensor(vec_bin_array(x.cpu().data.numpy()))", "\n", "#         print(\"chunk\")", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "x", "=", "self", ".", "embd", "(", "x", ")", "\n", "x", "=", "torch", ".", "transpose", "(", "x", ",", "-", "1", ",", "-", "2", ")", "\n", "\n", "", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_3", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv_4", "(", "x", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.AvastConv.forward": [[93, 102], ["AvastStyleConv.AvastConv.seq2fix", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "torch.selu", "AvastStyleConv.AvastConv.fc_4", "AvastStyleConv.AvastConv.fc_1", "AvastStyleConv.AvastConv.fc_2", "AvastStyleConv.AvastConv.fc_3"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "post_conv", "=", "x", "=", "self", ".", "seq2fix", "(", "x", ")", "\n", "\n", "x", "=", "F", ".", "selu", "(", "self", ".", "fc_1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "selu", "(", "self", ".", "fc_2", "(", "x", ")", ")", "\n", "penult", "=", "x", "=", "F", ".", "selu", "(", "self", ".", "fc_3", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc_4", "(", "x", ")", "\n", "\n", "return", "x", ",", "penult", ",", "post_conv", "", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.getParams": [[15, 24], ["collections.OrderedDict", "sorted", "params.items"], "function", ["None"], ["def", "getParams", "(", ")", ":", "\n", "#Format for this is to make it work easily with Optuna in an automated fashion.", "\n", "#variable name -> tuple(sampling function, dict(sampling_args) )", "\n", "    ", "params", "=", "{", "\n", "'channels'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'channels'", ",", "'low'", ":", "16", ",", "'high'", ":", "64", "}", ")", ",", "\n", "'stride'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'stride'", ",", "'low'", ":", "2", ",", "'high'", ":", "4", "}", ")", ",", "\n", "'window_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'window_size'", ",", "'low'", ":", "16", ",", "'high'", ":", "64", "}", ")", ",", "\n", "}", "\n", "return", "OrderedDict", "(", "sorted", "(", "params", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.initModel": [[25, 32], ["AvastStyleConv.getParams", "AvastStyleConv.AvastConv"], "function", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams"], ["", "def", "initModel", "(", "**", "kwargs", ")", ":", "\n", "    ", "new_args", "=", "{", "}", "\n", "for", "x", "in", "getParams", "(", ")", ":", "\n", "        ", "if", "x", "in", "kwargs", ":", "\n", "            ", "new_args", "[", "x", "]", "=", "kwargs", "[", "x", "]", "\n", "\n", "", "", "return", "AvastConv", "(", "**", "new_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.AvastStyleConv.vec_bin_array": [[33, 50], ["numpy.vectorize", "np.vectorize.", "numpy.zeros", "range", "numpy.vectorize", "np.vectorize.astype", "numpy.binary_repr().zfill", "list", "np.vectorize.", "numpy.binary_repr"], "function", ["None"], ["", "def", "vec_bin_array", "(", "arr", ",", "m", "=", "8", ")", ":", "\n", "    ", "\"\"\"\n    Arguments: \n    arr: Numpy array of positive integers\n    m: Number of bits of each integer to retain\n\n    Returns a copy of arr with every element replaced with a bit vector.\n    Bits encoded as int8's.\n    \"\"\"", "\n", "to_str_func", "=", "np", ".", "vectorize", "(", "lambda", "x", ":", "np", ".", "binary_repr", "(", "x", ")", ".", "zfill", "(", "m", ")", ")", "\n", "strs", "=", "to_str_func", "(", "arr", ")", "\n", "ret", "=", "np", ".", "zeros", "(", "list", "(", "arr", ".", "shape", ")", "+", "[", "m", "]", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "for", "bit_ix", "in", "range", "(", "0", ",", "m", ")", ":", "\n", "        ", "fetch_bit_func", "=", "np", ".", "vectorize", "(", "lambda", "x", ":", "x", "[", "bit_ix", "]", "==", "'1'", ")", "\n", "ret", "[", "...", ",", "bit_ix", "]", "=", "fetch_bit_func", "(", "strs", ")", ".", "astype", "(", "np", ".", "int8", ")", "\n", "\n", "", "return", "(", "ret", "*", "2", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "16", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvTrain.dir_path": [[31, 36], ["os.path.isdir", "NotADirectoryError"], "function", ["None"], ["def", "dir_path", "(", "string", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "string", ")", ":", "\n", "        ", "return", "string", "\n", "", "else", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.OptunaTrain.dir_path": [[31, 36], ["os.path.isdir", "NotADirectoryError"], "function", ["None"], ["def", "dir_path", "(", "string", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "string", ")", ":", "\n", "        ", "return", "string", "\n", "", "else", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.OptunaTrain.random_split": [[90, 108], ["torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "zip", "torch._utils._accumulate", "torch._utils._accumulate", "torch._utils._accumulate", "torch._utils._accumulate", "selected.sort", "to_ret.append", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.utils.data.Subset", "sum"], "function", ["None"], ["def", "random_split", "(", "dataset", ",", "lengths", ")", ":", "\n", "    ", "\"\"\"\n    Randomly split a dataset into non-overlapping new datasets of given lengths.\n\n    Arguments:\n        dataset (Dataset): Dataset to be split\n        lengths (sequence): lengths of splits to be produced\n    \"\"\"", "\n", "#if sum(lengths) != len(dataset):", "\n", "#    raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")", "\n", "\n", "indices", "=", "torch", ".", "randperm", "(", "sum", "(", "lengths", ")", ")", ".", "tolist", "(", ")", "\n", "to_ret", "=", "[", "]", "\n", "for", "offset", ",", "length", "in", "zip", "(", "torch", ".", "_utils", ".", "_accumulate", "(", "lengths", ")", ",", "lengths", ")", ":", "\n", "        ", "selected", "=", "indices", "[", "offset", "-", "length", ":", "offset", "]", "\n", "selected", ".", "sort", "(", ")", "\n", "to_ret", ".", "append", "(", "Subset", "(", "dataset", ",", "selected", ")", ")", "\n", "", "return", "to_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.OptunaTrain.objective": [[138, 310], ["collections.OrderedDict", "initModel().to", "os.path.join", "getParams().items", "trial.suggest_loguniform", "sorted", "torch.DataParallel", "os.path.exists", "os.makedirs", "open", "csv_log_out.write", "torch.CrossEntropyLoss", "torch.AdamW", "tqdm.tqdm", "collections.OrderedDict.items", "initModel", "len", "nn.DataParallel.parameters", "range", "nn.DataParallel.train", "tqdm.tqdm", "sklearn.metrics.roc_auc_score", "os.path.join", "collections.OrderedDict.copy", "optim.AdamW.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "nn.DataParallel.eval", "sklearn.metrics.roc_auc_score", "trial.report", "sklearn.metrics.roc_auc_score", "csv_log_out.write", "csv_log_out.flush", "trial.should_prune", "trial.set_user_attr", "getParams", "getattr", "labels.to.to", "optim.AdamW.zero_grad", "nn.DataParallel.", "nn.CrossEntropyLoss.", "criterion.backward", "optim.AdamW.step", "criterion.item", "torch.max", "torch.max", "torch.max", "torch.max", "labels.to.size", "nn.DataParallel.module.state_dict", "nn.DataParallel.state_dict", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "optuna.structs.TrialPruned", "str", "collections.OrderedDict.items", "nn.DataParallel.parameters", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "preds.extend", "truths.extend", "type", "nn.DataParallel.", "torch.max", "torch.max", "torch.max", "torch.max", "preds.extend", "truths.extend", "labels.to.size", "nn.DataParallel.", "torch.max", "torch.max", "torch.max", "torch.max", "preds.extend", "truths.extend", "labels.to.size", "p.data.clamp_", "torch.softmax().data[].detach().cpu().numpy().ravel", "labels.to.detach().cpu().numpy().ravel", "inputs.to", "labels.to.to", "torch.softmax().data[].detach().cpu().numpy().ravel", "labels.to.detach().cpu().numpy().ravel", "inputs.to", "labels.to.to", "torch.softmax().data[].detach().cpu().numpy().ravel", "labels.to.detach().cpu().numpy().ravel", "str", "torch.softmax().data[].detach().cpu().numpy", "labels.to.detach().cpu().numpy", "torch.softmax().data[].detach().cpu().numpy", "labels.to.detach().cpu().numpy", "torch.softmax().data[].detach().cpu().numpy", "labels.to.detach().cpu().numpy", "torch.softmax().data[].detach().cpu", "labels.to.detach().cpu", "torch.softmax().data[].detach().cpu", "labels.to.detach().cpu", "torch.softmax().data[].detach().cpu", "labels.to.detach().cpu", "torch.softmax().data[].detach", "labels.to.detach", "torch.softmax().data[].detach", "labels.to.detach", "torch.softmax().data[].detach", "labels.to.detach", "torch.softmax", "torch.softmax", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.initModel", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.checkpoint.CheckpointFunction.backward"], ["def", "objective", "(", "trial", ")", ":", "\n", "\n", "    ", "args_to_use", "=", "{", "\n", "'lr'", ":", "0.001", ",", "\n", "}", "\n", "\n", "if", "not", "trial", "is", "None", ":", "\n", "        ", "for", "param", ",", "(", "sample_func", ",", "sample_args", ")", "in", "getParams", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "args_to_use", "[", "param", "]", "=", "getattr", "(", "trial", ",", "sample_func", ")", "(", "**", "sample_args", ")", "\n", "", "args_to_use", "[", "'lr'", "]", "=", "trial", ".", "suggest_loguniform", "(", "'lr'", ",", "low", "=", "1e-4", ",", "high", "=", "1e-2", ")", "\n", "\n", "", "args_to_use", "=", "OrderedDict", "(", "sorted", "(", "args_to_use", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "\n", "model", "=", "initModel", "(", "**", "args_to_use", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "base_name", "=", "MODEL_NAME", "+", "\"_\"", ".", "join", "(", "[", "a", "+", "\"_\"", "+", "str", "(", "b", ")", "for", "(", "a", ",", "b", ")", "in", "args_to_use", ".", "items", "(", ")", "]", ")", "\n", "\n", "if", "NON_NEG", ":", "\n", "        ", "base_name", "=", "\"NonNeg_\"", "+", "base_name", "\n", "\n", "", "if", "GPUS", "is", "None", "or", "len", "(", "GPUS", ")", ">", "1", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "GPUS", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "base_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "base_name", ")", "\n", "", "file_name", "=", "os", ".", "path", ".", "join", "(", "base_name", ",", "base_name", ")", "\n", "\n", "\n", "headers", "=", "[", "'epoch'", ",", "'train_acc'", ",", "'train_auc'", ",", "'test_acc'", ",", "'test_auc'", ",", "'val_acc'", ",", "'val_auc'", "]", "\n", "\n", "#     csv_log_out = open(file_name + \".csv\", 'w')", "\n", "with", "open", "(", "file_name", "+", "\".csv\"", ",", "'w'", ")", "as", "csv_log_out", ":", "\n", "        ", "csv_log_out", ".", "write", "(", "\",\"", ".", "join", "(", "headers", ")", "+", "\"\\n\"", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args_to_use", "[", "'lr'", "]", ")", "\n", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "EPOCHS", ")", ")", ":", "\n", "\n", "            ", "preds", "=", "[", "]", "\n", "truths", "=", "[", "]", "\n", "running_loss", "=", "0.0", "\n", "\n", "\n", "train_correct", "=", "0", "\n", "train_total", "=", "0", "\n", "\n", "epoch_stats", "=", "{", "'epoch'", ":", "epoch", "}", "\n", "\n", "model", ".", "train", "(", ")", "\n", "for", "inputs", ",", "labels", "in", "tqdm", "(", "train_loader", ")", ":", "\n", "\n", "#inputs, labels = inputs.to(device), labels.to(device)", "\n", "#Keep inputs on CPU, the model will load chunks of input onto device as needed", "\n", "                ", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "#     outputs, penultimate_activ, conv_active = model.forward_extra(inputs)", "\n", "outputs", ",", "penult", ",", "post_conv", "=", "model", "(", "inputs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "loss", "=", "loss", "#+ decov_lambda*(decov_penalty(penultimate_activ) + decov_penalty(conv_active))", "\n", "#     loss = loss + decov_lambda*(decov_penalty(conv_active))", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "NON_NEG", ":", "\n", "                    ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                        ", "p", ".", "data", ".", "clamp_", "(", "0", ")", "\n", "\n", "\n", "", "", "running_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "preds", ".", "extend", "(", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", ".", "data", "[", ":", ",", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "truths", ".", "extend", "(", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "\n", "", "train_total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "train_correct", "+=", "(", "predicted", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "#end train loop", "\n", "\n", "#print(\"Training Accuracy: {}\".format(train_correct*100.0/train_total))", "\n", "\n", "", "epoch_stats", "[", "'train_acc'", "]", "=", "train_correct", "*", "1.0", "/", "train_total", "\n", "epoch_stats", "[", "'train_auc'", "]", "=", "roc_auc_score", "(", "truths", ",", "preds", ")", "\n", "#epoch_stats['train_loss'] = roc_auc_score(truths, preds)", "\n", "\n", "#Save the model and current state!", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "base_name", ",", "\"epoch_{}.checkpoint\"", ".", "format", "(", "epoch", ")", ")", "\n", "\n", "\n", "#Have to handle model state special if multi-gpu was used", "\n", "if", "type", "(", "model", ")", ".", "__name__", "is", "\"DataParallel\"", ":", "\n", "                ", "mstd", "=", "model", ".", "module", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "                ", "mstd", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "#Copy dict, and add extra info to save off ", "\n", "", "check_dict", "=", "args_to_use", ".", "copy", "(", ")", "\n", "check_dict", "[", "'epoch'", "]", "=", "epoch", "\n", "check_dict", "[", "'model_state_dict'", "]", "=", "mstd", "\n", "check_dict", "[", "'optimizer_state_dict'", "]", "=", "optimizer", ".", "state_dict", "(", ")", "\n", "check_dict", "[", "'non_neg'", "]", "=", "NON_NEG", "\n", "torch", ".", "save", "(", "check_dict", ",", "model_path", ")", "\n", "\n", "\n", "#Test Set Eval", "\n", "model", ".", "eval", "(", ")", "\n", "eval_train_correct", "=", "0", "\n", "eval_train_total", "=", "0", "\n", "\n", "preds", "=", "[", "]", "\n", "truths", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "inputs", ",", "labels", "in", "tqdm", "(", "test_loader", ")", ":", "\n", "\n", "                    ", "inputs", ",", "labels", "=", "inputs", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "\n", "outputs", ",", "_", ",", "_", "=", "model", "(", "inputs", ")", "\n", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "\n", "preds", ".", "extend", "(", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", ".", "data", "[", ":", ",", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "truths", ".", "extend", "(", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "\n", "eval_train_total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "eval_train_correct", "+=", "(", "predicted", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "epoch_stats", "[", "'test_acc'", "]", "=", "eval_train_correct", "*", "1.0", "/", "eval_train_total", "\n", "epoch_stats", "[", "'test_auc'", "]", "=", "roc_auc_score", "(", "truths", ",", "preds", ")", "\n", "\n", "#We've now done an epoch of training. Lets do a validation run to see what our current reuslts look like & report to Optuna", "\n", "eval_train_correct", "=", "0", "\n", "eval_train_total", "=", "0", "\n", "preds", "=", "[", "]", "\n", "truths", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "inputs", ",", "labels", "in", "val_loader", ":", "\n", "\n", "                    ", "inputs", ",", "labels", "=", "inputs", ".", "to", "(", "device", ")", ",", "labels", ".", "to", "(", "device", ")", "\n", "\n", "outputs", ",", "_", ",", "_", "=", "model", "(", "inputs", ")", "\n", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "outputs", ".", "data", ",", "1", ")", "\n", "\n", "preds", ".", "extend", "(", "F", ".", "softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", ".", "data", "[", ":", ",", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "truths", ".", "extend", "(", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "ravel", "(", ")", ")", "\n", "\n", "eval_train_total", "+=", "labels", ".", "size", "(", "0", ")", "\n", "eval_train_correct", "+=", "(", "predicted", "==", "labels", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "validation_error", "=", "1.0", "-", "eval_train_correct", "/", "eval_train_total", "\n", "trial", ".", "report", "(", "validation_error", ",", "epoch", ")", "\n", "\n", "epoch_stats", "[", "'val_acc'", "]", "=", "eval_train_correct", "*", "1.0", "/", "eval_train_total", "\n", "epoch_stats", "[", "'val_auc'", "]", "=", "roc_auc_score", "(", "truths", ",", "preds", ")", "\n", "\n", "csv_log_out", ".", "write", "(", "\",\"", ".", "join", "(", "[", "str", "(", "epoch_stats", "[", "h", "]", ")", "for", "h", "in", "headers", "]", ")", "+", "\"\\n\"", ")", "\n", "csv_log_out", ".", "flush", "(", ")", "\n", "\n", "# Handle pruning based on the intermediate value.", "\n", "if", "trial", ".", "should_prune", "(", ")", ":", "\n", "                ", "raise", "optuna", ".", "structs", ".", "TrialPruned", "(", ")", "\n", "\n", "#end for epoch loop", "\n", "", "", "for", "att", "in", "[", "'val_acc'", ",", "'val_auc'", ",", "'test_acc'", ",", "'test_auc'", "]", ":", "\n", "            ", "trial", ".", "set_user_attr", "(", "att", ",", "epoch_stats", "[", "att", "]", ")", "\n", "#end 'with csv' log", "\n", "", "", "return", "validation_error", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.BinaryDataset.__init__": [[31, 49], ["os.walk", "os.walk", "binaryLoader.BinaryDataset.all_files.sort", "os.path.join", "binaryLoader.BinaryDataset.all_files.append", "os.path.join", "binaryLoader.BinaryDataset.all_files.append", "os.path.getsize", "os.path.getsize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "good_dir", ",", "bad_dir", ",", "sort_by_size", "=", "False", ",", "max_len", "=", "4000000", ")", ":", "\n", "\n", "#Tuple (file_path, label, file_size)", "\n", "        ", "self", ".", "all_files", "=", "[", "]", "\n", "self", ".", "max_len", "=", "max_len", "\n", "\n", "for", "roor_dir", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "good_dir", ")", ":", "\n", "            ", "for", "file", "in", "files", ":", "\n", "                ", "to_add", "=", "os", ".", "path", ".", "join", "(", "roor_dir", ",", "file", ")", "\n", "self", ".", "all_files", ".", "append", "(", "(", "to_add", ",", "0", ",", "os", ".", "path", ".", "getsize", "(", "to_add", ")", ")", ")", "\n", "\n", "", "", "for", "roor_dir", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "bad_dir", ")", ":", "\n", "            ", "for", "file", "in", "files", ":", "\n", "                ", "to_add", "=", "os", ".", "path", ".", "join", "(", "roor_dir", ",", "file", ")", "\n", "self", ".", "all_files", ".", "append", "(", "(", "to_add", ",", "1", ",", "os", ".", "path", ".", "getsize", "(", "to_add", ")", ")", ")", "\n", "\n", "", "", "if", "sort_by_size", ":", "\n", "            ", "self", ".", "all_files", ".", "sort", "(", "key", "=", "lambda", "filename", ":", "filename", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.BinaryDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.BinaryDataset.__getitem__": [[53, 75], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gzip.open", "f.read", "numpy.frombuffer().astype", "open", "f.read", "numpy.frombuffer().astype", "numpy.frombuffer", "numpy.frombuffer"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "to_load", ",", "y", ",", "_", "=", "self", ".", "all_files", "[", "index", "]", "\n", "\n", "try", ":", "\n", "            ", "with", "gzip", ".", "open", "(", "to_load", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "x", "=", "f", ".", "read", "(", "self", ".", "max_len", ")", "\n", "#Need to use frombuffer b/c its a byte array, otherwise np.asarray will get wonked on trying to convert to ints", "\n", "#So decode as uint8 (1 byte per value), and then convert", "\n", "x", "=", "np", ".", "frombuffer", "(", "x", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "astype", "(", "np", ".", "int16", ")", "+", "1", "#index 0 will be special padding index", "\n", "", "", "except", "OSError", ":", "\n", "#OK, you are not a gziped file. Just read in raw bytes from disk. ", "\n", "            ", "with", "open", "(", "to_load", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "x", "=", "f", ".", "read", "(", "self", ".", "max_len", ")", "\n", "#Need to use frombuffer b/c its a byte array, otherwise np.asarray will get wonked on trying to convert to ints", "\n", "#So decode as uint8 (1 byte per value), and then convert", "\n", "x", "=", "np", ".", "frombuffer", "(", "x", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "astype", "(", "np", ".", "int16", ")", "+", "1", "#index 0 will be special padding index", "\n", "\n", "#x = np.pad(x, self.max_len-x.shape[0], 'constant')    ", "\n", "", "", "x", "=", "torch", ".", "tensor", "(", "x", ")", "\n", "\n", "return", "x", ",", "torch", ".", "tensor", "(", "[", "y", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.RandomChunkSampler.__init__": [[80, 87], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        data_source: the souce pytorch dataset object\n        batch_size: the size of the chunks to keep together. Should generally be set to the desired batch size during training to minimize runtime. \n        \"\"\"", "\n", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.RandomChunkSampler.__iter__": [[88, 101], ["len", "random.shuffle", "iter", "range", "range", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "n", "=", "len", "(", "self", ".", "data_source", ")", "\n", "\n", "data", "=", "[", "x", "for", "x", "in", "range", "(", "n", ")", "]", "\n", "\n", "# Create blocks", "\n", "blocks", "=", "[", "data", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "data", ")", ",", "self", ".", "batch_size", ")", "]", "\n", "# shuffle the blocks", "\n", "random", ".", "shuffle", "(", "blocks", ")", "\n", "# concatenate the shuffled blocks", "\n", "data", "[", ":", "]", "=", "[", "b", "for", "bs", "in", "blocks", "for", "b", "in", "bs", "]", "\n", "\n", "return", "iter", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.RandomChunkSampler.__len__": [[102, 104], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.binaryLoader.pad_collate_func": [[108, 120], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "function", ["None"], ["", "", "def", "pad_collate_func", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    This should be used as the collate_fn=pad_collate_func for a pytorch DataLoader object in order to pad out files in a batch to the length of the longest item in the batch. \n    \"\"\"", "\n", "vecs", "=", "[", "x", "[", "0", "]", "for", "x", "in", "batch", "]", "\n", "labels", "=", "[", "x", "[", "1", "]", "for", "x", "in", "batch", "]", "\n", "\n", "x", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "vecs", ",", "batch_first", "=", "True", ")", "\n", "#stack will give us (B, 1), so index [:,0] to get to just (B)", "\n", "y", "=", "torch", ".", "stack", "(", "labels", ")", "[", ":", ",", "0", "]", "\n", "\n", "return", "x", ",", "y", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.ContinueTraining.dir_path": [[33, 38], ["os.path.isdir", "NotADirectoryError"], "function", ["None"], ["def", "dir_path", "(", "string", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "string", ")", ":", "\n", "        ", "return", "string", "\n", "", "else", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.ContinueTraining.is_file": [[39, 44], ["os.path.isfile", "NotADirectoryError"], "function", ["None"], ["", "", "def", "is_file", "(", "string", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "string", ")", ":", "\n", "        ", "return", "string", "\n", "", "else", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.ContinueTraining.random_split": [[92, 110], ["torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "torch.randperm().tolist", "zip", "torch._utils._accumulate", "torch._utils._accumulate", "torch._utils._accumulate", "torch._utils._accumulate", "selected.sort", "to_ret.append", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.utils.data.Subset", "sum"], "function", ["None"], ["", "", "", "def", "random_split", "(", "dataset", ",", "lengths", ")", ":", "\n", "    ", "\"\"\"\n    Randomly split a dataset into non-overlapping new datasets of given lengths.\n\n    Arguments:\n        dataset (Dataset): Dataset to be split\n        lengths (sequence): lengths of splits to be produced\n    \"\"\"", "\n", "#if sum(lengths) != len(dataset):", "\n", "#    raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")", "\n", "\n", "indices", "=", "torch", ".", "randperm", "(", "sum", "(", "lengths", ")", ")", ".", "tolist", "(", ")", "\n", "to_ret", "=", "[", "]", "\n", "for", "offset", ",", "length", "in", "zip", "(", "torch", ".", "_utils", ".", "_accumulate", "(", "lengths", ")", ",", "lengths", ")", ":", "\n", "        ", "selected", "=", "indices", "[", "offset", "-", "length", ":", "offset", "]", "\n", "selected", ".", "sort", "(", ")", "\n", "to_ret", ".", "append", "(", "Subset", "(", "dataset", ",", "selected", ")", ")", "\n", "", "return", "to_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.CatMod.__init__": [[28, 30], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CatMod", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.CatMod.forward": [[31, 33], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "x", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.__init__": [[38, 59], ["torch.Module.__init__", "torch.AdaptiveMaxPool1d", "torch.AdaptiveMaxPool1d", "torch.AdaptiveMaxPool1d", "LowMemConv.CatMod", "LowMemConv.LowMemConvBase.cat.register_backward_hook", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__"], ["    ", "def", "__init__", "(", "self", ",", "chunk_size", "=", "65536", ",", "overlap", "=", "512", ",", "min_chunk_size", "=", "1024", ")", ":", "\n", "        ", "\"\"\"\n        chunk_size: how many bytes at a time to process. Increasing may improve compute efficent, but use more memory. Total memory use will be a function of chunk_size, and not of the length of the input sequence L\n        \n        overlap: how many bytes of overlap to use between chunks\n        \n        \"\"\"", "\n", "super", "(", "LowMemConvBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "self", ".", "overlap", "=", "overlap", "\n", "self", ".", "min_chunk_size", "=", "min_chunk_size", "\n", "\n", "#Used for pooling over time in a meory efficent way", "\n", "self", ".", "pooling", "=", "nn", ".", "AdaptiveMaxPool1d", "(", "1", ")", "\n", "#   self.pooling.register_backward_hook(drop_zeros_hook)", "\n", "self", ".", "cat", "=", "CatMod", "(", ")", "\n", "self", ".", "cat", ".", "register_backward_hook", "(", "drop_zeros_hook", ")", "\n", "self", ".", "receptive_field", "=", "None", "\n", "\n", "#Used to force checkpoint code to behave correctly due to poor design https://discuss.pytorch.org/t/checkpoint-with-no-grad-requiring-inputs-problem/19117/11", "\n", "self", ".", "dummy_tensor", "=", "torch", ".", "ones", "(", "1", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.processRange": [[60, 66], ["None"], "methods", ["None"], ["", "def", "processRange", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        This method does the work to convert an LongTensor input x of shape (B, L) , where B is the batch size and L is the length of the input. The output of this functoin should be a tensor of (B, C, L), where C is the number of channels, and L is again the input length (though its OK if it got a little shorter due to convs without padding or something). \n        \n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.determinRF": [[67, 115], ["hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "next", "LowMemConv.LowMemConvBase.embd.parameters", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "LowMemConv.LowMemConvBase.processRange", "LowMemConv.LowMemConvBase.processRange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.processRange", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.processRange"], ["", "def", "determinRF", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Lets determine the receptive field & stride of our sub-network\n        \"\"\"", "\n", "\n", "if", "self", ".", "receptive_field", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "receptive_field", ",", "self", ".", "stride", ",", "self", ".", "out_channels", "\n", "#else, figure this out! ", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"device_ids\"", ")", ":", "\n", "#We are training with just one device. Lets find out where we should move the data", "\n", "            ", "cur_device", "=", "next", "(", "self", ".", "embd", ".", "parameters", "(", ")", ")", ".", "device", "\n", "", "else", ":", "\n", "            ", "cur_device", "=", "\"cpu\"", "\n", "\n", "#Lets do a simple binary search to figure out how large our RF is. ", "\n", "#It can't be larger than our chunk size! So use that as upper bound", "\n", "", "min_rf", "=", "1", "\n", "max_rf", "=", "self", ".", "chunk_size", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "tmp", "=", "torch", ".", "zeros", "(", "(", "1", ",", "max_rf", ")", ")", ".", "long", "(", ")", ".", "to", "(", "cur_device", ")", "\n", "\n", "while", "True", ":", "\n", "                ", "test_size", "=", "(", "min_rf", "+", "max_rf", ")", "//", "2", "\n", "is_valid", "=", "True", "\n", "try", ":", "\n", "                    ", "self", ".", "processRange", "(", "tmp", "[", ":", ",", "0", ":", "test_size", "]", ")", "\n", "", "except", ":", "\n", "                    ", "is_valid", "=", "False", "\n", "\n", "", "if", "is_valid", ":", "\n", "                    ", "max_rf", "=", "test_size", "\n", "", "else", ":", "\n", "                    ", "min_rf", "=", "test_size", "+", "1", "\n", "\n", "#print(is_valid, test_size, min_rf, max_rf)", "\n", "\n", "", "if", "max_rf", "==", "min_rf", ":", "\n", "                    ", "self", ".", "receptive_field", "=", "min_rf", "\n", "out_shape", "=", "self", ".", "processRange", "(", "tmp", ")", ".", "shape", "\n", "self", ".", "stride", "=", "self", ".", "chunk_size", "//", "out_shape", "[", "2", "]", "\n", "self", ".", "out_channels", "=", "out_shape", "[", "1", "]", "\n", "break", "\n", "\n", "\n", "", "", "", "return", "self", ".", "receptive_field", ",", "self", ".", "stride", ",", "self", ".", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.pool_group": [[117, 122], ["LowMemConv.LowMemConvBase.cat", "LowMemConv.LowMemConvBase.pooling"], "methods", ["None"], ["", "def", "pool_group", "(", "self", ",", "*", "args", ")", ":", "\n", "#x = torch.cat(args[0:-1], dim=2)", "\n", "        ", "x", "=", "self", ".", "cat", "(", "args", ")", "\n", "x", "=", "self", ".", "pooling", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix": [[123, 211], ["LowMemConv.LowMemConvBase.determinRF", "numpy.zeros", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "LowMemConv.LowMemConvBase.processRange", "LowMemConv.LowMemConvBase.pooling", "x_selected.to.to.view", "torch.pad", "torch.pad", "torch.pad", "numpy.zeros", "hasattr", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "numpy.unique", "x_selected.to.to.to", "x_selected.to.to.long", "x_selected.to.to.size", "next", "LowMemConv.LowMemConvBase.processRange", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "min", "range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "LowMemConv.LowMemConvBase.embd.parameters", "max", "x_sub.to.to.to", "x_sub.to.to.long", "activ_win.cpu().numpy", "activ_indx.cpu().numpy", "activ_win.cpu", "activ_indx.cpu", "max", "min"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.determinRF", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.processRange", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.processRange"], ["", "def", "seq2fix", "(", "self", ",", "x", ",", "pr_args", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"\n        Takes in an input LongTensor of (B, L) that will be converted to a fixed length representation (B, C), where C is the number of channels provided by the base_network  given at construction. \n        \"\"\"", "\n", "\n", "receptive_window", ",", "stride", ",", "out_channels", "=", "self", ".", "determinRF", "(", ")", "\n", "\n", "if", "x", ".", "shape", "[", "1", "]", "<", "receptive_window", ":", "#This is a tiny input! pad it out please", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "receptive_window", "-", "x", ".", "shape", "[", "1", "]", ")", ",", "value", "=", "0", ")", "#0 is the pad value we use ", "\n", "\n", "", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "length", "=", "x", ".", "shape", "[", "1", "]", "\n", "\n", "\n", "\n", "#Lets go through the input data without gradients first, and find the positions that \"win\"", "\n", "#the max-pooling. Most of the gradients will be zero, and we don't want to waste valuable", "\n", "#memory and time computing them. ", "\n", "#Once we know the winners, we will go back and compute the forward activations on JUST", "\n", "#the subset of positions that won!", "\n", "winner_values", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "out_channels", ")", ")", "-", "1.0", "\n", "winner_indices", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "out_channels", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "if", "not", "hasattr", "(", "self", ",", "\"device_ids\"", ")", ":", "\n", "#We are training with just one device. Lets find out where we should move the data", "\n", "            ", "cur_device", "=", "next", "(", "self", ".", "embd", ".", "parameters", "(", ")", ")", ".", "device", "\n", "", "else", ":", "\n", "            ", "cur_device", "=", "None", "\n", "\n", "", "step", "=", "self", ".", "chunk_size", "#- self.overlap", "\n", "#step = length", "\n", "start", "=", "0", "\n", "end", "=", "start", "+", "step", "\n", "\n", "\n", "#TODO, I'm being a little sloppy on picking exact range, and selecting more context than i need", "\n", "#Future, should figure out precisely which bytes won and only include that range", "\n", "\n", "#print(\"Starting Search\")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "while", "start", "<", "end", "and", "(", "end", "-", "start", ")", ">=", "max", "(", "self", ".", "min_chunk_size", ",", "receptive_window", ")", ":", "\n", "#print(\"Range {}:{}/{}\".format(start,end,length))", "\n", "                ", "x_sub", "=", "x", "[", ":", ",", "start", ":", "end", "]", "\n", "if", "cur_device", "is", "not", "None", ":", "\n", "                    ", "x_sub", "=", "x_sub", ".", "to", "(", "cur_device", ")", "\n", "", "activs", "=", "self", ".", "processRange", "(", "x_sub", ".", "long", "(", ")", ",", "**", "pr_args", ")", "\n", "activ_win", ",", "activ_indx", "=", "F", ".", "max_pool1d", "(", "activs", ",", "kernel_size", "=", "activs", ".", "shape", "[", "2", "]", ",", "return_indices", "=", "True", ")", "\n", "#print(activ_win.shape)", "\n", "#Python for this code loop is WAY too slow! Numpy it!", "\n", "#for b in range(batch_size):", "\n", "#    for c in range(out_channels):", "\n", "#        if winner_values[b,c] < activ_win[b,c]:", "\n", "#            winner_indices[b, c] = activ_indx[b, c]*stride + start + receptive_window//2", "\n", "#            winner_values[b,c]   = activ_win[b,c]", "\n", "#We want to remove only last dimension, but if batch size is 1, np.squeeze", "\n", "#will screw us up and remove first dime too. ", "\n", "#activ_win = np.squeeze(activ_win.cpu().numpy())", "\n", "#activ_indx = np.squeeze(activ_indx.cpu().numpy())", "\n", "activ_win", "=", "activ_win", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "activ_indx", "=", "activ_indx", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "selected", "=", "winner_values", "<", "activ_win", "\n", "winner_indices", "[", "selected", "]", "=", "activ_indx", "[", "selected", "]", "*", "stride", "+", "start", "\n", "winner_values", "[", "selected", "]", "=", "activ_win", "[", "selected", "]", "\n", "start", "=", "end", "\n", "end", "=", "min", "(", "start", "+", "step", ",", "length", ")", "\n", "\n", "#Now we know every index that won, we need to compute values and with gradients! ", "\n", "\n", "#Find unique winners for every batch", "\n", "", "", "final_indices", "=", "[", "np", ".", "unique", "(", "winner_indices", "[", "b", ",", ":", "]", ")", "for", "b", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "#Collect inputs that won for each batch", "\n", "chunk_list", "=", "[", "[", "x", "[", "b", ":", "b", "+", "1", ",", "max", "(", "i", "-", "receptive_window", ",", "0", ")", ":", "min", "(", "i", "+", "receptive_window", ",", "length", ")", "]", "for", "i", "in", "final_indices", "[", "b", "]", "]", "for", "b", "in", "range", "(", "batch_size", ")", "]", "\n", "#Convert to a torch tensor of the bytes", "\n", "chunk_list", "=", "[", "torch", ".", "cat", "(", "c", ",", "dim", "=", "1", ")", "[", "0", ",", ":", "]", "for", "c", "in", "chunk_list", "]", "\n", "\n", "#Padd out shorter sequences to the longest one", "\n", "x_selected", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "chunk_list", ",", "batch_first", "=", "True", ")", "\n", "\n", "#Shape is not (B, L) Lets compute!", "\n", "\n", "if", "cur_device", "is", "not", "None", ":", "\n", "            ", "x_selected", "=", "x_selected", ".", "to", "(", "cur_device", ")", "\n", "", "x_selected", "=", "self", ".", "processRange", "(", "x_selected", ".", "long", "(", ")", ",", "**", "pr_args", ")", "\n", "x_selected", "=", "self", ".", "pooling", "(", "x_selected", ")", "\n", "x_selected", "=", "x_selected", ".", "view", "(", "x_selected", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "return", "x_selected", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.drop_zeros_hook": [[11, 26], ["tuple", "torch.no_grad", "torch.no_grad", "torch.no_grad", "grads.append", "grads.append", "g.to_sparse", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "function", ["None"], ["def", "drop_zeros_hook", "(", "module", ",", "grad_input", ",", "grad_out", ")", ":", "\n", "    ", "\"\"\"\n    This function is used to replace gradients that are all zeros with None\n    In pyTorch None will not get back-propogated\n    So we use this as a approximation to saprse BP to avoid redundant and useless work\n    \"\"\"", "\n", "grads", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "g", "in", "grad_input", ":", "\n", "            ", "if", "torch", ".", "nonzero", "(", "g", ")", ".", "shape", "[", "0", "]", "==", "0", ":", "#ITS ALL EMPTY!", "\n", "                ", "grads", ".", "append", "(", "g", ".", "to_sparse", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "grads", ".", "append", "(", "g", ")", "\n", "\n", "", "", "", "return", "tuple", "(", "grads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.__init__": [[40, 63], ["LowMemConv.LowMemConvBase.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "MalConvML.MalConvML.MalConvML", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_size", "=", "2", ",", "channels", "=", "128", ",", "window_size", "=", "512", ",", "stride", "=", "512", ",", "layers", "=", "1", ",", "embd_size", "=", "8", ",", "log_stride", "=", "None", ",", "low_mem", "=", "True", ")", ":", "\n", "        ", "super", "(", "MalConvGCT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "low_mem", "=", "low_mem", "\n", "self", ".", "embd", "=", "nn", ".", "Embedding", "(", "257", ",", "embd_size", ",", "padding_idx", "=", "0", ")", "\n", "if", "not", "log_stride", "is", "None", ":", "\n", "            ", "stride", "=", "2", "**", "log_stride", "\n", "\n", "", "self", ".", "context_net", "=", "MalConvML", "(", "out_size", "=", "channels", ",", "channels", "=", "channels", ",", "window_size", "=", "window_size", ",", "stride", "=", "stride", ",", "layers", "=", "layers", ",", "embd_size", "=", "embd_size", ")", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "embd_size", ",", "channels", "*", "2", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "]", "+", "[", "nn", ".", "Conv1d", "(", "channels", ",", "channels", "*", "2", ",", "window_size", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "for", "i", "in", "range", "(", "layers", "-", "1", ")", "]", ")", "\n", "\n", "#These two objs are not used. They were originally present before the F.glu function existed, and then were accidently left in when we switched over. So the state file provided has unusued states in it. They are left in this definition so that there are no issues loading the file that MalConv was trained on.", "\n", "#If you are going to train from scratch, you can delete these two lines.", "\n", "#self.convs_1 = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])", "\n", "#self.convs_atn = nn.ModuleList([nn.Conv1d(channels*2, channels, 1, bias=True) for i in range(layers)])", "\n", "\n", "self", ".", "linear_atn", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "channels", ",", "channels", ")", "for", "i", "in", "range", "(", "layers", ")", "]", ")", "\n", "\n", "#one-by-one cons to perform information sharing", "\n", "self", ".", "convs_share", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "1", ",", "bias", "=", "True", ")", "for", "i", "in", "range", "(", "layers", ")", "]", ")", "\n", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "channels", ",", "channels", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "channels", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.determinRF": [[66, 68], ["MalConvGCT_nocat.MalConvGCT.context_net.determinRF"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.determinRF"], ["", "def", "determinRF", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "context_net", ".", "determinRF", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.processRange": [[69, 102], ["MalConvGCT_nocat.MalConvGCT.embd", "torch.leaky_relu.permute", "zip", "Exception", "torch.glu", "torch.glu", "torch.glu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "numpy.sqrt", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.leaky_relu.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d.view", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "conv_glu", "conv_share", "linear_cntx"], "methods", ["None"], ["", "def", "processRange", "(", "self", ",", "x", ",", "gct", "=", "None", ")", ":", "\n", "        ", "if", "gct", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"No Global Context Given\"", ")", "\n", "\n", "", "x", "=", "self", ".", "embd", "(", "x", ")", "\n", "#x = torch.transpose(x,-1,-2)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "for", "conv_glu", ",", "linear_cntx", ",", "conv_share", "in", "zip", "(", "self", ".", "convs", ",", "self", ".", "linear_atn", ",", "self", ".", "convs_share", ")", ":", "\n", "            ", "x", "=", "F", ".", "glu", "(", "conv_glu", "(", "x", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "F", ".", "leaky_relu", "(", "conv_share", "(", "x", ")", ")", "\n", "x_len", "=", "x", ".", "shape", "[", "2", "]", "\n", "B", "=", "x", ".", "shape", "[", "0", "]", "\n", "C", "=", "x", ".", "shape", "[", "1", "]", "\n", "\n", "sqrt_dim", "=", "np", ".", "sqrt", "(", "x", ".", "shape", "[", "1", "]", ")", "\n", "#we are going to need a version of GCT with a time dimension, which we will adapt as needed to the right length", "\n", "ctnx", "=", "torch", ".", "tanh", "(", "linear_cntx", "(", "gct", ")", ")", "\n", "\n", "#Size is (B, C), but we need (B, C, 1) to use as a 1d conv filter", "\n", "ctnx", "=", "torch", ".", "unsqueeze", "(", "ctnx", ",", "dim", "=", "2", ")", "\n", "#roll the batches into the channels", "\n", "x_tmp", "=", "x", ".", "view", "(", "1", ",", "B", "*", "C", ",", "-", "1", ")", "\n", "#Now we can apply a conv with B groups, so that each batch gets its own context applied only to what was needed", "\n", "x_tmp", "=", "F", ".", "conv1d", "(", "x_tmp", ",", "ctnx", ",", "groups", "=", "B", ")", "\n", "#x_tmp will have a shape of (1, B, L), now we just need to re-order the data back to (B, 1, L)", "\n", "x_gates", "=", "x_tmp", ".", "view", "(", "B", ",", "1", ",", "-", "1", ")", "\n", "\n", "#Now we effectively apply \u03c3(x_t^T tanh(W c))", "\n", "gates", "=", "torch", ".", "sigmoid", "(", "x_gates", ")", "\n", "x", "=", "x", "*", "gates", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.MalConvGCT.forward": [[103, 116], ["MalConvGCT_nocat.MalConvGCT.seq2fix", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "MalConvGCT_nocat.MalConvGCT.fc_2", "checkpoint.CheckpointFunction.apply", "MalConvGCT_nocat.MalConvGCT.context_net.seq2fix", "MalConvGCT_nocat.MalConvGCT.fc_1"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix", "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "self", ".", "low_mem", ":", "\n", "            ", "global_context", "=", "checkpoint", ".", "CheckpointFunction", ".", "apply", "(", "self", ".", "context_net", ".", "seq2fix", ",", "1", ",", "x", ")", "\n", "", "else", ":", "\n", "            ", "global_context", "=", "self", ".", "context_net", ".", "seq2fix", "(", "x", ")", "\n", "\n", "", "post_conv", "=", "x", "=", "self", ".", "seq2fix", "(", "x", ",", "pr_args", "=", "{", "'gct'", ":", "global_context", "}", ")", "\n", "\n", "penult", "=", "x", "=", "F", ".", "leaky_relu", "(", "self", ".", "fc_1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc_2", "(", "x", ")", "\n", "\n", "return", "x", ",", "penult", ",", "post_conv", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.getParams": [[17, 28], ["collections.OrderedDict", "sorted", "params.items"], "function", ["None"], ["def", "getParams", "(", ")", ":", "\n", "#Format for this is to make it work easily with Optuna in an automated fashion.", "\n", "#variable name -> tuple(sampling function, dict(sampling_args) )", "\n", "    ", "params", "=", "{", "\n", "'channels'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'channels'", ",", "'low'", ":", "32", ",", "'high'", ":", "1024", "}", ")", ",", "\n", "'log_stride'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'log2_stride'", ",", "'low'", ":", "2", ",", "'high'", ":", "9", "}", ")", ",", "\n", "'window_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'window_size'", ",", "'low'", ":", "32", ",", "'high'", ":", "256", "}", ")", ",", "\n", "'layers'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'layers'", ",", "'low'", ":", "1", ",", "'high'", ":", "3", "}", ")", ",", "\n", "'embd_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'embd_size'", ",", "'low'", ":", "4", ",", "'high'", ":", "16", "}", ")", ",", "\n", "}", "\n", "return", "OrderedDict", "(", "sorted", "(", "params", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocat.initModel": [[29, 36], ["MalConvGCT_nocat.getParams", "MalConvGCT_nocat.MalConvGCT"], "function", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams"], ["", "def", "initModel", "(", "**", "kwargs", ")", ":", "\n", "    ", "new_args", "=", "{", "}", "\n", "for", "x", "in", "getParams", "(", ")", ":", "\n", "        ", "if", "x", "in", "kwargs", ":", "\n", "            ", "new_args", "[", "x", "]", "=", "kwargs", "[", "x", "]", "\n", "\n", "", "", "return", "MalConvGCT", "(", "**", "new_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConv.MalConv.__init__": [[38, 50], ["LowMemConv.LowMemConvBase.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_size", "=", "2", ",", "channels", "=", "128", ",", "window_size", "=", "512", ",", "stride", "=", "512", ",", "embd_size", "=", "8", ",", "log_stride", "=", "None", ")", ":", "\n", "        ", "super", "(", "MalConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embd", "=", "nn", ".", "Embedding", "(", "257", ",", "embd_size", ",", "padding_idx", "=", "0", ")", "\n", "if", "not", "log_stride", "is", "None", ":", "\n", "            ", "stride", "=", "2", "**", "log_stride", "\n", "\n", "", "self", ".", "conv_1", "=", "nn", ".", "Conv1d", "(", "embd_size", ",", "channels", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv_2", "=", "nn", ".", "Conv1d", "(", "embd_size", ",", "channels", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "\n", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "channels", ",", "channels", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "channels", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConv.MalConv.processRange": [[52, 62], ["MalConv.MalConv.embd", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "MalConv.MalConv.conv_1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "MalConv.MalConv.conv_2"], "methods", ["None"], ["", "def", "processRange", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embd", "(", "x", ")", "\n", "x", "=", "torch", ".", "transpose", "(", "x", ",", "-", "1", ",", "-", "2", ")", "\n", "\n", "cnn_value", "=", "self", ".", "conv_1", "(", "x", ")", "\n", "gating_weight", "=", "torch", ".", "sigmoid", "(", "self", ".", "conv_2", "(", "x", ")", ")", "\n", "\n", "x", "=", "cnn_value", "*", "gating_weight", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConv.MalConv.forward": [[63, 70], ["MalConv.MalConv.seq2fix", "torch.relu", "torch.relu", "torch.relu", "MalConv.MalConv.fc_2", "MalConv.MalConv.fc_1"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "post_conv", "=", "x", "=", "self", ".", "seq2fix", "(", "x", ")", "\n", "\n", "penult", "=", "x", "=", "F", ".", "relu", "(", "self", ".", "fc_1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc_2", "(", "x", ")", "\n", "\n", "return", "x", ",", "penult", ",", "post_conv", "", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConv.getParams": [[16, 26], ["collections.OrderedDict", "sorted", "params.items"], "function", ["None"], ["def", "getParams", "(", ")", ":", "\n", "#Format for this is to make it work easily with Optuna in an automated fashion.", "\n", "#variable name -> tuple(sampling function, dict(sampling_args) )", "\n", "    ", "params", "=", "{", "\n", "'channels'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'channels'", ",", "'low'", ":", "32", ",", "'high'", ":", "1024", "}", ")", ",", "\n", "'log_stride'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'log2_stride'", ",", "'low'", ":", "2", ",", "'high'", ":", "9", "}", ")", ",", "\n", "'window_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'window_size'", ",", "'low'", ":", "32", ",", "'high'", ":", "512", "}", ")", ",", "\n", "'embd_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'embd_size'", ",", "'low'", ":", "4", ",", "'high'", ":", "64", "}", ")", ",", "\n", "}", "\n", "return", "OrderedDict", "(", "sorted", "(", "params", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConv.initModel": [[27, 34], ["MalConv.getParams", "MalConv.MalConv"], "function", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams"], ["", "def", "initModel", "(", "**", "kwargs", ")", ":", "\n", "    ", "new_args", "=", "{", "}", "\n", "for", "x", "in", "getParams", "(", ")", ":", "\n", "        ", "if", "x", "in", "kwargs", ":", "\n", "            ", "new_args", "[", "x", "]", "=", "kwargs", "[", "x", "]", "\n", "\n", "", "", "return", "MalConv", "(", "**", "new_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.checkpoint.CheckpointFunction.forward": [[24, 32], ["list", "list", "torch.no_grad", "ctx.run_function"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "run_function", ",", "length", ",", "*", "args", ")", ":", "\n", "        ", "ctx", ".", "run_function", "=", "run_function", "\n", "ctx", ".", "input_tensors", "=", "list", "(", "args", "[", ":", "length", "]", ")", "\n", "ctx", ".", "input_params", "=", "list", "(", "args", "[", "length", ":", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output_tensors", "=", "ctx", ".", "run_function", "(", "*", "ctx", ".", "input_tensors", ")", "\n", "", "return", "output_tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.checkpoint.CheckpointFunction.backward": [[33, 43], ["range", "torch.autograd.grad", "len", "temp.detach", "torch.enable_grad", "ctx.run_function"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "*", "output_grads", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "ctx", ".", "input_tensors", ")", ")", ":", "\n", "            ", "temp", "=", "ctx", ".", "input_tensors", "[", "i", "]", "\n", "ctx", ".", "input_tensors", "[", "i", "]", "=", "temp", ".", "detach", "(", ")", "\n", "ctx", ".", "input_tensors", "[", "i", "]", ".", "requires_grad", "=", "temp", ".", "requires_grad", "\n", "", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "output_tensors", "=", "ctx", ".", "run_function", "(", "*", "ctx", ".", "input_tensors", ")", "\n", "", "input_grads", "=", "torch", ".", "autograd", ".", "grad", "(", "output_tensors", ",", "ctx", ".", "input_tensors", "+", "ctx", ".", "input_params", ",", "output_grads", ",", "allow_unused", "=", "True", ")", "\n", "return", "(", "None", ",", "None", ")", "+", "input_grads", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.checkpoint.detach_variable": [[5, 16], ["isinstance", "tuple", "RuntimeError", "inp.detach", "out.append", "type"], "function", ["None"], ["def", "detach_variable", "(", "inputs", ")", ":", "\n", "    ", "if", "isinstance", "(", "inputs", ",", "tuple", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "inp", "in", "inputs", ":", "\n", "            ", "x", "=", "inp", ".", "detach", "(", ")", "\n", "x", ".", "requires_grad", "=", "inp", ".", "requires_grad", "\n", "out", ".", "append", "(", "x", ")", "\n", "", "return", "tuple", "(", "out", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"Only tuple of tensors is supported. Got Unsupported input type: \"", ",", "type", "(", "inputs", ")", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.checkpoint.check_backward_validity": [[18, 21], ["any", "warnings.warn"], "function", ["None"], ["", "", "def", "check_backward_validity", "(", "inputs", ")", ":", "\n", "    ", "if", "not", "any", "(", "inp", ".", "requires_grad", "for", "inp", "in", "inputs", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"None of the inputs have requires_grad=True. Gradients will be None\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvGCT_nocatTrain.dir_path": [[31, 36], ["os.path.isdir", "NotADirectoryError"], "function", ["None"], ["def", "dir_path", "(", "string", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "string", ")", ":", "\n", "        ", "return", "string", "\n", "", "else", ":", "\n", "        ", "raise", "NotADirectoryError", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__": [[39, 52], ["LowMemConv.LowMemConvBase.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "range", "range"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_size", "=", "2", ",", "channels", "=", "128", ",", "window_size", "=", "512", ",", "stride", "=", "512", ",", "layers", "=", "1", ",", "embd_size", "=", "8", ",", "log_stride", "=", "None", ")", ":", "\n", "        ", "super", "(", "MalConvML", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embd", "=", "nn", ".", "Embedding", "(", "257", ",", "embd_size", ",", "padding_idx", "=", "0", ")", "\n", "if", "not", "log_stride", "is", "None", ":", "\n", "            ", "stride", "=", "2", "**", "log_stride", "\n", "\n", "", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "embd_size", ",", "channels", "*", "2", ",", "window_size", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", "]", "+", "[", "nn", ".", "Conv1d", "(", "channels", ",", "channels", "*", "2", ",", "window_size", ",", "stride", "=", "1", ",", "bias", "=", "True", ")", "for", "i", "in", "range", "(", "layers", "-", "1", ")", "]", ")", "\n", "#one-by-one cons to perform information sharing", "\n", "self", ".", "convs_1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "channels", ",", "channels", ",", "1", ",", "bias", "=", "True", ")", "for", "i", "in", "range", "(", "layers", ")", "]", ")", "\n", "\n", "\n", "self", ".", "fc_1", "=", "nn", ".", "Linear", "(", "channels", ",", "channels", ")", "\n", "self", ".", "fc_2", "=", "nn", ".", "Linear", "(", "channels", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.processRange": [[54, 63], ["MalConvML.MalConvML.embd", "torch.leaky_relu.permute().contiguous", "zip", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu.permute", "conv_share", "torch.glu", "torch.glu", "torch.glu", "conv_glu", "torch.leaky_relu.contiguous"], "methods", ["None"], ["", "def", "processRange", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "embd", "(", "x", ")", "\n", "#x = torch.transpose(x,-1,-2)", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "for", "conv_glu", ",", "conv_share", "in", "zip", "(", "self", ".", "convs", ",", "self", ".", "convs_1", ")", ":", "\n", "            ", "x", "=", "F", ".", "leaky_relu", "(", "conv_share", "(", "F", ".", "glu", "(", "conv_glu", "(", "x", ".", "contiguous", "(", ")", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.MalConvML.forward": [[64, 71], ["MalConvML.MalConvML.seq2fix", "torch.relu", "torch.relu", "torch.relu", "MalConvML.MalConvML.fc_2", "MalConvML.MalConvML.fc_1"], "methods", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.LowMemConv.LowMemConvBase.seq2fix"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "post_conv", "=", "x", "=", "self", ".", "seq2fix", "(", "x", ")", "\n", "\n", "penult", "=", "x", "=", "F", ".", "relu", "(", "self", ".", "fc_1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc_2", "(", "x", ")", "\n", "\n", "return", "x", ",", "penult", ",", "post_conv", "\n", "", "", ""]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams": [[16, 27], ["collections.OrderedDict", "sorted", "params.items"], "function", ["None"], ["def", "getParams", "(", ")", ":", "\n", "#Format for this is to make it work easily with Optuna in an automated fashion.", "\n", "#variable name -> tuple(sampling function, dict(sampling_args) )", "\n", "    ", "params", "=", "{", "\n", "'channels'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'channels'", ",", "'low'", ":", "32", ",", "'high'", ":", "1024", "}", ")", ",", "\n", "'log_stride'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'log2_stride'", ",", "'low'", ":", "2", ",", "'high'", ":", "9", "}", ")", ",", "\n", "'window_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'window_size'", ",", "'low'", ":", "32", ",", "'high'", ":", "256", "}", ")", ",", "\n", "'layers'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'layers'", ",", "'low'", ":", "1", ",", "'high'", ":", "6", "}", ")", ",", "\n", "'embd_size'", ":", "(", "\"suggest_int\"", ",", "{", "'name'", ":", "'embd_size'", ",", "'low'", ":", "4", ",", "'high'", ":", "64", "}", ")", ",", "\n", "}", "\n", "return", "OrderedDict", "(", "sorted", "(", "params", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.initModel": [[28, 35], ["MalConvML.getParams", "MalConvML.MalConvML"], "function", ["home.repos.pwc.inspect_result.NeuromorphicComputationResearchProgram_MalConv2.None.MalConvML.getParams"], ["", "def", "initModel", "(", "**", "kwargs", ")", ":", "\n", "    ", "new_args", "=", "{", "}", "\n", "for", "x", "in", "getParams", "(", ")", ":", "\n", "        ", "if", "x", "in", "kwargs", ":", "\n", "            ", "new_args", "[", "x", "]", "=", "kwargs", "[", "x", "]", "\n", "\n", "", "", "return", "MalConvML", "(", "**", "new_args", ")", "\n", "\n"]]}