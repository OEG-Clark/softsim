{"home.repos.pwc.inspect_result.firehose-dataset_congrad.None.eval.postprocess_args": [[30, 36], ["None"], "function", ["None"], ["def", "postprocess_args", "(", "args", ")", ":", "\n", "    ", "args", ".", "tie_weight", "=", "not", "args", ".", "not_tied", "\n", "args", ".", "d_embed", "=", "args", ".", "d_model", "if", "args", ".", "d_embed", "<", "0", "else", "args", ".", "d_embed", "\n", "assert", "args", ".", "batch_size", "%", "args", ".", "batch_chunk", "==", "0", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.None.eval._command_line_parser": [[37, 54], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "core.configs.get_basic_parser"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.configs.get_basic_parser"], ["", "def", "_command_line_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "parents", "=", "[", "get_basic_parser", "(", ")", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--data'", ",", "type", "=", "str", ",", "default", "=", "'data/cikm2010_dataset'", ",", "\n", "help", "=", "'location of the data corpus'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'cikm2010'", ",", "\n", "help", "=", "'dataset name'", ")", "\n", "parser", ".", "add_argument", "(", "'--cased'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use cased or uncased corpus'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_file'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'vocabulary'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "'model directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--split'", ",", "type", "=", "str", ",", "required", "=", "True", ",", "choices", "=", "[", "'train'", ",", "'val'", ",", "'test'", "]", ",", "\n", "help", "=", "'data split to evaluate'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'model of epoch to load'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.None.eval.batch_evaluate": [[55, 86], ["model.eval", "model.reset_length", "collections.defaultdict", "collections.defaultdict", "model.train", "model.reset_length", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tuple", "enumerate", "int", "int", "tqdm.tqdm", "model", "loss.sum().float().item", "word_len.sum().item", "token_len.sum().item", "enumerate", "user.flatten().tolist", "loss[].sum().float().item", "word_len[].item", "loss.sum().float", "word_len.sum", "token_len.sum", "user.flatten", "loss[].sum().float", "loss.sum", "loss[].sum"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.reset_length", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.reset_length", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "batch_evaluate", "(", "eval_data", ",", "model", ",", "args", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "model", ".", "reset_length", "(", "280", ",", "0", ")", "\n", "\n", "user_total_loss", "=", "defaultdict", "(", "lambda", ":", "int", "(", "0", ")", ")", "\n", "user_word_len", "=", "defaultdict", "(", "lambda", ":", "int", "(", "0", ")", ")", "\n", "user_word_ppl", "=", "{", "}", "\n", "# Evaluation", "\n", "total_word_len", ",", "total_token_len", ",", "total_loss", "=", "0", ",", "0", ",", "0.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "verbose", ":", "eval_data", "=", "tqdm", "(", "eval_data", ",", "ncols", "=", "64", ")", "\n", "mems", "=", "tuple", "(", ")", "\n", "for", "i", ",", "(", "data", ",", "target", ",", "user", ",", "token_len", ",", "word_len", ")", "in", "enumerate", "(", "eval_data", ")", ":", "\n", "            ", "if", "args", ".", "max_eval_steps", ">", "0", "and", "i", ">=", "args", ".", "max_eval_steps", ":", "\n", "                ", "break", "\n", "", "ret", "=", "model", "(", "data", ",", "target", ",", "user", ",", "*", "mems", ")", "\n", "loss", ",", "mems", "=", "ret", "[", "0", "]", ",", "ret", "[", "1", ":", "]", "\n", "total_loss", "+=", "loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "total_word_len", "+=", "word_len", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "total_token_len", "+=", "token_len", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "for", "ix", ",", "uid", "in", "enumerate", "(", "user", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", ":", "\n", "                ", "user_total_loss", "[", "uid", "]", "+=", "loss", "[", ":", ",", "ix", "]", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "user_word_len", "[", "uid", "]", "+=", "word_len", "[", "0", ",", "ix", "]", ".", "item", "(", ")", "\n", "\n", "# Switch back to the training mode", "\n", "", "", "", "model", ".", "train", "(", ")", "\n", "model", ".", "reset_length", "(", "args", ".", "max_seqlen", ",", "0", ")", "\n", "\n", "return", "total_loss", "/", "total_token_len", ",", "total_loss", "/", "total_word_len", ",", "user_total_loss", ",", "user_word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.None.train.postprocess_args": [[24, 70], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "json.load", "argparse.Namespace", "os.path.join", "os.path.join", "argparse.Namespace.model_class.startswith", "argparse.Namespace.model_class.startswith", "time.strftime"], "function", ["None"], ["def", "postprocess_args", "(", "args", ")", ":", "\n", "    ", "args", ".", "tie_weight", "=", "not", "args", ".", "not_tied", "\n", "args", ".", "d_embed", "=", "args", ".", "d_model", "if", "args", ".", "d_embed", "<", "0", "else", "args", ".", "d_embed", "\n", "args", ".", "d_user_embed", "=", "args", ".", "d_embed", "if", "args", ".", "d_user_embed", "<", "0", "else", "args", ".", "d_user_embed", "\n", "assert", "args", ".", "batch_size", "%", "args", ".", "batch_chunk", "==", "0", "\n", "\n", "if", "args", ".", "snapshot_dir", "is", "not", "None", ":", "\n", "      ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "snapshot_dir", ",", "\"configs.json\"", ")", ")", "as", "fd", ":", "\n", "        ", "max_step", "=", "args", ".", "max_step", "\n", "snapshot_dir", "=", "args", ".", "snapshot_dir", "\n", "args_json", "=", "json", ".", "load", "(", "fd", ")", "\n", "args", "=", "argparse", ".", "Namespace", "(", "**", "args_json", ")", "\n", "args", ".", "max_step", "=", "max_step", "\n", "args", ".", "snapshot_dir", "=", "snapshot_dir", "\n", "", "", "else", ":", "\n", "        ", "args", ".", "work_dir", "=", "\"_\"", ".", "join", "(", "[", "_", "for", "_", "in", "[", "\n", "args", ".", "work_dir", ",", "\n", "args", ".", "dataset", ",", "\n", "\"cased\"", "if", "args", ".", "cased", "else", "None", ",", "\n", "]", "if", "_", "is", "not", "None", "]", ")", "\n", "args", ".", "work_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "work_dir", ",", "\"_\"", ".", "join", "(", "[", "_", "for", "_", "in", "[", "\n", "args", ".", "learner", ",", "\n", "\"{}_online\"", ".", "format", "(", "args", ".", "online_buffer_strategy", ")", ",", "\n", "\"{}_replay\"", ".", "format", "(", "args", ".", "replay_buffer_strategy", ")", ",", "\n", "\"{:03g}databsz\"", ".", "format", "(", "args", ".", "batch_size", ")", ",", "\n", "\"{:03g}obsz\"", ".", "format", "(", "args", ".", "online_batch_size", ")", ",", "\n", "\"{:03g}rbsz\"", ".", "format", "(", "args", ".", "replay_batch_size", ")", ",", "\n", "\"{:02g}opusize\"", ".", "format", "(", "args", ".", "online_per_user_rbsize", ")", ",", "\n", "\"{:02g}rpusize\"", ".", "format", "(", "args", ".", "replay_per_user_rbsize", ")", ",", "\n", "\"{:02g}maxk\"", ".", "format", "(", "args", ".", "max_k_steps", ")", ",", "\n", "\"{}\"", ".", "format", "(", "args", ".", "mtl_type", ")", "if", "args", ".", "model_class", ".", "startswith", "(", "\"MTL\"", ")", "else", "None", ",", "\n", "\"allowZeroStep\"", "if", "args", ".", "allow_zero_step", "else", "None", ",", "\n", "\"fromPretrained\"", "if", "args", ".", "init_weights", "is", "not", "None", "else", "None", ",", "\n", "args", ".", "postfix", ",", "\n", "]", "if", "_", "is", "not", "None", "]", ")", ",", "\n", ")", "\n", "args", ".", "work_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "work_dir", ",", "\"_\"", ".", "join", "(", "[", "_", "for", "_", "in", "[", "\n", "args", ".", "model_class", ",", "\n", "\"{}\"", ".", "format", "(", "args", ".", "mtl_type", ")", "if", "args", ".", "model_class", ".", "startswith", "(", "\"MTL\"", ")", "else", "None", ",", "\n", "\"maxlen{:03d}\"", ".", "format", "(", "args", ".", "max_seqlen", ")", ",", "\n", "\"lr{:.4g}\"", ".", "format", "(", "args", ".", "lr", ")", ",", "\n", "\"time{}\"", ".", "format", "(", "time", ".", "strftime", "(", "\"%Y%m%d_%H%M%S\"", ")", ")", "\n", "]", "if", "_", "is", "not", "None", "]", ")", ",", "\n", ")", "\n", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.None.train._command_line_parser": [[71, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "core.configs.get_basic_parser"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.configs.get_basic_parser"], ["", "def", "_command_line_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "parents", "=", "[", "get_basic_parser", "(", ")", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset_path\"", ",", "type", "=", "str", ",", "default", "=", "\"data/Firehose10M\"", ",", "\n", "help", "=", "\"location of the data corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"Firehose10M\"", ",", "\n", "help", "=", "\"dataset name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cased\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use cased or uncased corpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--vocab_file\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"vocabulary\"", ")", "\n", "\n", "# replay buffer configs", "\n", "parser", ".", "add_argument", "(", "\"--online_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"online batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--online_per_user_rbsize\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"per user online memory buffer size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--replay_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "\n", "help", "=", "\"replay batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--replay_per_user_rbsize\"", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "\"per user replay memory buffer size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--online_buffer_strategy\"", ",", "type", "=", "str", ",", "default", "=", "\"greedy\"", ",", "\n", "help", "=", "\"online cache strategy (default: greedy)\"", ",", "\n", "choices", "=", "[", "\"greedy\"", ",", "\"reservoir\"", ",", "\"stratified\"", ",", "\"stratified-reservoir\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--replay_buffer_strategy\"", ",", "type", "=", "str", ",", "default", "=", "\"greedy\"", ",", "\n", "help", "=", "\"replay buffer strategy (default: greedy)\"", ",", "\n", "choices", "=", "[", "\"greedy\"", ",", "\"reservoir\"", ",", "\"stratified\"", ",", "\"stratified-reservoir\"", "]", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--allow_zero_step\"", ",", "action", "=", "\"store_false\"", ",", "\n", "help", "=", "\"whether allow the minimum number of gradient steps to be zero in ConGraD.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_k_steps\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"the maximum number of gradient steps per online data chunk.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learner\"", ",", "type", "=", "str", ",", "default", "=", "\"OnlineOnly\"", ",", "\n", "help", "=", "\"type of online learning algorithms\"", ",", "\n", "choices", "=", "[", "\"AGEM\"", ",", "\"OnlineOnly\"", ",", "\"ReplayOnly\"", ",", "\"MixedReplay\"", ",", "\n", "\"ConGraD_AGEM\"", ",", "\"ConGraD_OnlineOnly\"", ",", "\"ConGraD_ReplayOnly\"", ",", "\n", "\"ConGraD_MixedReplay\"", "]", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Timer.__init__": [[10, 12], ["time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "o", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Timer.measure": [[13, 21], ["int", "round", "time.time"], "methods", ["None"], ["", "def", "measure", "(", "self", ",", "p", "=", "1", ")", ":", "\n", "        ", "x", "=", "(", "time", ".", "time", "(", ")", "-", "self", ".", "o", ")", "/", "p", "\n", "x", "=", "int", "(", "x", ")", "\n", "if", "x", ">=", "3600", ":", "\n", "            ", "return", "'{:.1f}h'", ".", "format", "(", "x", "/", "3600.0", ")", "\n", "", "if", "x", ">=", "60", ":", "\n", "            ", "return", "'{:.1f}m'", ".", "format", "(", "x", "/", "60.0", ")", "\n", "", "return", "'{}s'", ".", "format", "(", "round", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.__init__": [[24, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "0", "\n", "self", ".", "v", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.add": [[28, 31], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "v", "=", "(", "self", ".", "v", "*", "self", ".", "n", "+", "x", ")", "/", "(", "self", ".", "n", "+", "1", ")", "\n", "self", ".", "n", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item": [[32, 34], ["None"], "methods", ["None"], ["", "def", "item", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.reset": [[35, 38], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "0", "\n", "self", ".", "v", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging": [[39, 45], ["print", "open", "f_log.write"], "function", ["None"], ["", "", "def", "logging", "(", "s", ",", "log_path", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "    ", "if", "print_", ":", "\n", "        ", "print", "(", "s", ")", "\n", "", "if", "log_", ":", "\n", "        ", "with", "open", "(", "log_path", ",", "'a+'", ")", "as", "f_log", ":", "\n", "            ", "f_log", ".", "write", "(", "s", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.get_logger": [[46, 48], ["functools.partial"], "function", ["None"], ["", "", "", "def", "get_logger", "(", "log_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "functools", ".", "partial", "(", "logging", ",", "log_path", "=", "log_path", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.create_exp_dir": [[49, 77], ["print", "os.path.join", "exp_utils.get_logger", "print", "functools.partial", "os.path.exists", "os.makedirs", "os.path.join", "os.path.exists", "os.makedirs", "os.path.join", "print", "os.path.isdir", "os.path.basename", "shutil.copytree", "shutil.copyfile"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.get_logger"], ["", "def", "create_exp_dir", "(", "dir_path", ",", "scripts_to_save", "=", "None", ",", "debug", "=", "False", ")", ":", "\n", "    ", "if", "debug", ":", "\n", "        ", "print", "(", "'Debug Mode : no experiment dir created'", ")", "\n", "return", "functools", ".", "partial", "(", "logging", ",", "log_path", "=", "None", ",", "log_", "=", "False", ")", "\n", "\n", "", "run_id", "=", "None", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir_path", ")", "\n", "", "else", ":", "\n", "        ", "run_id", "=", "'resume'", "\n", "\n", "", "print", "(", "'Experiment dir : {}'", ".", "format", "(", "dir_path", ")", ")", "\n", "if", "scripts_to_save", "is", "not", "None", ":", "\n", "        ", "script_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\n", "'resume.scripts'", "if", "run_id", "is", "not", "None", "else", "'scripts'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "script_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "script_path", ")", "\n", "for", "src_file", "in", "scripts_to_save", ":", "\n", "                ", "dst_file", "=", "os", ".", "path", ".", "join", "(", "script_path", ",", "os", ".", "path", ".", "basename", "(", "src_file", ")", ")", "\n", "print", "(", "'copy {} to {}'", ".", "format", "(", "src_file", ",", "dst_file", ")", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "src_file", ")", ":", "\n", "                    ", "shutil", ".", "copytree", "(", "src_file", ",", "dst_file", ")", "\n", "", "else", ":", "\n", "                    ", "shutil", ".", "copyfile", "(", "src_file", ",", "dst_file", ")", "\n", "\n", "", "", "", "", "log_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "\n", "'log.resume.txt'", "if", "run_id", "is", "not", "None", "else", "'log.txt'", ")", "\n", "return", "get_logger", "(", "log_path", "=", "log_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.__init__": [[52, 67], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "previousNode", ",", "tokens", ",", "logProb", ",", "length", ",", "\n", "alpha", "=", "0.0", ",", "beta", "=", "0.0", ",", "gamma", "=", "0.0", ")", ":", "\n", "    ", "'''\n    :param previousNode:\n    :param wordId:\n    :param logProb:\n    :param length:\n    '''", "\n", "self", ".", "prevNode", "=", "previousNode", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "logp", "=", "logProb", "\n", "self", ".", "leng", "=", "length", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "gamma", "=", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.score": [[68, 72], ["float", "float"], "methods", ["None"], ["", "def", "score", "(", "self", ")", ":", "\n", "    ", "reward", "=", "0", "\n", "lp", "=", "float", "(", "self", ".", "beta", "+", "self", ".", "leng", ")", "**", "self", ".", "alpha", "/", "float", "(", "self", ".", "beta", "+", "1", ")", "\n", "return", "-", "self", ".", "logp", "/", "lp", "+", "self", ".", "gamma", "*", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.__lt__": [[73, 75], ["inference.BeamSearchNode.score", "other.score"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.score", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.score"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "    ", "return", "self", ".", "score", "(", ")", "<", "other", ".", "score", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.__str__": [[76, 78], ["inference.BeamSearchNode.score"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.BeamSearchNode.score"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "    ", "return", "\"({}, {})\"", ".", "format", "(", "self", ".", "score", "(", ")", ",", "\" \"", ".", "join", "(", "self", ".", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.__init__": [[80, 90], ["next", "model.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "MemTransformerLM", ",", "\n", "vocab", ":", "Vocab", ",", "\n", "cased", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "self", ".", "lower", "=", "not", "cased", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.tokenize": [[92, 116], ["TOKENIZER.tokenize", "inference.ModelWrapper.vocab.encode_as_symbols", "inference.preprocess_text", "token.lower().startswith", "processed_tokens.append", "token.lower", "token.startswith", "processed_tokens.append", "processed_tokens.append", "len", "token.lower"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.tokenize", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_symbols", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.preprocess_text"], ["", "def", "tokenize", "(", "\n", "self", ",", "\n", "text", ":", "str", ",", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "tokens", "=", "TOKENIZER", ".", "tokenize", "(", "\n", "preprocess_text", "(", "text", ",", "\n", "lower", "=", "self", ".", "lower", ",", "\n", "remove_space", "=", "True", ",", "\n", "keep_accents", "=", "False", ",", "\n", ")", "\n", ")", "\n", "processed_tokens", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "if", "token", ".", "lower", "(", ")", ".", "startswith", "(", "'http'", ")", ":", "\n", "                ", "processed_tokens", ".", "append", "(", "'<url>'", ")", "\n", "", "elif", "len", "(", "token", ")", ">", "2", "and", "token", ".", "startswith", "(", "'@'", ")", ":", "\n", "                ", "processed_tokens", ".", "append", "(", "'<mention>'", ")", "\n", "", "else", ":", "\n", "                ", "processed_tokens", ".", "append", "(", "\n", "token", ".", "lower", "(", ")", "if", "self", ".", "lower", "else", "token", "\n", ")", "\n", "", "", "return_tokens", ",", "_", "=", "self", ".", "vocab", ".", "encode_as_symbols", "(", "\" \"", ".", "join", "(", "processed_tokens", ")", ")", "\n", "\n", "return", "return_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.get_logprobs": [[117, 147], ["inference.ModelWrapper.model.eval", "inference.ModelWrapper.vocab.convert_to_tensor", "len", "inference.ModelWrapper.vocab.get_indices", "torch.no_grad", "tuple", "torch.LongTensor().to", "user.unsqueeze.unsqueeze.unsqueeze", "xs.unsqueeze.unsqueeze.to", "xs.unsqueeze.unsqueeze.unsqueeze", "inference.ModelWrapper.model.get_logprob", "log_probs.squeeze().data.cpu.squeeze().data.cpu.squeeze().data.cpu", "torch.LongTensor", "log_probs.squeeze().data.cpu.squeeze().data.cpu.squeeze"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.convert_to_tensor", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_indices", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.get_logprob"], ["", "def", "get_logprobs", "(", "\n", "self", ",", "\n", "tokens", ":", "List", "[", "str", "]", ",", "\n", "user", ":", "int", "=", "0", ",", "\n", "softmax_temp", ":", "float", "=", "1.0", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Return log probabilities for next tokens.\n        Shape of returned tensor is len(tokens) x len(self.vocab),\n        where the first element contains log probabilities for tokens\n        after the first, and last element log probabilities for tokens\n        after the last one.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "# turn model into eval mode", "\n", "assert", "len", "(", "tokens", ")", ">", "0", ",", "'tokens must be non-empty string array'", "\n", "xs", "=", "self", ".", "vocab", ".", "convert_to_tensor", "(", "self", ".", "vocab", ".", "get_indices", "(", "tokens", ")", ")", "\n", "log_probs", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "mems", "=", "tuple", "(", ")", "\n", "\n", "batch_dim", "=", "1", "# batch size dimension is 1", "\n", "user", "=", "torch", ".", "LongTensor", "(", "[", "user", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "user", "=", "user", ".", "unsqueeze", "(", "batch_dim", ")", "\n", "\n", "xs", "=", "xs", ".", "to", "(", "self", ".", "device", ")", "\n", "xs", "=", "xs", ".", "unsqueeze", "(", "batch_dim", ")", "\n", "\n", "log_probs", "=", "self", ".", "model", ".", "get_logprob", "(", "xs", ",", "user", ",", "*", "mems", ",", "temperature", "=", "softmax_temp", ")", "\n", "log_probs", "=", "log_probs", ".", "squeeze", "(", "batch_dim", ")", ".", "data", ".", "cpu", "(", ")", "\n", "\n", "", "return", "log_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.sample_text": [[148, 188], ["inference.ModelWrapper.tokenize", "inference.ModelWrapper.beam_decode", "inference.ModelWrapper.greedy_decode"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.tokenize", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.beam_decode", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.greedy_decode"], ["", "def", "sample_text", "(", "\n", "self", ",", "\n", "text", ":", "str", ",", "\n", "top_k", ":", "int", "=", "100", ",", "\n", "max_text_len", ":", "int", "=", "100", ",", "\n", "user", ":", "int", "=", "0", ",", "\n", "sampling_strategy", ":", "str", "=", "'argmax'", ",", "\n", "softmax_temp", ":", "float", "=", "1.0", ",", "\n", "beam_width", ":", "int", "=", "10", ",", "# optional: only for BEAM search", "\n", "beam_alpha", ":", "float", "=", "0.0", ",", "\n", "beam_beta", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\" An iterator yielding pieces of generated text, resulting text\n        can be obtained by joining all of them with an empty string.\n        \"\"\"", "\n", "# TODO for longer texts we want to use memory and don't feed all tokens", "\n", "tokens", "=", "self", ".", "tokenize", "(", "text", ")", "\n", "\n", "if", "sampling_strategy", "==", "'beamsearch'", ":", "\n", "          ", "generated", "=", "self", ".", "beam_decode", "(", "\n", "tokens", ",", "\n", "top_k", ",", "\n", "max_text_len", ",", "\n", "user", ",", "\n", "1", ",", "\n", "softmax_temp", ",", "\n", "beam_width", ",", "\n", "beam_alpha", ",", "\n", "beam_beta", ",", "\n", ")", "\n", "", "elif", "sampling_strategy", "in", "{", "'argmax'", ",", "'multinomial'", "}", ":", "\n", "          ", "generated", "=", "self", ".", "greedy_decode", "(", "\n", "tokens", ",", "\n", "top_k", ",", "\n", "max_text_len", ",", "\n", "user", ",", "\n", "sampling_strategy", "\n", ")", "\n", "\n", "", "return", "generated", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.beam_decode": [[189, 260], ["inference.BeamSearchNode", "queue.PriorityQueue", "queue.PriorityQueue.put", "len", "queue.PriorityQueue.get", "inference.ModelWrapper.get_logprobs", "torch.topk", "range", "range", "len", "print", "endnodes.append", "print", "endnodes.append", "indexes[].item", "log_prob[].item", "inference.BeamSearchNode", "nextnodes.append", "len", "queue.PriorityQueue.put", "len", "queue.PriorityQueue.get", "len", "inference.ModelWrapper.vocab.get_sym"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.get_logprobs", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym"], ["", "def", "beam_decode", "(", "\n", "self", ",", "\n", "tokens", ":", "List", "[", "str", "]", ",", "\n", "top_k", ":", "int", "=", "100", ",", "\n", "max_text_len", ":", "int", "=", "100", ",", "\n", "user", ":", "int", "=", "0", ",", "\n", "nbest", ":", "int", "=", "1", ",", "\n", "softmax_temp", ":", "float", "=", "1.0", ",", "\n", "beam_width", ":", "int", "=", "10", ",", "\n", "beam_alpha", ":", "float", "=", "0.0", ",", "\n", "beam_beta", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "endnodes", "=", "[", "]", "\n", "\n", "node", "=", "BeamSearchNode", "(", "None", ",", "tokens", ",", "0", ",", "len", "(", "tokens", ")", ",", "beam_alpha", ",", "beam_beta", ")", "\n", "nodes", "=", "PriorityQueue", "(", ")", "\n", "\n", "nodes", ".", "put", "(", "node", ")", "# negative ll, node", "\n", "qsize", "=", "1", "\n", "\n", "while", "True", ":", "# decoding loop", "\n", "          ", "if", "qsize", ">", "2000", ":", "\n", "            ", "print", "(", "'Give up'", ")", "\n", "break", "# give up", "\n", "\n", "# fetch the best node", "\n", "", "_node", "=", "nodes", ".", "get", "(", ")", "\n", "\n", "# stop condition", "\n", "if", "_node", ".", "tokens", "[", "-", "1", "]", "==", "EOS_token", ":", "\n", "            ", "assert", "_node", ".", "prevNode", "!=", "None", "\n", "endnodes", ".", "append", "(", "_node", ")", "\n", "\n", "if", "len", "(", "endnodes", ")", ">=", "nbest", ":", "\n", "              ", "break", "\n", "", "else", ":", "\n", "              ", "continue", "\n", "\n", "# forward model", "\n", "", "", "log_probs", "=", "self", ".", "get_logprobs", "(", "_node", ".", "tokens", ",", "user", ",", "softmax_temp", ")", "\n", "\n", "# beam search start", "\n", "log_prob", ",", "indexes", "=", "torch", ".", "topk", "(", "log_probs", "[", "-", "1", ",", ":", "]", ",", "beam_width", ")", "\n", "nextnodes", "=", "[", "]", "\n", "for", "new_k", "in", "range", "(", "beam_width", ")", ":", "\n", "            ", "decoded_t", "=", "indexes", "[", "new_k", "]", ".", "item", "(", ")", "\n", "logp", "=", "log_prob", "[", "new_k", "]", ".", "item", "(", ")", "\n", "\n", "node", "=", "BeamSearchNode", "(", "\n", "_node", ",", "\n", "_node", ".", "tokens", "+", "[", "self", ".", "vocab", ".", "get_sym", "(", "decoded_t", ")", "]", ",", "\n", "_node", ".", "logp", "+", "logp", ",", "\n", "_node", ".", "leng", "+", "1", ",", "\n", "beam_alpha", ",", "\n", "beam_beta", ",", "\n", ")", "\n", "nextnodes", ".", "append", "(", "node", ")", "\n", "\n", "# enque nodes", "\n", "", "for", "i", "in", "range", "(", "len", "(", "nextnodes", ")", ")", ":", "\n", "            ", "nodes", ".", "put", "(", "nextnodes", "[", "i", "]", ")", "\n", "# increase qsize", "\n", "", "qsize", "+=", "len", "(", "nextnodes", ")", "-", "1", "\n", "\n", "# print([ str(_) for _ in nodes.queue[:5] ])", "\n", "# if nothing found", "\n", "", "if", "len", "(", "endnodes", ")", "==", "0", ":", "\n", "          ", "print", "(", "'Nothing found...use backoff prediction'", ")", "\n", "endnodes", ".", "append", "(", "nodes", ".", "get", "(", ")", ")", "\n", "\n", "", "return", "endnodes", "[", "0", "]", ".", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.greedy_next": [[261, 281], ["inference.ModelWrapper.get_logprobs", "[].item", "inference.ModelWrapper.vocab.get_sym", "log_probs[].double().exp", "top_indices[].item", "ValueError", "torch.argsort", "torch.argsort", "log_probs[].double", "torch.multinomial().item", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.get_logprobs", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "greedy_next", "(", "\n", "self", ",", "\n", "tokens", ":", "List", "[", "str", "]", ",", "\n", "top_k", ":", "int", "=", "100", ",", "\n", "user", ":", "int", "=", "0", ",", "\n", "sampling_strategy", ":", "str", "=", "'argmax'", ",", "\n", "softmax_temp", ":", "float", "=", "1.0", ",", "\n", ")", "->", "str", ":", "\n", "        ", "log_probs", "=", "self", ".", "get_logprobs", "(", "tokens", ",", "user", ",", "softmax_temp", ")", "\n", "log_probs", "=", "log_probs", "[", "-", "1", ",", ":", "]", "\n", "if", "sampling_strategy", "==", "'argmax'", ":", "\n", "            ", "sampled_idx", "=", "torch", ".", "argsort", "(", "log_probs", ")", "[", "-", "1", "]", ".", "item", "(", ")", "\n", "", "elif", "sampling_strategy", "==", "'multinomial'", ":", "\n", "            ", "top_indices", "=", "torch", ".", "argsort", "(", "log_probs", ")", "[", "-", "top_k", ":", "]", "\n", "top_probs", "=", "log_probs", "[", "top_indices", "]", ".", "double", "(", ")", ".", "exp", "(", ")", "\n", "sampled_idx", "=", "top_indices", "[", "torch", ".", "multinomial", "(", "top_probs", ",", "1", ")", ".", "item", "(", ")", "]", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported Sampling Method'", ")", "\n", "\n", "", "return", "self", ".", "vocab", ".", "get_sym", "(", "sampled_idx", ")", ",", "log_probs", "[", "sampled_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.greedy_decode": [[282, 298], ["inference.ModelWrapper.greedy_next", "tokens.append", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.greedy_next"], ["", "def", "greedy_decode", "(", "\n", "self", ",", "\n", "tokens", ":", "List", "[", "str", "]", ",", "\n", "top_k", ":", "int", "=", "100", ",", "\n", "max_text_len", ":", "int", "=", "100", ",", "\n", "user", ":", "int", "=", "0", ",", "\n", "sampling_strategy", ":", "str", "=", "'argmax'", ",", "\n", "softmax_temp", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "complete", "=", "False", "\n", "while", "len", "(", "tokens", ")", "<", "max_text_len", "and", "not", "complete", ":", "\n", "          ", "next_token", ",", "logprob", "=", "self", ".", "greedy_next", "(", "tokens", ",", "top_k", "=", "top_k", ",", "user", "=", "user", ",", "sampling_strategy", "=", "sampling_strategy", ",", "softmax_temp", "=", "softmax_temp", ")", "\n", "tokens", ".", "append", "(", "next_token", ")", "\n", "if", "EOS_token", "in", "next_token", ":", "complete", "=", "True", "\n", "\n", "", "return", "tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.preprocess_text": [[32, 50], ["outputs.lower.replace", "isinstance", "outputs.lower.decode", "unicodedata.normalize", "outputs.lower.lower", "inputs.strip().split", "inputs.strip", "unicodedata.combining"], "function", ["None"], ["def", "preprocess_text", "(", "inputs", ",", "lower", "=", "False", ",", "remove_space", "=", "True", ",", "keep_accents", "=", "False", ")", ":", "\n", "  ", "if", "remove_space", ":", "\n", "    ", "outputs", "=", "' '", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "    ", "outputs", "=", "inputs", "\n", "", "for", "src_str", ",", "dst_str", "in", "SUBSTITUTES", ":", "\n", "      ", "outputs", "=", "outputs", ".", "replace", "(", "src_str", ",", "dst_str", ")", "\n", "\n", "", "if", "six", ".", "PY2", "and", "isinstance", "(", "outputs", ",", "str", ")", ":", "\n", "    ", "outputs", "=", "outputs", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "", "if", "not", "keep_accents", ":", "\n", "    ", "outputs", "=", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "outputs", ")", "\n", "outputs", "=", "''", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "lower", ":", "\n", "    ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.ConfigEncoder.default": [[8, 20], ["isinstance", "json.JSONEncoder.default", "isinstance", "callable"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.ConfigEncoder.default"], ["    ", "def", "default", "(", "self", ",", "o", ")", ":", "\n", "        ", "if", "isinstance", "(", "o", ",", "type", ")", ":", "\n", "            ", "return", "{", "'$class'", ":", "o", ".", "__module__", "+", "\".\"", "+", "o", ".", "__name__", "}", "\n", "", "elif", "isinstance", "(", "o", ",", "Enum", ")", ":", "\n", "            ", "return", "{", "\n", "'$enum'", ":", "o", ".", "__module__", "+", "\".\"", "+", "o", ".", "__class__", ".", "__name__", "+", "'.'", "+", "o", ".", "name", "\n", "}", "\n", "", "elif", "callable", "(", "o", ")", ":", "\n", "            ", "return", "{", "\n", "'$function'", ":", "o", ".", "__module__", "+", "\".\"", "+", "o", ".", "__name__", "\n", "}", "\n", "", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "o", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.__init__": [[22, 34], ["logger.Logger.log_config", "collections.defaultdict", "os.join", "os.join", "tensorboardX.SummaryWriter", "vars", "os.join"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.log_config"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "log_dir", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "logger_path", "=", "osp", ".", "join", "(", "log_dir", ",", "'scalars.json'", ")", "if", "args", ".", "snapshot_dir", "is", "None", "else", "osp", ".", "join", "(", "log_dir", ",", "'scalars.resume.json'", ")", "\n", "self", ".", "use_tb_logger", "=", "args", ".", "use_tb_logger", "\n", "if", "self", ".", "use_tb_logger", ":", "\n", "            ", "self", ".", "tb_logger", "=", "SummaryWriter", "(", "\n", "log_dir", "=", "osp", ".", "join", "(", "log_dir", ",", "'tflogger'", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "self", ".", "log_config", "(", "vars", "(", "args", ")", ")", "\n", "\n", "self", ".", "scalars", "=", "defaultdict", "(", "OrderedDict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar": [[35, 40], ["logger.Logger.scalars[].get", "logger.Logger.tb_logger.add_scalar"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar"], ["", "def", "add_scalar", "(", "self", ",", "key", ",", "value", ",", "counter", ")", ":", "\n", "        ", "assert", "self", ".", "scalars", "[", "key", "]", ".", "get", "(", "counter", ",", "None", ")", "is", "None", ",", "'counter should be distinct'", "\n", "self", ".", "scalars", "[", "key", "]", "[", "counter", "]", "=", "value", "\n", "if", "self", ".", "use_tb_logger", ":", "\n", "            ", "self", ".", "tb_logger", ".", "add_scalar", "(", "key", ",", "value", ",", "counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.log_config": [[41, 45], ["os.join", "os.dirname", "open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.dump"], ["", "", "def", "log_config", "(", "self", ",", "variant_data", ")", ":", "\n", "        ", "config_filepath", "=", "osp", ".", "join", "(", "osp", ".", "dirname", "(", "self", ".", "logger_path", ")", ",", "'configs.json'", ")", "\n", "with", "open", "(", "config_filepath", ",", "\"w\"", ")", "as", "fd", ":", "\n", "            ", "json", ".", "dump", "(", "variant_data", ",", "fd", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ",", "cls", "=", "ConfigEncoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.dump": [[46, 49], ["open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.dump"], ["", "", "def", "dump", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "logger_path", ",", "'w'", ")", "as", "fd", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "scalars", ",", "fd", ",", "indent", "=", "2", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.configs.get_basic_parser": [[5, 128], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "get_basic_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Transformer Language Model'", ",", "add_help", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu0_bsz'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'batch size on gpu 0'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_layer'", ",", "type", "=", "int", ",", "default", "=", "12", ",", "\n", "help", "=", "'number of total layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_head'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'number of heads'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_head'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'head dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_embed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_user_embed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'user_embedding dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtl_depth'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'depth of the mtl model'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtl_width'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'width of the mtl model'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_model'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'model dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--d_inner'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'inner dimension in FF'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'global dropout rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropatt'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'attention probability dropout rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--init'", ",", "default", "=", "'normal'", ",", "type", "=", "str", ",", "\n", "help", "=", "'parameter initializer to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_init'", ",", "default", "=", "'normal'", ",", "type", "=", "str", ",", "\n", "help", "=", "'parameter initializer to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_range'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'parameters initialized by U(-init_range, init_range)'", ")", "\n", "parser", ".", "add_argument", "(", "'--emb_init_range'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'parameters initialized by U(-init_range, init_range)'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_std'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "\n", "help", "=", "'parameters initialized by N(0, init_std)'", ")", "\n", "parser", ".", "add_argument", "(", "'--proj_init_std'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "\n", "help", "=", "'parameters initialized by N(0, init_std)'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "default", "=", "'adam'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'adam'", ",", "'sgd'", ",", "'adagrad'", "]", ",", "\n", "help", "=", "'optimizer to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.00025", ",", "\n", "help", "=", "'initial learning rate (0.00025|5 for adam|sgd)'", ")", "\n", "parser", ".", "add_argument", "(", "'--mom'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'momentum for sgd'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduler'", ",", "default", "=", "'cosine'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'cosine'", ",", "'inv_sqrt'", ",", "'dev_perf'", ",", "'constant'", "]", ",", "\n", "help", "=", "'lr scheduler to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_step'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'upper epoch limit'", ")", "\n", "parser", ".", "add_argument", "(", "'--decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'decay factor when ReduceLROnPlateau is used'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_min'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'minimum learning rate during annealing'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "\n", "help", "=", "'gradient clipping'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_nonemb'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'only clip the gradient of non-embedding params'", ")", "\n", "parser", ".", "add_argument", "(", "'--parsimonious'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'parsimonious mtl params'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_step'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "'upper step limit'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "\n", "help", "=", "'the data chunk size. In continual learning, this is the rate of data arrival at each model learning step; In offline batch learning, this is the equivalent term to the mini-batch size of the model.'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_batch_size'", ",", "type", "=", "int", ",", "default", "=", "60", ",", "\n", "help", "=", "'evaluation batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_initial_model'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'evaluate the initialized model'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_chunk'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'split batch into chunks to save memory'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_seqlen'", ",", "type", "=", "int", ",", "default", "=", "280", ",", "\n", "help", "=", "'number of tokens to predict'", ")", "\n", "parser", ".", "add_argument", "(", "'--not_tied'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'do not tie the word embedding and softmax weights'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1111", ",", "\n", "help", "=", "'random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use CUDA'", ")", "\n", "parser", ".", "add_argument", "(", "'--varlen'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use variable length'", ")", "\n", "parser", ".", "add_argument", "(", "'--multi_gpu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use multiple GPU'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "\n", "help", "=", "'report interval'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval-interval'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'evaluation interval'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_dir'", ",", "default", "=", "'exp/LM'", ",", "type", "=", "str", ",", "\n", "help", "=", "'experiment directory.'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_class'", ",", "type", "=", "str", ",", "default", "=", "'MemTransformerLM'", ",", "\n", "choices", "=", "[", "'MTLMemTransformerLM'", ",", "'MemTransformerLM'", "]", ",", "\n", "help", "=", "'choose transformer model'", ")", "\n", "parser", ".", "add_argument", "(", "'--clamp_len'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'use the same pos embeddings after clamp_len'", ")", "\n", "parser", ".", "add_argument", "(", "'--eta_min'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'min learning rate for cosine scheduler'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_eval_steps'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'max eval steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--break_ratio'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'number of data to break down'", ")", "\n", "parser", ".", "add_argument", "(", "'--subword-augment'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'perform subword augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtl-type'", ",", "type", "=", "str", ",", "default", "=", "'layerwise'", ",", "\n", "choices", "=", "[", "'multi_encoder'", ",", "'multi_decoder'", ",", "'layerwise'", ",", "'all'", "]", ",", "\n", "help", "=", "'types of multitask learning architecture'", ")", "\n", "parser", ".", "add_argument", "(", "'--snapshot_dir'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'resume snapshot dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_weights'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'weights to init '", ")", "\n", "parser", ".", "add_argument", "(", "'--postfix'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'postfix of experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_tb_logger'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Turn on tensorboard logger.'", ")", "\n", "parser", ".", "add_argument", "(", "'--async_lr'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Smaller lr for backbone and larger lr for mtl.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'run in debug mode (do not create exp dir)'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'resume training from the saved checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'resume directory'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_online_fit'", ",", "action", "=", "'store_false'", ",", "\n", "help", "=", "'Evaluate online loss as metric for online fit.'", ")", "\n", "return", "parser", "\n", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.online.OnlineOnly.__init__": [[8, 32], ["next", "model.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "max_seqlen", "=", "args", ".", "max_seqlen", "\n", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.online.OnlineOnly.forward_eval": [[33, 41], ["online.OnlineOnly.model.eval", "online.OnlineOnly.model.train", "torch.no_grad", "online.OnlineOnly.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.online.OnlineOnly.forward": [[42, 88], ["tuple", "online.OnlineOnly.online_buffer.add_batch", "range", "online.OnlineOnly.forward_eval", "per_sample_loss.mean.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "online.OnlineOnly.online_buffer.sample_batch", "online.OnlineOnly.optimizer.zero_grad", "per_sample_loss.mean", "per_sample_loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "online.OnlineOnly.optimizer.step", "raw_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "core.dataset.utils.encap_batch", "online.OnlineOnly.para_model", "raw_loss.float().sum", "token_len.type_as", "online.OnlineOnly.model.parameters", "max", "per_sample_loss.mean.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.float", "len", "per_sample_loss.mean.float", "word_len.float", "token_len.float", "raw_loss.float", "word_len.float", "token_len.float"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "# Evaluate online batch.", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# input batch data", "\n", "", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "# * Optimize for k step on current dataset", "\n", "for", "k", "in", "range", "(", "self", ".", "max_k_steps", ")", ":", "\n", "# * Sample a batch of data from replay buffer", "\n", "            ", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "online_encodes", "[", ":", "5", "]", "\n", "\n", "# reset optimizer gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# decapsulate batch", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "per_sample_loss", "=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "total_loss", "=", "per_sample_loss", ".", "mean", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.base.Algorithm.__init__": [[4, 6], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.base.Algorithm.forward": [[7, 10], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.base.Algorithm.__call__": [[11, 13], ["base.Algorithm.forward"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.embeddings.PositionalEmbedding.forward"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.base.Algorithm.__str__": [[14, 16], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}()\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.replay.ReplayOnly.__init__": [[8, 34], ["next", "model.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.replay.ReplayOnly.forward_eval": [[35, 43], ["replay.ReplayOnly.model.eval", "replay.ReplayOnly.model.train", "torch.no_grad", "replay.ReplayOnly.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.replay.ReplayOnly.forward": [[44, 95], ["tuple", "replay.ReplayOnly.online_buffer.add_batch", "range", "replay.ReplayOnly.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "replay.ReplayOnly.replay_buffer.add_batch", "replay.ReplayOnly.replay_buffer.sample_batch", "replay.ReplayOnly.replay_buffer.sample_batch", "replay.ReplayOnly.optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "replay.ReplayOnly.optimizer.step", "raw_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "core.dataset.utils.encap_batch", "replay.ReplayOnly.para_model", "raw_loss.float().sum", "token_len.type_as", "replay.ReplayOnly.model.parameters", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.float", "len", "total_loss.float", "word_len.float", "token_len.float", "raw_loss.float", "word_len.float", "token_len.float"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "# Evaluate online batch.", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "# * Optimize for k step on current dataset", "\n", "", "for", "k", "in", "range", "(", "self", ".", "max_k_steps", ")", ":", "\n", "# * Sample a batch of data from replay buffer", "\n", "            ", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# reset optimizer gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", ",", "weights", "=", "replay_encodes", "[", ":", "6", "]", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "per_sample_loss", "=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "total_loss", "=", "(", "per_sample_loss", "*", "weights", ")", ".", "mean", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.agem.AGEM.__init__": [[33, 65], ["itertools.chain", "torch.zeros().to", "torch.zeros().to", "next", "agem.AGEM.grad_dims.append", "model.parameters", "param.data.numel", "torch.zeros", "torch.zeros", "model.word_emb.parameters", "model.layers.parameters", "model.mtl_layers.parameters", "sum", "sum"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ",", "para_model", ",", "optimizer", ",", "\n", "online_buffer", ",", "replay_buffer", ",", "args", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "# always use new data or not", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "# different parameter numbers", "\n", "model_params", "=", "itertools", ".", "chain", "(", "*", "[", "\n", "model", ".", "word_emb", ".", "parameters", "(", ")", ",", "\n", "model", ".", "layers", ".", "parameters", "(", ")", ",", "\n", "model", ".", "mtl_layers", ".", "parameters", "(", ")", ",", "\n", "]", ")", "\n", "\n", "for", "param", "in", "model_params", ":", "\n", "            ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "\n", "", "self", ".", "replay_grad", "=", "torch", ".", "zeros", "(", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "online_grad", "=", "torch", ".", "zeros", "(", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.agem.AGEM.forward_eval": [[66, 74], ["agem.AGEM.model.eval", "agem.AGEM.model.train", "torch.no_grad", "agem.AGEM.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.agem.AGEM.forward": [[75, 162], ["agem.AGEM.online_buffer.add_batch", "tuple", "list", "range", "agem.AGEM.replay_buffer.add_batch", "agem.AGEM.replay_buffer.sample_batch", "agem.AGEM.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "itertools.chain", "agem.AGEM.replay_buffer.sample_batch", "replay_psl.mean", "agem.AGEM.optimizer.zero_grad", "replay_psl.mean.backward", "agem.extract_grads", "agem.AGEM.online_buffer.sample_batch", "online_psl.mean", "agem.AGEM.optimizer.zero_grad", "online_psl.mean.backward", "agem.extract_grads", "torch.mm", "torch.nn.utils.clip_grad_norm_", "agem.AGEM.optimizer.step", "total_loss.sum().float().item", "word_len.sum().float().item", "token_len.sum().float().item", "core.dataset.utils.encap_batch", "agem.AGEM.para_model", "total_loss.sum", "token_len.type_as", "agem.AGEM.para_model", "total_loss.sum", "token_len.type_as", "agem.AGEM.online_grad.view", "agem.AGEM.replay_grad.view", "torch.mm.item", "torch.mm", "agem.AGEM.online_grad.copy_", "agem.overwrite_grad", "agem.AGEM.model.parameters", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "agem.AGEM.replay_grad.view", "agem.AGEM.replay_grad.view", "total_loss.sum().float", "word_len.sum().float", "token_len.sum().float", "agem.AGEM.model.word_emb.parameters", "agem.AGEM.model.layers.parameters", "agem.AGEM.model.mtl_layers.parameters", "len", "total_loss.float", "word_len.float", "token_len.float", "total_loss.sum", "word_len.sum", "token_len.sum", "torch.mm.item", "torch.mm.item"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.extract_grads", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.extract_grads", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.overwrite_grad", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "        ", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "# Skip optimization if in resume mode", "\n", "", "if", "skip_optim", ":", "return", "\n", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "mems", "=", "tuple", "(", ")", "\n", "model_params", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "\n", "self", ".", "model", ".", "word_emb", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "layers", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "mtl_layers", ".", "parameters", "(", ")", ",", "\n", "]", ")", ")", "\n", "\n", "# * Optimize for k step on current dataset", "\n", "for", "k", "in", "range", "(", "self", ".", "max_k_steps", ")", ":", "\n", "# Optimization on Replay Data", "\n", "            ", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "replay_encodes", "[", ":", "5", "]", "\n", "total_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "\n", "replay_psl", "=", "total_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "total_loss", ")", "\n", "replay_loss", "=", "replay_psl", ".", "mean", "(", ")", "\n", "\n", "# (*) Extract Replay Gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "replay_loss", ".", "backward", "(", ")", "\n", "extract_grads", "(", "model_params", ",", "self", ".", "replay_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "# * Sample a batch of data from replay buffer", "\n", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# decapsulate batch", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "online_encodes", "[", ":", "5", "]", "\n", "total_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "\n", "online_psl", "=", "total_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "total_loss", ")", "\n", "online_loss", "=", "online_psl", ".", "mean", "(", ")", "\n", "\n", "# (*) Extract Online Gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "online_loss", ".", "backward", "(", ")", "\n", "extract_grads", "(", "model_params", ",", "self", ".", "online_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "online_replay_dp", "=", "torch", ".", "mm", "(", "self", ".", "online_grad", ".", "view", "(", "1", ",", "-", "1", ")", ",", "self", ".", "replay_grad", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "if", "online_replay_dp", ".", "item", "(", ")", "<", "0", ":", "\n", "# constraint violation, next batch", "\n", "# reproject gradient when the constraint is violated", "\n", "                ", "replay_replay_dp", "=", "torch", ".", "mm", "(", "self", ".", "replay_grad", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "self", ".", "replay_grad", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "self", ".", "online_grad", ".", "copy_", "(", "self", ".", "online_grad", "-", "(", "online_replay_dp", ".", "item", "(", ")", "/", "replay_replay_dp", ".", "item", "(", ")", ")", "*", "self", ".", "replay_grad", ")", "\n", "overwrite_grad", "(", "model_params", ",", "self", ".", "online_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "# clip gradient norm", "\n", "", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "total_loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.agem.extract_grads": [[10, 19], ["grad.fill_", "sum", "grad[].copy_", "sum", "param.grad.data.view"], "function", ["None"], ["def", "extract_grads", "(", "params", ",", "grad", ",", "grad_dims", ")", ":", "\n", "    ", "grad", ".", "fill_", "(", "0", ")", "\n", "cnt", "=", "0", "\n", "for", "param", "in", "params", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "grad", "[", "beg", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.agem.overwrite_grad": [[20, 30], ["sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "function", ["None"], ["", "", "def", "overwrite_grad", "(", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "for", "param", "in", "params", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "en", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "beg", ":", "en", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.mr.MixedReplay.__init__": [[8, 34], ["next", "model.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", ",", "'prioritized'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.mr.MixedReplay.forward_eval": [[35, 43], ["mr.MixedReplay.model.eval", "mr.MixedReplay.model.train", "torch.no_grad", "mr.MixedReplay.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.mr.MixedReplay.forward": [[44, 109], ["tuple", "mr.MixedReplay.online_buffer.add_batch", "range", "mr.MixedReplay.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "mr.MixedReplay.replay_buffer.add_batch", "mr.MixedReplay.replay_buffer.sample_batch", "mr.MixedReplay.online_buffer.sample_batch", "mr.MixedReplay.replay_buffer.sample_batch", "zip", "mr.MixedReplay.optimizer.zero_grad", "total_loss.backward", "torch.nn.utils.clip_grad_norm_", "mr.MixedReplay.optimizer.step", "isinstance", "raw_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "core.dataset.utils.encap_batch", "online_encodes[].size", "batch_data.append", "mr.MixedReplay.para_model", "raw_loss.float().sum", "token_len.type_as", "mr.MixedReplay.model.parameters", "replay_encodes[].cpu().numpy", "mr.MixedReplay.replay_buffer.update_priorities", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "torch.cat", "per_sample_loss[].detach().cpu().numpy", "raw_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "len", "raw_loss.float", "replay_encodes[].cpu", "len", "total_loss.float", "word_len.float", "token_len.float", "per_sample_loss[].detach().cpu", "raw_loss.float", "word_len.float", "token_len.float", "per_sample_loss[].detach"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "# * Optimize for k step on current dataset", "\n", "", "for", "k", "in", "range", "(", "self", ".", "max_k_steps", ")", ":", "\n", "# * Sample a batch of data from replay buffer", "\n", "            ", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "self", ".", "device", ",", "online_encodes", "[", "0", "]", ".", "size", "(", "0", ")", ",", "\n", ")", "\n", "\n", "# * Use the union of online and replay data for a mini-batch", "\n", "batch_data", "=", "[", "]", "\n", "for", "online", ",", "replay", "in", "zip", "(", "online_encodes", ",", "replay_encodes", "[", ":", "len", "(", "online_encodes", ")", "]", ")", ":", "\n", "                ", "batch_data", ".", "append", "(", "torch", ".", "cat", "(", "[", "online", ",", "replay", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "# reset optimizer gradients", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# decapsulate batch", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", ",", "weights", ",", "_", "=", "batch_data", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "per_sample_loss", "=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "total_loss", "=", "(", "per_sample_loss", "*", "weights", ")", ".", "mean", "(", ")", "\n", "total_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# * Postprocess: prioritized experience replay sub-routines", "\n", "if", "isinstance", "(", "self", ".", "replay_buffer", ",", "PrioritizedBuffer", ")", ":", "\n", "                ", "indices", "=", "replay_encodes", "[", "-", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "priorities", "=", "per_sample_loss", "[", ":", ",", "self", ".", "online_bsz", ":", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "+", "1e-6", "\n", "self", ".", "replay_buffer", ".", "update_priorities", "(", "indices", ",", "priorities", ")", "\n", "\n", "# * Update global stats", "\n", "", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_online.ConGraD_OnlineOnly.__init__": [[10, 46], ["next", "itertools.chain", "model.parameters", "range", "range", "p.clone().detach", "p.clone"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "allow_zero_step", "=", "args", ".", "allow_zero_step", "\n", "\n", "self", ".", "param_groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "self", ".", "score_banks", "=", "[", "np", ".", "inf", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "self", ".", "model_banks", "=", "[", "[", "[", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "p", "in", "group", "[", "'params'", "]", "]", "for", "group", "in", "self", ".", "param_groups", "]", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "for", "model_bank", "in", "self", ".", "model_banks", ":", "\n", "            ", "for", "w", "in", "itertools", ".", "chain", "(", "*", "model_bank", ")", ":", "\n", "                ", "w", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_online.ConGraD_OnlineOnly.take_snapshot": [[47, 54], ["zip", "zip", "snapshot_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "take_snapshot", "(", "self", ",", "k", ",", "score", ")", ":", "\n", "# store model scores", "\n", "        ", "self", ".", "score_banks", "[", "k", "]", "=", "score", "\n", "# store snapshot weights", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "snapshot_weight", ".", "data", ".", "copy_", "(", "model_weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_online.ConGraD_OnlineOnly.resume_snapshot": [[55, 62], ["numpy.argmin", "zip", "zip", "model_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "resume_snapshot", "(", "self", ")", ":", "\n", "        ", "best_k", "=", "np", ".", "argmin", "(", "self", ".", "score_banks", ")", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "best_k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "model_weight", ".", "data", ".", "copy_", "(", "snapshot_weight", ".", "data", ")", "\n", "\n", "", "", "return", "best_k", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_online.ConGraD_OnlineOnly.forward_eval": [[63, 71], ["congrad_online.ConGraD_OnlineOnly.model.eval", "congrad_online.ConGraD_OnlineOnly.model.train", "torch.no_grad", "congrad_online.ConGraD_OnlineOnly.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_online.ConGraD_OnlineOnly.forward": [[72, 138], ["tuple", "congrad_online.ConGraD_OnlineOnly.online_buffer.add_batch", "congrad_online.ConGraD_OnlineOnly.online_buffer.sample_batch", "range", "congrad_online.ConGraD_OnlineOnly.resume_snapshot", "congrad_online.ConGraD_OnlineOnly.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "congrad_online.ConGraD_OnlineOnly.replay_buffer.add_batch", "congrad_online.ConGraD_OnlineOnly.replay_buffer.sample_batch", "congrad_online.ConGraD_OnlineOnly.forward_eval", "congrad_online.ConGraD_OnlineOnly.take_snapshot", "congrad_online.ConGraD_OnlineOnly.replay_buffer.sample_batch", "replay_psl.mean", "congrad_online.ConGraD_OnlineOnly.optimizer.zero_grad", "replay_psl.mean.backward", "torch.nn.utils.clip_grad_norm_", "congrad_online.ConGraD_OnlineOnly.optimizer.step", "congrad_online.ConGraD_OnlineOnly.forward_eval", "congrad_online.ConGraD_OnlineOnly.take_snapshot", "raw_loss.sum().float().item", "word_len.sum().float().item", "token_len.sum().float().item", "core.dataset.utils.encap_batch", "val_loss.sum().item", "congrad_online.ConGraD_OnlineOnly.para_model", "raw_loss.sum", "token_len.type_as", "congrad_online.ConGraD_OnlineOnly.model.parameters", "val_loss.sum().item", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.sum().float", "word_len.sum().float", "token_len.sum().float", "val_loss.sum", "val_loss.sum", "len", "total_loss.float", "word_len.float", "token_len.float", "raw_loss.sum", "word_len.sum", "token_len.sum"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.resume_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "return", "\n", "\n", "# Sample a cached (validation) batch for model selection", "\n", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# Snapshot Current Model", "\n", "if", "self", ".", "allow_zero_step", ":", "\n", "            ", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "0", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Optimize for k step on current dataset", "\n", "", "for", "k", "in", "range", "(", "1", ",", "self", ".", "max_k_steps", "+", "1", ")", ":", "\n", "# * Sample a batch of data from replay buffer", "\n", "            ", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "\n", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# decapsulate batch", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "replay_encodes", "[", ":", "5", "]", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "replay_psl", "=", "raw_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "replay_loss", "=", "replay_psl", ".", "mean", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "replay_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Take snapshot", "\n", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "k", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "\n", "# choose best snapshot based on current online measure", "\n", "", "best_k", "=", "self", ".", "resume_snapshot", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_mr.ConGraD_MixedReplay.__init__": [[10, 47], ["next", "itertools.chain", "model.parameters", "range", "range", "p.clone().detach", "p.clone"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "allow_zero_step", "=", "args", ".", "allow_zero_step", "\n", "\n", "self", ".", "param_groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "self", ".", "score_banks", "=", "[", "np", ".", "inf", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "self", ".", "model_banks", "=", "[", "[", "[", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "p", "in", "group", "[", "'params'", "]", "]", "for", "group", "in", "self", ".", "param_groups", "]", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "for", "model_bank", "in", "self", ".", "model_banks", ":", "\n", "            ", "for", "w", "in", "itertools", ".", "chain", "(", "*", "model_bank", ")", ":", "\n", "                ", "w", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_mr.ConGraD_MixedReplay.take_snapshot": [[48, 55], ["zip", "zip", "snapshot_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "take_snapshot", "(", "self", ",", "k", ",", "score", ")", ":", "\n", "# store model scores", "\n", "        ", "self", ".", "score_banks", "[", "k", "]", "=", "score", "\n", "# store snapshot weights", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "snapshot_weight", ".", "data", ".", "copy_", "(", "model_weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_mr.ConGraD_MixedReplay.resume_snapshot": [[56, 63], ["numpy.argmin", "zip", "zip", "model_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "resume_snapshot", "(", "self", ")", ":", "\n", "        ", "best_k", "=", "np", ".", "argmin", "(", "self", ".", "score_banks", ")", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "best_k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "model_weight", ".", "data", ".", "copy_", "(", "snapshot_weight", ".", "data", ")", "\n", "\n", "", "", "return", "best_k", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_mr.ConGraD_MixedReplay.forward_eval": [[64, 72], ["congrad_mr.ConGraD_MixedReplay.model.eval", "congrad_mr.ConGraD_MixedReplay.model.train", "torch.no_grad", "congrad_mr.ConGraD_MixedReplay.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_mr.ConGraD_MixedReplay.forward": [[73, 160], ["congrad_mr.ConGraD_MixedReplay.online_buffer.add_batch", "tuple", "congrad_mr.ConGraD_MixedReplay.online_buffer.sample_batch", "range", "congrad_mr.ConGraD_MixedReplay.resume_snapshot", "congrad_mr.ConGraD_MixedReplay.replay_buffer.add_batch", "congrad_mr.ConGraD_MixedReplay.replay_buffer.sample_batch", "congrad_mr.ConGraD_MixedReplay.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "congrad_mr.ConGraD_MixedReplay.forward_eval", "congrad_mr.ConGraD_MixedReplay.take_snapshot", "len", "replay_psl.mean", "congrad_mr.ConGraD_MixedReplay.optimizer.zero_grad", "replay_psl.mean.backward", "torch.nn.utils.clip_grad_norm_", "congrad_mr.ConGraD_MixedReplay.optimizer.step", "congrad_mr.ConGraD_MixedReplay.forward_eval", "congrad_mr.ConGraD_MixedReplay.take_snapshot", "raw_loss.sum().float().item", "word_len.sum().float().item", "token_len.sum().float().item", "core.dataset.utils.encap_batch", "val_loss.sum().item", "[].tolist", "core.dataset.utils.encap_batch", "congrad_mr.ConGraD_MixedReplay.replay_buffer.sample_batch", "zip", "congrad_mr.ConGraD_MixedReplay.replay_buffer.sample_batch", "congrad_mr.ConGraD_MixedReplay.para_model", "raw_loss.sum", "token_len.type_as", "congrad_mr.ConGraD_MixedReplay.model.parameters", "val_loss.sum().item", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "max", "retired_encodes[].size", "congrad_mr.ConGraD_MixedReplay.append", "raw_loss.sum().float", "word_len.sum().float", "token_len.sum().float", "val_loss.sum", "retired_encodes[].size", "torch.cat", "val_loss.sum", "len", "total_loss.float", "word_len.float", "token_len.float", "numpy.random.permutation", "len", "len", "raw_loss.sum", "word_len.sum", "token_len.sum", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.resume_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "        ", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "\n", "          ", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "", "if", "skip_optim", ":", "return", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "return", "\n", "\n", "mems", "=", "tuple", "(", ")", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Sample a cached (validation) batch for model selection", "\n", "", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# Snapshot Current Model", "\n", "if", "self", ".", "allow_zero_step", ":", "\n", "            ", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "0", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "retired_bsz", "=", "self", ".", "replay_bsz", "//", "2", "\n", "# * Optimize for k step on current dataset", "\n", "for", "k", "in", "range", "(", "1", ",", "self", ".", "max_k_steps", "+", "1", ")", ":", "\n", "            ", "if", "len", "(", "retired_batch", "[", "0", "]", ")", ":", "\n", "                ", "selected_data", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "retired_batch", "[", "0", "]", ")", ")", "[", ":", "retired_bsz", "]", ".", "tolist", "(", ")", "\n", "_retired_batch", "=", "[", "[", "_rbdata", "[", "selected_id", "]", "for", "selected_id", "in", "selected_data", "]", "for", "_rbdata", "in", "retired_batch", "]", "\n", "retired_encodes", "=", "encap_batch", "(", "_retired_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "_retired_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", "\n", "\n", "# * Sample a batch of data from replay buffer", "\n", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", "-", "retired_encodes", "[", "0", "]", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "device", ",", "retired_encodes", "[", "0", "]", ".", "size", "(", "0", ")", ",", "\n", ")", "\n", "\n", "batch_data", "=", "[", "]", "\n", "for", "online", ",", "replay", "in", "zip", "(", "retired_encodes", ",", "replay_encodes", "[", ":", "len", "(", "retired_encodes", ")", "]", ")", ":", "\n", "                    ", "batch_data", ".", "append", "(", "torch", ".", "cat", "(", "[", "online", ",", "replay", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "", "else", ":", "\n", "# print('Triggered')", "\n", "# * Sample a batch of data from replay buffer", "\n", "                ", "batch_data", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "\n", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# decapsulate batch", "\n", "", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "batch_data", "[", ":", "5", "]", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "replay_psl", "=", "raw_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "replay_loss", "=", "replay_psl", ".", "mean", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "replay_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Take snapshot", "\n", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "k", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "\n", "# choose best snapshot based on current online measure", "\n", "", "best_k", "=", "self", ".", "resume_snapshot", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_replay.ConGraD_ReplayOnly.__init__": [[10, 46], ["next", "itertools.chain", "model.parameters", "range", "range", "p.clone().detach", "p.clone"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "\n", "self", ".", "allow_zero_step", "=", "args", ".", "allow_zero_step", "\n", "\n", "self", ".", "param_groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "self", ".", "score_banks", "=", "[", "np", ".", "inf", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "self", ".", "model_banks", "=", "[", "[", "[", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "p", "in", "group", "[", "'params'", "]", "]", "for", "group", "in", "self", ".", "param_groups", "]", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "for", "model_bank", "in", "self", ".", "model_banks", ":", "\n", "            ", "for", "w", "in", "itertools", ".", "chain", "(", "*", "model_bank", ")", ":", "\n", "                ", "w", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_replay.ConGraD_ReplayOnly.take_snapshot": [[47, 54], ["zip", "zip", "snapshot_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "take_snapshot", "(", "self", ",", "k", ",", "score", ")", ":", "\n", "# store model scores", "\n", "        ", "self", ".", "score_banks", "[", "k", "]", "=", "score", "\n", "# store snapshot weights", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "snapshot_weight", ".", "data", ".", "copy_", "(", "model_weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_replay.ConGraD_ReplayOnly.resume_snapshot": [[55, 62], ["numpy.argmin", "zip", "zip", "model_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "resume_snapshot", "(", "self", ")", ":", "\n", "        ", "best_k", "=", "np", ".", "argmin", "(", "self", ".", "score_banks", ")", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "best_k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "model_weight", ".", "data", ".", "copy_", "(", "snapshot_weight", ".", "data", ")", "\n", "\n", "", "", "return", "best_k", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_replay.ConGraD_ReplayOnly.forward_eval": [[63, 71], ["congrad_replay.ConGraD_ReplayOnly.model.eval", "congrad_replay.ConGraD_ReplayOnly.model.train", "torch.no_grad", "congrad_replay.ConGraD_ReplayOnly.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_replay.ConGraD_ReplayOnly.forward": [[72, 138], ["tuple", "congrad_replay.ConGraD_ReplayOnly.online_buffer.add_batch", "congrad_replay.ConGraD_ReplayOnly.online_buffer.sample_batch", "range", "congrad_replay.ConGraD_ReplayOnly.resume_snapshot", "congrad_replay.ConGraD_ReplayOnly.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "congrad_replay.ConGraD_ReplayOnly.replay_buffer.add_batch", "congrad_replay.ConGraD_ReplayOnly.replay_buffer.sample_batch", "congrad_replay.ConGraD_ReplayOnly.forward_eval", "congrad_replay.ConGraD_ReplayOnly.take_snapshot", "congrad_replay.ConGraD_ReplayOnly.replay_buffer.sample_batch", "replay_psl.mean", "congrad_replay.ConGraD_ReplayOnly.optimizer.zero_grad", "replay_psl.mean.backward", "torch.nn.utils.clip_grad_norm_", "congrad_replay.ConGraD_ReplayOnly.optimizer.step", "congrad_replay.ConGraD_ReplayOnly.forward_eval", "congrad_replay.ConGraD_ReplayOnly.take_snapshot", "raw_loss.sum().float().item", "word_len.sum().float().item", "token_len.sum().float().item", "core.dataset.utils.encap_batch", "val_loss.sum().item", "congrad_replay.ConGraD_ReplayOnly.para_model", "raw_loss.sum", "token_len.type_as", "congrad_replay.ConGraD_ReplayOnly.model.parameters", "val_loss.sum().item", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "raw_loss.sum().float", "word_len.sum().float", "token_len.sum().float", "val_loss.sum", "val_loss.sum", "len", "total_loss.float", "word_len.float", "token_len.float", "raw_loss.sum", "word_len.sum", "token_len.sum"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.resume_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "return", "\n", "\n", "# Sample a cached (validation) batch for model selection", "\n", "online_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# Snapshot Current Model", "\n", "if", "self", ".", "allow_zero_step", ":", "\n", "            ", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "0", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Optimize for k step on current dataset", "\n", "", "for", "k", "in", "range", "(", "1", ",", "self", ".", "max_k_steps", "+", "1", ")", ":", "\n", "# * Sample a batch of data from replay buffer", "\n", "            ", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "self", ".", "replay_bsz", ",", "\n", "self", ".", "device", ",", "\n", ")", "\n", "\n", "# decapsulate batch", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "replay_encodes", "[", ":", "5", "]", "\n", "raw_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "replay_psl", "=", "raw_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "raw_loss", ")", "\n", "\n", "replay_loss", "=", "replay_psl", ".", "mean", "(", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "replay_loss", ".", "backward", "(", ")", "\n", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Take snapshot", "\n", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "online_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "k", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "raw_loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "\n", "# choose best snapshot based on current online measure", "\n", "", "best_k", "=", "self", ".", "resume_snapshot", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.__init__": [[32, 82], ["itertools.chain", "torch.zeros().to", "torch.zeros().to", "next", "congrad_agem.ConGraD_AGEM.grad_dims.append", "itertools.chain", "model.parameters", "param.data.numel", "torch.zeros", "torch.zeros", "range", "range", "model.word_emb.parameters", "model.layers.parameters", "model.mtl_layers.parameters", "sum", "sum", "p.clone().detach", "p.clone"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "para_model", ",", "\n", "optimizer", ",", "\n", "online_buffer", ",", "\n", "replay_buffer", ",", "\n", "args", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "online_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "assert", "args", ".", "replay_buffer_strategy", "in", "{", "'greedy'", ",", "'stratified'", ",", "'reservoir'", "}", "\n", "\n", "self", ".", "eval_online_fit", "=", "args", ".", "eval_online_fit", "# always use new data or not", "\n", "self", ".", "clip_value", "=", "args", ".", "clip", "\n", "self", ".", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "para_model", "=", "para_model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "max_k_steps", "=", "args", ".", "max_k_steps", "\n", "\n", "self", ".", "online_buffer", "=", "online_buffer", "\n", "self", ".", "replay_buffer", "=", "replay_buffer", "\n", "self", ".", "online_bsz", "=", "args", ".", "online_batch_size", "\n", "self", ".", "replay_bsz", "=", "args", ".", "replay_batch_size", "\n", "\n", "self", ".", "grad_dims", "=", "[", "]", "\n", "# different parameter numbers", "\n", "model_params", "=", "itertools", ".", "chain", "(", "*", "[", "\n", "model", ".", "word_emb", ".", "parameters", "(", ")", ",", "\n", "model", ".", "layers", ".", "parameters", "(", ")", ",", "\n", "model", ".", "mtl_layers", ".", "parameters", "(", ")", ",", "\n", "]", ")", "\n", "\n", "for", "param", "in", "model_params", ":", "\n", "            ", "self", ".", "grad_dims", ".", "append", "(", "param", ".", "data", ".", "numel", "(", ")", ")", "\n", "\n", "", "self", ".", "replay_grad", "=", "torch", ".", "zeros", "(", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "online_grad", "=", "torch", ".", "zeros", "(", "sum", "(", "self", ".", "grad_dims", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "allow_zero_step", "=", "args", ".", "allow_zero_step", "\n", "\n", "self", ".", "param_groups", "=", "self", ".", "optimizer", ".", "param_groups", "\n", "self", ".", "score_banks", "=", "[", "np", ".", "inf", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "self", ".", "model_banks", "=", "[", "[", "[", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "p", "in", "group", "[", "'params'", "]", "]", "for", "group", "in", "self", ".", "param_groups", "]", "for", "i", "in", "range", "(", "args", ".", "max_k_steps", "+", "1", ")", "]", "\n", "for", "model_bank", "in", "self", ".", "model_banks", ":", "\n", "            ", "for", "w", "in", "itertools", ".", "chain", "(", "*", "model_bank", ")", ":", "\n", "                ", "w", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot": [[83, 90], ["zip", "zip", "snapshot_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "take_snapshot", "(", "self", ",", "k", ",", "score", ")", ":", "\n", "# store model scores", "\n", "        ", "self", ".", "score_banks", "[", "k", "]", "=", "score", "\n", "# store snapshot weights", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "snapshot_weight", ".", "data", ".", "copy_", "(", "model_weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.resume_snapshot": [[91, 98], ["numpy.argmin", "zip", "zip", "model_weight.data.copy_"], "methods", ["None"], ["", "", "", "def", "resume_snapshot", "(", "self", ")", ":", "\n", "        ", "best_k", "=", "np", ".", "argmin", "(", "self", ".", "score_banks", ")", "\n", "for", "snapshot_weights", ",", "model_weights", "in", "zip", "(", "self", ".", "model_banks", "[", "best_k", "]", ",", "self", ".", "param_groups", ")", ":", "\n", "            ", "for", "snapshot_weight", ",", "model_weight", "in", "zip", "(", "snapshot_weights", ",", "model_weights", "[", "'params'", "]", ")", ":", "\n", "                ", "model_weight", ".", "data", ".", "copy_", "(", "snapshot_weight", ".", "data", ")", "\n", "\n", "", "", "return", "best_k", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval": [[99, 107], ["congrad_agem.ConGraD_AGEM.model.eval", "congrad_agem.ConGraD_AGEM.model.train", "torch.no_grad", "congrad_agem.ConGraD_AGEM.para_model", "tuple"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train"], ["", "def", "forward_eval", "(", "self", ",", "data_encodes", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "data_encodes", "[", ":", "5", "]", "\n", "online_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "tuple", "(", ")", ")", "[", "0", "]", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "online_loss", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward": [[108, 209], ["tuple", "congrad_agem.ConGraD_AGEM.online_buffer.add_batch", "tuple", "list", "congrad_agem.ConGraD_AGEM.online_buffer.sample_batch", "range", "congrad_agem.ConGraD_AGEM.resume_snapshot", "congrad_agem.ConGraD_AGEM.forward_eval", "total_loss.float().sum().item", "word_len.float().sum().item", "token_len.float().sum().item", "congrad_agem.ConGraD_AGEM.replay_buffer.add_batch", "congrad_agem.ConGraD_AGEM.replay_buffer.sample_batch", "itertools.chain", "congrad_agem.ConGraD_AGEM.forward_eval", "congrad_agem.ConGraD_AGEM.take_snapshot", "congrad_agem.ConGraD_AGEM.replay_buffer.sample_batch", "replay_psl.mean", "congrad_agem.ConGraD_AGEM.optimizer.zero_grad", "replay_psl.mean.backward", "congrad_agem.extract_grads", "[].tolist", "core.dataset.utils.encap_batch", "online_psl.mean", "congrad_agem.ConGraD_AGEM.optimizer.zero_grad", "online_psl.mean.backward", "congrad_agem.extract_grads", "torch.mm", "torch.nn.utils.clip_grad_norm_", "congrad_agem.ConGraD_AGEM.optimizer.step", "congrad_agem.ConGraD_AGEM.forward_eval", "congrad_agem.ConGraD_AGEM.take_snapshot", "total_loss.sum().float().item", "word_len.sum().float().item", "token_len.sum().float().item", "core.dataset.utils.encap_batch", "val_loss.sum().item", "congrad_agem.ConGraD_AGEM.para_model", "total_loss.sum", "token_len.type_as", "max", "congrad_agem.ConGraD_AGEM.para_model", "total_loss.sum", "token_len.type_as", "congrad_agem.ConGraD_AGEM.online_grad.view", "congrad_agem.ConGraD_AGEM.replay_grad.view", "torch.mm.item", "torch.mm", "congrad_agem.ConGraD_AGEM.online_grad.copy_", "congrad_agem.overwrite_grad", "congrad_agem.ConGraD_AGEM.model.parameters", "val_loss.sum().item", "max", "total_loss.float().sum", "word_len.float().sum", "token_len.float().sum", "congrad_agem.ConGraD_AGEM.replay_grad.view", "congrad_agem.ConGraD_AGEM.replay_grad.view", "total_loss.sum().float", "word_len.sum().float", "token_len.sum().float", "congrad_agem.ConGraD_AGEM.model.word_emb.parameters", "congrad_agem.ConGraD_AGEM.model.layers.parameters", "congrad_agem.ConGraD_AGEM.model.mtl_layers.parameters", "val_loss.sum", "numpy.random.permutation", "len", "val_loss.sum", "len", "total_loss.float", "word_len.float", "token_len.float", "len", "total_loss.sum", "word_len.sum", "token_len.sum", "torch.mm.item", "torch.mm.item"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.resume_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.extract_grads", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.extract_grads", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.forward_eval", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.ConGraD_AGEM.take_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.overwrite_grad", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "mems", "=", "tuple", "(", ")", "\n", "if", "not", "self", ".", "eval_online_fit", ":", "\n", "            ", "stats", "[", "'online_loss'", "]", "+=", "0", "\n", "stats", "[", "'online_word_count'", "]", "+=", "1e-20", "\n", "stats", "[", "'online_token_count'", "]", "+=", "1e-20", "\n", "", "else", ":", "\n", "# Evaluate online batch.", "\n", "            ", "total_loss", ",", "token_len", ",", "word_len", "=", "self", ".", "forward_eval", "(", "\n", "encap_batch", "(", "online_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "online_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", ",", "\n", ")", "\n", "\n", "stats", "[", "'online_loss'", "]", "+=", "total_loss", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_word_count'", "]", "+=", "word_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'online_token_count'", "]", "+=", "token_len", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Update buffer: add online data stream into replay buffer", "\n", "", "retired_batch", "=", "self", ".", "online_buffer", ".", "add_batch", "(", "*", "online_batch", ")", "\n", "if", "retired_batch", "is", "not", "None", ":", "self", ".", "replay_buffer", ".", "add_batch", "(", "*", "retired_batch", ")", "\n", "\n", "# Start training only after replay buffer has data", "\n", "if", "self", ".", "replay_buffer", ".", "sample_batch", "(", "self", ".", "replay_bsz", ",", "self", ".", "device", ")", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "mems", "=", "tuple", "(", ")", "\n", "model_params", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "\n", "self", ".", "model", ".", "word_emb", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "layers", ".", "parameters", "(", ")", ",", "\n", "self", ".", "model", ".", "mtl_layers", ".", "parameters", "(", ")", ",", "\n", "]", ")", ")", "\n", "\n", "# Sample a cached (validation) batch for model selection", "\n", "val_encodes", "=", "self", ".", "online_buffer", ".", "sample_batch", "(", "\n", "self", ".", "online_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "# Snapshot Current Model", "\n", "if", "self", ".", "allow_zero_step", ":", "\n", "            ", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "val_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "0", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "retired_bsz", "=", "self", ".", "replay_bsz", "//", "2", "\n", "# * Optimize for k step on current dataset", "\n", "for", "k", "in", "range", "(", "1", ",", "self", ".", "max_k_steps", "+", "1", ")", ":", "\n", "# Optimization on Replay Data", "\n", "            ", "replay_encodes", "=", "self", ".", "replay_buffer", ".", "sample_batch", "(", "\n", "retired_bsz", ",", "self", ".", "device", ",", "\n", ")", "\n", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "replay_encodes", "[", ":", "5", "]", "\n", "total_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "\n", "replay_psl", "=", "total_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "total_loss", ")", "\n", "replay_loss", "=", "replay_psl", ".", "mean", "(", ")", "\n", "\n", "# (*) Extract Replay Gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "replay_loss", ".", "backward", "(", ")", "\n", "extract_grads", "(", "model_params", ",", "self", ".", "replay_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "selected_data", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "retired_batch", "[", "0", "]", ")", ")", "[", ":", "retired_bsz", "]", ".", "tolist", "(", ")", "\n", "_retired_batch", "=", "[", "[", "_rbdata", "[", "selected_id", "]", "for", "selected_id", "in", "selected_data", "]", "for", "_rbdata", "in", "retired_batch", "]", "\n", "online_encodes", "=", "encap_batch", "(", "_retired_batch", ",", "max", "(", "[", "len", "(", "_", ")", "for", "_", "in", "_retired_batch", "[", "0", "]", "]", ")", ",", "self", ".", "device", ")", "\n", "\n", "# decapsulate batch", "\n", "data", ",", "target", ",", "users", ",", "token_len", ",", "word_len", "=", "online_encodes", "[", ":", "5", "]", "\n", "total_loss", "=", "self", ".", "para_model", "(", "data", ",", "target", ",", "users", ",", "*", "mems", ")", "[", "0", "]", "\n", "\n", "online_psl", "=", "total_loss", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "/", "token_len", ".", "type_as", "(", "total_loss", ")", "\n", "online_loss", "=", "online_psl", ".", "mean", "(", ")", "\n", "\n", "# (*) Extract Online Gradients", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "online_loss", ".", "backward", "(", ")", "\n", "extract_grads", "(", "model_params", ",", "self", ".", "online_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "online_replay_dp", "=", "torch", ".", "mm", "(", "self", ".", "online_grad", ".", "view", "(", "1", ",", "-", "1", ")", ",", "self", ".", "replay_grad", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "if", "online_replay_dp", ".", "item", "(", ")", "<", "0", ":", "\n", "# constraint violation, next batch", "\n", "# reproject gradient when the constraint is violated", "\n", "                ", "replay_replay_dp", "=", "torch", ".", "mm", "(", "self", ".", "replay_grad", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "self", ".", "replay_grad", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "self", ".", "online_grad", ".", "copy_", "(", "self", ".", "online_grad", "-", "(", "online_replay_dp", ".", "item", "(", ")", "/", "replay_replay_dp", ".", "item", "(", ")", ")", "*", "self", ".", "replay_grad", ")", "\n", "overwrite_grad", "(", "model_params", ",", "self", ".", "online_grad", ",", "self", ".", "grad_dims", ")", "\n", "\n", "# clip gradient norm", "\n", "", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "clip_value", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Take snapshot", "\n", "val_loss", ",", "_", ",", "_", "=", "self", ".", "forward_eval", "(", "val_encodes", ")", "\n", "self", ".", "take_snapshot", "(", "k", ",", "val_loss", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# * Update global stats", "\n", "stats", "[", "'num_updates'", "]", "+=", "1", "\n", "stats", "[", "'total_loss'", "]", "+=", "total_loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_word_count'", "]", "+=", "word_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "'total_token_count'", "]", "+=", "token_len", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "\n", "# choose best snapshot based on current online measure", "\n", "", "best_k", "=", "self", ".", "resume_snapshot", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.extract_grads": [[9, 18], ["grad.fill_", "sum", "grad[].copy_", "sum", "param.grad.data.view"], "function", ["None"], ["def", "extract_grads", "(", "params", ",", "grad", ",", "grad_dims", ")", ":", "\n", "    ", "grad", ".", "fill_", "(", "0", ")", "\n", "cnt", "=", "0", "\n", "for", "param", "in", "params", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "end", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "grad", "[", "beg", ":", "end", "]", ".", "copy_", "(", "param", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.algos.congrad_agem.overwrite_grad": [[19, 29], ["sum", "newgrad[].contiguous().view", "param.grad.data.copy_", "sum", "param.grad.data.size", "newgrad[].contiguous"], "function", ["None"], ["", "", "def", "overwrite_grad", "(", "params", ",", "newgrad", ",", "grad_dims", ")", ":", "\n", "    ", "cnt", "=", "0", "\n", "for", "param", "in", "params", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "beg", "=", "0", "if", "cnt", "==", "0", "else", "sum", "(", "grad_dims", "[", ":", "cnt", "]", ")", "\n", "en", "=", "sum", "(", "grad_dims", "[", ":", "cnt", "+", "1", "]", ")", "\n", "this_grad", "=", "newgrad", "[", "beg", ":", "en", "]", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "param", ".", "grad", ".", "data", ".", "size", "(", ")", ")", "\n", "param", ".", "grad", ".", "data", ".", "copy_", "(", "this_grad", ")", "\n", "", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.__init__": [[55, 63], ["sentencepiece.SentencePieceProcessor", "vocabulary.Vocab.sp_model.Load", "vocabulary.Vocab.sp_model.SetEncodeExtraOptions"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab_file", ",", "cased", "=", "False", ",", "small", "=", "False", ",", "prepend_bos", "=", "False", ")", ":", "\n", "        ", "self", ".", "cased", "=", "cased", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n", "if", "prepend_bos", ":", "\n", "          ", "self", ".", "sp_model", ".", "SetEncodeExtraOptions", "(", "\"bos\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_symbols": [[64, 67], ["vocabulary.encode_pieces", "sent.lower.lower.lower"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.encode_pieces"], ["", "", "def", "encode_as_symbols", "(", "self", ",", "sent", ",", "sample", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "cased", ":", "sent", "=", "sent", ".", "lower", "(", ")", "\n", "return", "encode_pieces", "(", "self", ".", "sp_model", ",", "sent", ",", "sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids": [[68, 71], ["vocabulary.Vocab.encode_as_symbols", "vocabulary.Vocab.get_indices"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_symbols", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_indices"], ["", "def", "encode_as_ids", "(", "self", ",", "sent", ",", "sample", "=", "False", ")", ":", "\n", "        ", "sentpiece", ",", "wordend", "=", "self", ".", "encode_as_symbols", "(", "sent", ",", "sample", ")", "\n", "return", "self", ".", "get_indices", "(", "sentpiece", ")", ",", "wordend", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_sents_as_ids": [[72, 81], ["vocabulary.Vocab.encode_sents_as_symbols", "encoded.append", "encoded_wordends.append", "vocabulary.Vocab.get_indices"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_sents_as_symbols", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_indices"], ["", "def", "encode_sents_as_ids", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "sentpieces", "=", "self", ".", "encode_sents_as_symbols", "(", "sents", ",", "verbose", ")", "\n", "encoded", "=", "[", "]", "\n", "encoded_wordends", "=", "[", "]", "\n", "for", "sentpiece", ",", "wordend", "in", "sentpieces", ":", "\n", "            ", "encoded", ".", "append", "(", "self", ".", "get_indices", "(", "sentpiece", ")", ")", "\n", "encoded_wordends", ".", "append", "(", "wordend", ")", "\n", "\n", "", "return", "encoded", ",", "encoded_wordends", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_sents_as_symbols": [[82, 89], ["print", "encoded.append", "vocabulary.Vocab.encode_as_symbols", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_symbols"], ["", "def", "encode_sents_as_symbols", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "print", "(", "'encoding {} sents ...'", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "encoded", "=", "[", "]", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "encoded", ".", "append", "(", "self", ".", "encode_as_symbols", "(", "sent", ")", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.load_file": [[90, 101], ["torch.load", "tqdm.tqdm.tqdm", "iter", "data.append", "users.append"], "methods", ["None"], ["", "def", "load_file", "(", "self", ",", "filepath", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "input_data", "=", "torch", ".", "load", "(", "filepath", ")", "\n", "iterator", "=", "tqdm", "(", "input_data", ",", "ncols", "=", "64", ")", "if", "verbose", "else", "iter", "(", "input_data", ")", "\n", "\n", "data", "=", "[", "]", "\n", "users", "=", "[", "]", "\n", "for", "data_item", "in", "iterator", ":", "\n", "            ", "data", ".", "append", "(", "data_item", "[", "-", "1", "]", ")", "\n", "users", ".", "append", "(", "data_item", "[", "0", "]", ")", "\n", "\n", "", "return", "data", ",", "users", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_file": [[102, 114], ["torch.load", "tqdm.tqdm.tqdm", "iter", "data.append", "users.append", "vocabulary.Vocab.encode_as_ids"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids"], ["", "def", "encode_file", "(", "self", ",", "filepath", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "input_data", "=", "torch", ".", "load", "(", "filepath", ")", "\n", "iterator", "=", "tqdm", "(", "input_data", ",", "ncols", "=", "64", ")", "if", "verbose", "else", "iter", "(", "input_data", ")", "\n", "\n", "data", "=", "[", "]", "\n", "users", "=", "[", "]", "\n", "for", "data_item", "in", "iterator", ":", "\n", "            ", "sent", "=", "data_item", "[", "-", "1", "]", "\n", "data", ".", "append", "(", "self", ".", "encode_as_ids", "(", "sent", ")", ")", "\n", "users", ".", "append", "(", "data_item", "[", "0", "]", ")", "\n", "\n", "", "return", "data", ",", "users", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym": [[115, 118], ["vocabulary.Vocab.sp_model.IdToPiece", "len"], "methods", ["None"], ["", "def", "get_sym", "(", "self", ",", "idx", ")", ":", "\n", "        ", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "'Index {} out of range'", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "sp_model", ".", "IdToPiece", "(", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_idx": [[119, 121], ["vocabulary.Vocab.sp_model.PieceToId"], "methods", ["None"], ["", "def", "get_idx", "(", "self", ",", "sym", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_symbols": [[122, 124], ["vocabulary.Vocab.get_sym"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym"], ["", "def", "get_symbols", "(", "self", ",", "indices", ")", ":", "\n", "        ", "return", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_indices": [[125, 127], ["vocabulary.Vocab.get_idx"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_idx"], ["", "def", "get_indices", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "[", "self", ".", "get_idx", "(", "sym", ")", "for", "sym", "in", "symbols", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.convert_to_tensor": [[128, 130], ["torch.LongTensor"], "methods", ["None"], ["", "def", "convert_to_tensor", "(", "self", ",", "ids", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.convert_to_sent": [[131, 138], ["vocabulary.Vocab.sp_model.DecodePieces", "vocabulary.Vocab.get_sym", "vocabulary.Vocab.get_sym"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.get_sym"], ["", "def", "convert_to_sent", "(", "self", ",", "indices", ",", "exclude", "=", "None", ")", ":", "\n", "        ", "if", "exclude", "is", "None", ":", "\n", "            ", "pieces", "=", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "]", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "[", "self", ".", "get_sym", "(", "idx", ")", "for", "idx", "in", "indices", "if", "idx", "not", "in", "exclude", "]", "\n", "\n", "", "return", "self", ".", "sp_model", ".", "DecodePieces", "(", "pieces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.decode_pieces": [[139, 141], ["vocabulary.Vocab.sp_model.DecodePieces"], "methods", ["None"], ["", "def", "decode_pieces", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "DecodePieces", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.__len__": [[142, 144], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary._tokenize": [[13, 15], ["TOKENIZER.tokenize"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.inference.ModelWrapper.tokenize"], ["def", "_tokenize", "(", "text", ")", ":", "\n", "    ", "return", "TOKENIZER", ".", "tokenize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary._is_start_piece": [[16, 23], ["set", "list", "piece.startswith", "piece.startswith"], "function", ["None"], ["", "def", "_is_start_piece", "(", "piece", ")", ":", "\n", "  ", "special_pieces", "=", "set", "(", "list", "(", "'!\"#$%&\\\"()*+,-./:;?@[\\\\]^_`{|}~'", ")", ")", "\n", "if", "(", "piece", ".", "startswith", "(", "\"\u2581\"", ")", "or", "piece", ".", "startswith", "(", "\"<\"", ")", "\n", "or", "piece", "in", "special_pieces", ")", ":", "\n", "    ", "return", "True", "\n", "", "else", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.encode_pieces": [[25, 53], ["sp_model.EncodeAsPieces", "sp_model.SampleEncodeAsPieces", "vocabulary._is_start_piece", "piece[].isdigit", "sp_model.EncodeAsPieces", "sp_model.EncodeAsPieces.append", "new_pieces.extend", "new_pieces.append", "new_wordends.append", "new_wordends.append", "len", "piece[].replace", "len"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary._is_start_piece"], ["", "", "def", "encode_pieces", "(", "sp_model", ",", "text", ",", "sample", "=", "False", ")", ":", "\n", "    ", "if", "not", "sample", ":", "\n", "        ", "pieces", "=", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "        ", "pieces", "=", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "new_wordends", "=", "[", "]", "\n", "word_cnt", "=", "0", "\n", "for", "piece", "in", "pieces", ":", "\n", "        ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "','", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "            ", "cur_pieces", "=", "sp_model", ".", "EncodeAsPieces", "(", "\n", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "''", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                    ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                    ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "            ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "", "if", "_is_start_piece", "(", "new_pieces", "[", "-", "1", "]", ")", ":", "\n", "            ", "new_wordends", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "new_wordends", ".", "append", "(", "0", ")", "\n", "\n", "", "", "return", "new_pieces", ",", "new_wordends", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.__init__": [[21, 34], ["kwargs.get", "core.dataset.vocabulary.Vocab", "print", "time.time", "os.path.join", "corpus.Corpus._create_datastruct", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus._create_datastruct"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "dataset", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "cased", "=", "kwargs", ".", "get", "(", "'cased'", ",", "False", ")", "\n", "self", ".", "vocab", "=", "Vocab", "(", "*", "args", ",", "prepend_bos", "=", "True", ",", "**", "kwargs", ")", "\n", "self", ".", "vocab_file", "=", "kwargs", "[", "'vocab_file'", "]", "\n", "\n", "assert", "self", ".", "dataset", "in", "VALID_DATASET", "\n", "print", "(", "'Loading dataset {}...'", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "data_tm", "=", "time", ".", "time", "(", ")", "\n", "infile_template", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"{}.\"", "+", "\"{}.pt\"", ".", "format", "(", "\n", "'cased'", "if", "self", ".", "cased", "else", "'uncased'", ")", ")", "\n", "self", ".", "_create_datastruct", "(", "self", ".", "vocab", ".", "load_file", ",", "infile_template", ")", "\n", "print", "(", "'Done. ({:.2f} sec)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "data_tm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus._create_datastruct": [[35, 47], ["load_fn", "load_fn", "load_fn", "infile_template.format", "infile_template.format", "infile_template.format", "enumerate", "corpus.Corpus.user_dict.items", "set"], "methods", ["None"], ["", "def", "_create_datastruct", "(", "self", ",", "load_fn", ",", "infile_template", ")", ":", "\n", "        ", "self", ".", "train_data", ",", "self", ".", "train_users", "=", "load_fn", "(", "infile_template", ".", "format", "(", "\"train\"", ")", ")", "\n", "self", ".", "val_data", ",", "self", ".", "val_users", "=", "load_fn", "(", "infile_template", ".", "format", "(", "\"val\"", ")", ")", "\n", "self", ".", "test_data", ",", "self", ".", "test_users", "=", "load_fn", "(", "infile_template", ".", "format", "(", "\"test\"", ")", ")", "\n", "\n", "self", ".", "user_dict", "=", "{", "user", ":", "uid", "for", "uid", ",", "user", "in", "enumerate", "(", "set", "(", "self", ".", "train_users", "+", "self", ".", "val_users", "+", "self", ".", "test_users", ")", ")", "}", "\n", "self", ".", "user_idict", "=", "{", "uid", ":", "user", "for", "user", ",", "uid", "in", "self", ".", "user_dict", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "train_users", "=", "[", "self", ".", "user_dict", "[", "_", "]", "for", "_", "in", "self", ".", "train_users", "]", "\n", "self", ".", "val_users", "=", "[", "self", ".", "user_dict", "[", "_", "]", "for", "_", "in", "self", ".", "val_users", "]", "\n", "self", ".", "test_users", "=", "[", "self", ".", "user_dict", "[", "_", "]", "for", "_", "in", "self", ".", "test_users", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.get_iterator": [[48, 62], ["getattr", "getattr", "eval", "eval."], "methods", ["None"], ["", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "iterator_name", "=", "'LMBatchIterator'", ",", "**", "kwargs", ")", ":", "\n", "        ", "data", "=", "getattr", "(", "self", ",", "'{}_data'", ".", "format", "(", "split", ")", ")", "\n", "users", "=", "getattr", "(", "self", ",", "'{}_users'", ".", "format", "(", "split", ")", ")", "\n", "\n", "iterator_class", "=", "eval", "(", "iterator_name", ")", "\n", "data_iter", "=", "iterator_class", "(", "\n", "data", ",", "\n", "users", ",", "\n", "*", "args", ",", "\n", "vocab", "=", "self", ".", "vocab", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.num_users": [[63, 66], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_users", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "user_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.get_lm_corpus": [[68, 76], ["os.path.exists", "corpus.Corpus"], "function", ["None"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ",", "vocab_file", ",", "cased", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "exists", "(", "vocab_file", ")", ",", "'Please compute the vocabulary first.'", "\n", "\n", "kwargs", "[", "'cased'", "]", "=", "cased", "\n", "kwargs", "[", "'vocab_file'", "]", "=", "vocab_file", "\n", "corpus", "=", "Corpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "\n", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.LinearSchedule.__init__": [[7, 18], ["float"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "start", ",", "end", "=", "None", ",", "steps", "=", "None", ")", ":", "\n", "        ", "if", "end", "is", "None", ":", "\n", "            ", "end", "=", "start", "\n", "steps", "=", "1", "\n", "", "self", ".", "inc", "=", "(", "end", "-", "start", ")", "/", "float", "(", "steps", ")", "\n", "self", ".", "current", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "if", "end", ">", "start", ":", "\n", "            ", "self", ".", "bound", "=", "min", "\n", "", "else", ":", "\n", "            ", "self", ".", "bound", "=", "max", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.LinearSchedule.__call__": [[19, 23], ["utils.LinearSchedule.bound"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "steps", "=", "1", ")", ":", "\n", "        ", "val", "=", "self", ".", "current", "\n", "self", ".", "current", "=", "self", ".", "bound", "(", "self", ".", "current", "+", "self", ".", "inc", "*", "steps", ",", "self", ".", "end", ")", "\n", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.__init__": [[101, 104], ["torch.nn.parallel.DataParallel.__init__"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gpu0_bsz", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "gpu0_bsz", "=", "gpu0_bsz", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.forward": [[105, 120], ["utils.BalancedDataParallel.scatter", "utils.BalancedDataParallel.replicate", "utils.BalancedDataParallel.parallel_apply", "utils.BalancedDataParallel.gather", "utils.BalancedDataParallel.module", "len", "utils.BalancedDataParallel.module"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.parallel_apply"], ["", "def", "forward", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "self", ".", "device_ids", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "if", "self", ".", "gpu0_bsz", "==", "0", ":", "\n", "            ", "device_ids", "=", "self", ".", "device_ids", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "device_ids", "=", "self", ".", "device_ids", "\n", "", "inputs", ",", "kwargs", "=", "self", ".", "scatter", "(", "inputs", ",", "kwargs", ",", "device_ids", ")", "\n", "if", "len", "(", "self", ".", "device_ids", ")", "==", "1", ":", "\n", "            ", "return", "self", ".", "module", "(", "*", "inputs", "[", "0", "]", ",", "**", "kwargs", "[", "0", "]", ")", "\n", "", "replicas", "=", "self", ".", "replicate", "(", "self", ".", "module", ",", "self", ".", "device_ids", ")", "\n", "if", "self", ".", "gpu0_bsz", "==", "0", ":", "\n", "            ", "replicas", "=", "replicas", "[", "1", ":", "]", "\n", "", "outputs", "=", "self", ".", "parallel_apply", "(", "replicas", ",", "device_ids", ",", "inputs", ",", "kwargs", ")", "\n", "return", "self", ".", "gather", "(", "outputs", ",", "self", ".", "output_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.parallel_apply": [[121, 123], ["torch.nn.parallel.parallel_apply.parallel_apply"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.parallel_apply"], ["", "def", "parallel_apply", "(", "self", ",", "replicas", ",", "device_ids", ",", "inputs", ",", "kwargs", ")", ":", "\n", "        ", "return", "parallel_apply", "(", "replicas", ",", "inputs", ",", "kwargs", ",", "device_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.BalancedDataParallel.scatter": [[124, 139], ["inputs[].size", "len", "utils.scatter_kwargs", "range", "super().scatter", "sum"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter_kwargs", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter"], ["", "def", "scatter", "(", "self", ",", "inputs", ",", "kwargs", ",", "device_ids", ")", ":", "\n", "        ", "bsz", "=", "inputs", "[", "0", "]", ".", "size", "(", "self", ".", "dim", ")", "\n", "num_dev", "=", "len", "(", "self", ".", "device_ids", ")", "\n", "gpu0_bsz", "=", "self", ".", "gpu0_bsz", "\n", "bsz_unit", "=", "(", "bsz", "-", "gpu0_bsz", ")", "//", "(", "num_dev", "-", "1", ")", "\n", "if", "gpu0_bsz", "<", "bsz_unit", ":", "\n", "            ", "chunk_sizes", "=", "[", "gpu0_bsz", "]", "+", "[", "bsz_unit", "]", "*", "(", "num_dev", "-", "1", ")", "\n", "delta", "=", "bsz", "-", "sum", "(", "chunk_sizes", ")", "\n", "for", "i", "in", "range", "(", "delta", ")", ":", "\n", "                ", "chunk_sizes", "[", "i", "+", "1", "]", "+=", "1", "\n", "", "if", "gpu0_bsz", "==", "0", ":", "\n", "                ", "chunk_sizes", "=", "chunk_sizes", "[", "1", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "scatter", "(", "inputs", ",", "kwargs", ",", "device_ids", ")", "\n", "", "return", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "device_ids", ",", "chunk_sizes", ",", "dim", "=", "self", ".", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch": [[24, 54], ["len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().view", "torch.LongTensor", "torch.LongTensor", "data.to.fill_", "target.to.fill_", "token_length.to.fill_", "word_length.to.fill_", "enumerate", "data.to.to", "target.to.to", "users.to.to", "token_length.to.to", "word_length.to.to", "zip", "min", "torch.LongTensor", "torch.LongTensor", "sum", "torch.LongTensor", "len"], "function", ["None"], ["", "", "def", "encap_batch", "(", "batch", ",", "bptt", ",", "device", ")", ":", "\n", "# decapsule batch", "\n", "    ", "wordpieces", ",", "wordends", ",", "users", "=", "batch", "\n", "bsz", "=", "len", "(", "wordpieces", ")", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "bptt", ",", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "bptt", ",", "bsz", ")", "\n", "users", "=", "torch", ".", "LongTensor", "(", "users", ")", ".", "view", "(", "1", ",", "bsz", ")", "\n", "token_length", "=", "torch", ".", "LongTensor", "(", "1", ",", "bsz", ")", "\n", "word_length", "=", "torch", ".", "LongTensor", "(", "1", ",", "bsz", ")", "\n", "\n", "data", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "token_length", ".", "fill_", "(", "0", ")", "\n", "word_length", ".", "fill_", "(", "0", ")", "\n", "\n", "for", "i", ",", "(", "wend", ",", "wpiece", ")", "in", "enumerate", "(", "zip", "(", "wordends", ",", "wordpieces", ")", ")", ":", "\n", "        ", "n_new", "=", "min", "(", "len", "(", "wpiece", ")", "-", "1", ",", "bptt", ")", "\n", "data", "[", ":", "n_new", ",", "i", "]", "=", "torch", ".", "LongTensor", "(", "wpiece", "[", ":", "n_new", "]", ")", "\n", "target", "[", ":", "n_new", ",", "i", "]", "=", "torch", ".", "LongTensor", "(", "wpiece", "[", "1", ":", "n_new", "+", "1", "]", ")", "\n", "token_length", "[", ":", ",", "i", "]", "=", "n_new", "\n", "word_length", "[", ":", ",", "i", "]", "=", "sum", "(", "wend", "[", ":", "n_new", "]", ")", "\n", "\n", "", "data", "=", "data", ".", "to", "(", "device", ")", "\n", "target", "=", "target", ".", "to", "(", "device", ")", "\n", "users", "=", "users", ".", "to", "(", "device", ")", "\n", "token_length", "=", "token_length", ".", "to", "(", "device", ")", "\n", "word_length", "=", "word_length", ".", "to", "(", "device", ")", "\n", "\n", "return", "data", ",", "target", ",", "users", ",", "token_length", ",", "word_length", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter": [[55, 87], ["isinstance", "utils.scatter.scatter_map"], "function", ["None"], ["", "def", "scatter", "(", "inputs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", "=", "0", ")", ":", "\n", "    ", "r\"\"\"\n    Slices tensors into approximately equal chunks and\n    distributes them across given GPUs. Duplicates\n    references to objects that are not tensors.\n    \"\"\"", "\n", "def", "scatter_map", "(", "obj", ")", ":", "\n", "        ", "if", "isinstance", "(", "obj", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "Scatter", ".", "apply", "(", "target_gpus", ",", "chunk_sizes", ",", "dim", ",", "obj", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "'obj'", ",", "obj", ".", "size", "(", ")", ")", "\n", "print", "(", "'dim'", ",", "dim", ")", "\n", "print", "(", "'chunk_sizes'", ",", "chunk_sizes", ")", "\n", "quit", "(", ")", "\n", "", "", "if", "isinstance", "(", "obj", ",", "tuple", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "list", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "list", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ")", ")", ")", ")", "\n", "", "if", "isinstance", "(", "obj", ",", "dict", ")", "and", "len", "(", "obj", ")", ">", "0", ":", "\n", "            ", "return", "list", "(", "map", "(", "type", "(", "obj", ")", ",", "zip", "(", "*", "map", "(", "scatter_map", ",", "obj", ".", "items", "(", ")", ")", ")", ")", ")", "\n", "", "return", "[", "obj", "for", "targets", "in", "target_gpus", "]", "\n", "\n", "# After scatter_map is called, a scatter_map cell will exist. This cell", "\n", "# has a reference to the actual function scatter_map, which has references", "\n", "# to a closure that has a reference to the scatter_map cell (because the", "\n", "# fn is recursive). To avoid this reference cycle, we set the function to", "\n", "# None, clearing the cell", "\n", "", "try", ":", "\n", "        ", "return", "scatter_map", "(", "inputs", ")", "\n", "", "finally", ":", "\n", "        ", "scatter_map", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter_kwargs": [[88, 99], ["tuple", "tuple", "utils.scatter", "utils.scatter", "len", "len", "tuple.extend", "len", "len", "tuple.extend", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.scatter"], ["", "", "def", "scatter_kwargs", "(", "inputs", ",", "kwargs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", "=", "0", ")", ":", "\n", "    ", "r\"\"\"Scatter with support for kwargs dictionary\"\"\"", "\n", "inputs", "=", "scatter", "(", "inputs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", ")", "if", "inputs", "else", "[", "]", "\n", "kwargs", "=", "scatter", "(", "kwargs", ",", "target_gpus", ",", "chunk_sizes", ",", "dim", ")", "if", "kwargs", "else", "[", "]", "\n", "if", "len", "(", "inputs", ")", "<", "len", "(", "kwargs", ")", ":", "\n", "        ", "inputs", ".", "extend", "(", "[", "(", ")", "for", "_", "in", "range", "(", "len", "(", "kwargs", ")", "-", "len", "(", "inputs", ")", ")", "]", ")", "\n", "", "elif", "len", "(", "kwargs", ")", "<", "len", "(", "inputs", ")", ":", "\n", "        ", "kwargs", ".", "extend", "(", "[", "{", "}", "for", "_", "in", "range", "(", "len", "(", "inputs", ")", "-", "len", "(", "kwargs", ")", ")", "]", ")", "\n", "", "inputs", "=", "tuple", "(", "inputs", ")", "\n", "kwargs", "=", "tuple", "(", "kwargs", ")", "\n", "return", "inputs", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.__init__": [[10, 80], ["torch.Module.__init__", "core.models.embeddings.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Linear", "torch.Linear", "torch.Linear", "print", "mem_transformer.MemTransformerLM._create_params", "print", "mem_transformer.MemTransformerLM.layers.append", "core.models.decoder.RelPartialLearnableDecoderLayer", "print"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._create_params"], ["    ", "def", "__init__", "(", "self", ",", "\n", "n_user", ",", "\n", "n_token", ",", "\n", "n_layer", ",", "\n", "n_head", ",", "\n", "d_model", ",", "\n", "d_head", ",", "\n", "d_inner", ",", "\n", "dropout", ",", "\n", "dropatt", ",", "\n", "*", "args", ",", "\n", "tgt_len", "=", "None", ",", "\n", "ext_len", "=", "None", ",", "\n", "mem_len", "=", "None", ",", "\n", "tie_weight", "=", "True", ",", "\n", "d_embed", "=", "None", ",", "\n", "clamp_len", "=", "-", "1", ",", "\n", "ignore_index", "=", "0", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "MemTransformerLM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# nll loss related", "\n", "if", "ignore_index", "!=", "0", ":", "print", "(", "'Ignore index is deprecated...'", ")", "\n", "self", ".", "ignore_index", "=", "constants", ".", "MODEL_PAD_INDEX", "\n", "self", ".", "token_offset", "=", "constants", ".", "MODEL_INDEX_OFFSET", "\n", "self", ".", "reduction", "=", "'none'", "\n", "\n", "self", ".", "n_user", "=", "n_user", "\n", "self", ".", "n_token", "=", "n_token", "+", "self", ".", "token_offset", "\n", "\n", "d_embed", "=", "d_model", "if", "d_embed", "is", "None", "else", "d_embed", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_head", "=", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "self", ".", "n_token", ",", "d_embed", ",", "d_model", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "max_klen", "=", "tgt_len", "+", "mem_len", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_layer", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "\n", "dropatt", "=", "dropatt", ")", "\n", ")", "\n", "\n", "# use standard softmax", "\n", "", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "d_model", ",", "self", ".", "n_token", ")", "\n", "if", "tie_weight", ":", "\n", "            ", "if", "d_model", "==", "d_embed", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "word_emb", ".", "emb_layers", "[", "0", "]", ".", "weight", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"[Warning] Dimensionality Mismatch Between WordEmb and Linear Classifier. Can't tie this weight...\"", ")", "\n", "pass", "\n", "", "", "self", ".", "tie_weight", "=", "tie_weight", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "\n", "print", "(", "'Initializing {} with {} Users and {} Tokens (Padding Token=0)...'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "n_user", ",", "self", ".", "n_token", ")", ")", "\n", "self", ".", "_create_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._create_params": [[81, 85], ["core.models.embeddings.PositionalEmbedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "_create_params", "(", "self", ")", ":", "\n", "        ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.reset_length": [[86, 89], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.init_mems": [[90, 104], ["next", "range", "mem_transformer.MemTransformerLM.parameters", "mems.append", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ",", "batch_size", "=", "0", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", "+", "1", ")", ":", "\n", "                ", "if", "batch_size", ">", "0", ":", "\n", "                    ", "mem", "=", "torch", ".", "zeros", "(", "(", "self", ".", "mem_len", ",", "batch_size", ",", "self", ".", "d_model", ")", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "", "else", ":", "\n", "                    ", "mem", "=", "torch", ".", "empty", "(", "0", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "", "mems", ".", "append", "(", "mem", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._update_mems": [[105, 123], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cat[].detach", "cat[].detach.masked_fill_", "new_mems.append"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "inps", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "return", "None", "\n", "\n", "# mems is not None", "\n", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "'len(hids) != len(mems)'", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "ctx", "=", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", "\n", "ctx", ".", "masked_fill_", "(", "(", "inps", "[", "-", "1", ",", ":", "]", "==", "constants", ".", "MODEL_PAD_INDEX", ")", "[", "None", ",", ":", ",", "None", "]", ",", "0", ")", "\n", "new_mems", ".", "append", "(", "ctx", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.preprocess_data": [[124, 130], ["None"], "methods", ["None"], ["", "def", "preprocess_data", "(", "self", ",", "data", ",", "target", ")", ":", "\n", "#IMPORTANT:", "\n", "#   - Shifting data and label by 1 (St. Pad Token index (which was set to be -1) becomes 0)", "\n", "        ", "data", "+=", "self", ".", "token_offset", "\n", "if", "target", "is", "not", "None", ":", "target", "+=", "self", ".", "token_offset", "\n", "return", "data", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._forward": [[134, 163], ["word_emb.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mem_transformer.MemTransformerLM.pos_emb", "mem_transformer.MemTransformerLM.drop", "mem_transformer.MemTransformerLM.drop", "hids.append", "enumerate", "mem_transformer.MemTransformerLM.drop", "mem_transformer.MemTransformerLM._update_mems", "word_emb.size", "word_emb.size", "mems[].size", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "layer", "hids.append", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._update_mems"], ["", "def", "_forward", "(", "self", ",", "word_emb", ",", "dec_inp", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "bsz", "=", "word_emb", ".", "size", "(", "0", ")", ",", "word_emb", ".", "size", "(", "1", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "all_ones", "=", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", "\n", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "all_ones", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "hids", "=", "[", "]", "\n", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "            ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "self", ".", "r_w_bias", ",", "\n", "self", ".", "r_r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "dec_inp", ",", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.forward": [[164, 197], ["mem_transformer.MemTransformerLM.preprocess_data", "target.view.view.size", "mem_transformer.MemTransformerLM.word_emb", "mem_transformer.MemTransformerLM._forward", "mem_transformer.MemTransformerLM.out_layer", "logit.view.view.view", "target.view.view.view", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss.view", "mem_transformer.MemTransformerLM.init_mems", "logit.view.view.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "data.size"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.preprocess_data", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM._forward", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.init_mems"], ["", "def", "forward", "(", "self", ",", "data", ",", "target", ",", "user", ",", "*", "mems", ")", ":", "\n", "        ", "data", ",", "target", "=", "self", ".", "preprocess_data", "(", "data", ",", "target", ")", "\n", "\n", "# nn.DataParallel does not allow size(0) tensors to be broadcasted.", "\n", "# So, have to initialize size(0) mems inside the model forward.", "\n", "# Moreover, have to return new_mems to allow nn.DataParallel to piece", "\n", "# them together.", "\n", "if", "not", "mems", ":", "mems", "=", "self", ".", "init_mems", "(", "data", ".", "size", "(", "1", ")", ")", "\n", "\n", "tgt_len", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "# extract word embedding", "\n", "word_emb", "=", "self", ".", "word_emb", "(", "data", ")", "\n", "hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "word_emb", ",", "data", ",", "mems", "=", "mems", ")", "\n", "\n", "pred_hid", "=", "hidden", "[", "-", "tgt_len", ":", "]", "\n", "logit", "=", "self", ".", "out_layer", "(", "pred_hid", ")", "\n", "\n", "logit", "=", "logit", ".", "view", "(", "-", "1", ",", "logit", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "nll", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", ",", "\n", "ignore_index", "=", "self", ".", "ignore_index", ",", "\n", "reduction", "=", "self", ".", "reduction", ",", "\n", ")", "\n", "loss", "=", "nll", ".", "view", "(", "tgt_len", ",", "-", "1", ")", "\n", "\n", "if", "new_mems", "is", "None", ":", "\n", "            ", "return", "[", "loss", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "loss", "]", "+", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.get_logprob": [[198, 207], ["mem_transformer.MemTransformerLM.preprocess_data", "mem_transformer.MemTransformerLM.word_emb", "mem_transformer.MemTransformerLM._forward", "mem_transformer.MemTransformerLM.out_layer", "mem_transformer.MemTransformerLM.init_mems", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "data.size"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.preprocess_data", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM._forward", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.init_mems"], ["", "", "def", "get_logprob", "(", "self", ",", "data", ",", "user", ",", "*", "mems", ",", "temperature", "=", "1.0", ")", ":", "\n", "        ", "data", ",", "_", "=", "self", ".", "preprocess_data", "(", "data", ",", "None", ")", "\n", "if", "not", "mems", ":", "mems", "=", "self", ".", "init_mems", "(", "data", ".", "size", "(", "1", ")", ")", "\n", "\n", "word_emb", "=", "self", ".", "word_emb", "(", "data", ")", "\n", "hidden", ",", "_", "=", "self", ".", "_forward", "(", "word_emb", ",", "data", ",", "mems", "=", "mems", ")", "\n", "logit", "=", "self", ".", "out_layer", "(", "hidden", ")", "\n", "\n", "return", "F", ".", "log_softmax", "(", "logit", "/", "temperature", ",", "dim", "=", "-", "1", ")", "[", ":", ",", ":", ",", "self", ".", "token_offset", ":", "]", "# get rid of the first padding token", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.decoder.RelPartialLearnableDecoderLayer.__init__": [[18, 25], ["torch.Module.__init__", "core.models.layers.RelPartialLearnableMultiHeadAttn", "core.models.layers.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "n_head", ",", "d_model", ",", "\n", "d_head", ",", "dropout", ",", "**", "kwargs", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "d_model", ",", "d_inner", ",", "dropout", ",", "\n", "pre_lnorm", "=", "kwargs", ".", "get", "(", "'pre_lnorm'", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.decoder.RelPartialLearnableDecoderLayer.forward": [[26, 34], ["decoder.RelPartialLearnableDecoderLayer.dec_attn", "decoder.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "\n", "        ", "output", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "\n", "attn_mask", "=", "dec_attn_mask", ",", "\n", "mems", "=", "mems", ")", "\n", "output", "=", "self", ".", "pos_ff", "(", "output", ")", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.__init__": [[14, 56], ["core.models.mem_transformer.MemTransformerLM.__init__", "hasattr", "core.models.embeddings.AdaptiveEmbedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "int", "range", "mtl_layer.extend", "mtl_transformer.MTLMemTransformerLM.mtl_layers.append", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "mtl_layer.extend", "torch.Sequential", "torch.Sequential", "torch.Sequential", "ValueError", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "len", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "mtl_transformer.MTLMemTransformerLM.__init__.build_mtl_layer"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "*", "args", ",", "\n", "mtl_type", "=", "'multi_decoder'", ",", "\n", "d_user_embed", "=", "-", "1", ",", "\n", "mtl_width", "=", "4", ",", "\n", "mtl_depth", "=", "1", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "assert", "hasattr", "(", "self", ",", "'n_user'", ")", ",", "'num of users must be specified'", "\n", "\n", "self", ".", "mtl_type", "=", "mtl_type", "\n", "assert", "d_user_embed", "!=", "-", "1", ",", "'[Error] d_user_embed must be specified.'", "\n", "self", ".", "d_user_embed", "=", "d_user_embed", "\n", "self", ".", "user_emb", "=", "AdaptiveEmbedding", "(", "self", ".", "n_user", ",", "self", ".", "d_user_embed", ",", "self", ".", "d_model", ")", "\n", "\n", "self", ".", "num_mtl_layers", "=", "0", "\n", "self", ".", "mtl_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "self", ".", "mtl_type", "in", "{", "'multi_encoder'", ",", "'multi_decoder'", "}", ":", "\n", "            ", "self", ".", "num_mtl_layers", "=", "1", "\n", "", "elif", "self", ".", "mtl_type", "in", "{", "'layerwise'", "}", ":", "\n", "            ", "self", ".", "num_mtl_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "", "elif", "self", ".", "mtl_type", "in", "{", "'all'", "}", ":", "\n", "            ", "self", ".", "num_mtl_layers", "=", "len", "(", "self", ".", "layers", ")", "+", "2", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unobserved Value.'", ")", "\n", "\n", "", "def", "build_mtl_layer", "(", "d_model", ",", "width", ",", "depth", ",", "dropout", ")", ":", "\n", "            ", "d_inner", "=", "int", "(", "d_model", "*", "width", ")", "\n", "mtl_layer", "=", "[", "nn", ".", "Linear", "(", "2", "*", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "for", "_", "in", "range", "(", "depth", "-", "1", ")", ":", "\n", "              ", "mtl_layer", ".", "extend", "(", "[", "nn", ".", "Linear", "(", "d_inner", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", ")", "\n", "", "mtl_layer", ".", "extend", "(", "[", "nn", ".", "Dropout", "(", "dropout", ")", ",", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "nn", ".", "Dropout", "(", "dropout", ")", ",", "nn", ".", "LayerNorm", "(", "d_model", ")", "]", ")", "\n", "return", "mtl_layer", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "num_mtl_layers", ")", ":", "\n", "            ", "self", ".", "mtl_layers", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "*", "build_mtl_layer", "(", "self", ".", "d_model", ",", "mtl_width", ",", "mtl_depth", ",", "self", ".", "dropout", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.forward": [[59, 79], ["mtl_transformer.MTLMemTransformerLM.preprocess_data", "target.reshape.reshape.size", "mtl_transformer.MTLMemTransformerLM.forward_model", "logit.view.view.view", "target.reshape.reshape.reshape", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss", "torch.nll_loss.view", "logit.view.view.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.preprocess_data", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.forward_model"], ["", "", "def", "forward", "(", "self", ",", "data", ",", "target", ",", "user", ",", "*", "mems", ")", ":", "\n", "        ", "data", ",", "target", "=", "self", ".", "preprocess_data", "(", "data", ",", "target", ")", "\n", "tgt_len", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "logit", ",", "new_mems", "=", "self", ".", "forward_model", "(", "data", ",", "user", ",", "mems", ",", "tgt_len", "=", "tgt_len", ")", "\n", "logit", "=", "logit", ".", "view", "(", "-", "1", ",", "logit", ".", "size", "(", "-", "1", ")", ")", "\n", "target", "=", "target", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "nll", "=", "F", ".", "nll_loss", "(", "\n", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ",", "\n", "target", ",", "\n", "ignore_index", "=", "self", ".", "ignore_index", ",", "\n", "reduction", "=", "self", ".", "reduction", ",", "\n", ")", "\n", "loss", "=", "nll", ".", "view", "(", "tgt_len", ",", "-", "1", ")", "\n", "\n", "if", "new_mems", "is", "None", ":", "\n", "            ", "return", "[", "loss", "]", "\n", "", "else", ":", "\n", "            ", "return", "[", "loss", "]", "+", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM._forward": [[80, 115], ["word_emb.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mtl_transformer.MTLMemTransformerLM.pos_emb", "mtl_transformer.MTLMemTransformerLM.drop", "mtl_transformer.MTLMemTransformerLM.drop", "hids.append", "enumerate", "mtl_transformer.MTLMemTransformerLM.drop", "mtl_transformer.MTLMemTransformerLM._update_mems", "word_emb.size", "word_emb.size", "mems[].size", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.triu().byte", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "layer", "hids.append", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "user_emb.expand_as", "user_emb.expand_as"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM._update_mems"], ["", "", "def", "_forward", "(", "self", ",", "word_emb", ",", "dec_inp", ",", "user_emb", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "bsz", "=", "word_emb", ".", "size", "(", "0", ")", ",", "word_emb", ".", "size", "(", "1", ")", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "all_ones", "=", "word_emb", ".", "new_ones", "(", "qlen", ",", "klen", ")", "\n", "dec_attn_mask", "=", "torch", ".", "triu", "(", "\n", "all_ones", ",", "diagonal", "=", "1", "+", "mlen", ")", ".", "byte", "(", ")", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "hids", "=", "[", "]", "\n", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "\n", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "            ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "hids", ".", "append", "(", "core_out", ")", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "core_out", "=", "layer", "(", "core_out", ",", "pos_emb", ",", "self", ".", "r_w_bias", ",", "\n", "self", ".", "r_r_bias", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ")", "\n", "if", "self", ".", "mtl_type", "in", "{", "'layerwise'", "}", ":", "\n", "                ", "task_specific", "=", "self", ".", "mtl_layers", "[", "i", "]", "(", "torch", ".", "cat", "(", "[", "core_out", ",", "user_emb", ".", "expand_as", "(", "core_out", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "core_out", "=", "core_out", "+", "task_specific", "\n", "", "elif", "self", ".", "mtl_type", "in", "{", "'all'", "}", ":", "# since all layers includes an additional layer", "\n", "                ", "task_specific", "=", "self", ".", "mtl_layers", "[", "i", "+", "1", "]", "(", "torch", ".", "cat", "(", "[", "core_out", ",", "user_emb", ".", "expand_as", "(", "core_out", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "core_out", "=", "core_out", "+", "task_specific", "\n", "", "hids", ".", "append", "(", "core_out", ")", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "dec_inp", ",", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "return", "core_out", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.forward_model": [[116, 137], ["mtl_transformer.MTLMemTransformerLM.user_emb", "mtl_transformer.MTLMemTransformerLM.word_emb", "mtl_transformer.MTLMemTransformerLM._forward", "mtl_transformer.MTLMemTransformerLM.init_mems", "mtl_transformer.MTLMemTransformerLM.out_layer", "data.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mtl_transformer.MTLMemTransformerLM.expand_as", "mtl_transformer.MTLMemTransformerLM.expand_as"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM._forward", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.init_mems"], ["", "def", "forward_model", "(", "self", ",", "data", ",", "user", ",", "mems", ",", "tgt_len", "=", "1", ")", ":", "\n", "        ", "if", "not", "mems", ":", "mems", "=", "self", ".", "init_mems", "(", "data", ".", "size", "(", "1", ")", ")", "\n", "\n", "user_emb", "=", "self", ".", "user_emb", "(", "user", ")", "\n", "word_emb", "=", "self", ".", "word_emb", "(", "data", ")", "\n", "\n", "# incorporate multitask information early", "\n", "if", "self", ".", "mtl_type", "in", "{", "'multi_encoder'", ",", "'all'", "}", ":", "\n", "            ", "task_specific", "=", "self", ".", "mtl_layers", "[", "0", "]", "(", "torch", ".", "cat", "(", "[", "word_emb", ",", "user_emb", ".", "expand_as", "(", "word_emb", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "word_emb", "=", "word_emb", "+", "task_specific", "\n", "\n", "# shared transformer step", "\n", "", "hidden", ",", "new_mems", "=", "self", ".", "_forward", "(", "word_emb", ",", "data", ",", "user_emb", ",", "mems", "=", "mems", ")", "\n", "pred_hid", "=", "hidden", "[", "-", "tgt_len", ":", "]", "\n", "\n", "# incorporate multitask information late", "\n", "if", "self", ".", "mtl_type", "in", "{", "'multi_decoder'", ",", "'all'", "}", ":", "\n", "            ", "task_specific", "=", "self", ".", "mtl_layers", "[", "-", "1", "]", "(", "torch", ".", "cat", "(", "[", "pred_hid", ",", "user_emb", ".", "expand_as", "(", "pred_hid", ")", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "pred_hid", "=", "pred_hid", "+", "task_specific", "\n", "\n", "", "return", "self", ".", "out_layer", "(", "pred_hid", ")", ",", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.get_logprob": [[138, 143], ["mtl_transformer.MTLMemTransformerLM.preprocess_data", "mtl_transformer.MTLMemTransformerLM.forward_model", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "data.size"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.preprocess_data", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.MTLMemTransformerLM.forward_model"], ["", "def", "get_logprob", "(", "self", ",", "data", ",", "user", ",", "*", "mems", ",", "temperature", "=", "1.0", ")", ":", "\n", "        ", "data", ",", "_", "=", "self", ".", "preprocess_data", "(", "data", ",", "None", ")", "\n", "logit", ",", "_", "=", "self", ".", "forward_model", "(", "data", ",", "user", ",", "mems", ",", "tgt_len", "=", "data", ".", "size", "(", "0", ")", ")", "\n", "\n", "return", "F", ".", "log_softmax", "(", "logit", "/", "temperature", ",", "dim", "=", "-", "1", ")", "[", ":", ",", ":", ",", "self", ".", "token_offset", ":", "]", "# get rid of the first padding token", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mtl_transformer.identity": [[10, 12], ["None"], "function", ["None"], ["def", "identity", "(", "x", ")", ":", "\n", "    ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.PositionwiseFF.__init__": [[12, 29], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.PositionwiseFF.forward": [[30, 45], ["layers.PositionwiseFF.CoreNet", "layers.PositionwiseFF.CoreNet", "layers.PositionwiseFF.layer_norm", "layers.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "##### residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "##### positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "##### residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.MultiHeadAttn.__init__": [[47, 68], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "\n", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "q_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "self", ".", "kv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "2", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.MultiHeadAttn.forward": [[69, 119], ["layers.MultiHeadAttn.q_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "head_q.view.view.view", "head_k.view.view.view", "head_v.view.view.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum.mul_", "torch.einsum.mul_", "torch.einsum.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "layers.MultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "layers.MultiHeadAttn.o_net", "layers.MultiHeadAttn.drop", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.MultiHeadAttn.layer_norm", "layers.MultiHeadAttn.kv_net", "h.size", "h.size", "layers.MultiHeadAttn.size", "layers.MultiHeadAttn.size", "layers.MultiHeadAttn.size", "layers.MultiHeadAttn.size", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "layers.MultiHeadAttn.layer_norm", "mems.size", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "attn_mask.any", "attn_mask[].bool", "attn_mask.dim", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "torch.einsum.masked_fill_", "float", "attn_mask[].bool", "float"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "h", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "##### multihead attention", "\n", "# [hlen x bsz x n_head x d_head]", "\n", "\n", "        ", "if", "mems", "is", "not", "None", "and", "mems", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "            ", "c", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "h", "\n", "\n", "", "if", "self", ".", "pre_lnorm", ":", "\n", "##### layer normalization", "\n", "            ", "c", "=", "self", ".", "layer_norm", "(", "c", ")", "\n", "\n", "", "head_q", "=", "self", ".", "q_net", "(", "h", ")", "\n", "head_k", ",", "head_v", "=", "torch", ".", "chunk", "(", "self", ".", "kv_net", "(", "c", ")", ",", "2", ",", "-", "1", ")", "\n", "\n", "head_q", "=", "head_q", ".", "view", "(", "h", ".", "size", "(", "0", ")", ",", "h", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_k", "=", "head_k", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "head_v", "=", "head_v", ".", "view", "(", "c", ".", "size", "(", "0", ")", ",", "c", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "head_q", ",", "head_k", ")", ")", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ")", ".", "bool", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ")", ".", "bool", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# [qlen x klen x bsz x n_head] + [klen x bsz x n_head x d_head] -> [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "head_v", ")", ")", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "h", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "h", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn.__init__": [[121, 140], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "dropatt", "=", "0", ",", "pre_lnorm", "=", "False", ")", ":", "\n", "        ", "super", "(", "RelMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn._parallelogram_mask": [[141, 151], ["torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "torch.ones().byte", "min", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones().byte.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "_parallelogram_mask", "(", "self", ",", "h", ",", "w", ",", "left", "=", "False", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "(", "h", ",", "w", ")", ")", ".", "byte", "(", ")", "\n", "m", "=", "min", "(", "h", ",", "w", ")", "\n", "mask", "[", ":", "m", ",", ":", "m", "]", "=", "torch", ".", "triu", "(", "mask", "[", ":", "m", ",", ":", "m", "]", ")", "\n", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", "=", "torch", ".", "tril", "(", "mask", "[", "-", "m", ":", ",", "-", "m", ":", "]", ")", "\n", "\n", "if", "left", ":", "\n", "            ", "return", "mask", "\n", "", "else", ":", "\n", "            ", "return", "mask", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn._shift": [[152, 169], ["torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.cat().expand.masked_select().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask.flip.flip.flip", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat().expand.masked_select().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "def", "_shift", "(", "self", ",", "x", ",", "qlen", ",", "klen", ",", "mask", ",", "left", "=", "False", ")", ":", "\n", "        ", "if", "qlen", ">", "1", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "qlen", "-", "1", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", "else", ":", "\n", "            ", "zero_pad", "=", "torch", ".", "zeros", "(", "0", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n", "", "if", "left", ":", "\n", "            ", "mask", "=", "mask", ".", "flip", "(", "1", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "x_padded", "=", "torch", ".", "cat", "(", "[", "x", ",", "zero_pad", "]", ",", "dim", "=", "1", ")", ".", "expand", "(", "qlen", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "x", "=", "x_padded", ".", "masked_select", "(", "mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ".", "view", "(", "qlen", ",", "klen", ",", "x", ".", "size", "(", "2", ")", ",", "x", ".", "size", "(", "3", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn._rel_shift": [[170, 184], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "x_padded[].view_as.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ",", "zero_triu", "=", "False", ")", ":", "\n", "        ", "zero_pad", "=", "torch", ".", "zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ",", "\n", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "if", "zero_triu", ":", "\n", "            ", "ones", "=", "torch", ".", "ones", "(", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ")", ")", "\n", "x", "=", "x", "*", "torch", ".", "tril", "(", "ones", ",", "x", ".", "size", "(", "1", ")", "-", "x", ".", "size", "(", "0", ")", ")", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn.forward": [[185, 187], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelPartialLearnableMultiHeadAttn.__init__": [[189, 193], ["layers.RelMultiHeadAttn.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelPartialLearnableMultiHeadAttn.forward": [[194, 266], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "layers.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "layers.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "layers.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "layers.RelPartialLearnableMultiHeadAttn.o_net", "layers.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "layers.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "attn_mask.any().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "layers.RelPartialLearnableMultiHeadAttn.layer_norm", "mems.size", "layers.RelPartialLearnableMultiHeadAttn.qkv_net", "layers.RelPartialLearnableMultiHeadAttn.qkv_net", "layers.RelPartialLearnableMultiHeadAttn.qkv_net", "layers.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_score.masked_fill_", "attn_vec.contiguous().view.contiguous().view.contiguous", "layers.RelPartialLearnableMultiHeadAttn.layer_norm", "layers.RelPartialLearnableMultiHeadAttn.layer_norm", "attn_mask.any", "attn_mask[].bool", "attn_mask.dim", "attn_score.masked_fill_", "float", "attn_mask[].bool", "float"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.layers.RelMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "r_w_bias", ",", "r_r_bias", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", "and", "mems", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "#### compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->ijbn'", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "'ibnd,jnd->ijbn'", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "#### compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "attn_mask", ".", "any", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ")", ".", "bool", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "attn_score", ".", "masked_fill_", "(", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ")", ".", "bool", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "#### compute attention vector", "\n", "attn_vec", "=", "torch", ".", "einsum", "(", "'ijbn,jbnd->ibnd'", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "##### linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "##### residual connection", "\n", "            ", "output", "=", "w", "+", "attn_out", "\n", "", "else", ":", "\n", "##### residual connection + layer normalization", "\n", "            ", "output", "=", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.embeddings.AdaptiveEmbedding.__init__": [[12, 28], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "embeddings.AdaptiveEmbedding.emb_layers.append", "torch.Embedding", "torch.Embedding", "torch.Embedding", "embeddings.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "max_norm", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "\n", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "padding_idx", "=", "0", ")", "\n", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "            ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.embeddings.AdaptiveEmbedding.forward": [[29, 40], ["torch.linear.mul_", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "# L2 normalize user embedding", "\n", "# if self.max_norm:", "\n", "#     embed = F.normalize(embed)", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "            ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.embeddings.PositionalEmbedding.__init__": [[42, 49], ["torch.Module.__init__", "embeddings.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "'inv_freq'", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.embeddings.PositionalEmbedding.forward": [[50, 59], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.__init__": [[7, 9], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "online_batch", ",", "stats", ",", "skip_optim", "=", "False", ")", ":", "\n", "        ", "pass", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_data": [[10, 13], ["NotImplementedError"], "methods", ["None"], ["\n", "", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_data": [[14, 17], ["NotImplementedError"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"{}()\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.add_batch": [[18, 28], ["enumerate", "zip", "base.BaseBuffer.add_data", "batch2rm[].append", "batch2rm[].append", "batch2rm[].append"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.add_data"], []], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.sample_batch": [[29, 47], ["torch.FloatTensor", "torch.LongTensor", "range", "min", "core.dataset.utils.encap_batch", "len", "base.BaseBuffer.sample_data", "batch[].append", "batch[].append", "batch[].append", "max", "torch.FloatTensor.to", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.sample_data"], []], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.base.BaseBuffer.__str__": [[48, 50], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.greedy.GreedyBuffer.__init__": [[8, 22], ["core.memories.base.BaseBuffer.__init__"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_wordpieces", "=", "[", "]", "\n", "self", ".", "_wordends", "=", "[", "]", "\n", "self", ".", "_users", "=", "[", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "buffer_filled", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.greedy.GreedyBuffer.add_data": [[23, 45], ["greedy.GreedyBuffer._wordpieces.append", "greedy.GreedyBuffer._wordends.append", "greedy.GreedyBuffer._users.append"], "methods", ["None"], ["", "def", "add_data", "(", "self", ",", "wordpiece", ",", "wordend", ",", "user", ")", ":", "\n", "        ", "data2rm", "=", "None", "\n", "if", "self", ".", "_next_idx", ">=", "self", ".", "buffer_filled", ":", "\n", "            ", "self", ".", "_wordpieces", ".", "append", "(", "wordpiece", ")", "\n", "self", ".", "_wordends", ".", "append", "(", "wordend", ")", "\n", "self", ".", "_users", ".", "append", "(", "user", ")", "\n", "\n", "self", ".", "buffer_filled", "+=", "1", "\n", "", "else", ":", "\n", "            ", "data2rm", "=", "(", "\n", "self", ".", "_wordpieces", "[", "self", ".", "_next_idx", "]", ",", "\n", "self", ".", "_wordends", "[", "self", ".", "_next_idx", "]", ",", "\n", "self", ".", "_users", "[", "self", ".", "_next_idx", "]", "\n", ")", "\n", "self", ".", "_wordpieces", "[", "self", ".", "_next_idx", "]", "=", "wordpiece", "\n", "self", ".", "_wordends", "[", "self", ".", "_next_idx", "]", "=", "wordend", "\n", "self", ".", "_users", "[", "self", ".", "_next_idx", "]", "=", "user", "\n", "\n", "# add data to replay buffer", "\n", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "buffer_size", "\n", "\n", "return", "data2rm", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.greedy.GreedyBuffer.sample_data": [[46, 53], ["numpy.random.randint"], "methods", ["None"], ["", "def", "sample_data", "(", "self", ")", ":", "\n", "        ", "sample_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "buffer_filled", ")", "\n", "wordpiece", "=", "self", ".", "_wordpieces", "[", "sample_idx", "]", "\n", "wordend", "=", "self", ".", "_wordends", "[", "sample_idx", "]", "\n", "user", "=", "self", ".", "_users", "[", "sample_idx", "]", "\n", "\n", "return", "wordpiece", ",", "wordend", ",", "user", ",", "1.0", ",", "sample_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.greedy.GreedyBuffer.__len__": [[54, 56], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_users", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.reservoir.ReservoirBuffer.__init__": [[6, 21], ["core.memories.base.BaseBuffer.__init__"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_wordpieces", "=", "[", "None", "]", "*", "buffer_size", "\n", "self", ".", "_wordends", "=", "[", "None", "]", "*", "buffer_size", "\n", "self", ".", "_users", "=", "[", "None", "]", "*", "buffer_size", "\n", "\n", "self", ".", "_size", "=", "0", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "# important for reservoir sampling", "\n", "self", ".", "example_seen_so_far", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.reservoir.ReservoirBuffer.add_data": [[22, 55], ["min", "numpy.random.randint"], "methods", ["None"], ["", "def", "add_data", "(", "self", ",", "wordpiece", ",", "wordend", ",", "user", ")", ":", "\n", "        ", "\"\"\" This function implements a reservoir update that ensures each data points has the equal probability to be kept in the memory buffer.\n        \"\"\"", "\n", "data2rm", "=", "None", "\n", "if", "self", ".", "example_seen_so_far", "<", "self", ".", "buffer_size", ":", "\n", "            ", "idx", "=", "self", ".", "example_seen_so_far", "\n", "# Fill the buffer when it is not full", "\n", "self", ".", "_wordpieces", "[", "idx", "]", "=", "wordpiece", "\n", "self", ".", "_wordends", "[", "idx", "]", "=", "wordend", "\n", "self", ".", "_users", "[", "idx", "]", "=", "user", "\n", "\n", "self", ".", "_size", "=", "min", "(", "self", ".", "_size", "+", "1", ",", "self", ".", "buffer_size", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "example_seen_so_far", ")", "\n", "if", "idx", "<", "self", ".", "buffer_size", ":", "\n", "                ", "data2rm", "=", "(", "\n", "self", ".", "_wordpieces", "[", "idx", "]", ",", "\n", "self", ".", "_wordends", "[", "idx", "]", ",", "\n", "self", ".", "_users", "[", "idx", "]", "\n", ")", "\n", "self", ".", "_wordpieces", "[", "idx", "]", "=", "wordpiece", "\n", "self", ".", "_wordends", "[", "idx", "]", "=", "wordend", "\n", "self", ".", "_users", "[", "idx", "]", "=", "user", "\n", "", "else", ":", "\n", "                ", "data2rm", "=", "(", "\n", "wordpiece", ",", "\n", "wordend", ",", "\n", "user", "\n", ")", "\n", "\n", "", "", "self", ".", "example_seen_so_far", "+=", "1", "\n", "\n", "return", "data2rm", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.reservoir.ReservoirBuffer.sample_data": [[56, 63], ["numpy.random.randint"], "methods", ["None"], ["", "def", "sample_data", "(", "self", ")", ":", "\n", "        ", "sample_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "_size", ")", "\n", "wordpiece", "=", "self", ".", "_wordpieces", "[", "sample_idx", "]", "\n", "wordend", "=", "self", ".", "_wordends", "[", "sample_idx", "]", "\n", "user", "=", "self", ".", "_users", "[", "sample_idx", "]", "\n", "\n", "return", "wordpiece", ",", "wordend", ",", "user", ",", "1.0", ",", "sample_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.reservoir.ReservoirBuffer.__len__": [[64, 66], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.__init__": [[12, 28], ["core.memories.base.BaseBuffer.__init__", "collections.OrderedDict", "eval"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "buffer_size", ",", "\n", "*", "args", ",", "\n", "buffer_class", "=", "'GreedyBuffer'", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# lazy initialization", "\n", "self", ".", "user_buffers", "=", "OrderedDict", "(", ")", "\n", "self", ".", "user_num", "=", "0", "\n", "self", ".", "inv_user_dict", "=", "{", "}", "\n", "self", ".", "buffer_class", "=", "eval", "(", "buffer_class", ")", "\n", "self", ".", "buffer_args", "=", "args", "\n", "self", ".", "buffer_kwargs", "=", "kwargs", "\n", "self", ".", "per_user_buffer_size", "=", "buffer_size", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.add_data": [[29, 38], ["stratified.StratifiedBuffer.user_buffers[].add_data", "stratified.StratifiedBuffer.user_buffers.get", "stratified.StratifiedBuffer.buffer_class"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.add_data"], ["", "def", "add_data", "(", "self", ",", "wordpiece", ",", "wordend", ",", "user", ")", ":", "\n", "        ", "if", "self", ".", "user_buffers", ".", "get", "(", "user", ",", "None", ")", "is", "None", ":", "\n", "            ", "self", ".", "inv_user_dict", "[", "self", ".", "user_num", "]", "=", "user", "\n", "self", ".", "user_buffers", "[", "user", "]", "=", "self", ".", "buffer_class", "(", "self", ".", "per_user_buffer_size", ",", "\n", "*", "self", ".", "buffer_args", ",", "**", "self", ".", "buffer_kwargs", ")", "\n", "\n", "self", ".", "user_num", "+=", "1", "\n", "# Add data to user specific buffer", "\n", "", "return", "self", ".", "user_buffers", "[", "user", "]", ".", "add_data", "(", "wordpiece", ",", "wordend", ",", "user", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.sample_data": [[39, 43], ["numpy.random.randint", "stratified.StratifiedBuffer.sample_user_data"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.sample_user_data"], ["", "def", "sample_data", "(", "self", ")", ":", "\n", "        ", "user_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "user_num", ")", "\n", "sampled_user", "=", "self", ".", "inv_user_dict", "[", "user_idx", "]", "\n", "return", "self", ".", "sample_user_data", "(", "sampled_user", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.sample_user_data": [[44, 49], ["stratified.StratifiedBuffer.user_buffers.get", "stratified.StratifiedBuffer.user_buffers[].sample_data", "ValueError"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.sample_data"], ["", "def", "sample_user_data", "(", "self", ",", "user", ")", ":", "\n", "        ", "if", "self", ".", "user_buffers", ".", "get", "(", "user", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "user_buffers", "[", "user", "]", ".", "sample_data", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unencountered User.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.memories.stratified.StratifiedBuffer.__len__": [[50, 52], ["sum", "len", "stratified.StratifiedBuffer.user_buffers.values"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "[", "len", "(", "buf", ")", "for", "buf", "in", "self", ".", "user_buffers", ".", "values", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.__init__": [[38, 139], ["core.trainer.base_trainer.BaseTrainer.__init__", "dict", "max", "max", "core.trainer.trainer_utils.prepare_buffer", "core.trainer.trainer_utils.prepare_buffer", "print", "print", "corpus.get_iterator", "corpus.get_iterator", "corpus.get_iterator", "Timer", "eval", "print", "os.path.join", "max", "print", "time.time", "time.time", "str", "open", "json.load", "int", "scalars[].values"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_buffer", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_buffer", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.get_iterator", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.get_iterator", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.corpus.Corpus.get_iterator"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "args", ",", "\n", "corpus", ":", "Corpus", ",", "\n", "scripts_to_save", "=", "None", ",", "\n", ")", ":", "\n", "        ", "assert", "args", ".", "scheduler", "in", "{", "'constant'", "}", ",", "'Online learning assumes no knowledge about max_step and only constant scheduler is applicable'", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "args", ",", "\n", "corpus", ",", "\n", "scripts_to_save", ",", "\n", ")", "\n", "\n", "self", ".", "stats", "=", "dict", "(", "\n", "num_data", "=", "0", ",", "# Number of data encountered so far", "\n", "num_updates", "=", "0", ",", "# Number of model updates so far", "\n", "train_step", "=", "0", ",", "# Global train counter", "\n", "online_loss", "=", "0", ",", "# Online Cumulative loss", "\n", "online_word_count", "=", "0", ",", "# Online Cumulative word counter", "\n", "online_token_count", "=", "0", ",", "# Online Cumulative token counter", "\n", "total_loss", "=", "0", ",", "# Cumulative loss", "\n", "total_word_count", "=", "0", ",", "# Cumulative word counter", "\n", "total_token_count", "=", "0", ",", "# Cumulative token counter", "\n", "best_val_loss", "=", "None", ",", "# Best validation loss so far", "\n", "eval_start_time", "=", "time", ".", "time", "(", ")", ",", "# Time of last evaluation start", "\n", "log_start_time", "=", "time", ".", "time", "(", ")", ",", "# Time of last logging end", "\n", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "eval_interval", "=", "args", ".", "eval_interval", "\n", "\n", "self", ".", "total_replay_rbsize", "=", "max", "(", "args", ".", "batch_size", ",", "args", ".", "replay_per_user_rbsize", "*", "corpus", ".", "num_users", ")", "\n", "self", ".", "total_online_rbsize", "=", "max", "(", "args", ".", "batch_size", ",", "args", ".", "online_per_user_rbsize", "*", "corpus", ".", "num_users", ")", "\n", "# prepare online cache and replay buffer", "\n", "self", ".", "online_buffer", "=", "prepare_buffer", "(", "\n", "args", ".", "online_buffer_strategy", ",", "\n", "args", ".", "online_per_user_rbsize", ",", "\n", "self", ".", "total_online_rbsize", ",", "\n", "args", ".", "max_seqlen", ",", "\n", ")", "\n", "self", ".", "replay_buffer", "=", "prepare_buffer", "(", "\n", "args", ".", "replay_buffer_strategy", ",", "\n", "args", ".", "replay_per_user_rbsize", ",", "\n", "self", ".", "total_replay_rbsize", ",", "\n", "args", ".", "max_seqlen", ",", "\n", ")", "\n", "\n", "params", "=", "(", "self", ".", "model", ",", "self", ".", "para_model", ",", "self", ".", "optimizer", ",", "\n", "self", ".", "online_buffer", ",", "self", ".", "replay_buffer", ",", "args", ")", "\n", "# setup learning algorithm", "\n", "self", ".", "learning_algorithm", "=", "eval", "(", "args", ".", "learner", ")", "(", "*", "params", ")", "\n", "\n", "assert", "(", "args", ".", "snapshot_dir", "is", "None", ")", "or", "(", "args", ".", "learner", "in", "{", "'AGEMOnline'", ",", "'OMSER'", "}", ")", ",", "'Can not resume, something went wrong.'", "\n", "\n", "print", "(", "'[*] Online Cache Size: {}, Replay Buffer Size: {}'", ".", "format", "(", "self", ".", "total_online_rbsize", ",", "\n", "self", ".", "total_replay_rbsize", ")", ")", "\n", "print", "(", "'[*] Learning Algorithm: {}'", ".", "format", "(", "str", "(", "self", ".", "learning_algorithm", ")", ")", ")", "\n", "# train iterator should be online and must not be shuffled", "\n", "self", ".", "train_data", "=", "corpus", ".", "get_iterator", "(", "\n", "'train'", ",", "\n", "args", ".", "batch_size", ",", "\n", "args", ".", "max_seqlen", ",", "\n", "iterator_name", "=", "'LMOnePassIterator'", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "subword_augment", "=", "args", ".", "subword_augment", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "\n", "# always load batch iterator in batch learning mode", "\n", "self", ".", "val_data", "=", "corpus", ".", "get_iterator", "(", "\n", "'val'", ",", "\n", "args", ".", "eval_batch_size", ",", "\n", "args", ".", "max_seqlen", ",", "\n", "iterator_name", "=", "'LMBatchIterator'", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "shuffle", "=", "True", ",", "\n", "subword_augment", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "test_data", "=", "corpus", ".", "get_iterator", "(", "\n", "'test'", ",", "\n", "args", ".", "eval_batch_size", ",", "\n", "args", ".", "max_seqlen", ",", "\n", "iterator_name", "=", "'LMBatchIterator'", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "shuffle", "=", "True", ",", "\n", "subword_augment", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "timer", "=", "Timer", "(", ")", "\n", "\n", "self", ".", "resume_numdata", "=", "-", "1", "\n", "if", "args", ".", "snapshot_dir", "is", "not", "None", ":", "\n", "            ", "print", "(", "'Resuming AGEMOnline from {}'", ".", "format", "(", "args", ".", "snapshot_dir", ")", ")", "\n", "scalar_filepath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "work_dir", ",", "'scalars.json'", ")", "\n", "with", "open", "(", "scalar_filepath", ",", "'r'", ")", "as", "in_file", ":", "\n", "              ", "scalars", "=", "json", ".", "load", "(", "in_file", ")", "\n", "", "self", ".", "resume_numdata", "=", "max", "(", "[", "int", "(", "_", ")", "for", "_", "in", "scalars", "[", "'Train/Num_Data'", "]", ".", "values", "(", ")", "]", ")", "\n", "print", "(", "'Skipping through {} data'", ".", "format", "(", "self", ".", "resume_numdata", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.try_training": [[140, 161], ["enumerate", "online_trainer.OnlineTrainer.evaluate", "online_trainer.OnlineTrainer.learning_algorithm", "len", "online_trainer.OnlineTrainer.try_logging", "online_trainer.OnlineTrainer.try_evaluate", "core.trainer.trainer_utils.step_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.evaluate", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_evaluate", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.step_lr_scheduler"], ["", "", "def", "try_training", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "args", "=", "self", ".", "args", "\n", "assert", "args", ".", "batch_chunk", "==", "1", ",", "'This version requires batch chunk to be 1.'", "\n", "\n", "if", "args", ".", "eval_initial_model", ":", "self", ".", "evaluate", "(", "0", ",", "0", ")", "\n", "for", "batch_id", ",", "online_batch", "in", "enumerate", "(", "self", ".", "train_data", ")", ":", "\n", "# (1) Learning: distribute the learning job for one step", "\n", "            ", "self", ".", "learning_algorithm", "(", "online_batch", ",", "self", ".", "stats", ",", "\n", "skip_optim", "=", "(", "self", ".", "stats", "[", "'num_data'", "]", "<", "self", ".", "resume_numdata", ")", ")", "\n", "\n", "# (2) Postprocess: update global stat tracker", "\n", "self", ".", "stats", "[", "'train_step'", "]", "+=", "1", "\n", "self", ".", "stats", "[", "'num_data'", "]", "+=", "len", "(", "online_batch", "[", "0", "]", ")", "\n", "self", ".", "try_logging", "(", "epoch", ",", "batch_id", ")", "\n", "\n", "# (3) Evaluation (if it is scheduled): evaluate model", "\n", "val_loss", "=", "self", ".", "try_evaluate", "(", "epoch", ",", "batch_id", ")", "\n", "step_lr_scheduler", "(", "self", ".", "args", ",", "self", ".", "scheduler", ",", "self", ".", "optimizer", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ",", "val_loss", ")", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.evaluate": [[162, 193], ["time.time", "core.trainer.trainer_utils.batch_evaluate", "online_trainer.OnlineTrainer.logging", "online_trainer.OnlineTrainer.logging", "online_trainer.OnlineTrainer.logging", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "math.exp", "math.exp", "online_trainer.OnlineTrainer.save_snapshot", "math.exp", "math.exp", "time.time"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.batch_evaluate", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.save_snapshot"], ["", "def", "evaluate", "(", "self", ",", "epoch", ",", "batch_id", ")", ":", "\n", "        ", "self", ".", "stats", "[", "'eval_start_time'", "]", "=", "time", ".", "time", "(", ")", "\n", "# batch evaluate", "\n", "val_token_loss", ",", "val_word_loss", "=", "batch_evaluate", "(", "self", ".", "val_data", ",", "self", ".", "model", ",", "self", ".", "args", ")", "\n", "self", ".", "logging", "(", "'-'", "*", "125", ")", "\n", "log_str", "=", "'| Eval {:3d} at step {:>8d} | time: {:5.2f}s | val loss {:5.2f}'", ".", "format", "(", "\n", "self", ".", "stats", "[", "'train_step'", "]", "//", "self", ".", "eval_interval", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ",", "\n", "(", "time", ".", "time", "(", ")", "-", "self", ".", "stats", "[", "'eval_start_time'", "]", ")", ",", "\n", "val_word_loss", "\n", ")", "\n", "log_str", "+=", "' | val token/word ppl {:9.3f} / {:9.3f} '", ".", "format", "(", "\n", "math", ".", "exp", "(", "val_token_loss", ")", ",", "\n", "math", ".", "exp", "(", "val_word_loss", ")", "\n", ")", "\n", "self", ".", "logging", "(", "log_str", ")", "\n", "self", ".", "logging", "(", "'-'", "*", "125", ")", "\n", "\n", "# Save the model with best validation loss", "\n", "if", "not", "self", ".", "stats", "[", "'best_val_loss'", "]", "or", "val_word_loss", "<", "self", ".", "stats", "[", "'best_val_loss'", "]", ":", "\n", "            ", "self", ".", "save_snapshot", "(", ")", "\n", "self", ".", "stats", "[", "'best_val_loss'", "]", "=", "val_word_loss", "\n", "\n", "", "self", ".", "logger", ".", "add_scalar", "(", "'Validate/Token_Perplexity'", ",", "\n", "math", ".", "exp", "(", "val_token_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Validate/Word_Perplexity'", ",", "\n", "math", ".", "exp", "(", "val_word_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "return", "val_token_loss", ",", "val_word_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.try_evaluate": [[194, 200], ["online_trainer.OnlineTrainer.evaluate"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.evaluate"], ["", "def", "try_evaluate", "(", "self", ",", "epoch", ",", "batch_id", ")", ":", "\n", "        ", "val_token_loss", "=", "None", "\n", "val_word_loss", "=", "None", "\n", "if", "(", "self", ".", "stats", "[", "'train_step'", "]", "%", "self", ".", "eval_interval", "==", "0", ")", "and", "(", "self", ".", "stats", "[", "'num_data'", "]", ">", "self", ".", "resume_numdata", ")", ":", "\n", "          ", "val_token_loss", ",", "val_word_loss", "=", "self", ".", "evaluate", "(", "epoch", ",", "batch_id", ")", "\n", "", "return", "val_word_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.online_trainer.OnlineTrainer.try_logging": [[201, 263], ["online_trainer.OnlineTrainer.logging", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.add_scalar", "online_trainer.OnlineTrainer.logger.dump", "time.time", "max", "max", "max", "max", "time.time", "online_trainer.OnlineTrainer.timer.measure", "math.exp", "math.exp", "math.exp", "math.exp", "math.exp"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.add_scalar", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.logger.Logger.dump", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Timer.measure"], ["", "def", "try_logging", "(", "self", ",", "epoch", ",", "batch_id", ")", ":", "\n", "        ", "if", "self", ".", "stats", "[", "'train_step'", "]", "%", "self", ".", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "train_word_loss", "=", "self", ".", "stats", "[", "'total_loss'", "]", "/", "max", "(", "self", ".", "stats", "[", "'total_word_count'", "]", ",", "1e-10", ")", "\n", "train_token_loss", "=", "self", ".", "stats", "[", "'total_loss'", "]", "/", "max", "(", "self", ".", "stats", "[", "'total_token_count'", "]", ",", "1e-10", ")", "\n", "online_word_loss", "=", "self", ".", "stats", "[", "'online_loss'", "]", "/", "max", "(", "self", ".", "stats", "[", "'online_word_count'", "]", ",", "1e-10", ")", "\n", "online_token_loss", "=", "self", ".", "stats", "[", "'online_loss'", "]", "/", "max", "(", "self", ".", "stats", "[", "'online_token_count'", "]", ",", "1e-10", ")", "\n", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "self", ".", "stats", "[", "'log_start_time'", "]", "\n", "log_str", "=", "'| global timer {} | epoch {:3d} step {:>8d} | {:>6d} batches | lr {:.2g} '", "'| ms/batch {:5.2f} | total loss {:5.2f} '", "'| online loss {:5.2f}'", ".", "format", "(", "\n", "self", ".", "timer", ".", "measure", "(", ")", ",", "\n", "epoch", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ",", "\n", "batch_id", "+", "1", ",", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "self", ".", "args", ".", "log_interval", ",", "\n", "train_token_loss", ",", "\n", "online_token_loss", ",", "\n", ")", "\n", "log_str", "+=", "' | online token ppl {:9.3f}'", ".", "format", "(", "\n", "math", ".", "exp", "(", "online_token_loss", ")", "\n", ")", "\n", "self", ".", "logging", "(", "log_str", ")", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Online/Token_Perplexity'", ",", "\n", "math", ".", "exp", "(", "online_token_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Online/Word_Perplexity'", ",", "\n", "math", ".", "exp", "(", "online_word_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Train/Token_Perplexity'", ",", "\n", "math", ".", "exp", "(", "train_token_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Train/Word_Perplexity'", ",", "\n", "math", ".", "exp", "(", "train_word_loss", ")", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Train/Num_Updates'", ",", "\n", "self", ".", "stats", "[", "'num_updates'", "]", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "add_scalar", "(", "'Train/Num_Data'", ",", "\n", "self", ".", "stats", "[", "'num_data'", "]", ",", "\n", "self", ".", "stats", "[", "'train_step'", "]", ")", "\n", "\n", "self", ".", "logger", ".", "dump", "(", ")", "\n", "\n", "# reset stats", "\n", "self", ".", "stats", "[", "'total_loss'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'total_word_count'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'total_token_count'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'online_loss'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'online_word_count'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'online_token_count'", "]", "=", "0", "\n", "self", ".", "stats", "[", "'log_start_time'", "]", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.__init__": [[27, 75], ["torch.device", "torch.device", "torch.device", "torch.device", "core.trainer.trainer_utils.prepare_logger", "len", "core.trainer.trainer_utils.prepare_model", "sum", "sum", "sum", "core.trainer.trainer_utils.prepare_optimizer", "core.trainer.trainer_utils.prepare_scheduler", "time.time", "time.time", "base_trainer.BaseTrainer.logging", "args.__dict__.items", "base_trainer.BaseTrainer.logging", "base_trainer.BaseTrainer.logging", "base_trainer.BaseTrainer.logging", "core.logger.Logger", "base_trainer.BaseTrainer.logging", "base_trainer.BaseTrainer.load_snapshot", "p.nelement", "p.nelement", "isinstance", "base_trainer.BaseTrainer.load_weight", "print", "base_trainer.BaseTrainer.model.parameters", "base_trainer.BaseTrainer.model.layers.parameters", "p.nelement", "base_trainer.BaseTrainer.model.mtl_layers.parameters"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_logger", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_model", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_optimizer", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_scheduler", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.logging", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_snapshot", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_weight"], ["def", "__init__", "(", "self", ",", "\n", "args", ",", "\n", "corpus", ":", "Corpus", ",", "\n", "scripts_to_save", ",", "\n", ")", ":", "\n", "\n", "# Specify device", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "args", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "corpus", "=", "corpus", "\n", "self", ".", "logging", "=", "prepare_logger", "(", "args", ",", "scripts_to_save", ")", "\n", "\n", "self", ".", "args", ".", "n_user", "=", "len", "(", "corpus", ".", "user_dict", ")", "\n", "self", ".", "model", ",", "self", ".", "para_model", "=", "prepare_model", "(", "self", ".", "args", ",", "self", ".", "device", ")", "\n", "self", ".", "args", ".", "n_all_param", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "]", ")", "\n", "self", ".", "args", ".", "n_nonemb_param", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "self", ".", "model", ".", "layers", ".", "parameters", "(", ")", "]", ")", "\n", "self", ".", "args", ".", "n_nonemb_param", "+=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "self", ".", "model", ".", "mtl_layers", ".", "parameters", "(", ")", "]", "if", "isinstance", "(", "self", ".", "model", ",", "MTLMemTransformerLM", ")", "else", "[", "]", ")", "\n", "\n", "self", ".", "optimizer", "=", "prepare_optimizer", "(", "self", ".", "args", ",", "self", ".", "model", ")", "\n", "self", ".", "scheduler", "=", "prepare_scheduler", "(", "self", ".", "args", ",", "self", ".", "optimizer", ")", "\n", "self", ".", "max_step", "=", "self", ".", "args", ".", "max_step", "\n", "\n", "self", ".", "train_step", "=", "0", "\n", "self", ".", "train_loss", "=", "0", "\n", "self", ".", "train_word_length", "=", "0", "\n", "self", ".", "train_token_length", "=", "0", "\n", "self", ".", "best_val_loss", "=", "None", "\n", "self", ".", "eval_start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "log_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Finish starting up", "\n", "self", ".", "logging", "(", "'='", "*", "100", ")", "\n", "for", "k", ",", "v", "in", "args", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "logging", "(", "'    - {} : {}'", ".", "format", "(", "k", ",", "v", ")", ")", "\n", "", "self", ".", "logging", "(", "'='", "*", "100", ")", "\n", "self", ".", "logging", "(", "'#params = {}'", ".", "format", "(", "self", ".", "args", ".", "n_all_param", ")", ")", "\n", "self", ".", "logging", "(", "'#non emb params = {}'", ".", "format", "(", "self", ".", "args", ".", "n_nonemb_param", ")", ")", "\n", "\n", "# Tensorboard Support", "\n", "self", ".", "logger", "=", "Logger", "(", "args", ",", "self", ".", "args", ".", "work_dir", ",", "flush_secs", "=", "10", ")", "\n", "if", "args", ".", "snapshot_dir", "is", "not", "None", ":", "\n", "          ", "self", ".", "load_snapshot", "(", ")", "\n", "", "elif", "args", ".", "init_weights", "is", "not", "None", ":", "\n", "          ", "self", ".", "load_weight", "(", "args", ".", "init_weights", ")", "\n", "", "else", ":", "\n", "          ", "print", "(", "\"[Warning] Random initialized model\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train": [[76, 79], ["base_trainer.BaseTrainer.model.train", "base_trainer.BaseTrainer.try_training"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_training"], ["", "", "def", "train", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "return", "self", ".", "try_training", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_training": [[80, 83], ["NotImplementedError"], "methods", ["None"], ["", "def", "try_training", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Trainer specific function not implemented:'", "\n", "+", "' try_evaluate(self, epoch, batch)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_evaluate": [[84, 87], ["NotImplementedError"], "methods", ["None"], ["", "def", "try_evaluate", "(", "self", ",", "epoch", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Trainer specific function not implemented:'", "\n", "+", "' try_evaluate(self, epoch, batch)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.try_logging": [[88, 91], ["NotImplementedError"], "methods", ["None"], ["", "def", "try_logging", "(", "self", ",", "epoch", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Trainer specific function not implemented:'", "\n", "+", "' try_logging(self, epoch, batch)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.save_snapshot": [[92, 102], ["os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "base_trainer.BaseTrainer.model.state_dict", "base_trainer.BaseTrainer.optimizer.state_dict"], "methods", ["None"], ["", "def", "save_snapshot", "(", "self", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "\"\"\"Save Model Snapshots\"\"\"", "\n", "model_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "work_dir", ",", "'model.pt'", "if", "epoch", "is", "None", "else", "'model_epoch{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "optimizer_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "work_dir", ",", "'optimizer.pt'", "if", "epoch", "is", "None", "else", "'optimizer_epoch{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "model_filepath", ")", "\n", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "optimizer_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_snapshot": [[103, 113], ["print", "os.path.join", "os.path.join", "base_trainer.BaseTrainer.load_weight", "base_trainer.BaseTrainer.load_optimizer"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_weight", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_optimizer"], ["", "def", "load_snapshot", "(", "self", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "print", "(", "'[*] Load weight and optimizer of epoch {}'", ".", "format", "(", "'last'", "if", "epoch", "is", "None", "else", "'#{}'", ".", "format", "(", "epoch", ")", ")", ")", "\n", "model_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "work_dir", ",", "'model.pt'", "if", "epoch", "is", "None", "else", "'model_epoch{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "optimizer_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "work_dir", ",", "'optimizer.pt'", "if", "epoch", "is", "None", "else", "'optimizer_epoch{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "self", ".", "load_weight", "(", "model_filepath", ")", "\n", "self", ".", "load_optimizer", "(", "optimizer_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_optimizer": [[114, 116], ["base_trainer.BaseTrainer.optimizer.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "load_optimizer", "(", "self", ",", "optimizer_filepath", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_filepath", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.load_weight": [[117, 127], ["torch.load", "torch.load", "torch.load", "torch.load", "base_trainer.BaseTrainer.model.state_dict", "torch.load.keys", "torch.load.keys", "base_trainer.BaseTrainer.keys", "print", "base_trainer.BaseTrainer.update", "base_trainer.BaseTrainer.model.load_state_dict", "base_trainer.BaseTrainer.model.load_state_dict", "torch.load.items", "torch.load.items"], "methods", ["None"], ["", "def", "load_weight", "(", "self", ",", "model_filepath", ")", ":", "\n", "        ", "loaded_state_dict", "=", "torch", ".", "load", "(", "model_filepath", ")", "\n", "current_state_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "if", "loaded_state_dict", ".", "keys", "(", ")", "!=", "current_state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "print", "(", "'[WARNING] Load only the partial model parameters...'", ")", "\n", "loaded_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "loaded_state_dict", ".", "items", "(", ")", "if", "k", "in", "current_state_dict", "}", "\n", "current_state_dict", ".", "update", "(", "loaded_state_dict", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "current_state_dict", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "loaded_state_dict", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.batch_evaluate": [[10, 33], ["model.eval", "model.reset_length", "model.train", "model.reset_length", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tuple", "enumerate", "tqdm", "model", "loss.sum().float().item", "word_len.sum().item", "token_len.sum().item", "loss.sum().float", "word_len.sum", "token_len.sum", "loss.sum"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.reset_length", "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.firehose-dataset_congrad.models.mem_transformer.MemTransformerLM.reset_length", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item", "home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.Averager.item"], ["def", "batch_evaluate", "(", "eval_data", ",", "model", ",", "args", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "model", ".", "reset_length", "(", "280", ",", "0", ")", "\n", "\n", "# Evaluation", "\n", "total_word_len", ",", "total_token_len", ",", "total_loss", "=", "0", ",", "0", ",", "0.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "verbose", ":", "eval_data", "=", "tqdm", "(", "eval_data", ",", "ncols", "=", "64", ")", "\n", "mems", "=", "tuple", "(", ")", "\n", "for", "i", ",", "(", "data", ",", "target", ",", "user", ",", "token_len", ",", "word_len", ")", "in", "enumerate", "(", "eval_data", ")", ":", "\n", "            ", "if", "args", ".", "max_eval_steps", ">", "0", "and", "i", ">=", "args", ".", "max_eval_steps", ":", "\n", "                ", "break", "\n", "", "ret", "=", "model", "(", "data", ",", "target", ",", "user", ",", "*", "mems", ")", "\n", "loss", ",", "mems", "=", "ret", "[", "0", "]", ",", "ret", "[", "1", ":", "]", "\n", "total_loss", "+=", "loss", ".", "sum", "(", ")", ".", "float", "(", ")", ".", "item", "(", ")", "\n", "total_word_len", "+=", "word_len", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "total_token_len", "+=", "token_len", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Switch back to the training mode", "\n", "", "", "model", ".", "train", "(", ")", "\n", "model", ".", "reset_length", "(", "args", ".", "max_seqlen", ",", "0", ")", "\n", "\n", "return", "total_loss", "/", "total_token_len", ",", "total_loss", "/", "total_word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_buffer": [[35, 56], ["core.memories.GreedyBuffer", "core.memories.ReservoirBuffer", "core.memories.StratifiedBuffer", "core.memories.StratifiedBuffer", "ValueError"], "function", ["None"], ["", "def", "prepare_buffer", "(", "buffer_strategy", ",", "per_user_buffer_size", ",", "total_buffer_size", ",", "max_seqlen", ")", ":", "\n", "    ", "memory_buffer", "=", "None", "\n", "# setup replay buffer", "\n", "if", "buffer_strategy", "==", "'greedy'", ":", "\n", "        ", "memory_buffer", "=", "GreedyBuffer", "(", "total_buffer_size", ",", "\n", "max_seqlen", "=", "max_seqlen", ")", "\n", "", "elif", "buffer_strategy", "==", "'reservoir'", ":", "\n", "        ", "memory_buffer", "=", "ReservoirBuffer", "(", "total_buffer_size", ",", "\n", "max_seqlen", "=", "max_seqlen", ")", "\n", "", "elif", "buffer_strategy", "==", "'stratified'", ":", "\n", "        ", "memory_buffer", "=", "StratifiedBuffer", "(", "per_user_buffer_size", ",", "\n", "buffer_class", "=", "'GreedyBuffer'", ",", "\n", "max_seqlen", "=", "max_seqlen", ")", "\n", "", "elif", "buffer_strategy", "==", "'stratified-reservoir'", ":", "\n", "        ", "memory_buffer", "=", "StratifiedBuffer", "(", "per_user_buffer_size", ",", "\n", "buffer_class", "=", "'ReservoirBuffer'", ",", "\n", "max_seqlen", "=", "max_seqlen", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unsupported Strategy: {}.'", ".", "format", "(", "buffer_strategy", ")", ")", "\n", "\n", "", "return", "memory_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_logger": [[58, 64], ["core.exp_utils.create_exp_dir"], "function", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.core.exp_utils.create_exp_dir"], ["", "def", "prepare_logger", "(", "args", ",", "scripts_to_save", "=", "None", ")", ":", "\n", "    ", "logging", "=", "create_exp_dir", "(", "args", ".", "work_dir", ",", "\n", "scripts_to_save", "=", "scripts_to_save", ",", "\n", "debug", "=", "args", ".", "debug", "\n", ")", "\n", "return", "logging", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_scheduler": [[66, 89], ["torch.lr_scheduler.CosineAnnealingLR", "torch.lr_scheduler.LambdaLR", "torch.lr_scheduler.LambdaLR"], "function", ["None"], ["", "def", "prepare_scheduler", "(", "args", ",", "optimizer", ")", ":", "\n", "    ", "if", "args", ".", "scheduler", "==", "'cosine'", ":", "\n", "# here we do not set eta_min to lr_min to be backward compatible", "\n", "# because in previous versions eta_min is default to 0", "\n", "# rather than the default value of lr_min 1e-6", "\n", "        ", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "\n", "args", ".", "max_step", ",", "eta_min", "=", "args", ".", "eta_min", ")", "# should use eta_min arg", "\n", "", "elif", "args", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "# originally used for Transformer (in Attention is all you need)", "\n", "        ", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# return a multiplier instead of a learning rate", "\n", "            ", "if", "step", "==", "0", "and", "args", ".", "warmup_step", "==", "0", ":", "\n", "                ", "return", "1.", "\n", "", "else", ":", "\n", "                ", "return", "1.", "/", "(", "step", "**", "0.5", ")", "if", "step", ">", "args", ".", "warmup_step", "else", "step", "/", "(", "args", ".", "warmup_step", "**", "1.5", ")", "\n", "", "", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lr_lambda", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "'constant'", ":", "\n", "        ", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# return a multiplier instead of a learning rate", "\n", "            ", "return", "1.", "\n", "", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lr_lambda", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.step_lr_scheduler": [[90, 103], ["scheduler.step", "scheduler.step", "scheduler.step"], "function", ["None"], ["", "def", "step_lr_scheduler", "(", "args", ",", "scheduler", ",", "optimizer", ",", "train_step", ",", "val_loss", "=", "None", ")", ":", "\n", "    ", "if", "args", ".", "scheduler", "in", "[", "'cosine'", ",", "'constant'", ",", "'dev_perf'", "]", ":", "\n", "# linear warmup stage", "\n", "        ", "if", "train_step", "<", "args", ".", "warmup_step", ":", "\n", "            ", "curr_lr", "=", "args", ".", "lr", "*", "train_step", "/", "args", ".", "warmup_step", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "curr_lr", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "scheduler", "==", "'cosine'", ":", "\n", "                ", "scheduler", ".", "step", "(", "train_step", ")", "\n", "", "elif", "args", ".", "scheduler", "==", "'dev_perf'", "and", "val_loss", "is", "not", "None", ":", "\n", "                ", "scheduler", ".", "step", "(", "val_loss", ")", "\n", "", "", "", "elif", "args", ".", "scheduler", "==", "'inv_sqrt'", ":", "\n", "        ", "scheduler", ".", "step", "(", "train_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_model": [[105, 211], ["torch.init.constant_", "hasattr", "model.float.apply", "model.float.apply", "eval", "eval.", "model.float.apply", "model.float.word_emb.apply", "model.float.to", "model.float.to", "torch.init.uniform_", "classname.find", "classname.find", "hasattr", "open", "torch.load", "torch.load", "torch.load", "model.float.float", "core.dataset.utils.BalancedDataParallel().to", "torch.DataParallel().to", "torch.init.normal_", "hasattr", "trainer_utils.prepare_model.init_weight"], "function", ["None"], ["", "", "def", "prepare_model", "(", "args", ",", "device", ")", ":", "\n", "###############################################################################", "\n", "# init methods (takes args locally)", "\n", "###############################################################################", "\n", "    ", "def", "init_weight", "(", "weight", ")", ":", "\n", "        ", "if", "args", ".", "init", "==", "'uniform'", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "args", ".", "init_range", ",", "args", ".", "init_range", ")", "\n", "", "elif", "args", ".", "init", "==", "'normal'", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "args", ".", "init_std", ")", "\n", "\n", "", "", "def", "init_bias", "(", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n", "", "def", "weights_init", "(", "m", ")", ":", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'AdaptiveEmbedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'emb_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "args", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'Embedding'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'ProjectedAdaptiveLogSoftmax'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'cluster_weight'", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'cluster_bias'", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'out_projs'", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "args", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "'LayerNorm'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "args", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'TransformerLM'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'r_emb'", ")", ":", "\n", "                ", "init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_w_bias'", ")", ":", "\n", "                ", "init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_r_bias'", ")", ":", "\n", "                ", "init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'r_bias'", ")", ":", "\n", "                ", "init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n", "", "", "", "def", "update_dropout", "(", "m", ")", ":", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Dropout'", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'p'", ")", ":", "\n", "                ", "m", ".", "p", "=", "args", ".", "dropout", "\n", "\n", "", "", "", "def", "update_dropatt", "(", "m", ")", ":", "\n", "        ", "if", "hasattr", "(", "m", ",", "'dropatt'", ")", ":", "\n", "            ", "m", ".", "dropatt", ".", "p", "=", "args", ".", "dropatt", "\n", "\n", "", "", "if", "args", ".", "resume", ":", "\n", "        ", "assert", "args", ".", "resume_dir", ",", "\"Resume directory must be non-empty.\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "resume_dir", ",", "'model.pt'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "model", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "if", "not", "args", ".", "fp16", ":", "\n", "            ", "model", "=", "model", ".", "float", "(", ")", "\n", "", "model", ".", "apply", "(", "update_dropout", ")", "\n", "model", ".", "apply", "(", "update_dropatt", ")", "\n", "", "else", ":", "\n", "        ", "model_class", "=", "eval", "(", "args", ".", "model_class", ")", "\n", "model", "=", "model_class", "(", "\n", "args", ".", "n_user", ",", "\n", "args", ".", "n_token", ",", "\n", "args", ".", "n_layer", ",", "\n", "args", ".", "n_head", ",", "\n", "args", ".", "d_model", ",", "\n", "args", ".", "d_head", ",", "\n", "args", ".", "d_inner", ",", "\n", "args", ".", "dropout", ",", "\n", "args", ".", "dropatt", ",", "\n", "tgt_len", "=", "args", ".", "max_seqlen", ",", "\n", "ext_len", "=", "0", ",", "# no extension", "\n", "mem_len", "=", "0", ",", "# no memory", "\n", "mtl_type", "=", "args", ".", "mtl_type", ",", "\n", "tie_weight", "=", "args", ".", "tie_weight", ",", "\n", "d_embed", "=", "args", ".", "d_embed", ",", "\n", "d_user_embed", "=", "args", ".", "d_user_embed", ",", "\n", "mtl_width", "=", "args", ".", "mtl_width", ",", "\n", "mtl_depth", "=", "args", ".", "mtl_depth", ",", "\n", "clamp_len", "=", "args", ".", "clamp_len", ")", "\n", "model", ".", "apply", "(", "weights_init", ")", "\n", "model", ".", "word_emb", ".", "apply", "(", "weights_init", ")", "# ensure embedding init is not overridden by out_layer in case of weight sharing", "\n", "\n", "", "if", "args", ".", "multi_gpu", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "if", "args", ".", "gpu0_bsz", ">=", "0", ":", "\n", "            ", "para_model", "=", "BalancedDataParallel", "(", "args", ".", "gpu0_bsz", "//", "args", ".", "batch_chunk", ",", "\n", "model", ",", "dim", "=", "1", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "para_model", "=", "nn", ".", "DataParallel", "(", "model", ",", "dim", "=", "1", ")", ".", "to", "(", "device", ")", "\n", "", "", "else", ":", "\n", "        ", "para_model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "", "return", "model", ",", "para_model", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.trainer.trainer_utils.prepare_optimizer": [[213, 233], ["isinstance", "model.parameters", "args.optim.lower", "torch.SGD", "args.optim.lower", "torch.Adam", "model.word_emb.parameters", "model.layers.parameters", "model.user_emb.parameters", "model.mtl_layers.parameters", "args.optim.lower", "torch.Adagrad"], "function", ["None"], ["", "def", "prepare_optimizer", "(", "args", ",", "model", ")", ":", "\n", "    ", "if", "isinstance", "(", "model", ",", "MTLMemTransformerLM", ")", "and", "args", ".", "async_lr", ":", "\n", "        ", "params", "=", "[", "\n", "{", "'params'", ":", "model", ".", "word_emb", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "/", "10.0", "}", ",", "\n", "{", "'params'", ":", "model", ".", "layers", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "/", "10.0", "}", ",", "\n", "{", "'params'", ":", "model", ".", "user_emb", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "}", ",", "\n", "{", "'params'", ":", "model", ".", "mtl_layers", ".", "parameters", "(", ")", ",", "'lr'", ":", "args", ".", "lr", "}", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "params", "=", "model", ".", "parameters", "(", ")", "\n", "\n", "", "if", "args", ".", "optim", ".", "lower", "(", ")", "==", "'sgd'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "mom", ")", "\n", "", "elif", "args", ".", "optim", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "args", ".", "lr", ")", "\n", "", "elif", "args", ".", "optim", ".", "lower", "(", ")", "==", "'adagrad'", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adagrad", "(", "params", ",", "lr", "=", "args", ".", "lr", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.__init__": [[5, 39], ["int", "len", "len", "print", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data", ",", "\n", "users", ",", "\n", "device", "=", "'cpu'", ",", "\n", "ext_len", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "\n", "vocab", "=", "None", ",", "\n", "subword_augment", "=", "False", ",", "\n", "user_dict", "=", "None", ",", "\n", "break_ratio", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n            data  -- list[LongTensor] -- there is no order among the LongTensors\n            users -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "assert", "vocab", "is", "not", "None", "\n", "self", ".", "sents", "=", "data", "\n", "self", ".", "users", "=", "users", "\n", "\n", "num_data", "=", "int", "(", "len", "(", "self", ".", "sents", ")", "*", "break_ratio", ")", "\n", "if", "num_data", "<", "len", "(", "self", ".", "sents", ")", ":", "\n", "          ", "orig_sent_num", "=", "len", "(", "self", ".", "sents", ")", "\n", "self", ".", "sents", "=", "self", ".", "sents", "[", ":", "num_data", "]", "\n", "self", ".", "users", "=", "self", ".", "users", "[", ":", "num_data", "]", "\n", "print", "(", "'[Warning] Only considering {} data (out of {} data).'", ".", "format", "(", "len", "(", "self", ".", "sents", ")", ",", "orig_sent_num", ")", ")", "\n", "\n", "", "self", ".", "user_dict", "=", "user_dict", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "subword_augment", "=", "subword_augment", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.__iter__": [[40, 56], ["online_iter.LMOnlineIterator.get_sent_stream", "online_iter.LMOnlineIterator.vocab.encode_as_ids", "torch.LongTensor().view", "torch.LongTensor().view", "target.fill_.fill_.fill_", "torch.LongTensor().view.size", "sum", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_sent_stream", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "sent", ",", "user", "in", "sent_stream", ":", "\n", "            ", "wordpieces", ",", "wordends", "=", "self", ".", "vocab", ".", "encode_as_ids", "(", "sent", ",", "sample", "=", "self", ".", "subword_augment", ")", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "wordpieces", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "wordpieces", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "\n", "target", "=", "target", ".", "fill_", "(", "-", "1", ")", "\n", "target", "[", ":", "-", "1", "]", "=", "data", "[", "1", ":", "]", "\n", "\n", "token_len", "=", "data", ".", "size", "(", "-", "1", ")", "\n", "word_len", "=", "sum", "(", "wordends", ")", "\n", "\n", "yield", "data", ",", "target", ",", "user", ",", "token_len", ",", "word_len", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_sent_stream": [[57, 66], ["len", "numpy.random.permutation", "numpy.array", "range"], "methods", ["None"], ["", "", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "num_sents", "=", "len", "(", "self", ".", "sents", ")", "\n", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "num_sents", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "num_sents", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "sents", "[", "idx", "]", ",", "self", ".", "users", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_data": [[67, 69], ["None"], "methods", ["None"], ["", "", "def", "get_data", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "sents", "[", "idx", "]", ",", "self", ".", "users", "[", "idx", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.__init__": [[8, 26], ["core.iterators.LMOnlineIterator", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "data", ",", "\n", "user", ",", "\n", "bsz", ",", "\n", "maxlen", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "_wrapped_iter", "=", "LMOnlineIterator", "(", "\n", "data", ",", "\n", "user", ",", "\n", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "print", "(", "\"[WARNING] {} truncates text with maximum length of {} tokens (Whilst Max Twitter Size = 280 Character).\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "maxlen", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.stream_iterator": [[28, 57], ["range", "next", "onepass_iter.LMOnePassIterator.vocab.encode_as_ids", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids"], ["", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "        ", "wordpieces", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "wordends", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "users", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "batch_size", "=", "self", ".", "bsz", "\n", "while", "True", ":", "\n", "            ", "valid_batch", "=", "True", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "while", "True", ":", "\n", "                        ", "sent", ",", "users", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "wordpieces", "[", "i", "]", ",", "wordends", "[", "i", "]", "=", "self", ".", "vocab", ".", "encode_as_ids", "(", "sent", ",", "sample", "=", "self", ".", "subword_augment", ")", "\n", "\n", "# discard tweets that is longer than max length", "\n", "if", "len", "(", "wordpieces", "[", "i", "]", ")", "<=", "self", ".", "maxlen", ":", "break", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "\n", "# last batch has number of instances smaller than i", "\n", "batch_size", "=", "i", "\n", "wordpieces", "=", "wordpieces", "[", ":", "batch_size", "]", "\n", "wordends", "=", "wordends", "[", ":", "batch_size", "]", "\n", "users", "=", "users", "[", ":", "batch_size", "]", "\n", "break", "\n", "\n", "", "", "yield", "wordpieces", ",", "wordends", ",", "users", "\n", "\n", "if", "not", "valid_batch", ":", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.get_batch": [[58, 74], ["len", "enumerate", "min", "core.dataset.utils.encap_batch", "range", "onepass_iter.LMOnePassIterator.get_data", "onepass_iter.LMOnePassIterator.vocab.encode_as_ids", "max", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch", "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_data", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids"], ["", "", "def", "get_batch", "(", "self", ",", "batch_id", ")", ":", "\n", "        ", "num_batch", "=", "len", "(", "self", ")", "\n", "assert", "batch_id", "<", "num_batch", ",", "'[Fatal error]'", "\n", "start_id", "=", "batch_id", "*", "self", ".", "bsz", "\n", "end_id", "=", "(", "batch_id", "+", "1", ")", "*", "self", ".", "bsz", "\n", "\n", "wordpieces", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "wordends", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "users", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "for", "i", ",", "data_id", "in", "enumerate", "(", "range", "(", "start_id", ",", "end_id", ")", ")", ":", "\n", "            ", "sent", ",", "users", "[", "i", "]", "=", "self", ".", "get_data", "(", "data_id", ")", "\n", "wordpieces", "[", "i", "]", ",", "wordends", "[", "i", "]", "=", "self", ".", "vocab", ".", "encode_as_ids", "(", "sent", ",", "sample", "=", "self", ".", "subword_augment", ")", "\n", "\n", "", "bptt", "=", "min", "(", "max", "(", "[", "len", "(", "wp", ")", "for", "wp", "in", "wordpieces", "]", ")", ",", "self", ".", "maxlen", ")", "\n", "\n", "return", "encap_batch", "(", "(", "wordpieces", ",", "wordends", ",", "users", ")", ",", "bptt", ",", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.__iter__": [[75, 81], ["onepass_iter.LMOnePassIterator.get_sent_stream", "onepass_iter.LMOnePassIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_sent_stream", "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.wrapped_iter": [[82, 85], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "wrapped_iter", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_wrapped_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.__getattr__": [[86, 90], ["getattr", "AttributeError"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "==", "'_wrapped_iter'", ":", "\n", "            ", "raise", "AttributeError", "(", ")", "\n", "", "return", "getattr", "(", "self", ".", "_wrapped_iter", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.__str__": [[91, 93], ["type"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'{}({})'", ".", "format", "(", "type", "(", "self", ")", ".", "__name__", ",", "self", ".", "wrapped_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.onepass_iter.LMOnePassIterator.__len__": [[94, 96], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sents", ")", "//", "self", ".", "bsz", "\n", "", "", ""]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__init__": [[8, 23], ["core.iterators.LMOnlineIterator", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "user", ",", "bsz", ",", "maxlen", ",", "*", "args", ",", "break_ratio", "=", "1.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_wrapped_iter", "=", "LMOnlineIterator", "(", "\n", "data", ",", "\n", "user", ",", "\n", "*", "args", ",", "\n", "break_ratio", "=", "break_ratio", ",", "\n", "**", "kwargs", ")", "\n", "\n", "self", ".", "break_ratio", "=", "break_ratio", "\n", "self", ".", "bsz", "=", "bsz", "\n", "# In Twitter domain, all text is under 280 characters", "\n", "self", ".", "maxlen", "=", "maxlen", "\n", "print", "(", "\"[WARNING] {} truncates text with maximum length of {} tokens (Whilst Max Twitter Size = 280 Character).\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "maxlen", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.stream_iterator": [[25, 55], ["range", "next", "batch_iter.LMBatchIterator.vocab.encode_as_ids", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.vocabulary.Vocab.encode_as_ids"], ["", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "        ", "wordpieces", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "wordends", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "users", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "batch_size", "=", "self", ".", "bsz", "\n", "while", "True", ":", "\n", "            ", "valid_batch", "=", "True", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "while", "True", ":", "\n", "                        ", "sent", ",", "users", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "wordpieces", "[", "i", "]", ",", "wordends", "[", "i", "]", "=", "self", ".", "vocab", ".", "encode_as_ids", "(", "sent", ",", "sample", "=", "self", ".", "subword_augment", ")", "\n", "\n", "# discard tweets that is longer than max length", "\n", "if", "len", "(", "wordpieces", "[", "i", "]", ")", "<=", "self", ".", "maxlen", ":", "break", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "\n", "# last batch has number of instances smaller than i", "\n", "batch_size", "=", "i", "\n", "wordpieces", "=", "wordpieces", "[", ":", "batch_size", "]", "\n", "wordends", "=", "wordends", "[", ":", "batch_size", "]", "\n", "users", "=", "users", "[", ":", "batch_size", "]", "\n", "break", "\n", "\n", "", "", "yield", "wordpieces", ",", "wordends", ",", "users", "\n", "\n", "if", "not", "valid_batch", ":", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.wrapped_iter": [[56, 59], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "wrapped_iter", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_wrapped_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__getattr__": [[60, 64], ["getattr", "AttributeError"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "        ", "if", "attr", "==", "'_wrapped_iter'", ":", "\n", "            ", "raise", "AttributeError", "(", ")", "\n", "", "return", "getattr", "(", "self", ".", "_wrapped_iter", ",", "attr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__str__": [[65, 67], ["type"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'{}({})'", ".", "format", "(", "type", "(", "self", ")", ".", "__name__", ",", "self", ".", "wrapped_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__iter__": [[68, 75], ["batch_iter.LMBatchIterator.get_sent_stream", "batch_iter.LMBatchIterator.stream_iterator", "min", "max", "core.dataset.utils.encap_batch", "len"], "methods", ["home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.online_iter.LMOnlineIterator.get_sent_stream", "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.stream_iterator", "home.repos.pwc.inspect_result.firehose-dataset_congrad.dataset.utils.encap_batch"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "bptt", "=", "min", "(", "max", "(", "[", "len", "(", "wp", ")", "for", "wp", "in", "batch", "[", "0", "]", "]", ")", ",", "self", ".", "maxlen", ")", "\n", "yield", "encap_batch", "(", "batch", ",", "bptt", ",", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.firehose-dataset_congrad.iterators.batch_iter.LMBatchIterator.__len__": [[76, 78], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sents", ")", "//", "self", ".", "bsz", "\n", "", "", ""]]}