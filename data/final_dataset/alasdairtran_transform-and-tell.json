{"home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.backend.manage.main": [[7, 18], ["os.environ.setdefault", "execute_from_command_line", "ImportError"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "os", ".", "environ", ".", "setdefault", "(", "'DJANGO_SETTINGS_MODULE'", ",", "'backend.settings'", ")", "\n", "try", ":", "\n", "        ", "from", "django", ".", "core", ".", "management", "import", "execute_from_command_line", "\n", "", "except", "ImportError", "as", "exc", ":", "\n", "        ", "raise", "ImportError", "(", "\n", "\"Couldn't import Django. Are you sure it's installed and \"", "\n", "\"available on your PYTHONPATH environment variable? Did you \"", "\n", "\"forget to activate a virtual environment?\"", "\n", ")", "from", "exc", "\n", "", "execute_from_command_line", "(", "sys", ".", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.views.visitor_ip_address": [[16, 24], ["request.META.get", "request.META.get", "request.META.get.split"], "function", ["None"], ["def", "visitor_ip_address", "(", "request", ")", ":", "\n", "    ", "x_forwarded_for", "=", "request", ".", "META", ".", "get", "(", "'HTTP_X_FORWARDED_FOR'", ")", "\n", "\n", "if", "x_forwarded_for", ":", "\n", "        ", "ip", "=", "x_forwarded_for", ".", "split", "(", "','", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "ip", "=", "request", ".", "META", ".", "get", "(", "'REMOTE_ADDR'", ")", "\n", "", "return", "ip", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.views.get_image_urls": [[26, 45], ["json.loads", "query[].strip", "logger.info", "django.http.JsonResponse", "django.http.JsonResponse", "django.http.JsonResponse", "extractor.get_urls", "django.http.JsonResponse", "django.http.JsonResponse", "views.visitor_ip_address", "str"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.get_urls", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.views.visitor_ip_address"], ["", "@", "csrf_exempt", "\n", "def", "get_image_urls", "(", "request", ")", ":", "\n", "    ", "query", "=", "json", ".", "loads", "(", "request", ".", "body", ")", "\n", "url", "=", "query", "[", "'url'", "]", ".", "strip", "(", ")", "\n", "logger", ".", "info", "(", "f\"{visitor_ip_address(request)} requests {url}\"", ")", "\n", "\n", "if", "not", "url", ":", "\n", "        ", "return", "JsonResponse", "(", "{", "'error'", ":", "'The URL cannot be empty.'", "}", ")", "\n", "", "if", "'nytimes.com'", "not", "in", "url", ":", "\n", "        ", "return", "JsonResponse", "(", "{", "'error'", ":", "'The URL must come from nytimes.com'", "}", ")", "\n", "\n", "", "try", ":", "\n", "        ", "output", "=", "get_urls", "(", "url", ")", "\n", "", "except", "ExtractError", "as", "e", ":", "\n", "        ", "return", "JsonResponse", "(", "{", "'error'", ":", "str", "(", "e", ")", "}", ")", "\n", "", "except", "Exception", ":", "\n", "        ", "return", "JsonResponse", "(", "{", "'error'", ":", "'Cannot parse the article. Pick another URL.'", "}", ")", "\n", "\n", "", "return", "JsonResponse", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.views.post_caption": [[47, 69], ["json.loads", "extractor.extract_article", "logger.info", "django.http.JsonResponse", "client.parse"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.extract_article", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.caption.CaptioningClient.parse"], ["", "@", "csrf_exempt", "\n", "def", "post_caption", "(", "request", ")", ":", "\n", "    ", "query", "=", "json", ".", "loads", "(", "request", ".", "body", ")", "\n", "\n", "article", "=", "extract_article", "(", "query", "[", "'sections'", "]", ",", "query", "[", "'title'", "]", ",", "query", "[", "'pos'", "]", ")", "\n", "output", "=", "client", ".", "parse", "(", "[", "article", "]", ")", "[", "0", "]", "\n", "output", "[", "'caption'", "]", "=", "''", ".", "join", "(", "[", "a", "[", "'tokens'", "]", "for", "a", "in", "output", "[", "'attns'", "]", "]", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Caption for {query['pos']}: {output['caption']}\"", ")", "\n", "\n", "data", "=", "{", "\n", "'title'", ":", "article", "[", "'title'", "]", ",", "\n", "'image_url'", ":", "article", "[", "'image_url'", "]", ",", "\n", "'generated_caption'", ":", "output", "[", "'caption'", "]", ",", "\n", "'true_caption'", ":", "article", "[", "'true_caption'", "]", ",", "\n", "'start'", ":", "output", "[", "'start'", "]", ",", "\n", "'before'", ":", "output", "[", "'before'", "]", ",", "\n", "'after'", ":", "output", "[", "'after'", "]", ",", "\n", "'attns'", ":", "output", "[", "'attns'", "]", ",", "\n", "'image'", ":", "output", "[", "'image'", "]", ",", "\n", "}", "\n", "return", "JsonResponse", "(", "data", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.get_urls": [[15, 45], ["urllib.request.Request", "urllib.request.urlopen", "urllib.request.urlopen.read().decode", "extractor.extract_text", "extractor.ExtractError", "extractor.ExtractError", "urllib.request.urlopen.read", "extractor.ExtractError", "requests.get", "str", "image_urls.append", "base64.b64encode"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text"], ["", "def", "get_urls", "(", "url", ")", ":", "\n", "    ", "req", "=", "Request", "(", "url", ",", "headers", "=", "{", "'User-Agent'", ":", "'Mozilla/5.0'", "}", ")", "\n", "response", "=", "urlopen", "(", "req", ",", "timeout", "=", "5", ")", "\n", "raw_html", "=", "response", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "try", ":", "\n", "        ", "parsed_sections", ",", "title", "=", "extract_text", "(", "raw_html", ")", "\n", "", "except", ":", "\n", "        ", "raise", "ExtractError", "(", "f'Error parsing the article. Pick another URL.'", ")", "\n", "\n", "", "if", "not", "parsed_sections", ":", "\n", "        ", "raise", "ExtractError", "(", "f'No article text is found. Pick another URL.'", ")", "\n", "\n", "", "image_urls", "=", "[", "]", "\n", "for", "section", "in", "parsed_sections", ":", "\n", "        ", "if", "section", "[", "'type'", "]", "==", "'caption'", ":", "\n", "            ", "img_response", "=", "requests", ".", "get", "(", "section", "[", "'url'", "]", ",", "stream", "=", "True", ")", "\n", "section", "[", "'image_data'", "]", "=", "str", "(", "base64", ".", "b64encode", "(", "img_response", ".", "content", ")", ",", "\n", "'utf-8'", ")", "\n", "image_urls", ".", "append", "(", "section", "[", "'url'", "]", ")", "\n", "\n", "", "", "if", "not", "image_urls", ":", "\n", "        ", "raise", "ExtractError", "(", "f'No image is found in the article. '", "\n", "f'Pick another URL.'", ")", "\n", "\n", "", "output", "=", "{", "\n", "'sections'", ":", "parsed_sections", ",", "\n", "'title'", ":", "title", ",", "\n", "'image_urls'", ":", "image_urls", ",", "\n", "}", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.extract_article": [[47, 62], ["enumerate"], "function", ["None"], ["", "def", "extract_article", "(", "sections", ",", "title", ",", "selected_pos", ")", ":", "\n", "    ", "positions", "=", "[", "i", "for", "i", ",", "s", "in", "enumerate", "(", "sections", ")", "if", "s", "[", "'type'", "]", "==", "'caption'", "]", "\n", "pos", "=", "positions", "[", "selected_pos", "]", "\n", "\n", "true_caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", "\n", "image_url", "=", "sections", "[", "pos", "]", "[", "'url'", "]", "\n", "\n", "article", "=", "{", "\n", "'sections'", ":", "sections", ",", "\n", "'image_position'", ":", "pos", ",", "\n", "'title'", ":", "title", ",", "\n", "'true_caption'", ":", "true_caption", ",", "\n", "'image_url'", ":", "image_url", ",", "\n", "}", "\n", "return", "article", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.extract_text": [[64, 82], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find().text.strip", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find().find_all", "bs4.BeautifulSoup.find_all", "extractor.extract_text_new", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find", "extractor.extract_text_old"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_new", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_old"], ["", "def", "extract_text", "(", "html", ")", ":", "\n", "# Before November 2019, we could just use BeautifulSoup to extract all", "\n", "# the image captions in the article. But since November 2019, it seems", "\n", "# that The New York Times starts to use more Javascript to insert images", "\n", "# into the page, so we can only extract the top image from now on.", "\n", "    ", "soup", "=", "bs4", ".", "BeautifulSoup", "(", "html", ",", "'html.parser'", ")", "\n", "\n", "title", "=", "soup", ".", "find", "(", "'h1'", ")", ".", "text", ".", "strip", "(", ")", "\n", "\n", "# Newer articles use StoryBodyCompanionColumn", "\n", "if", "soup", ".", "find", "(", "'article'", ")", "and", "soup", ".", "find", "(", "'article'", ")", ".", "find_all", "(", "'div'", ",", "{", "'class'", ":", "'StoryBodyCompanionColumn'", "}", ")", ":", "\n", "        ", "return", "extract_text_new", "(", "soup", ")", ",", "title", "\n", "\n", "# Older articles use story-body", "\n", "", "elif", "soup", ".", "find_all", "(", "'p'", ",", "{", "'class'", ":", "'story-body-text'", "}", ")", ":", "\n", "        ", "return", "extract_text_old", "(", "soup", ")", ",", "title", "\n", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.get_tags": [[84, 101], ["params.get().items", "any", "filter", "extractor.get_tags.find_match"], "function", ["None"], ["", "def", "get_tags", "(", "d", ",", "params", ")", ":", "\n", "# See https://stackoverflow.com/a/57683816/379011", "\n", "    ", "def", "find_match", "(", "attrs", ",", "tag", ",", "tag_names", ")", ":", "\n", "        ", "for", "tag_name", "in", "tag_names", ":", "\n", "            ", "if", "(", "tag", "==", "'class'", "and", "tag_name", "in", "attrs", ")", "or", "tag_name", "==", "attrs", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "matches", "=", "[", "]", "\n", "for", "tag", ",", "tag_names", "in", "params", ".", "get", "(", "d", ".", "name", ",", "{", "}", ")", ".", "items", "(", ")", ":", "\n", "        ", "match", "=", "find_match", "(", "d", ".", "attrs", ".", "get", "(", "tag", ",", "[", "]", ")", ",", "tag", ",", "tag_names", ")", "\n", "matches", ".", "append", "(", "match", ")", "\n", "\n", "", "if", "any", "(", "matches", ")", ":", "\n", "        ", "yield", "d", "\n", "", "for", "i", "in", "filter", "(", "lambda", "x", ":", "x", "!=", "'\\n'", "and", "not", "isinstance", "(", "x", ",", "bs4", ".", "element", ".", "NavigableString", ")", ",", "d", ".", "contents", ")", ":", "\n", "        ", "yield", "from", "get_tags", "(", "i", ",", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.extract_text_new": [[103, 164], ["soup.find", "extractor.get_tags", "part.find_all", "sections.append", "part.parent.find", "part.parent.find.find().attrs.get", "part.find", "extractor.resolve_url", "sections.append", "part.find.text.strip", "part.attrs.get", "p.text.strip", "hashlib.sha256().hexdigest", "part.find", "extractor.resolve_url", "sections.append", "part.parent.find.find", "part.find.text.strip", "hashlib.sha256", "hashlib.sha256().hexdigest", "resolve_url.encode", "hashlib.sha256", "resolve_url.encode"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "", "def", "extract_text_new", "(", "soup", ")", ":", "\n", "# For articles between 2013 and 2019", "\n", "    ", "sections", "=", "[", "]", "\n", "article_node", "=", "soup", ".", "find", "(", "'article'", ")", "\n", "\n", "params", "=", "{", "\n", "'div'", ":", "{", "'class'", ":", "[", "'StoryBodyCompanionColumn'", "]", "}", ",", "\n", "# 'figcaption': {'itemprop': 'caption description'},", "\n", "'figcaption'", ":", "{", "'class'", ":", "[", "'ewdxa0s0'", ",", "'e18f7pbr0'", "]", "}", ",", "\n", "'figure'", ":", "{", "'class'", ":", "[", "'e1g7ppur0'", "]", "}", ",", "\n", "}", "\n", "\n", "article_parts", "=", "get_tags", "(", "article_node", ",", "params", ")", "\n", "i", "=", "0", "\n", "\n", "for", "part", "in", "article_parts", ":", "\n", "        ", "if", "part", ".", "name", "==", "'div'", ":", "\n", "            ", "paragraphs", "=", "part", ".", "find_all", "(", "[", "'p'", ",", "'h2'", "]", ")", "\n", "for", "p", "in", "paragraphs", ":", "\n", "                ", "sections", ".", "append", "(", "{", "'type'", ":", "'paragraph'", ",", "'text'", ":", "p", ".", "text", ".", "strip", "(", ")", "}", ")", "\n", "\n", "", "", "elif", "part", ".", "name", "==", "'figcaption'", ":", "\n", "            ", "picture", "=", "part", ".", "parent", ".", "find", "(", "'picture'", ")", "\n", "if", "not", "picture", ":", "\n", "                ", "continue", "\n", "", "url", "=", "picture", ".", "find", "(", "'source'", ")", ".", "attrs", ".", "get", "(", "'srcset'", ",", "None", ")", "\n", "if", "not", "url", ":", "\n", "                ", "continue", "\n", "", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'e13ogyst0'", "}", ")", "\n", "if", "caption", ":", "\n", "                ", "caption_text", "=", "caption", ".", "text", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                ", "caption_text", "=", "''", "\n", "", "url", "=", "resolve_url", "(", "url", ")", "\n", "sections", ".", "append", "(", "{", "\n", "'type'", ":", "'caption'", ",", "\n", "'order'", ":", "i", ",", "\n", "'text'", ":", "caption_text", ",", "\n", "'url'", ":", "url", ",", "\n", "'hash'", ":", "hashlib", ".", "sha256", "(", "url", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", ",", "\n", "}", ")", "\n", "i", "+=", "1", "\n", "\n", "", "elif", "part", ".", "name", "==", "'figure'", ":", "\n", "            ", "if", "part", ".", "attrs", ".", "get", "(", "'itemid'", ",", "0", ")", ":", "\n", "                ", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'e13ogyst0'", "}", ")", "\n", "if", "caption", ":", "\n", "                    ", "caption_text", "=", "caption", ".", "text", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                    ", "caption_text", "=", "''", "\n", "", "url", "=", "resolve_url", "(", "part", ".", "attrs", "[", "'itemid'", "]", ")", "\n", "sections", ".", "append", "(", "{", "\n", "'type'", ":", "'caption'", ",", "\n", "'order'", ":", "i", ",", "\n", "'text'", ":", "caption_text", ",", "\n", "'url'", ":", "url", ",", "\n", "'hash'", ":", "hashlib", ".", "sha256", "(", "url", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", ",", "\n", "}", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "", "return", "sections", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.extract_text_old": [[166, 199], ["extractor.get_tags", "sections.append", "part.parent.attrs.get", "part.text.strip", "part.find", "extractor.resolve_url", "sections.append", "part.find.text.strip", "hashlib.sha256().hexdigest", "hashlib.sha256", "resolve_url.encode"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "def", "extract_text_old", "(", "soup", ")", ":", "\n", "# For articles in 2012 and earlier", "\n", "    ", "sections", "=", "[", "]", "\n", "\n", "params", "=", "{", "\n", "'p'", ":", "{", "'class'", ":", "'story-body-text'", "}", ",", "\n", "'figcaption'", ":", "{", "'itemprop'", ":", "'caption description'", "}", ",", "\n", "'span'", ":", "{", "'class'", ":", "'caption-text'", "}", ",", "\n", "}", "\n", "\n", "article_parts", "=", "get_tags", "(", "soup", ",", "params", ")", "\n", "i", "=", "0", "\n", "for", "part", "in", "article_parts", ":", "\n", "        ", "if", "part", ".", "name", "==", "'p'", ":", "\n", "            ", "sections", ".", "append", "(", "{", "'type'", ":", "'paragraph'", ",", "'text'", ":", "part", ".", "text", ".", "strip", "(", ")", "}", ")", "\n", "", "elif", "part", ".", "name", "==", "'figcaption'", ":", "\n", "            ", "if", "part", ".", "parent", ".", "attrs", ".", "get", "(", "'itemid'", ",", "0", ")", ":", "\n", "                ", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'caption-text'", "}", ")", "\n", "if", "caption", ":", "\n", "                    ", "caption_text", "=", "caption", ".", "text", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                    ", "caption_text", "=", "''", "\n", "", "url", "=", "resolve_url", "(", "part", ".", "parent", ".", "attrs", "[", "'itemid'", "]", ")", "\n", "sections", ".", "append", "(", "{", "\n", "'type'", ":", "'caption'", ",", "\n", "'order'", ":", "i", ",", "\n", "'text'", ":", "caption_text", ",", "\n", "'url'", ":", "url", ",", "\n", "'hash'", ":", "hashlib", ".", "sha256", "(", "url", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", ",", "\n", "}", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "", "return", "sections", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tat.extractor.resolve_url": [[201, 217], ["urllib.parse.urlparse", "posixpath.normpath", "urllib.parse.urlparse.path.endswith", "urllib.parse.urlparse._replace", "parsed._replace.geturl"], "function", ["None"], ["", "def", "resolve_url", "(", "url", ")", ":", "\n", "    ", "\"\"\"\n    resolve_url('http://www.example.com/foo/bar/../../baz/bux/')\n    'http://www.example.com/baz/bux/'\n    resolve_url('http://www.example.com/some/path/../file.ext')\n    'http://www.example.com/some/file.ext'\n    \"\"\"", "\n", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "new_path", "=", "normpath", "(", "parsed", ".", "path", ")", "\n", "if", "parsed", ".", "path", ".", "endswith", "(", "'/'", ")", ":", "\n", "# Compensate for issue1707768", "\n", "        ", "new_path", "+=", "'/'", "\n", "", "cleaned", "=", "parsed", ".", "_replace", "(", "path", "=", "new_path", ")", "\n", "\n", "return", "cleaned", ".", "geturl", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list": [[1, 10], ["isinstance", "eval", "list", "map", "type"], "function", ["None"], ["def", "eval_str_list", "(", "x", ",", "type", "=", "float", ")", ":", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "        ", "x", "=", "eval", "(", "x", ")", "\n", "", "try", ":", "\n", "        ", "return", "list", "(", "map", "(", "type", ",", "x", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "[", "type", "(", "x", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state": [[10, 15], ["state._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state._get_full_incremental_state_key"], ["def", "set_incremental_state", "(", "module", ",", "incremental_state", ",", "key", ",", "value", ")", ":", "\n", "    ", "\"\"\"Helper for setting incremental state for an nn.Module.\"\"\"", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "        ", "full_key", "=", "_get_full_incremental_state_key", "(", "module", ",", "key", ")", "\n", "incremental_state", "[", "full_key", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state._get_full_incremental_state_key": [[17, 27], ["hasattr"], "function", ["None"], ["", "", "def", "_get_full_incremental_state_key", "(", "module_instance", ",", "key", ")", ":", "\n", "    ", "module_name", "=", "module_instance", ".", "__class__", ".", "__name__", "\n", "\n", "# assign a unique ID to each module instance, so that incremental state is", "\n", "# not shared across module instances", "\n", "if", "not", "hasattr", "(", "module_instance", ",", "'_fairseq_instance_id'", ")", ":", "\n", "        ", "INCREMENTAL_STATE_INSTANCE_ID", "[", "module_name", "]", "+=", "1", "\n", "module_instance", ".", "_fairseq_instance_id", "=", "INCREMENTAL_STATE_INSTANCE_ID", "[", "module_name", "]", "\n", "\n", "", "return", "'{}.{}.{}'", ".", "format", "(", "module_name", ",", "module_instance", ".", "_fairseq_instance_id", ",", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state": [[29, 35], ["state._get_full_incremental_state_key"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state._get_full_incremental_state_key"], ["", "def", "get_incremental_state", "(", "module", ",", "incremental_state", ",", "key", ")", ":", "\n", "    ", "\"\"\"Helper for getting incremental state for an nn.Module.\"\"\"", "\n", "full_key", "=", "_get_full_incremental_state_key", "(", "module", ",", "key", ")", "\n", "if", "incremental_state", "is", "None", "or", "full_key", "not", "in", "incremental_state", ":", "\n", "        ", "return", "None", "\n", "", "return", "incremental_state", "[", "full_key", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.logger.setup_logger": [[12, 28], ["logging.getLogger", "logging.getLogger.hasHandlers", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.handlers.clear"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear"], ["def", "setup_logger", "(", "mode", "=", "'info'", ")", ":", "\n", "    ", "\"\"\"Initialize logger. Mode can be: info, debug, warning, stackdriver.\"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "\n", "if", "(", "logger", ".", "hasHandlers", "(", ")", ")", ":", "\n", "        ", "logger", ".", "handlers", ".", "clear", "(", ")", "\n", "\n", "", "logger", ".", "setLevel", "(", "LEVEL_DICT", "[", "mode", "]", ")", "\n", "handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "\n", "# Format log messages", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(levelname)-8s %(message)s'", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "handler", ")", "\n", "\n", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax": [[5, 10], ["torch.softmax", "torch.softmax", "x.float"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["def", "softmax", "(", "x", ",", "dim", ",", "onnx_trace", "=", "False", ")", ":", "\n", "    ", "if", "onnx_trace", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ".", "float", "(", ")", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "softmax", "(", "x", ",", "dim", "=", "dim", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.strip_pad": [[1, 3], ["tensor.ne"], "function", ["None"], ["def", "strip_pad", "(", "tensor", ",", "pad", ")", ":", "\n", "    ", "return", "tensor", "[", "tensor", ".", "ne", "(", "pad", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf": [[5, 8], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "\"\"\"FP16-compatible function that fills a tensor with -inf.\"\"\"", "\n", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "'-inf'", ")", ")", ".", "type_as", "(", "t", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.google_utils.gdrive_download": [[10, 47], ["time.time", "print", "os.system", "os.path.exists", "os.system", "name.endswith", "print", "os.path.exists", "os.remove", "os.path.exists", "os.remove", "os.path.exists", "os.remove", "print", "print", "os.system", "os.remove", "os.path.exists", "os.remove", "time.time"], "function", ["None"], ["def", "gdrive_download", "(", "id", "=", "'1HaXkef9z6y5l4vUnCYgdmEAj61c6bfWO'", ",", "name", "=", "'coco.zip'", ")", ":", "\n", "# https://gist.github.com/tanaikech/f0f2d122e05bf5f971611258c22c110f", "\n", "# Downloads a file from Google Drive, accepting presented query", "\n", "# from utils.google_utils import *; gdrive_download()", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'Downloading https://drive.google.com/uc?export=download&id=%s as %s... '", "%", "\n", "(", "id", ",", "name", ")", ",", "end", "=", "''", ")", "\n", "os", ".", "remove", "(", "name", ")", "if", "os", ".", "path", ".", "exists", "(", "name", ")", "else", "None", "# remove existing", "\n", "os", ".", "remove", "(", "'cookie'", ")", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", "else", "None", "\n", "\n", "# Attempt file download", "\n", "os", ".", "system", "(", "\n", "\"curl -c ./cookie -s -L \\\"https://drive.google.com/uc?export=download&id=%s\\\" > /dev/null\"", "%", "id", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", ":", "# large file", "\n", "        ", "s", "=", "\"curl -Lb ./cookie \\\"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=%s\\\" -o %s\"", "%", "(", "\n", "id", ",", "name", ")", "\n", "", "else", ":", "# small file", "\n", "        ", "s", "=", "\"curl -s -L -o %s 'https://drive.google.com/uc?export=download&id=%s'\"", "%", "(", "\n", "name", ",", "id", ")", "\n", "", "r", "=", "os", ".", "system", "(", "s", ")", "# execute, capture return values", "\n", "os", ".", "remove", "(", "'cookie'", ")", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", "else", "None", "\n", "\n", "# Error check", "\n", "if", "r", "!=", "0", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "if", "os", ".", "path", ".", "exists", "(", "name", ")", "else", "None", "# remove partial", "\n", "print", "(", "'Download error '", ")", "# raise Exception('Download error')", "\n", "return", "r", "\n", "\n", "# Unzip if archive", "\n", "", "if", "name", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "        ", "print", "(", "'unzipping... '", ",", "end", "=", "''", ")", "\n", "os", ".", "system", "(", "'unzip -q %s'", "%", "name", ")", "# unzip", "\n", "os", ".", "remove", "(", "name", ")", "# remove zip to free space", "\n", "\n", "", "print", "(", "'Done (%.1fs)'", "%", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.google_utils.upload_blob": [[49, 62], ["storage.Client", "storage.Client.get_bucket", "storage_client.get_bucket.blob", "bucket.blob.upload_from_filename", "print"], "function", ["None"], ["", "def", "upload_blob", "(", "bucket_name", ",", "source_file_name", ",", "destination_blob_name", ")", ":", "\n", "# Uploads a file to a bucket", "\n", "# https://cloud.google.com/storage/docs/uploading-objects#storage-upload-object-python", "\n", "\n", "    ", "storage_client", "=", "storage", ".", "Client", "(", ")", "\n", "bucket", "=", "storage_client", ".", "get_bucket", "(", "bucket_name", ")", "\n", "blob", "=", "bucket", ".", "blob", "(", "destination_blob_name", ")", "\n", "\n", "blob", ".", "upload_from_filename", "(", "source_file_name", ")", "\n", "\n", "print", "(", "'File {} uploaded to {}.'", ".", "format", "(", "\n", "source_file_name", ",", "\n", "destination_blob_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.google_utils.download_blob": [[64, 75], ["storage.Client", "storage.Client.get_bucket", "storage_client.get_bucket.blob", "bucket.blob.download_to_filename", "print"], "function", ["None"], ["", "def", "download_blob", "(", "bucket_name", ",", "source_blob_name", ",", "destination_file_name", ")", ":", "\n", "# Uploads a blob from a bucket", "\n", "    ", "storage_client", "=", "storage", ".", "Client", "(", ")", "\n", "bucket", "=", "storage_client", ".", "get_bucket", "(", "bucket_name", ")", "\n", "blob", "=", "bucket", ".", "blob", "(", "source_blob_name", ")", "\n", "\n", "blob", ".", "download_to_filename", "(", "destination_file_name", ")", "\n", "\n", "print", "(", "'Blob {} downloaded to {}.'", ".", "format", "(", "\n", "source_blob_name", ",", "\n", "destination_file_name", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.parse_config.parse_model_cfg": [[6, 59], ["path.endswith", "os.path.exists", "open", "f.read().split", "x.rstrip().lstrip", "line.startswith", "any", "os.path.exists", "mdefs.append", "line[].rstrip", "line.split", "key.rstrip.rstrip", "f.append", "f.read", "x.rstrip", "numpy.array().reshape", "x.startswith", "val.strip.strip", "val.strip.isnumeric", "numpy.array", "int", "val.strip.split", "int", "float", "float", "val.strip.split", "int", "float"], "function", ["None"], ["def", "parse_model_cfg", "(", "path", ")", ":", "\n", "# Parse the yolo *.cfg file and return module definitions path may be 'cfg/yolov3.cfg', 'yolov3.cfg', or 'yolov3'", "\n", "    ", "if", "not", "path", ".", "endswith", "(", "'.cfg'", ")", ":", "# add .cfg suffix if omitted", "\n", "        ", "path", "+=", "'.cfg'", "\n", "# add cfg/ prefix if omitted", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "os", ".", "path", ".", "exists", "(", "'cfg'", "+", "os", ".", "sep", "+", "path", ")", ":", "\n", "        ", "path", "=", "'cfg'", "+", "os", ".", "sep", "+", "path", "\n", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "lines", "=", "[", "x", "for", "x", "in", "lines", "if", "x", "and", "not", "x", ".", "startswith", "(", "'#'", ")", "]", "\n", "lines", "=", "[", "x", ".", "rstrip", "(", ")", ".", "lstrip", "(", ")", "\n", "for", "x", "in", "lines", "]", "# get rid of fringe whitespaces", "\n", "mdefs", "=", "[", "]", "# module definitions", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'['", ")", ":", "# This marks the start of a new block", "\n", "            ", "mdefs", ".", "append", "(", "{", "}", ")", "\n", "mdefs", "[", "-", "1", "]", "[", "'type'", "]", "=", "line", "[", "1", ":", "-", "1", "]", ".", "rstrip", "(", ")", "\n", "if", "mdefs", "[", "-", "1", "]", "[", "'type'", "]", "==", "'convolutional'", ":", "\n", "# pre-populate with zeros (may be overwritten later)", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "'batch_normalize'", "]", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "key", ",", "val", "=", "line", ".", "split", "(", "\"=\"", ")", "\n", "key", "=", "key", ".", "rstrip", "(", ")", "\n", "\n", "if", "key", "==", "'anchors'", ":", "# return nparray", "\n", "# np anchors", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "\n", "for", "x", "in", "val", ".", "split", "(", "','", ")", "]", ")", ".", "reshape", "(", "(", "-", "1", ",", "2", ")", ")", "\n", "", "elif", "key", "in", "[", "'from'", ",", "'layers'", ",", "'mask'", "]", ":", "# return array", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "[", "int", "(", "x", ")", "for", "x", "in", "val", ".", "split", "(", "','", ")", "]", "\n", "", "else", ":", "\n", "                ", "val", "=", "val", ".", "strip", "(", ")", "\n", "if", "val", ".", "isnumeric", "(", ")", ":", "# return int or float", "\n", "                    ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "int", "(", "val", ")", "if", "(", "int", "(", "val", ")", "-", "\n", "float", "(", "val", ")", ")", "==", "0", "else", "float", "(", "val", ")", "\n", "", "else", ":", "\n", "                    ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "val", "# return string", "\n", "\n", "# Check all fields are supported", "\n", "", "", "", "", "supported", "=", "[", "'type'", ",", "'batch_normalize'", ",", "'filters'", ",", "'size'", ",", "'stride'", ",", "'pad'", ",", "'activation'", ",", "'layers'", ",", "'groups'", ",", "\n", "'from'", ",", "'mask'", ",", "'anchors'", ",", "'classes'", ",", "'num'", ",", "'jitter'", ",", "'ignore_thresh'", ",", "'truth_thresh'", ",", "'random'", ",", "\n", "'stride_x'", ",", "'stride_y'", ",", "'weights_type'", ",", "'weights_normalization'", ",", "'scale_x_y'", ",", "'beta_nms'", ",", "'nms_kind'", ",", "\n", "'iou_loss'", ",", "'iou_normalizer'", ",", "'cls_normalizer'", ",", "'iou_thresh'", "]", "\n", "\n", "f", "=", "[", "]", "# fields", "\n", "for", "x", "in", "mdefs", "[", "1", ":", "]", ":", "\n", "        ", "[", "f", ".", "append", "(", "k", ")", "for", "k", "in", "x", "if", "k", "not", "in", "f", "]", "\n", "", "u", "=", "[", "x", "for", "x", "in", "f", "if", "x", "not", "in", "supported", "]", "# unsupported fields", "\n", "assert", "not", "any", "(", "\n", "u", ")", ",", "\"Unsupported fields %s in %s. See https://github.com/ultralytics/yolov3/issues/631\"", "%", "(", "u", ",", "path", ")", "\n", "\n", "return", "mdefs", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.parse_config.parse_data_cfg": [[61, 79], ["dict", "os.path.exists", "open", "f.readlines", "line.strip.strip", "line.strip.split", "val.strip", "os.path.exists", "line.strip.startswith", "key.strip"], "function", ["None"], ["", "def", "parse_data_cfg", "(", "path", ")", ":", "\n", "# Parses the data configuration file", "\n", "# add data/ prefix if omitted", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "os", ".", "path", ".", "exists", "(", "'data'", "+", "os", ".", "sep", "+", "path", ")", ":", "\n", "        ", "path", "=", "'data'", "+", "os", ".", "sep", "+", "path", "\n", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "options", "=", "dict", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", "or", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "continue", "\n", "", "key", ",", "val", "=", "line", ".", "split", "(", "'='", ")", "\n", "options", "[", "key", ".", "strip", "(", ")", "]", "=", "val", ".", "strip", "(", ")", "\n", "\n", "", "return", "options", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.init_seeds": [[8, 15], ["torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "init_seeds", "(", "seed", "=", "0", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "# Remove randomness (may be slower on Tesla GPUs) # https://pytorch.org/docs/stable/notes/randomness.html", "\n", "if", "seed", "==", "0", ":", "\n", "        ", "cudnn", ".", "deterministic", "=", "True", "\n", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.select_device": [[17, 45], ["print", "torch.device", "torch.device", "device.lower", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.device_count", "torch.cuda.device_count", "range", "print", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "print", "range", "len"], "function", ["None"], ["", "", "def", "select_device", "(", "device", "=", "''", ",", "apex", "=", "False", ",", "batch_size", "=", "None", ")", ":", "\n", "# device = 'cpu' or '0' or '0,1,2,3'", "\n", "    ", "cpu_request", "=", "device", ".", "lower", "(", ")", "==", "'cpu'", "\n", "if", "device", "and", "not", "cpu_request", ":", "# if device requested other than 'cpu'", "\n", "        ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "device", "# set environment variable", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", "\n", ")", ",", "'CUDA unavailable, invalid device %s requested'", "%", "device", "# check availablity", "\n", "\n", "", "cuda", "=", "False", "if", "cpu_request", "else", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "cuda", ":", "\n", "        ", "c", "=", "1024", "**", "2", "# bytes to MB", "\n", "ng", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "ng", ">", "1", "and", "batch_size", ":", "# check that batch_size is compatible with device_count", "\n", "            ", "assert", "batch_size", "%", "ng", "==", "0", ",", "'batch-size %g not multiple of GPU count %g'", "%", "(", "\n", "batch_size", ",", "ng", ")", "\n", "", "x", "=", "[", "torch", ".", "cuda", ".", "get_device_properties", "(", "i", ")", "for", "i", "in", "range", "(", "ng", ")", "]", "\n", "# apex for mixed precision https://github.com/NVIDIA/apex", "\n", "s", "=", "'Using CUDA '", "+", "(", "'Apex '", "if", "apex", "else", "''", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "ng", ")", ":", "\n", "            ", "if", "i", "==", "1", ":", "\n", "                ", "s", "=", "' '", "*", "len", "(", "s", ")", "\n", "", "print", "(", "\"%sdevice%g _CudaDeviceProperties(name='%s', total_memory=%dMB)\"", "%", "\n", "(", "s", ",", "i", ",", "x", "[", "i", "]", ".", "name", ",", "x", "[", "i", "]", ".", "total_memory", "/", "c", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Using CPU'", ")", "\n", "\n", "", "print", "(", "''", ")", "# skip a line", "\n", "return", "torch", ".", "device", "(", "'cuda:0'", "if", "cuda", "else", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.time_synchronized": [[47, 50], ["time.time", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.synchronize", "torch.cuda.synchronize"], "function", ["None"], ["", "def", "time_synchronized", "(", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", "\n", "return", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.fuse_conv_and_bn": [[52, 81], ["torch.no_grad", "torch.no_grad", "torch.nn.Conv2d", "torch.nn.Conv2d", "conv.weight.clone().view", "torch.diag", "torch.diag", "torch.nn.Conv2d.weight.copy_", "torch.nn.Conv2d.bias.copy_", "bn.weight.div", "torch.mm().view", "torch.mm().view", "torch.zeros", "torch.zeros", "bn.weight.mul().div", "conv.weight.clone", "torch.sqrt", "torch.sqrt", "torch.nn.Conv2d.weight.size", "conv.weight.size", "torch.sqrt", "torch.sqrt", "torch.mm().reshape", "torch.mm().reshape", "torch.mm", "torch.mm", "bn.weight.mul", "torch.mm", "torch.mm", "torch.zeros.reshape"], "function", ["None"], ["", "def", "fuse_conv_and_bn", "(", "conv", ",", "bn", ")", ":", "\n", "# https://tehnokv.com/posts/fusing-batchnorm-and-conv/", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# init", "\n", "        ", "fusedconv", "=", "torch", ".", "nn", ".", "Conv2d", "(", "conv", ".", "in_channels", ",", "\n", "conv", ".", "out_channels", ",", "\n", "kernel_size", "=", "conv", ".", "kernel_size", ",", "\n", "stride", "=", "conv", ".", "stride", ",", "\n", "padding", "=", "conv", ".", "padding", ",", "\n", "bias", "=", "True", ")", "\n", "\n", "# prepare filters", "\n", "w_conv", "=", "conv", ".", "weight", ".", "clone", "(", ")", ".", "view", "(", "conv", ".", "out_channels", ",", "-", "1", ")", "\n", "w_bn", "=", "torch", ".", "diag", "(", "bn", ".", "weight", ".", "div", "(", "torch", ".", "sqrt", "(", "bn", ".", "eps", "+", "bn", ".", "running_var", ")", ")", ")", "\n", "fusedconv", ".", "weight", ".", "copy_", "(", "\n", "torch", ".", "mm", "(", "w_bn", ",", "w_conv", ")", ".", "view", "(", "fusedconv", ".", "weight", ".", "size", "(", ")", ")", ")", "\n", "\n", "# prepare spatial bias", "\n", "if", "conv", ".", "bias", "is", "not", "None", ":", "\n", "            ", "b_conv", "=", "conv", ".", "bias", "\n", "", "else", ":", "\n", "            ", "b_conv", "=", "torch", ".", "zeros", "(", "conv", ".", "weight", ".", "size", "(", "0", ")", ")", "\n", "", "b_bn", "=", "bn", ".", "bias", "-", "bn", ".", "weight", ".", "mul", "(", "bn", ".", "running_mean", ")", ".", "div", "(", "\n", "torch", ".", "sqrt", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", ")", "\n", "fusedconv", ".", "bias", ".", "copy_", "(", "\n", "torch", ".", "mm", "(", "w_bn", ",", "b_conv", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "reshape", "(", "-", "1", ")", "+", "b_bn", ")", "\n", "\n", "return", "fusedconv", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.model_info": [[83, 97], ["sum", "sum", "print", "print", "enumerate", "x.numel", "x.numel", "model.named_parameters", "name.replace.replace", "print", "model.parameters", "model.parameters", "len", "list", "p.numel", "list", "p.mean", "p.std", "model.parameters"], "function", ["None"], ["", "", "def", "model_info", "(", "model", ",", "report", "=", "'summary'", ")", ":", "\n", "# Plots a line-by-line description of a PyTorch model", "\n", "    ", "n_p", "=", "sum", "(", "x", ".", "numel", "(", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", ")", "# number parameters", "\n", "n_g", "=", "sum", "(", "x", ".", "numel", "(", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", "\n", "if", "x", ".", "requires_grad", ")", "# number gradients", "\n", "if", "report", "is", "'full'", ":", "\n", "        ", "print", "(", "'%5s %40s %9s %12s %20s %10s %10s'", "%", "\n", "(", "'layer'", ",", "'name'", ",", "'gradient'", ",", "'parameters'", ",", "'shape'", ",", "'mu'", ",", "'sigma'", ")", ")", "\n", "for", "i", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "model", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "'module_list.'", ",", "''", ")", "\n", "print", "(", "'%5g %40s %9s %12g %20s %10.3g %10.3g'", "%", "\n", "(", "i", ",", "name", ",", "p", ".", "requires_grad", ",", "p", ".", "numel", "(", ")", ",", "list", "(", "p", ".", "shape", ")", ",", "p", ".", "mean", "(", ")", ",", "p", ".", "std", "(", ")", ")", ")", "\n", "", "", "print", "(", "'Model Summary: %g layers, %g parameters, %g gradients'", "%", "\n", "(", "len", "(", "list", "(", "model", ".", "parameters", "(", ")", ")", ")", ",", "n_p", ",", "n_g", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.load_classifier": [[99, 116], ["torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "eval"], "function", ["None"], ["", "def", "load_classifier", "(", "name", "=", "'resnet101'", ",", "n", "=", "2", ")", ":", "\n", "# Loads a pretrained model reshaped to n-class output", "\n", "# https://github.com/Cadene/pretrained-models.pytorch#torchvision", "\n", "    ", "import", "pretrainedmodels", "\n", "model", "=", "pretrainedmodels", ".", "__dict__", "[", "name", "]", "(", "\n", "num_classes", "=", "1000", ",", "pretrained", "=", "'imagenet'", ")", "\n", "\n", "# Display model properties", "\n", "for", "x", "in", "[", "'model.input_size'", ",", "'model.input_space'", ",", "'model.input_range'", ",", "'model.mean'", ",", "'model.std'", "]", ":", "\n", "        ", "print", "(", "x", "+", "' ='", ",", "eval", "(", "x", ")", ")", "\n", "\n", "# Reshape output to n classes", "\n", "", "filters", "=", "model", ".", "last_linear", ".", "weight", ".", "shape", "[", "1", "]", "\n", "model", ".", "last_linear", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n", ")", ")", "\n", "model", ".", "last_linear", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n", ",", "filters", ")", ")", "\n", "model", ".", "last_linear", ".", "out_features", "=", "n", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.FocalLoss.__init__": [[361, 368], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "loss_fcn", ",", "gamma", "=", "0.5", ",", "alpha", "=", "1", ")", ":", "\n", "        ", "super", "(", "FocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_fcn", "=", "loss_fcn", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "reduction", "=", "loss_fcn", ".", "reduction", "\n", "self", ".", "loss_fcn", ".", "reduction", "=", "'none'", "# required to apply FL to each element", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.FocalLoss.forward": [[369, 380], ["utils.FocalLoss.loss_fcn", "utils.FocalLoss.mean", "utils.FocalLoss.sum", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "loss", "=", "self", ".", "loss_fcn", "(", "input", ",", "target", ")", "\n", "# non-zero power for gradient stability", "\n", "loss", "*=", "self", ".", "alpha", "*", "(", "1.000001", "-", "torch", ".", "exp", "(", "-", "loss", ")", ")", "**", "self", ".", "gamma", "\n", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "            ", "return", "loss", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'sum'", ":", "\n", "            ", "return", "loss", ".", "sum", "(", ")", "\n", "", "else", ":", "# 'none'", "\n", "            ", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.floatn": [[30, 32], ["float", "format"], "function", ["None"], ["def", "floatn", "(", "x", ",", "n", "=", "3", ")", ":", "# format floats to n decimals", "\n", "    ", "return", "float", "(", "format", "(", "x", ",", "'.%gf'", "%", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.init_seeds": [[34, 38], ["random.seed", "numpy.random.seed", "torch_utils.init_seeds"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.init_seeds"], ["", "def", "init_seeds", "(", "seed", "=", "0", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch_utils", ".", "init_seeds", "(", "seed", "=", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.load_classes": [[40, 46], ["list", "open", "f.read().split", "filter", "f.read"], "function", ["None"], ["", "def", "load_classes", "(", "path", ")", ":", "\n", "# Loads *.names file at 'path'", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "names", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "# filter removes empty strings (such as last line)", "\n", "", "return", "list", "(", "filter", "(", "None", ",", "names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.labels_to_class_weights": [[48, 65], ["numpy.concatenate", "labels[].astype", "numpy.bincount", "np.bincount.sum", "torch.from_numpy", "torch.from_numpy", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "labels_to_class_weights", "(", "labels", ",", "nc", "=", "80", ")", ":", "\n", "# Get class weights (inverse frequency) from training labels", "\n", "    ", "if", "labels", "[", "0", "]", "is", "None", ":", "# no labels loaded", "\n", "        ", "return", "torch", ".", "Tensor", "(", ")", "\n", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "# labels.shape = (866643, 5) for COCO", "\n", "classes", "=", "labels", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", "# labels = [class xywh]", "\n", "weights", "=", "np", ".", "bincount", "(", "classes", ",", "minlength", "=", "nc", ")", "# occurences per class", "\n", "\n", "# Prepend gridpoint count (for uCE trianing)", "\n", "# gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image", "\n", "# weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start", "\n", "\n", "weights", "[", "weights", "==", "0", "]", "=", "1", "# replace empty bins with 1", "\n", "weights", "=", "1", "/", "weights", "# number of targets per class", "\n", "weights", "/=", "weights", ".", "sum", "(", ")", "# normalize", "\n", "return", "torch", ".", "from_numpy", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.labels_to_image_weights": [[67, 75], ["numpy.ones", "len", "numpy.array", "numpy.bincount", "[].astype", "range", "class_weights.reshape"], "function", ["None"], ["", "def", "labels_to_image_weights", "(", "labels", ",", "nc", "=", "80", ",", "class_weights", "=", "np", ".", "ones", "(", "80", ")", ")", ":", "\n", "# Produces image weights based on class mAPs", "\n", "    ", "n", "=", "len", "(", "labels", ")", "\n", "class_counts", "=", "np", ".", "array", "(", "\n", "[", "np", ".", "bincount", "(", "labels", "[", "i", "]", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", ",", "minlength", "=", "nc", ")", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "image_weights", "=", "(", "class_weights", ".", "reshape", "(", "1", ",", "nc", ")", "*", "class_counts", ")", ".", "sum", "(", "1", ")", "\n", "# index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample", "\n", "return", "image_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.coco_class_weights": [[77, 89], ["weights.sum", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "coco_class_weights", "(", ")", ":", "# frequency of each class in coco train2014", "\n", "    ", "n", "=", "[", "187437", ",", "4955", ",", "30920", ",", "6033", ",", "3838", ",", "4332", ",", "3160", ",", "7051", ",", "7677", ",", "9167", ",", "1316", ",", "1372", ",", "833", ",", "6757", ",", "7355", ",", "3302", ",", "3776", ",", "4671", ",", "\n", "6769", ",", "5706", ",", "3908", ",", "903", ",", "3686", ",", "3596", ",", "6200", ",", "7920", ",", "8779", ",", "4505", ",", "4272", ",", "1862", ",", "4698", ",", "1962", ",", "4403", ",", "6659", ",", "2402", ",", "2689", ",", "\n", "4012", ",", "4175", ",", "3411", ",", "17048", ",", "5637", ",", "14553", ",", "3923", ",", "5539", ",", "4289", ",", "10084", ",", "7018", ",", "4314", ",", "3099", ",", "4638", ",", "4939", ",", "5543", ",", "2038", ",", "4004", ",", "\n", "5053", ",", "4578", ",", "27292", ",", "4113", ",", "5931", ",", "2905", ",", "11174", ",", "2873", ",", "4036", ",", "3415", ",", "1517", ",", "4122", ",", "1980", ",", "4464", ",", "1190", ",", "2302", ",", "156", ",", "3933", ",", "\n", "1877", ",", "17630", ",", "4337", ",", "4624", ",", "1075", ",", "3468", ",", "135", ",", "1380", "]", "\n", "weights", "=", "1", "/", "torch", ".", "Tensor", "(", "n", ")", "\n", "weights", "/=", "weights", ".", "sum", "(", ")", "\n", "# with open('data/coco.names', 'r') as f:", "\n", "#     for k, v in zip(f.read().splitlines(), n):", "\n", "#         print('%20s: %g' % (k, v))", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.coco80_to_coco91_class": [[91, 101], ["None"], "function", ["None"], ["", "def", "coco80_to_coco91_class", "(", ")", ":", "# converts 80-index (val2014) to 91-index (paper)", "\n", "# https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/", "\n", "# a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')", "\n", "# b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')", "\n", "# x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco", "\n", "# x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet", "\n", "    ", "x", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", ",", "24", ",", "25", ",", "27", ",", "28", ",", "31", ",", "32", ",", "33", ",", "34", ",", "\n", "35", ",", "36", ",", "37", ",", "38", ",", "39", ",", "40", ",", "41", ",", "42", ",", "43", ",", "44", ",", "46", ",", "47", ",", "48", ",", "49", ",", "50", ",", "51", ",", "52", ",", "53", ",", "54", ",", "55", ",", "56", ",", "57", ",", "58", ",", "59", ",", "60", ",", "61", ",", "62", ",", "63", ",", "\n", "64", ",", "65", ",", "67", ",", "70", ",", "72", ",", "73", ",", "74", ",", "75", ",", "76", ",", "77", ",", "78", ",", "79", ",", "80", ",", "81", ",", "82", ",", "84", ",", "85", ",", "86", ",", "87", ",", "88", ",", "89", ",", "90", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.weights_init_normal": [[103, 110], ["classname.find", "torch.nn.init.normal_", "torch.nn.init.normal_", "classname.find", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "function", ["None"], ["", "def", "weights_init_normal", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "0.03", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "0.03", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xyxy2xywh": [[112, 121], ["isinstance", "torch.zeros_like", "torch.zeros_like", "numpy.zeros_like"], "function", ["None"], ["", "", "def", "xyxy2xywh", "(", "x", ")", ":", "\n", "# Convert bounding box format from [x1, y1, x2, y2] to [x, y, w, h]", "\n", "    ", "y", "=", "torch", ".", "zeros_like", "(", "x", ")", "if", "isinstance", "(", "\n", "x", ",", "torch", ".", "Tensor", ")", "else", "np", ".", "zeros_like", "(", "x", ")", "\n", "y", "[", ":", ",", "0", "]", "=", "(", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "2", "]", ")", "/", "2", "\n", "y", "[", ":", ",", "1", "]", "=", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", ")", "/", "2", "\n", "y", "[", ":", ",", "2", "]", "=", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "0", "]", "\n", "y", "[", ":", ",", "3", "]", "=", "x", "[", ":", ",", "3", "]", "-", "x", "[", ":", ",", "1", "]", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xywh2xyxy": [[123, 132], ["isinstance", "torch.zeros_like", "torch.zeros_like", "numpy.zeros_like"], "function", ["None"], ["", "def", "xywh2xyxy", "(", "x", ")", ":", "\n", "# Convert bounding box format from [x, y, w, h] to [x1, y1, x2, y2]", "\n", "    ", "y", "=", "torch", ".", "zeros_like", "(", "x", ")", "if", "isinstance", "(", "\n", "x", ",", "torch", ".", "Tensor", ")", "else", "np", ".", "zeros_like", "(", "x", ")", "\n", "y", "[", ":", ",", "0", "]", "=", "x", "[", ":", ",", "0", "]", "-", "x", "[", ":", ",", "2", "]", "/", "2", "\n", "y", "[", ":", ",", "1", "]", "=", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", "\n", "y", "[", ":", ",", "2", "]", "=", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "2", "]", "/", "2", "\n", "y", "[", ":", ",", "3", "]", "=", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.scale_coords": [[154, 169], ["utils.clip_coords", "max", "max"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.clip_coords"], ["", "def", "scale_coords", "(", "img1_shape", ",", "coords", ",", "img0_shape", ",", "ratio_pad", "=", "None", ")", ":", "\n", "# Rescale coords (xyxy) from img1_shape to img0_shape", "\n", "    ", "if", "ratio_pad", "is", "None", ":", "# calculate from img0_shape", "\n", "        ", "gain", "=", "max", "(", "img1_shape", ")", "/", "max", "(", "img0_shape", ")", "# gain  = old / new", "\n", "pad", "=", "(", "img1_shape", "[", "1", "]", "-", "img0_shape", "[", "1", "]", "*", "gain", ")", "/", "2", ",", "(", "img1_shape", "[", "0", "]", "-", "img0_shape", "[", "0", "]", "*", "gain", ")", "/", "2", "# wh padding", "\n", "", "else", ":", "\n", "        ", "gain", "=", "ratio_pad", "[", "0", "]", "[", "0", "]", "\n", "pad", "=", "ratio_pad", "[", "1", "]", "\n", "\n", "", "coords", "[", ":", ",", "[", "0", ",", "2", "]", "]", "-=", "pad", "[", "0", "]", "# x padding", "\n", "coords", "[", ":", ",", "[", "1", ",", "3", "]", "]", "-=", "pad", "[", "1", "]", "# y padding", "\n", "coords", "[", ":", ",", ":", "4", "]", "/=", "gain", "\n", "clip_coords", "(", "coords", ",", "img0_shape", ")", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.clip_coords": [[171, 177], ["boxes[].clamp", "boxes[].clamp"], "function", ["None"], ["", "def", "clip_coords", "(", "boxes", ",", "img_shape", ")", ":", "\n", "# Clip bounding xyxy bounding boxes to image shape (height, width)", "\n", "    ", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "boxes", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clamp", "(", "\n", "min", "=", "0", ",", "max", "=", "img_shape", "[", "1", "]", ")", "# clip x", "\n", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "boxes", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clamp", "(", "\n", "min", "=", "0", ",", "max", "=", "img_shape", "[", "0", "]", ")", "# clip y", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.ap_per_class": [[179, 240], ["numpy.argsort", "numpy.unique", "enumerate", "len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "np.argsort.sum", "np.unique.astype", "tp[].cumsum", "range", "utils.compute_ap"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.compute_ap"], ["", "def", "ap_per_class", "(", "tp", ",", "conf", ",", "pred_cls", ",", "target_cls", ")", ":", "\n", "    ", "\"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:    True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls: Predicted object classes (nparray).\n        target_cls: True object classes (nparray).\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"", "\n", "\n", "# Sort by objectness", "\n", "i", "=", "np", ".", "argsort", "(", "-", "conf", ")", "\n", "tp", ",", "conf", ",", "pred_cls", "=", "tp", "[", "i", "]", ",", "conf", "[", "i", "]", ",", "pred_cls", "[", "i", "]", "\n", "\n", "# Find unique classes", "\n", "unique_classes", "=", "np", ".", "unique", "(", "target_cls", ")", "\n", "\n", "# Create Precision-Recall curve and compute AP for each class", "\n", "# number class, number iou thresholds (i.e. 10 for mAP0.5...0.95)", "\n", "s", "=", "[", "len", "(", "unique_classes", ")", ",", "tp", ".", "shape", "[", "1", "]", "]", "\n", "ap", ",", "p", ",", "r", "=", "np", ".", "zeros", "(", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", "\n", "for", "ci", ",", "c", "in", "enumerate", "(", "unique_classes", ")", ":", "\n", "        ", "i", "=", "pred_cls", "==", "c", "\n", "n_gt", "=", "(", "target_cls", "==", "c", ")", ".", "sum", "(", ")", "# Number of ground truth objects", "\n", "n_p", "=", "i", ".", "sum", "(", ")", "# Number of predicted objects", "\n", "\n", "if", "n_p", "==", "0", "or", "n_gt", "==", "0", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "# Accumulate FPs and TPs", "\n", "            ", "fpc", "=", "(", "1", "-", "tp", "[", "i", "]", ")", ".", "cumsum", "(", "0", ")", "\n", "tpc", "=", "tp", "[", "i", "]", ".", "cumsum", "(", "0", ")", "\n", "\n", "# Recall", "\n", "recall", "=", "tpc", "/", "(", "n_gt", "+", "1e-16", ")", "# recall curve", "\n", "r", "[", "ci", "]", "=", "recall", "[", "-", "1", "]", "\n", "\n", "# Precision", "\n", "precision", "=", "tpc", "/", "(", "tpc", "+", "fpc", ")", "# precision curve", "\n", "p", "[", "ci", "]", "=", "precision", "[", "-", "1", "]", "\n", "\n", "# AP from recall-precision curve", "\n", "for", "j", "in", "range", "(", "tp", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "ap", "[", "ci", ",", "j", "]", "=", "compute_ap", "(", "recall", "[", ":", ",", "j", "]", ",", "precision", "[", ":", ",", "j", "]", ")", "\n", "\n", "# Plot", "\n", "# fig, ax = plt.subplots(1, 1, figsize=(4, 4))", "\n", "# ax.plot(recall, precision)", "\n", "# ax.set_xlabel('Recall')", "\n", "# ax.set_ylabel('Precision')", "\n", "# ax.set_xlim(0, 1.01)", "\n", "# ax.set_ylim(0, 1.01)", "\n", "# fig.tight_layout()", "\n", "# fig.savefig('PR_curve.png', dpi=300)", "\n", "\n", "# Compute F1 score (harmonic mean of precision and recall)", "\n", "", "", "", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", "+", "1e-16", ")", "\n", "\n", "return", "p", ",", "r", ",", "ap", ",", "f1", ",", "unique_classes", ".", "astype", "(", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.compute_ap": [[242, 270], ["numpy.concatenate", "numpy.concatenate", "numpy.flip", "numpy.maximum.accumulate", "numpy.linspace", "numpy.trapz", "numpy.sum", "numpy.flip", "numpy.interp", "numpy.where", "min"], "function", ["None"], ["", "def", "compute_ap", "(", "recall", ",", "precision", ")", ":", "\n", "    ", "\"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rbgirshick/py-faster-rcnn.\n    # Arguments\n        recall:    The recall curve (list).\n        precision: The precision curve (list).\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"", "\n", "\n", "# Append sentinel values to beginning and end", "\n", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "recall", ",", "[", "min", "(", "recall", "[", "-", "1", "]", "+", "1E-3", ",", "1.", ")", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "0.", "]", ",", "precision", ",", "[", "0.", "]", ")", ")", "\n", "\n", "# Compute the precision envelope", "\n", "mpre", "=", "np", ".", "flip", "(", "np", ".", "maximum", ".", "accumulate", "(", "np", ".", "flip", "(", "mpre", ")", ")", ")", "\n", "\n", "# Integrate area under curve", "\n", "method", "=", "'interp'", "# methods: 'continuous', 'interp'", "\n", "if", "method", "==", "'interp'", ":", "\n", "        ", "x", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "101", ")", "# 101-point interp (COCO)", "\n", "ap", "=", "np", ".", "trapz", "(", "np", ".", "interp", "(", "x", ",", "mrec", ",", "mpre", ")", ",", "x", ")", "# integrate", "\n", "", "else", ":", "# 'continuous'", "\n", "# points where x axis (recall) changes", "\n", "        ", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "# area under curve", "\n", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou": [[272, 319], ["box2.t.t", "torch.max", "torch.max", "torch.min", "torch.min", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.min", "torch.min", "torch.max", "torch.max", "torch.pow", "torch.pow", "torch.no_grad", "torch.no_grad", "torch.atan", "torch.atan", "torch.atan", "torch.atan"], "function", ["None"], ["", "def", "bbox_iou", "(", "box1", ",", "box2", ",", "x1y1x2y2", "=", "True", ",", "GIoU", "=", "False", ",", "DIoU", "=", "False", ",", "CIoU", "=", "False", ")", ":", "\n", "# Returns the IoU of box1 to box2. box1 is 4, box2 is nx4", "\n", "    ", "box2", "=", "box2", ".", "t", "(", ")", "\n", "\n", "# Get the coordinates of bounding boxes", "\n", "if", "x1y1x2y2", ":", "# x1, y1, x2, y2 = box1", "\n", "        ", "b1_x1", ",", "b1_y1", ",", "b1_x2", ",", "b1_y2", "=", "box1", "[", "0", "]", ",", "box1", "[", "1", "]", ",", "box1", "[", "2", "]", ",", "box1", "[", "3", "]", "\n", "b2_x1", ",", "b2_y1", ",", "b2_x2", ",", "b2_y2", "=", "box2", "[", "0", "]", ",", "box2", "[", "1", "]", ",", "box2", "[", "2", "]", ",", "box2", "[", "3", "]", "\n", "", "else", ":", "# x, y, w, h = box1", "\n", "        ", "b1_x1", ",", "b1_x2", "=", "box1", "[", "0", "]", "-", "box1", "[", "2", "]", "/", "2", ",", "box1", "[", "0", "]", "+", "box1", "[", "2", "]", "/", "2", "\n", "b1_y1", ",", "b1_y2", "=", "box1", "[", "1", "]", "-", "box1", "[", "3", "]", "/", "2", ",", "box1", "[", "1", "]", "+", "box1", "[", "3", "]", "/", "2", "\n", "b2_x1", ",", "b2_x2", "=", "box2", "[", "0", "]", "-", "box2", "[", "2", "]", "/", "2", ",", "box2", "[", "0", "]", "+", "box2", "[", "2", "]", "/", "2", "\n", "b2_y1", ",", "b2_y2", "=", "box2", "[", "1", "]", "-", "box2", "[", "3", "]", "/", "2", ",", "box2", "[", "1", "]", "+", "box2", "[", "3", "]", "/", "2", "\n", "\n", "# Intersection area", "\n", "", "inter", "=", "(", "torch", ".", "min", "(", "b1_x2", ",", "b2_x2", ")", "-", "torch", ".", "max", "(", "b1_x1", ",", "b2_x1", ")", ")", ".", "clamp", "(", "0", ")", "*", "(", "torch", ".", "min", "(", "b1_y2", ",", "b2_y2", ")", "-", "torch", ".", "max", "(", "b1_y1", ",", "b2_y1", ")", ")", ".", "clamp", "(", "0", ")", "\n", "\n", "# Union Area", "\n", "w1", ",", "h1", "=", "b1_x2", "-", "b1_x1", ",", "b1_y2", "-", "b1_y1", "\n", "w2", ",", "h2", "=", "b2_x2", "-", "b2_x1", ",", "b2_y2", "-", "b2_y1", "\n", "union", "=", "(", "w1", "*", "h1", "+", "1e-16", ")", "+", "w2", "*", "h2", "-", "inter", "\n", "\n", "iou", "=", "inter", "/", "union", "# iou", "\n", "if", "GIoU", "or", "DIoU", "or", "CIoU", ":", "\n", "# convex (smallest enclosing box) width", "\n", "        ", "cw", "=", "torch", ".", "max", "(", "b1_x2", ",", "b2_x2", ")", "-", "torch", ".", "min", "(", "b1_x1", ",", "b2_x1", ")", "\n", "ch", "=", "torch", ".", "max", "(", "b1_y2", ",", "b2_y2", ")", "-", "torch", ".", "min", "(", "b1_y1", ",", "b2_y1", ")", "# convex height", "\n", "if", "GIoU", ":", "# Generalized IoU https://arxiv.org/pdf/1902.09630.pdf", "\n", "            ", "c_area", "=", "cw", "*", "ch", "+", "1e-16", "# convex area", "\n", "return", "iou", "-", "(", "c_area", "-", "union", ")", "/", "c_area", "# GIoU", "\n", "", "if", "DIoU", "or", "CIoU", ":", "# Distance or Complete IoU https://arxiv.org/abs/1911.08287v1", "\n", "# convex diagonal squared", "\n", "            ", "c2", "=", "cw", "**", "2", "+", "ch", "**", "2", "+", "1e-16", "\n", "# centerpoint distance squared", "\n", "rho2", "=", "(", "(", "b2_x1", "+", "b2_x2", ")", "-", "(", "b1_x1", "+", "b1_x2", ")", ")", "**", "2", "/", "4", "+", "(", "(", "b2_y1", "+", "b2_y2", ")", "-", "(", "b1_y1", "+", "b1_y2", ")", ")", "**", "2", "/", "4", "\n", "if", "DIoU", ":", "\n", "                ", "return", "iou", "-", "rho2", "/", "c2", "# DIoU", "\n", "", "elif", "CIoU", ":", "# https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47", "\n", "                ", "v", "=", "(", "4", "/", "math", ".", "pi", "**", "2", ")", "*", "torch", ".", "pow", "(", "torch", ".", "atan", "(", "w2", "/", "h2", ")", "-", "torch", ".", "atan", "(", "w1", "/", "h1", ")", ",", "2", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "alpha", "=", "v", "/", "(", "1", "-", "iou", "+", "v", ")", "\n", "", "return", "iou", "-", "(", "rho2", "/", "c2", "+", "v", "*", "alpha", ")", "# CIoU", "\n", "\n", "", "", "", "return", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.box_iou": [[321, 347], ["utils.box_iou.box_area"], "function", ["None"], ["", "def", "box_iou", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "# https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py", "\n", "    ", "\"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        boxes1 (Tensor[N, 4])\n        boxes2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise\n            IoU values for every element in boxes1 and boxes2\n    \"\"\"", "\n", "\n", "def", "box_area", "(", "box", ")", ":", "\n", "# box = 4xn", "\n", "        ", "return", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "\n", "\n", "", "area1", "=", "box_area", "(", "boxes1", ".", "t", "(", ")", ")", "\n", "area2", "=", "box_area", "(", "boxes2", ".", "t", "(", ")", ")", "\n", "\n", "lt", "=", "torch", ".", "max", "(", "boxes1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "boxes2", "[", ":", ",", ":", "2", "]", ")", "# [N,M,2]", "\n", "rb", "=", "torch", ".", "min", "(", "boxes1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "boxes2", "[", ":", ",", "2", ":", "]", ")", "# [N,M,2]", "\n", "\n", "inter", "=", "(", "rb", "-", "lt", ")", ".", "clamp", "(", "min", "=", "0", ")", ".", "prod", "(", "2", ")", "# [N,M]", "\n", "# iou = inter / (area1 + area2 - inter)", "\n", "return", "inter", "/", "(", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.wh_iou": [[349, 356], ["torch.min().prod", "torch.min().prod", "torch.min", "torch.min", "wh1.prod", "wh2.prod"], "function", ["None"], ["", "def", "wh_iou", "(", "wh1", ",", "wh2", ")", ":", "\n", "# Returns the nxm IoU matrix. wh1 is nx2, wh2 is mx2", "\n", "    ", "wh1", "=", "wh1", "[", ":", ",", "None", "]", "# [N,1,2]", "\n", "wh2", "=", "wh2", "[", "None", "]", "# [1,M,2]", "\n", "inter", "=", "torch", ".", "min", "(", "wh1", ",", "wh2", ")", ".", "prod", "(", "2", ")", "# [N,M]", "\n", "# iou = inter / (area1 + area2 - inter)", "\n", "return", "inter", "/", "(", "wh1", ".", "prod", "(", "2", ")", "+", "wh2", ".", "prod", "(", "2", ")", "-", "inter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.compute_loss": [[382, 470], ["utils.build_targets", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.CrossEntropyLoss", "enumerate", "ft", "ft", "ft", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.numel", "len", "torch.cat().detach", "torch.cat().detach", "ft", "ft", "utils.FocalLoss", "utils.FocalLoss", "utils.FocalLoss", "utils.FocalLoss", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "utils.bbox_iou", "nn.BCEWithLogitsLoss.", "torch.exp().clamp", "torch.exp().clamp", "torch.cat.t", "torch.zeros_like", "torch.zeros_like", "nn.BCEWithLogitsLoss.", "torch.zeros_like", "torch.zeros_like", "nn.BCEWithLogitsLoss.", "torch.cat", "torch.cat", "bbox_iou.detach().clamp().type", "torch.zeros_like", "torch.zeros_like", "nn.CrossEntropyLoss.", "torch.exp", "torch.exp", "pi[].view", "torch.zeros_like.view", "bbox_iou.detach().clamp", "range", "bbox_iou.detach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.build_targets", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou"], ["", "", "", "def", "compute_loss", "(", "p", ",", "targets", ",", "model", ")", ":", "# predictions, targets, model", "\n", "    ", "ft", "=", "torch", ".", "cuda", ".", "FloatTensor", "if", "p", "[", "0", "]", ".", "is_cuda", "else", "torch", ".", "Tensor", "\n", "lcls", ",", "lbox", ",", "lobj", "=", "ft", "(", "[", "0", "]", ")", ",", "ft", "(", "[", "0", "]", ")", ",", "ft", "(", "[", "0", "]", ")", "\n", "tcls", ",", "tbox", ",", "indices", ",", "anchor_vec", "=", "build_targets", "(", "model", ",", "targets", ")", "\n", "h", "=", "model", ".", "hyp", "# hyperparameters", "\n", "arc", "=", "model", ".", "arc", "# # (default, uCE, uBCE) detection architectures", "\n", "red", "=", "'mean'", "# Loss reduction (sum or mean)", "\n", "\n", "# Define criteria", "\n", "BCEcls", "=", "nn", ".", "BCEWithLogitsLoss", "(", "pos_weight", "=", "ft", "(", "[", "h", "[", "'cls_pw'", "]", "]", ")", ",", "reduction", "=", "red", ")", "\n", "BCEobj", "=", "nn", ".", "BCEWithLogitsLoss", "(", "pos_weight", "=", "ft", "(", "[", "h", "[", "'obj_pw'", "]", "]", ")", ",", "reduction", "=", "red", ")", "\n", "BCE", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "red", ")", "\n", "CE", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "red", ")", "# weight=model.class_weights", "\n", "\n", "if", "'F'", "in", "arc", ":", "# add focal loss", "\n", "        ", "g", "=", "h", "[", "'fl_gamma'", "]", "\n", "BCEcls", ",", "BCEobj", ",", "BCE", ",", "CE", "=", "FocalLoss", "(", "BCEcls", ",", "g", ")", ",", "FocalLoss", "(", "\n", "BCEobj", ",", "g", ")", ",", "FocalLoss", "(", "BCE", ",", "g", ")", ",", "FocalLoss", "(", "CE", ",", "g", ")", "\n", "\n", "# Compute losses", "\n", "", "np", ",", "ng", "=", "0", ",", "0", "# number grid points, targets", "\n", "for", "i", ",", "pi", "in", "enumerate", "(", "p", ")", ":", "# layer index, layer predictions", "\n", "        ", "b", ",", "a", ",", "gj", ",", "gi", "=", "indices", "[", "i", "]", "# image, anchor, gridy, gridx", "\n", "tobj", "=", "torch", ".", "zeros_like", "(", "pi", "[", "...", ",", "0", "]", ")", "# target obj", "\n", "np", "+=", "tobj", ".", "numel", "(", ")", "\n", "\n", "# Compute losses", "\n", "nb", "=", "len", "(", "b", ")", "\n", "if", "nb", ":", "# number of targets", "\n", "            ", "ng", "+=", "nb", "\n", "ps", "=", "pi", "[", "b", ",", "a", ",", "gj", ",", "gi", "]", "# prediction subset corresponding to targets", "\n", "# ps[:, 2:4] = torch.sigmoid(ps[:, 2:4])  # wh power loss (uncomment)", "\n", "\n", "# GIoU", "\n", "# pxy = pxy * s - (s - 1) / 2,  s = 1.5  (scale_xy)", "\n", "pxy", "=", "torch", ".", "sigmoid", "(", "ps", "[", ":", ",", "0", ":", "2", "]", ")", "\n", "pwh", "=", "torch", ".", "exp", "(", "ps", "[", ":", ",", "2", ":", "4", "]", ")", ".", "clamp", "(", "max", "=", "1E3", ")", "*", "anchor_vec", "[", "i", "]", "\n", "pbox", "=", "torch", ".", "cat", "(", "(", "pxy", ",", "pwh", ")", ",", "1", ")", "# predicted box", "\n", "# giou computation", "\n", "giou", "=", "bbox_iou", "(", "pbox", ".", "t", "(", ")", ",", "tbox", "[", "i", "]", ",", "x1y1x2y2", "=", "False", ",", "GIoU", "=", "True", ")", "\n", "lbox", "+=", "(", "1.0", "-", "giou", ")", ".", "sum", "(", ")", "if", "red", "==", "'sum'", "else", "(", "1.0", "-", "\n", "giou", ")", ".", "mean", "(", ")", "# giou loss", "\n", "tobj", "[", "b", ",", "a", ",", "gj", ",", "gi", "]", "=", "(", "1.0", "-", "h", "[", "'gr'", "]", ")", "+", "h", "[", "'gr'", "]", "*", "giou", ".", "detach", "(", ")", ".", "clamp", "(", "0", ")", ".", "type", "(", "tobj", ".", "dtype", ")", "# giou ratio", "\n", "\n", "# cls loss (only if multiple classes)", "\n", "if", "'default'", "in", "arc", "and", "model", ".", "nc", ">", "1", ":", "\n", "                ", "t", "=", "torch", ".", "zeros_like", "(", "ps", "[", ":", ",", "5", ":", "]", ")", "# targets", "\n", "t", "[", "range", "(", "nb", ")", ",", "tcls", "[", "i", "]", "]", "=", "1.0", "\n", "lcls", "+=", "BCEcls", "(", "ps", "[", ":", ",", "5", ":", "]", ",", "t", ")", "# BCE", "\n", "# lcls += CE(ps[:, 5:], tcls[i])  # CE", "\n", "\n", "# Instance-class weighting (use with reduction='none')", "\n", "# nt = t.sum(0) + 1  # number of targets per class", "\n", "# lcls += (BCEcls(ps[:, 5:], t) / nt).mean() * nt.mean()  # v1", "\n", "# lcls += (BCEcls(ps[:, 5:], t) / nt[tcls[i]].view(-1,1)).mean() * nt.mean()  # v2", "\n", "\n", "# Append targets to text file", "\n", "# with open('targets.txt', 'a') as file:", "\n", "#     [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in torch.cat((txy[i], twh[i]), 1)]", "\n", "\n", "", "", "if", "'default'", "in", "arc", ":", "# separate obj and cls", "\n", "            ", "lobj", "+=", "BCEobj", "(", "pi", "[", "...", ",", "4", "]", ",", "tobj", ")", "# obj loss", "\n", "\n", "", "elif", "'BCE'", "in", "arc", ":", "# unified BCE (80 classes)", "\n", "            ", "t", "=", "torch", ".", "zeros_like", "(", "pi", "[", "...", ",", "5", ":", "]", ")", "# targets", "\n", "if", "nb", ":", "\n", "                ", "t", "[", "b", ",", "a", ",", "gj", ",", "gi", ",", "tcls", "[", "i", "]", "]", "=", "1.0", "\n", "", "lobj", "+=", "BCE", "(", "pi", "[", "...", ",", "5", ":", "]", ",", "t", ")", "\n", "\n", "", "elif", "'CE'", "in", "arc", ":", "# unified CE (1 background + 80 classes)", "\n", "            ", "t", "=", "torch", ".", "zeros_like", "(", "pi", "[", "...", ",", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", "# targets", "\n", "if", "nb", ":", "\n", "                ", "t", "[", "b", ",", "a", ",", "gj", ",", "gi", "]", "=", "tcls", "[", "i", "]", "+", "1", "\n", "", "lcls", "+=", "CE", "(", "pi", "[", "...", ",", "4", ":", "]", ".", "view", "(", "-", "1", ",", "model", ".", "nc", "+", "1", ")", ",", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "lbox", "*=", "h", "[", "'giou'", "]", "\n", "lobj", "*=", "h", "[", "'obj'", "]", "\n", "lcls", "*=", "h", "[", "'cls'", "]", "\n", "if", "red", "==", "'sum'", ":", "\n", "        ", "bs", "=", "tobj", ".", "shape", "[", "0", "]", "# batch size", "\n", "lobj", "*=", "3", "/", "(", "6300", "*", "bs", ")", "*", "2", "# 3 / np * 2", "\n", "if", "ng", ":", "\n", "            ", "lcls", "*=", "3", "/", "ng", "/", "model", ".", "nc", "\n", "lbox", "*=", "3", "/", "ng", "\n", "\n", "", "", "loss", "=", "lbox", "+", "lobj", "+", "lcls", "\n", "return", "loss", ",", "torch", ".", "cat", "(", "(", "lbox", ",", "lobj", ",", "lcls", ",", "loss", ")", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.build_targets": [[472, 526], ["len", "type", "t[].long().t", "gxy.long().t", "indices.append", "gxy.floor", "tbox.append", "av.append", "tcls.append", "utils.wh_iou", "torch.cat", "torch.cat", "len", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "targets.repeat", "gwh.repeat.repeat", "wh_iou.max", "t[].long", "gxy.long", "c.max", "wh_iou.view", "c.max", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view", "torch.arange().view", "torch.arange", "torch.arange"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.wh_iou"], ["", "def", "build_targets", "(", "model", ",", "targets", ")", ":", "\n", "# targets = [image, class, x, y, w, h]", "\n", "\n", "    ", "nt", "=", "len", "(", "targets", ")", "\n", "tcls", ",", "tbox", ",", "indices", ",", "av", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "multi_gpu", "=", "type", "(", "model", ")", "in", "(", "nn", ".", "parallel", ".", "DataParallel", ",", "\n", "nn", ".", "parallel", ".", "DistributedDataParallel", ")", "\n", "reject", ",", "use_all_anchors", "=", "True", ",", "True", "\n", "for", "i", "in", "model", ".", "yolo_layers", ":", "\n", "# get number of grid points and anchor vec for this yolo layer", "\n", "        ", "if", "multi_gpu", ":", "\n", "            ", "ng", ",", "anchor_vec", "=", "model", ".", "module", ".", "module_list", "[", "i", "]", ".", "ng", ",", "model", ".", "module", ".", "module_list", "[", "i", "]", ".", "anchor_vec", "\n", "", "else", ":", "\n", "            ", "ng", ",", "anchor_vec", "=", "model", ".", "module_list", "[", "i", "]", ".", "ng", ",", "model", ".", "module_list", "[", "i", "]", ".", "anchor_vec", "\n", "\n", "# iou of targets-anchors", "\n", "", "t", ",", "a", "=", "targets", ",", "[", "]", "\n", "gwh", "=", "t", "[", ":", ",", "4", ":", "6", "]", "*", "ng", "\n", "if", "nt", ":", "\n", "            ", "iou", "=", "wh_iou", "(", "anchor_vec", ",", "gwh", ")", "\n", "\n", "if", "use_all_anchors", ":", "\n", "                ", "na", "=", "len", "(", "anchor_vec", ")", "# number of anchors", "\n", "a", "=", "torch", ".", "arange", "(", "na", ")", ".", "view", "(", "(", "-", "1", ",", "1", ")", ")", ".", "repeat", "(", "[", "1", ",", "nt", "]", ")", ".", "view", "(", "-", "1", ")", "\n", "t", "=", "targets", ".", "repeat", "(", "[", "na", ",", "1", "]", ")", "\n", "gwh", "=", "gwh", ".", "repeat", "(", "[", "na", ",", "1", "]", ")", "\n", "", "else", ":", "# use best anchor only", "\n", "                ", "iou", ",", "a", "=", "iou", ".", "max", "(", "0", ")", "# best iou and anchor", "\n", "\n", "# reject anchors below iou_thres (OPTIONAL, increases P, lowers R)", "\n", "", "if", "reject", ":", "\n", "# iou threshold hyperparameter", "\n", "                ", "j", "=", "iou", ".", "view", "(", "-", "1", ")", ">", "model", ".", "hyp", "[", "'iou_t'", "]", "\n", "t", ",", "a", ",", "gwh", "=", "t", "[", "j", "]", ",", "a", "[", "j", "]", ",", "gwh", "[", "j", "]", "\n", "\n", "# Indices", "\n", "", "", "b", ",", "c", "=", "t", "[", ":", ",", ":", "2", "]", ".", "long", "(", ")", ".", "t", "(", ")", "# target image, class", "\n", "gxy", "=", "t", "[", ":", ",", "2", ":", "4", "]", "*", "ng", "# grid x, y", "\n", "gi", ",", "gj", "=", "gxy", ".", "long", "(", ")", ".", "t", "(", ")", "# grid x, y indices", "\n", "indices", ".", "append", "(", "(", "b", ",", "a", ",", "gj", ",", "gi", ")", ")", "\n", "\n", "# Box", "\n", "gxy", "-=", "gxy", ".", "floor", "(", ")", "# xy", "\n", "tbox", ".", "append", "(", "torch", ".", "cat", "(", "(", "gxy", ",", "gwh", ")", ",", "1", ")", ")", "# xywh (grids)", "\n", "av", ".", "append", "(", "anchor_vec", "[", "a", "]", ")", "# anchor vec", "\n", "\n", "# Class", "\n", "tcls", ".", "append", "(", "c", ")", "\n", "if", "c", ".", "shape", "[", "0", "]", ":", "# if any targets", "\n", "            ", "assert", "c", ".", "max", "(", ")", "<", "model", ".", "nc", ",", "'Model accepts %g classes labeled from 0-%g, however you labelled a class %g. '", "'See https://github.com/ultralytics/yolov3/wiki/Train-Custom-Data'", "%", "(", "\n", "model", ".", "nc", ",", "model", ".", "nc", "-", "1", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "", "", "return", "tcls", ",", "tbox", ",", "indices", ",", "av", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.non_max_suppression": [[528, 674], ["enumerate", "len", "utils.xywh2xyxy", "cls.unique", "len", "torch.cat", "torch.cat", "pred[].max", "torch.cat", "torch.cat", "torch.isfinite().all", "torch.isfinite().all", "method.startswith", "len", "torch.cat", "torch.cat", "pred[].clone", "torchvision.ops.boxes.batched_nms", "torch.cat.append", "torch.cat.append", "pred[].unsqueeze", "j.float().unsqueeze", "conf.unsqueeze", "j.float().unsqueeze", "torch.isfinite", "torch.isfinite", "torch.isfinite().all", "torch.isfinite().all", "pred[].argsort", "box_iou().triu_", "c.view", "torch.cat.append", "utils.bbox_iou", "j.float", "j.float", "torch.isfinite", "torch.isfinite", "utils.box_iou", "bbox_iou.max", "torchvision.ops.boxes.nms", "len", "len", "utils.bbox_iou", "len", "j.view", "torch.tensor", "torch.tensor", "bbox_iou.max", "torch.cat.append", "torch.cat.append", "len", "len", "torch.cat.append", "utils.bbox_iou", "weights.sum", "torch.cat.append", "utils.bbox_iou", "torch.exp", "torch.exp", "len", "torch.cat.append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xywh2xyxy", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.box_iou", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.bbox_iou"], ["", "def", "non_max_suppression", "(", "prediction", ",", "conf_thres", "=", "0.1", ",", "iou_thres", "=", "0.6", ",", "multi_cls", "=", "True", ",", "classes", "=", "None", ",", "agnostic", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Removes detections with lower object confidence score than 'conf_thres'\n    Non-Maximum Suppression to further filter detections.\n    Returns detections with shape:\n        (x1, y1, x2, y2, object_conf, conf, class)\n    \"\"\"", "\n", "# NMS methods https://github.com/ultralytics/yolov3/issues/679 'or', 'and', 'merge', 'vision', 'vision_batch'", "\n", "\n", "# Box constraints", "\n", "# (pixels) minimum and maximum box width and height", "\n", "min_wh", ",", "max_wh", "=", "2", ",", "4096", "\n", "\n", "method", "=", "'vision_batch'", "\n", "batched", "=", "'batch'", "in", "method", "# run once per image, all classes simultaneously", "\n", "nc", "=", "prediction", "[", "0", "]", ".", "shape", "[", "1", "]", "-", "5", "# number of classes", "\n", "multi_cls", "=", "multi_cls", "and", "(", "nc", ">", "1", ")", "# allow multiple classes per anchor", "\n", "output", "=", "[", "None", "]", "*", "len", "(", "prediction", ")", "\n", "for", "image_i", ",", "pred", "in", "enumerate", "(", "prediction", ")", ":", "\n", "# Apply conf constraint", "\n", "        ", "pred", "=", "pred", "[", "pred", "[", ":", ",", "4", "]", ">", "conf_thres", "]", "\n", "\n", "# Apply width-height constraint", "\n", "pred", "=", "pred", "[", "(", "(", "pred", "[", ":", ",", "2", ":", "4", "]", ">", "min_wh", ")", "&", "(", "pred", "[", ":", ",", "2", ":", "4", "]", "<", "max_wh", ")", ")", ".", "all", "(", "1", ")", "]", "\n", "\n", "# Compute conf", "\n", "pred", "[", "...", ",", "5", ":", "]", "*=", "pred", "[", "...", ",", "4", ":", "5", "]", "# conf = obj_conf * cls_conf", "\n", "\n", "# Box (center x, center y, width, height) to (x1, y1, x2, y2)", "\n", "box", "=", "xywh2xyxy", "(", "pred", "[", ":", ",", ":", "4", "]", ")", "\n", "\n", "# Detections matrix nx6 (xyxy, conf, cls)", "\n", "if", "multi_cls", ":", "\n", "            ", "i", ",", "j", "=", "(", "pred", "[", ":", ",", "5", ":", "]", ">", "conf_thres", ")", ".", "nonzero", "(", ")", ".", "t", "(", ")", "\n", "pred", "=", "torch", ".", "cat", "(", "\n", "(", "box", "[", "i", "]", ",", "pred", "[", "i", ",", "j", "+", "5", "]", ".", "unsqueeze", "(", "1", ")", ",", "j", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "", "else", ":", "# best class only", "\n", "            ", "conf", ",", "j", "=", "pred", "[", ":", ",", "5", ":", "]", ".", "max", "(", "1", ")", "\n", "pred", "=", "torch", ".", "cat", "(", "\n", "(", "box", ",", "conf", ".", "unsqueeze", "(", "1", ")", ",", "j", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "\n", "# Filter by class", "\n", "", "if", "classes", ":", "\n", "            ", "pred", "=", "pred", "[", "(", "j", ".", "view", "(", "-", "1", ",", "1", ")", "==", "\n", "torch", ".", "tensor", "(", "classes", ",", "device", "=", "j", ".", "device", ")", ")", ".", "any", "(", "1", ")", "]", "\n", "\n", "# Apply finite constraint", "\n", "", "if", "not", "torch", ".", "isfinite", "(", "pred", ")", ".", "all", "(", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "torch", ".", "isfinite", "(", "pred", ")", ".", "all", "(", "1", ")", "]", "\n", "\n", "# If none remain process next image", "\n", "", "if", "not", "pred", ".", "shape", "[", "0", "]", ":", "\n", "            ", "continue", "\n", "\n", "# Sort by confidence", "\n", "", "if", "not", "method", ".", "startswith", "(", "'vision'", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "pred", "[", ":", ",", "4", "]", ".", "argsort", "(", "descending", "=", "True", ")", "]", "\n", "\n", "# Batched NMS", "\n", "", "if", "batched", ":", "\n", "# class-agnostic NMS", "\n", "            ", "c", "=", "pred", "[", ":", ",", "5", "]", "*", "0", "if", "agnostic", "else", "pred", "[", ":", ",", "5", "]", "\n", "boxes", ",", "scores", "=", "pred", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", ",", "pred", "[", ":", ",", "4", "]", "\n", "if", "method", "==", "'vision_batch'", ":", "\n", "                ", "i", "=", "torchvision", ".", "ops", ".", "boxes", ".", "batched_nms", "(", "\n", "boxes", ",", "scores", ",", "c", ",", "iou_thres", ")", "\n", "", "elif", "method", "==", "'fast_batch'", ":", "# FastNMS from https://github.com/dbolya/yolact", "\n", "                ", "boxes", "+=", "c", ".", "view", "(", "-", "1", ",", "1", ")", "*", "max_wh", "\n", "iou", "=", "box_iou", "(", "boxes", ",", "boxes", ")", ".", "triu_", "(", "\n", "diagonal", "=", "1", ")", "# upper triangular iou matrix", "\n", "i", "=", "iou", ".", "max", "(", "dim", "=", "0", ")", "[", "0", "]", "<", "iou_thres", "\n", "\n", "", "output", "[", "image_i", "]", "=", "pred", "[", "i", "]", "\n", "continue", "\n", "\n", "# All other NMS methods", "\n", "", "det_max", "=", "[", "]", "\n", "cls", "=", "pred", "[", ":", ",", "-", "1", "]", "\n", "for", "c", "in", "cls", ".", "unique", "(", ")", ":", "\n", "            ", "dc", "=", "pred", "[", "cls", "==", "c", "]", "# select class c", "\n", "n", "=", "len", "(", "dc", ")", "\n", "if", "n", "==", "1", ":", "\n", "                ", "det_max", ".", "append", "(", "dc", ")", "# No NMS required if only 1 prediction", "\n", "continue", "\n", "", "elif", "n", ">", "500", ":", "\n", "# limit to first 500 boxes: https://github.com/ultralytics/yolov3/issues/117", "\n", "                ", "dc", "=", "dc", "[", ":", "500", "]", "\n", "\n", "", "if", "method", "==", "'vision'", ":", "\n", "                ", "det_max", ".", "append", "(", "dc", "[", "torchvision", ".", "ops", ".", "boxes", ".", "nms", "(", "\n", "dc", "[", ":", ",", ":", "4", "]", ",", "dc", "[", ":", ",", "4", "]", ",", "iou_thres", ")", "]", ")", "\n", "\n", "", "elif", "method", "==", "'or'", ":", "# default", "\n", "# METHOD1", "\n", "# ind = list(range(len(dc)))", "\n", "# while len(ind):", "\n", "# j = ind[0]", "\n", "# det_max.append(dc[j:j + 1])  # save highest conf detection", "\n", "# reject = (bbox_iou(dc[j], dc[ind]) > iou_thres).nonzero()", "\n", "# [ind.pop(i) for i in reversed(reject)]", "\n", "\n", "# METHOD2", "\n", "                ", "while", "dc", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "det_max", ".", "append", "(", "dc", "[", ":", "1", "]", ")", "# save highest conf detection", "\n", "if", "len", "(", "dc", ")", "==", "1", ":", "# Stop if we're at the last detection", "\n", "                        ", "break", "\n", "", "iou", "=", "bbox_iou", "(", "dc", "[", "0", "]", ",", "dc", "[", "1", ":", "]", ")", "# iou with other boxes", "\n", "dc", "=", "dc", "[", "1", ":", "]", "[", "iou", "<", "iou_thres", "]", "# remove ious > threshold", "\n", "\n", "", "", "elif", "method", "==", "'and'", ":", "# requires overlap, single boxes erased", "\n", "                ", "while", "len", "(", "dc", ")", ">", "1", ":", "\n", "                    ", "iou", "=", "bbox_iou", "(", "dc", "[", "0", "]", ",", "dc", "[", "1", ":", "]", ")", "# iou with other boxes", "\n", "if", "iou", ".", "max", "(", ")", ">", "0.5", ":", "\n", "                        ", "det_max", ".", "append", "(", "dc", "[", ":", "1", "]", ")", "\n", "", "dc", "=", "dc", "[", "1", ":", "]", "[", "iou", "<", "iou_thres", "]", "# remove ious > threshold", "\n", "\n", "", "", "elif", "method", "==", "'merge'", ":", "# weighted mixture box", "\n", "                ", "while", "len", "(", "dc", ")", ":", "\n", "                    ", "if", "len", "(", "dc", ")", "==", "1", ":", "\n", "                        ", "det_max", ".", "append", "(", "dc", ")", "\n", "break", "\n", "", "i", "=", "bbox_iou", "(", "dc", "[", "0", "]", ",", "dc", ")", ">", "iou_thres", "# iou with other boxes", "\n", "weights", "=", "dc", "[", "i", ",", "4", ":", "5", "]", "\n", "dc", "[", "0", ",", ":", "4", "]", "=", "(", "weights", "*", "dc", "[", "i", ",", ":", "4", "]", ")", ".", "sum", "(", "0", ")", "/", "weights", ".", "sum", "(", ")", "\n", "det_max", ".", "append", "(", "dc", "[", ":", "1", "]", ")", "\n", "dc", "=", "dc", "[", "i", "==", "0", "]", "\n", "\n", "", "", "elif", "method", "==", "'soft'", ":", "# soft-NMS https://arxiv.org/abs/1704.04503", "\n", "                ", "sigma", "=", "0.5", "# soft-nms sigma parameter", "\n", "while", "len", "(", "dc", ")", ":", "\n", "                    ", "if", "len", "(", "dc", ")", "==", "1", ":", "\n", "                        ", "det_max", ".", "append", "(", "dc", ")", "\n", "break", "\n", "", "det_max", ".", "append", "(", "dc", "[", ":", "1", "]", ")", "\n", "iou", "=", "bbox_iou", "(", "dc", "[", "0", "]", ",", "dc", "[", "1", ":", "]", ")", "# iou with other boxes", "\n", "dc", "=", "dc", "[", "1", ":", "]", "\n", "# decay confidences", "\n", "dc", "[", ":", ",", "4", "]", "*=", "torch", ".", "exp", "(", "-", "iou", "**", "2", "/", "sigma", ")", "\n", "# https://github.com/ultralytics/yolov3/issues/362", "\n", "dc", "=", "dc", "[", "dc", "[", ":", ",", "4", "]", ">", "conf_thres", "]", "\n", "\n", "", "", "", "if", "len", "(", "det_max", ")", ":", "\n", "            ", "det_max", "=", "torch", ".", "cat", "(", "det_max", ")", "# concatenate", "\n", "output", "[", "image_i", "]", "=", "det_max", "[", "(", "-", "det_max", "[", ":", ",", "4", "]", ")", ".", "argsort", "(", ")", "]", "# sort", "\n", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.get_yolo_layers": [[676, 679], ["enumerate"], "function", ["None"], ["", "def", "get_yolo_layers", "(", "model", ")", ":", "\n", "    ", "bool_vec", "=", "[", "x", "[", "'type'", "]", "==", "'yolo'", "for", "x", "in", "model", ".", "module_defs", "]", "\n", "return", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "bool_vec", ")", "if", "x", "]", "# [82, 94, 106] for yolov3", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.print_model_biases": [[681, 699], ["print", "type", "print", "[].bias.view", "[].bias.view", "b[].mean", "b[].std", "b[].mean", "b[].std", "b[].mean", "b[].std"], "function", ["None"], ["", "def", "print_model_biases", "(", "model", ")", ":", "\n", "# prints the bias neurons preceding each yolo layer", "\n", "    ", "print", "(", "'\\nModel Bias Summary: %8s%18s%18s%18s'", "%", "\n", "(", "'layer'", ",", "'regression'", ",", "'objectness'", ",", "'classification'", ")", ")", "\n", "multi_gpu", "=", "type", "(", "model", ")", "in", "(", "nn", ".", "parallel", ".", "DataParallel", ",", "\n", "nn", ".", "parallel", ".", "DistributedDataParallel", ")", "\n", "for", "l", "in", "model", ".", "yolo_layers", ":", "# print pretrained biases", "\n", "        ", "if", "multi_gpu", ":", "\n", "            ", "na", "=", "model", ".", "module", ".", "module_list", "[", "l", "]", ".", "na", "# number of anchors", "\n", "b", "=", "model", ".", "module", ".", "module_list", "[", "l", "-", "\n", "1", "]", "[", "0", "]", ".", "bias", ".", "view", "(", "na", ",", "-", "1", ")", "# bias 3x85", "\n", "", "else", ":", "\n", "            ", "na", "=", "model", ".", "module_list", "[", "l", "]", ".", "na", "\n", "b", "=", "model", ".", "module_list", "[", "l", "-", "1", "]", "[", "0", "]", ".", "bias", ".", "view", "(", "na", ",", "-", "1", ")", "# bias 3x85", "\n", "", "print", "(", "' '", "*", "20", "+", "'%8g %18s%18s%18s'", "%", "(", "l", ",", "'%5.2f+/-%-5.2f'", "%", "(", "b", "[", ":", ",", ":", "4", "]", ".", "mean", "(", ")", ",", "b", "[", ":", ",", ":", "4", "]", ".", "std", "(", ")", ")", ",", "\n", "'%5.2f+/-%-5.2f'", "%", "(", "\n", "b", "[", ":", ",", "4", "]", ".", "mean", "(", ")", ",", "b", "[", ":", ",", "4", "]", ".", "std", "(", ")", ")", ",", "\n", "'%5.2f+/-%-5.2f'", "%", "(", "b", "[", ":", ",", "5", ":", "]", ".", "mean", "(", ")", ",", "b", "[", ":", ",", "5", ":", "]", ".", "std", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.strip_optimizer": [[702, 709], ["torch.load", "torch.load", "torch.save", "torch.save", "torch.device", "torch.device"], "function", ["None"], ["", "", "def", "strip_optimizer", "(", "f", "=", "'weights/last.pt'", ")", ":", "\n", "# Strip optimizer from *.pt files for lighter files (reduced by 2/3 size)", "\n", "    ", "x", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "x", "[", "'optimizer'", "]", "=", "None", "\n", "# x['training_results'] = None  # uncomment to create a backbone", "\n", "# x['epoch'] = -1  # uncomment to create a backbone", "\n", "torch", ".", "save", "(", "x", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.create_backbone": [[712, 724], ["torch.load", "torch.load", "x[].values", "torch.save", "torch.save", "torch.device", "torch.device"], "function", ["None"], ["", "def", "create_backbone", "(", "f", "=", "'weights/last.pt'", ")", ":", "\n", "# create a backbone from a *.pt file", "\n", "    ", "x", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "x", "[", "'optimizer'", "]", "=", "None", "\n", "x", "[", "'training_results'", "]", "=", "None", "\n", "x", "[", "'epoch'", "]", "=", "-", "1", "\n", "for", "p", "in", "x", "[", "'model'", "]", ".", "values", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "", "torch", ".", "save", "(", "x", ",", "'weights/backbone.pt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.coco_class_count": [[726, 735], ["numpy.zeros", "sorted", "enumerate", "glob.glob", "numpy.loadtxt().reshape", "numpy.bincount", "print", "labels[].astype", "len", "numpy.loadtxt"], "function", ["None"], ["", "def", "coco_class_count", "(", "path", "=", "'../coco/labels/train2014/'", ")", ":", "\n", "# Histogram of occurrences per class", "\n", "    ", "nc", "=", "80", "# number classes", "\n", "x", "=", "np", ".", "zeros", "(", "nc", ",", "dtype", "=", "'int32'", ")", "\n", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "'%s/*.*'", "%", "path", ")", ")", "\n", "for", "i", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "labels", "=", "np", ".", "loadtxt", "(", "file", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "5", ")", "\n", "x", "+=", "np", ".", "bincount", "(", "labels", "[", ":", ",", "0", "]", ".", "astype", "(", "'int32'", ")", ",", "minlength", "=", "nc", ")", "\n", "print", "(", "i", ",", "len", "(", "files", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.coco_only_people": [[738, 745], ["sorted", "enumerate", "glob.glob", "numpy.loadtxt().reshape", "all", "print", "numpy.loadtxt"], "function", ["None"], ["", "", "def", "coco_only_people", "(", "path", "=", "'../coco/labels/train2017/'", ")", ":", "\n", "# Find images with only people", "\n", "    ", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "'%s/*.*'", "%", "path", ")", ")", "\n", "for", "i", ",", "file", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "labels", "=", "np", ".", "loadtxt", "(", "file", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "5", ")", "\n", "if", "all", "(", "labels", "[", ":", ",", "0", "]", "==", "0", ")", ":", "\n", "            ", "print", "(", "labels", ".", "shape", "[", "0", "]", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.select_best_evolve": [[748, 753], ["sorted", "glob.glob", "numpy.loadtxt", "print", "fitness().argmax", "utils.fitness"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.fitness"], ["", "", "", "def", "select_best_evolve", "(", "path", "=", "'evolve*.txt'", ")", ":", "\n", "# Find best evolved mutation", "\n", "    ", "for", "file", "in", "sorted", "(", "glob", ".", "glob", "(", "path", ")", ")", ":", "\n", "        ", "x", "=", "np", ".", "loadtxt", "(", "file", ",", "dtype", "=", "np", ".", "float32", ",", "ndmin", "=", "2", ")", "\n", "print", "(", "file", ",", "x", "[", "fitness", "(", "x", ")", ".", "argmax", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.crop_images_random": [[756, 777], ["tqdm.tqdm", "sorted", "cv2.imread", "glob.glob", "random.randint", "max", "max", "min", "min", "cv2.imwrite", "int", "max", "random.randint", "random.randint"], "function", ["None"], ["", "", "def", "crop_images_random", "(", "path", "=", "'../images/'", ",", "scale", "=", "0.50", ")", ":", "\n", "# crops images into random squares up to scale fraction", "\n", "# WARNING: overwrites images!", "\n", "    ", "for", "file", "in", "tqdm", "(", "sorted", "(", "glob", ".", "glob", "(", "'%s/*.*'", "%", "path", ")", ")", ")", ":", "\n", "        ", "img", "=", "cv2", ".", "imread", "(", "file", ")", "# BGR", "\n", "if", "img", "is", "not", "None", ":", "\n", "            ", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# create random mask", "\n", "a", "=", "30", "# minimum size (pixels)", "\n", "mask_h", "=", "random", ".", "randint", "(", "a", ",", "int", "(", "max", "(", "a", ",", "h", "*", "scale", ")", ")", ")", "# mask height", "\n", "mask_w", "=", "mask_h", "# mask width", "\n", "\n", "# box", "\n", "xmin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "w", ")", "-", "mask_w", "//", "2", ")", "\n", "ymin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "h", ")", "-", "mask_h", "//", "2", ")", "\n", "xmax", "=", "min", "(", "w", ",", "xmin", "+", "mask_w", ")", "\n", "ymax", "=", "min", "(", "h", ",", "ymin", "+", "mask_h", ")", "\n", "\n", "# apply random color mask", "\n", "cv2", ".", "imwrite", "(", "file", ",", "img", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.coco_single_class_labels": [[779, 801], ["os.path.exists", "os.makedirs", "os.makedirs", "os.makedirs", "tqdm.tqdm", "shutil.rmtree", "sorted", "any", "glob.glob", "open", "numpy.array", "file.replace().replace", "shutil.copyfile", "open", "f.write", "open", "x.split", "file.replace", "f.write", "f.read().splitlines", "pathlib.Path().name.replace", "pathlib.Path", "tuple", "f.read", "pathlib.Path"], "function", ["None"], ["", "", "", "def", "coco_single_class_labels", "(", "path", "=", "'../coco/labels/train2014/'", ",", "label_class", "=", "43", ")", ":", "\n", "# Makes single-class coco datasets. from utils.utils import *; coco_single_class_labels()", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "'new/'", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "'new/'", ")", "# delete output folder", "\n", "", "os", ".", "makedirs", "(", "'new/'", ")", "# make new output folder", "\n", "os", ".", "makedirs", "(", "'new/labels/'", ")", "\n", "os", ".", "makedirs", "(", "'new/images/'", ")", "\n", "for", "file", "in", "tqdm", "(", "sorted", "(", "glob", ".", "glob", "(", "'%s/*.*'", "%", "path", ")", ")", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "labels", "=", "np", ".", "array", "(", "[", "x", ".", "split", "(", ")", "\n", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "i", "=", "labels", "[", ":", ",", "0", "]", "==", "label_class", "\n", "if", "any", "(", "i", ")", ":", "\n", "            ", "img_file", "=", "file", ".", "replace", "(", "'labels'", ",", "'images'", ")", ".", "replace", "(", "'txt'", ",", "'jpg'", ")", "\n", "labels", "[", ":", ",", "0", "]", "=", "0", "# reset class to 0", "\n", "with", "open", "(", "'new/images.txt'", ",", "'a'", ")", "as", "f", ":", "# add image to dataset list", "\n", "                ", "f", ".", "write", "(", "img_file", "+", "'\\n'", ")", "\n", "", "with", "open", "(", "'new/labels/'", "+", "Path", "(", "file", ")", ".", "name", ",", "'a'", ")", "as", "f", ":", "# write label", "\n", "                ", "for", "l", "in", "labels", "[", "i", "]", ":", "\n", "                    ", "f", ".", "write", "(", "'%g %.6f %.6f %.6f %.6f\\n'", "%", "tuple", "(", "l", ")", ")", "\n", "", "", "shutil", ".", "copyfile", "(", "src", "=", "img_file", ",", "dst", "=", "'new/images/'", "+", "\n", "Path", "(", "file", ")", ".", "name", ".", "replace", "(", "'txt'", ",", "'jpg'", ")", ")", "# copy images", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.kmean_anchors": [[803, 888], ["LoadImagesAndLabels", "zip", "numpy.concatenate().repeat", "numpy.random.uniform", "torch.Tensor", "torch.Tensor", "utils.kmean_anchors.print_results"], "function", ["None"], ["", "", "", "def", "kmean_anchors", "(", "path", "=", "'../coco/train2017.txt'", ",", "n", "=", "9", ",", "img_size", "=", "(", "608", ",", "608", ")", ")", ":", "\n", "# from utils.utils import *; _ = kmean_anchors()", "\n", "# Produces a list of target kmeans suitable for use in *.cfg files", "\n", "    ", "from", "utils", ".", "datasets", "import", "LoadImagesAndLabels", "\n", "thr", "=", "0.20", "# IoU threshold", "\n", "\n", "def", "print_results", "(", "k", ")", ":", "\n", "        ", "k", "=", "k", "[", "np", ".", "argsort", "(", "k", ".", "prod", "(", "1", ")", ")", "]", "# sort small to large", "\n", "iou", "=", "wh_iou", "(", "wh", ",", "torch", ".", "Tensor", "(", "k", ")", ")", "\n", "max_iou", "=", "iou", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "bpr", ",", "aat", "=", "(", "max_iou", ">", "thr", ")", ".", "float", "(", ")", ".", "mean", "(", ")", ",", "(", "iou", ">", "thr", ")", ".", "float", "(", "\n", ")", ".", "mean", "(", ")", "*", "n", "# best possible recall, anch > thr", "\n", "print", "(", "'%.2f iou_thr: %.3f best possible recall, %.2f anchors > thr'", "%", "\n", "(", "thr", ",", "bpr", ",", "aat", ")", ")", "\n", "print", "(", "'n=%g, img_size=%s, IoU_all=%.3f/%.3f-mean/best, IoU>thr=%.3f-mean: '", "%", "\n", "(", "n", ",", "img_size", ",", "iou", ".", "mean", "(", ")", ",", "max_iou", ".", "mean", "(", ")", ",", "iou", "[", "iou", ">", "thr", "]", ".", "mean", "(", ")", ")", ",", "end", "=", "''", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "k", ")", ":", "\n", "            ", "print", "(", "'%i,%i'", "%", "(", "round", "(", "x", "[", "0", "]", ")", ",", "round", "(", "x", "[", "1", "]", ")", ")", ",", "end", "=", "',  '", "if", "i", "<", "len", "(", "\n", "k", ")", "-", "1", "else", "'\\n'", ")", "# use in *.cfg", "\n", "", "return", "k", "\n", "\n", "", "def", "fitness", "(", "k", ")", ":", "# mutation fitness", "\n", "        ", "iou", "=", "wh_iou", "(", "wh", ",", "torch", ".", "Tensor", "(", "k", ")", ")", "# iou", "\n", "max_iou", "=", "iou", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "return", "max_iou", ".", "mean", "(", ")", "# product", "\n", "\n", "# Get label wh", "\n", "", "wh", "=", "[", "]", "\n", "dataset", "=", "LoadImagesAndLabels", "(", "\n", "path", ",", "augment", "=", "True", ",", "rect", "=", "True", ",", "cache_labels", "=", "True", ")", "\n", "# number augmentation repetitions", "\n", "nr", "=", "1", "if", "img_size", "[", "0", "]", "==", "img_size", "[", "1", "]", "else", "10", "\n", "for", "s", ",", "l", "in", "zip", "(", "dataset", ".", "shapes", ",", "dataset", ".", "labels", ")", ":", "\n", "# image normalized to letterbox normalized wh", "\n", "        ", "wh", ".", "append", "(", "l", "[", ":", ",", "3", ":", "5", "]", "*", "(", "s", "/", "s", ".", "max", "(", ")", ")", ")", "\n", "", "wh", "=", "np", ".", "concatenate", "(", "wh", ",", "0", ")", ".", "repeat", "(", "nr", ",", "axis", "=", "0", ")", "# augment 10x", "\n", "# normalized to pixels (multi-scale)", "\n", "wh", "*=", "np", ".", "random", ".", "uniform", "(", "img_size", "[", "0", "]", ",", "img_size", "[", "1", "]", ",", "size", "=", "(", "wh", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "\n", "wh", "=", "wh", "[", "(", "wh", ">", "2.0", ")", ".", "all", "(", "1", ")", "]", "# remove below threshold boxes (< 2 pixels wh)", "\n", "\n", "# Darknet yolov3.cfg anchors", "\n", "use_darknet", "=", "False", "\n", "if", "use_darknet", "and", "n", "==", "9", ":", "\n", "        ", "k", "=", "np", ".", "array", "(", "[", "[", "10", ",", "13", "]", ",", "[", "16", ",", "30", "]", ",", "[", "33", ",", "23", "]", ",", "[", "30", ",", "61", "]", ",", "[", "62", ",", "45", "]", ",", "[", "\n", "59", ",", "119", "]", ",", "[", "116", ",", "90", "]", ",", "[", "156", ",", "198", "]", ",", "[", "373", ",", "326", "]", "]", ")", "\n", "", "else", ":", "\n", "# Kmeans calculation", "\n", "        ", "from", "scipy", ".", "cluster", ".", "vq", "import", "kmeans", "\n", "print", "(", "'Running kmeans for %g anchors on %g points...'", "%", "(", "n", ",", "len", "(", "wh", ")", ")", ")", "\n", "s", "=", "wh", ".", "std", "(", "0", ")", "# sigmas for whitening", "\n", "k", ",", "dist", "=", "kmeans", "(", "wh", "/", "s", ",", "n", ",", "iter", "=", "30", ")", "# points, mean distance", "\n", "k", "*=", "s", "\n", "", "wh", "=", "torch", ".", "Tensor", "(", "wh", ")", "\n", "k", "=", "print_results", "(", "k", ")", "\n", "\n", "# # Plot", "\n", "# k, d = [None] * 20, [None] * 20", "\n", "# for i in tqdm(range(1, 21)):", "\n", "#     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance", "\n", "# fig, ax = plt.subplots(1, 2, figsize=(14, 7))", "\n", "# ax = ax.ravel()", "\n", "# ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')", "\n", "# fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh", "\n", "# ax[0].hist(wh[wh[:, 0]<100, 0],400)", "\n", "# ax[1].hist(wh[wh[:, 1]<100, 1],400)", "\n", "# fig.tight_layout()", "\n", "# fig.savefig('wh.png', dpi=200)", "\n", "\n", "# Evolve", "\n", "npr", "=", "np", ".", "random", "\n", "# fitness, generations, mutation prob, sigma", "\n", "f", ",", "sh", ",", "ng", ",", "mp", ",", "s", "=", "fitness", "(", "k", ")", ",", "k", ".", "shape", ",", "1000", ",", "0.9", ",", "0.1", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "ng", ")", ",", "desc", "=", "'Evolving anchors'", ")", ":", "\n", "        ", "v", "=", "np", ".", "ones", "(", "sh", ")", "\n", "while", "(", "v", "==", "1", ")", ".", "all", "(", ")", ":", "# mutate until a change occurs (prevent duplicates)", "\n", "            ", "v", "=", "(", "(", "npr", ".", "random", "(", "sh", ")", "<", "mp", ")", "*", "npr", ".", "random", "(", ")", "*", "\n", "npr", ".", "randn", "(", "*", "sh", ")", "*", "s", "+", "1", ")", ".", "clip", "(", "0.3", ",", "3.0", ")", "# 98.6, 61.6", "\n", "", "kg", "=", "(", "k", ".", "copy", "(", ")", "*", "v", ")", ".", "clip", "(", "min", "=", "2.0", ")", "\n", "fg", "=", "fitness", "(", "kg", ")", "\n", "if", "fg", ">", "f", ":", "\n", "            ", "f", ",", "k", "=", "fg", ",", "kg", ".", "copy", "(", ")", "\n", "print_results", "(", "k", ")", "\n", "", "", "k", "=", "print_results", "(", "k", ")", "\n", "\n", "return", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.print_mutation": [[890, 910], ["print", "numpy.unique", "numpy.savetxt", "tuple", "tuple", "os.system", "open", "f.write", "numpy.loadtxt", "os.system", "len", "hyp.keys", "len", "hyp.values", "len", "numpy.argsort", "utils.fitness"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.fitness"], ["", "def", "print_mutation", "(", "hyp", ",", "results", ",", "bucket", "=", "''", ")", ":", "\n", "# Print mutation results to evolve.txt (for use with train.py --evolve)", "\n", "    ", "a", "=", "'%10s'", "*", "len", "(", "hyp", ")", "%", "tuple", "(", "hyp", ".", "keys", "(", ")", ")", "# hyperparam keys", "\n", "b", "=", "'%10.3g'", "*", "len", "(", "hyp", ")", "%", "tuple", "(", "hyp", ".", "values", "(", ")", ")", "# hyperparam values", "\n", "c", "=", "'%10.4g'", "*", "len", "(", "results", ")", "%", "results", "# results (P, R, mAP, F1, test_loss)", "\n", "print", "(", "'\\n%s\\n%s\\nEvolved fitness: %s\\n'", "%", "(", "a", ",", "b", ",", "c", ")", ")", "\n", "\n", "if", "bucket", ":", "\n", "        ", "os", ".", "system", "(", "'gsutil cp gs://%s/evolve.txt .'", "%", "\n", "bucket", ")", "# download evolve.txt", "\n", "\n", "", "with", "open", "(", "'evolve.txt'", ",", "'a'", ")", "as", "f", ":", "# append result", "\n", "        ", "f", ".", "write", "(", "c", "+", "b", "+", "'\\n'", ")", "\n", "", "x", "=", "np", ".", "unique", "(", "np", ".", "loadtxt", "(", "'evolve.txt'", ",", "ndmin", "=", "2", ")", ",", "\n", "axis", "=", "0", ")", "# load unique rows", "\n", "# save sort by fitness", "\n", "np", ".", "savetxt", "(", "'evolve.txt'", ",", "x", "[", "np", ".", "argsort", "(", "-", "fitness", "(", "x", ")", ")", "]", ",", "'%10.3g'", ")", "\n", "\n", "if", "bucket", ":", "\n", "        ", "os", ".", "system", "(", "'gsutil cp evolve.txt gs://%s'", "%", "bucket", ")", "# upload evolve.txt", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.apply_classifier": [[912, 949], ["enumerate", "isinstance", "len", "d.clone.clone", "utils.xyxy2xywh", "[].unsqueeze", "xywh2xyxy().long", "utils.scale_coords", "d[].long", "enumerate", "model().argmax", "cv2.resize", "im[].transpose", "numpy.ascontiguousarray", "ims.append", "utils.xywh2xyxy", "model", "b[].max", "torch.Tensor().to", "torch.Tensor().to", "int", "int", "int", "int", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xyxy2xywh", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.scale_coords", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xywh2xyxy"], ["", "", "def", "apply_classifier", "(", "x", ",", "model", ",", "img", ",", "im0", ")", ":", "\n", "# applies a second stage classifier to yolo outputs", "\n", "    ", "im0", "=", "[", "im0", "]", "if", "isinstance", "(", "im0", ",", "np", ".", "ndarray", ")", "else", "im0", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "x", ")", ":", "# per image", "\n", "        ", "if", "d", "is", "not", "None", "and", "len", "(", "d", ")", ":", "\n", "            ", "d", "=", "d", ".", "clone", "(", ")", "\n", "\n", "# Reshape and pad cutouts", "\n", "b", "=", "xyxy2xywh", "(", "d", "[", ":", ",", ":", "4", "]", ")", "# boxes", "\n", "b", "[", ":", ",", "2", ":", "]", "=", "b", "[", ":", ",", "2", ":", "]", ".", "max", "(", "1", ")", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", "# rectangle to square", "\n", "b", "[", ":", ",", "2", ":", "]", "=", "b", "[", ":", ",", "2", ":", "]", "*", "1.3", "+", "30", "# pad", "\n", "d", "[", ":", ",", ":", "4", "]", "=", "xywh2xyxy", "(", "b", ")", ".", "long", "(", ")", "\n", "\n", "# Rescale boxes from img_size to im0 size", "\n", "scale_coords", "(", "img", ".", "shape", "[", "2", ":", "]", ",", "d", "[", ":", ",", ":", "4", "]", ",", "im0", "[", "i", "]", ".", "shape", ")", "\n", "\n", "# Classes", "\n", "pred_cls1", "=", "d", "[", ":", ",", "5", "]", ".", "long", "(", ")", "\n", "ims", "=", "[", "]", "\n", "for", "j", ",", "a", "in", "enumerate", "(", "d", ")", ":", "# per item", "\n", "                ", "cutout", "=", "im0", "[", "i", "]", "[", "int", "(", "a", "[", "1", "]", ")", ":", "int", "(", "a", "[", "3", "]", ")", ",", "int", "(", "a", "[", "0", "]", ")", ":", "int", "(", "a", "[", "2", "]", ")", "]", "\n", "im", "=", "cv2", ".", "resize", "(", "cutout", ",", "(", "224", ",", "224", ")", ")", "# BGR", "\n", "# cv2.imwrite('test%i.jpg' % j, cutout)", "\n", "\n", "# BGR to RGB, to 3x416x416", "\n", "im", "=", "im", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "im", "=", "np", ".", "ascontiguousarray", "(", "\n", "im", ",", "dtype", "=", "np", ".", "float32", ")", "# uint8 to float32", "\n", "im", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "ims", ".", "append", "(", "im", ")", "\n", "\n", "", "pred_cls2", "=", "model", "(", "torch", ".", "Tensor", "(", "ims", ")", ".", "to", "(", "d", ".", "device", ")", "\n", ")", ".", "argmax", "(", "1", ")", "# classifier prediction", "\n", "# retain matching class detections", "\n", "x", "[", "i", "]", "=", "x", "[", "i", "]", "[", "pred_cls1", "==", "pred_cls2", "]", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.fitness": [[951, 956], ["None"], "function", ["None"], ["", "def", "fitness", "(", "x", ")", ":", "\n", "# Returns fitness (for use with results.txt or evolve.txt)", "\n", "# weights for [P, R, mAP, F1]@0.5 or [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "    ", "w", "=", "[", "0.0", ",", "0.01", ",", "0.99", ",", "0.00", "]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_one_box": [[959, 973], ["cv2.rectangle", "max", "cv2.rectangle", "cv2.putText", "round", "random.randint", "int", "int", "int", "int", "cv2.getTextSize", "range"], "function", ["None"], ["", "def", "plot_one_box", "(", "x", ",", "img", ",", "color", "=", "None", ",", "label", "=", "None", ",", "line_thickness", "=", "None", ")", ":", "\n", "# Plots one bounding box on image img", "\n", "    ", "tl", "=", "line_thickness", "or", "round", "(", "\n", "0.002", "*", "(", "img", ".", "shape", "[", "0", "]", "+", "img", ".", "shape", "[", "1", "]", ")", "/", "2", ")", "+", "1", "# line thickness", "\n", "color", "=", "color", "or", "[", "random", ".", "randint", "(", "0", ",", "255", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "c1", ",", "c2", "=", "(", "int", "(", "x", "[", "0", "]", ")", ",", "int", "(", "x", "[", "1", "]", ")", ")", ",", "(", "int", "(", "x", "[", "2", "]", ")", ",", "int", "(", "x", "[", "3", "]", ")", ")", "\n", "cv2", ".", "rectangle", "(", "img", ",", "c1", ",", "c2", ",", "color", ",", "thickness", "=", "tl", ")", "\n", "if", "label", ":", "\n", "        ", "tf", "=", "max", "(", "tl", "-", "1", ",", "1", ")", "# font thickness", "\n", "t_size", "=", "cv2", ".", "getTextSize", "(", "label", ",", "0", ",", "fontScale", "=", "tl", "/", "3", ",", "thickness", "=", "tf", ")", "[", "0", "]", "\n", "c2", "=", "c1", "[", "0", "]", "+", "t_size", "[", "0", "]", ",", "c1", "[", "1", "]", "-", "t_size", "[", "1", "]", "-", "3", "\n", "cv2", ".", "rectangle", "(", "img", ",", "c1", ",", "c2", ",", "color", ",", "-", "1", ")", "# filled", "\n", "cv2", ".", "putText", "(", "img", ",", "label", ",", "(", "c1", "[", "0", "]", ",", "c1", "[", "1", "]", "-", "2", ")", ",", "0", ",", "tl", "/", "3", ",", "\n", "[", "225", ",", "255", ",", "255", "]", ",", "thickness", "=", "tf", ",", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_wh_methods": [[975, 993], ["numpy.arange", "numpy.exp", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "plt.figure.tight_layout", "plt.figure.savefig", "torch.sigmoid().numpy", "torch.sigmoid().numpy", "torch.sigmoid", "torch.sigmoid", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "plot_wh_methods", "(", ")", ":", "# from utils.utils import *; plot_wh_methods()", "\n", "# Compares the two methods for width-height anchor multiplication", "\n", "# https://github.com/ultralytics/yolov3/issues/168", "\n", "    ", "x", "=", "np", ".", "arange", "(", "-", "4.0", ",", "4.0", ",", ".1", ")", "\n", "ya", "=", "np", ".", "exp", "(", "x", ")", "\n", "yb", "=", "torch", ".", "sigmoid", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "numpy", "(", ")", "*", "2", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "3", ")", ",", "dpi", "=", "150", ")", "\n", "plt", ".", "plot", "(", "x", ",", "ya", ",", "'.-'", ",", "label", "=", "'yolo method'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "yb", "**", "2", ",", "'.-'", ",", "label", "=", "'^2 power method'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "yb", "**", "2.5", ",", "'.-'", ",", "label", "=", "'^2.5 power method'", ")", "\n", "plt", ".", "xlim", "(", "left", "=", "-", "4", ",", "right", "=", "4", ")", "\n", "plt", ".", "ylim", "(", "bottom", "=", "0", ",", "top", "=", "6", ")", "\n", "plt", ".", "xlabel", "(", "'input'", ")", "\n", "plt", ".", "ylabel", "(", "'output'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "'comparison.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_images": [[995, 1020], ["imgs.cpu().numpy.cpu().numpy", "targets.cpu().numpy.cpu().numpy", "matplotlib.figure", "min", "numpy.ceil", "range", "plt.figure.tight_layout", "plt.figure.savefig", "matplotlib.close", "matplotlib.subplot().imshow", "matplotlib.plot", "matplotlib.axis", "imgs.cpu().numpy.cpu", "targets.cpu().numpy.cpu", "utils.xywh2xyxy", "imgs[].transpose", "matplotlib.title", "matplotlib.subplot", "pathlib.Path", "min", "len"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xywh2xyxy"], ["", "def", "plot_images", "(", "imgs", ",", "targets", ",", "paths", "=", "None", ",", "fname", "=", "'images.png'", ")", ":", "\n", "# Plots training images overlaid with targets", "\n", "    ", "imgs", "=", "imgs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "targets", "=", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# targets = targets[targets[:, 1] == 21]  # plot only one class", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "10", ")", ")", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "imgs", ".", "shape", "# batch size, _, height, width", "\n", "bs", "=", "min", "(", "bs", ",", "16", ")", "# limit plot to 16 images", "\n", "ns", "=", "np", ".", "ceil", "(", "bs", "**", "0.5", ")", "# number of subplots", "\n", "\n", "for", "i", "in", "range", "(", "bs", ")", ":", "\n", "        ", "boxes", "=", "xywh2xyxy", "(", "targets", "[", "targets", "[", ":", ",", "0", "]", "==", "i", ",", "2", ":", "6", "]", ")", ".", "T", "\n", "boxes", "[", "[", "0", ",", "2", "]", "]", "*=", "w", "\n", "boxes", "[", "[", "1", ",", "3", "]", "]", "*=", "h", "\n", "plt", ".", "subplot", "(", "ns", ",", "ns", ",", "i", "+", "1", ")", ".", "imshow", "(", "imgs", "[", "i", "]", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "plt", ".", "plot", "(", "boxes", "[", "[", "0", ",", "2", ",", "2", ",", "0", ",", "0", "]", "]", ",", "boxes", "[", "[", "1", ",", "1", ",", "3", ",", "3", ",", "1", "]", "]", ",", "'.-'", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "if", "paths", "is", "not", "None", ":", "\n", "            ", "s", "=", "Path", "(", "paths", "[", "i", "]", ")", ".", "name", "\n", "plt", ".", "title", "(", "s", "[", ":", "min", "(", "len", "(", "s", ")", ",", "40", ")", "]", ",", "fontdict", "=", "{", "\n", "'size'", ":", "8", "}", ")", "# limit to 40 characters", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "fname", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_test_txt": [[1022, 1039], ["numpy.loadtxt", "utils.xyxy2xywh", "matplotlib.subplots", "ax.hist2d", "ax.set_aspect", "fig.tight_layout", "matplotlib.savefig", "matplotlib.subplots", "ax[].hist", "ax[].hist", "fig.tight_layout", "matplotlib.savefig"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xyxy2xywh"], ["", "def", "plot_test_txt", "(", ")", ":", "# from utils.utils import *; plot_test()", "\n", "# Plot test.txt histograms", "\n", "    ", "x", "=", "np", ".", "loadtxt", "(", "'test.txt'", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "box", "=", "xyxy2xywh", "(", "x", "[", ":", ",", ":", "4", "]", ")", "\n", "cx", ",", "cy", "=", "box", "[", ":", ",", "0", "]", ",", "box", "[", ":", ",", "1", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "ax", ".", "hist2d", "(", "cx", ",", "cy", ",", "bins", "=", "600", ",", "cmax", "=", "10", ",", "cmin", "=", "0", ")", "\n", "ax", ".", "set_aspect", "(", "'equal'", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'hist2d.png'", ",", "dpi", "=", "300", ")", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "2", ",", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "ax", "[", "0", "]", ".", "hist", "(", "cx", ",", "bins", "=", "600", ")", "\n", "ax", "[", "1", "]", ".", "hist", "(", "cy", ",", "bins", "=", "600", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'hist1d.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_targets_txt": [[1041, 1056], ["numpy.loadtxt", "matplotlib.subplots", "ax.ravel.ravel", "range", "fig.tight_layout", "matplotlib.savefig", "ax[].hist", "ax[].legend", "ax[].set_title", "x[].mean", "x[].std"], "function", ["None"], ["", "def", "plot_targets_txt", "(", ")", ":", "# from utils.utils import *; plot_targets_txt()", "\n", "# Plot test.txt histograms", "\n", "    ", "x", "=", "np", ".", "loadtxt", "(", "'targets.txt'", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "x", "=", "x", ".", "T", "\n", "\n", "s", "=", "[", "'x targets'", ",", "'y targets'", ",", "'width targets'", ",", "'height targets'", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "2", ",", "figsize", "=", "(", "8", ",", "8", ")", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "ax", "[", "i", "]", ".", "hist", "(", "x", "[", "i", "]", ",", "bins", "=", "100", ",", "label", "=", "'%.3g +/- %.3g'", "%", "\n", "(", "x", "[", "i", "]", ".", "mean", "(", ")", ",", "x", "[", "i", "]", ".", "std", "(", ")", ")", ")", "\n", "ax", "[", "i", "]", ".", "legend", "(", ")", "\n", "ax", "[", "i", "]", ".", "set_title", "(", "s", "[", "i", "]", ")", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'targets.jpg'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_evolution_results": [[1059, 1078], ["numpy.loadtxt", "utils.fitness", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "enumerate", "plt.figure.tight_layout", "matplotlib.savefig", "hyp.items", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "print", "fitness.min", "fitness.max", "fitness.argmax"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.fitness"], ["", "def", "plot_evolution_results", "(", "hyp", ")", ":", "\n", "# Plot hyperparameter evolution results in evolve.txt", "\n", "    ", "x", "=", "np", ".", "loadtxt", "(", "'evolve.txt'", ",", "ndmin", "=", "2", ")", "\n", "f", "=", "fitness", "(", "x", ")", "\n", "weights", "=", "(", "f", "-", "f", ".", "min", "(", ")", ")", "**", "2", "# for weighted results", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "10", ")", ")", "\n", "matplotlib", ".", "rc", "(", "'font'", ",", "**", "{", "'size'", ":", "8", "}", ")", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "hyp", ".", "items", "(", ")", ")", ":", "\n", "        ", "y", "=", "x", "[", ":", ",", "i", "+", "7", "]", "\n", "# mu = (y * weights).sum() / weights.sum()  # best weighted result", "\n", "mu", "=", "y", "[", "f", ".", "argmax", "(", ")", "]", "# best single result", "\n", "plt", ".", "subplot", "(", "4", ",", "5", ",", "i", "+", "1", ")", "\n", "plt", ".", "plot", "(", "mu", ",", "f", ".", "max", "(", ")", ",", "'o'", ",", "markersize", "=", "10", ")", "\n", "plt", ".", "plot", "(", "y", ",", "f", ",", "'.'", ")", "\n", "plt", ".", "title", "(", "'%s = %.3g'", "%", "(", "k", ",", "mu", ")", ",", "fontdict", "=", "{", "\n", "'size'", ":", "9", "}", ")", "# limit to 40 characters", "\n", "print", "(", "'%15s: %.3g'", "%", "(", "k", ",", "mu", ")", ")", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'evolve.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_results_overlay": [[1081, 1104], ["sorted", "range", "matplotlib.subplots", "ax.ravel.ravel", "range", "fig.tight_layout", "fig.savefig", "glob.glob", "glob.glob", "numpy.loadtxt", "ax[].set_title", "ax[].legend", "f.replace", "min", "ax[].plot", "ax[].set_ylabel"], "function", ["None"], ["", "def", "plot_results_overlay", "(", "start", "=", "0", ",", "stop", "=", "0", ")", ":", "\n", "# Plot training results files 'results*.txt', overlaying train and val losses", "\n", "    ", "s", "=", "[", "'train'", ",", "'train'", ",", "'train'", ",", "'Precision'", ",", "'mAP@0.5'", ",", "\n", "'val'", ",", "'val'", ",", "'val'", ",", "'Recall'", ",", "'F1'", "]", "# legends", "\n", "t", "=", "[", "'GIoU'", ",", "'Objectness'", ",", "'Classification'", ",", "'P-R'", ",", "'mAP-F1'", "]", "# titles", "\n", "for", "f", "in", "sorted", "(", "glob", ".", "glob", "(", "'results*.txt'", ")", "+", "glob", ".", "glob", "(", "'../../Downloads/results*.txt'", ")", ")", ":", "\n", "        ", "results", "=", "np", ".", "loadtxt", "(", "\n", "f", ",", "usecols", "=", "[", "2", ",", "3", ",", "4", ",", "8", ",", "9", ",", "12", ",", "13", ",", "14", ",", "10", ",", "11", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "n", "=", "results", ".", "shape", "[", "1", "]", "# number of rows", "\n", "x", "=", "range", "(", "start", ",", "min", "(", "stop", ",", "n", ")", "if", "stop", "else", "n", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "5", ",", "figsize", "=", "(", "14", ",", "3.5", ")", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "for", "j", "in", "[", "i", ",", "i", "+", "5", "]", ":", "\n", "                ", "y", "=", "results", "[", "j", ",", "x", "]", "\n", "if", "i", "in", "[", "0", ",", "1", ",", "2", "]", ":", "\n", "                    ", "y", "[", "y", "==", "0", "]", "=", "np", ".", "nan", "# dont show zero loss values", "\n", "", "ax", "[", "i", "]", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "label", "=", "s", "[", "j", "]", ")", "\n", "", "ax", "[", "i", "]", ".", "set_title", "(", "t", "[", "i", "]", ")", "\n", "ax", "[", "i", "]", ".", "legend", "(", ")", "\n", "ax", "[", "i", "]", ".", "set_ylabel", "(", "f", ")", "if", "i", "==", "0", "else", "None", "# add filename", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "f", ".", "replace", "(", "'.txt'", ",", "'.png'", ")", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_results": [[1107, 1139], ["matplotlib.subplots", "ax.ravel.ravel", "sorted", "fig.tight_layout", "ax[].legend", "fig.savefig", "os.system", "range", "range", "glob.glob", "glob.glob", "numpy.loadtxt", "ax[].plot", "ax[].set_title", "min", "ax[].get_shared_y_axes().join", "pathlib.Path", "ax[].get_shared_y_axes"], "function", ["None"], ["", "", "def", "plot_results", "(", "start", "=", "0", ",", "stop", "=", "0", ",", "bucket", "=", "''", ",", "id", "=", "(", ")", ")", ":", "\n", "# Plot training results files 'results*.txt'", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "5", ",", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "s", "=", "[", "'GIoU'", ",", "'Objectness'", ",", "'Classification'", ",", "'Precision'", ",", "'Recall'", ",", "\n", "'val GIoU'", ",", "'val Objectness'", ",", "'val Classification'", ",", "'mAP@0.5'", ",", "'F1'", "]", "\n", "if", "bucket", ":", "\n", "        ", "os", ".", "system", "(", "'rm -rf storage.googleapis.com'", ")", "\n", "files", "=", "[", "'https://storage.googleapis.com/%s/results%g.txt'", "%", "\n", "(", "bucket", ",", "x", ")", "for", "x", "in", "id", "]", "\n", "", "else", ":", "\n", "        ", "files", "=", "glob", ".", "glob", "(", "'results*.txt'", ")", "+", "glob", ".", "glob", "(", "'../../Downloads/results*.txt'", ")", "\n", "", "for", "f", "in", "sorted", "(", "files", ")", ":", "\n", "        ", "results", "=", "np", ".", "loadtxt", "(", "\n", "f", ",", "usecols", "=", "[", "2", ",", "3", ",", "4", ",", "8", ",", "9", ",", "12", ",", "13", ",", "14", ",", "10", ",", "11", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "n", "=", "results", ".", "shape", "[", "1", "]", "# number of rows", "\n", "x", "=", "range", "(", "start", ",", "min", "(", "stop", ",", "n", ")", "if", "stop", "else", "n", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "y", "=", "results", "[", "i", ",", "x", "]", "\n", "if", "i", "in", "[", "0", ",", "1", ",", "2", ",", "5", ",", "6", ",", "7", "]", ":", "\n", "                ", "y", "[", "y", "==", "0", "]", "=", "np", ".", "nan", "# dont show zero loss values", "\n", "# y /= y[0]  # normalize", "\n", "", "ax", "[", "i", "]", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "label", "=", "Path", "(", "\n", "f", ")", ".", "stem", ",", "linewidth", "=", "2", ",", "markersize", "=", "8", ")", "\n", "ax", "[", "i", "]", ".", "set_title", "(", "s", "[", "i", "]", ")", "\n", "if", "i", "in", "[", "5", ",", "6", ",", "7", "]", ":", "# share train and val loss y axes", "\n", "                ", "ax", "[", "i", "]", ".", "get_shared_y_axes", "(", ")", ".", "join", "(", "ax", "[", "i", "]", ",", "ax", "[", "i", "-", "5", "]", ")", "\n", "\n", "", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "ax", "[", "1", "]", ".", "legend", "(", ")", "\n", "fig", ".", "savefig", "(", "'results.png'", ",", "dpi", "=", "200", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.__init__": [[45, 69], ["str", "os.path.isdir", "any", "pathlib.Path", "sorted", "os.path.isfile", "len", "len", "datasets.LoadImages.new_video", "glob.glob", "os.path.join", "[].lower", "[].lower", "os.path.splitext", "os.path.splitext"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.new_video"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "img_size", "=", "416", ")", ":", "\n", "        ", "path", "=", "str", "(", "Path", "(", "path", ")", ")", "# os-agnostic", "\n", "files", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "            ", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'*.*'", ")", ")", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "            ", "files", "=", "[", "path", "]", "\n", "\n", "", "images", "=", "[", "x", "for", "x", "in", "files", "if", "os", ".", "path", ".", "splitext", "(", "\n", "x", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "img_formats", "]", "\n", "videos", "=", "[", "x", "for", "x", "in", "files", "if", "os", ".", "path", ".", "splitext", "(", "\n", "x", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "vid_formats", "]", "\n", "nI", ",", "nV", "=", "len", "(", "images", ")", ",", "len", "(", "videos", ")", "\n", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "files", "=", "images", "+", "videos", "\n", "self", ".", "nF", "=", "nI", "+", "nV", "# number of files", "\n", "self", ".", "video_flag", "=", "[", "False", "]", "*", "nI", "+", "[", "True", "]", "*", "nV", "\n", "self", ".", "mode", "=", "'images'", "\n", "if", "any", "(", "videos", ")", ":", "\n", "            ", "self", ".", "new_video", "(", "videos", "[", "0", "]", ")", "# new video", "\n", "", "else", ":", "\n", "            ", "self", ".", "cap", "=", "None", "\n", "", "assert", "self", ".", "nF", ">", "0", ",", "'No images or videos found in '", "+", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.__iter__": [[70, 73], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "0", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.__next__": [[74, 116], ["img[].transpose", "numpy.ascontiguousarray", "datasets.LoadImages.cap.read", "print", "cv2.imread", "datasets.LoadImages.cap.release", "datasets.letterbox", "datasets.LoadImages.new_video", "datasets.LoadImages.cap.read"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.new_video"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", "==", "self", ".", "nF", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "path", "=", "self", ".", "files", "[", "self", ".", "count", "]", "\n", "\n", "if", "self", ".", "video_flag", "[", "self", ".", "count", "]", ":", "\n", "# Read video", "\n", "            ", "self", ".", "mode", "=", "'video'", "\n", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret_val", ":", "\n", "                ", "self", ".", "count", "+=", "1", "\n", "self", ".", "cap", ".", "release", "(", ")", "\n", "if", "self", ".", "count", "==", "self", ".", "nF", ":", "# last video", "\n", "                    ", "raise", "StopIteration", "\n", "", "else", ":", "\n", "                    ", "path", "=", "self", ".", "files", "[", "self", ".", "count", "]", "\n", "self", ".", "new_video", "(", "path", ")", "\n", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "\n", "", "", "self", ".", "frame", "+=", "1", "\n", "print", "(", "'video %g/%g (%g/%g) %s: '", "%", "(", "self", ".", "count", "+", "1", ",", "\n", "self", ".", "nF", ",", "self", ".", "frame", ",", "self", ".", "nframes", ",", "path", ")", ",", "end", "=", "''", ")", "\n", "\n", "", "else", ":", "\n", "# Read image", "\n", "            ", "self", ".", "count", "+=", "1", "\n", "img0", "=", "cv2", ".", "imread", "(", "path", ")", "# BGR", "\n", "if", "img0", "is", "None", ":", "\n", "                ", "return", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "# Padded resize", "\n", "", "", "try", ":", "\n", "            ", "img", "=", "letterbox", "(", "img0", ",", "new_shape", "=", "self", ".", "img_size", ")", "[", "0", "]", "\n", "", "except", "cv2", ".", "error", ":", "\n", "            ", "return", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "# Convert", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "# cv2.imwrite(path + '.letterbox.jpg', 255 * img.transpose((1, 2, 0))[:, :, ::-1])  # save letterbox image", "\n", "return", "path", ",", "img", ",", "img0", ",", "self", ".", "cap", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.new_video": [[117, 121], ["cv2.VideoCapture", "int", "datasets.LoadImages.cap.get"], "methods", ["None"], ["", "def", "new_video", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "frame", "=", "0", "\n", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "path", ")", "\n", "self", ".", "nframes", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImages.__len__": [[122, 124], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "nF", "# number of files", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadWebcam.__init__": [[127, 147], ["cv2.VideoCapture", "datasets.LoadWebcam.cap.set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pipe", "=", "0", ",", "img_size", "=", "416", ")", ":", "\n", "        ", "self", ".", "img_size", "=", "img_size", "\n", "\n", "if", "pipe", "==", "'0'", ":", "\n", "            ", "pipe", "=", "0", "# local camera", "\n", "# pipe = 'rtsp://192.168.1.64/1'  # IP camera", "\n", "# pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login", "\n", "# pipe = 'rtsp://170.93.143.139/rtplive/470011e600ef003a004ee33696235daa'  # IP traffic camera", "\n", "# pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera", "\n", "\n", "# https://answers.opencv.org/question/215996/changing-gstreamer-pipeline-to-opencv-in-pythonsolved/", "\n", "# pipe = '\"rtspsrc location=\"rtsp://username:password@192.168.1.64/1\" latency=10 ! appsink'  # GStreamer", "\n", "\n", "# https://answers.opencv.org/question/200787/video-acceleration-gstremer-pipeline-in-videocapture/", "\n", "# https://stackoverflow.com/questions/54095699/install-gstreamer-support-for-opencv-python-package  # install help", "\n", "# pipe = \"rtspsrc location=rtsp://root:root@192.168.0.91:554/axis-media/media.amp?videocodec=h264&resolution=3840x2160 protocols=GST_RTSP_LOWER_TRANS_TCP ! rtph264depay ! queue ! vaapih264dec ! videoconvert ! appsink\"  # GStreamer", "\n", "\n", "", "self", ".", "pipe", "=", "pipe", "\n", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "pipe", ")", "# video capture object", "\n", "self", ".", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_BUFFERSIZE", ",", "3", ")", "# set buffer size", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadWebcam.__iter__": [[148, 151], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "-", "1", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadWebcam.__next__": [[152, 186], ["print", "img[].transpose", "numpy.ascontiguousarray", "cv2.waitKey", "ord", "datasets.LoadWebcam.cap.release", "cv2.destroyAllWindows", "datasets.LoadWebcam.cap.read", "cv2.flip", "datasets.letterbox", "datasets.LoadWebcam.cap.grab", "datasets.LoadWebcam.cap.retrieve"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "+=", "1", "\n", "if", "cv2", ".", "waitKey", "(", "1", ")", "==", "ord", "(", "'q'", ")", ":", "# q to quit", "\n", "            ", "self", ".", "cap", ".", "release", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Read frame", "\n", "", "if", "self", ".", "pipe", "==", "0", ":", "# local camera", "\n", "            ", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "img0", "=", "cv2", ".", "flip", "(", "img0", ",", "1", ")", "# flip left-right", "\n", "", "else", ":", "# IP camera", "\n", "            ", "n", "=", "0", "\n", "while", "True", ":", "\n", "                ", "n", "+=", "1", "\n", "self", ".", "cap", ".", "grab", "(", ")", "\n", "if", "n", "%", "30", "==", "0", ":", "# skip frames", "\n", "                    ", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "retrieve", "(", ")", "\n", "if", "ret_val", ":", "\n", "                        ", "break", "\n", "\n", "# Print", "\n", "", "", "", "", "assert", "ret_val", ",", "'Camera Error %s'", "%", "self", ".", "pipe", "\n", "img_path", "=", "'webcam.jpg'", "\n", "print", "(", "'webcam %g: '", "%", "self", ".", "count", ",", "end", "=", "''", ")", "\n", "\n", "# Padded resize", "\n", "img", "=", "letterbox", "(", "img0", ",", "new_shape", "=", "self", ".", "img_size", ")", "[", "0", "]", "\n", "\n", "# Convert", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "img_path", ",", "img", ",", "img0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadWebcam.__len__": [[187, 189], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadStreams.__init__": [[192, 227], ["os.path.isfile", "len", "enumerate", "print", "numpy.stack", "print", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "int", "cv2.VideoCapture.read", "threading.Thread", "print", "threading.Thread.start", "print", "open", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "x.strip", "numpy.unique", "f.read().splitlines", "len", "datasets.letterbox", "x.strip", "f.read"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox"], ["    ", "def", "__init__", "(", "self", ",", "sources", "=", "'streams.txt'", ",", "img_size", "=", "416", ")", ":", "\n", "        ", "self", ".", "mode", "=", "'images'", "\n", "self", ".", "img_size", "=", "img_size", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "sources", ")", ":", "\n", "            ", "with", "open", "(", "sources", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "sources", "=", "[", "x", ".", "strip", "(", ")", "\n", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "len", "(", "x", ".", "strip", "(", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "sources", "=", "[", "sources", "]", "\n", "\n", "", "n", "=", "len", "(", "sources", ")", "\n", "self", ".", "imgs", "=", "[", "None", "]", "*", "n", "\n", "self", ".", "sources", "=", "sources", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "sources", ")", ":", "\n", "# Start the thread to read frames from the video stream", "\n", "            ", "print", "(", "'%g/%g: %s... '", "%", "(", "i", "+", "1", ",", "n", ",", "s", ")", ",", "end", "=", "''", ")", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "0", "if", "s", "==", "'0'", "else", "s", ")", "\n", "assert", "cap", ".", "isOpened", "(", ")", ",", "'Failed to open %s'", "%", "s", "\n", "w", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "h", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "%", "100", "\n", "_", ",", "self", ".", "imgs", "[", "i", "]", "=", "cap", ".", "read", "(", ")", "# guarantee first frame", "\n", "thread", "=", "Thread", "(", "target", "=", "self", ".", "update", ",", "args", "=", "(", "[", "i", ",", "cap", "]", ")", ",", "daemon", "=", "True", ")", "\n", "print", "(", "' success (%gx%g at %.2f FPS).'", "%", "(", "w", ",", "h", ",", "fps", ")", ")", "\n", "thread", ".", "start", "(", ")", "\n", "", "print", "(", "''", ")", "# newline", "\n", "\n", "# check for common shapes", "\n", "s", "=", "np", ".", "stack", "(", "[", "letterbox", "(", "x", ",", "new_shape", "=", "self", ".", "img_size", ")", "[", "\n", "0", "]", ".", "shape", "for", "x", "in", "self", ".", "imgs", "]", ",", "0", ")", "# inference shapes", "\n", "# rect inference if all shapes equal", "\n", "self", ".", "rect", "=", "np", ".", "unique", "(", "s", ",", "axis", "=", "0", ")", ".", "shape", "[", "0", "]", "==", "1", "\n", "if", "not", "self", ".", "rect", ":", "\n", "            ", "print", "(", "'WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadStreams.update": [[228, 239], ["cap.isOpened", "cap.grab", "time.sleep", "cap.retrieve"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "index", ",", "cap", ")", ":", "\n", "# Read next stream frame in a daemon thread", "\n", "        ", "n", "=", "0", "\n", "while", "cap", ".", "isOpened", "(", ")", ":", "\n", "            ", "n", "+=", "1", "\n", "# _, self.imgs[index] = cap.read()", "\n", "cap", ".", "grab", "(", ")", "\n", "if", "n", "==", "4", ":", "# read every 4th frame", "\n", "                ", "_", ",", "self", ".", "imgs", "[", "index", "]", "=", "cap", ".", "retrieve", "(", ")", "\n", "n", "=", "0", "\n", "", "time", ".", "sleep", "(", "0.01", ")", "# wait time", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadStreams.__iter__": [[240, 243], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "-", "1", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadStreams.__next__": [[244, 264], ["datasets.LoadStreams.imgs.copy", "numpy.stack", "img[].transpose", "numpy.ascontiguousarray", "cv2.waitKey", "ord", "cv2.destroyAllWindows", "datasets.letterbox"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "+=", "1", "\n", "img0", "=", "self", ".", "imgs", ".", "copy", "(", ")", "\n", "if", "cv2", ".", "waitKey", "(", "1", ")", "==", "ord", "(", "'q'", ")", ":", "# q to quit", "\n", "            ", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Letterbox", "\n", "", "img", "=", "[", "letterbox", "(", "x", ",", "new_shape", "=", "self", ".", "img_size", ",", "auto", "=", "self", ".", "rect", ",", "\n", "interp", "=", "cv2", ".", "INTER_LINEAR", ")", "[", "0", "]", "for", "x", "in", "img0", "]", "\n", "\n", "# Stack", "\n", "img", "=", "np", ".", "stack", "(", "img", ",", "0", ")", "\n", "\n", "# Convert", "\n", "# BGR to RGB, to bsx3x416x416", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "self", ".", "sources", ",", "img", ",", "img0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadStreams.__len__": [[265, 267], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "# 1E12 frames = 32 streams at 30 FPS for 30 years", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImagesAndLabels.__init__": [[270, 428], ["str", "os.path.isfile", "len", "numpy.floor().astype", "pathlib.Path", "open", "x.replace().replace", "str.replace", "numpy.array", "ar.argsort", "range", "tqdm.tqdm.tqdm", "enumerate", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm", "x.replace", "numpy.floor", "numpy.ceil().astype", "range", "datasets.load_image", "f.read().splitlines", "x.replace", "os.path.splitext", "open", "numpy.savetxt", "ari.min", "ari.max", "numpy.zeros", "len", "io.imread", "[].lower", "numpy.arange", "x.split", "len", "datasets.exif_size", "numpy.ceil", "open", "numpy.array", "pathlib.Path", "cv2.imread", "enumerate", "print", "f.read", "f.read().splitlines", "PIL.Image.open", "tqdm.tqdm.tqdm", "datasets.create_folder", "os.makedirs", "str", "b[].max", "tell.yolov3.utils.utils.xywh2xyxy().ravel().astype", "numpy.clip", "numpy.clip", "cv2.imwrite", "x.split", "numpy.unique", "open", "f.write", "os.path.exists", "os.makedirs", "os.path.splitext", "f.read", "numpy.array", "f.read().splitlines", "tell.yolov3.utils.utils.xywh2xyxy().ravel", "pathlib.Path", "pathlib.Path", "f.read", "tell.yolov3.utils.utils.xywh2xyxy", "tell.yolov3.utils.utils.xywh2xyxy().ravel().astype.reshape"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_image", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.exif_size", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.create_folder", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xywh2xyxy"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "img_size", "=", "416", ",", "batch_size", "=", "16", ",", "augment", "=", "False", ",", "hyp", "=", "None", ",", "rect", "=", "False", ",", "image_weights", "=", "False", ",", "\n", "cache_labels", "=", "True", ",", "cache_images", "=", "False", ",", "single_cls", "=", "False", ")", ":", "\n", "        ", "path", "=", "str", "(", "Path", "(", "path", ")", ")", "# os-agnostic", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "\n", "path", ")", ",", "'File not found %s. See %s'", "%", "(", "path", ",", "help_url", ")", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "self", ".", "img_files", "=", "[", "x", ".", "replace", "(", "'/'", ",", "os", ".", "sep", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "# os-agnostic", "\n", "if", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "img_formats", "]", "\n", "\n", "", "n", "=", "len", "(", "self", ".", "img_files", ")", "\n", "assert", "n", ">", "0", ",", "'No images found in %s. See %s'", "%", "(", "path", ",", "help_url", ")", "\n", "bi", "=", "np", ".", "floor", "(", "np", ".", "arange", "(", "n", ")", "/", "batch_size", ")", ".", "astype", "(", "np", ".", "int", ")", "# batch index", "\n", "nb", "=", "bi", "[", "-", "1", "]", "+", "1", "# number of batches", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "batch", "=", "bi", "# batch index of image", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "augment", "=", "augment", "\n", "self", ".", "hyp", "=", "hyp", "\n", "self", ".", "image_weights", "=", "image_weights", "\n", "self", ".", "rect", "=", "False", "if", "image_weights", "else", "rect", "\n", "\n", "# Define labels", "\n", "self", ".", "label_files", "=", "[", "x", ".", "replace", "(", "'images'", ",", "'labels'", ")", ".", "replace", "(", "os", ".", "path", ".", "splitext", "(", "x", ")", "[", "-", "1", "]", ",", "'.txt'", ")", "\n", "for", "x", "in", "self", ".", "img_files", "]", "\n", "\n", "# Rectangular Training  https://github.com/ultralytics/yolov3/issues/232", "\n", "if", "self", ".", "rect", ":", "\n", "# Read image shapes (wh)", "\n", "            ", "sp", "=", "path", ".", "replace", "(", "'.txt'", ",", "'.shapes'", ")", "# shapefile path", "\n", "try", ":", "\n", "                ", "with", "open", "(", "sp", ",", "'r'", ")", "as", "f", ":", "# read existing shapefile", "\n", "                    ", "s", "=", "[", "x", ".", "split", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", "\n", "assert", "len", "(", "s", ")", "==", "n", ",", "'Shapefile out of sync'", "\n", "", "", "except", ":", "\n", "                ", "s", "=", "[", "exif_size", "(", "Image", ".", "open", "(", "f", ")", ")", "for", "f", "in", "tqdm", "(", "\n", "self", ".", "img_files", ",", "desc", "=", "'Reading image shapes'", ")", "]", "\n", "np", ".", "savetxt", "(", "sp", ",", "s", ",", "fmt", "=", "'%g'", ")", "# overwrites existing (if any)", "\n", "\n", "# Sort by aspect ratio", "\n", "", "s", "=", "np", ".", "array", "(", "s", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "ar", "=", "s", "[", ":", ",", "1", "]", "/", "s", "[", ":", ",", "0", "]", "# aspect ratio", "\n", "i", "=", "ar", ".", "argsort", "(", ")", "\n", "self", ".", "img_files", "=", "[", "self", ".", "img_files", "[", "i", "]", "for", "i", "in", "i", "]", "\n", "self", ".", "label_files", "=", "[", "self", ".", "label_files", "[", "i", "]", "for", "i", "in", "i", "]", "\n", "self", ".", "shapes", "=", "s", "[", "i", "]", "# wh", "\n", "ar", "=", "ar", "[", "i", "]", "\n", "\n", "# Set training image shapes", "\n", "shapes", "=", "[", "[", "1", ",", "1", "]", "]", "*", "nb", "\n", "for", "i", "in", "range", "(", "nb", ")", ":", "\n", "                ", "ari", "=", "ar", "[", "bi", "==", "i", "]", "\n", "mini", ",", "maxi", "=", "ari", ".", "min", "(", ")", ",", "ari", ".", "max", "(", ")", "\n", "if", "maxi", "<", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "maxi", ",", "1", "]", "\n", "", "elif", "mini", ">", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "1", ",", "1", "/", "mini", "]", "\n", "\n", "", "", "self", ".", "batch_shapes", "=", "np", ".", "ceil", "(", "\n", "np", ".", "array", "(", "shapes", ")", "*", "img_size", "/", "32.", ")", ".", "astype", "(", "np", ".", "int", ")", "*", "32", "\n", "\n", "# Preload labels (required for weighted CE training)", "\n", "", "self", ".", "imgs", "=", "[", "None", "]", "*", "n", "\n", "self", ".", "labels", "=", "[", "None", "]", "*", "n", "\n", "if", "cache_labels", "or", "image_weights", ":", "# cache labels for faster training", "\n", "            ", "self", ".", "labels", "=", "[", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ")", "]", "*", "n", "\n", "extract_bounding_boxes", "=", "False", "\n", "create_datasubset", "=", "False", "\n", "pbar", "=", "tqdm", "(", "self", ".", "label_files", ",", "desc", "=", "'Caching labels'", ")", "\n", "# number missing, found, empty, datasubset, duplicate", "\n", "nm", ",", "nf", ",", "ne", ",", "ns", ",", "nd", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "i", ",", "file", "in", "enumerate", "(", "pbar", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "l", "=", "np", ".", "array", "(", "\n", "[", "x", ".", "split", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "except", ":", "\n", "# print('missing labels for image %s' % self.img_files[i])  # file missing", "\n", "                    ", "nm", "+=", "1", "\n", "continue", "\n", "\n", "", "if", "l", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "assert", "l", ".", "shape", "[", "1", "]", "==", "5", ",", "'> 5 label columns: %s'", "%", "file", "\n", "assert", "(", "l", ">=", "0", ")", ".", "all", "(", ")", ",", "'negative labels: %s'", "%", "file", "\n", "assert", "(", "l", "[", ":", ",", "1", ":", "]", "<=", "1", ")", ".", "all", "(", "\n", ")", ",", "'non-normalized or out of bounds coordinate labels: %s'", "%", "file", "\n", "if", "np", ".", "unique", "(", "l", ",", "axis", "=", "0", ")", ".", "shape", "[", "0", "]", "<", "l", ".", "shape", "[", "0", "]", ":", "# duplicate rows", "\n", "# print('WARNING: duplicate rows in %s' % self.label_files[i])  # duplicate rows", "\n", "                        ", "nd", "+=", "1", "\n", "", "if", "single_cls", ":", "\n", "                        ", "l", "[", ":", ",", "0", "]", "=", "0", "# force dataset into single-class mode", "\n", "", "self", ".", "labels", "[", "i", "]", "=", "l", "\n", "nf", "+=", "1", "# file found", "\n", "\n", "# Create subdataset (a smaller dataset)", "\n", "if", "create_datasubset", "and", "ns", "<", "1E4", ":", "\n", "                        ", "if", "ns", "==", "0", ":", "\n", "                            ", "create_folder", "(", "path", "=", "'./datasubset'", ")", "\n", "os", ".", "makedirs", "(", "'./datasubset/images'", ")", "\n", "", "exclude_classes", "=", "43", "\n", "if", "exclude_classes", "not", "in", "l", "[", ":", ",", "0", "]", ":", "\n", "                            ", "ns", "+=", "1", "\n", "# shutil.copy(src=self.img_files[i], dst='./datasubset/images/')  # copy image", "\n", "with", "open", "(", "'./datasubset/images.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "                                ", "f", ".", "write", "(", "self", ".", "img_files", "[", "i", "]", "+", "'\\n'", ")", "\n", "\n", "# Extract object detection boxes for a second stage classifier", "\n", "", "", "", "if", "extract_bounding_boxes", ":", "\n", "                        ", "p", "=", "Path", "(", "self", ".", "img_files", "[", "i", "]", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "str", "(", "p", ")", ")", "\n", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "for", "j", ",", "x", "in", "enumerate", "(", "l", ")", ":", "\n", "                            ", "f", "=", "'%s%sclassifier%s%g_%g_%s'", "%", "(", "\n", "p", ".", "parent", ".", "parent", ",", "os", ".", "sep", ",", "os", ".", "sep", ",", "x", "[", "0", "]", ",", "j", ",", "p", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "Path", "(", "f", ")", ".", "parent", ")", ":", "\n", "# make new output folder", "\n", "                                ", "os", ".", "makedirs", "(", "Path", "(", "f", ")", ".", "parent", ")", "\n", "\n", "", "b", "=", "x", "[", "1", ":", "]", "*", "[", "w", ",", "h", ",", "w", ",", "h", "]", "# box", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", ".", "max", "(", ")", "# rectangle to square", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", "*", "1.3", "+", "30", "# pad", "\n", "b", "=", "xywh2xyxy", "(", "b", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", ")", ".", "ravel", "(", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# clip boxes outside of image", "\n", "b", "[", "[", "0", ",", "2", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "0", ",", "2", "]", "]", ",", "0", ",", "w", ")", "\n", "b", "[", "[", "1", ",", "3", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "1", ",", "3", "]", "]", ",", "0", ",", "h", ")", "\n", "assert", "cv2", ".", "imwrite", "(", "\n", "f", ",", "img", "[", "b", "[", "1", "]", ":", "b", "[", "3", "]", ",", "b", "[", "0", "]", ":", "b", "[", "2", "]", "]", ")", ",", "'Failure extracting classifier boxes'", "\n", "", "", "", "else", ":", "\n", "# print('empty labels for image %s' % self.img_files[i])  # file empty", "\n", "                    ", "ne", "+=", "1", "\n", "# os.system(\"rm '%s' '%s'\" % (self.img_files[i], self.label_files[i]))  # remove", "\n", "\n", "", "pbar", ".", "desc", "=", "'Caching labels (%g found, %g missing, %g empty, %g duplicate, for %g images)'", "%", "(", "\n", "nf", ",", "nm", ",", "ne", ",", "nd", ",", "n", ")", "\n", "", "assert", "nf", ">", "0", ",", "'No labels found. See %s'", "%", "help_url", "\n", "\n", "# Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)", "\n", "", "if", "cache_images", ":", "# if training", "\n", "            ", "gb", "=", "0", "# Gigabytes of cached images", "\n", "pbar", "=", "tqdm", "(", "range", "(", "len", "(", "self", ".", "img_files", ")", ")", ",", "desc", "=", "'Caching images'", ")", "\n", "self", ".", "img_hw0", ",", "self", ".", "img_hw", "=", "[", "None", "]", "*", "n", ",", "[", "None", "]", "*", "n", "\n", "for", "i", "in", "pbar", ":", "# max 10k images", "\n", "                ", "self", ".", "imgs", "[", "i", "]", ",", "self", ".", "img_hw0", "[", "i", "]", ",", "self", ".", "img_hw", "[", "i", "]", "=", "load_image", "(", "\n", "self", ",", "i", ")", "# img, hw_original, hw_resized", "\n", "gb", "+=", "self", ".", "imgs", "[", "i", "]", ".", "nbytes", "\n", "pbar", ".", "desc", "=", "'Caching images (%.1fGB)'", "%", "(", "gb", "/", "1E9", ")", "\n", "\n", "# Detect corrupted images https://medium.com/joelthchao/programmatically-detect-corrupted-image-8c1b2006c3d3", "\n", "", "", "detect_corrupted_images", "=", "False", "\n", "if", "detect_corrupted_images", ":", "\n", "            ", "from", "skimage", "import", "io", "# conda install -c conda-forge scikit-image", "\n", "for", "file", "in", "tqdm", "(", "self", ".", "img_files", ",", "desc", "=", "'Detecting corrupted images'", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "_", "=", "io", ".", "imread", "(", "file", ")", "\n", "", "except", ":", "\n", "                    ", "print", "(", "'Corrupted image detected: %s'", "%", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImagesAndLabels.__len__": [[429, 431], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImagesAndLabels.__getitem__": [[438, 537], ["len", "torch.zeros", "img[].transpose", "numpy.ascontiguousarray", "datasets.load_mosaic", "datasets.load_image", "datasets.letterbox", "os.path.isfile", "datasets.augment_hsv", "tell.yolov3.utils.utils.xyxy2xywh", "torch.from_numpy", "torch.from_numpy", "datasets.random_affine", "numpy.fliplr", "numpy.flipud", "numpy.array.copy", "random.random", "random.random", "open", "numpy.array", "numpy.array.split", "f.read().splitlines", "f.read"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_mosaic", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_image", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.augment_hsv", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.xyxy2xywh", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.random_affine"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "image_weights", ":", "\n", "            ", "index", "=", "self", ".", "indices", "[", "index", "]", "\n", "\n", "", "img_path", "=", "self", ".", "img_files", "[", "index", "]", "\n", "label_path", "=", "self", ".", "label_files", "[", "index", "]", "\n", "\n", "hyp", "=", "self", ".", "hyp", "\n", "# load 4 images at a time into a mosaic (only during training)", "\n", "mosaic", "=", "True", "and", "self", ".", "augment", "\n", "if", "mosaic", ":", "\n", "# Load mosaic", "\n", "            ", "img", ",", "labels", "=", "load_mosaic", "(", "self", ",", "index", ")", "\n", "shapes", "=", "None", "\n", "\n", "", "else", ":", "\n", "# Load image", "\n", "            ", "img", ",", "(", "h0", ",", "w0", ")", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# Letterbox", "\n", "# final letterboxed shape", "\n", "shape", "=", "self", ".", "batch_shapes", "[", "self", ".", "batch", "[", "index", "]", "\n", "]", "if", "self", ".", "rect", "else", "self", ".", "img_size", "\n", "img", ",", "ratio", ",", "pad", "=", "letterbox", "(", "\n", "img", ",", "shape", ",", "auto", "=", "False", ",", "scaleup", "=", "self", ".", "augment", ")", "\n", "# for COCO mAP rescaling", "\n", "shapes", "=", "(", "h0", ",", "w0", ")", ",", "(", "(", "h", "/", "h0", ",", "w", "/", "w0", ")", ",", "pad", ")", "\n", "\n", "# Load labels", "\n", "labels", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "isfile", "(", "label_path", ")", ":", "\n", "                ", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "if", "x", "is", "None", ":", "# labels not preloaded", "\n", "                    ", "with", "open", "(", "label_path", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "x", "=", "np", ".", "array", "(", "\n", "[", "x", ".", "split", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "", "if", "x", ".", "size", ">", "0", ":", "\n", "# Normalized xywh to pixel xyxy format", "\n", "                    ", "labels", "=", "x", ".", "copy", "(", ")", "\n", "labels", "[", ":", ",", "1", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "# pad width", "\n", "labels", "[", ":", ",", "2", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "# pad height", "\n", "labels", "[", ":", ",", "3", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "\n", "labels", "[", ":", ",", "4", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "\n", "\n", "", "", "", "if", "self", ".", "augment", ":", "\n", "# Augment imagespace", "\n", "            ", "if", "not", "mosaic", ":", "\n", "                ", "img", ",", "labels", "=", "random_affine", "(", "img", ",", "labels", ",", "\n", "degrees", "=", "hyp", "[", "'degrees'", "]", ",", "\n", "translate", "=", "hyp", "[", "'translate'", "]", ",", "\n", "scale", "=", "hyp", "[", "'scale'", "]", ",", "\n", "shear", "=", "hyp", "[", "'shear'", "]", ")", "\n", "\n", "# Augment colorspace", "\n", "", "augment_hsv", "(", "img", ",", "hgain", "=", "hyp", "[", "'hsv_h'", "]", ",", "\n", "sgain", "=", "hyp", "[", "'hsv_s'", "]", ",", "vgain", "=", "hyp", "[", "'hsv_v'", "]", ")", "\n", "\n", "# Apply cutouts", "\n", "# if random.random() < 0.9:", "\n", "#     labels = cutout(img, labels)", "\n", "\n", "", "nL", "=", "len", "(", "labels", ")", "# number of labels", "\n", "if", "nL", ":", "\n", "# convert xyxy to xywh", "\n", "            ", "labels", "[", ":", ",", "1", ":", "5", "]", "=", "xyxy2xywh", "(", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "\n", "\n", "# Normalize coordinates 0 - 1", "\n", "labels", "[", ":", ",", "[", "2", ",", "4", "]", "]", "/=", "img", ".", "shape", "[", "0", "]", "# height", "\n", "labels", "[", ":", ",", "[", "1", ",", "3", "]", "]", "/=", "img", ".", "shape", "[", "1", "]", "# width", "\n", "\n", "", "if", "self", ".", "augment", ":", "\n", "# random left-right flip", "\n", "            ", "lr_flip", "=", "True", "\n", "if", "lr_flip", "and", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "img", "=", "np", ".", "fliplr", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "1", "]", "=", "1", "-", "labels", "[", ":", ",", "1", "]", "\n", "\n", "# random up-down flip", "\n", "", "", "ud_flip", "=", "False", "\n", "if", "ud_flip", "and", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "img", "=", "np", ".", "flipud", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "2", "]", "=", "1", "-", "labels", "[", ":", ",", "2", "]", "\n", "\n", "", "", "", "labels_out", "=", "torch", ".", "zeros", "(", "(", "nL", ",", "6", ")", ")", "\n", "if", "nL", ":", "\n", "            ", "labels_out", "[", ":", ",", "1", ":", "]", "=", "torch", ".", "from_numpy", "(", "labels", ")", "\n", "\n", "# Convert", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "img", ")", ",", "labels_out", ",", "img_path", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.LoadImagesAndLabels.collate_fn": [[538, 544], ["zip", "enumerate", "torch.stack", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "img", ",", "label", ",", "path", ",", "shapes", "=", "zip", "(", "*", "batch", ")", "# transposed", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "l", "[", ":", ",", "0", "]", "=", "i", "# add target image index for build_targets()", "\n", "", "return", "torch", ".", "stack", "(", "img", ",", "0", ")", ",", "torch", ".", "cat", "(", "label", ",", "0", ")", ",", "path", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.exif_size": [[29, 42], ["dict", "img._getexif().items", "img._getexif"], "function", ["None"], ["", "", "def", "exif_size", "(", "img", ")", ":", "\n", "# Returns exif-corrected PIL size", "\n", "    ", "s", "=", "img", ".", "size", "# (width, height)", "\n", "try", ":", "\n", "        ", "rotation", "=", "dict", "(", "img", ".", "_getexif", "(", ")", ".", "items", "(", ")", ")", "[", "orientation", "]", "\n", "if", "rotation", "==", "6", ":", "# rotation 270", "\n", "            ", "s", "=", "(", "s", "[", "1", "]", ",", "s", "[", "0", "]", ")", "\n", "", "elif", "rotation", "==", "8", ":", "# rotation 90", "\n", "            ", "s", "=", "(", "s", "[", "1", "]", ",", "s", "[", "0", "]", ")", "\n", "", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_image": [[546, 565], ["cv2.imread", "max", "cv2.resize", "int", "int"], "function", ["None"], ["", "", "def", "load_image", "(", "self", ",", "index", ")", ":", "\n", "# loads 1 image from dataset, returns img, original hw, resized hw", "\n", "    ", "img", "=", "self", ".", "imgs", "[", "index", "]", "\n", "if", "img", "is", "None", ":", "# not cached", "\n", "        ", "img_path", "=", "self", ".", "img_files", "[", "index", "]", "\n", "img", "=", "cv2", ".", "imread", "(", "img_path", ")", "# BGR", "\n", "assert", "img", "is", "not", "None", ",", "'Image Not Found '", "+", "img_path", "\n", "h0", ",", "w0", "=", "img", ".", "shape", "[", ":", "2", "]", "# orig hw", "\n", "r", "=", "self", ".", "img_size", "/", "max", "(", "h0", ",", "w0", ")", "# resize image to img_size", "\n", "# always resize down, only resize up if training with augmentation", "\n", "if", "r", "<", "1", "or", "(", "self", ".", "augment", "and", "(", "r", "!=", "1", ")", ")", ":", "\n", "# LINEAR for training, AREA for testing", "\n", "            ", "interp", "=", "cv2", ".", "INTER_LINEAR", "if", "self", ".", "augment", "else", "cv2", ".", "INTER_AREA", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "int", "(", "w0", "*", "r", ")", ",", "int", "(", "h0", "*", "r", ")", ")", ",", "\n", "interpolation", "=", "interp", ")", "\n", "", "return", "img", ",", "(", "h0", ",", "w0", ")", ",", "img", ".", "shape", "[", ":", "2", "]", "# img, hw_original, hw_resized", "\n", "", "else", ":", "\n", "# img, hw_original, hw_resized", "\n", "        ", "return", "self", ".", "imgs", "[", "index", "]", ",", "self", ".", "img_hw0", "[", "index", "]", ",", "self", ".", "img_hw", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.augment_hsv": [[567, 574], ["numpy.clip", "cv2.cvtColor", "numpy.random.uniform", "cv2.cvtColor"], "function", ["None"], ["", "", "def", "augment_hsv", "(", "img", ",", "hgain", "=", "0.5", ",", "sgain", "=", "0.5", ",", "vgain", "=", "0.5", ")", ":", "\n", "    ", "x", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "3", ")", "*", "[", "hgain", ",", "sgain", ",", "vgain", "]", "+", "1", "# random gains", "\n", "img_hsv", "=", "(", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2HSV", ")", "\n", "*", "x", ")", ".", "clip", "(", "None", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "# inplace hue clip (0 - 179 deg)", "\n", "np", ".", "clip", "(", "img_hsv", "[", ":", ",", ":", ",", "0", "]", ",", "None", ",", "179", ",", "out", "=", "img_hsv", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "cv2", ".", "cvtColor", "(", "img_hsv", ",", "cv2", ".", "COLOR_HSV2BGR", ",", "dst", "=", "img", ")", "# no return needed", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_mosaic": [[576, 651], ["enumerate", "len", "datasets.random_affine", "int", "numpy.zeros", "datasets.load_image", "os.path.isfile", "numpy.concatenate", "numpy.clip", "random.uniform", "range", "random.randint", "np.concatenate.append", "range", "max", "max", "np.array.copy", "numpy.zeros", "len", "max", "min", "min", "open", "numpy.array", "max", "min", "max", "min", "min", "min", "min", "min", "np.array.split", "f.read().splitlines", "f.read"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.random_affine", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.load_image"], ["", "def", "load_mosaic", "(", "self", ",", "index", ")", ":", "\n", "# loads images in a mosaic", "\n", "\n", "    ", "labels4", "=", "[", "]", "\n", "s", "=", "self", ".", "img_size", "\n", "xc", ",", "yc", "=", "[", "int", "(", "random", ".", "uniform", "(", "s", "*", "0.5", ",", "s", "*", "1.5", ")", ")", "\n", "for", "_", "in", "range", "(", "2", ")", "]", "# mosaic center x, y", "\n", "img4", "=", "np", ".", "zeros", "(", "(", "s", "*", "2", ",", "s", "*", "2", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "+", "128", "# base image with 4 tiles", "\n", "# 3 additional image indices", "\n", "indices", "=", "[", "index", "]", "+", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "labels", ")", "-", "1", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "indices", ")", ":", "\n", "# Load image", "\n", "        ", "img", ",", "_", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# place img in img4", "\n", "if", "i", "==", "0", ":", "# top left", "\n", "# xmin, ymin, xmax, ymax (large image)", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "max", "(", "xc", "-", "w", ",", "0", ")", ",", "max", "(", "yc", "-", "h", ",", "0", ")", ",", "xc", ",", "yc", "\n", "# xmin, ymin, xmax, ymax (small image)", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "w", "-", "(", "x2a", "-", "x1a", ")", ",", "h", "-", "(", "y2a", "-", "y1a", ")", ",", "w", ",", "h", "\n", "", "elif", "i", "==", "1", ":", "# top right", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "xc", ",", "max", "(", "yc", "-", "h", ",", "0", ")", ",", "min", "(", "xc", "+", "w", ",", "s", "*", "2", ")", ",", "yc", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "0", ",", "h", "-", "(", "y2a", "-", "y1a", ")", ",", "min", "(", "w", ",", "x2a", "-", "x1a", ")", ",", "h", "\n", "", "elif", "i", "==", "2", ":", "# bottom left", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "max", "(", "xc", "-", "w", ",", "0", ")", ",", "yc", ",", "xc", ",", "min", "(", "s", "*", "2", ",", "yc", "+", "h", ")", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "w", "-", "(", "x2a", "-", "x1a", ")", ",", "0", ",", "max", "(", "xc", ",", "w", ")", ",", "min", "(", "y2a", "-", "y1a", ",", "h", ")", "\n", "", "elif", "i", "==", "3", ":", "# bottom right", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "xc", ",", "yc", ",", "min", "(", "xc", "+", "w", ",", "s", "*", "2", ")", ",", "min", "(", "s", "*", "2", ",", "yc", "+", "h", ")", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "0", ",", "0", ",", "min", "(", "w", ",", "x2a", "-", "x1a", ")", ",", "min", "(", "y2a", "-", "y1a", ",", "h", ")", "\n", "\n", "# img4[ymin:ymax, xmin:xmax]", "\n", "", "img4", "[", "y1a", ":", "y2a", ",", "x1a", ":", "x2a", "]", "=", "img", "[", "y1b", ":", "y2b", ",", "x1b", ":", "x2b", "]", "\n", "padw", "=", "x1a", "-", "x1b", "\n", "padh", "=", "y1a", "-", "y1b", "\n", "\n", "# Load labels", "\n", "label_path", "=", "self", ".", "label_files", "[", "index", "]", "\n", "if", "os", ".", "path", ".", "isfile", "(", "label_path", ")", ":", "\n", "            ", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "if", "x", "is", "None", ":", "# labels not preloaded", "\n", "                ", "with", "open", "(", "label_path", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "x", "=", "np", ".", "array", "(", "[", "x", ".", "split", "(", ")", "\n", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "", "if", "x", ".", "size", ">", "0", ":", "\n", "# Normalized xywh to pixel xyxy format", "\n", "                ", "labels", "=", "x", ".", "copy", "(", ")", "\n", "labels", "[", ":", ",", "1", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padw", "\n", "labels", "[", ":", ",", "2", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "padh", "\n", "labels", "[", ":", ",", "3", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padw", "\n", "labels", "[", ":", ",", "4", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "padh", "\n", "", "else", ":", "\n", "                ", "labels", "=", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "labels4", ".", "append", "(", "labels", ")", "\n", "\n", "# Concat/clip labels", "\n", "", "", "if", "len", "(", "labels4", ")", ":", "\n", "        ", "labels4", "=", "np", ".", "concatenate", "(", "labels4", ",", "0", ")", "\n", "# np.clip(labels4[:, 1:] - s / 2, 0, s, out=labels4[:, 1:])  # use with center crop", "\n", "# use with random_affine", "\n", "np", ".", "clip", "(", "labels4", "[", ":", ",", "1", ":", "]", ",", "0", ",", "2", "*", "s", ",", "out", "=", "labels4", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "# Augment", "\n", "# img4 = img4[s // 2: int(s * 1.5), s // 2:int(s * 1.5)]  # center crop (WARNING, requires box pruning)", "\n", "", "img4", ",", "labels4", "=", "random_affine", "(", "img4", ",", "labels4", ",", "\n", "degrees", "=", "self", ".", "hyp", "[", "'degrees'", "]", "*", "1", ",", "\n", "translate", "=", "self", ".", "hyp", "[", "'translate'", "]", "*", "1", ",", "\n", "scale", "=", "self", ".", "hyp", "[", "'scale'", "]", "*", "1", ",", "\n", "shear", "=", "self", ".", "hyp", "[", "'shear'", "]", "*", "1", ",", "\n", "border", "=", "-", "s", "//", "2", ")", "# border to remove", "\n", "\n", "return", "img4", ",", "labels4", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox": [[653, 689], ["isinstance", "cv2.copyMakeBorder", "max", "max", "min", "int", "int", "cv2.resize", "int", "int", "int", "int", "round", "round", "numpy.mod", "numpy.mod", "round", "round", "round", "round"], "function", ["None"], ["", "def", "letterbox", "(", "img", ",", "new_shape", "=", "(", "416", ",", "416", ")", ",", "color", "=", "(", "128", ",", "128", ",", "128", ")", ",", "\n", "auto", "=", "True", ",", "scaleFill", "=", "False", ",", "scaleup", "=", "True", ",", "interp", "=", "cv2", ".", "INTER_AREA", ")", ":", "\n", "# Resize image to a 32-pixel-multiple rectangle https://github.com/ultralytics/yolov3/issues/232", "\n", "    ", "shape", "=", "img", ".", "shape", "[", ":", "2", "]", "# current shape [height, width]", "\n", "if", "isinstance", "(", "new_shape", ",", "int", ")", ":", "\n", "        ", "new_shape", "=", "(", "new_shape", ",", "new_shape", ")", "\n", "\n", "# Scale ratio (new / old)", "\n", "", "r", "=", "max", "(", "new_shape", ")", "/", "max", "(", "shape", ")", "\n", "if", "not", "scaleup", ":", "# only scale down, do not scale up (for better test mAP)", "\n", "        ", "r", "=", "min", "(", "r", ",", "1.0", ")", "\n", "\n", "# Compute padding", "\n", "", "ratio", "=", "r", ",", "r", "# width, height ratios", "\n", "new_unpad", "=", "int", "(", "round", "(", "shape", "[", "1", "]", "*", "r", ")", ")", ",", "int", "(", "round", "(", "shape", "[", "0", "]", "*", "r", ")", ")", "\n", "dw", ",", "dh", "=", "new_shape", "[", "1", "]", "-", "new_unpad", "[", "0", "]", ",", "new_shape", "[", "0", "]", "-", "new_unpad", "[", "1", "]", "# wh padding", "\n", "if", "auto", ":", "# minimum rectangle", "\n", "        ", "dw", ",", "dh", "=", "np", ".", "mod", "(", "dw", ",", "32", ")", ",", "np", ".", "mod", "(", "dh", ",", "32", ")", "# wh padding", "\n", "", "elif", "scaleFill", ":", "# stretch", "\n", "        ", "dw", ",", "dh", "=", "0.0", ",", "0.0", "\n", "new_unpad", "=", "new_shape", "\n", "ratio", "=", "new_shape", "[", "0", "]", "/", "shape", "[", "1", "]", ",", "new_shape", "[", "1", "]", "/", "shape", "[", "0", "]", "# width, height ratios", "\n", "\n", "", "dw", "/=", "2", "# divide padding into 2 sides", "\n", "dh", "/=", "2", "\n", "\n", "if", "shape", "[", ":", ":", "-", "1", "]", "!=", "new_unpad", ":", "# resize", "\n", "# INTER_AREA is better, INTER_LINEAR is faster", "\n", "        ", "img", "=", "cv2", ".", "resize", "(", "img", ",", "new_unpad", ",", "interpolation", "=", "interp", ")", "\n", "", "top", ",", "bottom", "=", "int", "(", "round", "(", "dh", "-", "0.1", ")", ")", ",", "int", "(", "round", "(", "dh", "+", "0.1", ")", ")", "\n", "left", ",", "right", "=", "int", "(", "round", "(", "dw", "-", "0.1", ")", ")", ",", "int", "(", "round", "(", "dw", "+", "0.1", ")", ")", "\n", "img", "=", "cv2", ".", "copyMakeBorder", "(", "\n", "img", ",", "top", ",", "bottom", ",", "left", ",", "right", ",", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "color", ")", "# add border", "\n", "return", "img", ",", "ratio", ",", "(", "dw", ",", "dh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.random_affine": [[691, 768], ["numpy.eye", "random.uniform", "random.uniform", "cv2.getRotationMatrix2D", "numpy.eye", "numpy.eye", "math.tan", "math.tan", "len", "cv2.warpAffine", "numpy.ones", "targets[].reshape", "[].reshape", "xy[].clip", "xy[].clip", "numpy.maximum", "random.uniform", "random.uniform", "numpy.concatenate().reshape", "random.uniform", "random.uniform", "numpy.eye", "numpy.concatenate", "x.min", "y.min", "x.max", "y.max"], "function", ["None"], ["", "def", "random_affine", "(", "img", ",", "targets", "=", "(", ")", ",", "degrees", "=", "10", ",", "translate", "=", ".1", ",", "scale", "=", ".1", ",", "shear", "=", "10", ",", "border", "=", "0", ")", ":", "\n", "# torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))", "\n", "# https://medium.com/uruvideo/dataset-augmentation-with-random-homographies-a8f4b44830d4", "\n", "\n", "    ", "if", "targets", "is", "None", ":", "# targets = [cls, xyxy]", "\n", "        ", "targets", "=", "[", "]", "\n", "", "height", "=", "img", ".", "shape", "[", "0", "]", "+", "border", "*", "2", "\n", "width", "=", "img", ".", "shape", "[", "1", "]", "+", "border", "*", "2", "\n", "\n", "# Rotation and Scale", "\n", "R", "=", "np", ".", "eye", "(", "3", ")", "\n", "a", "=", "random", ".", "uniform", "(", "-", "degrees", ",", "degrees", ")", "\n", "# a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations", "\n", "s", "=", "random", ".", "uniform", "(", "1", "-", "scale", ",", "1", "+", "scale", ")", "\n", "R", "[", ":", "2", "]", "=", "cv2", ".", "getRotationMatrix2D", "(", "angle", "=", "a", ",", "center", "=", "(", "\n", "img", ".", "shape", "[", "1", "]", "/", "2", ",", "img", ".", "shape", "[", "0", "]", "/", "2", ")", ",", "scale", "=", "s", ")", "\n", "\n", "# Translation", "\n", "T", "=", "np", ".", "eye", "(", "3", ")", "\n", "T", "[", "0", ",", "2", "]", "=", "random", ".", "uniform", "(", "-", "translate", ",", "translate", ")", "*", "img", ".", "shape", "[", "0", "]", "+", "border", "# x translation (pixels)", "\n", "T", "[", "1", ",", "2", "]", "=", "random", ".", "uniform", "(", "-", "translate", ",", "translate", ")", "*", "img", ".", "shape", "[", "1", "]", "+", "border", "# y translation (pixels)", "\n", "\n", "# Shear", "\n", "S", "=", "np", ".", "eye", "(", "3", ")", "\n", "S", "[", "0", ",", "1", "]", "=", "math", ".", "tan", "(", "random", ".", "uniform", "(", "-", "shear", ",", "shear", ")", "*", "\n", "math", ".", "pi", "/", "180", ")", "# x shear (deg)", "\n", "S", "[", "1", ",", "0", "]", "=", "math", ".", "tan", "(", "random", ".", "uniform", "(", "-", "shear", ",", "shear", ")", "*", "\n", "math", ".", "pi", "/", "180", ")", "# y shear (deg)", "\n", "\n", "# Combined rotation matrix", "\n", "M", "=", "S", "@", "T", "@", "R", "# ORDER IS IMPORTANT HERE!!", "\n", "changed", "=", "(", "border", "!=", "0", ")", "or", "(", "M", "!=", "np", ".", "eye", "(", "3", ")", ")", ".", "any", "(", ")", "\n", "if", "changed", ":", "\n", "        ", "img", "=", "cv2", ".", "warpAffine", "(", "img", ",", "M", "[", ":", "2", "]", ",", "dsize", "=", "(", "\n", "width", ",", "height", ")", ",", "flags", "=", "cv2", ".", "INTER_AREA", ",", "borderValue", "=", "(", "128", ",", "128", ",", "128", ")", ")", "\n", "\n", "# Transform label coordinates", "\n", "", "n", "=", "len", "(", "targets", ")", "\n", "if", "n", ":", "\n", "# warp points", "\n", "        ", "xy", "=", "np", ".", "ones", "(", "(", "n", "*", "4", ",", "3", ")", ")", "\n", "xy", "[", ":", ",", ":", "2", "]", "=", "targets", "[", ":", ",", "[", "1", ",", "2", ",", "3", ",", "4", ",", "1", ",", "4", ",", "3", ",", "2", "]", "]", ".", "reshape", "(", "\n", "n", "*", "4", ",", "2", ")", "# x1y1, x2y2, x1y2, x2y1", "\n", "xy", "=", "(", "xy", "@", "M", ".", "T", ")", "[", ":", ",", ":", "2", "]", ".", "reshape", "(", "n", ",", "8", ")", "\n", "\n", "# create new boxes", "\n", "x", "=", "xy", "[", ":", ",", "[", "0", ",", "2", ",", "4", ",", "6", "]", "]", "\n", "y", "=", "xy", "[", ":", ",", "[", "1", ",", "3", ",", "5", ",", "7", "]", "]", "\n", "xy", "=", "np", ".", "concatenate", "(", "\n", "(", "x", ".", "min", "(", "1", ")", ",", "y", ".", "min", "(", "1", ")", ",", "x", ".", "max", "(", "1", ")", ",", "y", ".", "max", "(", "1", ")", ")", ")", ".", "reshape", "(", "4", ",", "n", ")", ".", "T", "\n", "\n", "# # apply angle-based reduction of bounding boxes", "\n", "# radians = a * math.pi / 180", "\n", "# reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5", "\n", "# x = (xy[:, 2] + xy[:, 0]) / 2", "\n", "# y = (xy[:, 3] + xy[:, 1]) / 2", "\n", "# w = (xy[:, 2] - xy[:, 0]) * reduction", "\n", "# h = (xy[:, 3] - xy[:, 1]) * reduction", "\n", "# xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T", "\n", "\n", "# reject warped points outside of image", "\n", "xy", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "xy", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clip", "(", "0", ",", "width", ")", "\n", "xy", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "xy", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clip", "(", "0", ",", "height", ")", "\n", "w", "=", "xy", "[", ":", ",", "2", "]", "-", "xy", "[", ":", ",", "0", "]", "\n", "h", "=", "xy", "[", ":", ",", "3", "]", "-", "xy", "[", ":", ",", "1", "]", "\n", "area", "=", "w", "*", "h", "\n", "area0", "=", "(", "targets", "[", ":", ",", "3", "]", "-", "targets", "[", ":", ",", "1", "]", ")", "*", "(", "targets", "[", ":", ",", "4", "]", "-", "targets", "[", ":", ",", "2", "]", ")", "\n", "ar", "=", "np", ".", "maximum", "(", "w", "/", "(", "h", "+", "1e-16", ")", ",", "h", "/", "(", "w", "+", "1e-16", ")", ")", "# aspect ratio", "\n", "i", "=", "(", "w", ">", "4", ")", "&", "(", "h", ">", "4", ")", "&", "(", "area", "/", "(", "area0", "+", "1e-16", ")", ">", "0.2", ")", "&", "(", "ar", "<", "10", ")", "\n", "\n", "targets", "=", "targets", "[", "i", "]", "\n", "targets", "[", ":", ",", "1", ":", "5", "]", "=", "xy", "[", "i", "]", "\n", "\n", "", "return", "img", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.cutout": [[770, 818], ["box2.transpose.transpose", "random.randint", "random.randint", "max", "max", "min", "min", "int", "int", "random.randint", "len", "numpy.array", "datasets.cutout.bbox_ioa"], "function", ["None"], ["", "def", "cutout", "(", "image", ",", "labels", ")", ":", "\n", "# https://arxiv.org/abs/1708.04552", "\n", "# https://github.com/hysts/pytorch_cutout/blob/master/dataloader.py", "\n", "# https://towardsdatascience.com/when-conventional-wisdom-fails-revisiting-data-augmentation-for-self-driving-cars-4831998c5509", "\n", "    ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "def", "bbox_ioa", "(", "box1", ",", "box2", ")", ":", "\n", "# Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2", "\n", "        ", "box2", "=", "box2", ".", "transpose", "(", ")", "\n", "\n", "# Get the coordinates of bounding boxes", "\n", "b1_x1", ",", "b1_y1", ",", "b1_x2", ",", "b1_y2", "=", "box1", "[", "0", "]", ",", "box1", "[", "1", "]", ",", "box1", "[", "2", "]", ",", "box1", "[", "3", "]", "\n", "b2_x1", ",", "b2_y1", ",", "b2_x2", ",", "b2_y2", "=", "box2", "[", "0", "]", ",", "box2", "[", "1", "]", ",", "box2", "[", "2", "]", ",", "box2", "[", "3", "]", "\n", "\n", "# Intersection area", "\n", "inter_area", "=", "(", "np", ".", "minimum", "(", "b1_x2", ",", "b2_x2", ")", "-", "np", ".", "maximum", "(", "b1_x1", ",", "b2_x1", ")", ")", ".", "clip", "(", "0", ")", "*", "(", "np", ".", "minimum", "(", "b1_y2", ",", "b2_y2", ")", "-", "np", ".", "maximum", "(", "b1_y1", ",", "b2_y1", ")", ")", ".", "clip", "(", "0", ")", "\n", "\n", "# box2 area", "\n", "box2_area", "=", "(", "b2_x2", "-", "b2_x1", ")", "*", "(", "b2_y2", "-", "b2_y1", ")", "+", "1e-16", "\n", "\n", "# Intersection over box2 area", "\n", "return", "inter_area", "/", "box2_area", "\n", "\n", "# create random masks", "\n", "", "scales", "=", "[", "0.5", "]", "*", "1", "+", "[", "0.25", "]", "*", "2", "+", "[", "0.125", "]", "*", "4", "+", "[", "0.0625", "]", "*", "8", "+", "[", "0.03125", "]", "*", "16", "# image size fraction", "\n", "for", "s", "in", "scales", ":", "\n", "        ", "mask_h", "=", "random", ".", "randint", "(", "1", ",", "int", "(", "h", "*", "s", ")", ")", "\n", "mask_w", "=", "random", ".", "randint", "(", "1", ",", "int", "(", "w", "*", "s", ")", ")", "\n", "\n", "# box", "\n", "xmin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "w", ")", "-", "mask_w", "//", "2", ")", "\n", "ymin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "h", ")", "-", "mask_h", "//", "2", ")", "\n", "xmax", "=", "min", "(", "w", ",", "xmin", "+", "mask_w", ")", "\n", "ymax", "=", "min", "(", "h", ",", "ymin", "+", "mask_h", ")", "\n", "\n", "# apply random color mask", "\n", "image", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "=", "[", "\n", "random", ".", "randint", "(", "64", ",", "191", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "\n", "# return unobscured labels", "\n", "if", "len", "(", "labels", ")", "and", "s", ">", "0.03", ":", "\n", "            ", "box", "=", "np", ".", "array", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ioa", "=", "bbox_ioa", "(", "box", ",", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "# intersection over area", "\n", "labels", "=", "labels", "[", "ioa", "<", "0.60", "]", "# remove >60% obscured labels", "\n", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.reduce_img_size": [[821, 838], ["datasets.create_folder", "tqdm.tqdm", "glob.glob", "cv2.imread", "f.replace", "cv2.imwrite", "max", "cv2.resize", "print", "int", "int"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.create_folder"], ["", "def", "reduce_img_size", "(", "path", "=", "'../data/sm4/images'", ",", "img_size", "=", "1024", ")", ":", "\n", "# creates a new ./images_reduced folder with reduced size images of maximum size img_size", "\n", "    ", "path_new", "=", "path", "+", "'_reduced'", "# reduced images path", "\n", "create_folder", "(", "path_new", ")", "\n", "for", "f", "in", "tqdm", "(", "glob", ".", "glob", "(", "'%s/*.*'", "%", "path", ")", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "img", "=", "cv2", ".", "imread", "(", "f", ")", "\n", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "r", "=", "img_size", "/", "max", "(", "h", ",", "w", ")", "# size ratio", "\n", "if", "r", "<", "1.0", ":", "\n", "                ", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "int", "(", "w", "*", "r", ")", ",", "int", "(", "h", "*", "r", ")", ")", ",", "\n", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "# _LINEAR fastest", "\n", "# .replace(Path(f).suffix, '.jpg')", "\n", "", "fnew", "=", "f", ".", "replace", "(", "path", ",", "path_new", ")", "\n", "cv2", ".", "imwrite", "(", "fnew", ",", "img", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'WARNING: image failure %s'", "%", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.convert_images2bmp": [[840, 864], ["datasets.create_folder", "x.lower", "x.upper", "tqdm.tqdm", "open", "f.read", "lines.replace.replace", "lines.replace.replace", "lines.replace.replace", "open", "f.write", "glob.glob", "cv2.imwrite", "file.replace", "f.replace().replace", "cv2.imread", "f.replace", "ext.lower"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.create_folder"], ["", "", "", "def", "convert_images2bmp", "(", ")", ":", "# from utils.datasets import *; convert_images2bmp()", "\n", "# Save images", "\n", "    ", "formats", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "img_formats", "]", "+", "[", "x", ".", "upper", "(", ")", "\n", "for", "x", "in", "img_formats", "]", "\n", "# for path in ['../coco/images/val2014', '../coco/images/train2014']:", "\n", "for", "path", "in", "[", "'../data/sm4/images'", ",", "'../data/sm4/background'", "]", ":", "\n", "        ", "create_folder", "(", "path", "+", "'bmp'", ")", "\n", "for", "ext", "in", "formats", ":", "# ['.bmp', '.jpg', '.jpeg', '.png', '.tif', '.dng']", "\n", "            ", "for", "f", "in", "tqdm", "(", "glob", ".", "glob", "(", "'%s/*%s'", "%", "(", "path", ",", "ext", ")", ")", ",", "desc", "=", "'Converting %s'", "%", "ext", ")", ":", "\n", "                ", "cv2", ".", "imwrite", "(", "f", ".", "replace", "(", "ext", ".", "lower", "(", ")", ",", "'.bmp'", ")", ".", "replace", "(", "\n", "path", ",", "path", "+", "'bmp'", ")", ",", "cv2", ".", "imread", "(", "f", ")", ")", "\n", "\n", "# Save labels", "\n", "# for path in ['../coco/trainvalno5k.txt', '../coco/5k.txt']:", "\n", "", "", "", "for", "file", "in", "[", "'../data/sm4/out_train.txt'", ",", "'../data/sm4/out_test.txt'", "]", ":", "\n", "        ", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "read", "(", ")", "\n", "# lines = f.read().replace('2014/', '2014bmp/')  # coco", "\n", "lines", "=", "lines", ".", "replace", "(", "'/images'", ",", "'/imagesbmp'", ")", "\n", "lines", "=", "lines", ".", "replace", "(", "'/background'", ",", "'/backgroundbmp'", ")", "\n", "", "for", "ext", "in", "formats", ":", "\n", "            ", "lines", "=", "lines", ".", "replace", "(", "ext", ",", "'.bmp'", ")", "\n", "", "with", "open", "(", "file", ".", "replace", "(", "'.txt'", ",", "'bmp.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.recursive_dataset2bmp": [[867, 886], ["os.walk", "tqdm.tqdm", "x.lower", "x.upper", "pathlib.Path", "open", "f.read", "lines.replace.replace", "open", "f.write", "cv2.imwrite", "p.replace", "cv2.imread", "os.system"], "function", ["None"], ["", "", "", "def", "recursive_dataset2bmp", "(", "dataset", "=", "'../data/sm4_bmp'", ")", ":", "\n", "# Converts dataset to bmp (for faster training)", "\n", "    ", "formats", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "img_formats", "]", "+", "[", "x", ".", "upper", "(", ")", "\n", "for", "x", "in", "img_formats", "]", "\n", "for", "a", ",", "b", ",", "files", "in", "os", ".", "walk", "(", "dataset", ")", ":", "\n", "        ", "for", "file", "in", "tqdm", "(", "files", ",", "desc", "=", "a", ")", ":", "\n", "            ", "p", "=", "a", "+", "'/'", "+", "file", "\n", "s", "=", "Path", "(", "file", ")", ".", "suffix", "\n", "if", "s", "==", "'.txt'", ":", "# replace text", "\n", "                ", "with", "open", "(", "p", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "lines", "=", "f", ".", "read", "(", ")", "\n", "", "for", "f", "in", "formats", ":", "\n", "                    ", "lines", "=", "lines", ".", "replace", "(", "f", ",", "'.bmp'", ")", "\n", "", "with", "open", "(", "p", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "lines", ")", "\n", "", "", "elif", "s", "in", "formats", ":", "# replace image", "\n", "                ", "cv2", ".", "imwrite", "(", "p", ".", "replace", "(", "s", ",", "'.bmp'", ")", ",", "cv2", ".", "imread", "(", "p", ")", ")", "\n", "if", "s", "!=", "'.bmp'", ":", "\n", "                    ", "os", ".", "system", "(", "\"rm '%s'\"", "%", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.imagelist2folder": [[889, 896], ["datasets.create_folder", "open", "f.read().splitlines", "os.system", "print", "f.read"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.create_folder"], ["", "", "", "", "", "def", "imagelist2folder", "(", "path", "=", "'data/coco_64img.txt'", ")", ":", "\n", "# Copies all the images in a text file (list of images) into a folder", "\n", "    ", "create_folder", "(", "path", "[", ":", "-", "4", "]", ")", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "os", ".", "system", "(", "'cp \"%s\" %s'", "%", "(", "line", ",", "path", "[", ":", "-", "4", "]", ")", ")", "\n", "print", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.create_folder": [[898, 903], ["os.path.exists", "os.makedirs", "shutil.rmtree"], "function", ["None"], ["", "", "", "def", "create_folder", "(", "path", "=", "'./new_folder'", ")", ":", "\n", "# Create folder", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "path", ")", "# delete output folder", "\n", "", "os", ".", "makedirs", "(", "path", ")", "# make new output folder", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.detect_face": [[9, 137], ["any", "len", "torch.cat().unsqueeze().permute", "min", "numpy.empty", "max", "numpy.array", "isinstance", "Exception", "torch.tensor().float().to", "int", "int", "detect_face.imresample", "pnet", "generateBoundingBox().numpy", "detect_face.nms", "detect_face.nms", "numpy.transpose", "detect_face.rerec", "numpy.fix().astype", "detect_face.pad", "range", "torch.cat", "rnet", "numpy.transpose", "numpy.transpose", "numpy.where", "numpy.hstack", "numpy.fix().astype", "detect_face.pad", "range", "torch.cat", "onet", "numpy.transpose", "numpy.transpose", "numpy.transpose", "numpy.where", "numpy.hstack", "int", "batch_boxes[].append", "torch.cat().unsqueeze", "numpy.append", "numpy.vstack", "bbreg.copy", "bbreg.copy", "torch.cat.append", "out[].numpy", "out[].numpy", "detect_face.nms", "detect_face.bbreg", "detect_face.rerec", "bbreg.copy", "torch.cat.append", "out[].numpy", "out[].numpy", "out[].numpy", "detect_face.bbreg", "detect_face.nms", "range", "torch.tensor().float", "detect_face.generateBoundingBox", "numpy.fix", "detect_face.imresample", "total_boxes[].copy", "numpy.expand_dims", "bbreg.copy", "numpy.transpose", "bbreg.copy", "numpy.fix", "detect_face.imresample", "total_boxes[].copy", "numpy.expand_dims", "numpy.tile", "numpy.tile", "bbreg.copy", "numpy.transpose", "bbreg.copy", "torch.cat", "score[].copy", "score[].copy", "numpy.tile", "numpy.tile", "torch.tensor", "numpy.uint8"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.imresample", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.rerec", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.pad", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.pad", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.bbreg", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.rerec", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.bbreg", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.generateBoundingBox", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.imresample", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.imresample"], ["def", "detect_face", "(", "img", ",", "minsize", ",", "pnet", ",", "rnet", ",", "onet", ",", "threshold", ",", "factor", ",", "device", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "img", ",", "Iterable", ")", ":", "\n", "        ", "img", "=", "[", "img", "]", "\n", "", "if", "any", "(", "im", ".", "size", "!=", "img", "[", "0", "]", ".", "size", "for", "im", "in", "img", ")", ":", "\n", "        ", "raise", "Exception", "(", "\n", "'MTCNN batch processing only compatible with equal-dimension images.'", ")", "\n", "\n", "", "batch_size", "=", "len", "(", "img", ")", "\n", "img", "=", "[", "torch", ".", "tensor", "(", "np", ".", "uint8", "(", "im", ")", ")", ".", "float", "(", ")", ".", "to", "(", "device", ")", "for", "im", "in", "img", "]", "\n", "wo", ",", "ho", "=", "img", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "axis", "=", "1", "if", "ho", "<", "wo", "else", "0", "\n", "img", "=", "torch", ".", "cat", "(", "img", ",", "axis", ")", ".", "unsqueeze", "(", "0", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "h", ",", "w", "=", "img", ".", "shape", "[", "2", ":", "4", "]", "\n", "m", "=", "12.0", "/", "minsize", "\n", "minl", "=", "min", "(", "h", ",", "w", ")", "\n", "minl", "=", "minl", "*", "m", "\n", "\n", "# First stage", "\n", "# Create scale pyramid", "\n", "total_boxes", "=", "np", ".", "empty", "(", "(", "0", ",", "9", ")", ")", "\n", "scale", "=", "m", "\n", "while", "minl", ">=", "12", ":", "\n", "        ", "hs", "=", "int", "(", "h", "*", "scale", "+", "1", ")", "\n", "ws", "=", "int", "(", "w", "*", "scale", "+", "1", ")", "\n", "im_data", "=", "imresample", "(", "img", ",", "(", "hs", ",", "ws", ")", ")", "\n", "im_data", "=", "(", "im_data", "-", "127.5", ")", "*", "0.0078125", "\n", "reg", ",", "probs", "=", "pnet", "(", "im_data", ")", "\n", "\n", "boxes", "=", "generateBoundingBox", "(", "\n", "reg", "[", "0", "]", ",", "probs", "[", "0", ",", "1", "]", ",", "scale", ",", "threshold", "[", "0", "]", ")", ".", "numpy", "(", ")", "\n", "\n", "scale", "=", "scale", "*", "factor", "\n", "minl", "=", "minl", "*", "factor", "\n", "\n", "# inter-scale nms", "\n", "pick", "=", "nms", "(", "boxes", ",", "0.5", ",", "'Union'", ")", "\n", "if", "boxes", ".", "size", ">", "0", "and", "pick", ".", "size", ">", "0", ":", "\n", "            ", "boxes", "=", "boxes", "[", "pick", ",", ":", "]", "\n", "total_boxes", "=", "np", ".", "append", "(", "total_boxes", ",", "boxes", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "numbox", "=", "total_boxes", ".", "shape", "[", "0", "]", "\n", "if", "numbox", ">", "0", ":", "\n", "        ", "pick", "=", "nms", "(", "total_boxes", ",", "0.7", ",", "'Union'", ")", "\n", "total_boxes", "=", "total_boxes", "[", "pick", ",", ":", "]", "\n", "regw", "=", "total_boxes", "[", ":", ",", "2", "]", "-", "total_boxes", "[", ":", ",", "0", "]", "\n", "regh", "=", "total_boxes", "[", ":", ",", "3", "]", "-", "total_boxes", "[", ":", ",", "1", "]", "\n", "qq1", "=", "total_boxes", "[", ":", ",", "0", "]", "+", "total_boxes", "[", ":", ",", "5", "]", "*", "regw", "\n", "qq2", "=", "total_boxes", "[", ":", ",", "1", "]", "+", "total_boxes", "[", ":", ",", "6", "]", "*", "regh", "\n", "qq3", "=", "total_boxes", "[", ":", ",", "2", "]", "+", "total_boxes", "[", ":", ",", "7", "]", "*", "regw", "\n", "qq4", "=", "total_boxes", "[", ":", ",", "3", "]", "+", "total_boxes", "[", ":", ",", "8", "]", "*", "regh", "\n", "total_boxes", "=", "np", ".", "transpose", "(", "\n", "np", ".", "vstack", "(", "[", "qq1", ",", "qq2", ",", "qq3", ",", "qq4", ",", "total_boxes", "[", ":", ",", "4", "]", "]", ")", ")", "\n", "total_boxes", "=", "rerec", "(", "total_boxes", ".", "copy", "(", ")", ")", "\n", "total_boxes", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "fix", "(", "total_boxes", "[", ":", ",", "0", ":", "4", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "dy", ",", "edy", ",", "dx", ",", "edx", ",", "y", ",", "ey", ",", "x", ",", "ex", ",", "tmpw", ",", "tmph", "=", "pad", "(", "\n", "total_boxes", ".", "copy", "(", ")", ",", "w", ",", "h", ")", "\n", "\n", "", "numbox", "=", "total_boxes", ".", "shape", "[", "0", "]", "\n", "if", "numbox", ">", "0", ":", "\n", "# second stage", "\n", "        ", "im_data", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "0", ",", "numbox", ")", ":", "\n", "            ", "img_k", "=", "img", "[", "[", "0", "]", ",", ":", ",", "(", "y", "[", "k", "]", "-", "1", ")", ":", "ey", "[", "k", "]", ",", "(", "x", "[", "k", "]", "-", "1", ")", ":", "ex", "[", "k", "]", "]", "\n", "im_data", ".", "append", "(", "imresample", "(", "img_k", ",", "(", "24", ",", "24", ")", ")", ")", "\n", "", "im_data", "=", "torch", ".", "cat", "(", "im_data", ",", "0", ")", "\n", "im_data", "=", "(", "im_data", "-", "127.5", ")", "*", "0.0078125", "\n", "out", "=", "rnet", "(", "im_data", ")", "\n", "\n", "out0", "=", "np", ".", "transpose", "(", "out", "[", "0", "]", ".", "numpy", "(", ")", ")", "\n", "out1", "=", "np", ".", "transpose", "(", "out", "[", "1", "]", ".", "numpy", "(", ")", ")", "\n", "score", "=", "out1", "[", "1", ",", ":", "]", "\n", "ipass", "=", "np", ".", "where", "(", "score", ">", "threshold", "[", "1", "]", ")", "\n", "total_boxes", "=", "np", ".", "hstack", "(", "\n", "[", "total_boxes", "[", "ipass", "[", "0", "]", ",", "0", ":", "4", "]", ".", "copy", "(", ")", ",", "np", ".", "expand_dims", "(", "score", "[", "ipass", "]", ".", "copy", "(", ")", ",", "1", ")", "]", ")", "\n", "mv", "=", "out0", "[", ":", ",", "ipass", "[", "0", "]", "]", "\n", "if", "total_boxes", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "            ", "pick", "=", "nms", "(", "total_boxes", ",", "0.7", ",", "'Union'", ")", "\n", "total_boxes", "=", "total_boxes", "[", "pick", ",", ":", "]", "\n", "total_boxes", "=", "bbreg", "(", "total_boxes", ".", "copy", "(", ")", ",", "np", ".", "transpose", "(", "mv", "[", ":", ",", "pick", "]", ")", ")", "\n", "total_boxes", "=", "rerec", "(", "total_boxes", ".", "copy", "(", ")", ")", "\n", "\n", "", "", "numbox", "=", "total_boxes", ".", "shape", "[", "0", "]", "\n", "if", "numbox", ">", "0", ":", "\n", "# third stage", "\n", "        ", "total_boxes", "=", "np", ".", "fix", "(", "total_boxes", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "dy", ",", "edy", ",", "dx", ",", "edx", ",", "y", ",", "ey", ",", "x", ",", "ex", ",", "tmpw", ",", "tmph", "=", "pad", "(", "\n", "total_boxes", ".", "copy", "(", ")", ",", "w", ",", "h", ")", "\n", "im_data", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "0", ",", "numbox", ")", ":", "\n", "            ", "img_k", "=", "img", "[", "[", "0", "]", ",", ":", ",", "(", "y", "[", "k", "]", "-", "1", ")", ":", "ey", "[", "k", "]", ",", "(", "x", "[", "k", "]", "-", "1", ")", ":", "ex", "[", "k", "]", "]", "\n", "im_data", ".", "append", "(", "imresample", "(", "img_k", ",", "(", "48", ",", "48", ")", ")", ")", "\n", "", "im_data", "=", "torch", ".", "cat", "(", "im_data", ",", "0", ")", "\n", "im_data", "=", "(", "im_data", "-", "127.5", ")", "*", "0.0078125", "\n", "out", "=", "onet", "(", "im_data", ")", "\n", "\n", "out0", "=", "np", ".", "transpose", "(", "out", "[", "0", "]", ".", "numpy", "(", ")", ")", "\n", "out1", "=", "np", ".", "transpose", "(", "out", "[", "1", "]", ".", "numpy", "(", ")", ")", "\n", "out2", "=", "np", ".", "transpose", "(", "out", "[", "2", "]", ".", "numpy", "(", ")", ")", "\n", "score", "=", "out2", "[", "1", ",", ":", "]", "\n", "points", "=", "out1", "\n", "ipass", "=", "np", ".", "where", "(", "score", ">", "threshold", "[", "2", "]", ")", "\n", "points", "=", "points", "[", ":", ",", "ipass", "[", "0", "]", "]", "\n", "total_boxes", "=", "np", ".", "hstack", "(", "\n", "[", "total_boxes", "[", "ipass", "[", "0", "]", ",", "0", ":", "4", "]", ".", "copy", "(", ")", ",", "np", ".", "expand_dims", "(", "score", "[", "ipass", "]", ".", "copy", "(", ")", ",", "1", ")", "]", ")", "\n", "mv", "=", "out0", "[", ":", ",", "ipass", "[", "0", "]", "]", "\n", "\n", "w", "=", "total_boxes", "[", ":", ",", "2", "]", "-", "total_boxes", "[", ":", ",", "0", "]", "+", "1", "\n", "h", "=", "total_boxes", "[", ":", ",", "3", "]", "-", "total_boxes", "[", ":", ",", "1", "]", "+", "1", "\n", "points", "[", "0", ":", "5", ",", ":", "]", "=", "np", ".", "tile", "(", "\n", "w", ",", "(", "5", ",", "1", ")", ")", "*", "points", "[", "0", ":", "5", ",", ":", "]", "+", "np", ".", "tile", "(", "total_boxes", "[", ":", ",", "0", "]", ",", "(", "5", ",", "1", ")", ")", "-", "1", "\n", "points", "[", "5", ":", "10", ",", ":", "]", "=", "np", ".", "tile", "(", "\n", "h", ",", "(", "5", ",", "1", ")", ")", "*", "points", "[", "5", ":", "10", ",", ":", "]", "+", "np", ".", "tile", "(", "total_boxes", "[", ":", ",", "1", "]", ",", "(", "5", ",", "1", ")", ")", "-", "1", "\n", "if", "total_boxes", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "            ", "total_boxes", "=", "bbreg", "(", "total_boxes", ".", "copy", "(", ")", ",", "np", ".", "transpose", "(", "mv", ")", ")", "\n", "pick", "=", "nms", "(", "total_boxes", ".", "copy", "(", ")", ",", "0.7", ",", "'Min'", ")", "\n", "total_boxes", "=", "total_boxes", "[", "pick", ",", ":", "]", "\n", "points", "=", "points", "[", ":", ",", "pick", "]", "\n", "\n", "", "", "dim", "=", "1", "-", "axis", "\n", "batch_dim", "=", "max", "(", "wo", ",", "ho", ")", "\n", "batch_boxes", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "box", "in", "total_boxes", ":", "\n", "        ", "batch_ind", "=", "int", "(", "box", "[", "1", "-", "axis", "]", "/", "batch_dim", ")", "\n", "box", "[", "[", "1", "-", "axis", ",", "1", "-", "axis", "+", "2", "]", "]", "=", "[", "b", "%", "\n", "batch_dim", "for", "b", "in", "box", "[", "[", "1", "-", "axis", ",", "1", "-", "axis", "+", "2", "]", "]", "]", "\n", "batch_boxes", "[", "batch_ind", "]", ".", "append", "(", "box", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "batch_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.bbreg": [[139, 151], ["numpy.transpose", "numpy.reshape", "numpy.vstack"], "function", ["None"], ["", "def", "bbreg", "(", "boundingbox", ",", "reg", ")", ":", "\n", "    ", "if", "reg", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "        ", "reg", "=", "np", ".", "reshape", "(", "reg", ",", "(", "reg", ".", "shape", "[", "2", "]", ",", "reg", ".", "shape", "[", "3", "]", ")", ")", "\n", "\n", "", "w", "=", "boundingbox", "[", ":", ",", "2", "]", "-", "boundingbox", "[", ":", ",", "0", "]", "+", "1", "\n", "h", "=", "boundingbox", "[", ":", ",", "3", "]", "-", "boundingbox", "[", ":", ",", "1", "]", "+", "1", "\n", "b1", "=", "boundingbox", "[", ":", ",", "0", "]", "+", "reg", "[", ":", ",", "0", "]", "*", "w", "\n", "b2", "=", "boundingbox", "[", ":", ",", "1", "]", "+", "reg", "[", ":", ",", "1", "]", "*", "h", "\n", "b3", "=", "boundingbox", "[", ":", ",", "2", "]", "+", "reg", "[", ":", ",", "2", "]", "*", "w", "\n", "b4", "=", "boundingbox", "[", ":", ",", "3", "]", "+", "reg", "[", ":", ",", "3", "]", "*", "h", "\n", "boundingbox", "[", ":", ",", "0", ":", "4", "]", "=", "np", ".", "transpose", "(", "np", ".", "vstack", "(", "[", "b1", ",", "b2", ",", "b3", ",", "b4", "]", ")", ")", "\n", "return", "boundingbox", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.generateBoundingBox": [[153, 165], ["numpy.transpose", "mask.nonzero().float().flip", "torch.cat", "mask.nonzero().float", "score.unsqueeze", "mask.nonzero"], "function", ["None"], ["", "def", "generateBoundingBox", "(", "reg", ",", "probs", ",", "scale", ",", "thresh", ")", ":", "\n", "    ", "stride", "=", "2", "\n", "cellsize", "=", "12", "\n", "\n", "mask", "=", "probs", ">=", "thresh", "\n", "score", "=", "probs", "[", "mask", "]", "\n", "reg", "=", "np", ".", "transpose", "(", "reg", "[", "0", ":", "4", ",", "mask", "]", ")", "\n", "bb", "=", "mask", ".", "nonzero", "(", ")", ".", "float", "(", ")", ".", "flip", "(", "1", ")", "\n", "q1", "=", "(", "(", "stride", "*", "bb", "+", "1", ")", "/", "scale", ")", ".", "floor", "(", ")", "\n", "q2", "=", "(", "(", "stride", "*", "bb", "+", "cellsize", "-", "1", "+", "1", ")", "/", "scale", ")", ".", "floor", "(", ")", "\n", "boundingbox", "=", "torch", ".", "cat", "(", "[", "q1", ",", "q2", ",", "score", ".", "unsqueeze", "(", "1", ")", ",", "reg", "]", ",", "dim", "=", "1", ")", "\n", "return", "boundingbox", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.nms": [[167, 198], ["numpy.argsort", "numpy.zeros_like", "numpy.empty", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.where"], "function", ["None"], ["", "def", "nms", "(", "boxes", ",", "threshold", ",", "method", ")", ":", "\n", "    ", "if", "boxes", ".", "size", "==", "0", ":", "\n", "        ", "return", "np", ".", "empty", "(", "(", "0", ",", "3", ")", ")", "\n", "", "x1", "=", "boxes", "[", ":", ",", "0", "]", "\n", "y1", "=", "boxes", "[", ":", ",", "1", "]", "\n", "x2", "=", "boxes", "[", ":", ",", "2", "]", "\n", "y2", "=", "boxes", "[", ":", ",", "3", "]", "\n", "s", "=", "boxes", "[", ":", ",", "4", "]", "\n", "area", "=", "(", "x2", "-", "x1", "+", "1", ")", "*", "(", "y2", "-", "y1", "+", "1", ")", "\n", "I", "=", "np", ".", "argsort", "(", "s", ")", "\n", "pick", "=", "np", ".", "zeros_like", "(", "s", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "counter", "=", "0", "\n", "while", "I", ".", "size", ">", "0", ":", "\n", "        ", "i", "=", "I", "[", "-", "1", "]", "\n", "pick", "[", "counter", "]", "=", "i", "\n", "counter", "+=", "1", "\n", "idx", "=", "I", "[", "0", ":", "-", "1", "]", "\n", "xx1", "=", "np", ".", "maximum", "(", "x1", "[", "i", "]", ",", "x1", "[", "idx", "]", ")", "\n", "yy1", "=", "np", ".", "maximum", "(", "y1", "[", "i", "]", ",", "y1", "[", "idx", "]", ")", "\n", "xx2", "=", "np", ".", "minimum", "(", "x2", "[", "i", "]", ",", "x2", "[", "idx", "]", ")", "\n", "yy2", "=", "np", ".", "minimum", "(", "y2", "[", "i", "]", ",", "y2", "[", "idx", "]", ")", "\n", "w", "=", "np", ".", "maximum", "(", "0.0", ",", "xx2", "-", "xx1", "+", "1", ")", "\n", "h", "=", "np", ".", "maximum", "(", "0.0", ",", "yy2", "-", "yy1", "+", "1", ")", "\n", "inter", "=", "w", "*", "h", "\n", "if", "method", "is", "'Min'", ":", "\n", "            ", "o", "=", "inter", "/", "np", ".", "minimum", "(", "area", "[", "i", "]", ",", "area", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "o", "=", "inter", "/", "(", "area", "[", "i", "]", "+", "area", "[", "idx", "]", "-", "inter", ")", "\n", "", "I", "=", "I", "[", "np", ".", "where", "(", "o", "<=", "threshold", ")", "]", "\n", "", "pick", "=", "pick", "[", "0", ":", "counter", "]", "\n", "return", "pick", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.pad": [[200, 232], ["numpy.ones", "numpy.ones", "tmpw.copy().astype", "tmph.copy().astype", "total_boxes[].copy().astype", "total_boxes[].copy().astype", "total_boxes[].copy().astype", "total_boxes[].copy().astype", "numpy.where", "numpy.expand_dims", "numpy.where", "numpy.expand_dims", "numpy.where", "numpy.expand_dims", "numpy.where", "numpy.expand_dims", "tmpw.copy", "tmph.copy", "total_boxes[].copy", "total_boxes[].copy", "total_boxes[].copy", "total_boxes[].copy"], "function", ["None"], ["", "def", "pad", "(", "total_boxes", ",", "w", ",", "h", ")", ":", "\n", "    ", "tmpw", "=", "(", "total_boxes", "[", ":", ",", "2", "]", "-", "total_boxes", "[", ":", ",", "0", "]", "+", "1", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "tmph", "=", "(", "total_boxes", "[", ":", ",", "3", "]", "-", "total_boxes", "[", ":", ",", "1", "]", "+", "1", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "numbox", "=", "total_boxes", ".", "shape", "[", "0", "]", "\n", "\n", "dx", "=", "np", ".", "ones", "(", "(", "numbox", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "dy", "=", "np", ".", "ones", "(", "(", "numbox", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "edx", "=", "tmpw", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "edy", "=", "tmph", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "x", "=", "total_boxes", "[", ":", ",", "0", "]", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "y", "=", "total_boxes", "[", ":", ",", "1", "]", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "ex", "=", "total_boxes", "[", ":", ",", "2", "]", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "ey", "=", "total_boxes", "[", ":", ",", "3", "]", ".", "copy", "(", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n", "tmp", "=", "np", ".", "where", "(", "ex", ">", "w", ")", "\n", "edx", ".", "flat", "[", "tmp", "]", "=", "np", ".", "expand_dims", "(", "-", "ex", "[", "tmp", "]", "+", "w", "+", "tmpw", "[", "tmp", "]", ",", "1", ")", "\n", "ex", "[", "tmp", "]", "=", "w", "\n", "\n", "tmp", "=", "np", ".", "where", "(", "ey", ">", "h", ")", "\n", "edy", ".", "flat", "[", "tmp", "]", "=", "np", ".", "expand_dims", "(", "-", "ey", "[", "tmp", "]", "+", "h", "+", "tmph", "[", "tmp", "]", ",", "1", ")", "\n", "ey", "[", "tmp", "]", "=", "h", "\n", "\n", "tmp", "=", "np", ".", "where", "(", "x", "<", "1", ")", "\n", "dx", ".", "flat", "[", "tmp", "]", "=", "np", ".", "expand_dims", "(", "2", "-", "x", "[", "tmp", "]", ",", "1", ")", "\n", "x", "[", "tmp", "]", "=", "1", "\n", "\n", "tmp", "=", "np", ".", "where", "(", "y", "<", "1", ")", "\n", "dy", ".", "flat", "[", "tmp", "]", "=", "np", ".", "expand_dims", "(", "2", "-", "y", "[", "tmp", "]", ",", "1", ")", "\n", "y", "[", "tmp", "]", "=", "1", "\n", "\n", "return", "dy", ",", "edy", ",", "dx", ",", "edx", ",", "y", ",", "ey", ",", "x", ",", "ex", ",", "tmpw", ",", "tmph", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.rerec": [[234, 242], ["numpy.maximum", "numpy.transpose", "numpy.tile"], "function", ["None"], ["", "def", "rerec", "(", "bboxA", ")", ":", "\n", "    ", "h", "=", "bboxA", "[", ":", ",", "3", "]", "-", "bboxA", "[", ":", ",", "1", "]", "\n", "w", "=", "bboxA", "[", ":", ",", "2", "]", "-", "bboxA", "[", ":", ",", "0", "]", "\n", "l", "=", "np", ".", "maximum", "(", "w", ",", "h", ")", "\n", "bboxA", "[", ":", ",", "0", "]", "=", "bboxA", "[", ":", ",", "0", "]", "+", "w", "*", "0.5", "-", "l", "*", "0.5", "\n", "bboxA", "[", ":", ",", "1", "]", "=", "bboxA", "[", ":", ",", "1", "]", "+", "h", "*", "0.5", "-", "l", "*", "0.5", "\n", "bboxA", "[", ":", ",", "2", ":", "4", "]", "=", "bboxA", "[", ":", ",", "0", ":", "2", "]", "+", "np", ".", "transpose", "(", "np", ".", "tile", "(", "l", ",", "(", "2", ",", "1", ")", ")", ")", "\n", "return", "bboxA", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.imresample": [[244, 248], ["torch.nn.functional.interpolate"], "function", ["None"], ["", "def", "imresample", "(", "img", ",", "sz", ")", ":", "\n", "    ", "out_shape", "=", "(", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", "\n", "im_data", "=", "torch", ".", "nn", ".", "functional", ".", "interpolate", "(", "img", ",", "size", "=", "out_shape", ",", "mode", "=", "'area'", ")", "\n", "return", "im_data", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.extract_face": [[250, 287], ["img.crop().resize", "torchvision.to_tensor", "int", "int", "int", "int", "os.makedirs", "F.to_tensor.save", "numpy.float32", "max", "max", "min", "min", "img.crop", "os.path.dirname"], "function", ["None"], ["", "def", "extract_face", "(", "img", ",", "box", ",", "image_size", "=", "160", ",", "margin", "=", "0", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract face + margin from PIL Image given bounding box.\n\n    Arguments:\n        img {PIL.Image} -- A PIL Image.\n        box {numpy.ndarray} -- Four-element bounding box.\n        image_size {int} -- Output image size in pixels. The image will be square.\n        margin {int} -- Margin to add to bounding box, in terms of pixels in the final image.\n            Note that the application of the margin differs slightly from the davidsandberg/facenet\n            repo, which applies the margin to the original image before resizing, making the margin\n            dependent on the original image size.\n        save_path {str} -- Save path for extracted face image. (default: {None})\n\n    Returns:\n        torch.tensor -- tensor representing the extracted face.\n    \"\"\"", "\n", "margin", "=", "[", "\n", "margin", "*", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "/", "(", "image_size", "-", "margin", ")", ",", "\n", "margin", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "/", "(", "image_size", "-", "margin", ")", "\n", "]", "\n", "box", "=", "[", "\n", "int", "(", "max", "(", "box", "[", "0", "]", "-", "margin", "[", "0", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "max", "(", "box", "[", "1", "]", "-", "margin", "[", "1", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "2", "]", "+", "margin", "[", "0", "]", "/", "2", ",", "img", ".", "size", "[", "0", "]", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "3", "]", "+", "margin", "[", "1", "]", "/", "2", ",", "img", ".", "size", "[", "1", "]", ")", ")", "\n", "]", "\n", "\n", "face", "=", "img", ".", "crop", "(", "box", ")", ".", "resize", "(", "(", "image_size", ",", "image_size", ")", ",", "2", ")", "\n", "\n", "if", "save_path", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "+", "'/'", ",", "exist_ok", "=", "True", ")", "\n", "save_args", "=", "{", "'compress_level'", ":", "0", "}", "if", "'.png'", "in", "save_path", "else", "{", "}", "\n", "face", ".", "save", "(", "save_path", ",", "**", "save_args", ")", "\n", "\n", "", "face", "=", "F", ".", "to_tensor", "(", "np", ".", "float32", "(", "face", ")", ")", "\n", "\n", "return", "face", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.weightedFeatureFusion.__init__": [[135, 142], ["nn.Module.__init__", "len", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.weightedFeatureFusion.forward": [[143, 167], ["range", "torch.sigmoid"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.SwishImplementation.forward": [[170, 174], ["ctx.save_for_backward", "torch.sigmoid"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.SwishImplementation.backward": [[175, 179], ["torch.sigmoid"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.MemoryEfficientSwish.forward": [[182, 184], ["SwishImplementation.apply"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.Swish.forward": [[187, 189], ["x.mul_", "torch.sigmoid"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.Mish.forward": [[192, 194], ["x.mul_", "torch.softplus().tanh", "torch.softplus"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.YOLOLayer.__init__": [[197, 213], ["nn.Module.__init__", "torch.Tensor", "len", "int", "int", "models.create_grids"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.create_grids"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.YOLOLayer.forward": [[214, 269], ["p.view.view.view().permute().contiguous", "models.create_grids", "p.view.view.view().permute", "models.YOLOLayer.grid_xy.repeat().view", "p.view.view.view", "p.view.view.clone", "models.YOLOLayer.ng.repeat", "models.YOLOLayer.anchor_wh.repeat().view", "torch.sigmoid", "torch.exp", "torch.sigmoid", "torch.sigmoid", "torch.exp", "torch.sigmoid_", "p.view.clone.view", "p.view.view.view", "models.YOLOLayer.grid_xy.repeat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid_", "models.YOLOLayer.anchor_wh.repeat", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.create_grids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.Darknet.__init__": [[274, 287], ["nn.Module.__init__", "parse_model_cfg", "models.create_modules", "models.get_yolo_layers", "np.array", "np.array"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.parse_config.parse_model_cfg", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.create_modules", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.get_yolo_layers"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.Darknet.forward": [[288, 342], ["enumerate", "print", "zip", "out.append", "module", "print", "zip", "module", "list", "torch.cat", "torch.cat", "torch.cat", "zip", "len", "yolo_out.append", "len", "list", "list", "torch.cat", "module", "list", "list", "torch.interpolate", "torch.cat", "zip", "zip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.Darknet.fuse": [[343, 357], ["nn.ModuleList", "list", "isinstance", "nn.ModuleList.append", "models.Darknet.children", "enumerate", "isinstance", "torch_utils.fuse_conv_and_bn", "nn.Sequential", "list", "nn.Sequential.children"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.fuse_conv_and_bn"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.create_modules": [[10, 131], ["module_defs.pop", "nn.ModuleList", "enumerate", "int", "nn.Sequential", "nn.ModuleList.append", "output_filters.append", "YOLOLayer.add_module", "nn.Conv2d", "YOLOLayer.add_module", "YOLOLayer.add_module", "nn.MaxPool2d", "nn.BatchNorm2d", "nn.LeakyReLU", "YOLOLayer.add_module", "YOLOLayer.add_module", "YOLOLayer.add_module", "models.Swish", "nn.ZeroPad2d", "nn.Upsample", "nn.Upsample", "sum", "routs.extend", "routs.extend", "models.weightedFeatureFusion", "tuple", "models.YOLOLayer", "print", "int", "math.log", "[].bias.view", "torch.nn.Parameter", "len", "bias[].mean", "bias[].mean", "[].bias.view.view", "print"], "function", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.get_yolo_layers": [[360, 363], ["enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.create_grids": [[365, 382], ["max", "torch.meshgrid", "torch.stack().to().type().view", "models..anchor_vec.view().to().type", "torch.Tensor().to", "max", "models..anchors.to", "torch.arange", "torch.arange", "torch.stack().to().type", "models..anchor_vec.view().to", "torch.Tensor", "torch.stack().to", "models..anchor_vec.view", "torch.stack"], "function", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.load_darknet_weights": [[384, 440], ["enumerate", "Path", "open", "np.fromfile", "np.fromfile", "np.fromfile", "zip", "conv.weight.numel", "conv.weight.data.copy_", "bn.bias.numel", "bn.bias.data.copy_", "bn.weight.data.copy_", "bn.running_mean.data.copy_", "bn.running_var.data.copy_", "conv.bias.numel", "torch.from_numpy().view_as", "conv.bias.data.copy_", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.save_weights": [[442, 466], ["open", "models..version.tofile", "models..seen.tofile", "enumerate", "zip", "conv_layer.weight.data.cpu().numpy().tofile", "bn_layer.bias.data.cpu().numpy().tofile", "bn_layer.weight.data.cpu().numpy().tofile", "bn_layer.running_mean.data.cpu().numpy().tofile", "bn_layer.running_var.data.cpu().numpy().tofile", "conv_layer.bias.data.cpu().numpy().tofile", "conv_layer.weight.data.cpu().numpy", "bn_layer.bias.data.cpu().numpy", "bn_layer.weight.data.cpu().numpy", "bn_layer.running_mean.data.cpu().numpy", "bn_layer.running_var.data.cpu().numpy", "conv_layer.bias.data.cpu().numpy", "conv_layer.weight.data.cpu", "bn_layer.bias.data.cpu", "bn_layer.weight.data.cpu", "bn_layer.running_mean.data.cpu", "bn_layer.running_var.data.cpu", "conv_layer.bias.data.cpu"], "function", ["None"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert": [[468, 495], ["models.Darknet", "weights.endswith", "Darknet.load_state_dict", "models.save_weights", "print", "weights.endswith", "models.load_darknet_weights", "torch.save", "print", "print", "torch.load", "Darknet.state_dict"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.save_weights", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.load_darknet_weights"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.attempt_download": [[497, 527], ["os.path.isfile", "Path", "gdrive_download", "print", "os.system", "os.system", "Exception", "os.path.exists", "os.path.getsize"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.google_utils.gdrive_download"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.__init__": [[33, 52], ["threading.Thread.__init__", "utils.set_logger", "threading.Event", "max", "termcolor.colored", "zmq.pyzmq_version", "zmq.pyzmq_version", "zmq.pyzmq_version", "zmq.pyzmq_version", "zmq.zmq_version", "zmq.zmq_version", "zmq.zmq_version", "zmq.zmq_version", "str", "datetime.datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger"], ["def", "__init__", "(", "self", ",", "port", "=", "5558", ",", "port_out", "=", "5559", ",", "n_workers", "=", "1", ",", "verbose", "=", "False", ",", "\n", "max_batch_size", "=", "32", ",", "task", "=", "'coref'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'VENTILATOR'", ",", "'magenta'", ")", ",", "verbose", ")", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "port_out", "=", "port_out", "\n", "self", ".", "processes", "=", "[", "]", "\n", "self", ".", "is_ready", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "n_workers", "=", "n_workers", "\n", "self", ".", "n_concurrent_sockets", "=", "max", "(", "8", ",", "n_workers", "*", "2", ")", "\n", "self", ".", "max_batch_size", "=", "max_batch_size", "\n", "self", ".", "status_static", "=", "{", "\n", "'python_version'", ":", "sys", ".", "version", ",", "\n", "'server_version'", ":", "__version__", ",", "\n", "'pyzmq_version'", ":", "zmq", ".", "pyzmq_version", "(", ")", ",", "\n", "'zmq_version'", ":", "zmq", ".", "zmq_version", "(", ")", ",", "\n", "'server_start_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "}", "\n", "self", ".", "Worker", "=", "WorkerRegistry", "[", "task", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.__enter__": [[53, 57], ["base.NLPServer.start", "base.NLPServer.is_ready.wait"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "(", ")", "\n", "self", ".", "is_ready", ".", "wait", "(", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.__exit__": [[58, 60], ["base.NLPServer.close"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.close": [[61, 66], ["base.NLPServer.logger.info", "base.NLPServer._send_close_signal", "base.NLPServer.is_ready.clear", "base.NLPServer.join"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer._send_close_signal", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'shutting down...'", ")", "\n", "self", ".", "_send_close_signal", "(", ")", "\n", "self", ".", "is_ready", ".", "clear", "(", ")", "\n", "self", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer._send_close_signal": [[67, 72], ["zmq.context", "zmq.context", "zmq.socket", "zmq.socket", "frontend.connect", "frontend.send_multipart"], "methods", ["None"], ["", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PUSH", ")", "\n", "def", "_send_close_signal", "(", "self", ",", "_", ",", "frontend", ")", ":", "\n", "        ", "frontend", ".", "connect", "(", "'tcp://localhost:%d'", "%", "self", ".", "port", ")", "\n", "frontend", ".", "send_multipart", "(", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.shutdown": [[73, 87], ["zmq.Context", "zmq.Context", "zmq.Context", "zmq.Context", "ctx.setsockopt", "ctx.socket", "frontend.connect", "frontend.send_multipart", "print", "TimeoutError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "shutdown", "(", "args", ")", ":", "\n", "        ", "with", "zmq", ".", "Context", "(", ")", "as", "ctx", ":", "\n", "            ", "ctx", ".", "setsockopt", "(", "zmq", ".", "LINGER", ",", "args", ".", "timeout", ")", "\n", "with", "ctx", ".", "socket", "(", "zmq", ".", "PUSH", ")", "as", "frontend", ":", "\n", "                ", "try", ":", "\n", "                    ", "frontend", ".", "connect", "(", "'tcp://%s:%d'", "%", "(", "args", ".", "ip", ",", "args", ".", "port", ")", ")", "\n", "frontend", ".", "send_multipart", "(", "\n", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "print", "(", "'shutdown signal sent to %d'", "%", "args", ".", "port", ")", "\n", "", "except", "zmq", ".", "error", ".", "Again", ":", "\n", "                    ", "raise", "TimeoutError", "(", "\n", "'no response from the server (with \"timeout\"=%d ms), please check the following:'", "\n", "'is the server still online? is the network broken? are \"port\" correct? '", "%", "args", ".", "timeout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer.run": [[88, 90], ["base.NLPServer._run"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker._run"], ["", "", "", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "_run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.NLPServer._run": [[91, 192], ["zmq.context", "zmq.context", "zmq.socket", "zmq.socket", "zmq.socket", "zmq.socket", "zmq_decor.multi_socket", "base.NLPServer.logger.info", "frontend.bind", "utils.auto_bind", "base.NLPServer.logger.info", "base.NLPServer.logger.info", "base.Sink", "base.NLPServer.processes.append", "Sink.start", "sink.recv().decode", "enumerate", "base.ServerStatistic", "base.NLPServer.is_ready.set", "base.NLPServer.logger.info", "base.NLPServer.logger.info", "_sock.send_multipart", "utils.auto_bind", "base.NLPServer.Worker", "base.NLPServer.processes.append", "base.NLPServer.start", "p.is_ready.wait", "p.close", "sink.recv", "frontend.recv_multipart", "base.ServerStatistic.update", "len", "base.NLPServer.logger.error", "base.NLPServer.logger.error", "base.NLPServer.logger.info", "sink.send_multipart", "base.NLPServer.logger.info", "sink.send_multipart", "random.choice", "len", "client.decode", "len", "str", "int", "zmq.utils.jsonapi.loads", "zmq.utils.jsonapi.loads", "range", "base.NLPServer._run.push_new_job"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor.multi_socket", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.auto_bind", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.auto_bind", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PULL", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PAIR", ")", "\n", "@", "multi_socket", "(", "zmq", ".", "PUSH", ",", "num_socket", "=", "'n_concurrent_sockets'", ")", "\n", "def", "_run", "(", "self", ",", "_", ",", "frontend", ",", "sink", ",", "*", "backend_socks", ")", ":", "\n", "\n", "        ", "def", "push_new_job", "(", "_job_id", ",", "_json_msg", ",", "_msg_len", ")", ":", "\n", "            ", "_sock", "=", "rand_backend_socket", "\n", "_sock", ".", "send_multipart", "(", "[", "_job_id", ",", "_json_msg", "]", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "f'Bind all sockets. Use ports '", "\n", "f'{self.port}/{self.port_out}'", ")", "\n", "frontend", ".", "bind", "(", "f'tcp://*:{self.port}'", ")", "\n", "addr_front2sink", "=", "auto_bind", "(", "sink", ")", "\n", "addr_backend_list", "=", "[", "auto_bind", "(", "b", ")", "for", "b", "in", "backend_socks", "]", "\n", "self", ".", "logger", ".", "info", "(", "f'open {len(addr_backend_list)} ventilator-worker '", "\n", "'sockets'", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Start the sink'", ")", "\n", "proc_sink", "=", "Sink", "(", "self", ".", "port_out", ",", "addr_front2sink", ")", "\n", "self", ".", "processes", ".", "append", "(", "proc_sink", ")", "\n", "proc_sink", ".", "start", "(", ")", "\n", "addr_sink", "=", "sink", ".", "recv", "(", ")", ".", "decode", "(", "'ascii'", ")", "\n", "\n", "# start the backend processes", "\n", "device_map", "=", "[", "-", "1", "]", "*", "self", ".", "n_workers", "\n", "for", "idx", ",", "device_id", "in", "enumerate", "(", "device_map", ")", ":", "\n", "            ", "process", "=", "self", ".", "Worker", "(", "idx", ",", "addr_backend_list", ",", "addr_sink", ")", "\n", "self", ".", "processes", ".", "append", "(", "process", ")", "\n", "process", ".", "start", "(", ")", "\n", "\n", "", "rand_backend_socket", "=", "None", "\n", "server_status", "=", "ServerStatistic", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "processes", ":", "\n", "            ", "p", ".", "is_ready", ".", "wait", "(", ")", "\n", "\n", "", "self", ".", "is_ready", ".", "set", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'all set, ready to serve request!'", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "request", "=", "frontend", ".", "recv_multipart", "(", ")", "\n", "client", ",", "msg", ",", "req_id", ",", "msg_len", "=", "request", "\n", "", "except", "ValueError", ":", "\n", "                ", "self", ".", "logger", ".", "error", "(", "\n", "'received a wrongly-formatted request (expected 4 frames, got %d)'", "%", "len", "(", "request", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "'\\n'", ".", "join", "(", "'field %d: %s'", "%", "(", "idx", ",", "k", ")", "\n", "for", "idx", ",", "k", "in", "enumerate", "(", "request", ")", ")", ",", "exc_info", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "server_status", ".", "update", "(", "request", ")", "\n", "if", "msg", "==", "ServerCmd", ".", "terminate", ":", "\n", "                    ", "break", "\n", "", "elif", "msg", "==", "ServerCmd", ".", "show_config", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "\n", "'new config request\\treq id: %d\\tclient: %s'", "%", "(", "int", "(", "req_id", ")", ",", "client", ")", ")", "\n", "status_runtime", "=", "{", "'client'", ":", "client", ".", "decode", "(", "'ascii'", ")", ",", "\n", "'num_process'", ":", "len", "(", "self", ".", "processes", ")", ",", "\n", "'ventilator -> worker'", ":", "addr_backend_list", ",", "\n", "'worker -> sink'", ":", "addr_sink", ",", "\n", "'ventilator <-> sink'", ":", "addr_front2sink", ",", "\n", "'server_current_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "'statistic'", ":", "server_status", ".", "value", ",", "\n", "'device_map'", ":", "device_map", ",", "\n", "'n_concurrent_sockets'", ":", "self", ".", "n_concurrent_sockets", "}", "\n", "\n", "sink", ".", "send_multipart", "(", "[", "client", ",", "msg", ",", "jsonapi", ".", "dumps", "(", "{", "**", "status_runtime", ",", "\n", "**", "self", ".", "status_static", "}", ")", ",", "req_id", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "'new encode request\\treq id: %d\\tsize: %d\\tclient: %s'", "%", "\n", "(", "int", "(", "req_id", ")", ",", "int", "(", "msg_len", ")", ",", "client", ")", ")", "\n", "# register a new job at sink", "\n", "sink", ".", "send_multipart", "(", "\n", "[", "client", ",", "ServerCmd", ".", "new_job", ",", "msg_len", ",", "req_id", "]", ")", "\n", "\n", "# renew the backend socket to prevent large job queueing up", "\n", "# [0] is reserved for high priority job", "\n", "# last used backennd shouldn't be selected either as it may be queued up already", "\n", "rand_backend_socket", "=", "random", ".", "choice", "(", "\n", "[", "b", "for", "b", "in", "backend_socks", "[", "1", ":", "]", "if", "b", "!=", "rand_backend_socket", "]", ")", "\n", "\n", "# push a new job, note super large job will be pushed to one socket only,", "\n", "# leaving other sockets free", "\n", "job_id", "=", "client", "+", "b'#'", "+", "req_id", "\n", "if", "int", "(", "msg_len", ")", ">", "self", ".", "max_batch_size", ":", "\n", "                        ", "seqs", "=", "jsonapi", ".", "loads", "(", "msg", ")", "\n", "job_gen", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "int", "(", "msg_len", ")", ",", "self", ".", "max_batch_size", ")", ":", "\n", "                            ", "pid", "=", "job_id", "+", "b'@%d'", "%", "i", "\n", "pjob", "=", "seqs", "[", "i", ":", "(", "i", "+", "self", ".", "max_batch_size", ")", "]", "\n", "job_gen", ".", "append", "(", "(", "pid", ",", "pjob", ")", ")", "\n", "\n", "", "for", "partial_job_id", ",", "job", "in", "job_gen", ":", "\n", "                            ", "push_new_job", "(", "partial_job_id", ",", "\n", "jsonapi", ".", "dumps", "(", "job", ")", ",", "len", "(", "job", ")", ")", "\n", "", "", "else", ":", "\n", "                        ", "push_new_job", "(", "job_id", ",", "msg", ",", "int", "(", "msg_len", ")", ")", "\n", "\n", "", "", "", "", "for", "p", "in", "self", ".", "processes", ":", "\n", "            ", "p", ".", "close", "(", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "'terminated!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.Sink.__init__": [[195, 203], ["torch.multiprocessing.Process.__init__", "torch.multiprocessing.Event", "utils.set_logger", "torch.multiprocessing.Event", "termcolor.colored"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger"], ["    ", "def", "__init__", "(", "self", ",", "port_out", ",", "front_sink_addr", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "port", "=", "port_out", "\n", "self", ".", "exit_flag", "=", "Event", "(", ")", "\n", "self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'SINK'", ",", "'green'", ")", ",", "verbose", ")", "\n", "self", ".", "front_sink_addr", "=", "front_sink_addr", "\n", "self", ".", "is_ready", "=", "Event", "(", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.Sink.close": [[204, 211], ["base.Sink.logger.info", "base.Sink.is_ready.clear", "base.Sink.exit_flag.set", "base.Sink.terminate", "base.Sink.join", "base.Sink.logger.info"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'shutting down...'", ")", "\n", "self", ".", "is_ready", ".", "clear", "(", ")", "\n", "self", ".", "exit_flag", ".", "set", "(", ")", "\n", "self", ".", "terminate", "(", ")", "\n", "self", ".", "join", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'terminated!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.Sink.run": [[212, 214], ["base.Sink._run"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker._run"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "_run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.Sink._run": [[215, 288], ["zmq.socket", "zmq.socket", "zmq.socket", "zmq.socket", "zmq.socket", "zmq.socket", "utils.auto_bind", "frontend.connect", "sender.bind", "collections.defaultdict", "zmq.Poller", "zmq.Poller", "zmq.Poller", "zmq.Poller", "zmq.Poller.register", "zmq.Poller.register", "zmq.Poller.register", "zmq.Poller.register", "frontend.send", "utils.set_logger", "utils.set_logger.info", "base.Sink.is_ready.set", "utils.auto_bind.encode", "termcolor.colored", "base.Sink.exit_flag.is_set", "dict", "base.SinkJob", "zmq.Poller.poll", "zmq.Poller.poll", "dict.get", "receiver.recv_multipart", "job_id.split", "utils.set_logger.info", "dict.get", "frontend.recv_multipart", "int", "zmq.utils.jsonapi.loads", "zmq.utils.jsonapi.loads", "pending_jobs[].add_output", "utils.set_logger.error", "utils.set_logger.error", "job_id.split.split", "sender.send_multipart", "utils.set_logger.info", "tmp.clear", "pending_jobs.pop", "int", "utils.set_logger.info", "len", "pending_jobs.items", "time.sleep", "utils.set_logger.info", "sender.send_multipart", "len", "int", "enumerate"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.auto_bind", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.add_output", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PULL", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PAIR", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PUB", ")", "\n", "def", "_run", "(", "self", ",", "receiver", ",", "frontend", ",", "sender", ")", ":", "\n", "        ", "receiver_addr", "=", "auto_bind", "(", "receiver", ")", "\n", "frontend", ".", "connect", "(", "self", ".", "front_sink_addr", ")", "\n", "sender", ".", "bind", "(", "'tcp://*:%d'", "%", "self", ".", "port", ")", "\n", "\n", "pending_jobs", ":", "Dict", "[", "str", ",", "SinkJob", "]", "=", "defaultdict", "(", "lambda", ":", "SinkJob", "(", ")", ")", "\n", "\n", "poller", "=", "zmq", ".", "Poller", "(", ")", "\n", "poller", ".", "register", "(", "frontend", ",", "zmq", ".", "POLLIN", ")", "\n", "poller", ".", "register", "(", "receiver", ",", "zmq", ".", "POLLIN", ")", "\n", "\n", "# send worker receiver address back to frontend", "\n", "frontend", ".", "send", "(", "receiver_addr", ".", "encode", "(", "'ascii'", ")", ")", "\n", "\n", "# Windows does not support logger in MP environment, thus get a new logger", "\n", "# inside the process for better compability", "\n", "logger", "=", "set_logger", "(", "colored", "(", "'SINK'", ",", "'green'", ")", ",", "self", ".", "verbose", ")", "\n", "logger", ".", "info", "(", "'ready'", ")", "\n", "self", ".", "is_ready", ".", "set", "(", ")", "\n", "\n", "while", "not", "self", ".", "exit_flag", ".", "is_set", "(", ")", ":", "\n", "            ", "socks", "=", "dict", "(", "poller", ".", "poll", "(", ")", ")", "\n", "if", "socks", ".", "get", "(", "receiver", ")", "==", "zmq", ".", "POLLIN", ":", "\n", "                ", "msg", "=", "receiver", ".", "recv_multipart", "(", ")", "\n", "job_id", "=", "msg", "[", "0", "]", "\n", "# parsing job_id and partial_id", "\n", "job_info", "=", "job_id", ".", "split", "(", "b'@'", ")", "\n", "job_id", "=", "job_info", "[", "0", "]", "\n", "partial_id", "=", "int", "(", "job_info", "[", "1", "]", ")", "if", "len", "(", "job_info", ")", "==", "2", "else", "0", "\n", "\n", "if", "msg", "[", "2", "]", "==", "ServerCmd", ".", "data_embed", ":", "\n", "                    ", "x", "=", "jsonapi", ".", "loads", "(", "msg", "[", "1", "]", ")", "\n", "pending_jobs", "[", "job_id", "]", ".", "add_output", "(", "x", ",", "partial_id", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "'received a wrongly-formatted request (expected 4 frames, got %d)'", "%", "len", "(", "msg", ")", ")", "\n", "logger", ".", "error", "(", "'\\n'", ".", "join", "(", "'field %d: %s'", "%", "(", "idx", ",", "k", ")", "\n", "for", "idx", ",", "k", "in", "enumerate", "(", "msg", ")", ")", ",", "exc_info", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "'collect %s %s (E:%d/A:%d)'", "%", "(", "msg", "[", "2", "]", ",", "job_id", ",", "\n", "pending_jobs", "[", "job_id", "]", ".", "progress_outputs", ",", "\n", "pending_jobs", "[", "job_id", "]", ".", "checksum", ")", ")", "\n", "\n", "# check if there are finished jobs, then send it back to workers", "\n", "\n", "finished", "=", "[", "(", "k", ",", "v", ")", "\n", "for", "k", ",", "v", "in", "pending_jobs", ".", "items", "(", ")", "if", "v", ".", "is_done", "]", "\n", "for", "job_info", ",", "tmp", "in", "finished", ":", "\n", "                    ", "client_addr", ",", "req_id", "=", "job_info", ".", "split", "(", "b'#'", ")", "\n", "x", "=", "tmp", ".", "result", "\n", "sender", ".", "send_multipart", "(", "[", "client_addr", ",", "x", ",", "req_id", "]", ")", "\n", "logger", ".", "info", "(", "'send back\\tsize: %d\\tjob id: %s'", "%", "\n", "(", "tmp", ".", "checksum", ",", "job_info", ")", ")", "\n", "# release the job", "\n", "tmp", ".", "clear", "(", ")", "\n", "pending_jobs", ".", "pop", "(", "job_info", ")", "\n", "\n", "", "", "if", "socks", ".", "get", "(", "frontend", ")", "==", "zmq", ".", "POLLIN", ":", "\n", "                ", "client_addr", ",", "msg_type", ",", "msg_info", ",", "req_id", "=", "frontend", ".", "recv_multipart", "(", ")", "\n", "if", "msg_type", "==", "ServerCmd", ".", "new_job", ":", "\n", "                    ", "job_info", "=", "client_addr", "+", "b'#'", "+", "req_id", "\n", "# register a new job", "\n", "pending_jobs", "[", "job_info", "]", ".", "checksum", "=", "int", "(", "msg_info", ")", "\n", "logger", ".", "info", "(", "'job register\\tsize: %d\\tjob id: %s'", "%", "\n", "(", "int", "(", "msg_info", ")", ",", "job_info", ")", ")", "\n", "", "elif", "msg_type", "==", "ServerCmd", ".", "show_config", ":", "\n", "# dirty fix of slow-joiner: sleep so that client receiver can connect.", "\n", "                    ", "time", ".", "sleep", "(", "0.1", ")", "\n", "logger", ".", "info", "(", "'send config\\tclient %s'", "%", "client_addr", ")", "\n", "sender", ".", "send_multipart", "(", "[", "client_addr", ",", "msg_info", ",", "req_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.__init__": [[291, 296], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "outputs", "=", "[", "]", "\n", "self", ".", "output_ids", "=", "[", "]", "\n", "self", ".", "checksum", "=", "0", "# message length", "\n", "self", ".", "progress_outputs", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear": [[297, 299], ["base.SinkJob.outputs.clear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "outputs", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.add_output": [[300, 305], ["len", "base.SinkJob.outputs.append", "base.SinkJob.output_ids.append"], "methods", ["None"], ["", "def", "add_output", "(", "self", ",", "data", ",", "pid", ")", ":", "\n", "        ", "progress", "=", "len", "(", "data", ")", "\n", "self", ".", "outputs", ".", "append", "(", "data", ")", "\n", "self", ".", "output_ids", ".", "append", "(", "pid", ")", "\n", "self", ".", "progress_outputs", "+=", "progress", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.is_done": [[306, 309], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "checksum", ">", "0", "and", "self", ".", "checksum", "==", "self", ".", "progress_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.result": [[310, 317], ["numpy.argsort", "[].tolist", "zmq.utils.jsonapi.dumps", "zmq.utils.jsonapi.dumps", "numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "result", "(", "self", ")", ":", "\n", "# Sort the results", "\n", "        ", "sort_idx", "=", "np", ".", "argsort", "(", "self", ".", "output_ids", ")", "\n", "outputs", "=", "np", ".", "array", "(", "self", ".", "outputs", ")", "[", "sort_idx", "]", ".", "tolist", "(", ")", "\n", "outputs", "=", "[", "elem", "for", "output", "in", "outputs", "for", "elem", "in", "output", "]", "\n", "return", "jsonapi", ".", "dumps", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.__init__": [[320, 330], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "time.perf_counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_hist_client", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_hist_msg_len", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "_client_last_active_time", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "_num_data_req", "=", "0", "\n", "self", ".", "_num_sys_req", "=", "0", "\n", "self", ".", "_num_total_seq", "=", "0", "\n", "self", ".", "_last_req_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_last_two_req_interval", "=", "[", "]", "\n", "self", ".", "_num_last_two_req", "=", "200", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update": [[331, 348], ["utils.ServerCmd.is_valid", "int", "time.perf_counter", "len", "base.ServerStatistic._last_two_req_interval.append", "base.ServerStatistic._last_two_req_interval.pop", "int"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.ServerCmd.is_valid"], ["", "def", "update", "(", "self", ",", "request", ")", ":", "\n", "        ", "client", ",", "msg", ",", "req_id", ",", "msg_len", "=", "request", "\n", "self", ".", "_hist_client", "[", "client", "]", "+=", "1", "\n", "if", "ServerCmd", ".", "is_valid", "(", "msg", ")", ":", "\n", "            ", "self", ".", "_num_sys_req", "+=", "1", "\n", "# do not count for system request, as they are mainly for heartbeats", "\n", "", "else", ":", "\n", "            ", "self", ".", "_hist_msg_len", "[", "int", "(", "msg_len", ")", "]", "+=", "1", "\n", "self", ".", "_num_total_seq", "+=", "int", "(", "msg_len", ")", "\n", "self", ".", "_num_data_req", "+=", "1", "\n", "tmp", "=", "time", ".", "perf_counter", "(", ")", "\n", "self", ".", "_client_last_active_time", "[", "client", "]", "=", "tmp", "\n", "if", "len", "(", "self", ".", "_last_two_req_interval", ")", "<", "self", ".", "_num_last_two_req", ":", "\n", "                ", "self", ".", "_last_two_req_interval", ".", "append", "(", "tmp", "-", "self", ".", "_last_req_time", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_last_two_req_interval", ".", "pop", "(", "0", ")", "\n", "", "self", ".", "_last_req_time", "=", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.value": [[349, 383], ["time.perf_counter", "sum", "base.ServerStatistic.value.get_min_max_avg"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "value", "(", "self", ")", ":", "\n", "        ", "def", "get_min_max_avg", "(", "name", ",", "stat", ")", ":", "\n", "            ", "if", "len", "(", "stat", ")", ">", "0", ":", "\n", "                ", "return", "{", "\n", "'avg_%s'", "%", "name", ":", "sum", "(", "stat", ")", "/", "len", "(", "stat", ")", ",", "\n", "'min_%s'", "%", "name", ":", "min", "(", "stat", ")", ",", "\n", "'max_%s'", "%", "name", ":", "max", "(", "stat", ")", ",", "\n", "'num_min_%s'", "%", "name", ":", "sum", "(", "v", "==", "min", "(", "stat", ")", "for", "v", "in", "stat", ")", ",", "\n", "'num_max_%s'", "%", "name", ":", "sum", "(", "v", "==", "max", "(", "stat", ")", "for", "v", "in", "stat", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "                ", "return", "{", "}", "\n", "\n", "", "", "def", "get_num_active_client", "(", "interval", "=", "180", ")", ":", "\n", "# we count a client active when its last request is within 3 min.", "\n", "            ", "now", "=", "time", ".", "perf_counter", "(", ")", "\n", "return", "sum", "(", "1", "for", "v", "in", "self", ".", "_client_last_active_time", ".", "values", "(", ")", "if", "(", "now", "-", "v", ")", "<", "interval", ")", "\n", "\n", "", "parts", "=", "[", "{", "\n", "'num_data_request'", ":", "self", ".", "_num_data_req", ",", "\n", "'num_total_seq'", ":", "self", ".", "_num_total_seq", ",", "\n", "'num_sys_request'", ":", "self", ".", "_num_sys_req", ",", "\n", "'num_total_request'", ":", "self", ".", "_num_data_req", "+", "self", ".", "_num_sys_req", ",", "\n", "'num_total_client'", ":", "len", "(", "self", ".", "_hist_client", ")", ",", "\n", "'num_active_client'", ":", "get_num_active_client", "(", ")", "}", ",", "\n", "get_min_max_avg", "(", "'request_per_client'", ",", "self", ".", "_hist_client", ".", "values", "(", ")", ")", ",", "\n", "get_min_max_avg", "(", "'size_per_request'", ",", "self", ".", "_hist_msg_len", ".", "keys", "(", ")", ")", ",", "\n", "get_min_max_avg", "(", "'last_two_interval'", ",", "self", ".", "_last_two_req_interval", ")", ",", "\n", "get_min_max_avg", "(", "'request_per_second'", ",", "[", "\n", "1.", "/", "v", "for", "v", "in", "self", ".", "_last_two_req_interval", "]", ")", ",", "\n", "]", "\n", "\n", "return", "{", "k", ":", "v", "for", "d", "in", "parts", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._MyDecorator.__call__": [[13, 32], ["zmq_decor._MyDecorator.process_decorator_args", "dec_kwargs.pop", "functools.wraps", "getattr", "zmq_decor._MyDecorator.get_target", "contextlib.ExitStack", "func", "range", "stack.enter_context", "target"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator.process_decorator_args", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator.get_target"], ["    ", "def", "__call__", "(", "self", ",", "*", "dec_args", ",", "**", "dec_kwargs", ")", ":", "\n", "        ", "kw_name", ",", "dec_args", ",", "dec_kwargs", "=", "self", ".", "process_decorator_args", "(", "*", "dec_args", ",", "**", "dec_kwargs", ")", "\n", "num_socket_str", "=", "dec_kwargs", ".", "pop", "(", "'num_socket'", ")", "\n", "\n", "def", "decorator", "(", "func", ")", ":", "\n", "            ", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "num_socket", "=", "getattr", "(", "args", "[", "0", "]", ",", "num_socket_str", ")", "\n", "targets", "=", "[", "self", ".", "get_target", "(", "*", "args", ",", "**", "kwargs", ")", "for", "_", "in", "range", "(", "num_socket", ")", "]", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "                    ", "for", "target", "in", "targets", ":", "\n", "                        ", "obj", "=", "stack", ".", "enter_context", "(", "target", "(", "*", "dec_args", ",", "**", "dec_kwargs", ")", ")", "\n", "args", "=", "args", "+", "(", "obj", ",", ")", "\n", "\n", "", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "wrapper", "\n", "\n", "", "return", "decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator.process_decorator_args": [[35, 40], ["super().process_decorator_args", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator.process_decorator_args"], ["    ", "def", "process_decorator_args", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Also grab context_name out of kwargs\"\"\"", "\n", "kw_name", ",", "args", ",", "kwargs", "=", "super", "(", "_SocketDecorator", ",", "self", ")", ".", "process_decorator_args", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "context_name", "=", "kwargs", ".", "pop", "(", "'context_name'", ",", "'context'", ")", "\n", "return", "kw_name", ",", "args", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator.get_target": [[41, 45], ["zmq_decor._SocketDecorator._get_context"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator._get_context"], ["", "def", "get_target", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Get context, based on call-time args\"\"\"", "\n", "context", "=", "self", ".", "_get_context", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "context", ".", "socket", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor._SocketDecorator._get_context": [[46, 58], ["zmq.Context.instance", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "_get_context", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "context_name", "in", "kwargs", ":", "\n", "            ", "ctx", "=", "kwargs", "[", "self", ".", "context_name", "]", "\n", "\n", "if", "isinstance", "(", "ctx", ",", "zmq", ".", "Context", ")", ":", "\n", "                ", "return", "ctx", "\n", "\n", "", "", "for", "arg", "in", "args", ":", "\n", "            ", "if", "isinstance", "(", "arg", ",", "zmq", ".", "Context", ")", ":", "\n", "                ", "return", "arg", "\n", "# not specified by any decorator", "\n", "", "", "return", "zmq", ".", "Context", ".", "instance", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor.multi_socket": [[60, 62], ["zmq_decor._SocketDecorator"], "function", ["None"], ["", "", "def", "multi_socket", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "_SocketDecorator", "(", ")", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.__main__.validate": [[27, 41], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Use", "schema.Use", "schema.Use", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'n_workers'", ":", "Use", "(", "int", ")", ",", "\n", "'port'", ":", "Use", "(", "int", ")", ",", "\n", "'port_out'", ":", "Use", "(", "int", ")", ",", "\n", "object", ":", "object", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "args", "[", "'debug'", "]", "=", "args", "[", "'ptvsd'", "]", "or", "args", "[", "'pudb'", "]", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.__main__.main": [[43, 58], ["docopt.docopt", "__main__.validate", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "base.NLPServer", "server.join", "pudb.set_trace"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "", "elif", "args", "[", "'pudb'", "]", ":", "\n", "        ", "pudb", ".", "set_trace", "(", ")", "\n", "\n", "", "with", "NLPServer", "(", "task", "=", "args", "[", "'task'", "]", ",", "\n", "n_workers", "=", "args", "[", "'n_workers'", "]", ",", "\n", "port", "=", "args", "[", "'port'", "]", ",", "\n", "port_out", "=", "args", "[", "'port_out'", "]", ")", "as", "server", ":", "\n", "        ", "server", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.http.BertHTTPProxy.__init__": [[9, 13], ["multiprocessing.Process.__init__", "multiprocessing.Event"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "is_ready", "=", "Event", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.http.BertHTTPProxy.create_flask_app": [[14, 61], ["ConcurrentBertClient", "Flask", "utils.set_logger", "Flask.route", "Flask.route", "Flask.route", "CORS", "FlaskJSON", "Compress().init_app", "termcolor.colored", "ImportError", "utils.set_logger.info", "Compress", "ConcurrentBertClient.encode", "utils.set_logger.error", "JsonError", "str", "str", "bool", "type"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error"], ["", "def", "create_flask_app", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "flask", "import", "Flask", ",", "request", "\n", "from", "flask_compress", "import", "Compress", "\n", "from", "flask_cors", "import", "CORS", "\n", "from", "flask_json", "import", "FlaskJSON", ",", "as_json", ",", "JsonError", "\n", "from", "bert_serving", ".", "client", "import", "ConcurrentBertClient", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "'BertClient or Flask or its dependencies are not fully installed, '", "\n", "'they are required for serving HTTP requests.'", "\n", "'Please use \"pip install -U bert-serving-server[http]\" to install it.'", ")", "\n", "\n", "# support up to 10 concurrent HTTP requests", "\n", "", "bc", "=", "ConcurrentBertClient", "(", "max_concurrency", "=", "self", ".", "args", ".", "http_max_connect", ",", "\n", "port", "=", "self", ".", "args", ".", "port", ",", "port_out", "=", "self", ".", "args", ".", "port_out", ",", "\n", "output_fmt", "=", "'list'", ")", "\n", "app", "=", "Flask", "(", "__name__", ")", "\n", "logger", "=", "set_logger", "(", "colored", "(", "'PROXY'", ",", "'red'", ")", ")", "\n", "\n", "@", "app", ".", "route", "(", "'/status/server'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "@", "as_json", "\n", "def", "get_server_status", "(", ")", ":", "\n", "            ", "return", "bc", ".", "server_status", "\n", "\n", "", "@", "app", ".", "route", "(", "'/status/client'", ",", "methods", "=", "[", "'GET'", "]", ")", "\n", "@", "as_json", "\n", "def", "get_client_status", "(", ")", ":", "\n", "            ", "return", "bc", ".", "status", "\n", "\n", "", "@", "app", ".", "route", "(", "'/encode'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "@", "as_json", "\n", "def", "encode_query", "(", ")", ":", "\n", "            ", "data", "=", "request", ".", "form", "if", "request", ".", "form", "else", "request", ".", "json", "\n", "try", ":", "\n", "                ", "logger", ".", "info", "(", "'new request from %s'", "%", "request", ".", "remote_addr", ")", "\n", "return", "{", "'id'", ":", "data", "[", "'id'", "]", ",", "\n", "'result'", ":", "bc", ".", "encode", "(", "data", "[", "'texts'", "]", ",", "is_tokenized", "=", "bool", "(", "\n", "data", "[", "'is_tokenized'", "]", ")", "if", "'is_tokenized'", "in", "data", "else", "False", ")", "}", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "logger", ".", "error", "(", "'error when handling HTTP request'", ",", "exc_info", "=", "True", ")", "\n", "raise", "JsonError", "(", "description", "=", "str", "(", "e", ")", ",", "type", "=", "str", "(", "type", "(", "e", ")", ".", "__name__", ")", ")", "\n", "\n", "", "", "CORS", "(", "app", ",", "origins", "=", "self", ".", "args", ".", "cors", ")", "\n", "FlaskJSON", "(", "app", ")", "\n", "Compress", "(", ")", ".", "init_app", "(", "app", ")", "\n", "return", "app", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.http.BertHTTPProxy.run": [[62, 66], ["http.BertHTTPProxy.create_flask_app", "http.BertHTTPProxy.is_ready.set", "http.BertHTTPProxy.run"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.http.BertHTTPProxy.create_flask_app", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.run"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "app", "=", "self", ".", "create_flask_app", "(", ")", "\n", "self", ".", "is_ready", ".", "set", "(", ")", "\n", "app", ".", "run", "(", "port", "=", "self", ".", "args", ".", "http_port", ",", "threaded", "=", "True", ",", "host", "=", "'0.0.0.0'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.ServerCmd.is_valid": [[15, 18], ["any", "vars().items", "k.startswith", "vars"], "methods", ["None"], ["from", "tqdm", "import", "tqdm", "\n", "\n", "from", ".", "import", "torch_utils", "# , google_utils", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.__init__": [[37, 40], ["None"], "methods", ["None"], ["torch_utils", ".", "init_seeds", "(", "seed", "=", "seed", ")", "\n", "\n", "\n", "", "def", "load_classes", "(", "path", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info": [[41, 43], ["print"], "methods", ["None"], ["# Loads *.names file at 'path'", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "names", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.debug": [[44, 47], ["print"], "methods", ["None"], ["# filter removes empty strings (such as last line)", "\n", "", "return", "list", "(", "filter", "(", "None", ",", "names", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.error": [[48, 50], ["print"], "methods", ["None"], ["", "def", "labels_to_class_weights", "(", "labels", ",", "nc", "=", "80", ")", ":", "\n", "# Get class weights (inverse frequency) from training labels", "\n", "    ", "if", "labels", "[", "0", "]", "is", "None", ":", "# no labels loaded", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning": [[51, 53], ["print"], "methods", ["None"], ["        ", "return", "torch", ".", "Tensor", "(", ")", "\n", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "# labels.shape = (866643, 5) for COCO", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger": [[20, 34], ["logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "utils.NTLogger"], "function", ["None"], ["\n", "# Set printoptions", "\n", "torch", ".", "set_printoptions", "(", "linewidth", "=", "320", ",", "precision", "=", "5", ",", "profile", "=", "'long'", ")", "\n", "# format short g, %precision=5", "\n", "np", ".", "set_printoptions", "(", "linewidth", "=", "320", ",", "formatter", "=", "{", "'float_kind'", ":", "'{:11.5g}'", ".", "format", "}", ")", "\n", "\n", "# Prevent OpenCV from multithreading (to use PyTorch DataLoader)", "\n", "cv2", ".", "setNumThreads", "(", "0", ")", "\n", "\n", "\n", "def", "floatn", "(", "x", ",", "n", "=", "3", ")", ":", "# format floats to n decimals", "\n", "    ", "return", "float", "(", "format", "(", "x", ",", "'.%gf'", "%", "n", ")", ")", "\n", "\n", "\n", "", "def", "init_seeds", "(", "seed", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.auto_bind": [[55, 72], ["socket.getsockopt().decode", "socket.bind_to_random_port", "socket.bind", "os.path.join", "socket.getsockopt", "os.path.exists", "ValueError", "os.makedirs", "os.path.join", "str", "uuid.uuid1", "str", "uuid.uuid1"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["weights", "=", "np", ".", "bincount", "(", "classes", ",", "minlength", "=", "nc", ")", "# occurences per class", "\n", "\n", "# Prepend gridpoint count (for uCE trianing)", "\n", "# gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image", "\n", "# weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start", "\n", "\n", "weights", "[", "weights", "==", "0", "]", "=", "1", "# replace empty bins with 1", "\n", "weights", "=", "1", "/", "weights", "# number of targets per class", "\n", "weights", "/=", "weights", ".", "sum", "(", ")", "# normalize", "\n", "return", "torch", ".", "from_numpy", "(", "weights", ")", "\n", "\n", "\n", "", "def", "labels_to_image_weights", "(", "labels", ",", "nc", "=", "80", ",", "class_weights", "=", "np", ".", "ones", "(", "80", ")", ")", ":", "\n", "# Produces image weights based on class mAPs", "\n", "    ", "n", "=", "len", "(", "labels", ")", "\n", "class_counts", "=", "np", ".", "array", "(", "\n", "[", "np", ".", "bincount", "(", "labels", "[", "i", "]", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", ",", "minlength", "=", "nc", ")", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "image_weights", "=", "(", "class_weights", ".", "reshape", "(", "1", ",", "nc", ")", "*", "class_counts", ")", ".", "sum", "(", "1", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.send_ndarray": [[74, 78], ["dict", "src.send_multipart", "str", "jsonapi.dumps"], "function", ["None"], ["return", "image_weights", "\n", "\n", "\n", "", "def", "coco_class_weights", "(", ")", ":", "# frequency of each class in coco train2014", "\n", "    ", "n", "=", "[", "187437", ",", "4955", ",", "30920", ",", "6033", ",", "3838", ",", "4332", ",", "3160", ",", "7051", ",", "7677", ",", "9167", ",", "1316", ",", "1372", ",", "833", ",", "6757", ",", "7355", ",", "3302", ",", "3776", ",", "4671", ",", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.PNet.__init__": [[18, 39], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.Conv2d", "torch.nn.Softmax", "torch.nn.Conv2d", "os.path.join", "torch.load", "mtcnn.PNet.load_state_dict", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["def", "__init__", "(", "self", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "10", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu1", "=", "nn", ".", "PReLU", "(", "10", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "10", ",", "16", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu2", "=", "nn", ".", "PReLU", "(", "16", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu3", "=", "nn", ".", "PReLU", "(", "32", ")", "\n", "self", ".", "conv4_1", "=", "nn", ".", "Conv2d", "(", "32", ",", "2", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "softmax4_1", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "conv4_2", "=", "nn", ".", "Conv2d", "(", "32", ",", "4", ",", "kernel_size", "=", "1", ")", "\n", "\n", "self", ".", "training", "=", "False", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "state_dict_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'data/pnet.pt'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "state_dict_path", ")", "\n", "self", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.PNet.forward": [[40, 52], ["mtcnn.PNet.conv1", "mtcnn.PNet.prelu1", "mtcnn.PNet.pool1", "mtcnn.PNet.conv2", "mtcnn.PNet.prelu2", "mtcnn.PNet.conv3", "mtcnn.PNet.prelu3", "mtcnn.PNet.conv4_1", "mtcnn.PNet.softmax4_1", "mtcnn.PNet.conv4_2", "mtcnn.PNet.cpu", "mtcnn.PNet.cpu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu1", "(", "x", ")", "\n", "x", "=", "self", ".", "pool1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu3", "(", "x", ")", "\n", "a", "=", "self", ".", "conv4_1", "(", "x", ")", "\n", "a", "=", "self", ".", "softmax4_1", "(", "a", ")", "\n", "b", "=", "self", ".", "conv4_2", "(", "x", ")", "\n", "return", "b", ".", "cpu", "(", ")", ",", "a", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.RNet.__init__": [[61, 85], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.Linear", "torch.nn.PReLU", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Linear", "os.path.join", "torch.load", "mtcnn.RNet.load_state_dict", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["def", "__init__", "(", "self", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "28", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu1", "=", "nn", ".", "PReLU", "(", "28", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "28", ",", "48", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu2", "=", "nn", ".", "PReLU", "(", "48", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "48", ",", "64", ",", "kernel_size", "=", "2", ")", "\n", "self", ".", "prelu3", "=", "nn", ".", "PReLU", "(", "64", ")", "\n", "self", ".", "dense4", "=", "nn", ".", "Linear", "(", "576", ",", "128", ")", "\n", "self", ".", "prelu4", "=", "nn", ".", "PReLU", "(", "128", ")", "\n", "self", ".", "dense5_1", "=", "nn", ".", "Linear", "(", "128", ",", "2", ")", "\n", "self", ".", "softmax5_1", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "dense5_2", "=", "nn", ".", "Linear", "(", "128", ",", "4", ")", "\n", "\n", "self", ".", "training", "=", "False", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "state_dict_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'./data/rnet.pt'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "state_dict_path", ")", "\n", "self", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.RNet.forward": [[86, 102], ["mtcnn.RNet.conv1", "mtcnn.RNet.prelu1", "mtcnn.RNet.pool1", "mtcnn.RNet.conv2", "mtcnn.RNet.prelu2", "mtcnn.RNet.pool2", "mtcnn.RNet.conv3", "mtcnn.RNet.prelu3", "mtcnn.RNet.permute().contiguous", "mtcnn.RNet.dense4", "mtcnn.RNet.prelu4", "mtcnn.RNet.dense5_1", "mtcnn.RNet.softmax5_1", "mtcnn.RNet.dense5_2", "mtcnn.RNet.view", "mtcnn.RNet.cpu", "mtcnn.RNet.cpu", "mtcnn.RNet.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu1", "(", "x", ")", "\n", "x", "=", "self", ".", "pool1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu2", "(", "x", ")", "\n", "x", "=", "self", ".", "pool2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu3", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "dense4", "(", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "prelu4", "(", "x", ")", "\n", "a", "=", "self", ".", "dense5_1", "(", "x", ")", "\n", "a", "=", "self", ".", "softmax5_1", "(", "a", ")", "\n", "b", "=", "self", ".", "dense5_2", "(", "x", ")", "\n", "return", "b", ".", "cpu", "(", ")", ",", "a", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.ONet.__init__": [[111, 139], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.PReLU", "torch.nn.Linear", "torch.nn.PReLU", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Linear", "torch.nn.Linear", "os.path.join", "torch.load", "mtcnn.ONet.load_state_dict", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["def", "__init__", "(", "self", ",", "pretrained", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu1", "=", "nn", ".", "PReLU", "(", "32", ")", "\n", "self", ".", "pool1", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu2", "=", "nn", ".", "PReLU", "(", "64", ")", "\n", "self", ".", "pool2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ")", "\n", "self", ".", "prelu3", "=", "nn", ".", "PReLU", "(", "64", ")", "\n", "self", ".", "pool3", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ",", "ceil_mode", "=", "True", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "2", ")", "\n", "self", ".", "prelu4", "=", "nn", ".", "PReLU", "(", "128", ")", "\n", "self", ".", "dense5", "=", "nn", ".", "Linear", "(", "1152", ",", "256", ")", "\n", "self", ".", "prelu5", "=", "nn", ".", "PReLU", "(", "256", ")", "\n", "self", ".", "dense6_1", "=", "nn", ".", "Linear", "(", "256", ",", "2", ")", "\n", "self", ".", "softmax6_1", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "dense6_2", "=", "nn", ".", "Linear", "(", "256", ",", "4", ")", "\n", "self", ".", "dense6_3", "=", "nn", ".", "Linear", "(", "256", ",", "10", ")", "\n", "\n", "self", ".", "training", "=", "False", "\n", "\n", "if", "pretrained", ":", "\n", "            ", "state_dict_path", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'./data/onet.pt'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "state_dict_path", ")", "\n", "self", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.ONet.forward": [[140, 160], ["mtcnn.ONet.conv1", "mtcnn.ONet.prelu1", "mtcnn.ONet.pool1", "mtcnn.ONet.conv2", "mtcnn.ONet.prelu2", "mtcnn.ONet.pool2", "mtcnn.ONet.conv3", "mtcnn.ONet.prelu3", "mtcnn.ONet.pool3", "mtcnn.ONet.conv4", "mtcnn.ONet.prelu4", "mtcnn.ONet.permute().contiguous", "mtcnn.ONet.dense5", "mtcnn.ONet.prelu5", "mtcnn.ONet.dense6_1", "mtcnn.ONet.softmax6_1", "mtcnn.ONet.dense6_2", "mtcnn.ONet.dense6_3", "mtcnn.ONet.view", "mtcnn.ONet.cpu", "mtcnn.ONet.cpu", "mtcnn.ONet.cpu", "mtcnn.ONet.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu1", "(", "x", ")", "\n", "x", "=", "self", ".", "pool1", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu2", "(", "x", ")", "\n", "x", "=", "self", ".", "pool2", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu3", "(", "x", ")", "\n", "x", "=", "self", ".", "pool3", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "x", "=", "self", ".", "prelu4", "(", "x", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "dense5", "(", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "prelu5", "(", "x", ")", "\n", "a", "=", "self", ".", "dense6_1", "(", "x", ")", "\n", "a", "=", "self", ".", "softmax6_1", "(", "a", ")", "\n", "b", "=", "self", ".", "dense6_2", "(", "x", ")", "\n", "c", "=", "self", ".", "dense6_3", "(", "x", ")", "\n", "return", "b", ".", "cpu", "(", ")", ",", "c", ".", "cpu", "(", ")", ",", "a", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.MTCNN.__init__": [[188, 212], ["torch.nn.Module.__init__", "mtcnn.PNet", "mtcnn.RNet", "mtcnn.ONet", "mtcnn.MTCNN.to"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "\n", "self", ",", "image_size", "=", "160", ",", "margin", "=", "0", ",", "min_face_size", "=", "20", ",", "\n", "thresholds", "=", "[", "0.6", ",", "0.7", ",", "0.7", "]", ",", "factor", "=", "0.709", ",", "prewhiten", "=", "True", ",", "\n", "select_largest", "=", "True", ",", "keep_all", "=", "False", ",", "device", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "image_size", "=", "image_size", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "min_face_size", "=", "min_face_size", "\n", "self", ".", "thresholds", "=", "thresholds", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "prewhiten", "=", "prewhiten", "\n", "self", ".", "select_largest", "=", "select_largest", "\n", "self", ".", "keep_all", "=", "keep_all", "\n", "\n", "self", ".", "pnet", "=", "PNet", "(", ")", "\n", "self", ".", "rnet", "=", "RNet", "(", ")", "\n", "self", ".", "onet", "=", "ONet", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "if", "device", "is", "not", "None", ":", "\n", "            ", "self", ".", "device", "=", "device", "\n", "self", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.MTCNN.forward": [[213, 303], ["zip", "torch.no_grad", "mtcnn.MTCNN.detect", "isinstance", "isinstance", "enumerate", "faces.append", "probs.append", "faces.append", "probs.append", "utils.detect_face.extract_face", "torch.stack.append", "torch.stack", "range", "os.path.splitext", "mtcnn.prewhiten", "len", "str"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.detect", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.extract_face", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.prewhiten"], ["", "", "def", "forward", "(", "self", ",", "img", ",", "save_path", "=", "None", ",", "return_prob", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run MTCNN face detection on a PIL image. This method performs both detection and\n        extraction of faces, returning tensors representing detected faces rather than the bounding\n        boxes. To access bounding boxes, see the MTCNN.detect() method below.\n\n        Arguments:\n            img {PIL.Image or list} -- A PIL image or a list of PIL images.\n\n        Keyword Arguments:\n            save_path {str} -- An optional save path for the cropped image. Note that when\n                self.prewhiten=True, although the returned tensor is prewhitened, the saved face\n                image is not, so it is a true representation of the face in the input image.\n                If `img` is a list of images, `save_path` should be a list of equal length.\n                (default: {None})\n            return_prob {bool} -- Whether or not to return the detection probability.\n                (default: {False})\n\n        Returns:\n            Union[torch.Tensor, tuple(torch.tensor, float)] -- If detected, cropped image of a face\n                with dimensions 3 x image_size x image_size. Optionally, the probability that a\n                face was detected. If self.keep_all is True, n detected faces are returned in an\n                n x 3 x image_size x image_size tensor with an optional list of detection\n                probabilities. If `img` is a list of images, the item(s) returned have an extra\n                dimension (batch) as the first dimension.\n        Example:\n        >>> from facenet_pytorch import MTCNN\n        >>> mtcnn = MTCNN()\n        >>> face_tensor, prob = mtcnn(img, save_path='face.png', return_prob=True)\n        \"\"\"", "\n", "\n", "# Detect faces", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_boxes", ",", "batch_probs", "=", "self", ".", "detect", "(", "img", ")", "\n", "\n", "# Determine if a batch or single image was passed", "\n", "", "batch_mode", "=", "True", "\n", "if", "not", "isinstance", "(", "img", ",", "Iterable", ")", ":", "\n", "            ", "img", "=", "[", "img", "]", "\n", "batch_boxes", "=", "[", "batch_boxes", "]", "\n", "batch_probs", "=", "[", "batch_probs", "]", "\n", "batch_mode", "=", "False", "\n", "\n", "# Parse save path(s)", "\n", "", "if", "save_path", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "save_path", ",", "str", ")", ":", "\n", "                ", "save_path", "=", "[", "save_path", "]", "\n", "", "", "else", ":", "\n", "            ", "save_path", "=", "[", "None", "for", "_", "in", "range", "(", "len", "(", "img", ")", ")", "]", "\n", "\n", "# Process all bounding boxes and probabilities", "\n", "", "faces", ",", "probs", "=", "[", "]", ",", "[", "]", "\n", "for", "im", ",", "box_im", ",", "prob_im", ",", "path_im", "in", "zip", "(", "img", ",", "batch_boxes", ",", "batch_probs", ",", "save_path", ")", ":", "\n", "            ", "if", "box_im", "is", "None", ":", "\n", "                ", "faces", ".", "append", "(", "None", ")", "\n", "probs", ".", "append", "(", "[", "None", "]", "if", "self", ".", "keep_all", "else", "None", ")", "\n", "continue", "\n", "\n", "", "if", "not", "self", ".", "keep_all", ":", "\n", "                ", "box_im", "=", "box_im", "[", "[", "0", "]", "]", "\n", "\n", "", "faces_im", "=", "[", "]", "\n", "for", "i", ",", "box", "in", "enumerate", "(", "box_im", ")", ":", "\n", "                ", "face_path", "=", "path_im", "\n", "if", "path_im", "is", "not", "None", "and", "i", ">", "0", ":", "\n", "                    ", "save_name", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path_im", ")", "\n", "face_path", "=", "save_name", "+", "'_'", "+", "str", "(", "i", "+", "1", ")", "+", "ext", "\n", "\n", "", "face", "=", "extract_face", "(", "im", ",", "box", ",", "self", ".", "image_size", ",", "\n", "self", ".", "margin", ",", "face_path", ")", "\n", "if", "self", ".", "prewhiten", ":", "\n", "                    ", "face", "=", "prewhiten", "(", "face", ")", "\n", "", "faces_im", ".", "append", "(", "face", ")", "\n", "\n", "", "if", "self", ".", "keep_all", ":", "\n", "                ", "faces_im", "=", "torch", ".", "stack", "(", "faces_im", ")", "\n", "", "else", ":", "\n", "                ", "faces_im", "=", "faces_im", "[", "0", "]", "\n", "prob_im", "=", "prob_im", "[", "0", "]", "\n", "\n", "", "faces", ".", "append", "(", "faces_im", ")", "\n", "probs", ".", "append", "(", "prob_im", ")", "\n", "\n", "", "if", "not", "batch_mode", ":", "\n", "            ", "faces", "=", "faces", "[", "0", "]", "\n", "probs", "=", "probs", "[", "0", "]", "\n", "\n", "", "if", "return_prob", ":", "\n", "            ", "return", "faces", ",", "probs", "\n", "", "else", ":", "\n", "            ", "return", "faces", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.MTCNN.detect": [[304, 365], ["numpy.array", "numpy.array", "torch.no_grad", "utils.detect_face.detect_face", "numpy.array", "isinstance", "len", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.argsort"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.detect_face"], ["", "", "def", "detect", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"Detect all faces in PIL image and return bounding boxes.\n        This method is used by the forward method and is also useful for face detection tasks\n        that require lower-level handling of bounding boxes (e.g., face tracking). The\n        functionality of the forward function can be emulated by using this method followed by\n        the extract_face() function.\n\n        Arguments:\n            img {PIL.Image or list} -- A PIL image or a list of PIL images.\n\n        Returns:\n            tuple(numpy.ndarray, list) -- For N detected faces, a tuple containing an\n                Nx4 array of bounding boxes and a length N list of detection probabilities.\n                Returned boxes will be sorted in descending order by detection probability if\n                self.select_largest=False, otherwise the largest face will be returned first.\n                If `img` is a list of images, the items returned have an extra dimension\n                (batch) as the first dimension.\n        Example:\n        >>> from PIL import Image, ImageDraw\n        >>> from facenet_pytorch import MTCNN, extract_face\n        >>> mtcnn = MTCNN(keep_all=True)\n        >>> boxes, probs = mtcnn.detect(img)\n        >>> # Draw boxes and save faces\n        >>> img_draw = img.copy()\n        >>> draw = ImageDraw.Draw(img_draw)\n        >>> for i, box in enumerate(boxes):\n        ...     draw.rectangle(box.tolist())\n        ...     extract_face(img, box, save_path='detected_face_{}.png'.format(i))\n        >>> img_draw.save('annotated_faces.png')\n        \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "batch_boxes", "=", "detect_face", "(", "\n", "img", ",", "self", ".", "min_face_size", ",", "\n", "self", ".", "pnet", ",", "self", ".", "rnet", ",", "self", ".", "onet", ",", "\n", "self", ".", "thresholds", ",", "self", ".", "factor", ",", "\n", "self", ".", "device", "\n", ")", "\n", "\n", "", "boxes", ",", "probs", "=", "[", "]", ",", "[", "]", "\n", "for", "box", "in", "batch_boxes", ":", "\n", "            ", "box", "=", "np", ".", "array", "(", "box", ")", "\n", "if", "len", "(", "box", ")", "==", "0", ":", "\n", "                ", "boxes", ".", "append", "(", "None", ")", "\n", "probs", ".", "append", "(", "[", "None", "]", ")", "\n", "", "elif", "self", ".", "select_largest", ":", "\n", "                ", "box", "=", "box", "[", "np", ".", "argsort", "(", "(", "box", "[", ":", ",", "2", "]", "-", "box", "[", ":", ",", "0", "]", ")", "\n", "*", "(", "box", "[", ":", ",", "3", "]", "-", "box", "[", ":", ",", "1", "]", ")", ")", "[", ":", ":", "-", "1", "]", "]", "\n", "boxes", ".", "append", "(", "box", "[", ":", ",", ":", "4", "]", ")", "\n", "probs", ".", "append", "(", "box", "[", ":", ",", "4", "]", ")", "\n", "", "else", ":", "\n", "                ", "boxes", ".", "append", "(", "box", "[", ":", ",", ":", "4", "]", ")", "\n", "probs", ".", "append", "(", "box", "[", ":", ",", "4", "]", ")", "\n", "", "", "boxes", "=", "np", ".", "array", "(", "boxes", ")", "\n", "probs", "=", "np", ".", "array", "(", "probs", ")", "\n", "\n", "if", "not", "isinstance", "(", "img", ",", "Iterable", ")", ":", "\n", "            ", "boxes", "=", "boxes", "[", "0", "]", "\n", "probs", "=", "probs", "[", "0", "]", "\n", "\n", "", "return", "boxes", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.mtcnn.prewhiten": [[367, 373], ["x.mean", "x.std", "x.std.clamp", "float", "x.numel"], "function", ["None"], ["", "", "def", "prewhiten", "(", "x", ")", ":", "\n", "    ", "mean", "=", "x", ".", "mean", "(", ")", "\n", "std", "=", "x", ".", "std", "(", ")", "\n", "std_adj", "=", "std", ".", "clamp", "(", "min", "=", "1.0", "/", "(", "float", "(", "x", ".", "numel", "(", ")", ")", "**", "0.5", ")", ")", "\n", "y", "=", "(", "x", "-", "mean", ")", "/", "std_adj", "\n", "return", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.BasicConv2d.__init__": [[12, 26], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "\n", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "bias", "=", "False", "\n", ")", "# verify bias false", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "\n", "out_planes", ",", "\n", "eps", "=", "0.001", ",", "# value found in tensorflow", "\n", "momentum", "=", "0.1", ",", "# default pytorch value", "\n", "affine", "=", "True", "\n", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.BasicConv2d.forward": [[27, 32], ["inception_resnet_v1.BasicConv2d.conv", "inception_resnet_v1.BasicConv2d.bn", "inception_resnet_v1.BasicConv2d.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block35.__init__": [[36, 56], ["torch.nn.Module.__init__", "inception_resnet_v1.BasicConv2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.ReLU", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "256", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "256", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "256", ",", "32", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "96", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block35.forward": [[57, 66], ["inception_resnet_v1.Block35.branch0", "inception_resnet_v1.Block35.branch1", "inception_resnet_v1.Block35.branch2", "torch.cat", "inception_resnet_v1.Block35.conv2d", "inception_resnet_v1.Block35.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block17.__init__": [[70, 86], ["torch.nn.Module.__init__", "inception_resnet_v1.BasicConv2d", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.ReLU", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "896", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "896", ",", "128", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "128", ",", "128", ",", "kernel_size", "=", "(", "\n", "1", ",", "7", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "3", ")", ")", ",", "\n", "BasicConv2d", "(", "128", ",", "128", ",", "kernel_size", "=", "(", "7", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "3", ",", "0", ")", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "256", ",", "896", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block17.forward": [[87, 95], ["inception_resnet_v1.Block17.branch0", "inception_resnet_v1.Block17.branch1", "torch.cat", "inception_resnet_v1.Block17.conv2d", "inception_resnet_v1.Block17.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block8.__init__": [[99, 117], ["torch.nn.Module.__init__", "inception_resnet_v1.BasicConv2d", "torch.nn.Sequential", "torch.nn.Conv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scale", "=", "1.0", ",", "noReLU", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "noReLU", "=", "noReLU", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "1792", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "1792", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "(", "\n", "1", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "1", ")", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "(", "3", ",", "1", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "0", ")", ")", "\n", ")", "\n", "\n", "self", ".", "conv2d", "=", "nn", ".", "Conv2d", "(", "384", ",", "1792", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "if", "not", "self", ".", "noReLU", ":", "\n", "            ", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Block8.forward": [[118, 127], ["inception_resnet_v1.Block8.branch0", "inception_resnet_v1.Block8.branch1", "torch.cat", "inception_resnet_v1.Block8.conv2d", "inception_resnet_v1.Block8.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ")", ",", "1", ")", "\n", "out", "=", "self", ".", "conv2d", "(", "out", ")", "\n", "out", "=", "out", "*", "self", ".", "scale", "+", "x", "\n", "if", "not", "self", ".", "noReLU", ":", "\n", "            ", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Mixed_6a.__init__": [[131, 143], ["torch.nn.Module.__init__", "inception_resnet_v1.BasicConv2d", "torch.nn.Sequential", "torch.nn.MaxPool2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "BasicConv2d", "(", "256", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "256", ",", "192", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "192", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Mixed_6a.forward": [[144, 150], ["inception_resnet_v1.Mixed_6a.branch0", "inception_resnet_v1.Mixed_6a.branch1", "inception_resnet_v1.Mixed_6a.branch2", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Mixed_7a.__init__": [[154, 174], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.MaxPool2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "branch0", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "896", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "384", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch1", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "896", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch2", "=", "nn", ".", "Sequential", "(", "\n", "BasicConv2d", "(", "896", ",", "256", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "BasicConv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", ")", "\n", "\n", "self", ".", "branch3", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.Mixed_7a.forward": [[175, 182], ["inception_resnet_v1.Mixed_7a.branch0", "inception_resnet_v1.Mixed_7a.branch1", "inception_resnet_v1.Mixed_7a.branch2", "inception_resnet_v1.Mixed_7a.branch3", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x0", "=", "self", ".", "branch0", "(", "x", ")", "\n", "x1", "=", "self", ".", "branch1", "(", "x", ")", "\n", "x2", "=", "self", ".", "branch2", "(", "x", ")", "\n", "x3", "=", "self", ".", "branch3", "(", "x", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "x0", ",", "x1", ",", "x2", ",", "x3", ")", ",", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.InceptionResnetV1.__init__": [[202, 270], ["torch.nn.Module.__init__", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "torch.nn.MaxPool2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "inception_resnet_v1.BasicConv2d", "torch.nn.Sequential", "inception_resnet_v1.Mixed_6a", "torch.nn.Sequential", "inception_resnet_v1.Mixed_7a", "torch.nn.Sequential", "inception_resnet_v1.Block8", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.Linear", "inception_resnet_v1.Block35", "inception_resnet_v1.Block35", "inception_resnet_v1.Block35", "inception_resnet_v1.Block35", "inception_resnet_v1.Block35", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block17", "inception_resnet_v1.Block8", "inception_resnet_v1.Block8", "inception_resnet_v1.Block8", "inception_resnet_v1.Block8", "inception_resnet_v1.Block8", "inception_resnet_v1.load_weights", "torch.nn.Linear", "Exception"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.load_weights", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["def", "__init__", "(", "self", ",", "pretrained", "=", "None", ",", "classify", "=", "False", ",", "num_classes", "=", "None", ",", "dropout_prob", "=", "0.6", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Set simple attributes", "\n", "self", ".", "pretrained", "=", "pretrained", "\n", "self", ".", "classify", "=", "classify", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "if", "pretrained", "==", "'vggface2'", ":", "\n", "            ", "tmp_classes", "=", "8631", "\n", "", "elif", "pretrained", "==", "'casia-webface'", ":", "\n", "            ", "tmp_classes", "=", "10575", "\n", "", "elif", "pretrained", "is", "None", "and", "self", ".", "num_classes", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\n", "'At least one of \"pretrained\" or \"num_classes\" must be specified'", ")", "\n", "", "else", ":", "\n", "            ", "tmp_classes", "=", "self", ".", "num_classes", "\n", "\n", "# Define layers", "\n", "", "self", ".", "conv2d_1a", "=", "BasicConv2d", "(", "3", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv2d_2a", "=", "BasicConv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv2d_2b", "=", "BasicConv2d", "(", "\n", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "maxpool_3a", "=", "nn", ".", "MaxPool2d", "(", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "conv2d_3b", "=", "BasicConv2d", "(", "64", ",", "80", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv2d_4a", "=", "BasicConv2d", "(", "80", ",", "192", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv2d_4b", "=", "BasicConv2d", "(", "192", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "self", ".", "repeat_1", "=", "nn", ".", "Sequential", "(", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", "Block35", "(", "scale", "=", "0.17", ")", ",", "\n", ")", "\n", "self", ".", "mixed_6a", "=", "Mixed_6a", "(", ")", "\n", "self", ".", "repeat_2", "=", "nn", ".", "Sequential", "(", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", "Block17", "(", "scale", "=", "0.10", ")", ",", "\n", ")", "\n", "self", ".", "mixed_7a", "=", "Mixed_7a", "(", ")", "\n", "self", ".", "repeat_3", "=", "nn", ".", "Sequential", "(", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", "Block8", "(", "scale", "=", "0.20", ")", ",", "\n", ")", "\n", "self", ".", "block8", "=", "Block8", "(", "noReLU", "=", "True", ")", "\n", "self", ".", "avgpool_1a", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_prob", ")", "\n", "self", ".", "last_linear", "=", "nn", ".", "Linear", "(", "1792", ",", "512", ",", "bias", "=", "False", ")", "\n", "self", ".", "last_bn", "=", "nn", ".", "BatchNorm1d", "(", "\n", "512", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "512", ",", "tmp_classes", ")", "\n", "\n", "if", "pretrained", "is", "not", "None", ":", "\n", "            ", "load_weights", "(", "self", ",", "pretrained", ")", "\n", "\n", "", "if", "self", ".", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "512", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.InceptionResnetV1.forward": [[271, 300], ["inception_resnet_v1.InceptionResnetV1.conv2d_1a", "inception_resnet_v1.InceptionResnetV1.conv2d_2a", "inception_resnet_v1.InceptionResnetV1.conv2d_2b", "inception_resnet_v1.InceptionResnetV1.maxpool_3a", "inception_resnet_v1.InceptionResnetV1.conv2d_3b", "inception_resnet_v1.InceptionResnetV1.conv2d_4a", "inception_resnet_v1.InceptionResnetV1.conv2d_4b", "inception_resnet_v1.InceptionResnetV1.repeat_1", "inception_resnet_v1.InceptionResnetV1.mixed_6a", "inception_resnet_v1.InceptionResnetV1.repeat_2", "inception_resnet_v1.InceptionResnetV1.mixed_7a", "inception_resnet_v1.InceptionResnetV1.repeat_3", "inception_resnet_v1.InceptionResnetV1.block8", "inception_resnet_v1.InceptionResnetV1.avgpool_1a", "inception_resnet_v1.InceptionResnetV1.dropout", "inception_resnet_v1.InceptionResnetV1.last_linear", "inception_resnet_v1.InceptionResnetV1.last_bn", "torch.nn.functional.normalize", "inception_resnet_v1.InceptionResnetV1.logits", "torch.nn.functional.normalize.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Calculate embeddings or probabilities given a batch of input image tensors.\n\n        Arguments:\n            x {torch.tensor} -- Batch of image tensors representing faces.\n\n        Returns:\n            torch.tensor -- Batch of embeddings or softmax probabilities.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv2d_1a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_2a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_2b", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool_3a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_3b", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_4a", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2d_4b", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat_1", "(", "x", ")", "\n", "x", "=", "self", ".", "mixed_6a", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat_2", "(", "x", ")", "\n", "x", "=", "self", ".", "mixed_7a", "(", "x", ")", "\n", "x", "=", "self", ".", "repeat_3", "(", "x", ")", "\n", "x", "=", "self", ".", "block8", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool_1a", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "last_linear", "(", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "last_bn", "(", "x", ")", "\n", "x", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "logits", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.load_weights": [[302, 339], ["os.path.join", "os.makedirs", "enumerate", "mdl.load_state_dict", "inception_resnet_v1.get_torch_home", "os.path.join", "state_dict.update", "ValueError", "os.path.exists", "print", "requests.Session", "requests.Session.mount", "requests.Session.get", "torch.load", "requests.adapters.HTTPAdapter", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.get_torch_home", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "", "def", "load_weights", "(", "mdl", ",", "name", ")", ":", "\n", "    ", "\"\"\"Download pretrained state_dict and load into model.\n\n    Arguments:\n        mdl {torch.nn.Module} -- Pytorch model.\n        name {str} -- Name of dataset that was used to generate pretrained state_dict.\n\n    Raises:\n        ValueError: If 'pretrained' not equal to 'vggface2' or 'casia-webface'.\n    \"\"\"", "\n", "if", "name", "==", "'vggface2'", ":", "\n", "        ", "features_path", "=", "'https://drive.google.com/uc?export=download&id=1cWLH_hPns8kSfMz9kKl9PsG5aNV2VSMn'", "\n", "logits_path", "=", "'https://drive.google.com/uc?export=download&id=1mAie3nzZeno9UIzFXvmVZrDG3kwML46X'", "\n", "", "elif", "name", "==", "'casia-webface'", ":", "\n", "        ", "features_path", "=", "'https://drive.google.com/uc?export=download&id=1LSHHee_IQj5W3vjBcRyVaALv4py1XaGy'", "\n", "logits_path", "=", "'https://drive.google.com/uc?export=download&id=1QrhPgn1bGlDxAil2uc07ctunCQoDnCzT'", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'Pretrained models only exist for \"vggface2\" and \"casia-webface\"'", ")", "\n", "\n", "", "model_dir", "=", "os", ".", "path", ".", "join", "(", "get_torch_home", "(", ")", ",", "'checkpoints'", ")", "\n", "os", ".", "makedirs", "(", "model_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "state_dict", "=", "{", "}", "\n", "for", "i", ",", "path", "in", "enumerate", "(", "[", "features_path", ",", "logits_path", "]", ")", ":", "\n", "        ", "cached_file", "=", "os", ".", "path", ".", "join", "(", "\n", "model_dir", ",", "'{}_{}.pt'", ".", "format", "(", "name", ",", "path", "[", "-", "10", ":", "]", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cached_file", ")", ":", "\n", "            ", "print", "(", "'Downloading parameters ({}/2)'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "s", "=", "requests", ".", "Session", "(", ")", "\n", "s", ".", "mount", "(", "'https://'", ",", "HTTPAdapter", "(", "max_retries", "=", "10", ")", ")", "\n", "r", "=", "s", ".", "get", "(", "path", ",", "allow_redirects", "=", "True", ")", "\n", "with", "open", "(", "cached_file", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "r", ".", "content", ")", "\n", "", "", "state_dict", ".", "update", "(", "torch", ".", "load", "(", "cached_file", ")", ")", "\n", "\n", "", "mdl", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.facenet.inception_resnet_v1.get_torch_home": [[341, 349], ["os.path.expanduser", "os.getenv", "os.path.join", "os.getenv"], "function", ["None"], ["", "def", "get_torch_home", "(", ")", ":", "\n", "    ", "torch_home", "=", "os", ".", "path", ".", "expanduser", "(", "\n", "os", ".", "getenv", "(", "\n", "'TORCH_HOME'", ",", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getenv", "(", "'XDG_CACHE_HOME'", ",", "'~/.cache'", ")", ",", "'torch'", ")", "\n", ")", "\n", ")", "\n", "return", "torch_home", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.__init__": [[53, 164], ["allennlp.training.trainer_base.TrainerBase.__init__", "logger.warning", "allennlp.training.callbacks.callback_handler.CallbackHandler", "ConfigurationError", "logging.info", "amp.initialize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.initialize"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ":", "Model", ",", "\n", "training_data", ":", "Iterable", "[", "Instance", "]", ",", "\n", "iterator", ":", "DataIterator", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "num_epochs", ":", "int", "=", "20", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "serialization_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "cuda_device", ":", "Union", "[", "int", ",", "List", "]", "=", "-", "1", ",", "\n", "callbacks", ":", "List", "[", "Callback", "]", "=", "None", ",", "\n", "apex_opt_level", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "keep_batchnorm_fp32", ":", "Optional", "[", "bool", "]", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        A trainer for doing supervised learning. It just takes a labeled dataset\n        and a ``DataIterator``, and uses the supplied ``Optimizer`` to learn the weights\n        for your model over some fixed number of epochs. It uses callbacks to handle various\n        things ancillary to training, like tracking metrics, validation, early stopping,\n        logging to tensorboard, and so on.\n\n        It's easy to create your own callbacks; for example, if you wanted to get a Slack\n        notification when training finishes. For more complicated variations, you might have\n        to create your own subclass, in which case make sure to fire off all the training events.\n\n        Parameters\n        ----------\n        model : ``Model``, required.\n            An AllenNLP model to be optimized. Pytorch Modules can also be optimized if\n            their ``forward`` method returns a dictionary with a \"loss\" key, containing a\n            scalar tensor representing the loss function to be optimized.\n\n            If you are training your model using GPUs, your model should already be\n            on the correct device. (If you use `Trainer.from_params` this will be\n            handled for you.)\n        training_data : ``Iterable[Instance]``, required\n            The instances that you want to train your model on.\n        iterator : ``DataIterator``, required\n            The iterator for batching / epoch-ing the instances.\n        optimizer : ``torch.nn.Optimizer``, required.\n            An instance of a Pytorch Optimizer, instantiated with the parameters of the\n            model to be optimized.\n        num_epochs : int, optional (default=20)\n            Number of training epochs.\n        shuffle : bool, optional (default=True)\n            Whether to shuffle the instances each epoch.\n        serialization_dir : str, optional (default=None)\n            Path to directory for saving and loading model files. Models will not be saved if\n            this parameter is not passed.\n        cuda_device : ``Union[int, List[int]]``, optional (default=-1)\n            An integer or list of integers specifying the CUDA device(s) to use. If -1, the CPU is used.\n        callbacks : ``List[Callback]``, optional (default=None)\n            A list of callbacks that will be called based on training events.\n        apex_opt_level: ``str``, optional (default = None)\n            If provided, we will use the apex library to do mixed-precision training with the specified\n            opt_level. This will cause an error if apex is not installed.\n            Allowed values are O0, O1, O2, and O3. (Note that is capital-O then a number.)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "serialization_dir", ",", "cuda_device", ")", "\n", "\n", "logger", ".", "warning", "(", "\"The CallbackTrainer should be considered 'experimental' code, \"", "\n", "\"and its behavior may change as we use it more and iterate on it.\"", ")", "\n", "\n", "if", "apex_opt_level", "and", "not", "_APEX_IMPORTED", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\"You specified an apex_opt_level, but we could not import apex. \"", "\n", "\"Is it installed? see https://github.com/NVIDIA/apex#quick-start\"", ")", "\n", "\n", "# This is all state that the callbacks might want:", "\n", "# I am not calling move_to_gpu here, because if the model is", "\n", "# not already on the GPU then the optimizer is going to be wrong.", "\n", "", "if", "apex_opt_level", ":", "\n", "            ", "logging", ".", "info", "(", "f\"using apex.amp with opt_level {apex_opt_level}\"", ")", "\n", "self", ".", "model", ",", "self", ".", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "opt_level", "=", "apex_opt_level", ",", "\n", "keep_batchnorm_fp32", "=", "keep_batchnorm_fp32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ",", "self", ".", "optimizer", "=", "model", ",", "optimizer", "\n", "\n", "", "self", ".", "_use_apex", "=", "apex_opt_level", "is", "not", "None", "\n", "self", ".", "validate", "=", "False", "\n", "\n", "# For capturing mid / end-of-epoch metrics", "\n", "self", ".", "train_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "self", ".", "val_metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "self", ".", "latest_val_metric", "=", "0.0", "\n", "self", ".", "train_loss", "=", "0.0", "\n", "\n", "# For capturing overall metrics", "\n", "self", ".", "metrics", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "\n", "self", ".", "batch_num_total", "=", "0", "\n", "self", ".", "batch_group", ":", "List", "[", "TensorDict", "]", "=", "[", "]", "\n", "self", ".", "batches_this_epoch", "=", "0", "\n", "\n", "self", ".", "training_batches", ":", "Iterable", "[", "List", "[", "TensorDict", "]", "]", "=", "(", ")", "\n", "self", ".", "num_training_batches", "=", "0", "\n", "\n", "self", ".", "should_stop_early", "=", "False", "\n", "self", ".", "num_epochs", "=", "num_epochs", "\n", "\n", "self", ".", "training_start_time", "=", "0.0", "\n", "\n", "self", ".", "last_log", "=", "0.0", "\n", "self", ".", "epoch_number", "=", "0", "\n", "self", ".", "batch_grad_norm", ":", "Optional", "[", "float", "]", "=", "None", "\n", "\n", "self", ".", "training_data", "=", "training_data", "\n", "self", ".", "iterator", "=", "iterator", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "handler", "=", "CallbackHandler", "(", "callbacks", ",", "self", ")", "\n", "\n", "# For capturing errors that occur during the train loop.", "\n", "self", ".", "exception", ":", "Optional", "[", "Exception", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.generate_training_batches": [[165, 178], ["len", "callback_apex_trainer.CallbackApexTrainer.iterator", "allennlp.common.util.lazy_groups_of", "math.ceil", "callback_apex_trainer.CallbackApexTrainer.iterator.get_num_batches"], "methods", ["None"], ["", "def", "generate_training_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generates one epoch worth of training data. Stores it in trainer instance variables\n        so that callbacks can access it.\n        \"\"\"", "\n", "num_gpus", "=", "len", "(", "self", ".", "_cuda_devices", ")", "\n", "\n", "raw_train_generator", "=", "self", ".", "iterator", "(", "self", ".", "training_data", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "self", ".", "training_batches", "=", "lazy_groups_of", "(", "raw_train_generator", ",", "num_gpus", ")", "\n", "self", ".", "num_training_batches", "=", "math", ".", "ceil", "(", "\n", "self", ".", "iterator", ".", "get_num_batches", "(", "self", ".", "training_data", ")", "/", "num_gpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.batch_loss": [[179, 207], ["allennlp.training.util.data_parallel", "allennlp.nn.util.move_to_device", "callback_apex_trainer.CallbackApexTrainer.model", "len", "callback_apex_trainer.CallbackApexTrainer.model.get_regularization_penalty", "RuntimeError"], "methods", ["None"], ["", "def", "batch_loss", "(", "self", ",", "batch_group", ":", "List", "[", "TensorDict", "]", ",", "for_training", ":", "bool", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Does a forward pass on the given batches and returns the ``loss`` value in the result.\n        If ``for_training`` is `True` also applies regularization penalty.\n\n        This is a method on the trainer so that it can be used both in training and validation\n        (which are handled separately).\n        \"\"\"", "\n", "if", "self", ".", "_multiple_gpu", ":", "\n", "            ", "output_dict", "=", "training_util", ".", "data_parallel", "(", "\n", "batch_group", ",", "self", ".", "model", ",", "self", ".", "_cuda_devices", ")", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "batch_group", ")", "==", "1", "\n", "batch", "=", "batch_group", "[", "0", "]", "\n", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "self", ".", "_cuda_devices", "[", "0", "]", ")", "\n", "output_dict", "=", "self", ".", "model", "(", "**", "batch", ")", "\n", "\n", "", "try", ":", "\n", "            ", "loss", "=", "output_dict", "[", "\"loss\"", "]", "\n", "if", "loss", "is", "not", "None", "and", "for_training", ":", "\n", "                ", "loss", "+=", "self", ".", "model", ".", "get_regularization_penalty", "(", ")", "\n", "", "", "except", "KeyError", ":", "\n", "            ", "if", "for_training", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"The model you are trying to optimize does not contain a\"", "\n", "\" 'loss' key in the output of model.forward(inputs).\"", ")", "\n", "", "loss", "=", "None", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train_one_batch_group": [[208, 248], ["callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.optimizer.zero_grad", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.batch_loss", "torch.isnan", "callback_apex_trainer.CallbackApexTrainer.item", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.optimizer.step", "allennlp.training.util.get_metrics", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "allennlp.training.util.description_from_metrics", "logger.warning", "callback_apex_trainer.CallbackApexTrainer.backward", "amp.scale_loss", "scaled_loss.backward"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.batch_loss", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.get_metrics", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.backward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.backward"], ["", "def", "train_one_batch_group", "(", "self", ",", "batch_group", ":", "List", "[", "TensorDict", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Handles the training for a single batch group.\n        Fires off the events BATCH_START, FORWARD, BACKWARD, and BATCH_END.\n        \"\"\"", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "BATCH_START", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "self", ".", "batches_this_epoch", "+=", "1", "\n", "self", ".", "batch_num_total", "+=", "1", "\n", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "FORWARD", ")", "\n", "loss", "=", "self", ".", "batch_loss", "(", "batch_group", ",", "for_training", "=", "True", ")", "\n", "\n", "if", "loss", "is", "None", ":", "\n", "            ", "return", "\n", "\n", "", "if", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"NaN loss encountered.\"", ")", "\n", "return", "\n", "\n", "", "if", "self", ".", "_use_apex", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "self", ".", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "", "self", ".", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "BACKWARD", ")", "\n", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update the description with the latest metrics", "\n", "self", ".", "train_metrics", "=", "training_util", ".", "get_metrics", "(", "self", ".", "model", ",", "\n", "self", ".", "train_loss", ",", "\n", "self", ".", "batches_this_epoch", ")", "\n", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "BATCH_END", ")", "\n", "\n", "return", "training_util", ".", "description_from_metrics", "(", "self", ".", "train_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train_one_epoch": [[249, 277], ["callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.model.train", "time.time", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "callback_apex_trainer.CallbackApexTrainer.train_one_batch_group", "allennlp.common.tqdm.Tqdm.tqdm.set_description"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train_one_batch_group"], ["", "def", "train_one_epoch", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Trains the model for a single epoch.\n        Fires off the events EPOCH_START and EPOCH_END,\n        and repeatedly calls self.train_one_batch_group().\n        \"\"\"", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "EPOCH_START", ")", "\n", "\n", "self", ".", "train_loss", "=", "0.0", "\n", "# Set the model to \"train\" mode.", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "last_log", "=", "time", ".", "time", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training\"", ")", "\n", "self", ".", "batches_this_epoch", "=", "0", "\n", "\n", "batch_groups_tqdm", "=", "Tqdm", ".", "tqdm", "(", "\n", "self", ".", "training_batches", ",", "total", "=", "self", ".", "num_training_batches", ")", "\n", "\n", "for", "self", ".", "batch_group", "in", "batch_groups_tqdm", ":", "\n", "            ", "description", "=", "self", ".", "train_one_batch_group", "(", "self", ".", "batch_group", ")", "\n", "if", "description", "is", "None", ":", "\n", "                ", "continue", "\n", "", "batch_groups_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "VALIDATE", ")", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "EPOCH_END", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train": [[278, 318], ["logger.info", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "time.time", "range", "callback_apex_trainer.CallbackApexTrainer.handler.fire_event", "time.time", "callback_apex_trainer.CallbackApexTrainer.generate_training_batches", "callback_apex_trainer.CallbackApexTrainer.train_one_epoch", "logger.info", "time.time", "datetime.timedelta", "str", "logger.info", "logger.info", "time.time", "datetime.timedelta", "float", "int"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.generate_training_batches", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.train_one_epoch", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["", "@", "handle_errors", "\n", "def", "train", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Trains the supplied model with the supplied parameters.\n        Fires off the events TRAINING_START and TRAINING END,\n        and repeatedly calls `self.train_one_epoch()`.\n        \"\"\"", "\n", "logger", ".", "info", "(", "\"Beginning training.\"", ")", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "TRAINING_START", ")", "\n", "\n", "self", ".", "training_start_time", "=", "time", ".", "time", "(", ")", "\n", "starting_epoch", "=", "self", ".", "epoch_number", "\n", "\n", "for", "self", ".", "epoch_number", "in", "range", "(", "self", ".", "epoch_number", ",", "self", ".", "num_epochs", ")", ":", "\n", "            ", "epoch_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "generate_training_batches", "(", ")", "\n", "self", ".", "train_one_epoch", "(", ")", "\n", "\n", "epoch_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "epoch_start_time", "\n", "logger", ".", "info", "(", "\"Epoch duration: %s\"", ",", "datetime", ".", "timedelta", "(", "\n", "seconds", "=", "epoch_elapsed_time", ")", ")", "\n", "\n", "if", "self", ".", "epoch_number", "<", "self", ".", "num_epochs", "-", "1", ":", "\n", "                ", "training_elapsed_time", "=", "time", ".", "time", "(", ")", "-", "self", ".", "training_start_time", "\n", "estimated_time_remaining", "=", "training_elapsed_time", "*", "(", "(", "self", ".", "num_epochs", "-", "starting_epoch", ")", "/", "\n", "float", "(", "self", ".", "epoch_number", "-", "starting_epoch", "+", "1", ")", "-", "1", ")", "\n", "formatted_time", "=", "str", "(", "datetime", ".", "timedelta", "(", "\n", "seconds", "=", "int", "(", "estimated_time_remaining", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Estimated training time remaining: %s\"", ",", "formatted_time", ")", "\n", "\n", "", "if", "self", ".", "should_stop_early", ":", "\n", "                ", "logger", ".", "info", "(", "\"Ran out of patience.  Stopping training.\"", ")", "\n", "break", "\n", "\n", "", "", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "TRAINING_END", ")", "\n", "\n", "return", "self", ".", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.CallbackApexTrainer.from_params": [[320, 376], ["allennlp.training.trainer_pieces.TrainerPieces.from_params", "params.pop_bool", "params.pop_int", "params.pop", "params.pop", "allennlp.common.checks.parse_cuda_device", "isinstance", "allennlp.training.optimizers.Optimizer.from_params", "params.pop", "params.assert_empty", "cls", "params.pop", "model.cuda.cuda.cuda", "params.pop", "allennlp.training.callbacks.callback.Callback.from_params", "model.cuda.cuda.named_parameters"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "# type: ignore", "\n", "params", ":", "Params", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "recover", ":", "bool", "=", "False", ",", "\n", "cache_directory", ":", "str", "=", "None", ",", "\n", "cache_prefix", ":", "str", "=", "None", ")", "->", "'CallbackTrainer'", ":", "\n", "        ", "pieces", "=", "TrainerPieces", ".", "from_params", "(", "\n", "params", ",", "serialization_dir", ",", "recover", ")", "# pylint: disable=no-member", "\n", "model", "=", "pieces", ".", "model", "\n", "params", "=", "pieces", ".", "params", "\n", "validation_iterator", "=", "pieces", ".", "validation_iterator", "or", "pieces", ".", "iterator", "\n", "\n", "shuffle", "=", "params", ".", "pop_bool", "(", "\"shuffle\"", ",", "True", ")", "\n", "num_epochs", "=", "params", ".", "pop_int", "(", "\"num_epochs\"", ",", "20", ")", "\n", "apex_opt_level", "=", "params", ".", "pop", "(", "'apex_opt_level'", ",", "None", ")", "\n", "keep_batchnorm_fp32", "=", "params", ".", "pop", "(", "\"keep_batchnorm_fp32\"", ",", "True", ")", "\n", "cuda_device", "=", "parse_cuda_device", "(", "params", ".", "pop", "(", "\"cuda_device\"", ",", "-", "1", ")", ")", "\n", "\n", "if", "isinstance", "(", "cuda_device", ",", "list", ")", ":", "\n", "            ", "model_device", "=", "cuda_device", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "model_device", "=", "cuda_device", "\n", "", "if", "model_device", ">=", "0", ":", "\n", "# Moving model to GPU here so that the optimizer state gets constructed on", "\n", "# the right device.", "\n", "            ", "model", "=", "model", ".", "cuda", "(", "model_device", ")", "\n", "\n", "", "parameters", "=", "[", "[", "n", ",", "p", "]", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "optimizer", "=", "Optimizer", ".", "from_params", "(", "parameters", ",", "params", ".", "pop", "(", "\"optimizer\"", ")", ")", "\n", "\n", "callbacks_params", "=", "params", ".", "pop", "(", "\"callbacks\"", ",", "[", "]", ")", "\n", "callbacks", ":", "List", "[", "Callback", "]", "=", "[", "Callback", ".", "from_params", "(", "params", "=", "callback_params", ",", "\n", "model", "=", "model", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "instances", "=", "pieces", ".", "train_dataset", ",", "\n", "iterator", "=", "pieces", ".", "iterator", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "validation_data", "=", "pieces", ".", "validation_dataset", ",", "\n", "validation_iterator", "=", "validation_iterator", ",", "\n", "serialization_dir", "=", "serialization_dir", ")", "\n", "for", "callback_params", "in", "callbacks_params", "]", "\n", "\n", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "model", ",", "\n", "pieces", ".", "train_dataset", ",", "\n", "pieces", ".", "iterator", ",", "\n", "optimizer", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "serialization_dir", "=", "serialization_dir", ",", "\n", "cuda_device", "=", "cuda_device", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "apex_opt_level", "=", "apex_opt_level", ",", "\n", "keep_batchnorm_fp32", "=", "keep_batchnorm_fp32", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.training.callback_apex_trainer.handle_errors": [[38, 49], ["functools.wraps", "method", "callback_apex_trainer..handler.fire_event"], "function", ["None"], ["def", "handle_errors", "(", "method", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "method", ")", "\n", "def", "train_and_handle_errors", "(", "self", ":", "'CallbackTrainer'", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "method", "(", "self", ")", "\n", "", "except", "Exception", "as", "exc", ":", "\n", "            ", "self", ".", "exception", "=", "exc", "\n", "self", ".", "handler", ".", "fire_event", "(", "Events", ".", "ERROR", ")", "\n", "raise", "\n", "\n", "", "", "return", "train_and_handle_errors", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict": [[7, 55], ["getattr", "state_dict.copy.copy.copy", "mixins.LoadStateDictWithPrefix.load_state_dict.load"], "methods", ["None"], ["    ", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "r\"\"\"Copies parameters and buffers from :attr:`state_dict` into\n        this module and its descendants. If :attr:`strict` is ``True``, then\n        the keys of :attr:`state_dict` must exactly match the keys returned\n        by this module's :meth:`~torch.nn.Module.state_dict` function.\n\n        Arguments:\n            state_dict (dict): a dict containing parameters and\n                persistent buffers.\n            strict (bool, optional): whether to strictly enforce that the keys\n                in :attr:`state_dict` match the keys returned by this module's\n                :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n        \"\"\"", "\n", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "\n", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "strict", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "", "", "", "load", "(", "self", ",", "prefix", "=", "prefix", ")", "\n", "\n", "if", "strict", ":", "\n", "            ", "error_msg", "=", "''", "\n", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "error_msgs", ".", "insert", "(", "\n", "0", ",", "'Unexpected key(s) in state_dict: {}. '", ".", "format", "(", "\n", "', '", ".", "join", "(", "'\"{}\"'", ".", "format", "(", "k", ")", "for", "k", "in", "unexpected_keys", ")", ")", ")", "\n", "", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "error_msgs", ".", "insert", "(", "\n", "0", ",", "'Missing key(s) in state_dict: {}. '", ".", "format", "(", "\n", "', '", ".", "join", "(", "'\"{}\"'", ".", "format", "(", "k", ")", "for", "k", "in", "missing_keys", ")", ")", ")", "\n", "\n", "", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.beam.BeamableMM.__init__": [[15, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "beam_size", "=", "None", ")", ":", "\n", "        ", "super", "(", "BeamableMM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.beam.BeamableMM.forward": [[19, 42], ["input1[].unfold().transpose", "input1[].unfold().transpose.bmm.view", "input1[].unfold().transpose.bmm", "input1[].unfold().transpose.dim", "input1[].unfold().transpose.size", "input1[].unfold().transpose.size", "input2.unfold", "input1[].unfold().transpose.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "input1[].unfold().transpose.bmm", "input1[].unfold"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input1", ",", "input2", ")", ":", "\n", "        ", "if", "(", "\n", "not", "self", ".", "training", "and", "# test mode", "\n", "self", ".", "beam_size", "is", "not", "None", "and", "# beam size is set", "\n", "input1", ".", "dim", "(", ")", "==", "3", "and", "# only support batched input", "\n", "input1", ".", "size", "(", "1", ")", "==", "1", "# single time step update", "\n", ")", ":", "\n", "            ", "bsz", ",", "beam", "=", "input1", ".", "size", "(", "0", ")", ",", "self", ".", "beam_size", "\n", "\n", "# bsz x 1 x nhu --> bsz/beam x beam x nhu", "\n", "input1", "=", "input1", "[", ":", ",", "0", ",", ":", "]", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# bsz x sz2 x nhu --> bsz/beam x sz2 x nhu", "\n", "input2", "=", "input2", ".", "unfold", "(", "0", ",", "beam", ",", "beam", ")", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "\n", "# use non batched operation if bsz = beam", "\n", "if", "input1", ".", "size", "(", "0", ")", "==", "1", ":", "\n", "                ", "output", "=", "torch", ".", "mm", "(", "input1", "[", "0", ",", ":", ",", ":", "]", ",", "input2", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "output", "=", "input1", ".", "bmm", "(", "input2", ")", "\n", "", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "input1", ".", "bmm", "(", "input2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.beam.BeamableMM.set_beam_size": [[43, 45], ["None"], "methods", ["None"], ["", "", "def", "set_beam_size", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.TiedHeadModule.__init__": [[12, 29], ["torch.Module.__init__", "tied_emb.size", "nn.Linear.TiedLinear", "softmax.TiedHeadModule.register_buffer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["    ", "def", "__init__", "(", "self", ",", "weights", ",", "input_dim", ",", "n_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "tied_emb", ",", "_", "=", "weights", "\n", "self", ".", "num_words", ",", "emb_dim", "=", "tied_emb", ".", "size", "(", ")", "\n", "\n", "self", ".", "word_proj", "=", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", "\n", "if", "input_dim", "!=", "emb_dim", ":", "\n", "            ", "linear", "=", "nn", ".", "Linear", "(", "input_dim", ",", "emb_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "word_proj", "=", "nn", ".", "Sequential", "(", "linear", ",", "self", ".", "word_proj", ")", "\n", "\n", "", "self", ".", "n_classes", "=", "n_classes", "\n", "if", "n_classes", ">", "0", ":", "\n", "            ", "self", ".", "class_proj", "=", "nn", ".", "Linear", "(", "input_dim", ",", "n_classes", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "out_dim", "=", "self", ".", "num_words", "+", "n_classes", "\n", "\n", "# Shortcut to create new tensors in the same device as the module", "\n", "self", ".", "register_buffer", "(", "'_float_tensor'", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.TiedHeadModule.forward": [[30, 41], ["functools.reduce", "X.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "softmax.TiedHeadModule.word_proj", "torch.cat.append", "torch.cat.append", "torch.cat.append", "softmax.TiedHeadModule.class_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "# Flatten out the batch and time dimensions", "\n", "        ", "input_size", "=", "functools", ".", "reduce", "(", "operator", ".", "mul", ",", "X", ".", "shape", "[", ":", "-", "1", "]", ",", "1", ")", "\n", "X", "=", "X", ".", "view", "(", "input_size", ",", "-", "1", ")", "\n", "\n", "out", "=", "[", "self", ".", "word_proj", "(", "X", ")", "]", "\n", "if", "self", ".", "n_classes", ":", "\n", "            ", "out", ".", "append", "(", "self", ".", "class_proj", "(", "X", ")", ")", "\n", "\n", "", "out", "=", "torch", ".", "cat", "(", "out", ",", "dim", "=", "1", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.__init__": [[64, 103], ["torch.Module.__init__", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "softmax.AdaptiveSoftmax._make_tail", "softmax.AdaptiveSoftmax.apply", "softmax.AdaptiveSoftmax.register_buffer", "cutoff.append", "adaptive_inputs.weights_for_band", "softmax.TiedHeadModule", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "hasattr", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax._make_tail", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.weights_for_band", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "input_dim", ",", "cutoff", ",", "dropout", ",", "factor", "=", "4.", ",", "\n", "adaptive_inputs", "=", "None", ",", "tie_proj", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "not", "cutoff", "or", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", ".", "append", "(", "vocab_size", ")", "\n", "\n", "", "assert", "vocab_size", "==", "cutoff", "[", "-", "1", "]", ",", "f'Cutoff {cutoff[-1]} is larger than vocab size {vocab_size}.'", "\n", "\n", "output_dim", "=", "cutoff", "[", "0", "]", "+", "len", "(", "cutoff", ")", "-", "1", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "lsm", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n", "if", "adaptive_inputs", "is", "not", "None", ":", "\n", "            ", "embed_weight", "=", "adaptive_inputs", ".", "weights_for_band", "(", "0", ")", "\n", "n_tails", "=", "len", "(", "cutoff", ")", "-", "1", "\n", "self", ".", "head", "=", "TiedHeadModule", "(", "embed_weight", ",", "input_dim", ",", "n_tails", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "head", "=", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "_make_tail", "(", "True", ",", "adaptive_inputs", ",", "tie_proj", ")", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "not", "isinstance", "(", "m", ",", "TiedLinear", ")", "and", "not", "isinstance", "(", "m", ",", "TiedHeadModule", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "LongTensor", "(", "[", "1", "]", ")", ")", "\n", "# versions prior to 1 had a bug that offset indices on the head by 1", "\n", "self", ".", "buggy_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax._make_tail": [[104, 136], ["torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "softmax.AdaptiveSoftmax.tail.append", "len", "adaptive_inputs.weights_for_band", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "linear.TiedLinear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "linear.TiedLinear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.weights_for_band", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["", "def", "_make_tail", "(", "self", ",", "fix_exponent", ",", "adaptive_inputs", "=", "None", ",", "tie_proj", "=", "False", ")", ":", "\n", "        ", "extra_denom", "=", "1", "if", "fix_exponent", "else", "0", "\n", "\n", "self", ".", "tail", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "dim", "=", "int", "(", "self", ".", "input_dim", "//", "self", ".", "factor", "**", "(", "i", "+", "extra_denom", ")", ")", "\n", "\n", "tied_emb", ",", "tied_proj", "=", "adaptive_inputs", ".", "weights_for_band", "(", "i", "+", "1", ")", "if", "adaptive_inputs", "is", "not", "None", "else", "(", "None", ",", "None", ")", "\n", "\n", "# There was a bug in the original Fairseq implementation, where", "\n", "# it assumes that self.input_dim has the same dimension as", "\n", "# tied_proj.shape[0] (the output dimension of the adaptive embeddings).", "\n", "# The change below removes this assumption.", "\n", "if", "tied_proj", "is", "not", "None", ":", "\n", "                ", "if", "tie_proj", ":", "\n", "                    ", "proj", "=", "TiedLinear", "(", "tied_proj", ",", "transpose", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "proj", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "input_dim", ",", "tied_proj", ".", "shape", "[", "1", "]", ",", "bias", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                ", "proj", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "m", "=", "nn", ".", "Sequential", "(", "\n", "proj", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "dim", ",", "self", ".", "cutoff", "[", "i", "+", "1", "]", "-", "self", ".", "cutoff", "[", "i", "]", ",", "bias", "=", "False", ",", "\n", ")", "if", "tied_emb", "is", "None", "else", "TiedLinear", "(", "tied_emb", ",", "transpose", "=", "False", ")", ",", "\n", ")", "\n", "\n", "self", ".", "tail", ".", "append", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.upgrade_state_dict_named": [[137, 143], ["softmax.AdaptiveSoftmax._make_tail", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax._make_tail"], ["", "", "def", "upgrade_state_dict_named", "(", "self", ",", "state_dict", ",", "name", ")", ":", "\n", "        ", "version_name", "=", "name", "+", "'.version'", "\n", "if", "version_name", "not", "in", "state_dict", ":", "\n", "            ", "self", ".", "buggy_offset", "=", "1", "\n", "self", ".", "_make_tail", "(", "False", ")", "\n", "state_dict", "[", "version_name", "]", "=", "torch", ".", "LongTensor", "(", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.adapt_target": [[144, 168], ["target.view.view.view", "range", "target.view.view.clone", "target.view.view.ge().mul", "target.view.ge().mul.any", "len", "target.view.view.lt", "target_idxs.append", "new_target.append", "target_idxs.append", "new_target.append", "target.view.view.ge", "target.view.ge().mul.nonzero().squeeze", "target[].add", "target.view.ge().mul.nonzero"], "methods", ["None"], ["", "", "def", "adapt_target", "(", "self", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        In order to be efficient, the AdaptiveSoftMax does not compute the\n        scores for all the word of the vocabulary for all the examples. It is\n        thus necessary to call the method adapt_target of the AdaptiveSoftMax\n        layer inside each forward pass.\n        \"\"\"", "\n", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "new_target", "=", "[", "target", ".", "clone", "(", ")", "]", "\n", "target_idxs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", "-", "1", ")", ":", "\n", "            ", "mask", "=", "target", ".", "ge", "(", "self", ".", "cutoff", "[", "i", "]", ")", ".", "mul", "(", "target", ".", "lt", "(", "self", ".", "cutoff", "[", "i", "+", "1", "]", ")", ")", "\n", "new_target", "[", "0", "]", "[", "mask", "]", "=", "self", ".", "cutoff", "[", "0", "]", "+", "i", "-", "self", ".", "buggy_offset", "\n", "\n", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "target_idxs", ".", "append", "(", "mask", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", ")", "\n", "new_target", ".", "append", "(", "target", "[", "mask", "]", ".", "add", "(", "-", "self", ".", "cutoff", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "target_idxs", ".", "append", "(", "None", ")", "\n", "new_target", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "new_target", ",", "target_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.forward": [[169, 192], ["torch.dropout.contiguous().view", "torch.dropout", "torch.dropout", "torch.dropout", "softmax.AdaptiveSoftmax.adapt_target", "range", "torch.dropout.size", "softmax.AdaptiveSoftmax.head", "len", "torch.dropout.contiguous", "output.append", "output.append", "torch.dropout.index_select"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.adapt_target"], ["", "def", "forward", "(", "self", ",", "X", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            X: (b x t x d)\n            target: (b x t)\n        Returns:\n            2 lists: output for each cutoff section and new targets by cut off\n        \"\"\"", "\n", "\n", "X", "=", "X", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "X", ".", "size", "(", "-", "1", ")", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "new_target", ",", "target_idxs", "=", "self", ".", "adapt_target", "(", "target", ")", "\n", "output", "=", "[", "self", ".", "head", "(", "X", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "target_idxs", ")", ")", ":", "\n", "            ", "if", "target_idxs", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "output", ".", "append", "(", "self", ".", "tail", "[", "i", "]", "(", "\n", "X", ".", "index_select", "(", "0", ",", "target_idxs", "[", "i", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "None", ")", "\n", "\n", "", "", "return", "output", ",", "new_target", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob": [[193, 223], ["X.contiguous().view.contiguous().view.size", "X.contiguous().view.contiguous().view.contiguous().view", "softmax.AdaptiveSoftmax.head", "softmax.AdaptiveSoftmax.lsm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "log_probs.view.view.view", "len", "len", "range", "X.contiguous().view.contiguous().view.contiguous", "len", "softmax.AdaptiveSoftmax.lsm", "log_probs_list.append"], "methods", ["None"], ["", "def", "get_log_prob", "(", "self", ",", "X", ",", "target", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the log probabilities for all the words of the vocabulary,\n        given a 2D tensor of hidden vectors.\n        \"\"\"", "\n", "\n", "# We don't support the target argument for now.", "\n", "assert", "target", "is", "None", "\n", "\n", "batch_size", ",", "seq_len", ",", "dim", "=", "X", ".", "size", "(", ")", "\n", "X", "=", "X", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", "\n", "\n", "head_y", "=", "self", ".", "head", "(", "X", ")", "\n", "# log_probs = head_y.new_zeros(X.size(0), self.vocab_size)", "\n", "\n", "head_size", "=", "self", ".", "cutoff", "[", "0", "]", "+", "len", "(", "self", ".", "tail", ")", "\n", "head_log_probs", "=", "self", ".", "lsm", "(", "head_y", ")", "\n", "log_probs_list", "=", "[", "head_log_probs", "[", ":", ",", ":", "self", ".", "cutoff", "[", "0", "]", "]", "]", "\n", "\n", "if", "len", "(", "self", ".", "tail", ")", ">", "0", ":", "\n", "            ", "tail_priors", "=", "head_log_probs", "[", ":", ",", "self", ".", "cutoff", "[", "0", "]", ":", "head_size", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "tail", ")", ")", ":", "\n", "                ", "tail_i", "=", "self", ".", "lsm", "(", "self", ".", "tail", "[", "i", "]", "(", "X", ")", ")", "\n", "tail_i", "=", "tail_i", "+", "tail_priors", "[", ":", ",", "i", ",", "None", "]", "\n", "log_probs_list", ".", "append", "(", "tail_i", ")", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_probs_list", ",", "dim", "=", "1", ")", "\n", "log_probs", "=", "log_probs", ".", "view", "(", "batch_size", ",", "seq_len", ",", "self", ".", "vocab_size", ")", "\n", "return", "log_probs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.linear.GehringLinear.__init__": [[11, 16], ["torch.Linear.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "dropout", "=", "0", ",", "bias", "=", "True", ",", "\n", "weight_norm", "=", "True", ")", ":", "\n", "        ", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "weight_norm", "=", "weight_norm", "\n", "super", "(", ")", ".", "__init__", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.linear.GehringLinear.reset_parameters": [[17, 35], ["math.sqrt", "linear.GehringLinear.weight.data.normal_", "linear.GehringLinear.bias.data.fill_", "torch.utils.weight_norm", "torch.utils.weight_norm"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "# One problem with initialization from the uniform distribution is that", "\n", "# the distribution of the outputs has a variance that grows with the", "\n", "# number of inputs. It turns out that we can normalize the variance of", "\n", "# each neuron\u2019s output to 1 by scaling its weight vector by the square", "\n", "# root of its fan-in (i.e. its number of inputs). Dropout further", "\n", "# increases the variance of each input, so we need to scale down std.", "\n", "# See A.3. in Gehring et al (2017): https://arxiv.org/pdf/1705.03122.", "\n", "        ", "std", "=", "math", ".", "sqrt", "(", "(", "1", "-", "self", ".", "dropout", ")", "/", "self", ".", "in_features", ")", "\n", "self", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "# Weight normalization is a reparameterization that decouples the", "\n", "# magnitude of a weight tensor from its direction. See Salimans and", "\n", "# Kingma (2016): https://arxiv.org/abs/1602.07868.", "\n", "", "if", "self", ".", "weight_norm", ":", "\n", "            ", "nn", ".", "utils", ".", "weight_norm", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.linear.TiedLinear.__init__": [[43, 47], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "weight", ",", "transpose", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "weight", "\n", "self", ".", "transpose", "=", "transpose", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.linear.TiedLinear.forward": [[48, 51], ["torch.linear", "torch.linear", "linear.TiedLinear.weight.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "weight", "=", "self", ".", "weight", ".", "t", "(", ")", "if", "self", ".", "transpose", "else", "self", ".", "weight", "\n", "return", "F", ".", "linear", "(", "X", ",", "weight", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.__init__": [[20, 57], ["allennlp.modules.token_embedders.TokenEmbedder.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "adaptive.AdaptiveEmbedding.apply", "vocab.get_vocab_size", "cutoff.append", "math.sqrt", "len", "int", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "adaptive.AdaptiveEmbedding.embeddings.append", "isinstance", "math.sqrt", "m.weight.data.normal_", "m.weight.data[].fill_", "hasattr", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["def", "__init__", "(", "self", ",", "vocab", ",", "namespace", ",", "padding_idx", ":", "int", ",", "\n", "initial_dim", ":", "int", ",", "factor", ":", "float", ",", "output_dim", ":", "int", ",", "\n", "cutoff", ":", "List", "[", "int", "]", ",", "vocab_size", ":", "int", "=", "None", ",", "scale_embeds", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "if", "not", "cutoff", "or", "vocab_size", ">", "cutoff", "[", "-", "1", "]", ":", "\n", "            ", "cutoff", ".", "append", "(", "vocab_size", ")", "\n", "\n", "", "assert", "vocab_size", "==", "cutoff", "[", "-", "1", "]", ",", "f'Cutoff {cutoff[-1]} is larger than vocab size {vocab_size}.'", "\n", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "embed_size", "=", "output_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "embeddings", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "output_dim", ")", "if", "scale_embeds", "else", "1", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "prev", "=", "self", ".", "cutoff", "[", "i", "-", "1", "]", "if", "i", ">", "0", "else", "0", "\n", "vocab_size", "=", "self", ".", "cutoff", "[", "i", "]", "-", "prev", "\n", "embed_size", "=", "int", "(", "initial_dim", "//", "(", "factor", "**", "i", ")", ")", "\n", "embed", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embed_size", ",", "padding_idx", ")", "\n", "projection", "=", "nn", ".", "Linear", "(", "embed_size", ",", "output_dim", ",", "bias", "=", "False", ")", "\n", "seq", "=", "nn", ".", "Sequential", "(", "embed", ",", "projection", ")", "\n", "self", ".", "embeddings", ".", "append", "(", "seq", ")", "\n", "\n", "", "def", "init_weights", "(", "m", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Embedding", ")", ":", "\n", "                ", "std", "=", "math", ".", "sqrt", "(", "1", "/", "m", ".", "weight", ".", "shape", "[", "1", "]", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "m", ".", "weight", ".", "data", "[", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "", "elif", "hasattr", "(", "m", ",", "'weight'", ")", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "\n", "# Recursively initialize weights of all children", "\n", "", "", "self", ".", "apply", "(", "init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.weights_for_band": [[58, 60], ["None"], "methods", ["None"], ["", "def", "weights_for_band", "(", "self", ",", "band", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "[", "band", "]", "[", "0", "]", ".", "weight", ",", "self", ".", "embeddings", "[", "band", "]", "[", "1", "]", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.forward": [[61, 77], ["[].weight.new_zeros", "range", "len", "mask.any", "mask.mul_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "result_shape", "=", "X", ".", "shape", "+", "(", "self", ".", "embed_size", ",", ")", "\n", "result", "=", "self", ".", "embeddings", "[", "0", "]", "[", "0", "]", ".", "weight", ".", "new_zeros", "(", "result_shape", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoff", ")", ")", ":", "\n", "            ", "mask", "=", "X", "<", "self", ".", "cutoff", "[", "i", "]", "\n", "if", "i", ">", "0", ":", "\n", "                ", "mask", ".", "mul_", "(", "X", ">=", "self", ".", "cutoff", "[", "i", "-", "1", "]", ")", "\n", "chunk_input", "=", "X", "[", "mask", "]", "-", "self", ".", "cutoff", "[", "i", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "chunk_input", "=", "X", "[", "mask", "]", "\n", "", "if", "mask", ".", "any", "(", ")", ":", "\n", "                ", "result", "[", "mask", "]", "=", "self", ".", "embeddings", "[", "i", "]", "(", "chunk_input", ")", ".", "type_as", "(", "result", ")", "\n", "\n", "", "", "result", "=", "self", ".", "embed_scale", "*", "result", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.adaptive.AdaptiveEmbedding.get_output_dim": [[78, 81], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "embed_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding.__init__": [[20, 24], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "vocab", ",", "max_positions", ",", "embedding_dim", ",", "padding_idx", "=", "0", ",", "left_pad", "=", "False", ")", ":", "\n", "        ", "self", ".", "left_pad", "=", "left_pad", "\n", "super", "(", ")", ".", "__init__", "(", "num_embeddings", "=", "max_positions", ",", "\n", "embedding_dim", "=", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding.max_positions": [[25, 28], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "self", ".", "num_embeddings", "-", "self", ".", "padding_idx", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding.reset_parameters": [[29, 34], ["positional.LearnedPositionalEmbedding.weight.data.normal_", "positional.LearnedPositionalEmbedding.weight.data[].fill_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize weights. This is called in __init__.\"\"\"", "\n", "self", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "0.1", ")", "\n", "if", "self", ".", "padding_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", ".", "data", "[", "self", ".", "padding_idx", "]", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding.forward": [[35, 69], ["positional.make_positions", "super().forward", "positional.LearnedPositionalEmbedding._get_last_position", "positional.LearnedPositionalEmbedding._save_last_position"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._get_last_position", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._save_last_position"], ["", "", "def", "forward", "(", "self", ",", "X", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return the embeddings of the positions of the words.\n\n        Parameters\n        ----------\n            X : LongTensor with shape [batch_size, seq_len].\n                X contains the normal word indices. We first convert this into\n                their positions in each sequence. Then we retrieve the\n                position embeddings.\n\n            incremental_state : bool\n                If True, then we assume that we're decoding a single step. We\n                will then return the next positional number in the sequence.\n        \"\"\"", "\n", "seq_len", "=", "X", ".", "shape", "[", "1", "]", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "start_pos", "=", "self", ".", "_get_last_position", "(", "incremental_state", ")", "\n", "max_pos", "=", "start_pos", "+", "seq_len", "\n", "self", ".", "_save_last_position", "(", "incremental_state", ",", "max_pos", ")", "\n", "", "else", ":", "\n", "            ", "start_pos", "=", "0", "\n", "max_pos", "=", "seq_len", "\n", "\n", "", "positions", "=", "make_positions", "(", "X", ".", "data", ",", "self", ".", "padding_idx", ",", "self", ".", "left_pad", ")", "\n", "pos_mask", "=", "positions", "!=", "self", ".", "padding_idx", "\n", "positions", "[", "pos_mask", "]", "=", "positions", "[", "pos_mask", "]", "+", "start_pos", "\n", "\n", "# if incremental_state is not None:", "\n", "#     # positions is the same for every token when decoding a single step", "\n", "#     positions = X.data.new(1, 1).fill_(", "\n", "#         self.padding_idx + X.shape[1])", "\n", "# else:", "\n", "#     positions = make_positions(X.data, self.padding_idx, self.left_pad)", "\n", "return", "super", "(", ")", ".", "forward", "(", "positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding.get_output_dim": [[70, 73], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding._get_last_position": [[74, 79], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "def", "_get_last_position", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "last_pos", "=", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'position'", ")", "\n", "if", "last_pos", "is", "None", ":", "\n", "            ", "last_pos", "=", "0", "\n", "", "return", "last_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.LearnedPositionalEmbedding._save_last_position": [[80, 82], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_save_last_position", "(", "self", ",", "incremental_state", ",", "position", ")", ":", "\n", "        ", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'position'", ",", "position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.__init__": [[112, 121], ["allennlp.modules.token_embedders.TokenEmbedder.__init__", "positional.SinusoidalPositionalEmbedding.get_embedding", "positional.SinusoidalPositionalEmbedding.register_buffer"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "vocab", ",", "embedding_dim", ",", "padding_idx", ",", "left_pad", ",", "init_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "init_size", "=", "init_size", "+", "1", "# for padding index", "\n", "weights", "=", "self", ".", "get_embedding", "(", "init_size", ",", "embedding_dim", ",", "padding_idx", ")", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "self", ".", "register_buffer", "(", "'weights'", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.prepare_for_onnx_export_": [[122, 124], ["None"], "methods", ["None"], ["", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.get_embedding": [[125, 166], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "inv_timescales.unsqueeze.unsqueeze.unsqueeze", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "math.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "n_embeds", ",", "embed_dim", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "max_ts", "=", "10000", "\n", "min_ts", "=", "1", "\n", "n_timescales", "=", "embed_dim", "//", "2", "\n", "increment", "=", "math", ".", "log", "(", "max_ts", "/", "min_ts", ")", "/", "(", "n_timescales", "-", "1", ")", "\n", "# Example increment: 9 / 384 = 0.024", "\n", "\n", "timescales", "=", "torch", ".", "arange", "(", "n_timescales", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# inv_timescales ranges from 1 to 1/10000 with log spacing", "\n", "inv_timescales", "=", "min_ts", "*", "torch", ".", "exp", "(", "timescales", "*", "-", "increment", ")", "\n", "# inv_timescales.shape == [embed_size // 2]", "\n", "\n", "positions", "=", "torch", ".", "arange", "(", "n_embeds", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# positions.shape ==  [n_embeds, 1]", "\n", "\n", "inv_timescales", "=", "inv_timescales", ".", "unsqueeze", "(", "0", ")", "\n", "# inv_timescales.shape == [1, embed_size // 2]", "\n", "\n", "scaled_time", "=", "positions", "*", "inv_timescales", "\n", "# scaled_time.shape == [n_embeds, embed_size // 2]", "\n", "\n", "sin_signal", "=", "torch", ".", "sin", "(", "scaled_time", ")", "\n", "cos_signal", "=", "torch", ".", "cos", "(", "scaled_time", ")", "\n", "signal", "=", "torch", ".", "cat", "(", "[", "sin_signal", ",", "cos_signal", "]", ",", "dim", "=", "1", ")", "\n", "# signal.shape == [n_embeds, embed_dim]", "\n", "\n", "# Ensure that embed_dim is even", "\n", "if", "embed_dim", "%", "2", "==", "1", ":", "\n", "            ", "signal", "=", "torch", ".", "cat", "(", "[", "signal", ",", "torch", ".", "zeros", "(", "n_embeds", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "signal", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "\n", "", "return", "signal", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.forward": [[167, 212], ["positional.make_positions", "positional.SinusoidalPositionalEmbedding.weights.index_select", "embeds.view.view.view", "embeds.view.view.detach", "positional.SinusoidalPositionalEmbedding._get_last_position", "positional.SinusoidalPositionalEmbedding._save_last_position", "positional.SinusoidalPositionalEmbedding.get_embedding", "positional.SinusoidalPositionalEmbedding.weights.new_tensor", "positional.SinusoidalPositionalEmbedding.register_buffer", "make_positions.view"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._get_last_position", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._save_last_position", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.get_embedding"], ["", "def", "forward", "(", "self", ",", "X", ",", "incremental_state", "=", "None", ",", "timestep", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "batch_size", ",", "seq_len", "=", "X", ".", "shape", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "start_pos", "=", "self", ".", "_get_last_position", "(", "incremental_state", ")", "\n", "max_pos", "=", "start_pos", "+", "seq_len", "\n", "self", ".", "_save_last_position", "(", "incremental_state", ",", "max_pos", ")", "\n", "", "else", ":", "\n", "            ", "start_pos", "=", "0", "\n", "max_pos", "=", "seq_len", "\n", "\n", "# bsz, seq_len = torch.onnx.operators.shape_as_tensor(X)", "\n", "# Expand embeddings if needed", "\n", "", "max_pos", "=", "max_pos", "+", "1", "\n", "if", "max_pos", ">", "self", ".", "weights", ".", "shape", "[", "0", "]", ":", "\n", "            ", "weights", "=", "self", ".", "get_embedding", "(", "max_pos", ",", "self", ".", "embedding_dim", ",", "\n", "self", ".", "padding_idx", ")", "\n", "# We need to manually move weights to GPU if needed", "\n", "weights", "=", "self", ".", "weights", ".", "new_tensor", "(", "weights", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'weights'", ",", "weights", ")", "\n", "\n", "# if incremental_state is not None:", "\n", "#     # positions is the same for every token when decoding a single step", "\n", "#     pos = (timestep.int() + 1).long() if timestep is not None else seq_len", "\n", "#     if self.onnx_trace:", "\n", "#         return self.weights[self.padding_idx + pos, :].unsqueeze(1).repeat(bsz, 1, 1)", "\n", "#     return self.weights[self.padding_idx + pos, :].expand(bsz, 1, -1)", "\n", "\n", "", "positions", "=", "make_positions", "(", "\n", "X", ",", "self", ".", "padding_idx", ",", "self", ".", "left_pad", ",", "self", ".", "onnx_trace", ")", "\n", "pos_mask", "=", "positions", "!=", "self", ".", "padding_idx", "\n", "positions", "[", "pos_mask", "]", "=", "positions", "[", "pos_mask", "]", "+", "start_pos", "\n", "# if self.onnx_trace:", "\n", "#     flat_embeddings = self.weights.detach().index_select(0, positions.view(-1))", "\n", "#     embedding_shape = torch.cat(", "\n", "#         (bsz.view(1), seq_len.view(1), torch.LongTensor([-1])))", "\n", "#     embeddings = torch.onnx.operators.reshape_from_tensor_shape(", "\n", "#         flat_embeddings, embedding_shape)", "\n", "#     return embeddings", "\n", "\n", "embeds", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "embeds", "=", "embeds", ".", "view", "(", "batch_size", ",", "seq_len", ",", "-", "1", ")", "\n", "return", "embeds", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.max_positions": [[213, 216], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding.get_output_dim": [[217, 220], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._get_last_position": [[221, 226], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "def", "_get_last_position", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "last_pos", "=", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'position'", ")", "\n", "if", "last_pos", "is", "None", ":", "\n", "            ", "last_pos", "=", "0", "\n", "", "return", "last_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.SinusoidalPositionalEmbedding._save_last_position": [[227, 229], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_save_last_position", "(", "self", ",", "incremental_state", ",", "position", ")", ":", "\n", "        ", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'position'", ",", "position", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions": [[231, 269], ["make_positions.range_buf.type_as", "X.ne", "make_positions.range_buf[].expand_as", "X.clone().masked_scatter_", "X.ne", "range_buf.expand_as", "X.size", "hasattr", "X.new", "make_positions.range_buf.numel", "torch.arange", "torch.arange", "torch.arange", "X.ne.long().sum().unsqueeze", "X.clone", "torch._dim_arange", "torch._dim_arange", "torch._dim_arange", "X.ne.long().sum().unsqueeze", "X.ne.long", "X.ne.long", "X.size", "X.ne.long().sum", "X.ne.long().sum", "X.ne.long", "X.ne.long"], "function", ["None"], ["", "", "def", "make_positions", "(", "X", ",", "padding_idx", ",", "left_pad", ",", "onnx_trace", "=", "False", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n\n    Position numbers begin at padding_idx+1.\n\n    Padding symbols are ignored, but it is necessary to specify whether padding\n    is added on the left side (left_pad=True) or right side (left_pad=False).\n    \"\"\"", "\n", "max_seq_len", "=", "X", ".", "shape", "[", "1", "]", "\n", "# torch._dim_arange is a temporary hack to allow tracing of arange like", "\n", "# constructs with dynamic bounds on arange.  Normal arange is not traceable", "\n", "# because it does not take any tensor inputs; if the range you need is", "\n", "# based on another tensor, calling this function directly will preserve", "\n", "# tracing.  Get rid of this when arange can directly take tensors for", "\n", "# bounds (so that it can be traced directly).", "\n", "if", "onnx_trace", ":", "\n", "        ", "range_buf", "=", "torch", ".", "_dim_arange", "(", "like", "=", "X", ",", "dim", "=", "1", ")", "+", "padding_idx", "+", "1", "\n", "mask", "=", "X", ".", "ne", "(", "padding_idx", ")", "\n", "positions", "=", "range_buf", ".", "expand_as", "(", "X", ")", "\n", "if", "left_pad", ":", "\n", "            ", "offsets", "=", "max_seq_len", "-", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "positions", "=", "positions", "-", "offsets", "\n", "", "return", "positions", "*", "mask", ".", "long", "(", ")", "+", "padding_idx", "*", "(", "1", "-", "mask", ".", "long", "(", ")", ")", "\n", "\n", "", "max_pos", "=", "padding_idx", "+", "1", "+", "X", ".", "size", "(", "1", ")", "\n", "\n", "# Function attributes are used for caching", "\n", "if", "not", "hasattr", "(", "make_positions", ",", "'range_buf'", ")", ":", "\n", "        ", "make_positions", ".", "range_buf", "=", "X", ".", "new", "(", ")", "\n", "", "make_positions", ".", "range_buf", "=", "make_positions", ".", "range_buf", ".", "type_as", "(", "X", ")", "\n", "if", "make_positions", ".", "range_buf", ".", "numel", "(", ")", "<", "max_pos", ":", "\n", "        ", "torch", ".", "arange", "(", "padding_idx", "+", "1", ",", "max_pos", ",", "out", "=", "make_positions", ".", "range_buf", ")", "\n", "", "mask", "=", "X", ".", "ne", "(", "padding_idx", ")", "\n", "positions", "=", "make_positions", ".", "range_buf", "[", ":", "X", ".", "size", "(", "1", ")", "]", ".", "expand_as", "(", "X", ")", "\n", "if", "left_pad", ":", "\n", "        ", "offsets", "=", "max_seq_len", "-", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "positions", "=", "positions", "-", "offsets", "\n", "", "return", "X", ".", "clone", "(", ")", ".", "masked_scatter_", "(", "mask", ",", "positions", "[", "mask", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.__init__": [[51, 62], ["allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder.__init__", "token_embedders.items", "sum_text_field_embedder.SumTextFieldEmbedder.add_module"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "token_embedders", ":", "Dict", "[", "str", ",", "TokenEmbedder", "]", ",", "\n", "embedder_to_indexer_map", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "allow_unmatched_keys", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_token_embedders", "=", "token_embedders", "\n", "self", ".", "_embedder_to_indexer_map", "=", "embedder_to_indexer_map", "\n", "for", "key", ",", "embedder", "in", "token_embedders", ".", "items", "(", ")", ":", "\n", "            ", "name", "=", "'token_embedder_%s'", "%", "key", "\n", "self", ".", "add_module", "(", "name", ",", "embedder", ")", "\n", "", "self", ".", "_allow_unmatched_keys", "=", "allow_unmatched_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim": [[63, 69], ["sum_text_field_embedder.SumTextFieldEmbedder._token_embedders.values", "max", "output_dim.append", "embedder.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim"], ["", "@", "overrides", "\n", "def", "get_output_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "output_dim", "=", "[", "]", "\n", "for", "embedder", "in", "self", ".", "_token_embedders", ".", "values", "(", ")", ":", "\n", "            ", "output_dim", ".", "append", "(", "embedder", ".", "get_output_dim", "(", ")", ")", "\n", "", "return", "max", "(", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.forward": [[70, 119], ["sum_text_field_embedder.SumTextFieldEmbedder._token_embedders.keys", "text_field_input.keys", "sorted", "torch.stack().sum", "getattr", "range", "allennlp.modules.time_distributed.TimeDistributed.", "embedded_representations.append", "allennlp.common.checks.ConfigurationError", "allennlp.modules.time_distributed.TimeDistributed", "torch.stack", "sum_text_field_embedder.SumTextFieldEmbedder._token_embedders.keys", "text_field_input.keys", "allennlp.common.checks.ConfigurationError", "list", "list", "str", "str", "sum_text_field_embedder.SumTextFieldEmbedder._token_embedders.keys", "text_field_input.keys"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text_field_input", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "num_wrapping_dims", ":", "int", "=", "0", ",", "\n", "incremental_state", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "embedder_keys", "=", "self", ".", "_token_embedders", ".", "keys", "(", ")", "\n", "input_keys", "=", "text_field_input", ".", "keys", "(", ")", "\n", "\n", "# Check for unmatched keys", "\n", "if", "not", "self", ".", "_allow_unmatched_keys", ":", "\n", "            ", "if", "embedder_keys", "<", "input_keys", ":", "\n", "# token embedder keys are a strict subset of text field input keys.", "\n", "                ", "message", "=", "(", "f\"Your text field is generating more keys ({list(input_keys)}) \"", "\n", "f\"than you have token embedders ({list(embedder_keys)}. \"", "\n", "f\"If you are using a token embedder that requires multiple keys \"", "\n", "f\"(for example, the OpenAI Transformer embedder or the BERT embedder) \"", "\n", "f\"you need to add allow_unmatched_keys = True \"", "\n", "f\"(and likely an embedder_to_indexer_map) to your \"", "\n", "f\"BasicTextFieldEmbedder configuration. \"", "\n", "f\"Otherwise, you should check that there is a 1:1 embedding \"", "\n", "f\"between your token indexers and token embedders.\"", ")", "\n", "raise", "ConfigurationError", "(", "message", ")", "\n", "\n", "", "elif", "self", ".", "_token_embedders", ".", "keys", "(", ")", "!=", "text_field_input", ".", "keys", "(", ")", ":", "\n", "# some other mismatch", "\n", "                ", "message", "=", "\"Mismatched token keys: %s and %s\"", "%", "(", "str", "(", "self", ".", "_token_embedders", ".", "keys", "(", ")", ")", ",", "\n", "str", "(", "text_field_input", ".", "keys", "(", ")", ")", ")", "\n", "raise", "ConfigurationError", "(", "message", ")", "\n", "\n", "", "", "embedded_representations", "=", "[", "]", "\n", "keys", "=", "sorted", "(", "embedder_keys", ")", "\n", "for", "key", "in", "keys", ":", "\n", "# If we pre-specified a mapping explictly, use that.", "\n", "            ", "if", "self", ".", "_embedder_to_indexer_map", "is", "not", "None", ":", "\n", "                ", "tensors", "=", "[", "text_field_input", "[", "indexer_key", "]", "for", "\n", "indexer_key", "in", "self", ".", "_embedder_to_indexer_map", "[", "key", "]", "]", "\n", "", "else", ":", "\n", "# otherwise, we assume the mapping between indexers and embedders", "\n", "# is bijective and just use the key directly.", "\n", "                ", "tensors", "=", "[", "text_field_input", "[", "key", "]", "]", "\n", "# Note: need to use getattr here so that the pytorch voodoo", "\n", "# with submodules works with multiple GPUs.", "\n", "", "embedder", "=", "getattr", "(", "self", ",", "'token_embedder_{}'", ".", "format", "(", "key", ")", ")", "\n", "for", "_", "in", "range", "(", "num_wrapping_dims", ")", ":", "\n", "                ", "embedder", "=", "TimeDistributed", "(", "embedder", ")", "\n", "", "token_vectors", "=", "embedder", "(", "*", "tensors", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "embedded_representations", ".", "append", "(", "token_vectors", ")", "\n", "\n", "", "combined", "=", "torch", ".", "stack", "(", "embedded_representations", ",", "dim", "=", "-", "1", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "return", "combined", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params": [[121, 164], ["params.pop", "params.pop_bool", "params.pop", "params.assert_empty", "cls", "embedder_to_indexer_map.as_dict.as_dict.as_dict", "warnings.warn", "list", "allennlp.modules.token_embedders.token_embedder.TokenEmbedder.from_params", "DeprecationWarning", "params.keys", "params.pop", "allennlp.modules.token_embedders.token_embedder.TokenEmbedder.from_params", "params.pop.items"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params"], ["", "@", "classmethod", "\n", "def", "from_params", "(", "cls", ",", "vocab", ":", "Vocabulary", ",", "params", ":", "Params", ")", "->", "'BasicTextFieldEmbedder'", ":", "# type: ignore", "\n", "# pylint: disable=arguments-differ,bad-super-call", "\n", "\n", "# The original `from_params` for this class was designed in a way that didn't agree", "\n", "# with the constructor. The constructor wants a 'token_embedders' parameter that is a", "\n", "# `Dict[str, TokenEmbedder]`, but the original `from_params` implementation expected those", "\n", "# key-value pairs to be top-level in the params object.", "\n", "#", "\n", "# This breaks our 'configuration wizard' and configuration checks. Hence, going forward,", "\n", "# the params need a 'token_embedders' key so that they line up with what the constructor wants.", "\n", "# For now, the old behavior is still supported, but produces a DeprecationWarning.", "\n", "\n", "        ", "embedder_to_indexer_map", "=", "params", ".", "pop", "(", "\"embedder_to_indexer_map\"", ",", "None", ")", "\n", "if", "embedder_to_indexer_map", "is", "not", "None", ":", "\n", "            ", "embedder_to_indexer_map", "=", "embedder_to_indexer_map", ".", "as_dict", "(", "\n", "quiet", "=", "True", ")", "\n", "", "allow_unmatched_keys", "=", "params", ".", "pop_bool", "(", "\"allow_unmatched_keys\"", ",", "False", ")", "\n", "\n", "token_embedder_params", "=", "params", ".", "pop", "(", "'token_embedders'", ",", "None", ")", "\n", "\n", "if", "token_embedder_params", "is", "not", "None", ":", "\n", "# New way: explicitly specified, so use it.", "\n", "            ", "token_embedders", "=", "{", "\n", "name", ":", "TokenEmbedder", ".", "from_params", "(", "subparams", ",", "vocab", "=", "vocab", ")", "\n", "for", "name", ",", "subparams", "in", "token_embedder_params", ".", "items", "(", ")", "\n", "}", "\n", "\n", "", "else", ":", "\n", "# Warn that the original behavior is deprecated", "\n", "            ", "warnings", ".", "warn", "(", "DeprecationWarning", "(", "\"the token embedders for BasicTextFieldEmbedder should now \"", "\n", "\"be specified as a dict under the 'token_embedders' key, \"", "\n", "\"not as top-level key-value pairs\"", ")", ")", "\n", "\n", "token_embedders", "=", "{", "}", "\n", "keys", "=", "list", "(", "params", ".", "keys", "(", ")", ")", "\n", "for", "key", "in", "keys", ":", "\n", "                ", "embedder_params", "=", "params", ".", "pop", "(", "key", ")", "\n", "token_embedders", "[", "key", "]", "=", "TokenEmbedder", ".", "from_params", "(", "\n", "vocab", "=", "vocab", ",", "params", "=", "embedder_params", ")", "\n", "\n", "", "", "params", ".", "assert_empty", "(", "cls", ".", "__name__", ")", "\n", "return", "cls", "(", "token_embedders", ",", "embedder_to_indexer_map", ",", "allow_unmatched_keys", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_positional.TestEmbeddings.test_make_positions": [[9, 41], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "print", "print", "test_positional.TestEmbeddings.assertAlmostEqual", "test_positional.TestEmbeddings.assertAlmostEqual", "tell.modules.token_embedders.positional.make_positions", "tell.modules.token_embedders.positional.make_positions", "tell.modules.token_embedders.positional.make_positions"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.positional.make_positions"], ["    ", "def", "test_make_positions", "(", "self", ")", ":", "\n", "        ", "pad", "=", "1", "\n", "\n", "left_pad_input", "=", "torch", ".", "LongTensor", "(", "[", "\n", "[", "9", ",", "9", ",", "9", ",", "9", ",", "9", "]", ",", "\n", "[", "1", ",", "9", ",", "9", ",", "9", ",", "9", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "9", ",", "9", "]", ",", "\n", "]", ")", "\n", "left_pad_output", "=", "torch", ".", "LongTensor", "(", "[", "\n", "[", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", ",", "\n", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "2", ",", "3", "]", ",", "\n", "]", ")", "\n", "\n", "right_pad_input", "=", "torch", ".", "LongTensor", "(", "[", "\n", "[", "9", ",", "9", ",", "9", ",", "9", ",", "9", "]", ",", "\n", "[", "9", ",", "9", ",", "9", ",", "9", ",", "1", "]", ",", "\n", "[", "9", ",", "9", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", ")", "\n", "right_pad_output", "=", "torch", ".", "LongTensor", "(", "[", "\n", "[", "2", ",", "3", ",", "4", ",", "5", ",", "6", "]", ",", "\n", "[", "2", ",", "3", ",", "4", ",", "5", ",", "1", "]", ",", "\n", "[", "2", ",", "3", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", ")", "\n", "\n", "print", "(", "left_pad_output", ")", "\n", "print", "(", "make_positions", "(", "left_pad_input", ",", "pad", ",", "left_pad", "=", "True", ")", ")", "\n", "self", ".", "assertAlmostEqual", "(", "left_pad_output", ",", "\n", "make_positions", "(", "left_pad_input", ",", "pad", ",", "left_pad", "=", "True", ")", ")", "\n", "\n", "self", ".", "assertAlmostEqual", "(", "right_pad_output", ",", "\n", "make_positions", "(", "right_pad_input", ",", "pad", ",", "left_pad", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_positional.TestEmbeddings.assertAlmostEqual": [[42, 45], ["test_positional.TestEmbeddings.assertEqual", "test_positional.TestEmbeddings.assertLess", "t1.size", "t2.size"], "methods", ["None"], ["", "def", "assertAlmostEqual", "(", "self", ",", "t1", ",", "t2", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "t1", ".", "size", "(", ")", ",", "t2", ".", "size", "(", ")", ",", "\"size mismatch\"", ")", "\n", "self", ".", "assertLess", "(", "(", "t1", "-", "t2", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ",", "1e-4", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_linearized.TestLinearizedConvolution.test_linearized_with_empty_incremental_state": [[9, 20], ["tell.modules.convolutions.linearized.LinearizedConvolution", "torch.randn", "tell.modules.convolutions.linearized.LinearizedConvolution.", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["    ", "def", "test_linearized_with_empty_incremental_state", "(", "self", ")", ":", "\n", "        ", "conv", "=", "LinearizedConvolution", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "2", ")", "\n", "# conv.weight_v.shape == [kernel_size, in_channels, out_channels]", "\n", "# conv.weight_g.shape == [1, 1, out_channels]", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output", "=", "conv", "(", "X", ")", "\n", "output_incremental", "=", "conv", "(", "X", ",", "incremental_state", "=", "{", "}", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output", ",", "output_incremental", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_linearized.TestLinearizedConvolution.test_linearized_using_multi_step_incremental_state": [[21, 46], ["tell.modules.convolutions.linearized.LinearizedConvolution", "torch.randn", "tell.modules.convolutions.linearized.LinearizedConvolution.", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["", "def", "test_linearized_using_multi_step_incremental_state", "(", "self", ")", ":", "\n", "        ", "conv", "=", "LinearizedConvolution", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "2", ")", "\n", "# conv.weight_v.shape == [kernel_size, in_channels, out_channels]", "\n", "# conv.weight_g.shape == [1, 1, out_channels]", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "8", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output_full", "=", "conv", "(", "X", ")", "\n", "# output_full.shape == [seq_len, batch_size, out_channels]", "\n", "# import pudb", "\n", "# pudb.set_trace()", "\n", "incremental_state", "=", "{", "}", "\n", "\n", "# Feed in first 3 steps", "\n", "output_incr", "=", "conv", "(", "X", "[", ":", "3", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", ":", "3", "]", ",", "output_incr", ")", "\n", "\n", "# Feed in next 1 step", "\n", "output_incr", "=", "conv", "(", "X", "[", "3", ":", "4", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "3", ":", "4", "]", ",", "output_incr", ")", "\n", "\n", "# Feed in final 4 steps", "\n", "output_incr", "=", "conv", "(", "X", "[", "4", ":", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "4", ":", "]", ",", "output_incr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_linearized.TestLinearizedConvolution.test_linearized_using_incremental_state": [[47, 63], ["tell.modules.convolutions.linearized.LinearizedConvolution", "torch.randn", "tell.modules.convolutions.linearized.LinearizedConvolution.", "range", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["", "def", "test_linearized_using_incremental_state", "(", "self", ")", ":", "\n", "        ", "conv", "=", "LinearizedConvolution", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "2", ")", "\n", "# conv.weight_v.shape == [kernel_size, in_channels, out_channels]", "\n", "# conv.weight_g.shape == [1, 1, out_channels]", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output_full", "=", "conv", "(", "X", ")", "\n", "# output_full.shape == [seq_len, batch_size, out_channels]", "\n", "# import pudb", "\n", "# pudb.set_trace()", "\n", "incremental_state", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "output_incr", "=", "conv", "(", "X", "[", "i", ":", "i", "+", "1", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "i", ":", "i", "+", "1", "]", ",", "output_incr", ")", "\n", "# output_incr.shape == [1, batch_size, out_channels]", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_linearized.TestLinearizedConvolution.test_linearized_using_incremental_state_pad_1": [[65, 83], ["tell.modules.convolutions.linearized.LinearizedConvolution", "torch.randn", "tell.modules.convolutions.linearized.LinearizedConvolution.", "range", "tell.modules.convolutions.linearized.LinearizedConvolution.", "test_linearized.TestLinearizedConvolution.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["", "", "def", "test_linearized_using_incremental_state_pad_1", "(", "self", ")", ":", "\n", "        ", "conv", "=", "LinearizedConvolution", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "# conv.weight_v.shape == [kernel_size, in_channels, out_channels]", "\n", "# conv.weight_g.shape == [1, 1, out_channels]", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output_full", "=", "conv", "(", "X", ")", "\n", "# output_full.shape == [seq_len - 1, batch_size, out_channels]", "\n", "\n", "incremental_state", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "output_incr", "=", "conv", "(", "X", "[", "i", ":", "i", "+", "1", "]", ",", "incremental_state", ")", "\n", "# Because padding is 1, we ignore the first output. The first", "\n", "# output assumes that the padding is `kernel_size -1`.", "\n", "if", "i", ">=", "1", ":", "\n", "                ", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "i", "-", "1", ":", "i", "]", ",", "output_incr", ")", "\n", "# output_incr.shape == [1, batch_size, out_channels]", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_linearized.TestLinearizedConvolution.assertAlmostEqual": [[85, 88], ["test_linearized.TestLinearizedConvolution.assertEqual", "test_linearized.TestLinearizedConvolution.assertLess", "t1.size", "t2.size"], "methods", ["None"], ["", "", "", "def", "assertAlmostEqual", "(", "self", ",", "t1", ",", "t2", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "t1", ".", "size", "(", ")", ",", "t2", ".", "size", "(", ")", ",", "\"size mismatch\"", ")", "\n", "self", ".", "assertLess", "(", "(", "t1", "-", "t2", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ",", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_base.TestConvTBC.test_convtbc": [[9, 46], ["tell.modules.convolutions.base.ConvTBC", "tell.modules.convolutions.base.ConvBCT", "tell.modules.convolutions.base.ConvTBC.weight_g.data.copy_", "tell.modules.convolutions.base.ConvTBC.weight_v.data.copy_", "tell.modules.convolutions.base.ConvTBC.bias.data.copy_", "torch.randn", "torch.randn.data.transpose().transpose", "tell.modules.convolutions.base.ConvTBC.", "tell.modules.convolutions.base.ConvBCT.", "test_base.TestConvTBC.assertAlmostEqual", "torch.randn", "torch.randn.transpose().transpose().contiguous", "tell.modules.convolutions.base.ConvTBC.backward", "tell.modules.convolutions.base.ConvBCT.backward", "test_base.TestConvTBC.assertAlmostEqual", "test_base.TestConvTBC.assertAlmostEqual", "test_base.TestConvTBC.assertAlmostEqual", "test_base.TestConvTBC.assertAlmostEqual", "tell.modules.convolutions.base.ConvBCT.weight_g.data.transpose", "tell.modules.convolutions.base.ConvBCT.weight_v.data.transpose", "tell.modules.convolutions.base.ConvTBC.data.transpose().transpose", "tell.modules.convolutions.base.ConvTBC.size", "tell.modules.convolutions.base.ConvTBC.weight_g.grad.data.transpose", "tell.modules.convolutions.base.ConvTBC.weight_v.grad.data.transpose", "torch.randn.grad.data.transpose().transpose", "torch.randn.data.transpose", "torch.randn.transpose().transpose", "tell.modules.convolutions.base.ConvTBC.data.transpose", "torch.randn.grad.data.transpose", "torch.randn.transpose"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.backward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.backward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["    ", "def", "test_convtbc", "(", "self", ")", ":", "\n", "        ", "conv_tbc", "=", "ConvTBC", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "# conv_tbc.weight_v.shape == [kernel_size, in_channels, out_channels]", "\n", "# conv_tbc.weight_g.shape == [1, 1, out_channels]", "\n", "conv_bct", "=", "ConvBCT", "(", "4", ",", "5", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", "\n", "# conv_bct.weight_v.shape == [out_channels, in_channels, kernel_size]", "\n", "# conv_bct.weight_g.shape == [out_channels, 1, 1]", "\n", "\n", "conv_tbc", ".", "weight_g", ".", "data", ".", "copy_", "(", "conv_bct", ".", "weight_g", ".", "data", ".", "transpose", "(", "0", ",", "2", ")", ")", "\n", "conv_tbc", ".", "weight_v", ".", "data", ".", "copy_", "(", "conv_bct", ".", "weight_v", ".", "data", ".", "transpose", "(", "0", ",", "2", ")", ")", "\n", "conv_tbc", ".", "bias", ".", "data", ".", "copy_", "(", "conv_bct", ".", "bias", ".", "data", ")", "\n", "\n", "input_tbc", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "input_bct", "=", "input_tbc", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "input_bct", ".", "requires_grad", "=", "True", "\n", "\n", "output_tbc", "=", "conv_tbc", "(", "input_tbc", ")", "\n", "output_bct", "=", "conv_bct", "(", "input_bct", ")", "\n", "\n", "self", ".", "assertAlmostEqual", "(", "output_tbc", ".", "data", ".", "transpose", "(", "\n", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "output_bct", ".", "data", ")", "\n", "\n", "grad_tbc", "=", "torch", ".", "randn", "(", "output_tbc", ".", "size", "(", ")", ")", "\n", "grad_bct", "=", "grad_tbc", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "output_tbc", ".", "backward", "(", "grad_tbc", ")", "\n", "output_bct", ".", "backward", "(", "grad_bct", ")", "\n", "\n", "self", ".", "assertAlmostEqual", "(", "conv_tbc", ".", "weight_g", ".", "grad", ".", "data", ".", "transpose", "(", "0", ",", "2", ")", ",", "\n", "conv_bct", ".", "weight_g", ".", "grad", ".", "data", ")", "\n", "self", ".", "assertAlmostEqual", "(", "conv_tbc", ".", "weight_v", ".", "grad", ".", "data", ".", "transpose", "(", "0", ",", "2", ")", ",", "\n", "conv_bct", ".", "weight_v", ".", "grad", ".", "data", ")", "\n", "self", ".", "assertAlmostEqual", "(", "conv_tbc", ".", "bias", ".", "grad", ".", "data", ",", "\n", "conv_bct", ".", "bias", ".", "grad", ".", "data", ")", "\n", "self", ".", "assertAlmostEqual", "(", "\n", "input_tbc", ".", "grad", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ",", "\n", "input_bct", ".", "grad", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_base.TestConvTBC.assertAlmostEqual": [[47, 50], ["test_base.TestConvTBC.assertEqual", "test_base.TestConvTBC.assertLess", "t1.size", "t2.size"], "methods", ["None"], ["", "def", "assertAlmostEqual", "(", "self", ",", "t1", ",", "t2", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "t1", ".", "size", "(", ")", ",", "t2", ".", "size", "(", ")", ",", "\"size mismatch\"", ")", "\n", "self", ".", "assertLess", "(", "(", "t1", "-", "t2", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ",", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.test_self_attention_with_empty_incremental_state": [[9, 20], ["tell.modules.attention.self_attention.SelfAttention", "torch.randn", "tell.modules.attention.self_attention.SelfAttention.", "tell.modules.attention.self_attention.SelfAttention.", "test_self_attention.TestSelfAttention.TestSelfAttention.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["    ", "def", "test_self_attention_with_empty_incremental_state", "(", "self", ")", ":", "\n", "        ", "attn", "=", "SelfAttention", "(", "4", ",", "5", ",", "num_heads", "=", "1", ")", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output", "=", "attn", "(", "X", ")", "\n", "# output.shape == [seq_len, batch_size, out_channels]", "\n", "\n", "output_incremental", "=", "attn", "(", "X", ",", "incremental_state", "=", "{", "}", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output", ",", "output_incremental", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.test_self_attention_using_incremental_state": [[21, 34], ["tell.modules.attention.self_attention.SelfAttention", "torch.randn", "tell.modules.attention.self_attention.SelfAttention.", "range", "tell.modules.attention.self_attention.SelfAttention.", "test_self_attention.TestSelfAttention.TestSelfAttention.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["", "def", "test_self_attention_using_incremental_state", "(", "self", ")", ":", "\n", "        ", "attn", "=", "SelfAttention", "(", "4", ",", "5", ",", "num_heads", "=", "1", ")", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "7", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output_full", "=", "attn", "(", "X", ")", "\n", "# output.shape == [seq_len, batch_size, out_channels]", "\n", "\n", "incremental_state", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "output_incr", "=", "attn", "(", "X", "[", "i", ":", "i", "+", "1", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "i", ":", "i", "+", "1", "]", ",", "output_incr", ")", "\n", "# output_incr.shape == [1, batch_size, out_channels]", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.test_self_attention_using_multi_step_incremental_state": [[36, 58], ["tell.modules.attention.self_attention.SelfAttention", "torch.randn", "tell.modules.attention.self_attention.SelfAttention.", "tell.modules.attention.self_attention.SelfAttention.", "test_self_attention.TestSelfAttention.TestSelfAttention.assertAlmostEqual", "tell.modules.attention.self_attention.SelfAttention.", "test_self_attention.TestSelfAttention.TestSelfAttention.assertAlmostEqual", "tell.modules.attention.self_attention.SelfAttention.", "test_self_attention.TestSelfAttention.TestSelfAttention.assertAlmostEqual"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual"], ["", "", "def", "test_self_attention_using_multi_step_incremental_state", "(", "self", ")", ":", "\n", "        ", "attn", "=", "SelfAttention", "(", "4", ",", "5", ",", "num_heads", "=", "1", ")", "\n", "\n", "X", "=", "torch", ".", "randn", "(", "8", ",", "2", ",", "4", ",", "requires_grad", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "output_full", "=", "attn", "(", "X", ")", "\n", "# output.shape == [seq_len, batch_size, out_channels]", "\n", "\n", "incremental_state", "=", "{", "}", "\n", "\n", "# Feed in first 3 steps", "\n", "output_incr", "=", "attn", "(", "X", "[", ":", "3", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", ":", "3", "]", ",", "output_incr", ")", "\n", "\n", "# Feed in next 1 step", "\n", "output_incr", "=", "attn", "(", "X", "[", "3", ":", "4", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "3", ":", "4", "]", ",", "output_incr", ")", "\n", "\n", "# Feed in last 4 steps", "\n", "output_incr", "=", "attn", "(", "X", "[", "4", ":", "]", ",", "incremental_state", ")", "\n", "self", ".", "assertAlmostEqual", "(", "output_full", "[", "4", ":", "]", ",", "output_incr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tests.test_self_attention.TestSelfAttention.assertAlmostEqual": [[59, 62], ["test_self_attention.TestSelfAttention.TestSelfAttention.assertEqual", "test_self_attention.TestSelfAttention.TestSelfAttention.assertLess", "t1.size", "t2.size"], "methods", ["None"], ["", "def", "assertAlmostEqual", "(", "self", ",", "t1", ",", "t2", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "t1", ".", "size", "(", ")", ",", "t2", ".", "size", "(", ")", ",", "\"size mismatch\"", ")", "\n", "self", ".", "assertLess", "(", "(", "t1", "-", "t2", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ",", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.base.ConvTBC.__init__": [[20, 34], ["torch.Module.__init__", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.modules.utils._single", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "base.ConvTBC.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters"], ["\n", "__version__", "=", "'0.0.1'", "\n", "\n", "# See https://stackoverflow.com/a/48938860", "\n", "try", ":", "\n", "    ", "set_start_method", "(", "'spawn'", ")", "\n", "", "except", "RuntimeError", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "class", "NLPServer", "(", "threading", ".", "Thread", ")", ":", "\n", "    ", "\"\"\"For connecting two processes in the same server it is considered that IPC is the fastest option\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "port", "=", "5558", ",", "port_out", "=", "5559", ",", "n_workers", "=", "1", ",", "verbose", "=", "False", ",", "\n", "max_batch_size", "=", "32", ",", "task", "=", "'coref'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.base.ConvTBC.reset_parameters": [[35, 47], ["math.sqrt", "base.ConvTBC.weight.data.normal_", "base.ConvTBC.bias.data.fill_", "torch.utils.weight_norm", "torch.utils.weight_norm"], "methods", ["None"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'VENTILATOR'", ",", "'magenta'", ")", ",", "verbose", ")", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "port_out", "=", "port_out", "\n", "self", ".", "processes", "=", "[", "]", "\n", "self", ".", "is_ready", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "n_workers", "=", "n_workers", "\n", "self", ".", "n_concurrent_sockets", "=", "max", "(", "8", ",", "n_workers", "*", "2", ")", "\n", "self", ".", "max_batch_size", "=", "max_batch_size", "\n", "self", ".", "status_static", "=", "{", "\n", "'python_version'", ":", "sys", ".", "version", ",", "\n", "'server_version'", ":", "__version__", ",", "\n", "'pyzmq_version'", ":", "zmq", ".", "pyzmq_version", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.base.ConvTBC.forward": [[48, 50], ["torch.conv_tbc", "torch.conv_tbc", "torch.conv_tbc", "torch.conv_tbc", "input.contiguous"], "methods", ["None"], ["'zmq_version'", ":", "zmq", ".", "zmq_version", "(", ")", ",", "\n", "'server_start_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.base.ConvTBC.__repr__": [[51, 58], ["s.format"], "methods", ["None"], ["self", ".", "Worker", "=", "WorkerRegistry", "[", "task", "]", "\n", "\n", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "(", ")", "\n", "self", ".", "is_ready", ".", "wait", "(", ")", "\n", "return", "self", "\n", "\n", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.base.ConvBCT.reset_parameters": [[66, 79], ["math.sqrt", "base.ConvBCT.weight.data.normal_", "base.ConvBCT.bias.data.fill_", "torch.utils.weight_norm", "torch.utils.weight_norm"], "methods", ["None"], ["\n", "", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PUSH", ")", "\n", "def", "_send_close_signal", "(", "self", ",", "_", ",", "frontend", ")", ":", "\n", "        ", "frontend", ".", "connect", "(", "'tcp://localhost:%d'", "%", "self", ".", "port", ")", "\n", "frontend", ".", "send_multipart", "(", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "shutdown", "(", "args", ")", ":", "\n", "        ", "with", "zmq", ".", "Context", "(", ")", "as", "ctx", ":", "\n", "            ", "ctx", ".", "setsockopt", "(", "zmq", ".", "LINGER", ",", "args", ".", "timeout", ")", "\n", "with", "ctx", ".", "socket", "(", "zmq", ".", "PUSH", ")", "as", "frontend", ":", "\n", "                ", "try", ":", "\n", "                    ", "frontend", ".", "connect", "(", "'tcp://%s:%d'", "%", "(", "args", ".", "ip", ",", "args", ".", "port", ")", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1d.__init__": [[39, 55], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lightweight.LightweightConv1d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "num_heads", "=", "1", ",", "\n", "weight_softmax", "=", "False", ",", "bias", "=", "False", ",", "weight_dropout", "=", "0.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "weight_dropout", "=", "weight_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1d.reset_parameters": [[56, 60], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1d.forward": [[61, 86], ["input.view.view.size", "torch.dropout", "torch.dropout", "torch.dropout", "input.view.view.view", "torch.conv1d", "torch.conv1d", "torch.conv1d", "output.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "lightweight.LightweightConv1d.bias.view"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "'''\n        input size: B x C x T\n        output size: B x C x T\n        '''", "\n", "B", ",", "C", ",", "T", "=", "input", ".", "size", "(", ")", "\n", "H", "=", "self", ".", "num_heads", "\n", "\n", "weight", "=", "self", ".", "weight", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "weight", "=", "F", ".", "dropout", "(", "weight", ",", "self", ".", "weight_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "# Merge every C/H entries into the batch dimension (C = self.input_size)", "\n", "# B x C x T -> (B * C/H) x H x T", "\n", "# One can also expand the weight to C x 1 x K by a factor of C/H", "\n", "# and do not reshape the input instead, which is slow though", "\n", "input", "=", "input", ".", "view", "(", "-", "1", ",", "H", ",", "T", ")", "\n", "output", "=", "F", ".", "conv1d", "(", "input", ",", "weight", ",", "padding", "=", "self", ".", "padding", ",", "\n", "groups", "=", "self", ".", "num_heads", ")", "\n", "output", "=", "output", ".", "view", "(", "B", ",", "C", ",", "T", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC.__init__": [[109, 126], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "lightweight.LightweightConv1dTBC.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "kernel_size", "=", "1", ",", "padding_l", "=", "None", ",", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.", ",", "weight_softmax", "=", "False", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout", "=", "weight_dropout", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_heads", ",", "1", ",", "kernel_size", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC.reset_parameters": [[127, 131], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC.forward": [[132, 149], ["lightweight.LightweightConv1dTBC._forward_unfolded", "lightweight.LightweightConv1dTBC._forward_expanded", "lightweight.LightweightConv1dTBC.bias.view"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_unfolded", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_expanded"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "incremental_state", "=", "None", ",", "unfold", "=", "False", ")", ":", "\n", "        ", "'''Assuming the input, x, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            x: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n        '''", "\n", "unfold", "=", "unfold", "or", "(", "incremental_state", "is", "not", "None", ")", "\n", "\n", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "x", ",", "incremental_state", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "x", ",", "incremental_state", ")", "\n", "\n", "", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC._forward_unfolded": [[150, 187], ["x.size", "lightweight.LightweightConv1dTBC.weight.view", "torch.softmax().type_as.view().expand().contiguous().view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "lightweight.LightweightConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_unfold.view.view.view", "unfold.unfold1d", "x_unfold.view.view.view", "torch.softmax().type_as", "torch.softmax().type_as", "torch.softmax().type_as", "torch.softmax().type_as.size", "x.new", "lightweight.LightweightConv1dTBC._set_input_buffer", "torch.softmax().type_as.view().expand().contiguous", "x.unsqueeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax().type_as.float", "torch.softmax().type_as.view().expand", "x_unfold.view.view.size", "torch.softmax().type_as.view"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.unfold.unfold1d", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward_unfolded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "'''The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.'''", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "x", ".", "new", "(", ")", "\n", "", "x_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "x", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "x_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", ")", "\n", "", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "# unfold the input: T x B x C --> T' x B x C x K", "\n", "            ", "x_unfold", "=", "unfold1d", "(", "x", ",", "self", ".", "kernel_size", ",", "self", ".", "padding_l", ",", "0", ")", "\n", "x_unfold", "=", "x_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "\n", "", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ".", "float", "(", ")", ",", "dim", "=", "1", ")", ".", "type_as", "(", "weight", ")", "\n", "\n", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "x_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "\n", "", "weight", "=", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "\n", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "K", ",", "1", ")", "\n", "\n", "weight", "=", "F", ".", "dropout", "(", "weight", ",", "self", ".", "weight_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "x_unfold", ",", "weight", ")", "# T*B*H x R x 1", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC._forward_expanded": [[188, 220], ["x.view().transpose.view().transpose.size", "lightweight.LightweightConv1dTBC.weight.view", "weight.narrow.narrow.view().expand().contiguous", "weight.narrow.narrow.view().transpose", "x.view().transpose.view().transpose.view().transpose", "weight.narrow.narrow.new_zeros", "torch.dropout.as_strided().copy_", "torch.dropout.narrow", "torch.dropout", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "torch.softmax().type_as", "torch.softmax().type_as", "torch.softmax().type_as", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view().expand", "weight.narrow.narrow.view", "x.view().transpose.view().transpose.view", "torch.dropout.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.float", "weight.narrow.narrow.view", "output.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "x", ",", "incremental_state", ")", ":", "\n", "        ", "'''Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        '''", "\n", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "weight", "=", "self", ".", "weight", ".", "view", "(", "H", ",", "K", ")", "\n", "if", "self", ".", "weight_softmax", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ".", "float", "(", ")", ",", "dim", "=", "1", ")", ".", "type_as", "(", "weight", ")", "\n", "", "weight", "=", "weight", ".", "view", "(", "1", ",", "H", ",", "K", ")", ".", "expand", "(", "T", "*", "B", ",", "H", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "P", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "            ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "\n", "weight_expanded", "=", "F", ".", "dropout", "(", "\n", "weight_expanded", ",", "self", ".", "weight_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "x", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC.reorder_incremental_state": [[221, 226], ["lightweight.LightweightConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "lightweight.LightweightConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC._get_input_buffer": [[227, 229], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC._set_input_buffer": [[230, 232], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ",", "new_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.lightweight.LightweightConv1dTBC.extra_repr": [[233, 241], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, bias={}'", ".", "format", "(", "\n", "self", ".", "input_size", ",", "self", ".", "kernel_size", ",", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "self", ".", "weight_softmax", ",", "self", ".", "bias", "is", "not", "None", "\n", ")", "\n", "if", "self", ".", "weight_dropout", ">", "0.", ":", "\n", "            ", "s", "+=", "', weight_dropout={}'", ".", "format", "(", "self", ".", "weight_dropout", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution.__init__": [[28, 32], ["base.ConvTBC.__init__", "linearized.LinearizedConvolution.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "self", ".", "_linearized_weight", "=", "None", "\n", "self", ".", "register_backward_hook", "(", "self", ".", "_clear_linearized_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution.forward": [[33, 65], ["super().forward", "linearized.LinearizedConvolution._forward_one_step", "linearized.LinearizedConvolution._forward_multiple_steps"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._forward_one_step", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._forward_multiple_steps"], ["", "def", "forward", "(", "self", ",", "X", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            incremental_state: Used to buffer signal; if not None, then X is\n                expected to contain a single frame. If the X order changes\n                between time steps, call reorder_incremental_state.\n        Input:\n            Time x Batch x Channel\n        \"\"\"", "\n", "\n", "# We shall take care of three cases. If incremental state is not", "\n", "# supplied at well, we fall back to the standard ConvTBC", "\n", "# implementation, which does a full convolution over all words in a", "\n", "# sequence.", "\n", "if", "incremental_state", "is", "None", ":", "\n", "            ", "output", "=", "super", "(", ")", ".", "forward", "(", "X", ")", "\n", "# output.shape == [seq_len + padding, batch_size, out_channels]", "\n", "if", "self", ".", "kernel_size", "[", "0", "]", ">", "1", "and", "self", ".", "padding", "[", "0", "]", ">", "0", ":", "\n", "# remove future timesteps added by padding", "\n", "                ", "output", "=", "output", "[", ":", "-", "self", ".", "padding", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "", "return", "output", "\n", "\n", "# Otherwise we're in incremental mode. If we're only provided with", "\n", "# one step, we'll perform the convolution using a simple linear layer.", "\n", "# We assume that the first dimension is time.", "\n", "", "elif", "X", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "output", "=", "self", ".", "_forward_one_step", "(", "X", ",", "incremental_state", ")", "\n", "return", "output", "\n", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_multiple_steps", "(", "X", ",", "incremental_state", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._forward_one_step": [[66, 105], ["linearized.LinearizedConvolution._get_linearized_weight", "X.view.view.size", "X.view.view.transpose().contiguous", "X.view.view.view", "torch.linear", "torch.linear", "output.transpose.transpose.view", "output.transpose.transpose.transpose", "linearized.LinearizedConvolution._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "linearized.LinearizedConvolution._set_input_buffer", "X.view.view.new", "input_buffer.zero_.zero_.zero_", "X.view.view.transpose"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._get_linearized_weight", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "", "def", "_forward_one_step", "(", "self", ",", "X", ",", "incremental_state", ")", ":", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "\n", "        ", "kernel_width", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "# weight.shape == [in_channels, kernel_width, out_channels]", "\n", "weight", "=", "self", ".", "_get_linearized_weight", "(", ")", "\n", "# weight.shape == [out_channels, kernel_width * in_channels]", "\n", "\n", "batch_size", "=", "X", ".", "size", "(", "1", ")", "\n", "if", "kernel_width", ">", "1", ":", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "X", ".", "new", "(", "kernel_width", ",", "batch_size", ",", "X", ".", "shape", "[", "2", "]", ")", "\n", "input_buffer", "=", "input_buffer", ".", "zero_", "(", ")", "\n", "\n", "# Shift buffer to remove the oldest step. The input buffer", "\n", "# records the last `kernel_size` steps of X.", "\n", "# Last step in the buffer is the current latest step", "\n", "", "input_buffer", "=", "torch", ".", "cat", "(", "[", "input_buffer", "[", "1", ":", "]", ",", "X", "[", "-", "1", ":", "]", "]", ",", "dim", "=", "0", ")", "\n", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "X", "=", "input_buffer", "\n", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# X.shape == [batch_size, kernel_width, in_channels]", "\n", "\n", "X", "=", "X", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "# X.shape == [batch_size, kernel_width * in_channels]", "\n", "\n", "output", "=", "F", ".", "linear", "(", "X", ",", "weight", ",", "self", ".", "bias", ")", "\n", "# output.shape == [batch_size, out_channels]", "\n", "\n", "output", "=", "output", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ")", "\n", "# output.shape == [batch_size, 1, out_channels]", "\n", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# output.shape == [1, batch_size, out_channels]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._forward_multiple_steps": [[106, 138], ["linearized.LinearizedConvolution._get_input_buffer", "super().forward", "linearized.LinearizedConvolution._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "_forward_multiple_steps", "(", "self", ",", "X", ",", "incremental_state", ")", ":", "\n", "# X.shape == [seq_len, batch_size, in_channels]", "\n", "        ", "kernel_width", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "\n", "# Retrieve the previous `kernel_width` steps of X", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "X", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "X", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# Now that we have the required history, we simply put X through", "\n", "# the standard ConvTBC.", "\n", "", "output", "=", "super", "(", ")", ".", "forward", "(", "X", ")", "\n", "# output.shape == [buffer_len + seq_len + padding, batch_size, out_channels]", "\n", "\n", "# Remove future timesteps added by padding. We usually pad the input X", "\n", "# with `padding == kernel_size - 1` zeros so that the output retains", "\n", "# the same time dimension, once the right pads are removed", "\n", "if", "self", ".", "kernel_size", "[", "0", "]", ">", "1", "and", "self", ".", "padding", "[", "0", "]", ">", "0", ":", "\n", "            ", "output", "=", "output", "[", ":", "-", "self", ".", "padding", "[", "0", "]", ",", ":", ",", ":", "]", "\n", "# output.shape == [buffer_len + seq_len, batch_size, out_channels]", "\n", "\n", "# We also need to remove the extra buffer on the left", "\n", "", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "buffer_len", "=", "input_buffer", ".", "shape", "[", "0", "]", "\n", "output", "=", "output", "[", "buffer_len", ":", ",", ":", ",", ":", "]", "\n", "# output.shape == [seq_len, batch_size, out_channels]", "\n", "\n", "# We store the previous `kernel_width` steps of X", "\n", "", "input_buffer", "=", "X", "[", "-", "kernel_width", ":", "]", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution.reorder_incremental_state": [[139, 144], ["linearized.LinearizedConvolution._get_input_buffer", "input_buffer.index_select.index_select.index_select", "linearized.LinearizedConvolution._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._get_input_buffer": [[145, 147], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._set_input_buffer": [[148, 150], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ",", "new_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._get_linearized_weight": [[151, 161], ["linearized.LinearizedConvolution.weight.transpose().transpose().contiguous", "linearized.LinearizedConvolution.view", "linearized.LinearizedConvolution.size", "linearized.LinearizedConvolution.weight.transpose().transpose", "linearized.LinearizedConvolution.weight.transpose"], "methods", ["None"], ["", "def", "_get_linearized_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_linearized_weight", "is", "None", ":", "\n", "# The kernel width, e.g. 4", "\n", "            ", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "\n", "# self.weight.shape == [kernel_width, in_channels, out_channels]", "\n", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "kw", ",", "self", ".", "in_channels", ")", "\n", "self", ".", "_linearized_weight", "=", "weight", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "", "return", "self", ".", "_linearized_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.linearized.LinearizedConvolution._clear_linearized_weight": [[162, 164], ["None"], "methods", ["None"], ["", "def", "_clear_linearized_weight", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_linearized_weight", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.__init__": [[50, 75], ["torch.Module.__init__", "dynamic.DynamicConv1dTBC.reset_parameters", "dynamic.Linear", "dynamic.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["def", "__init__", "(", "self", ",", "input_size", ",", "kernel_size", "=", "1", ",", "padding_l", "=", "None", ",", "num_heads", "=", "1", ",", "\n", "weight_dropout", "=", "0.", ",", "weight_softmax", "=", "False", ",", "\n", "renorm_padding", "=", "False", ",", "bias", "=", "False", ",", "conv_bias", "=", "False", ",", "\n", "query_size", "=", "None", ",", "in_proj", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "query_size", "=", "input_size", "if", "query_size", "is", "None", "else", "query_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding_l", "=", "padding_l", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "weight_dropout", "=", "weight_dropout", "\n", "self", ".", "weight_softmax", "=", "weight_softmax", "\n", "self", ".", "renorm_padding", "=", "renorm_padding", "\n", "\n", "if", "in_proj", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "input_size", ",", "self", ".", "input_size", "+", "num_heads", "*", "kernel_size", "*", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight_linear", "=", "Linear", "(", "\n", "self", ".", "query_size", ",", "num_heads", "*", "kernel_size", "*", "1", ",", "bias", "=", "bias", ")", "\n", "", "if", "conv_bias", ":", "\n", "            ", "self", ".", "conv_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.in_proj": [[76, 79], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "in_proj", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "weight_linear", ".", "out_features", "==", "self", ".", "input_size", "+", "self", ".", "num_heads", "*", "self", ".", "kernel_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.reset_parameters": [[80, 84], ["dynamic.DynamicConv1dTBC.weight_linear.reset_parameters", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight_linear", ".", "reset_parameters", "(", ")", "\n", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "conv_bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.forward": [[85, 121], ["dynamic.DynamicConv1dTBC._get_input_buffer", "dynamic.DynamicConv1dTBC._set_input_buffer", "dynamic.DynamicConv1dTBC._forward_unfolded", "dynamic.DynamicConv1dTBC._forward_expanded", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "torch.cat.size", "dynamic.DynamicConv1dTBC.conv_bias.view"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_unfolded", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_expanded"], ["", "", "def", "forward", "(", "self", ",", "X", ",", "incremental_state", "=", "None", ",", "query", "=", "None", ",", "unfold", "=", "None", ")", ":", "\n", "        ", "'''Assuming the input, X, of the shape T x B x C and producing an output in the shape T x B x C\n        args:\n            X: Input of shape T x B x C, i.e. (timesteps, batch_size, input_size)\n            incremental_state: A dict to keep the state\n            unfold: unfold the input or not. If not, we use the matrix trick instead\n            query: use the specified query to predict the conv filters\n        '''", "\n", "# X.shape == [seq_len, batch_size, input_dim]", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_X", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "prev_X", "is", "not", "None", ":", "\n", "                ", "X", "=", "torch", ".", "cat", "(", "[", "prev_X", ",", "X", "]", ",", "dim", "=", "0", ")", "\n", "", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "X", "[", "-", "self", ".", "kernel_size", "+", "1", ":", "]", ")", "\n", "\n", "# use unfold mode as default for long sequence to save memory", "\n", "", "unfold", "=", "X", ".", "size", "(", "0", ")", ">", "512", "if", "unfold", "is", "None", "else", "unfold", "\n", "# unfold = unfold or (incremental_state is not None)", "\n", "assert", "query", "is", "None", "or", "not", "self", ".", "in_proj", "\n", "\n", "if", "query", "is", "None", ":", "\n", "            ", "query", "=", "X", "\n", "\n", "", "if", "unfold", ":", "\n", "            ", "output", "=", "self", ".", "_forward_unfolded", "(", "X", ",", "incremental_state", ",", "query", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_forward_expanded", "(", "X", ",", "incremental_state", ",", "query", ")", "\n", "\n", "# Remove the history:", "\n", "", "if", "incremental_state", "is", "not", "None", "and", "prev_X", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "[", "prev_X", ".", "shape", "[", "0", "]", ":", "]", "\n", "\n", "", "if", "self", ".", "conv_bias", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "+", "self", ".", "conv_bias", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_unfolded": [[122, 191], ["dynamic.DynamicConv1dTBC.narrow().contiguous.size", "unfold.unfold1d", "X_unfold.view.view.view", "torch.softmax.narrow", "torch.dropout", "torch.dropout", "torch.dropout", "torch.softmax.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamic.DynamicConv1dTBC.weight_linear", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.narrow().contiguous().view", "dynamic.DynamicConv1dTBC.weight_linear().view", "torch.softmax.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "dynamic.DynamicConv1dTBC.narrow", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.weight_linear", "dynamic.DynamicConv1dTBC.narrow"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.unfold.unfold1d", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward_unfolded", "(", "self", ",", "X", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "'''The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.'''", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim]", "\n", "\n", "T", ",", "B", ",", "C", "=", "X", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "# It seems to get the kernel weight, we can either project X or query.", "\n", "# We project the query by default.", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "X", ")", "\n", "X", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "\n", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "# Every word in a sequence will have a unique kernel of size", "\n", "# [n_heads, kernel_size]", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "", "assert", "not", "self", ".", "renorm_padding", "\n", "\n", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "            ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# For even padding, left padding should be K/2. Right padding will", "\n", "# automatically be K - padding_l - 1. To prevent our input from", "\n", "# seeing the future, padding needs to be K - 1 (and there will be", "\n", "# no right padding). This is what we always want in a decoder.", "\n", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim]", "\n", "", "X_unfold", "=", "unfold1d", "(", "X", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim, kernel_size]", "\n", "\n", "X_unfold", "=", "X_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "# X.shape == query.shape == [seq_len * batch_size * n_heads, head_size, kernel_size]", "\n", "\n", "# We can think of the weight as the important of each kernel item.", "\n", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "\n", "# This doesn't do anything for self.in_proj == False. The last", "\n", "# dimension should already have length `kernel_size`.", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "F", ".", "dropout", "(", "weight", ",", "self", ".", "weight_dropout", ",", "\n", "training", "=", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "2", ")", "\n", "# X_unfold.shape == [seq_len * batch_size * n_heads, head_size, c_kernel_size]", "\n", "# weight.shape == [seq_len * batch_size * n_heads, c_kernel_size, 1]", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "X_unfold", ",", "weight", ")", "\n", "# output.shape == [seq_len * batch_size * n_heads, head_size, 1]", "\n", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "# output.shape == [seq_len, batch_size, n_heads * head_size]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._old_forward_unfolded": [[192, 284], ["dynamic.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow", "torch.dropout", "torch.dropout", "torch.dropout", "weight.narrow.narrow.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.view.view.view", "dynamic.DynamicConv1dTBC.weight_linear", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.narrow().contiguous().view", "dynamic.DynamicConv1dTBC.weight_linear().view", "dynamic.DynamicConv1dTBC._get_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "X_unfold.view.view.view", "unfold.unfold1d", "X_unfold.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.size", "torch.softmax", "torch.softmax", "torch.softmax", "dynamic.DynamicConv1dTBC.narrow().contiguous.new", "dynamic.DynamicConv1dTBC._set_input_buffer", "weight.narrow.narrow.narrow", "dynamic.DynamicConv1dTBC.narrow", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.weight_linear", "dynamic.DynamicConv1dTBC.narrow().contiguous.unsqueeze", "dynamic.DynamicConv1dTBC.narrow", "X_unfold.view.view.size"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.unfold.unfold1d", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "_old_forward_unfolded", "(", "self", ",", "X", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "'''The conventional implementation of convolutions.\n        Unfolding the input by having a window shifting to the right.'''", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim]", "\n", "\n", "T", ",", "B", ",", "C", "=", "X", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "\n", "# It seems to get the kernel weight, we can either project X or query.", "\n", "# We project the query by default.", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "X", ")", "\n", "X", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "\n", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "# Every word in a sequence will have a unique kernel of size", "\n", "# [n_heads, kernel_size]", "\n", "\n", "# renorm_padding is only implemented in _forward_expanded", "\n", "", "assert", "not", "self", ".", "renorm_padding", "or", "incremental_state", "is", "not", "None", "\n", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "# The input buffer is simply X", "\n", "            ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "None", ":", "\n", "                ", "input_buffer", "=", "X", ".", "new", "(", ")", "\n", "", "X_unfold", "=", "torch", ".", "cat", "(", "[", "input_buffer", ",", "X", ".", "unsqueeze", "(", "3", ")", "]", ",", "dim", "=", "3", ")", "\n", "# X_unfold.shape == [seq_len, batch_size, input_dim, c_kernel_size]", "\n", "\n", "if", "self", ".", "kernel_size", ">", "1", ":", "\n", "                ", "self", ".", "_set_input_buffer", "(", "\n", "incremental_state", ",", "X_unfold", "[", ":", ",", ":", ",", ":", ",", "-", "self", ".", "kernel_size", "+", "1", ":", "]", ")", "\n", "", "X_unfold", "=", "X_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "-", "1", ")", "\n", "# X_unfold.shape == [seq_len * batch_size * n_heads, head_size, c_kernel_size]", "\n", "# Each head is responsible for a patch in the input dim.", "\n", "\n", "", "else", ":", "\n", "            ", "padding_l", "=", "self", ".", "padding_l", "\n", "if", "K", ">", "T", "and", "padding_l", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "padding_l", "=", "T", ",", "T", "-", "1", "\n", "# For even padding, left padding should be K/2. Right padding will", "\n", "# automatically be K - padding_l - 1. To prevent our input from", "\n", "# seeing the future, padding needs to be K - 1 (and there will be", "\n", "# no right padding). This is what we always want in a decoder.", "\n", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim]", "\n", "", "X_unfold", "=", "unfold1d", "(", "X", ",", "K", ",", "padding_l", ",", "0", ")", "\n", "# X.shape == query.shape == [seq_len, batch_size, input_dim, kernel_size]", "\n", "\n", "X_unfold", "=", "X_unfold", ".", "view", "(", "T", "*", "B", "*", "H", ",", "R", ",", "K", ")", "\n", "# X.shape == query.shape == [seq_len * batch_size * n_heads, head_size, kernel_size]", "\n", "\n", "# We can think of the weight as the important of each kernel item.", "\n", "", "if", "self", ".", "weight_softmax", "and", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "\n", "# This doesn't do anything for self.in_proj == False. The last", "\n", "# dimension should already have length `kernel_size`.", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, kernel_size]", "\n", "\n", "# Once we have seen `kernel_size` words, this operation has no effect.", "\n", "# K is now the actual kernel size.", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "weight", "=", "weight", "[", ":", ",", "-", "X_unfold", ".", "size", "(", "2", ")", ":", "]", "\n", "K", "=", "weight", ".", "size", "(", "1", ")", "\n", "# weight.shape == [seq_len * batch_size * n_heads, c_kernel_size]", "\n", "\n", "", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "            ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "\n", "", "weight", "=", "F", ".", "dropout", "(", "weight", ",", "self", ".", "weight_dropout", ",", "\n", "training", "=", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "2", ")", "\n", "# X_unfold.shape == [seq_len * batch_size * n_heads, head_size, c_kernel_size]", "\n", "# weight.shape == [seq_len * batch_size * n_heads, c_kernel_size, 1]", "\n", "\n", "output", "=", "torch", ".", "bmm", "(", "X_unfold", ",", "weight", ")", "\n", "# output.shape == [seq_len * batch_size * n_heads, head_size, 1]", "\n", "\n", "output", "=", "output", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "# output.shape == [seq_len, batch_size, n_heads * head_size]", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._forward_expanded": [[285, 337], ["dynamic.DynamicConv1dTBC.narrow().contiguous.size", "weight.narrow.narrow.narrow().contiguous", "weight.narrow.narrow.view().transpose", "dynamic.DynamicConv1dTBC.narrow().contiguous.view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "dynamic.DynamicConv1dTBC.weight_linear", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.narrow().contiguous().view", "dynamic.DynamicConv1dTBC.weight_linear().view", "torch.dropout", "torch.dropout", "torch.dropout", "weight.narrow.narrow.new().fill_", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "weight.narrow.narrow.new_zeros", "weight_expanded.narrow.narrow.as_strided().copy_", "weight_expanded.narrow.narrow.narrow", "torch.softmax", "torch.softmax", "torch.softmax", "weight.narrow.narrow.narrow", "weight.narrow.narrow.view", "dynamic.DynamicConv1dTBC.narrow().contiguous.view", "float", "weight.narrow.narrow.narrow", "output.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "dynamic.DynamicConv1dTBC.narrow", "dynamic.DynamicConv1dTBC.narrow().contiguous", "dynamic.DynamicConv1dTBC.weight_linear", "weight.narrow.narrow.new", "weight_expanded.narrow.narrow.as_strided", "weight_expanded.narrow.narrow.as_strided", "output.transpose().contiguous().view.transpose().contiguous().view.transpose", "dynamic.DynamicConv1dTBC.narrow"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward_expanded", "(", "self", ",", "X", ",", "incremental_state", ",", "query", ")", ":", "\n", "        ", "'''Turn the convolution filters into band matrices and do matrix multiplication.\n        This is faster when the sequence is short, but less memory efficient.\n        This is not used in the decoder during inference.\n        '''", "\n", "T", ",", "B", ",", "C", "=", "X", ".", "size", "(", ")", "\n", "K", ",", "H", "=", "self", ".", "kernel_size", ",", "self", ".", "num_heads", "\n", "R", "=", "C", "//", "H", "\n", "assert", "R", "*", "H", "==", "C", "==", "self", ".", "input_size", "\n", "if", "self", ".", "in_proj", ":", "\n", "            ", "proj", "=", "self", ".", "weight_linear", "(", "X", ")", "\n", "X", "=", "proj", ".", "narrow", "(", "2", ",", "0", ",", "self", ".", "input_size", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "proj", ".", "narrow", "(", "2", ",", "self", ".", "input_size", ",", "H", "*", "\n", "K", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "weight_linear", "(", "query", ")", ".", "view", "(", "T", "*", "B", "*", "H", ",", "-", "1", ")", "\n", "\n", "", "if", "not", "self", ".", "renorm_padding", ":", "\n", "            ", "if", "self", ".", "weight_softmax", ":", "\n", "                ", "weight", "=", "F", ".", "softmax", "(", "weight", ",", "dim", "=", "1", ")", "\n", "", "weight", "=", "F", ".", "dropout", "(", "weight", ",", "self", ".", "weight_dropout", ",", "\n", "training", "=", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "", "weight", "=", "weight", ".", "narrow", "(", "1", ",", "0", ",", "K", ")", ".", "contiguous", "(", ")", "\n", "weight", "=", "weight", ".", "view", "(", "T", ",", "B", "*", "H", ",", "K", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "X", "=", "X", ".", "view", "(", "T", ",", "B", "*", "H", ",", "R", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "weight_softmax", "and", "self", ".", "renorm_padding", ":", "\n", "# turn the convolution filters into band matrices", "\n", "            ", "weight_expanded", "=", "weight", ".", "new", "(", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ")", ".", "fill_", "(", "float", "(", "'-inf'", ")", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "self", ".", "padding_l", ",", "T", ")", "\n", "# normalize the weight over valid positions like self-attention", "\n", "weight_expanded", "=", "F", ".", "softmax", "(", "weight_expanded", ",", "dim", "=", "2", ")", "\n", "weight_expanded", "=", "F", ".", "dropout", "(", "\n", "weight_expanded", ",", "self", ".", "weight_dropout", ",", "training", "=", "self", ".", "training", ",", "inplace", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "P", "=", "self", ".", "padding_l", "\n", "# For efficieny, we cut the kernel size and reduce the padding when the kernel is larger than the length", "\n", "if", "K", ">", "T", "and", "P", "==", "K", "-", "1", ":", "\n", "                ", "weight", "=", "weight", ".", "narrow", "(", "2", ",", "K", "-", "T", ",", "T", ")", "\n", "K", ",", "P", "=", "T", ",", "T", "-", "1", "\n", "# turn the convolution filters into band matrices", "\n", "", "weight_expanded", "=", "weight", ".", "new_zeros", "(", "\n", "B", "*", "H", ",", "T", ",", "T", "+", "K", "-", "1", ",", "requires_grad", "=", "False", ")", "\n", "weight_expanded", ".", "as_strided", "(", "\n", "(", "B", "*", "H", ",", "T", ",", "K", ")", ",", "(", "T", "*", "(", "T", "+", "K", "-", "1", ")", ",", "T", "+", "K", ",", "1", ")", ")", ".", "copy_", "(", "weight", ")", "\n", "weight_expanded", "=", "weight_expanded", ".", "narrow", "(", "2", ",", "P", ",", "T", ")", "# B*H x T x T", "\n", "\n", "", "output", "=", "torch", ".", "bmm", "(", "weight_expanded", ",", "X", ")", "\n", "output", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "B", ",", "C", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.reorder_incremental_state": [[338, 343], ["dynamic.DynamicConv1dTBC._get_input_buffer", "input_buffer.index_select.index_select.index_select", "dynamic.DynamicConv1dTBC._set_input_buffer"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "input_buffer", "=", "input_buffer", ".", "index_select", "(", "1", ",", "new_order", ")", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._get_input_buffer": [[344, 346], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC._set_input_buffer": [[347, 349], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "new_buffer", ")", ":", "\n", "        ", "return", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'input_buffer'", ",", "new_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.DynamicConv1dTBC.extra_repr": [[350, 362], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "'{}, kernel_size={}, padding_l={}, num_heads={}, weight_softmax={}, conv_bias={}, renorm_padding={}, in_proj={}'", ".", "format", "(", "\n", "self", ".", "input_size", ",", "self", ".", "kernel_size", ",", "self", ".", "padding_l", ",", "\n", "self", ".", "num_heads", ",", "self", ".", "weight_softmax", ",", "self", ".", "conv_bias", "is", "not", "None", ",", "self", ".", "renorm_padding", ",", "\n", "self", ".", "in_proj", ",", "\n", ")", "\n", "\n", "if", "self", ".", "query_size", "!=", "self", ".", "input_size", ":", "\n", "            ", "s", "+=", "', query_size={}'", ".", "format", "(", "self", ".", "query_size", ")", "\n", "", "if", "self", ".", "weight_dropout", ">", "0.", ":", "\n", "            ", "s", "+=", "', weight_dropout={}'", ".", "format", "(", "self", ".", "weight_dropout", ")", "\n", "", "return", "s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear": [[17, 23], ["torch.Linear", "torch.init.xavier_uniform_", "torch.init.constant_"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.unfold.unfold1d": [[11, 22], ["x.unsqueeze.size", "torch.pad", "x.unsqueeze.contiguous", "x.unsqueeze.as_strided", "x.unsqueeze.unsqueeze"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.detect_face.pad"], ["def", "unfold1d", "(", "x", ",", "kernel_size", ",", "padding_l", ",", "pad_value", "=", "0", ")", ":", "\n", "    ", "'''unfold T x B x C to T x B x C x K'''", "\n", "if", "kernel_size", ">", "1", ":", "\n", "        ", "T", ",", "B", ",", "C", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "padding_l", ",", "kernel_size", "-", "\n", "1", "-", "padding_l", ")", ",", "value", "=", "pad_value", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", "\n", "x", "=", "x", ".", "as_strided", "(", "(", "T", ",", "B", ",", "C", ",", "kernel_size", ")", ",", "(", "B", "*", "C", ",", "C", ",", "1", ",", "B", "*", "C", ")", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "3", ")", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_multi_head.DownsampledMultiHeadAttention.__init__": [[12, 42], ["range", "torch.ModuleList.__init__", "tell.modules.linear.GehringLinear", "torch.ModuleList.__init__", "downsampled_single_head.SingleHeadAttention", "attention_heads.append", "downsampled_single_head.SingleHeadAttention"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "out_channels", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ",", "\n", "project_input", "=", "True", ",", "gated", "=", "False", ",", "downsample", "=", "False", ")", ":", "\n", "        ", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "project_input", "=", "project_input", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "embed_dim", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attention_heads", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "attention_heads", ".", "append", "(", "\n", "SingleHeadAttention", "(", "\n", "out_channels", ",", "self", ".", "embed_dim", ",", "self", ".", "head_dim", ",", "index", ",", "\n", "self", ".", "dropout", ",", "bias", ",", "self", ".", "project_input", ",", "self", ".", "gated", ",", "\n", "self", ".", "downsample", ",", "self", ".", "num_heads", ",", "\n", ")", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "modules", "=", "attention_heads", ")", "\n", "self", ".", "out_proj", "=", "GehringLinear", "(", "embed_dim", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# either we have a list of attention heads, or just one attention head", "\n", "# if not being downsampled, we can do the heads with one linear layer instead of separate ones", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention_module", "=", "SingleHeadAttention", "(", "\n", "out_channels", ",", "self", ".", "embed_dim", ",", "self", ".", "head_dim", ",", "1", ",", "self", ".", "dropout", ",", "\n", "bias", ",", "self", ".", "project_input", ",", "self", ".", "gated", ",", "self", ".", "downsample", ",", "self", ".", "num_heads", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_multi_head.DownsampledMultiHeadAttention.forward": [[44, 86], ["list", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "downsampled_multi_head.DownsampledMultiHeadAttention.out_proj", "downsampled_multi_head.DownsampledMultiHeadAttention.attention_module", "attn.append", "attn_weights.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "full_attn_weights.view.view.view", "attn.append", "attn_weights.append", "attn_weights[].clone", "full_attn_weights.view.view.sum"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "use_scalar_bias", "=", "False", ")", ":", "\n", "        ", "src_len", ",", "batch_size", ",", "embed_dim", "=", "key", ".", "shape", "\n", "tgt_len", "=", "query", ".", "shape", "[", "0", "]", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "shape", ")", "==", "[", "tgt_len", ",", "batch_size", ",", "embed_dim", "]", "\n", "assert", "key", ".", "shape", "==", "value", ".", "shape", "\n", "\n", "src_size", "=", "src_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "src_size", "+=", "1", "\n", "\n", "", "attn", "=", "[", "]", "\n", "attn_weights", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "for", "attention_head_number", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "# call the forward of each attention head", "\n", "                ", "_attn", ",", "_attn_weight", "=", "self", "[", "attention_head_number", "]", "(", "\n", "query", ",", "key", ",", "value", ",", "mask_future_timesteps", ",", "key_padding_mask", ",", "use_scalar_bias", ",", "\n", ")", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn", "=", "self", ".", "out_proj", "(", "full_attn", ")", "\n", "return", "full_attn", ",", "attn_weights", "[", "0", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "_attn", ",", "_attn_weight", "=", "self", ".", "attention_module", "(", "\n", "query", ",", "key", ",", "value", ",", "mask_future_timesteps", ",", "key_padding_mask", ",", "use_scalar_bias", ",", "\n", ")", "\n", "# _attn.shape == [tgt_len, batch_size, out_channels]", "\n", "# _attn_weight.shape == [batch_size, tgt_len, 1 + src_len]", "\n", "attn", ".", "append", "(", "_attn", ")", "\n", "attn_weights", ".", "append", "(", "_attn_weight", ")", "\n", "full_attn", "=", "torch", ".", "cat", "(", "attn", ",", "dim", "=", "2", ")", "\n", "full_attn_weights", "=", "torch", ".", "cat", "(", "attn_weights", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "view", "(", "\n", "batch_size", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_size", ")", "\n", "full_attn_weights", "=", "full_attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "\n", "# full_attn.shape == [tgt_len, batch_size, out_channels]", "\n", "# full_attn_weights.shape == [batch_size, tgt_len, src_size]", "\n", "return", "full_attn", ",", "full_attn_weights", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.__init__": [[212, 267], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "multi_head.MultiHeadAttention.reset_parameters", "hasattr", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "multi_head.MultiHeadAttention.register_parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "kdim", "=", "None", ",", "vdim", "=", "None", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "add_zero_attn", "=", "True", ",", "self_attention", "=", "False", ",", "\n", "encoder_decoder_attention", "=", "False", ",", "out_dim", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "kdim", "=", "kdim", "if", "kdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "vdim", "=", "vdim", "if", "vdim", "is", "not", "None", "else", "embed_dim", "\n", "self", ".", "qkv_same_dim", "=", "self", ".", "kdim", "==", "embed_dim", "and", "self", ".", "vdim", "==", "embed_dim", "\n", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "self_attention", "=", "self_attention", "\n", "self", ".", "encoder_decoder_attention", "=", "encoder_decoder_attention", "\n", "\n", "assert", "not", "self", ".", "self_attention", "or", "self", ".", "qkv_same_dim", ",", "'Self-attention requires query, key and '", "'value to be of the same size'", "\n", "\n", "if", "self", ".", "qkv_same_dim", ":", "\n", "            ", "self", ".", "in_proj_weight", "=", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "k_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "self", ".", "kdim", ")", ")", "\n", "self", ".", "v_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "self", ".", "vdim", ")", ")", "\n", "self", ".", "q_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "embed_dim", ",", "embed_dim", ")", ")", "\n", "\n", "", "if", "bias", ":", "\n", "            ", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'in_proj_bias'", ",", "None", ")", "\n", "\n", "", "out_dim", "=", "out_dim", "if", "out_dim", "else", "embed_dim", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "out_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "self", ".", "onnx_trace", "=", "False", "\n", "\n", "self", ".", "enable_torch_version", "=", "False", "\n", "if", "hasattr", "(", "F", ",", "\"multi_head_attention_forward\"", ")", ":", "\n", "            ", "self", ".", "enable_torch_version", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "enable_torch_version", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.prepare_for_onnx_export_": [[268, 270], ["None"], "methods", ["None"], ["", "", "def", "prepare_for_onnx_export_", "(", "self", ")", ":", "\n", "        ", "self", ".", "onnx_trace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reset_parameters": [[271, 287], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "k_proj_weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "v_proj_weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "q_proj_weight", ")", "\n", "\n", "", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.forward": [[288, 487], ["query.size", "multi_head.MultiHeadAttention.contiguous().view().transpose", "torch.cat.size", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multi_head.MultiHeadAttention.apply_sparse_mask", "tell.utils.softmax().type_as", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multi_head.MultiHeadAttention.out_proj", "multi_head.MultiHeadAttention._get_input_buffer", "multi_head.MultiHeadAttention.in_proj_qkv", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.contiguous().view().transpose", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "multi_head.MultiHeadAttention._set_input_buffer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.transpose", "torch.cat.transpose", "list", "attn_mask.repeat.repeat.unsqueeze", "attn_weights.masked_fill.masked_fill.view", "attn_weights.masked_fill.masked_fill.view", "list", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "attn_weights.masked_fill.masked_fill.view", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "torch.multi_head_attention_forward", "multi_head.MultiHeadAttention.in_proj_q", "multi_head.MultiHeadAttention.in_proj_q", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multi_head.MultiHeadAttention.bias_k.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multi_head.MultiHeadAttention.bias_v.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multi_head.MultiHeadAttention.contiguous().view", "saved_state[].view", "saved_state[].view", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "key_padding_mask.new_zeros.new_zeros.size", "key_padding_mask.new_zeros.new_zeros.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_weights.masked_fill.masked_fill.size", "attn_mask.repeat.repeat.repeat", "torch.where().type_as", "torch.where().type_as", "torch.where().type_as", "torch.where().type_as", "attn_weights.masked_fill.masked_fill.masked_fill", "tell.utils.softmax", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn.transpose().contiguous().view.transpose().contiguous().view.size", "attn_weights.masked_fill.masked_fill.sum", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "multi_head.MultiHeadAttention.in_proj_k", "multi_head.MultiHeadAttention.in_proj_v", "multi_head.MultiHeadAttention.in_proj_k", "multi_head.MultiHeadAttention.in_proj_v", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "key_padding_mask.new_zeros.new_zeros.new_zeros", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros", "attn_weights.masked_fill.masked_fill.size", "key_padding_mask.new_zeros.new_zeros.unsqueeze().unsqueeze", "float", "attn.transpose().contiguous().view.transpose().contiguous().view.contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "multi_head.MultiHeadAttention.bias_k.repeat", "multi_head.MultiHeadAttention.bias_v.repeat", "attn_mask.repeat.repeat.new_zeros", "key_padding_mask.new_zeros.new_zeros.size", "multi_head.MultiHeadAttention.contiguous", "attn_mask.repeat.repeat.new_zeros", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.zeros().type_as", "torch.where", "torch.where", "torch.where", "torch.where", "attn_mask.repeat.repeat.size", "key_padding_mask.new_zeros.new_zeros.new_zeros", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "attn_mask.repeat.repeat.size", "key_padding_mask.new_zeros.new_zeros.unsqueeze().unsqueeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "attn_weights.masked_fill.masked_fill.float", "key_padding_mask.new_zeros.new_zeros.unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "key_padding_mask.new_zeros.new_zeros.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "key_padding_mask.new_zeros.new_zeros.size", "key_padding_mask.new_zeros.new_zeros.unsqueeze", "float"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.apply_sparse_mask", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_q", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_q", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_k", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_v", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_k", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_v"], ["", "", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "incremental_state", "=", "None", ",", "\n", "need_weights", "=", "True", ",", "static_kv", "=", "False", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Timesteps can be masked by supplying a T x T mask in the\n        `attn_mask` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "# assert list(query.size()) == [tgt_len, bsz, embed_dim]", "\n", "\n", "if", "self", ".", "enable_torch_version", "and", "not", "self", ".", "onnx_trace", "and", "incremental_state", "is", "None", "and", "not", "static_kv", ":", "\n", "            ", "if", "self", ".", "qkv_same_dim", ":", "\n", "                ", "return", "F", ".", "multi_head_attention_forward", "(", "query", ",", "key", ",", "value", ",", "\n", "self", ".", "embed_dim", ",", "self", ".", "num_heads", ",", "\n", "self", ".", "in_proj_weight", ",", "\n", "self", ".", "in_proj_bias", ",", "self", ".", "bias_k", ",", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "self", ".", "dropout", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", ",", "key_padding_mask", ",", "need_weights", ",", "\n", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "return", "F", ".", "multi_head_attention_forward", "(", "query", ",", "key", ",", "value", ",", "\n", "self", ".", "embed_dim", ",", "self", ".", "num_heads", ",", "\n", "torch", ".", "empty", "(", "[", "0", "]", ")", ",", "\n", "self", ".", "in_proj_bias", ",", "self", ".", "bias_k", ",", "self", ".", "bias_v", ",", "\n", "self", ".", "add_zero_attn", ",", "self", ".", "dropout", ",", "\n", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "self", ".", "training", ",", "key_padding_mask", ",", "need_weights", ",", "\n", "attn_mask", ",", "use_separate_proj_weight", "=", "True", ",", "\n", "q_proj_weight", "=", "self", ".", "q_proj_weight", ",", "\n", "k_proj_weight", "=", "self", ".", "k_proj_weight", ",", "\n", "v_proj_weight", "=", "self", ".", "v_proj_weight", ")", "\n", "\n", "", "", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "saved_state", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "'prev_key'", "in", "saved_state", ":", "\n", "# previous time steps are cached - no need to recompute", "\n", "# key and value if they are static", "\n", "                ", "if", "static_kv", ":", "\n", "                    ", "assert", "self", ".", "encoder_decoder_attention", "and", "not", "self", ".", "self_attention", "\n", "key", "=", "value", "=", "None", "\n", "", "", "", "else", ":", "\n", "            ", "saved_state", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attention", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "self", ".", "encoder_decoder_attention", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "key", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "if", "key", ".", "shape", "[", "2", "]", ">", "0", ":", "\n", "                ", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "", "if", "value", ".", "shape", "[", "2", "]", ">", "0", ":", "\n", "                ", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "if", "key", ".", "shape", "[", "2", "]", ">", "0", ":", "\n", "                ", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "k", "=", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "\n", "", "if", "key", ".", "shape", "[", "2", "]", ">", "0", ":", "\n", "                ", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "v", "=", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "if", "key", ".", "shape", "[", "2", "]", ">", "0", ":", "\n", "                    ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "key_padding_mask", ".", "new_zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "key_padding_mask", "=", "key_padding_mask", ".", "new_zeros", "(", "\n", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "\n", "", "", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "if", "saved_state", "is", "not", "None", ":", "\n", "# saved states are stored with shape (bsz, num_heads, seq_len, head_dim)", "\n", "            ", "if", "'prev_key'", "in", "saved_state", ":", "\n", "                ", "prev_key", "=", "saved_state", "[", "'prev_key'", "]", ".", "view", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "k", "=", "prev_key", "\n", "", "else", ":", "\n", "                    ", "k", "=", "torch", ".", "cat", "(", "(", "prev_key", ",", "k", ")", ",", "dim", "=", "1", ")", "\n", "", "", "if", "'prev_value'", "in", "saved_state", ":", "\n", "                ", "prev_value", "=", "saved_state", "[", "'prev_value'", "]", ".", "view", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "if", "static_kv", ":", "\n", "                    ", "v", "=", "prev_value", "\n", "", "else", ":", "\n", "                    ", "v", "=", "torch", ".", "cat", "(", "(", "prev_value", ",", "v", ")", ",", "dim", "=", "1", ")", "\n", "", "", "saved_state", "[", "'prev_key'", "]", "=", "k", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "saved_state", "[", "'prev_value'", "]", "=", "v", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "-", "1", ",", "self", ".", "head_dim", ")", "\n", "\n", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "saved_state", ")", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# This is part of a workaround to get around fork/join parallelism", "\n", "# not supporting Optional types.", "\n", "if", "key_padding_mask", "is", "not", "None", "and", "key_padding_mask", ".", "shape", "==", "torch", ".", "Size", "(", "[", "]", ")", ":", "\n", "            ", "key_padding_mask", "=", "None", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "self", ".", "add_zero_attn", ":", "\n", "            ", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "\n", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "\n", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ".", "type_as", "(", "key_padding_mask", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn_weights", "=", "self", ".", "apply_sparse_mask", "(", "\n", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", "\n", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "\n", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_mask", "=", "attn_mask", ".", "repeat", "(", "attn_weights", ".", "size", "(", "0", ")", ",", "1", ",", "1", ")", "\n", "", "attn_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "self", ".", "onnx_trace", ":", "\n", "                ", "attn_weights", "=", "torch", ".", "where", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "float", "(", "\"-Inf\"", ")", "]", ")", ",", "\n", "attn_weights", ".", "float", "(", ")", "\n", ")", ".", "type_as", "(", "attn_weights", ")", "\n", "", "else", ":", "\n", "                ", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", ",", "\n", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_weights", "=", "softmax", "(", "\n", "attn_weights", ",", "dim", "=", "-", "1", ",", "onnx_trace", "=", "self", ".", "onnx_trace", ",", "\n", ")", ".", "type_as", "(", "attn_weights", ")", "\n", "attn_weights", "=", "F", ".", "dropout", "(", "\n", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "\n", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "if", "(", "self", ".", "onnx_trace", "and", "attn", ".", "size", "(", "1", ")", "==", "1", ")", ":", "\n", "# when ONNX tracing a single decoder step (sequence length == 1)", "\n", "# the transpose is a no-op copy before view, thus unnecessary", "\n", "            ", "attn", "=", "attn", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# average attention weights over heads", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_qkv": [[488, 490], ["multi_head.MultiHeadAttention._in_proj().chunk", "multi_head.MultiHeadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_q": [[491, 499], ["multi_head.MultiHeadAttention._in_proj", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "            ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "bias", "=", "self", ".", "in_proj_bias", "\n", "if", "bias", "is", "not", "None", ":", "\n", "                ", "bias", "=", "bias", "[", ":", "self", ".", "embed_dim", "]", "\n", "", "return", "F", ".", "linear", "(", "query", ",", "self", ".", "q_proj_weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_k": [[500, 509], ["multi_head.MultiHeadAttention._in_proj", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._in_proj"], ["", "", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "            ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "k_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "if", "bias", "is", "not", "None", ":", "\n", "                ", "bias", "=", "bias", "[", "self", ".", "embed_dim", ":", "2", "*", "self", ".", "embed_dim", "]", "\n", "", "return", "F", ".", "linear", "(", "key", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_v": [[510, 519], ["multi_head.MultiHeadAttention._in_proj", "torch.linear", "torch.linear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._in_proj"], ["", "", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "if", "self", ".", "qkv_same_dim", ":", "\n", "            ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "v_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "if", "bias", "is", "not", "None", ":", "\n", "                ", "bias", "=", "bias", "[", "2", "*", "self", ".", "embed_dim", ":", "]", "\n", "", "return", "F", ".", "linear", "(", "value", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._in_proj": [[520, 527], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.reorder_incremental_state": [[528, 535], ["multi_head.MultiHeadAttention._get_input_buffer", "multi_head.MultiHeadAttention.keys", "multi_head.MultiHeadAttention._set_input_buffer", "input_buffer[].index_select"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer"], ["", "def", "reorder_incremental_state", "(", "self", ",", "incremental_state", ",", "new_order", ")", ":", "\n", "        ", "\"\"\"Reorder buffered internal state (for incremental generation).\"\"\"", "\n", "input_buffer", "=", "self", ".", "_get_input_buffer", "(", "incremental_state", ")", "\n", "if", "input_buffer", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "input_buffer", ".", "keys", "(", ")", ":", "\n", "                ", "input_buffer", "[", "k", "]", "=", "input_buffer", "[", "k", "]", ".", "index_select", "(", "0", ",", "new_order", ")", "\n", "", "self", ".", "_set_input_buffer", "(", "incremental_state", ",", "input_buffer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._get_input_buffer": [[536, 542], ["tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "", "def", "_get_input_buffer", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "return", "get_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", ")", "or", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention._set_input_buffer": [[543, 549], ["tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_set_input_buffer", "(", "self", ",", "incremental_state", ",", "buffer", ")", ":", "\n", "        ", "set_incremental_state", "(", "\n", "self", ",", "\n", "incremental_state", ",", "\n", "'attn_state'", ",", "\n", "buffer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.apply_sparse_mask": [[551, 553], ["None"], "methods", ["None"], ["", "def", "apply_sparse_mask", "(", "self", ",", "attn_weights", ",", "tgt_len", ",", "src_len", ",", "bsz", ")", ":", "\n", "        ", "return", "attn_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.multi_head_attention_score_forward": [[14, 205], ["torch.equal", "torch.equal", "query.size", "F.linear.contiguous().view().transpose", "torch.cat.size", "torch.bmm", "torch.bmm", "torch.softmax", "torch.dropout", "attn_output_weights.view.view", "list", "float", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional.size", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional", "torch.jit._unwrap_optional.size", "torch.cat.contiguous().view().transpose", "torch.cat", "torch.cat", "torch.cat.transpose", "list", "torch.cat.unsqueeze", "attn_output_weights.view.view", "attn_output_weights.view.masked_fill", "attn_output_weights.view.view", "attn_output_weights.view.sum", "query.size", "torch.linear().chunk", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.cat", "torch.cat", "F.linear.contiguous().view", "static_k.size", "static_k.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_output_weights.view.size", "torch.cat.unsqueeze().unsqueeze", "float", "query.size", "key.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.contiguous().view", "torch.zeros", "torch.zeros", "torch.linear", "bias_k.repeat", "F.linear.contiguous", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.contiguous", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["def", "multi_head_attention_score_forward", "(", "query", ",", "\n", "key", ",", "\n", "embed_dim_to_check", ",", "\n", "num_heads", ",", "\n", "in_proj_weight", ",", "\n", "in_proj_bias", ",", "\n", "bias_k", ",", "\n", "add_zero_attn", ",", "\n", "dropout_p", ",", "\n", "out_proj_weight", ",", "\n", "out_proj_bias", ",", "\n", "training", "=", "True", ",", "\n", "key_padding_mask", "=", "None", ",", "\n", "attn_mask", "=", "None", ",", "\n", "use_separate_proj_weight", "=", "False", ",", "\n", "q_proj_weight", "=", "None", ",", "\n", "k_proj_weight", "=", "None", ",", "\n", "static_k", "=", "None", ")", ":", "\n", "# type: (...) -> Tuple[Tensor, Optional[Tensor]]", "\n", "    ", "r\"\"\"\n    Args:\n        query, key: map a query and a set of keys to an output.\n            See \"Attention Is All You Need\" for more details.\n        embed_dim_to_check: total dimension of the model.\n        num_heads: parallel attention heads.\n        in_proj_weight, in_proj_bias: input projection weight and bias.\n        bias_k: bias of the key sequences to be added at dim=0.\n        add_zero_attn: add a new batch of zeros to the key sequences at dim=1.\n        dropout_p: probability of an element to be zeroed.\n        out_proj_weight, out_proj_bias: the output projection weight and bias.\n        training: apply dropout if is ``True``.\n        key_padding_mask: if provided, specified padding elements in the key will\n            be ignored by the attention. This is an binary mask. When the value is True,\n            the corresponding value on the attention layer will be filled with -inf.\n        attn_mask: mask that prevents attention to certain positions. This is an additive mask\n            (i.e. the values will be added to the attention layer).\n        use_separate_proj_weight: the function accept the proj. weights for query, key,\n            in different forms. If false, in_proj_weight will be used, which is\n            a combination of q_proj_weight, k_proj_weight, v_proj_weight.\n        q_proj_weight, k_proj_weight, v_proj_weight, in_proj_bias: input projection weight and bias.\n        static_k: static key used for attention operators.\n\n\n    Shape:\n        Inputs:\n        - query: :math:`(L, N, E)` where L is the target sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key: :math:`(S, N, E)`, where S is the source sequence length, N is the batch size, E is\n          the embedding dimension.\n        - key_padding_mask: :math:`(N, S)`, ByteTensor, where N is the batch size, S is the source sequence length.\n        - attn_mask: :math:`(L, S)` where L is the target sequence length, S is the source sequence length.\n        - static_k: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n        - static_v: :math:`(N*num_heads, S, E/num_heads)`, where S is the source sequence length,\n          N is the batch size, E is the embedding dimension. E/num_heads is the head dimension.\n\n        Outputs:\n        - attn_output: :math:`(L, N, E)` where L is the target sequence length, N is the batch size,\n          E is the embedding dimension.\n        - attn_output_weights: :math:`(N, L, S)` where N is the batch size,\n          L is the target sequence length, S is the source sequence length.\n    \"\"\"", "\n", "\n", "qk_same", "=", "torch", ".", "equal", "(", "query", ",", "key", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "embed_dim_to_check", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "\n", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "head_dim", "*", "num_heads", "==", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "scaling", "=", "float", "(", "head_dim", ")", "**", "-", "0.5", "\n", "\n", "if", "use_separate_proj_weight", "is", "not", "True", ":", "\n", "        ", "if", "qk_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", "=", "F", ".", "linear", "(", "query", ",", "in_proj_weight", ",", "\n", "in_proj_bias", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "            ", "_b", "=", "in_proj_bias", "\n", "_start", "=", "0", "\n", "_end", "=", "embed_dim", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", "_end", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "_end", "]", "\n", "", "q", "=", "F", ".", "linear", "(", "query", ",", "_w", ",", "_b", ")", "\n", "\n", "# This is inline in_proj function with in_proj_weight and in_proj_bias", "\n", "_b", "=", "in_proj_bias", "\n", "_start", "=", "embed_dim", "\n", "_end", "=", "embed_dim", "*", "2", "\n", "_w", "=", "in_proj_weight", "[", "_start", ":", "_end", ",", ":", "]", "\n", "if", "_b", "is", "not", "None", ":", "\n", "                ", "_b", "=", "_b", "[", "_start", ":", "_end", "]", "\n", "", "k", "=", "F", ".", "linear", "(", "key", ",", "_w", ",", "_b", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "q_proj_weight_non_opt", "=", "torch", ".", "jit", ".", "_unwrap_optional", "(", "q_proj_weight", ")", "\n", "len1", ",", "len2", "=", "q_proj_weight_non_opt", ".", "size", "(", ")", "\n", "assert", "len1", "==", "embed_dim", "and", "len2", "==", "query", ".", "size", "(", "-", "1", ")", "\n", "\n", "k_proj_weight_non_opt", "=", "torch", ".", "jit", ".", "_unwrap_optional", "(", "k_proj_weight", ")", "\n", "len1", ",", "len2", "=", "k_proj_weight_non_opt", ".", "size", "(", ")", "\n", "assert", "len1", "==", "embed_dim", "and", "len2", "==", "key", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "q", "=", "F", ".", "linear", "(", "query", ",", "q_proj_weight_non_opt", ",", "\n", "in_proj_bias", "[", "0", ":", "embed_dim", "]", ")", "\n", "k", "=", "F", ".", "linear", "(", "key", ",", "k_proj_weight_non_opt", ",", "\n", "in_proj_bias", "[", "embed_dim", ":", "(", "embed_dim", "*", "2", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "F", ".", "linear", "(", "query", ",", "q_proj_weight_non_opt", ",", "in_proj_bias", ")", "\n", "k", "=", "F", ".", "linear", "(", "key", ",", "k_proj_weight_non_opt", ",", "in_proj_bias", ")", "\n", "", "", "q", "=", "q", "*", "scaling", "\n", "\n", "if", "bias_k", "is", "not", "None", ":", "\n", "        ", "if", "static_k", "is", "None", ":", "\n", "            ", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "\n", "torch", ".", "zeros", "(", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "attn_mask", ".", "dtype", ",", "\n", "device", "=", "attn_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "                ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "key_padding_mask", ".", "dtype", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "assert", "static_k", "is", "None", ",", "\"bias cannot be added to static key.\"", "\n", "", "", "else", ":", "\n", "        ", "assert", "bias_k", "is", "None", "\n", "\n", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "num_heads", ",", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "        ", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "num_heads", ",", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "if", "static_k", "is", "not", "None", ":", "\n", "        ", "assert", "static_k", ".", "size", "(", "0", ")", "==", "bsz", "*", "num_heads", "\n", "assert", "static_k", ".", "size", "(", "2", ")", "==", "head_dim", "\n", "k", "=", "static_k", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "        ", "assert", "key_padding_mask", ".", "size", "(", "0", ")", "==", "bsz", "\n", "assert", "key_padding_mask", ".", "size", "(", "1", ")", "==", "src_len", "\n", "\n", "", "if", "add_zero_attn", ":", "\n", "        ", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "torch", ".", "zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "\n", "[", "2", ":", "]", ",", "dtype", "=", "k", ".", "dtype", ",", "device", "=", "k", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "torch", ".", "zeros", "(", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "attn_mask", ".", "dtype", ",", "\n", "device", "=", "attn_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "key_padding_mask", "=", "torch", ".", "cat", "(", "\n", "[", "key_padding_mask", ",", "torch", ".", "zeros", "(", "(", "key_padding_mask", ".", "size", "(", "0", ")", ",", "1", ")", ",", "\n", "dtype", "=", "key_padding_mask", ".", "dtype", ",", "\n", "device", "=", "key_padding_mask", ".", "device", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "attn_output_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_output_weights", ".", "size", "(", ")", ")", "==", "[", "\n", "bsz", "*", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "        ", "attn_mask", "=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "attn_output_weights", "+=", "attn_mask", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "        ", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "\n", "bsz", ",", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_output_weights", "=", "attn_output_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", ",", "\n", ")", "\n", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "\n", "bsz", "*", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "attn_output_weights", "=", "F", ".", "softmax", "(", "\n", "attn_output_weights", ",", "dim", "=", "-", "1", ")", "\n", "attn_output_weights", "=", "F", ".", "dropout", "(", "\n", "attn_output_weights", ",", "p", "=", "dropout_p", ",", "training", "=", "training", ")", "\n", "\n", "# average attention weights over heads", "\n", "attn_output_weights", "=", "attn_output_weights", ".", "view", "(", "\n", "bsz", ",", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "return", "attn_output_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention.__init__": [[15, 63], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "k_layers.append", "v_layers.append", "k_layers.append", "downsampled_single_head.GatedLinear", "v_layers.append", "k_layers.append", "tell.modules.linear.GehringLinear", "v_layers.append", "tell.modules.linear.GehringLinear", "tell.modules.linear.GehringLinear", "downsampled_single_head.Downsample", "downsampled_single_head.Downsample", "downsampled_single_head.GatedLinear", "downsampled_single_head.GatedLinear", "tell.modules.linear.GehringLinear", "tell.modules.linear.GehringLinear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.GatedLinear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.GatedLinear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.GatedLinear"], ["def", "__init__", "(", "self", ",", "out_channels", ",", "embed_dim", ",", "head_dim", ",", "head_index", ",", "dropout", "=", "0.", ",", "\n", "bias", "=", "True", ",", "project_input", "=", "True", ",", "gated", "=", "False", ",", "downsample", "=", "False", ",", "\n", "num_heads", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_index", "=", "head_index", "\n", "self", ".", "head_dim", "=", "head_dim", "\n", "self", ".", "project_input", "=", "project_input", "\n", "self", ".", "gated", "=", "gated", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "projection", "=", "None", "\n", "\n", "k_layers", "=", "[", "]", "\n", "v_layers", "=", "[", "]", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "k_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "v_layers", ".", "append", "(", "Downsample", "(", "self", ".", "head_index", ")", ")", "\n", "out_proj_size", "=", "self", ".", "head_dim", "\n", "", "else", ":", "\n", "            ", "out_proj_size", "=", "self", ".", "head_dim", "*", "self", ".", "num_heads", "\n", "", "if", "self", ".", "gated", ":", "\n", "            ", "k_layers", ".", "append", "(", "GatedLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "GatedLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "GatedLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "", "else", ":", "\n", "            ", "k_layers", ".", "append", "(", "GehringLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "self", ".", "in_proj_q", "=", "GehringLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", "\n", "v_layers", ".", "append", "(", "GehringLinear", "(", "\n", "self", ".", "embed_dim", ",", "out_proj_size", ",", "bias", "=", "bias", ")", ")", "\n", "\n", "", "self", ".", "in_proj_k", "=", "nn", ".", "Sequential", "(", "*", "k_layers", ")", "\n", "self", ".", "in_proj_v", "=", "nn", ".", "Sequential", "(", "*", "v_layers", ")", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "self", ".", "out_proj", "=", "GehringLinear", "(", "\n", "out_proj_size", ",", "self", ".", "head_dim", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "out_proj", "=", "GehringLinear", "(", "\n", "out_proj_size", ",", "out_channels", ",", "bias", "=", "bias", ")", "\n", "\n", "", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention.forward": [[64, 172], ["q.view.view.transpose", "k.view.view.transpose", "scalar_bias.scalar_bias.scalar_bias.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "downsampled_single_head.SingleHeadAttention.out_proj", "list", "downsampled_single_head.SingleHeadAttention.in_proj_q", "downsampled_single_head.SingleHeadAttention.in_proj_k", "downsampled_single_head.SingleHeadAttention.in_proj_v", "q.view.view.view", "k.view.view.view", "scalar_bias.scalar_bias.scalar_bias.view", "k.view.view.transpose", "scalar_bias.scalar_bias.scalar_bias", "scalar_bias.scalar_bias.scalar_bias", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "downsampled_single_head.SingleHeadAttention._mask_future_full", "downsampled_single_head.SingleHeadAttention._mask_future_partial", "key_padding_mask.max", "attn_weights.view.view.masked_fill", "attn_weights.view.view.view", "attn_weights.view.view.view", "attn_weights.view.view.view", "key_padding_mask.unsqueeze().unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "key_padding_mask.unsqueeze", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose", "attn.transpose().contiguous().view.transpose().contiguous().view.transpose"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_q", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_k", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_v", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.scalar_bias", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention._mask_future_full", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention._mask_future_partial"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask_future_timesteps", "=", "False", ",", "\n", "key_padding_mask", "=", "None", ",", "use_scalar_bias", "=", "False", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Self-attention can be implemented by passing in the same arguments for\n        query, key and value. Future timesteps can be masked with the\n        `mask_future_timesteps` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "orginal_src_len", ",", "batch_size", ",", "out_channels", "=", "key", ".", "shape", "\n", "tgt_len", "=", "query", ".", "shape", "[", "0", "]", "\n", "assert", "list", "(", "query", ".", "shape", ")", "==", "[", "tgt_len", ",", "batch_size", ",", "out_channels", "]", "\n", "assert", "key", ".", "shape", "==", "value", ".", "shape", "\n", "\n", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "            ", "assert", "key_padding_mask", ".", "shape", "[", "0", "]", "==", "batch_size", "\n", "assert", "key_padding_mask", ".", "shape", "[", "1", "]", "==", "orginal_src_len", "\n", "\n", "", "if", "self", ".", "downsample", ":", "\n", "            ", "size", "=", "batch_size", "\n", "", "else", ":", "\n", "            ", "size", "=", "batch_size", "*", "self", ".", "num_heads", "\n", "\n", "", "k", "=", "key", "\n", "v", "=", "value", "\n", "q", "=", "query", "\n", "src_len", "=", "orginal_src_len", "\n", "if", "self", ".", "project_input", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "q", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "k", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "v", ")", "\n", "src_len", "=", "k", ".", "shape", "[", "0", "]", "\n", "", "q", "=", "q", "*", "self", ".", "scaling", "\n", "\n", "if", "not", "self", ".", "downsample", ":", "\n", "            ", "q", "=", "q", ".", "view", "(", "tgt_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "k", "=", "k", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "v", "=", "v", ".", "view", "(", "src_len", ",", "size", ",", "self", ".", "head_dim", ")", "\n", "\n", "", "q", "=", "q", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# v.shape = [batch_size, src_len, embed_dim]", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "# attn_weights.shape == [batch_size, tgt_len, src_len]", "\n", "\n", "# Note that we should only mask future timesteps when we're doing", "\n", "# self-attention.", "\n", "if", "mask_future_timesteps", ":", "\n", "# If we're not in incremental mode, the attention weight is a", "\n", "# square matrix, and the diagonal is the attention on the current", "\n", "# step, while the upper triangle is the attention on future steps.", "\n", "# Furthermore, when using downsampling, the attention weight will", "\n", "# have fewer columns than src_len.", "\n", "            ", "if", "query", ".", "shape", "==", "key", ".", "shape", ":", "\n", "                ", "attn_weights", "=", "self", ".", "_mask_future_full", "(", "attn_weights", ")", "\n", "\n", "# Otherwise, we assume that we're in incremental mode and we only", "\n", "# have a partial query. The attention weight matrix now has more", "\n", "# columns than rows.", "\n", "", "else", ":", "\n", "                ", "attn_weights", "=", "self", ".", "_mask_future_partial", "(", "\n", "attn_weights", ",", "orginal_src_len", ")", "\n", "\n", "# Give our model the option to attend to not attend to anything at all", "\n", "# (i.e. a zero placeholder is added at the beginning of the source).", "\n", "", "", "src_size", "=", "src_len", "\n", "if", "use_scalar_bias", ":", "\n", "            ", "attn_weights", "=", "scalar_bias", "(", "attn_weights", ",", "2", ")", "\n", "# attn_weights.shape == [batch_size, tgt_len, 1 + src_len]", "\n", "v", "=", "scalar_bias", "(", "v", ",", "1", ")", "\n", "# v.shape = [batch_size, 1 + src_len, embed_dim]", "\n", "src_size", "+=", "1", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "if", "key_padding_mask", ".", "max", "(", ")", ">", "0", ":", "\n", "                ", "if", "self", ".", "downsample", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "batch_size", ",", "1", ",", "tgt_len", ",", "src_len", ")", "\n", "", "else", ":", "\n", "                    ", "attn_weights", "=", "attn_weights", ".", "view", "(", "\n", "size", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "", "attn_weights", "=", "attn_weights", ".", "masked_fill", "(", "\n", "key_padding_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "-", "math", ".", "inf", ",", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "size", ",", "tgt_len", ",", "src_len", ")", "\n", "", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "attn_weights", "=", "F", ".", "dropout", "(", "\n", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "# attn.shape == [batch_size, tgt_len, embed_dim]", "\n", "\n", "if", "self", ".", "downsample", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_len", ",", "batch_size", ",", "self", ".", "head_dim", ")", "\n", "", "else", ":", "\n", "            ", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_len", ",", "batch_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "# attn.shape == [tgt_len, batch_size, out_channels]", "\n", "# attn_weights.shape == [batch_size, tgt_len, 1 + src_len]", "\n", "\n", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention._mask_future_full": [[173, 194], ["attn_weights.data.new().expand().clone", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze.unsqueeze.unsqueeze", "attn_weights.data.new", "offset.unsqueeze.unsqueeze.expand().clone", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "offset.unsqueeze.unsqueeze.unsqueeze", "attn_weights.data.new().expand", "offset.unsqueeze.unsqueeze.expand", "attn_weights.data.new"], "methods", ["None"], ["", "def", "_mask_future_full", "(", "self", ",", "attn_weights", ")", ":", "\n", "        ", "tgt_len", "=", "attn_weights", ".", "shape", "[", "1", "]", "\n", "\n", "# Zero out the upper triangle, including the diagonal (we don't", "\n", "# attend to ourself, but only to past words)", "\n", "ones", "=", "attn_weights", ".", "data", ".", "new", "(", "[", "1", "]", ")", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", "\n", "mask", "=", "torch", ".", "tril", "(", "ones", ",", "diagonal", "=", "-", "1", ")", "\n", "mask", "=", "mask", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "*=", "mask", "\n", "\n", "# Give all of the zero-out entries a value of -infinity. This means", "\n", "# we'll get a probability of zero after applying softmax.", "\n", "offset", "=", "attn_weights", ".", "data", ".", "new", "(", "[", "-", "math", ".", "inf", "]", ")", "\n", "offset", "=", "offset", ".", "expand", "(", "tgt_len", ",", "tgt_len", ")", ".", "clone", "(", ")", "\n", "offset", "=", "torch", ".", "triu", "(", "offset", ",", "diagonal", "=", "0", ")", "\n", "offset", "=", "offset", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", "\n", "offset", "=", "offset", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "+=", "offset", "\n", "\n", "return", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.SingleHeadAttention._mask_future_partial": [[195, 223], ["attn_weights.data.new", "ones.expand().clone.expand().clone.expand().clone", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze.unsqueeze.unsqueeze", "attn_weights.data.new", "offset.unsqueeze.unsqueeze.expand().clone", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "offset.unsqueeze.unsqueeze.unsqueeze", "ones.expand().clone.expand().clone.expand", "offset.unsqueeze.unsqueeze.expand"], "methods", ["None"], ["", "def", "_mask_future_partial", "(", "self", ",", "attn_weights", ",", "orginal_src_len", ")", ":", "\n", "        ", "\"\"\"Basically the same as _mask_future_full, but we can deal with\n        non-square attention matrices.\"\"\"", "\n", "_", ",", "tgt_len", ",", "_", "=", "attn_weights", ".", "shape", "\n", "\n", "# For the last row, we want to zero out the last entry (we don't", "\n", "# attend to ourself). For the second-to-last row, we want to zero out", "\n", "# the last two entries. And so on. The diagonal calculation will", "\n", "# help us construct this mask.", "\n", "ones", "=", "attn_weights", ".", "data", ".", "new", "(", "[", "1", "]", ")", "\n", "ones", "=", "ones", ".", "expand", "(", "tgt_len", ",", "orginal_src_len", ")", ".", "clone", "(", ")", "\n", "diagonal", "=", "orginal_src_len", "-", "tgt_len", "-", "1", "\n", "mask", "=", "torch", ".", "tril", "(", "ones", ",", "diagonal", "=", "diagonal", ")", "\n", "mask", "=", "mask", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "*=", "mask", "\n", "\n", "# Give all of the zero-out entries a value of -infinity. This means", "\n", "# we'll get a probability of zero after applying softmax.", "\n", "offset", "=", "attn_weights", ".", "data", ".", "new", "(", "[", "-", "math", ".", "inf", "]", ")", "\n", "offset", "=", "offset", ".", "expand", "(", "tgt_len", ",", "orginal_src_len", ")", ".", "clone", "(", ")", "\n", "diagonal", "=", "orginal_src_len", "-", "tgt_len", "\n", "offset", "=", "torch", ".", "triu", "(", "offset", ",", "diagonal", "=", "diagonal", ")", "\n", "offset", "=", "offset", "[", ":", ",", ":", ":", "self", ".", "head_index", "+", "1", "if", "self", ".", "downsample", "else", "1", "]", "\n", "offset", "=", "offset", ".", "unsqueeze", "(", "0", ")", "\n", "attn_weights", "+=", "offset", "\n", "\n", "return", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.Downsample.__init__": [[228, 231], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "index", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "index", "=", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.Downsample.forward": [[232, 234], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ":", "self", ".", "index", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.downsampled_single_head.GatedLinear": [[236, 244], ["torch.Sequential", "tell.modules.linear.GehringLinear", "torch.GLU", "tell.modules.linear.GehringLinear", "torch.GLU", "tell.modules.linear.GehringLinear"], "function", ["None"], ["", "", "def", "GatedLinear", "(", "in_features", ",", "out_features", ",", "dropout", "=", "0.", ",", "bias", "=", "True", ")", ":", "\n", "    ", "\"\"\"Weight-normalized Linear layer (input: B x T x C) with interspersed GLU units\"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "GehringLinear", "(", "in_features", ",", "out_features", "*", "4", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "GehringLinear", "(", "out_features", "*", "2", ",", "out_features", "*", "2", ",", "dropout", ",", "bias", ")", ",", "\n", "nn", ".", "GLU", "(", ")", ",", "\n", "GehringLinear", "(", "out_features", ",", "out_features", ",", "dropout", ",", "bias", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention.__init__": [[25, 38], ["torch.Module.__init__", "downsampled_multi_head.DownsampledMultiHeadAttention", "tell.modules.linear.GehringLinear", "tell.modules.linear.GehringLinear", "tell.modules.linear.GehringLinear", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "out_channels", ",", "embed_dim", ",", "num_heads", ",", "project_input", "=", "False", ",", "\n", "gated", "=", "False", ",", "downsample", "=", "False", ",", "weight_norm", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "DownsampledMultiHeadAttention", "(", "\n", "out_channels", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0", ",", "bias", "=", "True", ",", "\n", "project_input", "=", "project_input", ",", "gated", "=", "gated", ",", "downsample", "=", "downsample", ")", "\n", "self", ".", "in_proj_q", "=", "GehringLinear", "(", "\n", "out_channels", ",", "embed_dim", ",", "weight_norm", "=", "weight_norm", ")", "\n", "self", ".", "in_proj_k", "=", "GehringLinear", "(", "\n", "out_channels", ",", "embed_dim", ",", "weight_norm", "=", "weight_norm", ")", "\n", "self", ".", "in_proj_v", "=", "GehringLinear", "(", "\n", "out_channels", ",", "embed_dim", ",", "weight_norm", "=", "weight_norm", ")", "\n", "self", ".", "ln", "=", "nn", ".", "LayerNorm", "(", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention.forward": [[39, 65], ["self_attention.SelfAttention.SelfAttention.in_proj_q", "self_attention.SelfAttention.SelfAttention.in_proj_k", "self_attention.SelfAttention.SelfAttention.in_proj_v", "self_attention.SelfAttention.SelfAttention.attention", "self_attention.SelfAttention.SelfAttention.ln", "self_attention.SelfAttention.SelfAttention._get_history", "self_attention.SelfAttention.SelfAttention._save_history", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_q", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_k", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.MultiHeadAttention.in_proj_v", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention._get_history", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention._save_history"], ["", "def", "forward", "(", "self", ",", "X", ",", "incremental_state", "=", "None", ")", ":", "\n", "        ", "residual", "=", "X", "\n", "# residual.shape == X.shape == [seq_len, batch_size, out_channels]", "\n", "query", "=", "self", ".", "in_proj_q", "(", "X", ")", "\n", "key", "=", "self", ".", "in_proj_k", "(", "X", ")", "\n", "value", "=", "self", ".", "in_proj_v", "(", "X", ")", "\n", "\n", "# When the incremental state is enabled, we assume that all the", "\n", "# previous key and value (the entire history) will be used in the", "\n", "# next step.", "\n", "if", "incremental_state", "is", "not", "None", ":", "\n", "            ", "prev_key", ",", "prev_value", "=", "self", ".", "_get_history", "(", "incremental_state", ")", "\n", "if", "prev_key", "is", "not", "None", ":", "\n", "                ", "key", "=", "torch", ".", "cat", "(", "[", "prev_key", ",", "key", "]", ",", "dim", "=", "0", ")", "\n", "", "if", "prev_value", "is", "not", "None", ":", "\n", "                ", "value", "=", "torch", ".", "cat", "(", "[", "prev_value", ",", "value", "]", ",", "dim", "=", "0", ")", "\n", "", "self", ".", "_save_history", "(", "incremental_state", ",", "key", ",", "value", ")", "\n", "# key.shape == value.shape == [prev_seq_len, batch_size, embed_dim]", "\n", "\n", "# No need to mask future timestep if query sequence contains only 1 step", "\n", "# mask_future_timesteps = query.shape[0] > 1", "\n", "", "X", ",", "_", "=", "self", ".", "attention", "(", "query", ",", "key", ",", "value", ",", "\n", "mask_future_timesteps", "=", "True", ",", "\n", "use_scalar_bias", "=", "True", ")", "\n", "# X.shape == [seq_len, batch_size, out_channels]", "\n", "return", "self", ".", "ln", "(", "X", "+", "residual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention._save_history": [[66, 69], ["tell.utils.set_incremental_state", "tell.utils.set_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.set_incremental_state"], ["", "def", "_save_history", "(", "self", ",", "incremental_state", ",", "key", ",", "value", ")", ":", "\n", "        ", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'key'", ",", "key", ")", "\n", "set_incremental_state", "(", "self", ",", "incremental_state", ",", "'value'", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.self_attention.SelfAttention._get_history": [[70, 74], ["tell.utils.get_incremental_state", "tell.utils.get_incremental_state"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.state.get_incremental_state"], ["", "def", "_get_history", "(", "self", ",", "incremental_state", ")", ":", "\n", "        ", "key", "=", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'key'", ")", "\n", "value", "=", "get_incremental_state", "(", "self", ",", "incremental_state", ",", "'value'", ")", "\n", "return", "key", ",", "value", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.attention.AttentionLayer.__init__": [[12, 20], ["torch.Module.__init__", "tell.modules.linear.GehringLinear", "tell.modules.linear.GehringLinear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "conv_channels", ",", "embed_dim", ",", "bmm", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# projects from output of convolution to embedding dimension", "\n", "self", ".", "in_projection", "=", "GehringLinear", "(", "conv_channels", ",", "embed_dim", ")", "\n", "# projects from embedding dimension to convolution size", "\n", "self", ".", "out_projection", "=", "GehringLinear", "(", "embed_dim", ",", "conv_channels", ")", "\n", "\n", "self", ".", "bmm", "=", "bmm", "if", "bmm", "is", "not", "None", "else", "torch", ".", "bmm", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.attention.AttentionLayer.forward": [[21, 56], ["attention.AttentionLayer.bmm", "x.float().masked_fill().type_as.float().masked_fill().type_as.size", "torch.softmax", "torch.softmax", "torch.softmax", "x.float().masked_fill().type_as.float().masked_fill().type_as.view", "attention.AttentionLayer.bmm", "encoder_out[].size", "math.sqrt", "x.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "x.float().masked_fill().type_as.float().masked_fill().type_as.view", "s.unsqueeze.unsqueeze.unsqueeze", "math.sqrt", "attention.AttentionLayer.in_projection", "encoder_padding_mask.type_as().sum", "attention.AttentionLayer.out_projection", "x.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "math.sqrt", "s.unsqueeze.unsqueeze.rsqrt", "encoder_padding_mask.unsqueeze", "float", "encoder_padding_mask.type_as", "x.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "forward", "(", "self", ",", "x", ",", "target_embedding", ",", "encoder_out", ",", "encoder_padding_mask", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "# attention", "\n", "x", "=", "(", "self", ".", "in_projection", "(", "x", ")", "+", "target_embedding", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "x", "=", "self", ".", "bmm", "(", "x", ",", "encoder_out", "[", "0", "]", ")", "\n", "\n", "# don't attend over padding", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "x", "=", "x", ".", "float", "(", ")", ".", "masked_fill", "(", "\n", "encoder_padding_mask", ".", "unsqueeze", "(", "1", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", ".", "type_as", "(", "x", ")", "# FP16 support: cast to float and back", "\n", "\n", "# softmax over last dim", "\n", "", "sz", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "F", ".", "softmax", "(", "x", ".", "view", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ",", "sz", "[", "2", "]", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "sz", ")", "\n", "attn_scores", "=", "x", "\n", "\n", "x", "=", "self", ".", "bmm", "(", "x", ",", "encoder_out", "[", "1", "]", ")", "\n", "\n", "# scale attention output (respecting potentially different lengths)", "\n", "s", "=", "encoder_out", "[", "1", "]", ".", "size", "(", "1", ")", "\n", "if", "encoder_padding_mask", "is", "None", ":", "\n", "            ", "x", "=", "x", "*", "(", "s", "*", "math", ".", "sqrt", "(", "1.0", "/", "s", ")", ")", "\n", "", "else", ":", "\n", "# exclude padding", "\n", "            ", "s", "=", "s", "-", "encoder_padding_mask", ".", "type_as", "(", "x", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "s", ".", "unsqueeze", "(", "-", "1", ")", "\n", "x", "=", "x", "*", "(", "s", "*", "s", ".", "rsqrt", "(", ")", ")", "\n", "\n", "# project back", "\n", "", "x", "=", "(", "self", ".", "out_projection", "(", "x", ")", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.attention.AttentionLayer.make_generation_fast_": [[57, 62], ["attention.AttentionLayer.add_module", "tell.modules.beam.BeamableMM"], "methods", ["None"], ["", "def", "make_generation_fast_", "(", "self", ",", "beamable_mm_beam_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Replace torch.bmm with BeamableMM.\"\"\"", "\n", "if", "beamable_mm_beam_size", "is", "not", "None", ":", "\n", "            ", "del", "self", ".", "bmm", "\n", "self", ".", "add_module", "(", "'bmm'", ",", "BeamableMM", "(", "beamable_mm_beam_size", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.forward": [[16, 24], ["list", "input.new().fill_", "input.new().fill_.narrow().copy_", "input.size", "input.new", "input.new().fill_.narrow"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "dim", ",", "bias_init", ")", ":", "\n", "        ", "size", "=", "list", "(", "input", ".", "size", "(", ")", ")", "\n", "size", "[", "dim", "]", "+=", "1", "\n", "output", "=", "input", ".", "new", "(", "*", "size", ")", ".", "fill_", "(", "bias_init", ")", "\n", "output", ".", "narrow", "(", "dim", ",", "1", ",", "size", "[", "dim", "]", "-", "1", ")", ".", "copy_", "(", "input", ")", "\n", "ctx", ".", "dim", "=", "dim", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.ScalarBias.backward": [[25, 28], ["grad.narrow", "grad.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "grad", ".", "narrow", "(", "ctx", ".", "dim", ",", "1", ",", "grad", ".", "size", "(", "ctx", ".", "dim", ")", "-", "1", ")", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.scalar_bias.scalar_bias": [[30, 32], ["ScalarBias.apply"], "function", ["None"], ["", "", "def", "scalar_bias", "(", "input", ",", "dim", ",", "bias_init", "=", "0", ")", ":", "\n", "    ", "return", "ScalarBias", ".", "apply", "(", "input", ",", "dim", ",", "bias_init", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.criteria.adaptive_loss.AdaptiveLoss.__init__": [[20, 26], ["base.Criterion.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "padding_idx", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "# normalize gradients by the number of sentences in a batch", "\n", "# (default is to normalize by number of tokens)", "\n", "self", ".", "sentence_avg", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.criteria.adaptive_loss.AdaptiveLoss.forward": [[27, 74], ["orig_target.reshape.reshape.reshape", "orig_target.reshape.reshape.size", "adaptive_softmax", "net_output[].new().zero_", "range", "tell.utils.strip_pad", "tell.utils.strip_pad.numel", "len", "len", "len", "decoder_target.size", "net_output[].new", "torch.cross_entropy", "net_output[].new().zero_.data.item", "target[].min", "target[].max", "logits[].size"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.strip_pad"], ["", "def", "forward", "(", "self", ",", "adaptive_softmax", ",", "net_output", ",", "decoder_target", ",", "reduction", "=", "'sum'", ")", ":", "\n", "        ", "\"\"\"Compute the loss for the given sample.\n\n        Reduction can be 'sum' or None\n\n        Returns a tuple with three elements:\n        1) the loss\n        2) the sample size, which is used as the denominator for the gradient\n        3) logging outputs to display while training\n        \"\"\"", "\n", "\n", "orig_target", "=", "decoder_target", "\n", "# orig_target.shape == [batch_size, seq_len]", "\n", "\n", "orig_target", "=", "orig_target", ".", "reshape", "(", "-", "1", ")", "\n", "# orig_target.shape == [batch_size * seq_len]", "\n", "\n", "batch_size", "=", "orig_target", ".", "size", "(", "0", ")", "\n", "\n", "logits", ",", "target", "=", "adaptive_softmax", "(", "net_output", "[", "0", "]", ",", "orig_target", ")", "\n", "assert", "len", "(", "target", ")", "==", "len", "(", "logits", ")", "\n", "# len(target) == len(logits) == n_clusters", "\n", "# logits[i].shape == [batch_size * seq_len, cluster_size]", "\n", "# target[i].shape == [batch_size * seq_len]", "\n", "\n", "loss", "=", "net_output", "[", "0", "]", ".", "new", "(", "\n", "1", "if", "reduction", "==", "'sum'", "else", "batch_size", ")", ".", "zero_", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "target", ")", ")", ":", "\n", "            ", "if", "target", "[", "i", "]", "is", "not", "None", ":", "\n", "                ", "assert", "(", "target", "[", "i", "]", ".", "min", "(", ")", ">=", "0", "and", "target", "[", "i", "]", ".", "max", "(", ")", "\n", "<=", "logits", "[", "i", "]", ".", "size", "(", "1", ")", ")", "\n", "loss", "+=", "F", ".", "cross_entropy", "(", "logits", "[", "i", "]", ",", "target", "[", "i", "]", ",", "ignore_index", "=", "self", ".", "padding_idx", ",", "\n", "reduction", "=", "reduction", ")", "\n", "\n", "", "", "orig", "=", "strip_pad", "(", "orig_target", ",", "self", ".", "padding_idx", ")", "\n", "ntokens", "=", "orig", ".", "numel", "(", ")", "\n", "sample_size", "=", "decoder_target", ".", "size", "(", "\n", "0", ")", "if", "self", ".", "sentence_avg", "else", "ntokens", "\n", "logging_output", "=", "{", "\n", "'loss'", ":", "loss", ".", "data", ".", "item", "(", ")", "if", "reduction", "==", "'sum'", "else", "loss", ".", "data", ",", "\n", "'ntokens'", ":", "ntokens", ",", "\n", "'nsentences'", ":", "batch_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "loss", "=", "loss", "\n", "return", "loss", ",", "sample_size", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.criteria.adaptive_loss.AdaptiveLoss.aggregate_logging_outputs": [[75, 92], ["sum", "sum", "sum", "sum", "log.get", "log.get", "log.get", "log.get", "math.log", "math.log", "math.log"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "aggregate_logging_outputs", "(", "logging_outputs", ")", ":", "\n", "        ", "\"\"\"Aggregate logging outputs from data parallel training.\"\"\"", "\n", "loss_sum", "=", "sum", "(", "log", ".", "get", "(", "'loss'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "ntokens", "=", "sum", "(", "log", ".", "get", "(", "'ntokens'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "nsentences", "=", "sum", "(", "log", ".", "get", "(", "'nsentences'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "sample_size", "=", "sum", "(", "log", ".", "get", "(", "'sample_size'", ",", "0", ")", "for", "log", "in", "logging_outputs", ")", "\n", "agg_output", "=", "{", "\n", "'loss'", ":", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "\n", "'nll_loss'", ":", "loss_sum", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", ",", "\n", "'ntokens'", ":", "ntokens", ",", "\n", "'nsentences'", ":", "nsentences", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "if", "sample_size", "!=", "ntokens", ":", "\n", "            ", "agg_output", "[", "'nll_loss'", "]", "=", "loss_sum", "/", "ntokens", "/", "math", ".", "log", "(", "2", ")", "\n", "", "return", "agg_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.__init__": [[14, 27], ["multiprocessing.Process.__init__", "tell.server.utils.set_logger", "multiprocessing.Event", "len", "multiprocessing.Event", "termcolor.colored"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.set_logger"], ["from", "zmq", ".", "utils", "import", "jsonapi", "\n", "\n", "from", "tell", ".", "tasks", "import", "WorkerRegistry", "\n", "\n", "from", ".", "utils", "import", "ServerCmd", ",", "auto_bind", ",", "set_logger", "\n", "from", ".", "zmq_decor", "import", "multi_socket", "\n", "\n", "__version__", "=", "'0.0.1'", "\n", "\n", "# See https://stackoverflow.com/a/48938860", "\n", "try", ":", "\n", "    ", "set_start_method", "(", "'spawn'", ")", "\n", "", "except", "RuntimeError", ":", "\n", "    ", "pass", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.close": [[28, 35], ["base.Worker.logger.info", "base.Worker.exit_flag.set", "base.Worker.is_ready.clear", "base.Worker.terminate", "base.Worker.join", "base.Worker.logger.info"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.SinkJob.clear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["\n", "\n", "", "class", "NLPServer", "(", "threading", ".", "Thread", ")", ":", "\n", "    ", "\"\"\"For connecting two processes in the same server it is considered that IPC is the fastest option\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "port", "=", "5558", ",", "port_out", "=", "5559", ",", "n_workers", "=", "1", ",", "verbose", "=", "False", ",", "\n", "max_batch_size", "=", "32", ",", "task", "=", "'coref'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.run": [[36, 38], ["base.Worker._run"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker._run"], ["self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'VENTILATOR'", ",", "'magenta'", ")", ",", "verbose", ")", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "port_out", "=", "port_out", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker._run": [[39, 58], ["zmq.socket", "zmq.socket", "zmq.socket", "zmq.socket", "tell.server.zmq_decor.multi_socket", "zip", "sink_embed.connect", "sink_token.connect", "base.Worker.initialize", "base.Worker.job_buffer", "sock.connect", "base.Worker._process", "sink_embed.send_multipart", "base.Worker.logger.info", "zmq.utils.jsonapi.dumps", "zmq.utils.jsonapi.dumps"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.zmq_decor.multi_socket", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.initialize", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.job_buffer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker._process", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["self", ".", "processes", "=", "[", "]", "\n", "self", ".", "is_ready", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "n_workers", "=", "n_workers", "\n", "self", ".", "n_concurrent_sockets", "=", "max", "(", "8", ",", "n_workers", "*", "2", ")", "\n", "self", ".", "max_batch_size", "=", "max_batch_size", "\n", "self", ".", "status_static", "=", "{", "\n", "'python_version'", ":", "sys", ".", "version", ",", "\n", "'server_version'", ":", "__version__", ",", "\n", "'pyzmq_version'", ":", "zmq", ".", "pyzmq_version", "(", ")", ",", "\n", "'zmq_version'", ":", "zmq", ".", "zmq_version", "(", ")", ",", "\n", "'server_start_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "}", "\n", "self", ".", "Worker", "=", "WorkerRegistry", "[", "task", "]", "\n", "\n", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "(", ")", "\n", "self", ".", "is_ready", ".", "wait", "(", ")", "\n", "return", "self", "\n", "\n", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.initialize": [[59, 61], ["None"], "methods", ["None"], ["        ", "self", ".", "close", "(", ")", "\n", "\n", "", "def", "close", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker._process": [[62, 64], ["None"], "methods", ["None"], ["        ", "self", ".", "logger", ".", "info", "(", "'shutting down...'", ")", "\n", "self", ".", "_send_close_signal", "(", ")", "\n", "self", ".", "is_ready", ".", "clear", "(", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.base.Worker.job_buffer": [[65, 85], ["zmq.Poller", "zmq.Poller", "zmq.Poller", "zmq.Poller", "base.Worker.is_ready.set", "zmq.Poller.register", "zmq.Poller.register", "base.Worker.exit_flag.is_set", "dict", "enumerate", "zmq.Poller.poll", "zmq.Poller.poll", "sock.recv_multipart", "zmq.utils.jsonapi.loads", "zmq.utils.jsonapi.loads", "base.Worker.logger.info", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["self", ".", "join", "(", ")", "\n", "\n", "", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PUSH", ")", "\n", "def", "_send_close_signal", "(", "self", ",", "_", ",", "frontend", ")", ":", "\n", "        ", "frontend", ".", "connect", "(", "'tcp://localhost:%d'", "%", "self", ".", "port", ")", "\n", "frontend", ".", "send_multipart", "(", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "shutdown", "(", "args", ")", ":", "\n", "        ", "with", "zmq", ".", "Context", "(", ")", "as", "ctx", ":", "\n", "            ", "ctx", ".", "setsockopt", "(", "zmq", ".", "LINGER", ",", "args", ".", "timeout", ")", "\n", "with", "ctx", ".", "socket", "(", "zmq", ".", "PUSH", ")", "as", "frontend", ":", "\n", "                ", "try", ":", "\n", "                    ", "frontend", ".", "connect", "(", "'tcp://%s:%d'", "%", "(", "args", ".", "ip", ",", "args", ".", "port", ")", ")", "\n", "frontend", ".", "send_multipart", "(", "\n", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "print", "(", "'shutdown signal sent to %d'", "%", "args", ".", "port", ")", "\n", "", "except", "zmq", ".", "error", ".", "Again", ":", "\n", "                    ", "raise", "TimeoutError", "(", "\n", "'no response from the server (with \"timeout\"=%d ms), please check the following:'", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.__init__": [[51, 78], ["base.Worker.__init__", "torch.cuda.is_available", "torch.cuda.device_count", "torch.device", "torch.device", "ENV[].split", "str"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "worker_id", ",", "worker_address_list", ",", "sink_address", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "worker_id", ",", "worker_address_list", ",", "sink_address", ",", "verbose", ")", "\n", "self", ".", "model", "=", "None", "\n", "self", ".", "bpe", "=", "None", "\n", "self", ".", "indices", "=", "None", "\n", "self", ".", "preprocess", "=", "None", "\n", "self", ".", "data_iterator", "=", "None", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "token_indexers", "=", "None", "\n", "self", ".", "mtcnn", "=", "None", "\n", "self", ".", "inception", "=", "None", "\n", "self", ".", "resnet", "=", "None", "\n", "self", ".", "darknet", "=", "None", "\n", "self", ".", "names", "=", "None", "\n", "self", ".", "colors", "=", "None", "\n", "self", ".", "nlp", "=", "None", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "n_devices", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "d", "=", "worker_id", "%", "n_devices", "\n", "if", "'CUDA_VISIBLE_DEVICES'", "in", "os", ".", "environ", ":", "\n", "                ", "devs", "=", "ENV", "[", "'CUDA_VISIBLE_DEVICES'", "]", ".", "split", "(", "','", ")", "\n", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "devs", "[", "d", "]", "\n", "", "else", ":", "\n", "                ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "d", ")", "\n", "", "self", ".", "device", "=", "torch", ".", "device", "(", "f'cuda:0'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.initialize": [[79, 142], ["logger.info", "tell.commands.train.yaml_to_params", "allennlp.common.util.prepare_environment", "allennlp.data.vocabulary.Vocabulary.from_params", "allennlp.models.Model.from_params", "model.eval.eval.eval", "logger.info", "torch.load", "model.eval.eval.load_state_dict", "model.eval.eval.to", "logger.info", "torch.hub.load", "logger.info", "tell.facenet.MTCNN", "tell.facenet.InceptionResnetV1().eval", "tell.models.resnet.resnet152", "captioner.CaptioningWorker.resnet.to().eval", "tell.yolov3.models.Darknet", "tell.yolov3.models.attempt_download", "captioner.CaptioningWorker.darknet.load_state_dict", "captioner.CaptioningWorker.darknet.to().eval", "tell.yolov3.utils.utils.load_classes", "random.seed", "torchvision.transforms.Compose", "allennlp.data.iterators.BasicIterator", "allennlp.data.iterators.BasicIterator.index_with", "allennlp.data.tokenizers.Tokenizer.from_params", "tell.commands.train.yaml_to_params.get().get", "tell.commands.train.yaml_to_params.pop", "tell.commands.train.yaml_to_params.get().get", "allennlp.data.token_indexers.TokenIndexer.from_params", "tell.commands.train.yaml_to_params.pop", "torch.device", "tell.facenet.InceptionResnetV1", "captioner.CaptioningWorker.resnet.to", "torch.load", "captioner.CaptioningWorker.darknet.to", "random.randint", "range", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "tell.commands.train.yaml_to_params.get", "tell.commands.train.yaml_to_params.get().get.items", "range", "len", "tell.commands.train.yaml_to_params.get"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.yaml_to_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.attempt_download", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.load_classes", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params"], ["", "", "def", "initialize", "(", "self", ")", ":", "\n", "# We need to initialize the model inside self.run and not self.__init__", "\n", "# to ensure that the model loads in the correct thread.", "\n", "        ", "config_path", "=", "'expt/nytimes/9_transformer_objects/config.yaml'", "\n", "logger", ".", "info", "(", "f'Loading config from {config_path}'", ")", "\n", "config", "=", "yaml_to_params", "(", "config_path", ",", "overrides", "=", "''", ")", "\n", "prepare_environment", "(", "config", ")", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "config", ".", "pop", "(", "'vocabulary'", ")", ")", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "config", ".", "pop", "(", "'model'", ")", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "\n", "model_path", "=", "'expt/nytimes/9_transformer_objects/serialization/best.th'", "\n", "logger", ".", "info", "(", "f'Loading best model from {model_path}'", ")", "\n", "best_model_state", "=", "torch", ".", "load", "(", "\n", "model_path", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "'Loading roberta model.'", ")", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", "\n", "self", ".", "indices", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "\n", "\n", "logger", ".", "info", "(", "'Loading face detection model.'", ")", "\n", "self", ".", "mtcnn", "=", "MTCNN", "(", "keep_all", "=", "True", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "inception", "=", "InceptionResnetV1", "(", "pretrained", "=", "'vggface2'", ")", ".", "eval", "(", ")", "\n", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "resnet", "=", "self", ".", "resnet", ".", "to", "(", "self", ".", "device", ")", ".", "eval", "(", ")", "\n", "\n", "cfg", "=", "'tell/yolov3/cfg/yolov3-spp.cfg'", "\n", "weight_path", "=", "'data/yolov3-spp-ultralytics.pt'", "\n", "self", ".", "darknet", "=", "Darknet", "(", "cfg", ",", "img_size", "=", "416", ")", "\n", "attempt_download", "(", "weight_path", ")", "\n", "self", ".", "darknet", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "weight_path", ",", "map_location", "=", "self", ".", "device", ")", "[", "'model'", "]", ")", "\n", "self", ".", "darknet", ".", "to", "(", "self", ".", "device", ")", ".", "eval", "(", ")", "\n", "\n", "# Get names and colors", "\n", "self", ".", "names", "=", "load_classes", "(", "'tell/yolov3/data/coco.names'", ")", "\n", "random", ".", "seed", "(", "123", ")", "\n", "self", ".", "colors", "=", "[", "[", "random", ".", "randint", "(", "0", ",", "255", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "for", "_", "in", "range", "(", "len", "(", "self", ".", "names", ")", ")", "]", "\n", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "Resize", "(", "256", ")", ",", "\n", "CenterCrop", "(", "224", ")", ",", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ",", "\n", "]", ")", "\n", "\n", "data_iterator", "=", "BasicIterator", "(", "batch_size", "=", "4", ")", "\n", "data_iterator", ".", "index_with", "(", "model", ".", "vocab", ")", "\n", "self", ".", "data_iterator", "=", "data_iterator", "\n", "\n", "self", ".", "tokenizer", "=", "Tokenizer", ".", "from_params", "(", "\n", "config", ".", "get", "(", "'dataset_reader'", ")", ".", "get", "(", "'tokenizer'", ")", ")", "\n", "\n", "indexer_params", "=", "config", ".", "get", "(", "'dataset_reader'", ")", ".", "get", "(", "'token_indexers'", ")", "\n", "\n", "self", ".", "token_indexers", "=", "{", "k", ":", "TokenIndexer", ".", "from_params", "(", "p", ")", "\n", "for", "k", ",", "p", "in", "indexer_params", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.generate_captions": [[146, 177], ["captioner.CaptioningWorker.data_iterator", "enumerate", "captioner.CaptioningWorker.prepare_instance", "captioner.CaptioningWorker.model.generate", "io.BytesIO", "[].save", "base64.b64encode().decode", "output.append", "allennlp.nn.util.move_to_device", "base64.b64encode", "io.BytesIO.getvalue"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.prepare_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate_captions", "(", "self", ",", "articles", ")", ":", "\n", "        ", "instances", "=", "[", "self", ".", "prepare_instance", "(", "a", ")", "for", "a", "in", "articles", "]", "\n", "iterator", "=", "self", ".", "data_iterator", "(", "instances", ",", "num_epochs", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "generated_captions", "=", "[", "]", "\n", "for", "batch", "in", "iterator", ":", "\n", "            ", "if", "self", ".", "device", ".", "type", "==", "'cuda'", ":", "\n", "                ", "batch", "=", "move_to_device", "(", "batch", ",", "self", ".", "device", ".", "index", ")", "\n", "", "attns_list", "=", "self", ".", "model", ".", "generate", "(", "**", "batch", ")", "\n", "# generated_captions += output_dict['generations']", "\n", "# attns = output_dict['attns']", "\n", "# len(attns) == gen_len (ignoring seed)", "\n", "# len(attns[0]) == n_layers", "\n", "# attns[0][0]['image'].shape == [47]", "\n", "# attns[0][0]['article'].shape == [article_len]", "\n", "\n", "", "output", "=", "[", "]", "\n", "for", "i", ",", "instance", "in", "enumerate", "(", "instances", ")", ":", "\n", "            ", "buffered", "=", "BytesIO", "(", ")", "\n", "instance", "[", "'metadata'", "]", "[", "'image'", "]", ".", "save", "(", "buffered", ",", "format", "=", "\"JPEG\"", ")", "\n", "img_str", "=", "base64", ".", "b64encode", "(", "buffered", ".", "getvalue", "(", ")", ")", ".", "decode", "(", ")", "\n", "output", ".", "append", "(", "{", "\n", "'title'", ":", "instance", "[", "'metadata'", "]", "[", "'title'", "]", ",", "\n", "'start'", ":", "instance", "[", "'metadata'", "]", "[", "'start'", "]", ",", "\n", "'before'", ":", "instance", "[", "'metadata'", "]", "[", "'before'", "]", ",", "\n", "'after'", ":", "instance", "[", "'metadata'", "]", "[", "'after'", "]", ",", "\n", "# 'caption': generated_captions[i],", "\n", "'attns'", ":", "attns_list", "[", "i", "]", ",", "\n", "'image'", ":", "img_str", ",", "\n", "}", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.prepare_instance": [[178, 205], ["captioner.CaptioningWorker.prepare_sample", "captioner.CaptioningWorker.tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "allennlp.data.fields.TextField", "tell.data.fields.ImageField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "torchvision.transforms.CenterCrop", "torchvision.transforms.Resize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.prepare_sample"], ["", "def", "prepare_instance", "(", "self", ",", "article", ")", ":", "\n", "        ", "sample", "=", "self", ".", "prepare_sample", "(", "article", ")", "\n", "\n", "context", "=", "'\\n'", ".", "join", "(", "sample", "[", "'paragraphs'", "]", ")", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "context", ")", "\n", "\n", "# proper_infos = self._get_context_names(context)", "\n", "\n", "fields", "=", "{", "\n", "# 'context': CopyTextField(context_tokens, self.token_indexers, proper_infos, proper_infos, 'context'),", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "token_indexers", ")", ",", "\n", "'image'", ":", "ImageField", "(", "sample", "[", "'image'", "]", ",", "self", ".", "preprocess", ")", ",", "\n", "'face_embeds'", ":", "ArrayField", "(", "sample", "[", "'face_embeds'", "]", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "'obj_embeds'", ":", "ArrayField", "(", "sample", "[", "'obj_embeds'", "]", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "\n", "'title'", ":", "sample", "[", "'title'", "]", ",", "\n", "'start'", ":", "'\\n'", ".", "join", "(", "sample", "[", "'start'", "]", ")", ".", "strip", "(", ")", ",", "\n", "'before'", ":", "'\\n'", ".", "join", "(", "sample", "[", "'before'", "]", ")", ".", "strip", "(", ")", ",", "\n", "'after'", ":", "'\\n'", ".", "join", "(", "sample", "[", "'after'", "]", ")", ".", "strip", "(", ")", ",", "\n", "'image'", ":", "CenterCrop", "(", "224", ")", "(", "Resize", "(", "256", ")", "(", "sample", "[", "'image'", "]", ")", ")", "\n", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.prepare_sample": [[232, 290], ["enumerate", "base64.b64decode", "PIL.Image.open", "image.convert.convert.convert", "captioner.CaptioningWorker.get_faces", "captioner.CaptioningWorker.get_objects", "paragraphs.append", "len", "[].encode", "io.BytesIO", "captioner.CaptioningWorker.to_token_ids", "paragraphs.append", "start.append", "before.insert", "len", "after.append", "len", "captioner.CaptioningWorker.to_token_ids", "len", "captioner.CaptioningWorker.to_token_ids", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.get_faces", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.get_objects", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids"], ["", "def", "prepare_sample", "(", "self", ",", "article", ")", ":", "\n", "        ", "paragraphs", "=", "[", "]", "\n", "start", "=", "[", "]", "\n", "n_words", "=", "0", "\n", "pos", "=", "article", "[", "'image_position'", "]", "\n", "sections", "=", "article", "[", "'sections'", "]", "\n", "\n", "if", "article", "[", "'title'", "]", ":", "\n", "            ", "paragraphs", ".", "append", "(", "article", "[", "'title'", "]", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "article", "[", "'title'", "]", ")", ")", "\n", "\n", "", "before", "=", "[", "]", "\n", "after", "=", "[", "]", "\n", "i", "=", "pos", "-", "1", "\n", "j", "=", "pos", "+", "1", "\n", "\n", "# Append the first paragraph", "\n", "for", "k", ",", "section", "in", "enumerate", "(", "sections", ")", ":", "\n", "            ", "if", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                ", "paragraphs", ".", "append", "(", "section", "[", "'text'", "]", ")", "\n", "start", ".", "append", "(", "section", "[", "'text'", "]", ")", "\n", "break", "\n", "\n", "", "", "while", "True", ":", "\n", "            ", "if", "i", ">", "k", "and", "sections", "[", "i", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                ", "text", "=", "sections", "[", "i", "]", "[", "'text'", "]", "\n", "before", ".", "insert", "(", "0", ",", "text", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "i", "-=", "1", "\n", "\n", "if", "k", "<", "j", "<", "len", "(", "sections", ")", "and", "sections", "[", "j", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                ", "text", "=", "sections", "[", "j", "]", "[", "'text'", "]", "\n", "after", ".", "append", "(", "text", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "j", "+=", "1", "\n", "\n", "if", "n_words", ">=", "510", "or", "(", "i", "<=", "k", "and", "j", ">=", "len", "(", "sections", ")", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "image_data", "=", "base64", ".", "b64decode", "(", "\n", "sections", "[", "pos", "]", "[", "'image_data'", "]", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "image", "=", "Image", ".", "open", "(", "io", ".", "BytesIO", "(", "image_data", ")", ")", "\n", "image", "=", "image", ".", "convert", "(", "'RGB'", ")", "\n", "face_embeds", "=", "self", ".", "get_faces", "(", "image", ")", "\n", "obj_embeds", "=", "self", ".", "get_objects", "(", "image", ")", "\n", "\n", "output", "=", "{", "\n", "'paragraphs'", ":", "paragraphs", "+", "before", "+", "after", ",", "\n", "'title'", ":", "article", "[", "'title'", "]", ",", "\n", "'start'", ":", "start", ",", "\n", "'before'", ":", "before", ",", "\n", "'after'", ":", "after", ",", "\n", "'image'", ":", "image", ",", "\n", "'face_embeds'", ":", "face_embeds", ",", "\n", "'obj_embeds'", ":", "obj_embeds", ",", "\n", "}", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.get_faces": [[291, 304], ["torch.no_grad", "captioner.CaptioningWorker.inception", "captioner.CaptioningWorker.mtcnn", "numpy.array", "embeddings.cpu().numpy", "logger.warning", "numpy.array", "embeddings.cpu"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning"], ["", "def", "get_faces", "(", "self", ",", "image", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "faces", "=", "self", ".", "mtcnn", "(", "image", ")", "\n", "", "except", "IndexError", ":", "# Strange index error on line 135 in utils/detect_face.py", "\n", "                ", "logger", ".", "warning", "(", "'Strange index error from FaceNet.'", ")", "\n", "return", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "\n", "", "if", "faces", "is", "None", ":", "\n", "                ", "return", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "\n", "", "embeddings", ",", "_", "=", "self", ".", "inception", "(", "faces", ")", "\n", "return", "embeddings", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.get_objects": [[305, 363], ["numpy.array", "img.unsqueeze.unsqueeze.transpose", "numpy.ascontiguousarray", "torch.from_numpy().to", "img.unsqueeze.unsqueeze.float", "tell.yolov3.utils.utils.non_max_suppression", "numpy.ascontiguousarray", "numpy.array", "tell.yolov3.utils.datasets.letterbox", "img.unsqueeze.unsqueeze.ndimension", "img.unsqueeze.unsqueeze.unsqueeze", "captioner.CaptioningWorker.darknet", "len", "len", "tell.yolov3.utils.utils.scale_coords().round", "det[].unique", "enumerate", "numpy.array", "torch.from_numpy", "len", "captioner.get_obj_embeddings", "obj_feats.append", "confidences.append", "classes.append", "tell.yolov3.utils.utils.plot_one_box", "tell.yolov3.utils.utils.scale_coords", "conf.item", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.non_max_suppression", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.datasets.letterbox", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.get_obj_embeddings", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_one_box", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.scale_coords"], ["", "", "def", "get_objects", "(", "self", ",", "image", ")", ":", "\n", "        ", "im0", "=", "np", ".", "array", "(", "image", ")", "\n", "img", "=", "letterbox", "(", "im0", ",", "new_shape", "=", "416", ")", "[", "0", "]", "\n", "img", "=", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "img", "=", "img", ".", "float", "(", ")", "\n", "img", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "if", "img", ".", "ndimension", "(", ")", "==", "3", ":", "\n", "            ", "img", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "pred", "=", "self", ".", "darknet", "(", "img", ")", "[", "0", "]", "\n", "\n", "# Apply NMS", "\n", "# We ignore the person class (class 0)", "\n", "pred", "=", "non_max_suppression", "(", "pred", ",", "0.3", ",", "0.6", ",", "\n", "classes", "=", "None", ",", "agnostic", "=", "False", ")", "\n", "\n", "# Process detections", "\n", "assert", "len", "(", "pred", ")", "==", "1", ",", "f'Length of pred is {len(pred)}'", "\n", "det", "=", "pred", "[", "0", "]", "\n", "\n", "im0", "=", "im0", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "# to BGR", "\n", "im0", "=", "np", ".", "ascontiguousarray", "(", "im0", ")", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "confidences", "=", "[", "]", "\n", "classes", "=", "[", "]", "\n", "if", "det", "is", "not", "None", "and", "len", "(", "det", ")", ":", "\n", "# Rescale boxes from img_size to im0 size", "\n", "            ", "det", "[", ":", ",", ":", "4", "]", "=", "scale_coords", "(", "\n", "img", ".", "shape", "[", "2", ":", "]", ",", "det", "[", ":", ",", ":", "4", "]", ",", "im0", ".", "shape", ")", ".", "round", "(", ")", "\n", "\n", "# Print results", "\n", "for", "c", "in", "det", "[", ":", ",", "-", "1", "]", ".", "unique", "(", ")", ":", "\n", "                ", "n", "=", "(", "det", "[", ":", ",", "-", "1", "]", "==", "c", ")", ".", "sum", "(", ")", "# detections per class", "\n", "\n", "# Write results", "\n", "", "for", "j", ",", "(", "*", "xyxy", ",", "conf", ",", "class_", ")", "in", "enumerate", "(", "det", ")", ":", "\n", "                ", "if", "j", ">=", "64", ":", "\n", "                    ", "break", "\n", "\n", "", "obj_feat", "=", "get_obj_embeddings", "(", "\n", "xyxy", ",", "image", ",", "None", ",", "self", ".", "resnet", ")", "\n", "obj_feats", ".", "append", "(", "obj_feat", ")", "\n", "confidences", ".", "append", "(", "conf", ".", "item", "(", ")", ")", "\n", "classes", ".", "append", "(", "int", "(", "class_", ")", ")", "\n", "\n", "label", "=", "'%s %.2f'", "%", "(", "self", ".", "names", "[", "int", "(", "class_", ")", "]", ",", "conf", ")", "\n", "plot_one_box", "(", "xyxy", ",", "im0", ",", "label", "=", "label", ",", "\n", "color", "=", "self", ".", "colors", "[", "int", "(", "class_", ")", "]", ")", "\n", "\n", "# Save results (image with detections)", "\n", "# cv2.imwrite(save_path, im0)", "\n", "\n", "", "", "if", "not", "obj_feats", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "return", "np", ".", "array", "(", "obj_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.to_token_ids": [[364, 373], ["captioner.CaptioningWorker.bpe.encode", "captioner.tokenize_line", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["", "def", "to_token_ids", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "bpe_tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker._process": [[374, 383], ["torch.no_grad", "captioner.CaptioningWorker.generate_captions"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.CaptioningWorker.generate_captions"], ["", "@", "overrides", "\n", "def", "_process", "(", "self", ",", "job", ")", ":", "\n", "        ", "articles", "=", "job", "[", "'message'", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "self", ".", "generate_captions", "(", "articles", ")", "\n", "\n", "", "return", "{", "\n", "'client_id'", ":", "job", "[", "'client_id'", "]", ",", "\n", "'output'", ":", "output", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.tokenize_line": [[44, 48], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.get_obj_embeddings": [[386, 408], ["pil_image.convert.convert", "captioner.extract_object", "torchvision.transforms.Compose", "torchvision.transforms.Compose.", "obj_image.unsqueeze().to.unsqueeze().to", "resnet", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu().numpy().tolist", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "obj_image.unsqueeze().to.unsqueeze", "next", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu().numpy", "resnet.parameters", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu", "X_image.squeeze().cpu().numpy().tolist.squeeze"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.extract_object"], ["", "", "def", "get_obj_embeddings", "(", "xyxy", ",", "pil_image", ",", "obj_path", ",", "resnet", ")", ":", "\n", "    ", "pil_image", "=", "pil_image", ".", "convert", "(", "'RGB'", ")", "\n", "obj_image", "=", "extract_object", "(", "pil_image", ",", "xyxy", ",", "save_path", "=", "obj_path", ")", "\n", "\n", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "obj_image", "=", "preprocess", "(", "obj_image", ")", "\n", "# obj_image.shape == [n_channels, height, width]", "\n", "\n", "# Add a batch dimension", "\n", "obj_image", "=", "obj_image", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "next", "(", "resnet", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "# obj_image.shape == [1, n_channels, height, width]", "\n", "\n", "X_image", "=", "resnet", "(", "obj_image", ",", "pool", "=", "True", ")", "\n", "# X_image.shape == [1, 2048]", "\n", "\n", "X_image", "=", "X_image", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "# X_image.shape == [2048]", "\n", "\n", "return", "X_image", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tasks.captioner.extract_object": [[410, 445], ["img.crop().resize", "int", "int", "int", "int", "os.makedirs", "img.crop().resize.save", "max", "max", "min", "min", "img.crop", "os.path.dirname"], "function", ["None"], ["", "def", "extract_object", "(", "img", ",", "box", ",", "image_size", "=", "224", ",", "margin", "=", "0", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract object + margin from PIL Image given bounding box.\n\n    Arguments:\n        img {PIL.Image} -- A PIL Image.\n        box {numpy.ndarray} -- Four-element bounding box.\n        image_size {int} -- Output image size in pixels. The image will be square.\n        margin {int} -- Margin to add to bounding box, in terms of pixels in the final image.\n            Note that the application of the margin differs slightly from the davidsandberg/facenet\n            repo, which applies the margin to the original image before resizing, making the margin\n            dependent on the original image size.\n        save_path {str} -- Save path for extracted object image. (default: {None})\n\n    Returns:\n        torch.tensor -- tensor representing the extracted object.\n    \"\"\"", "\n", "margin", "=", "[", "\n", "margin", "*", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "/", "(", "image_size", "-", "margin", ")", ",", "\n", "margin", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "/", "(", "image_size", "-", "margin", ")", "\n", "]", "\n", "box", "=", "[", "\n", "int", "(", "max", "(", "box", "[", "0", "]", "-", "margin", "[", "0", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "max", "(", "box", "[", "1", "]", "-", "margin", "[", "1", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "2", "]", "+", "margin", "[", "0", "]", "/", "2", ",", "img", ".", "size", "[", "0", "]", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "3", "]", "+", "margin", "[", "1", "]", "/", "2", ",", "img", ".", "size", "[", "1", "]", ")", ")", "\n", "]", "\n", "\n", "obj", "=", "img", ".", "crop", "(", "box", ")", ".", "resize", "(", "(", "image_size", ",", "image_size", ")", ",", "2", ")", "\n", "\n", "if", "save_path", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "+", "'/'", ",", "exist_ok", "=", "True", ")", "\n", "save_args", "=", "{", "'compress_level'", ":", "0", "}", "if", "'.png'", "in", "save_path", "else", "{", "}", "\n", "obj", ".", "save", "(", "save_path", ",", "**", "save_args", ")", "\n", "\n", "", "return", "obj", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.__init__": [[24, 95], ["decoder_base.Decoder.__init__", "embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.layers.extend", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.register_buffer", "vocab.get_vocab_size", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "isinstance", "tell.modules.AdaptiveSoftmax", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "decoder_faces_parallel.DynamicConvDecoderLayer", "hasattr", "tell.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "embedder", ":", "TextFieldEmbedder", ",", "max_target_positions", ",", "dropout", ",", "\n", "share_decoder_input_output_embed", ",", "\n", "decoder_output_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "decoder_kernel_size_list", ",", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "tie_adaptive_weights", "=", "False", ",", "adaptive_softmax_dropout", "=", "0", ",", "\n", "tie_adaptive_proj", "=", "False", ",", "adaptive_softmax_factor", "=", "0", ",", "decoder_layers", "=", "6", ",", "\n", "final_norm", "=", "True", ",", "padding_idx", "=", "0", ",", "namespace", "=", "'target_tokens'", ",", "\n", "vocab_size", "=", "None", ",", "section_attn", "=", "False", ",", "swap", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embedder", ".", "get_output_dim", "(", ")", "\n", "embed_dim", "=", "input_embed_dim", "\n", "output_embed_dim", "=", "input_embed_dim", "\n", "\n", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "max_target_positions", "\n", "\n", "self", ".", "embedder", "=", "embedder", "\n", "\n", "self", ".", "project_in_dim", "=", "GehringLinear", "(", "\n", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "input_embed_dim", "else", "None", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "DynamicConvDecoderLayer", "(", "embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "swap", ",", "\n", "kernel_size", "=", "decoder_kernel_size_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "decoder_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "GehringLinear", "(", "embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "output_embed_dim", "and", "not", "tie_adaptive_weights", "else", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "adaptive_inputs", "=", "None", "\n", "if", "isinstance", "(", "embedder", ",", "AdaptiveEmbedding", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", "\n", "", "elif", "hasattr", "(", "embedder", ",", "'token_embedder_adaptive'", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", ".", "token_embedder_adaptive", "\n", "", "elif", "tie_adaptive_weights", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot locate adaptive_inputs.'", ")", "\n", "", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "vocab_size", ",", "\n", "output_embed_dim", ",", "\n", "eval_str_list", "(", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "adaptive_inputs", ",", "\n", "factor", "=", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "vocab_size", ",", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "\n", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "decoder_normalize_before", "and", "final_norm", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.forward": [[96, 143], ["decoder_faces_parallel.DynamicConvFacesParallelDecoder.embedder", "torch.dropout", "torch.dropout", "torch.dropout", "torch.linear.transpose", "enumerate", "torch.linear.transpose", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.project_in_dim", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.layer_norm", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.project_out_dim", "layer", "inner_states.append", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "prev_target", ",", "contexts", ",", "incremental_state", "=", "None", ",", "\n", "use_layers", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "X", "=", "self", ".", "embedder", "(", "prev_target", ",", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# if incremental_state is not None:", "\n", "#     X = X[:, -1:]", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_in_dim", "(", "X", ")", "\n", "\n", "", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "X", "]", "\n", "\n", "# decoder layers", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "not", "use_layers", "or", "i", "in", "use_layers", ":", "\n", "                ", "X", ",", "attn", "=", "layer", "(", "\n", "X", ",", "\n", "contexts", ",", "\n", "incremental_state", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "X", ")", "\n", "\n", "", "", "if", "self", ".", "normalize", ":", "\n", "            ", "X", "=", "self", ".", "layer_norm", "(", "X", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_out_dim", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "\n", "X", ",", "self", ".", "embedder", ".", "token_embedder_bert", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "X", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "X", ",", "{", "'attn'", ":", "attn", ",", "'inner_states'", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.max_positions": [[144, 147], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "max_target_positions", "\n", "# return min(self.max_target_positions, self.embedder.max_positions())", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.buffered_future_mask": [[149, 159], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "decoder_faces_parallel.DynamicConvFacesParallelDecoder._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "tell.utils.fill_with_neg_inf", "tell.utils.fill_with_neg_inf", "tensor.new", "decoder_faces_parallel.DynamicConvFacesParallelDecoder._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# pylint: disable=access-member-before-definition", "\n", "if", "not", "hasattr", "(", "self", ",", "'_future_mask'", ")", "or", "self", ".", "_future_mask", "is", "None", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "\n", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.get_normalized_probs": [[160, 174], ["net_output[].float", "hasattr", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.adaptive_softmax.get_log_prob", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "decoder_faces_parallel.DynamicConvFacesParallelDecoder.exp"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "'adaptive_softmax'", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "target", "=", "sample", "[", "'target'", "]", "if", "sample", "else", "None", "\n", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "\n", "net_output", "[", "0", "]", ",", "target", ")", "\n", "return", "out", ".", "exp", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvFacesParallelDecoder.filter_incremental_state": [[175, 181], ["None"], "methods", ["None"], ["", "", "def", "filter_incremental_state", "(", "self", ",", "incremental_state", ",", "active_idx", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", ":", "\n", "            ", "return", "\n", "", "for", "key", "in", "incremental_state", ":", "\n", "            ", "if", "'DynamicConv1dTBC'", "in", "key", ":", "\n", "                ", "incremental_state", "[", "key", "]", "=", "incremental_state", "[", "key", "]", "[", ":", ",", "active_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvDecoderLayer.__init__": [[186, 250], ["decoder_base.DecoderLayer.__init__", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "torch.GLU", "torch.GLU", "torch.GLU", "tell.modules.GehringLinear", "tell.modules.LightweightConv1dTBC", "tell.modules.DynamicConv1dTBC"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "swap", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "decoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "decoder_conv_dim", "\n", "if", "decoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "decoder_conv_type", "==", "'lightweight'", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "elif", "decoder_conv_type", "==", "'dynamic'", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "GehringLinear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "input_dropout", "=", "input_dropout", "\n", "self", ".", "normalize_before", "=", "decoder_normalize_before", "\n", "\n", "self", ".", "conv_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "context_attn_lns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "C", "=", "2048", "\n", "\n", "self", ".", "context_attns", "[", "'image'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "C", ",", "vdim", "=", "C", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'article'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "1024", ",", "vdim", "=", "1024", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'faces'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "512", ",", "vdim", "=", "512", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "context_size", "=", "self", ".", "embed_dim", "*", "3", "\n", "\n", "self", ".", "context_fc", "=", "GehringLinear", "(", "context_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "fc1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "GehringLinear", "(", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "self", ".", "swap", "=", "swap", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvDecoderLayer.forward": [[251, 335], ["decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.linear1", "decoder_faces_parallel.DynamicConvDecoderLayer.conv", "decoder_faces_parallel.DynamicConvDecoderLayer.linear2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_faces_parallel.DynamicConvDecoderLayer.context_fc", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_faces_parallel.DynamicConvDecoderLayer.act", "decoder_faces_parallel.DynamicConvDecoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "X", ",", "contexts", ",", "incremental_state", ")", ":", "\n", "        ", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "input_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "linear1", "(", "X", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "act", "(", "X", ")", "\n", "", "X", "=", "self", ".", "conv", "(", "X", ",", "incremental_state", "=", "incremental_state", ")", "\n", "X", "=", "self", ".", "linear2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "\n", "attn", "=", "None", "\n", "X_contexts", "=", "[", "]", "\n", "\n", "# Image attention", "\n", "residual", "=", "X", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_image", ",", "attn", "=", "self", ".", "context_attns", "[", "'image'", "]", "(", "\n", "query", "=", "X_image", ",", "\n", "key", "=", "contexts", "[", "'image'", "]", ",", "\n", "value", "=", "contexts", "[", "'image'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'image_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_image", "=", "F", ".", "dropout", "(", "X_image", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X_image", "=", "residual", "+", "X_image", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X_image", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_image", ")", "\n", "\n", "# Article attention", "\n", "residual", "=", "X", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_article", ",", "attn", "=", "self", ".", "context_attns", "[", "'article'", "]", "(", "\n", "query", "=", "X_article", ",", "\n", "key", "=", "contexts", "[", "'article'", "]", ",", "\n", "value", "=", "contexts", "[", "'article'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'article_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_article", "=", "F", ".", "dropout", "(", "X_article", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_article", "=", "residual", "+", "X_article", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X_article", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_article", ")", "\n", "\n", "# Face attention", "\n", "residual", "=", "X", "\n", "X_faces", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_faces", ",", "attn", "=", "self", ".", "context_attns", "[", "'faces'", "]", "(", "\n", "query", "=", "X_faces", ",", "\n", "key", "=", "contexts", "[", "'faces'", "]", ",", "\n", "value", "=", "contexts", "[", "'faces'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'faces_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_faces", "=", "F", ".", "dropout", "(", "X_faces", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_faces", "=", "residual", "+", "X_faces", "\n", "X_faces", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", ",", "X_faces", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_faces", ")", "\n", "\n", "X_context", "=", "torch", ".", "cat", "(", "X_contexts", ",", "dim", "=", "-", "1", ")", "\n", "X", "=", "self", ".", "context_fc", "(", "X_context", ")", "\n", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "X", ")", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "fc2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "return", "X", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvDecoderLayer.maybe_layer_norm": [[336, 342], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "X", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "X", ")", "\n", "", "else", ":", "\n", "            ", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvDecoderLayer.make_generation_fast_": [[343, 345], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_parallel.DynamicConvDecoderLayer.extra_repr": [[346, 349], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}'", ".", "format", "(", "\n", "self", ".", "dropout", ",", "self", ".", "relu_dropout", ",", "self", ".", "input_dropout", ",", "self", ".", "normalize_before", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.__init__": [[24, 95], ["decoder_base.Decoder.__init__", "embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "decoder_flattened_no_image.DynamicConvDecoderNoImage.layers.extend", "decoder_flattened_no_image.DynamicConvDecoderNoImage.register_buffer", "vocab.get_vocab_size", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "isinstance", "tell.modules.AdaptiveSoftmax", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "decoder_flattened_no_image.DynamicConvDecoderLayer", "hasattr", "tell.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "embedder", ":", "TextFieldEmbedder", ",", "max_target_positions", ",", "dropout", ",", "\n", "share_decoder_input_output_embed", ",", "\n", "decoder_output_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "decoder_kernel_size_list", ",", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "tie_adaptive_weights", "=", "False", ",", "adaptive_softmax_dropout", "=", "0", ",", "\n", "tie_adaptive_proj", "=", "False", ",", "adaptive_softmax_factor", "=", "0", ",", "decoder_layers", "=", "6", ",", "\n", "final_norm", "=", "True", ",", "padding_idx", "=", "0", ",", "namespace", "=", "'target_tokens'", ",", "\n", "vocab_size", "=", "None", ",", "section_attn", "=", "False", ",", "article_embed_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embedder", ".", "get_output_dim", "(", ")", "\n", "embed_dim", "=", "input_embed_dim", "\n", "output_embed_dim", "=", "input_embed_dim", "\n", "\n", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "max_target_positions", "\n", "\n", "self", ".", "embedder", "=", "embedder", "\n", "\n", "self", ".", "project_in_dim", "=", "GehringLinear", "(", "\n", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "input_embed_dim", "else", "None", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "DynamicConvDecoderLayer", "(", "embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "article_embed_size", ",", "\n", "kernel_size", "=", "decoder_kernel_size_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "decoder_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "GehringLinear", "(", "embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "output_embed_dim", "and", "not", "tie_adaptive_weights", "else", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "adaptive_inputs", "=", "None", "\n", "if", "isinstance", "(", "embedder", ",", "AdaptiveEmbedding", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", "\n", "", "elif", "hasattr", "(", "embedder", ",", "'token_embedder_adaptive'", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", ".", "token_embedder_adaptive", "\n", "", "elif", "tie_adaptive_weights", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot locate adaptive_inputs.'", ")", "\n", "", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "vocab_size", ",", "\n", "output_embed_dim", ",", "\n", "eval_str_list", "(", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "adaptive_inputs", ",", "\n", "factor", "=", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "vocab_size", ",", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "\n", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "decoder_normalize_before", "and", "final_norm", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.forward": [[96, 143], ["decoder_flattened_no_image.DynamicConvDecoderNoImage.embedder", "torch.dropout", "torch.dropout", "torch.dropout", "torch.linear.transpose", "enumerate", "torch.linear.transpose", "decoder_flattened_no_image.DynamicConvDecoderNoImage.project_in_dim", "decoder_flattened_no_image.DynamicConvDecoderNoImage.layer_norm", "decoder_flattened_no_image.DynamicConvDecoderNoImage.project_out_dim", "layer", "inner_states.append", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "prev_target", ",", "contexts", ",", "incremental_state", "=", "None", ",", "\n", "use_layers", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "X", "=", "self", ".", "embedder", "(", "prev_target", ",", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# if incremental_state is not None:", "\n", "#     X = X[:, -1:]", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_in_dim", "(", "X", ")", "\n", "\n", "", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "X", "]", "\n", "\n", "# decoder layers", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "not", "use_layers", "or", "i", "in", "use_layers", ":", "\n", "                ", "X", ",", "attn", "=", "layer", "(", "\n", "X", ",", "\n", "contexts", ",", "\n", "incremental_state", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "X", ")", "\n", "\n", "", "", "if", "self", ".", "normalize", ":", "\n", "            ", "X", "=", "self", ".", "layer_norm", "(", "X", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_out_dim", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "\n", "X", ",", "self", ".", "embedder", ".", "token_embedder_bert", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "X", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "X", ",", "{", "'attn'", ":", "attn", ",", "'inner_states'", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.max_positions": [[144, 147], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "max_target_positions", "\n", "# return min(self.max_target_positions, self.embedder.max_positions())", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.buffered_future_mask": [[149, 159], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "decoder_flattened_no_image.DynamicConvDecoderNoImage._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "tell.utils.fill_with_neg_inf", "tell.utils.fill_with_neg_inf", "tensor.new", "decoder_flattened_no_image.DynamicConvDecoderNoImage._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# pylint: disable=access-member-before-definition", "\n", "if", "not", "hasattr", "(", "self", ",", "'_future_mask'", ")", "or", "self", ".", "_future_mask", "is", "None", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "\n", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.get_normalized_probs": [[160, 174], ["net_output[].float", "hasattr", "decoder_flattened_no_image.DynamicConvDecoderNoImage.adaptive_softmax.get_log_prob", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "decoder_flattened_no_image.DynamicConvDecoderNoImage.exp"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "'adaptive_softmax'", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "target", "=", "sample", "[", "'target'", "]", "if", "sample", "else", "None", "\n", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "\n", "net_output", "[", "0", "]", ",", "target", ")", "\n", "return", "out", ".", "exp", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderNoImage.filter_incremental_state": [[175, 181], ["None"], "methods", ["None"], ["", "", "def", "filter_incremental_state", "(", "self", ",", "incremental_state", ",", "active_idx", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", ":", "\n", "            ", "return", "\n", "", "for", "key", "in", "incremental_state", ":", "\n", "            ", "if", "'DynamicConv1dTBC'", "in", "key", ":", "\n", "                ", "incremental_state", "[", "key", "]", "=", "incremental_state", "[", "key", "]", "[", ":", ",", "active_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderLayer.__init__": [[185, 238], ["decoder_base.DecoderLayer.__init__", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "torch.GLU", "torch.GLU", "torch.GLU", "tell.modules.GehringLinear", "tell.modules.LightweightConv1dTBC", "tell.modules.DynamicConv1dTBC"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "article_embed_size", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "decoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "decoder_conv_dim", "\n", "if", "decoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "decoder_conv_type", "==", "'lightweight'", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "elif", "decoder_conv_type", "==", "'dynamic'", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "GehringLinear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "input_dropout", "=", "input_dropout", "\n", "self", ".", "normalize_before", "=", "decoder_normalize_before", "\n", "\n", "self", ".", "conv_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "context_attn_lns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "C", "=", "2048", "\n", "\n", "self", ".", "context_attns", "[", "'article'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "article_embed_size", ",", "vdim", "=", "article_embed_size", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "context_size", "=", "self", ".", "embed_dim", "\n", "\n", "self", ".", "context_fc", "=", "GehringLinear", "(", "context_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "fc1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "GehringLinear", "(", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderLayer.forward": [[239, 296], ["decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_no_image.DynamicConvDecoderLayer.linear1", "decoder_flattened_no_image.DynamicConvDecoderLayer.conv", "decoder_flattened_no_image.DynamicConvDecoderLayer.linear2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_flattened_no_image.DynamicConvDecoderLayer.context_fc", "decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_no_image.DynamicConvDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_flattened_no_image.DynamicConvDecoderLayer.act", "decoder_flattened_no_image.DynamicConvDecoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "X", ",", "contexts", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            X (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n\n        Returns:\n            encoded output of shape `(batch, src_len, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "input_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "linear1", "(", "X", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "act", "(", "X", ")", "\n", "", "X", "=", "self", ".", "conv", "(", "X", ",", "incremental_state", "=", "incremental_state", ")", "\n", "X", "=", "self", ".", "linear2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "\n", "attn", "=", "None", "\n", "X_contexts", "=", "[", "]", "\n", "\n", "# Article attention", "\n", "residual", "=", "X", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_article", ",", "attn", "=", "self", ".", "context_attns", "[", "'article'", "]", "(", "\n", "query", "=", "X_article", ",", "\n", "key", "=", "contexts", "[", "'article'", "]", ",", "\n", "value", "=", "contexts", "[", "'article'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'article_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_article", "=", "F", ".", "dropout", "(", "X_article", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_article", "=", "residual", "+", "X_article", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X_article", ",", "after", "=", "True", ")", "\n", "\n", "X_contexts", ".", "append", "(", "X_article", ")", "\n", "\n", "X_context", "=", "torch", ".", "cat", "(", "X_contexts", ",", "dim", "=", "-", "1", ")", "\n", "X", "=", "self", ".", "context_fc", "(", "X_context", ")", "\n", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "X", ")", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "fc2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "return", "X", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderLayer.maybe_layer_norm": [[297, 303], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "X", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "X", ")", "\n", "", "else", ":", "\n", "            ", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderLayer.make_generation_fast_": [[304, 306], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_no_image.DynamicConvDecoderLayer.extra_repr": [[307, 310], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}'", ".", "format", "(", "\n", "self", ".", "dropout", ",", "self", ".", "relu_dropout", ",", "self", ".", "input_dropout", ",", "self", ".", "normalize_before", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.__init__": [[29, 99], ["allennlp.nn.initializers.InitializerApplicator", "tell.modules.LoadStateDictWithPrefix.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "collections.defaultdict", "tell.modules.GehringLinear", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "tell.modules.GehringLinear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "tell.modules.SelfAttention", "initializer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "logger.info", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "transformer_pointer.TransformerPointerModel.load_state_dict", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "self", ".", "bert_weight_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight_2", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "batch_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "self", ".", "entity_fc", "=", "GehringLinear", "(", "1024", ",", "2", ")", "\n", "self", ".", "entity_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "# self.copy_loss = nn.CrossEntropyLoss(ignore_index=padding_value)", "\n", "\n", "# Copy-related modules", "\n", "self", ".", "in_proj_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "2", "*", "1024", ",", "1024", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "2", "*", "1024", ")", ")", "\n", "self", ".", "out_proj", "=", "GehringLinear", "(", "1024", ",", "1024", ",", "bias", "=", "True", ")", "\n", "self", ".", "bias_k", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "1", ",", "1", ",", "1024", ")", ")", "\n", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "\n", "# Entity-related modules", "\n", "self", ".", "entity_attn", "=", "SelfAttention", "(", "\n", "out_channels", "=", "1024", ",", "embed_dim", "=", "1024", ",", "num_heads", "=", "16", ",", "gated", "=", "True", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "\n", "if", "model_path", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f'Recovering weights from {model_path}.'", ")", "\n", "model_state", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "self", ".", "load_state_dict", "(", "model_state", ")", "\n", "# Initialize the weight with first layer of BERT", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.forward": [[103, 179], ["transformer_pointer.TransformerPointerModel._forward", "transformer_pointer.TransformerPointerModel.decoder", "transformer_pointer.TransformerPointerModel.criterion", "transformer_pointer.TransformerPointerModel.pointer_loss", "math.log", "math.log", "math.log", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "gen_loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "entity_loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "copy_loss.item", "transformer_pointer.TransformerPointerModel._generate", "zip", "transformer_pointer.TransformerPointerModel.roberta.decode", "transformer_pointer.TransformerPointerModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "gen_ids.cpu", "enumerate", "gen_ids.cpu"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.pointer_loss", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ":", "torch", ".", "Tensor", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "names", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "target_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "gen_loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "entity_loss", ",", "copy_loss", "=", "self", ".", "pointer_loss", "(", "\n", "decoder_out", ",", "context", ",", "caption", ",", "target_ids", ",", "X_sections_hiddens", ",", "article_padding_mask", ")", "\n", "\n", "gen_loss", "=", "gen_loss", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", "\n", "entity_loss", "=", "entity_loss", "/", "math", ".", "log", "(", "2", ")", "\n", "copy_loss", "=", "copy_loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "loss", "=", "entity_loss", "+", "copy_loss", "\n", "\n", "if", "(", "self", ".", "training", "and", "not", "loss", ".", "requires_grad", ")", "or", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "loss", "=", "None", "\n", "\n", "", "if", "not", "torch", ".", "isnan", "(", "gen_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'gen_loss'", "]", "+=", "gen_loss", ".", "item", "(", ")", "\n", "", "if", "not", "torch", ".", "isnan", "(", "entity_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'entity_loss'", "]", "+=", "entity_loss", ".", "item", "(", ")", "\n", "", "if", "not", "torch", ".", "isnan", "(", "copy_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'copy_loss'", "]", "+=", "copy_loss", ".", "item", "(", ")", "\n", "\n", "", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "log_probs", ",", "copy_probs", ",", "should_copy_mask", ",", "gen_ids", "=", "self", ".", "_generate", "(", "\n", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "copied_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "should_copy_mask", "[", "i", "]", "]", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "gen_ids", ".", "cpu", "(", ")", ")", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "output_dict", "[", "'copied_texts'", "]", "=", "copied_texts", "\n", "\n", "# Remove punctuation", "\n", "gen_texts", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts", ",", "captions", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.pointer_loss": [[180, 314], ["X.transpose.transpose.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "transformer_pointer.TransformerPointerModel.entity_attn", "X_entity.transpose.transpose.transpose", "transformer_pointer.TransformerPointerModel.entity_fc", "entity_logits.view.view.view", "caption_copy_masks.clone().reshape", "transformer_pointer.TransformerPointerModel.entity_loss", "tell.modules.multi_head_attention_score_forward", "context_copy_masks.expand_as.expand_as.unsqueeze", "context_copy_masks.expand_as.expand_as.expand_as", "tell.modules.multi_head_attention_score_forward.new_zeros", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "len", "torch.cat().unique.new_full", "torch.cat().unique.new_full", "torch.cat().unique.new_full", "torch.cat().unique.new_full.index_copy_", "torch.cat().unique.new_full.index_select", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.cat().unique.new_full.index_select", "new_caption_targets.reshape.reshape.reshape", "tell.modules.multi_head_attention_score_forward.new_zeros", "tell.modules.multi_head_attention_score_forward.new_zeros.scatter_add_", "tell.modules.multi_head_attention_score_forward.new_zeros.new_zeros", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "copy_lprobs.view.view.view", "caption_copy_masks.max().item", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "range", "caption_copy_masks[].bool().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "context_ids.reshape", "caption_targets.reshape", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "caption_copy_masks.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "caption_copy_masks.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "copy_lprobs_i.gather().mean", "caption_copy_masks[].bool", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "copy_lprobs_i.gather", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.multi_head_attention_score_forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "pointer_loss", "(", "self", ",", "decoder_out", ",", "context", ",", "caption", ",", "caption_targets", ",", "\n", "X_sections_hiddens", ",", "article_padding_mask", ")", ":", "\n", "        ", "X", "=", "decoder_out", "[", "0", "]", "\n", "# X.shape == [batch_size, target_len, embed_size]", "\n", "\n", "caption_copy_masks", "=", "caption", "[", "f'{self.index}_copy_masks'", "]", "\n", "caption_copy_masks", "=", "caption_copy_masks", "[", ":", ",", "1", ":", "]", "\n", "# caption_copy_masks.shape == [batch_size, target_len]", "\n", "\n", "if", "not", "caption_copy_masks", "[", "caption_copy_masks", ">=", "1", "]", ".", "bool", "(", ")", ".", "any", "(", ")", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "\n", "", "context_copy_masks", "=", "context", "[", "f'{self.index}_proper_masks'", "]", "\n", "# context_copy_masks.shape == [batch_size, source_len]", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight_2", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [target_len, batch_size, embed_size]", "\n", "\n", "X_article", "=", "X_article", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "X_entity", "=", "self", ".", "entity_attn", "(", "X", ")", "\n", "# X_entity.shape == [target_len, batch_size, embed_size]", "\n", "\n", "X_entity", "=", "X_entity", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_entity.shape == [batch_size, target_len, embed_size]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X_entity", ")", "\n", "# entity_logits.shape == [batch_size, target_len, 2]", "\n", "\n", "entity_logits", "=", "entity_logits", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "# entity_logits.shape == [batch_size * target_len, 2]", "\n", "\n", "targets", "=", "caption_copy_masks", ".", "clone", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "targets", "[", "targets", ">", "1", "]", "=", "1", "\n", "# targets.shape == [batch_size * target_len]", "\n", "\n", "entity_loss", "=", "self", ".", "entity_loss", "(", "entity_logits", ",", "targets", ")", "\n", "\n", "copy_attn", "=", "multi_head_attention_score_forward", "(", "\n", "X", ",", "X_article", ",", "1024", ",", "16", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "True", ",", "0.1", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "article_padding_mask", ")", "\n", "# copy_attn.shape == [batch_size, target_len, source_len + 2]", "\n", "\n", "copy_attn", "=", "copy_attn", "[", ":", ",", ":", ",", ":", "-", "2", "]", "\n", "# copy_attn.shape == [batch_size, target_len, source_len]", "\n", "\n", "context_copy_masks", "=", "context_copy_masks", ".", "unsqueeze", "(", "1", ")", "\n", "# context_copy_masks.shape == [batch_size, 1, source_len]", "\n", "\n", "context_copy_masks", "=", "context_copy_masks", ".", "expand_as", "(", "copy_attn", ")", "\n", "# context_copy_masks.shape == [batch_size, target_len, source_len]", "\n", "\n", "irrelevant_mask", "=", "context_copy_masks", "<", "1", "\n", "copy_attn", "[", "irrelevant_mask", "]", "=", "0", "\n", "# copy_attn.shape == [batch_size, target_len, source_len]", "\n", "\n", "B", ",", "L", ",", "S", "=", "copy_attn", ".", "shape", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B", ",", "L", ",", "self", ".", "vocab_size", ")", "\n", "# copy_probs.shape == [batch_size, target_len, vocab_size]", "\n", "\n", "context_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# context_ids.shape == [batch_size, source_len]", "\n", "\n", "########################################", "\n", "# Second attempt at calculating copy loss", "\n", "# First construct the reduced dictionary, containing only tokens", "\n", "# mentioned in the context.", "\n", "unique_ids", "=", "torch", ".", "cat", "(", "[", "context_ids", ",", "caption_targets", "]", ",", "dim", "=", "1", ")", ".", "unique", "(", ")", "\n", "V", "=", "len", "(", "unique_ids", ")", "\n", "# unique_ids.shape == [reduced_vocab_size]", "\n", "\n", "# Construct the inverse map of unique_ids", "\n", "inverse_unique_ids", "=", "unique_ids", ".", "new_full", "(", "[", "self", ".", "vocab_size", "]", ",", "-", "1", ")", "\n", "inverse_unique_ids", ".", "index_copy_", "(", "\n", "0", ",", "unique_ids", ",", "torch", ".", "arange", "(", "V", ")", ".", "to", "(", "unique_ids", ".", "device", ")", ")", "\n", "# inverse_unique_ids.shape == [vocab_size]", "\n", "# e.g. [-1, -1, 0, -1, -1, 1, 2, -1, 3, ....]", "\n", "\n", "# Next we need to remap the context_ids to the new dictionary.", "\n", "new_context_ids", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "context_ids", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_context_ids.shape == [batch_size * source_len]", "\n", "\n", "new_context_ids", "=", "new_context_ids", ".", "view", "(", "B", ",", "S", ")", "\n", "new_context_ids", "=", "new_context_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "copy_attn", ")", "\n", "# new_context_ids.shape == [batch_size, target_len, source_len]", "\n", "\n", "new_caption_targets", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "caption_targets", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_caption_targets.shape == [batch_size * target_len, 1]", "\n", "\n", "new_caption_targets", "=", "new_caption_targets", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "# new_caption_targets.shape == [batch_size * target_len, 1]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B", ",", "L", ",", "V", ")", "\n", "# copy_probs.shape == [batch_size, target_len, reduced_vocab_size]", "\n", "\n", "copy_probs", ".", "scatter_add_", "(", "2", ",", "new_context_ids", ",", "copy_attn", ")", "\n", "copy_lprobs", "=", "copy_probs", ".", "new_zeros", "(", "copy_probs", ".", "shape", ")", "\n", "copy_lprobs", "[", "copy_probs", ">", "0", "]", "=", "torch", ".", "log", "(", "copy_probs", "[", "copy_probs", ">", "0", "]", ")", "\n", "copy_lprobs", "=", "copy_lprobs", ".", "view", "(", "B", "*", "L", ",", "V", ")", "\n", "\n", "max_index", "=", "caption_copy_masks", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "copy_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "max_index", "+", "1", ")", ":", "\n", "            ", "relevant_mask", "=", "(", "caption_copy_masks", "==", "i", ")", ".", "view", "(", "-", "1", ")", "\n", "new_caption_targets_i", "=", "new_caption_targets", "[", "relevant_mask", "]", "\n", "# new_caption_targets_i.shape == [batch_size * n_entity_tokens, 1]", "\n", "\n", "copy_lprobs_i", "=", "copy_lprobs", "[", "relevant_mask", "]", "\n", "# copy_lprobs_i.shape == [batch_size * n_entity_tokens, reduced_vocab_size]", "\n", "\n", "copy_loss", "+=", "-", "copy_lprobs_i", ".", "gather", "(", "dim", "=", "-", "1", ",", "\n", "index", "=", "new_caption_targets_i", ")", ".", "mean", "(", ")", "\n", "\n", "", "return", "entity_loss", ",", "copy_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.generate": [[315, 343], ["transformer_pointer.TransformerPointerModel._forward", "transformer_pointer.TransformerPointerModel._generate", "gen_ids.cpu.cpu.cpu", "context[].new_zeros", "transformer_pointer.TransformerPointerModel.roberta.decode", "transformer_pointer.TransformerPointerModel.roberta.decode", "enumerate"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "face_embeds", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "B", "=", "image", ".", "shape", "[", "0", "]", "\n", "caption", "=", "{", "self", ".", "index", ":", "context", "[", "self", ".", "index", "]", ".", "new_zeros", "(", "B", ",", "2", ")", "}", "\n", "caption_ids", ",", "_", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "\n", "log_probs", ",", "copy_probs", ",", "should_copy_mask", ",", "gen_ids", "=", "self", ".", "_generate", "(", "\n", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "# Get the copied words", "\n", "copied_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "should_copy_mask", "[", "i", "]", "]", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "gen_ids", ")", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generations'", ":", "gen_texts", ",", "\n", "'copied_texts'", ":", "copied_texts", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel._forward": [[344, 426], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer_pointer.TransformerPointerModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_pointer.TransformerPointerModel.roberta.extract_features", "X_image.view.view.new_zeros().bool", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "X_image.view.view.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "face_embeds.transpose", "X_image.view.view.new_zeros", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "# For masks, 1 is padding, 2 is normal word, 3 is entity word", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "article_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "article_padding_mask", "=", "article_ids", "==", "self", ".", "padding_idx", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "B", ",", "S", "=", "article_ids", ".", "shape", "\n", "\n", "X_sections_hiddens", "=", "self", ".", "roberta", ".", "extract_features", "(", "\n", "article_ids", ",", "return_all_hiddens", "=", "True", ")", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# face_embeds.shape == [batch_size, n_faces, 512]", "\n", "face_masks", "=", "torch", ".", "isnan", "(", "face_embeds", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "face_embeds", "[", "face_masks", "]", "=", "0", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "'faces'", ":", "face_embeds", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'faces_mask'", ":", "face_masks", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel._generate": [[427, 696], ["torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "caption_ids.new_full", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_ones().bool", "torch.cat.new_ones().bool", "torch.cat.new_ones().bool", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "transformer_pointer.TransformerPointerModel.decoder.filter_incremental_state", "transformer_pointer.TransformerPointerModel.decoder", "transformer_pointer.TransformerPointerModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "Xs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "X_full.transpose.transpose.transpose", "transformer_pointer.TransformerPointerModel.entity_attn", "X_entity.transpose.transpose.transpose", "transformer_pointer.TransformerPointerModel.entity_fc", "transformer_pointer.TransformerPointerModel.entity_fc", "X.transpose.transpose.transpose", "tell.modules.multi_head_attention_score_forward", "copy_attn.squeeze.squeeze.squeeze", "copy_attn.squeeze.squeeze.new_zeros", "context_ids.unique", "len", "context_ids.unique.new_full", "context_ids.unique.new_full.index_copy_", "context_ids.unique.new_full.index_select", "new_context_ids.view.view.view", "copy_attn.squeeze.squeeze.new_zeros", "copy_attn.squeeze.new_zeros.scatter_add_", "copy_attn.squeeze.new_zeros.topk", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_copy_probs.gather", "topk_copy_indices.gather", "context_ids.unique.gather", "selected_copy_index.unsqueeze.unsqueeze.unsqueeze", "selected_copy_index.unsqueeze.unsqueeze.expand_as", "selected_copy_index.unsqueeze.unsqueeze.new_full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_copy_probs.gather.new_zeros", "copy_prob_list.append", "should_copy.new_zeros", "should_copy.unsqueeze", "should_copy_list.append", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_indices.gather.new_zeros", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_zeros.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_pointer.TransformerPointerModel.argmax", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "context_ids.reshape", "topk_indices.gather.new_zeros.squeeze", "active_idx.sum().item", "torch.cat.new_ones", "torch.cat.new_ones", "torch.cat.new_ones", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "topk_copy_indices.gather.squeeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "empty_copy.max", "full_active_idx.nonzero().squeeze", "full_active_idx.nonzero", "active_idx.sum", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "full_active_idx.nonzero"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.multi_head_attention_score_forward"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "copy_prob_list", "=", "[", "]", "\n", "should_copy_list", "=", "[", "seed_input", ".", "new_ones", "(", "B", ",", "1", ")", ".", "bool", "(", ")", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "\n", "context_copy_masks", "=", "context", "[", "f'{self.index}_proper_masks'", "]", "\n", "# context_copy_masks.shape == [batch_size, source_len]", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, src_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight_2", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "X_article", "=", "X_article", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_article.shape == [seq_len, batch_size, embed_size]", "\n", "\n", "Xs", "=", "[", "]", "\n", "\n", "copied_indices_full", "=", "caption_ids", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'faces'", ":", "contexts", "[", "'faces'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'faces_mask'", ":", "contexts", "[", "'faces_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "X", "=", "decoder_out", "[", "0", "]", "\n", "# X.shape == [batch_size, 1, embed_size]", "\n", "\n", "Xs", ".", "append", "(", "X", ")", "\n", "\n", "X_full", "=", "torch", ".", "cat", "(", "Xs", ",", "dim", "=", "1", ")", "\n", "# X.shape == [batch_size_i, target_len, embed_size]", "\n", "\n", "X_full", "=", "X_full", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [target_len, batch_size_i, embed_size]", "\n", "\n", "X_entity", "=", "self", ".", "entity_attn", "(", "X_full", ")", "\n", "# X_entity.shape == [target_len, batch_size_i, embed_size]", "\n", "\n", "X_entity", "=", "X_entity", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_entity.shape == [batch_size_i, target_len, embed_size]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X", ")", "\n", "# entity_logits.shape == [batch_size, 1, 2]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X_entity", "[", ":", ",", "-", "1", "]", ")", "\n", "# entity_logits.shape == [batch_size, 2]", "\n", "\n", "should_copy", "=", "entity_logits", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "1", "\n", "# should_copy.shape == [batch_size]", "\n", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [1, batch_size, embed_size]", "\n", "\n", "X_article_i", "=", "X_article", "[", ":", ",", "full_active_idx", "]", "\n", "article_padding_mask_i", "=", "article_padding_mask", "[", "full_active_idx", "]", "\n", "\n", "copy_attn", "=", "multi_head_attention_score_forward", "(", "\n", "X", ",", "X_article_i", ",", "1024", ",", "16", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "True", ",", "0.1", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "article_padding_mask_i", ")", "\n", "# copy_attn.shape == [batch_size, target_len, source_len + 2]", "\n", "\n", "copy_attn", "=", "copy_attn", "[", ":", ",", ":", ",", ":", "-", "2", "]", "\n", "# copy_attn.shape == [batch_size, 1, source_len]", "\n", "\n", "copy_attn", "=", "copy_attn", ".", "squeeze", "(", "1", ")", "\n", "# copy_attn.shape == [batch_size, source_len]", "\n", "\n", "irrelevant_mask", "=", "context_copy_masks", "[", "full_active_idx", "]", "<", "1", "\n", "copy_attn", "[", "irrelevant_mask", "]", "=", "0", "\n", "# copy_attn.shape == [batch_size, source_len]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "\n", "copy_attn", ".", "shape", "[", "0", "]", ",", "self", ".", "vocab_size", ")", "\n", "# copy_probs.shape == [batch_size, vocab_size]", "\n", "\n", "context_ids", "=", "context", "[", "self", ".", "index", "]", "[", "full_active_idx", "]", "\n", "# context_ids.shape == [batch_size, source_len]", "\n", "\n", "# First construct the reduced dictionary, containing only tokens", "\n", "# mentioned in the context.", "\n", "unique_ids", "=", "context_ids", ".", "unique", "(", ")", "\n", "V", "=", "len", "(", "unique_ids", ")", "\n", "# unique_ids.shape == [reduced_vocab_size]", "\n", "\n", "# Construct the inverse map of unique_ids", "\n", "inverse_unique_ids", "=", "unique_ids", ".", "new_full", "(", "[", "self", ".", "vocab_size", "]", ",", "-", "1", ")", "\n", "inverse_unique_ids", ".", "index_copy_", "(", "\n", "0", ",", "unique_ids", ",", "torch", ".", "arange", "(", "V", ")", ".", "to", "(", "unique_ids", ".", "device", ")", ")", "\n", "# inverse_unique_ids.shape == [vocab_size]", "\n", "# e.g. [-1, -1, 0, -1, -1, 1, 2, -1, 3, ....]", "\n", "\n", "# Next we need to remap the context_ids to the new dictionary.", "\n", "new_context_ids", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "context_ids", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_context_ids.shape == [batch_size * source_len]", "\n", "\n", "B_i", ",", "S", "=", "copy_attn", ".", "shape", "\n", "new_context_ids", "=", "new_context_ids", ".", "view", "(", "B_i", ",", "S", ")", "\n", "# new_context_ids.shape == [batch_size, source_len]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B_i", ",", "V", ")", "\n", "# copy_probs.shape == [batch_size, reduced_vocab_size]", "\n", "\n", "copy_probs", ".", "scatter_add_", "(", "1", ",", "new_context_ids", ",", "copy_attn", ")", "\n", "\n", "topk_copy_probs", ",", "topk_copy_indices", "=", "copy_probs", ".", "topk", "(", "\n", "self", ".", "sampling_topk", ")", "\n", "# topk_copy_probs.shape == [batch_size, topk]", "\n", "\n", "# If the top probability is 0, then we simply don't copy", "\n", "empty_copy", "=", "topk_copy_probs", "<", "1e-6", "\n", "# Add small epsilon", "\n", "topk_copy_probs", "[", "empty_copy", "]", "=", "1e-6", "\n", "should_copy", "=", "should_copy", "&", "(", "~", "empty_copy", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ")", "\n", "\n", "sampled_copy_index", "=", "torch", ".", "multinomial", "(", "\n", "topk_copy_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_copy_index.shape == [batch_size, 1]", "\n", "\n", "selected_copy_prob", "=", "topk_copy_probs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_copy_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_copy_new_index", "=", "topk_copy_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_copy_index", ")", "\n", "# selected_copy_new_index.shape == [batch_size, 1]", "\n", "\n", "# Convert back to old vocab space", "\n", "selected_copy_index", "=", "unique_ids", ".", "gather", "(", "\n", "dim", "=", "0", ",", "index", "=", "selected_copy_new_index", ".", "squeeze", "(", "1", ")", ")", "\n", "# selected_copy_index.shape == [batch_size]", "\n", "\n", "selected_copy_index", "=", "selected_copy_index", ".", "unsqueeze", "(", "1", ")", "\n", "# selected_copy_index.shape == [batch_size, 1]", "\n", "\n", "selection", "=", "selected_copy_index", ".", "expand_as", "(", "\n", "copied_indices_full", "[", "full_active_idx", "]", ")", "\n", "# selected_copy_index.shape == [batch_size_i, 1]", "\n", "\n", "has_copied", "=", "(", "\n", "selection", "==", "copied_indices_full", "[", "full_active_idx", "]", ")", ".", "any", "(", "dim", "=", "1", ")", "\n", "# has_copied.shape == [batch_size_i]", "\n", "\n", "should_copy", "=", "should_copy", "&", "(", "~", "has_copied", ")", "\n", "# should_copy.shape == [batch_size_i]", "\n", "\n", "copied_indices", "=", "selected_copy_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "-", "1", ")", "\n", "copied_indices", "[", "full_active_idx", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "[", "should_copy", "]", "]", "=", "selected_copy_index", "[", "should_copy", "]", "\n", "copied_indices_full", "=", "torch", ".", "cat", "(", "\n", "[", "copied_indices_full", ",", "copied_indices", "]", ",", "dim", "=", "1", ")", "\n", "\n", "copy_prob", "=", "selected_copy_prob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "copy_prob", "[", "full_active_idx", "]", "=", "selected_copy_prob", "\n", "\n", "copy_prob_list", ".", "append", "(", "copy_prob", ")", "\n", "\n", "should_copy_full", "=", "should_copy", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "should_copy_full", "[", "full_active_idx", "]", "=", "should_copy", ".", "unsqueeze", "(", "1", ")", "\n", "should_copy_list", ".", "append", "(", "should_copy_full", ")", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_gen_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_gen_index.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "selected_gen_index", ".", "new_zeros", "(", "\n", "selected_gen_index", ".", "shape", ")", "\n", "selected_index", "[", "should_copy", "]", "=", "selected_copy_index", "[", "should_copy", "]", "\n", "selected_index", "[", "~", "should_copy", "]", "=", "selected_gen_index", "[", "~", "should_copy", "]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "Xs", "=", "[", "x", "[", "active_idx", "]", "for", "x", "in", "Xs", "]", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "copy_probs", "=", "torch", ".", "cat", "(", "copy_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "\n", "should_copy_probs", "=", "torch", ".", "cat", "(", "should_copy_list", ",", "dim", "=", "-", "1", ")", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "copy_probs", ",", "should_copy_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.decode": [[697, 704], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer.TransformerPointerModel.get_metrics": [[705, 723], ["transformer_pointer.TransformerPointerModel.sample_history.items", "transformer_pointer.TransformerPointerModel.batch_history.items", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "for", "key", ",", "value", "in", "self", ".", "batch_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_batches", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "batch_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel.__init__": [[24, 66], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "initializer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel.forward": [[67, 141], ["transformer_faces_objects.TransformerFacesObjectModel._forward", "transformer_faces_objects.TransformerFacesObjectModel.decoder", "transformer_faces_objects.TransformerFacesObjectModel.criterion", "math.log", "transformer_faces_objects.TransformerFacesObjectModel._generate", "gen_ids.cpu().detach().numpy", "zip", "transformer_faces_objects.TransformerFacesObjectModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "zip", "gen_ids.cpu", "gen_ids.cpu().detach", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "print", "print", "print", "gen_ids.cpu"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ":", "torch", ".", "Tensor", ",", "\n", "obj_embeds", ":", "torch", ".", "Tensor", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "names", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "attn_idx", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "target_ids", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ",", "obj_embeds", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "loss", "=", "loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", "/", "sample_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "_", ",", "gen_ids", ",", "attns", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ",", "attn_idx", ")", "\n", "# We ignore <s> and <pad>", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "output_dict", "[", "'attns'", "]", "=", "attns", "\n", "output_dict", "[", "'gen_ids'", "]", "=", "gen_ids", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Remove punctuation", "\n", "gen_texts", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts", ",", "captions", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "if", "'rare_tokens'", "in", "caption", ":", "\n", "                ", "for", "gen", ",", "ref", ",", "rare_list", "in", "zip", "(", "gen_texts", ",", "captions", ",", "caption", "[", "'rare_tokens'", "]", ")", ":", "\n", "                    ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rare_words", "=", "' '", ".", "join", "(", "rare_list", ")", "\n", "gen", "=", "gen", "+", "' '", "+", "rare_words", "\n", "\n", "if", "rare_words", ":", "\n", "                        ", "print", "(", "ref", ")", "\n", "print", "(", "gen", ")", "\n", "print", "(", ")", "\n", "\n", "", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1r'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "\n", "", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel.generate": [[142, 310], ["transformer_faces_objects.TransformerFacesObjectModel._forward", "transformer_faces_objects.TransformerFacesObjectModel._generate", "gen_ids.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy().tolist", "enumerate", "context[].new_zeros", "article_ids.cpu().numpy.cpu().numpy.cpu().numpy", "enumerate", "bytearray().decode", "merged_article.append", "enumerate", "range", "bytearray().decode", "attn_dicts.append", "attns_list.append", "gen_ids.cpu().numpy().tolist.cpu().numpy().tolist.cpu().numpy", "transformer_faces_objects.TransformerFacesObjectModel.roberta.task.source_dictionary.bos", "transformer_faces_objects.TransformerFacesObjectModel.roberta.task.source_dictionary.eos", "int", "transformer_faces_objects.TransformerFacesObjectModel.roberta.bpe.bpe.decoder.get", "transformer_faces_objects.TransformerFacesObjectModel.roberta.task.source_dictionary.bos", "len", "len", "transformer_faces_objects.TransformerFacesObjectModel.roberta.task.source_dictionary.eos", "int", "transformer_faces_objects.TransformerFacesObjectModel.roberta.bpe.bpe.decoder.get", "copy.deepcopy", "len", "article_ids.cpu().numpy.cpu().numpy.cpu", "article_mask.append", "a[].append", "article_mask.append", "bytearray", "range", "a[].append", "range", "len", "[].tolist", "len", "[].tolist", "bytearray", "gen_ids.cpu().numpy().tolist.cpu().numpy().tolist.cpu", "bytearray().decode", "merged_article.append", "len", "len", "layer_attns.append", "range", "bytearray().decode", "attn_dicts.append", "len", "enumerate", "[].mean", "len", "bytearray", "len", "[].tolist", "len", "[].tolist", "bytearray", "range", "range", "range", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "face_embeds", ",", "\n", "obj_embeds", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "List", "[", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "]", ":", "\n", "\n", "        ", "B", "=", "image", ".", "shape", "[", "0", "]", "\n", "caption", "=", "{", "self", ".", "index", ":", "context", "[", "self", ".", "index", "]", ".", "new_zeros", "(", "B", ",", "2", ")", "}", "\n", "caption_ids", ",", "_", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ",", "obj_embeds", ")", "\n", "\n", "_", ",", "gen_ids", ",", "attns", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "attns_list", ":", "List", "[", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "]", "=", "[", "]", "\n", "\n", "for", "i", ",", "token_ids", "in", "enumerate", "(", "gen_ids", ")", ":", "\n", "# Let's process the article text", "\n", "            ", "article_ids", "=", "context", "[", "self", ".", "index", "]", "[", "i", "]", "\n", "article_ids", "=", "article_ids", "[", "article_ids", "!=", "self", ".", "padding_idx", "]", "\n", "article_ids", "=", "article_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# article_ids.shape == [seq_len]", "\n", "\n", "# remove <s>", "\n", "if", "article_ids", "[", "0", "]", "==", "self", ".", "roberta", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", ":", "\n", "                ", "article_ids", "=", "article_ids", "[", "1", ":", "]", "\n", "\n", "# Ignore final </s> token", "\n", "", "if", "article_ids", "[", "-", "1", "]", "==", "self", ".", "roberta", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", ":", "\n", "                ", "article_ids", "=", "article_ids", "[", ":", "-", "1", "]", "\n", "\n", "# Sanity check. We plus three because we removed <s>, </s> and", "\n", "# the last two attention scores are for no attention and bias", "\n", "", "assert", "article_ids", ".", "shape", "[", "0", "]", "==", "attns", "[", "0", "]", "[", "0", "]", "[", "'article'", "]", "[", "i", "]", "[", "0", "]", ".", "shape", "[", "0", "]", "-", "4", "\n", "\n", "byte_ids", "=", "[", "int", "(", "self", ".", "roberta", ".", "task", ".", "source_dictionary", "[", "k", "]", ")", "\n", "for", "k", "in", "article_ids", "]", "\n", "# e.g. [16012, 17163, 447, 247, 82, 4640, 3437]", "\n", "\n", "byte_strs", "=", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "decoder", ".", "get", "(", "token", ",", "token", ")", "\n", "for", "token", "in", "byte_ids", "]", "\n", "# e.g. ['Sun', 'rise', '\u00e2\u0122', '\u013b', 's', '\u0120executive', '\u0120director']", "\n", "\n", "merged_article", "=", "[", "]", "\n", "article_mask", "=", "[", "]", "\n", "cursor", "=", "0", "\n", "a", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "newline", "=", "False", "\n", "for", "j", ",", "b", "in", "enumerate", "(", "byte_strs", ")", ":", "\n", "# Start a new word", "\n", "                ", "if", "j", "==", "0", "or", "b", "[", "0", "]", "==", "'\u0120'", "or", "b", "[", "0", "]", "==", "'\u010a'", "or", "newline", ":", "\n", "                    ", "if", "a", ":", "\n", "                        ", "byte_text", "=", "''", ".", "join", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'text'", "]", "=", "bytearray", "(", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "byte_text", "]", ")", ".", "decode", "(", "\n", "'utf-8'", ",", "errors", "=", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "errors", ")", "\n", "merged_article", ".", "append", "(", "a", ")", "\n", "cursor", "+=", "1", "\n", "# Note that", "\n", "#   len(attns) == generation_length", "\n", "#   len(attns[j]) == n_layers", "\n", "#   attns[j][l] is a dictionary", "\n", "#   attns[j][l]['article'].shape == [batch_size, target_len, source_len]", "\n", "#   target_len == 1 since we generate one word at a time", "\n", "", "a", "=", "{", "'tokens'", ":", "[", "b", "]", "}", "\n", "article_mask", ".", "append", "(", "cursor", ")", "\n", "newline", "=", "b", "[", "0", "]", "==", "'\u010a'", "\n", "", "else", ":", "\n", "                    ", "a", "[", "'tokens'", "]", ".", "append", "(", "b", ")", "\n", "article_mask", ".", "append", "(", "cursor", ")", "\n", "", "", "byte_text", "=", "''", ".", "join", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'text'", "]", "=", "bytearray", "(", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "byte_text", "]", ")", ".", "decode", "(", "\n", "'utf-8'", ",", "errors", "=", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "errors", ")", "\n", "merged_article", ".", "append", "(", "a", ")", "\n", "\n", "# Next let's process the caption text", "\n", "attn_dicts", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "[", "]", "\n", "# Ignore seed input <s>", "\n", "if", "token_ids", "[", "0", "]", "==", "self", ".", "roberta", ".", "task", ".", "source_dictionary", ".", "bos", "(", ")", ":", "\n", "                ", "token_ids", "=", "token_ids", "[", "1", ":", "]", "# remove <s>", "\n", "# Now len(token_ids) should be the same of len(attns)", "\n", "\n", "", "assert", "len", "(", "attns", ")", "==", "len", "(", "token_ids", ")", "\n", "\n", "# Ignore final </s> token", "\n", "if", "token_ids", "[", "-", "1", "]", "==", "self", ".", "roberta", ".", "task", ".", "source_dictionary", ".", "eos", "(", ")", ":", "\n", "                ", "token_ids", "=", "token_ids", "[", ":", "-", "1", "]", "\n", "# Now len(token_ids) should be len(attns) - 1", "\n", "\n", "", "byte_ids", "=", "[", "int", "(", "self", ".", "roberta", ".", "task", ".", "source_dictionary", "[", "k", "]", ")", "\n", "for", "k", "in", "token_ids", "]", "\n", "# e.g. [16012, 17163, 447, 247, 82, 4640, 3437]", "\n", "\n", "byte_strs", "=", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "decoder", ".", "get", "(", "token", ",", "token", ")", "\n", "for", "token", "in", "byte_ids", "]", "\n", "# e.g. ['Sun', 'rise', '\u00e2\u0122', '\u013b', 's', '\u0120executive', '\u0120director']", "\n", "\n", "# Merge by space", "\n", "a", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "for", "j", ",", "b", "in", "enumerate", "(", "byte_strs", ")", ":", "\n", "# Clean up article attention", "\n", "                ", "article_attns", "=", "copy", ".", "deepcopy", "(", "merged_article", ")", "\n", "start", "=", "0", "\n", "for", "word", "in", "article_attns", ":", "\n", "                    ", "end", "=", "start", "+", "len", "(", "word", "[", "'tokens'", "]", ")", "\n", "layer_attns", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "len", "(", "attns", "[", "j", "]", ")", ")", ":", "\n", "                        ", "layer_attns", ".", "append", "(", "\n", "attns", "[", "j", "]", "[", "layer", "]", "[", "'article'", "]", "[", "i", "]", "[", "0", "]", "[", "start", ":", "end", "]", ".", "mean", "(", ")", ")", "\n", "", "word", "[", "'attns'", "]", "=", "layer_attns", "\n", "start", "=", "end", "\n", "del", "word", "[", "'tokens'", "]", "\n", "\n", "# Start a new word. \u0120 is space", "\n", "", "if", "j", "==", "0", "or", "b", "[", "0", "]", "==", "'\u0120'", ":", "\n", "                    ", "if", "a", ":", "\n", "                        ", "for", "l", "in", "range", "(", "len", "(", "a", "[", "'attns'", "]", "[", "'image'", "]", ")", ")", ":", "\n", "                            ", "for", "modal", "in", "[", "'image'", ",", "'faces'", ",", "'obj'", "]", ":", "\n", "                                ", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", "/=", "len", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", "=", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", ".", "tolist", "(", ")", "\n", "", "for", "word", "in", "a", "[", "'attns'", "]", "[", "'article'", "]", ":", "\n", "                                ", "word", "[", "'attns'", "]", "[", "l", "]", "/=", "len", "(", "a", "[", "'tokens'", "]", ")", "\n", "word", "[", "'attns'", "]", "[", "l", "]", "=", "word", "[", "'attns'", "]", "[", "l", "]", ".", "tolist", "(", ")", "\n", "", "", "byte_text", "=", "''", ".", "join", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'tokens'", "]", "=", "bytearray", "(", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "byte_text", "]", ")", ".", "decode", "(", "\n", "'utf-8'", ",", "errors", "=", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "errors", ")", "\n", "attn_dicts", ".", "append", "(", "a", ")", "\n", "# Note that", "\n", "#   len(attns) == generation_length", "\n", "#   len(attns[j]) == n_layers", "\n", "#   attns[j][l] is a dictionary", "\n", "#   attns[j][l]['article'].shape == [batch_size, target_len, source_len]", "\n", "#   target_len == 1 since we generate one word at a time", "\n", "", "a", "=", "{", "\n", "'tokens'", ":", "[", "b", "]", ",", "\n", "'attns'", ":", "{", "\n", "'article'", ":", "article_attns", ",", "\n", "'image'", ":", "[", "attns", "[", "j", "]", "[", "l", "]", "[", "'image'", "]", "[", "i", "]", "[", "0", "]", "for", "l", "in", "range", "(", "len", "(", "attns", "[", "j", "]", ")", ")", "]", ",", "\n", "'faces'", ":", "[", "attns", "[", "j", "]", "[", "l", "]", "[", "'faces'", "]", "[", "i", "]", "[", "0", "]", "for", "l", "in", "range", "(", "len", "(", "attns", "[", "j", "]", ")", ")", "]", ",", "\n", "'obj'", ":", "[", "attns", "[", "j", "]", "[", "l", "]", "[", "'obj'", "]", "[", "i", "]", "[", "0", "]", "for", "l", "in", "range", "(", "len", "(", "attns", "[", "j", "]", ")", ")", "]", ",", "\n", "}", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "a", "[", "'tokens'", "]", ".", "append", "(", "b", ")", "\n", "for", "l", "in", "range", "(", "len", "(", "a", "[", "'attns'", "]", "[", "'image'", "]", ")", ")", ":", "\n", "                        ", "for", "modal", "in", "[", "'image'", ",", "'faces'", ",", "'obj'", "]", ":", "\n", "                            ", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", "+=", "attns", "[", "j", "]", "[", "l", "]", "[", "modal", "]", "[", "i", "]", "[", "0", "]", "\n", "", "for", "w", ",", "word", "in", "enumerate", "(", "a", "[", "'attns'", "]", "[", "'article'", "]", ")", ":", "\n", "                            ", "word", "[", "'attns'", "]", "[", "l", "]", "+=", "article_attns", "[", "w", "]", "[", "'attns'", "]", "[", "l", "]", "\n", "\n", "", "", "", "", "for", "l", "in", "range", "(", "len", "(", "a", "[", "'attns'", "]", "[", "'image'", "]", ")", ")", ":", "\n", "                ", "for", "modal", "in", "[", "'image'", ",", "'faces'", ",", "'obj'", "]", ":", "\n", "                    ", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", "/=", "len", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", "=", "a", "[", "'attns'", "]", "[", "modal", "]", "[", "l", "]", ".", "tolist", "(", ")", "\n", "", "for", "word", "in", "a", "[", "'attns'", "]", "[", "'article'", "]", ":", "\n", "                    ", "word", "[", "'attns'", "]", "[", "l", "]", "/=", "len", "(", "a", "[", "'tokens'", "]", ")", "\n", "word", "[", "'attns'", "]", "[", "l", "]", "=", "word", "[", "'attns'", "]", "[", "l", "]", ".", "tolist", "(", ")", "\n", "", "", "byte_text", "=", "''", ".", "join", "(", "a", "[", "'tokens'", "]", ")", "\n", "a", "[", "'tokens'", "]", "=", "bytearray", "(", "[", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "byte_text", "]", ")", ".", "decode", "(", "\n", "'utf-8'", ",", "errors", "=", "self", ".", "roberta", ".", "bpe", ".", "bpe", ".", "errors", ")", "\n", "attn_dicts", ".", "append", "(", "a", ")", "\n", "\n", "attns_list", ".", "append", "(", "attn_dicts", ")", "\n", "\n", "# gen_texts = [self.roberta.decode(", "\n", "#     x[x != self.padding_idx]) for x in gen_ids]", "\n", "\n", "", "return", "attns_list", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel._forward": [[311, 398], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer_faces_objects.TransformerFacesObjectModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_faces_objects.TransformerFacesObjectModel.roberta.extract_features", "X_image.view.view.new_zeros().bool", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "X_image.view.view.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "face_embeds.transpose", "obj_embeds.transpose", "X_image.view.view.new_zeros", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ",", "\n", "obj_embeds", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "article_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "article_padding_mask", "=", "article_ids", "==", "self", ".", "padding_idx", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "B", ",", "S", "=", "article_ids", ".", "shape", "\n", "\n", "X_sections_hiddens", "=", "self", ".", "roberta", ".", "extract_features", "(", "\n", "article_ids", ",", "return_all_hiddens", "=", "True", ")", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# face_embeds.shape == [batch_size, n_faces, 512]", "\n", "face_masks", "=", "torch", ".", "isnan", "(", "face_embeds", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "face_embeds", "[", "face_masks", "]", "=", "0", "\n", "\n", "# obj_embeds.shape == [batch_size, n_objects, 1024]", "\n", "obj_masks", "=", "torch", ".", "isnan", "(", "obj_embeds", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "obj_embeds", "[", "obj_masks", "]", "=", "0", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "'faces'", ":", "face_embeds", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'faces_mask'", ":", "face_masks", ",", "\n", "'obj'", ":", "obj_embeds", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'obj_mask'", ":", "obj_masks", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel._generate": [[399, 495], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_faces_objects.TransformerFacesObjectModel.decoder.filter_incremental_state", "transformer_faces_objects.TransformerFacesObjectModel.decoder", "attns.append", "transformer_faces_objects.TransformerFacesObjectModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ",", "attn_idx", "=", "None", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "attns", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'faces'", ":", "contexts", "[", "'faces'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'faces_mask'", ":", "contexts", "[", "'faces_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'obj'", ":", "contexts", "[", "'obj'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'obj_mask'", ":", "contexts", "[", "'obj_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "attns", ".", "append", "(", "decoder_out", "[", "1", "]", "[", "'attn'", "]", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel.decode": [[496, 503], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces_objects.TransformerFacesObjectModel.get_metrics": [[504, 518], ["transformer_faces_objects.TransformerFacesObjectModel.sample_history.items", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.__init__": [[24, 95], ["decoder_base.Decoder.__init__", "embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "decoder_flattened.DynamicConvDecoder.layers.extend", "decoder_flattened.DynamicConvDecoder.register_buffer", "vocab.get_vocab_size", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "isinstance", "tell.modules.AdaptiveSoftmax", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "decoder_flattened.DynamicConvDecoderLayer", "hasattr", "tell.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "embedder", ":", "TextFieldEmbedder", ",", "max_target_positions", ",", "dropout", ",", "\n", "share_decoder_input_output_embed", ",", "\n", "decoder_output_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "decoder_kernel_size_list", ",", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "tie_adaptive_weights", "=", "False", ",", "adaptive_softmax_dropout", "=", "0", ",", "\n", "tie_adaptive_proj", "=", "False", ",", "adaptive_softmax_factor", "=", "0", ",", "decoder_layers", "=", "6", ",", "\n", "final_norm", "=", "True", ",", "padding_idx", "=", "0", ",", "namespace", "=", "'target_tokens'", ",", "\n", "vocab_size", "=", "None", ",", "section_attn", "=", "False", ",", "article_embed_size", "=", "1024", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embedder", ".", "get_output_dim", "(", ")", "\n", "embed_dim", "=", "input_embed_dim", "\n", "output_embed_dim", "=", "input_embed_dim", "\n", "\n", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "max_target_positions", "\n", "\n", "self", ".", "embedder", "=", "embedder", "\n", "\n", "self", ".", "project_in_dim", "=", "GehringLinear", "(", "\n", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "input_embed_dim", "else", "None", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "DynamicConvDecoderLayer", "(", "embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "article_embed_size", ",", "\n", "kernel_size", "=", "decoder_kernel_size_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "decoder_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "GehringLinear", "(", "embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "output_embed_dim", "and", "not", "tie_adaptive_weights", "else", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "adaptive_inputs", "=", "None", "\n", "if", "isinstance", "(", "embedder", ",", "AdaptiveEmbedding", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", "\n", "", "elif", "hasattr", "(", "embedder", ",", "'token_embedder_adaptive'", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", ".", "token_embedder_adaptive", "\n", "", "elif", "tie_adaptive_weights", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot locate adaptive_inputs.'", ")", "\n", "", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "vocab_size", ",", "\n", "output_embed_dim", ",", "\n", "eval_str_list", "(", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "adaptive_inputs", ",", "\n", "factor", "=", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "vocab_size", ",", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "\n", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "decoder_normalize_before", "and", "final_norm", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.forward": [[96, 144], ["decoder_flattened.DynamicConvDecoder.embedder", "torch.dropout", "torch.dropout", "torch.dropout", "torch.linear.transpose", "enumerate", "torch.linear.transpose", "decoder_flattened.DynamicConvDecoder.project_in_dim", "decoder_flattened.DynamicConvDecoder.layer_norm", "decoder_flattened.DynamicConvDecoder.project_out_dim", "layer", "inner_states.append", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "prev_target", ",", "contexts", ",", "incremental_state", "=", "None", ",", "\n", "use_layers", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# embed tokens and positions", "\n", "        ", "X", "=", "self", ".", "embedder", "(", "prev_target", ",", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# if incremental_state is not None:", "\n", "#     X = X[:, -1:]", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_in_dim", "(", "X", ")", "\n", "\n", "", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attn", "=", "None", "\n", "\n", "inner_states", "=", "[", "X", "]", "\n", "\n", "# decoder layers", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "not", "use_layers", "or", "i", "in", "use_layers", ":", "\n", "                ", "X", ",", "attn", "=", "layer", "(", "\n", "X", ",", "\n", "contexts", ",", "\n", "incremental_state", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "X", ")", "\n", "\n", "", "", "if", "self", ".", "normalize", ":", "\n", "            ", "X", "=", "self", ".", "layer_norm", "(", "X", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_out_dim", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "\n", "X", ",", "self", ".", "embedder", ".", "token_embedder_bert", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "X", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "X", ",", "{", "'attn'", ":", "attn", ",", "'inner_states'", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.max_positions": [[145, 148], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "max_target_positions", "\n", "# return min(self.max_target_positions, self.embedder.max_positions())", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.buffered_future_mask": [[150, 160], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "decoder_flattened.DynamicConvDecoder._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "tell.utils.fill_with_neg_inf", "tell.utils.fill_with_neg_inf", "tensor.new", "decoder_flattened.DynamicConvDecoder._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# pylint: disable=access-member-before-definition", "\n", "if", "not", "hasattr", "(", "self", ",", "'_future_mask'", ")", "or", "self", ".", "_future_mask", "is", "None", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "\n", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.get_normalized_probs": [[161, 175], ["net_output[].float", "hasattr", "decoder_flattened.DynamicConvDecoder.adaptive_softmax.get_log_prob", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "decoder_flattened.DynamicConvDecoder.exp"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "'adaptive_softmax'", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "target", "=", "sample", "[", "'target'", "]", "if", "sample", "else", "None", "\n", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "\n", "net_output", "[", "0", "]", ",", "target", ")", "\n", "return", "out", ".", "exp", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoder.filter_incremental_state": [[176, 182], ["None"], "methods", ["None"], ["", "", "def", "filter_incremental_state", "(", "self", ",", "incremental_state", ",", "active_idx", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", ":", "\n", "            ", "return", "\n", "", "for", "key", "in", "incremental_state", ":", "\n", "            ", "if", "'DynamicConv1dTBC'", "in", "key", ":", "\n", "                ", "incremental_state", "[", "key", "]", "=", "incremental_state", "[", "key", "]", "[", ":", ",", "active_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoderLayer.__init__": [[186, 244], ["decoder_base.DecoderLayer.__init__", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "torch.GLU", "torch.GLU", "torch.GLU", "tell.modules.GehringLinear", "tell.modules.LightweightConv1dTBC", "tell.modules.DynamicConv1dTBC"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "article_embed_size", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "decoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "decoder_conv_dim", "\n", "if", "decoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "decoder_conv_type", "==", "'lightweight'", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "elif", "decoder_conv_type", "==", "'dynamic'", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "GehringLinear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "input_dropout", "=", "input_dropout", "\n", "self", ".", "normalize_before", "=", "decoder_normalize_before", "\n", "\n", "self", ".", "conv_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "context_attn_lns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "C", "=", "2048", "\n", "\n", "self", ".", "context_attns", "[", "'image'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "C", ",", "vdim", "=", "C", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'article'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "article_embed_size", ",", "vdim", "=", "article_embed_size", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "context_size", "=", "self", ".", "embed_dim", "*", "2", "\n", "\n", "self", ".", "context_fc", "=", "GehringLinear", "(", "context_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "fc1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "GehringLinear", "(", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoderLayer.forward": [[245, 320], ["decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.linear1", "decoder_flattened.DynamicConvDecoderLayer.conv", "decoder_flattened.DynamicConvDecoderLayer.linear2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_flattened.DynamicConvDecoderLayer.context_fc", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_flattened.DynamicConvDecoderLayer.act", "decoder_flattened.DynamicConvDecoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "X", ",", "contexts", ",", "incremental_state", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            X (Tensor): input to the layer of shape `(seq_len, batch, embed_dim)`\n            encoder_padding_mask (ByteTensor): binary ByteTensor of shape\n                `(batch, src_len)` where padding elements are indicated by ``1``.\n\n        Returns:\n            encoded output of shape `(batch, src_len, embed_dim)`\n        \"\"\"", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "input_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "linear1", "(", "X", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "act", "(", "X", ")", "\n", "", "X", "=", "self", ".", "conv", "(", "X", ",", "incremental_state", "=", "incremental_state", ")", "\n", "X", "=", "self", ".", "linear2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "\n", "attn", "=", "None", "\n", "X_contexts", "=", "[", "]", "\n", "\n", "# Image attention", "\n", "residual", "=", "X", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_image", ",", "attn", "=", "self", ".", "context_attns", "[", "'image'", "]", "(", "\n", "query", "=", "X_image", ",", "\n", "key", "=", "contexts", "[", "'image'", "]", ",", "\n", "value", "=", "contexts", "[", "'image'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'image_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_image", "=", "F", ".", "dropout", "(", "X_image", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X_image", "=", "residual", "+", "X_image", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X_image", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_image", ")", "\n", "\n", "# Article attention", "\n", "residual", "=", "X", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_article", ",", "attn", "=", "self", ".", "context_attns", "[", "'article'", "]", "(", "\n", "query", "=", "X_article", ",", "\n", "key", "=", "contexts", "[", "'article'", "]", ",", "\n", "value", "=", "contexts", "[", "'article'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'article_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_article", "=", "F", ".", "dropout", "(", "X_article", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_article", "=", "residual", "+", "X_article", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X_article", ",", "after", "=", "True", ")", "\n", "\n", "X_contexts", ".", "append", "(", "X_article", ")", "\n", "\n", "X_context", "=", "torch", ".", "cat", "(", "X_contexts", ",", "dim", "=", "-", "1", ")", "\n", "X", "=", "self", ".", "context_fc", "(", "X_context", ")", "\n", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "X", ")", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "fc2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "return", "X", ",", "attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoderLayer.maybe_layer_norm": [[321, 327], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "X", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "X", ")", "\n", "", "else", ":", "\n", "            ", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoderLayer.make_generation_fast_": [[328, 330], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened.DynamicConvDecoderLayer.extra_repr": [[331, 334], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}'", ".", "format", "(", "\n", "self", ".", "dropout", ",", "self", ".", "relu_dropout", ",", "self", ".", "input_dropout", ",", "self", ".", "normalize_before", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.AttentionLayer.__init__": [[30, 37], ["torch.Module.__init__", "tell.modules.GehringLinear", "tell.modules.GehringLinear"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_embed_dim", ",", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_proj", "=", "GehringLinear", "(", "\n", "input_embed_dim", ",", "source_embed_dim", ",", "bias", "=", "bias", ")", "\n", "self", ".", "output_proj", "=", "GehringLinear", "(", "\n", "input_embed_dim", "+", "source_embed_dim", ",", "output_embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.AttentionLayer.forward": [[38, 66], ["decoder_flattened_lstm.AttentionLayer.input_proj", "encoder_padding_mask.transpose.transpose.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_().type_as", "decoder_flattened_lstm.AttentionLayer.output_proj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "torch.tanh.unsqueeze", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float().masked_fill_", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.unsqueeze", "float", "attn_scores.float().masked_fill_().type_as.float().masked_fill_().type_as.float"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "forward", "(", "self", ",", "input", ",", "source_hids", ",", "encoder_padding_mask", ")", ":", "\n", "# input: bsz x input_embed_dim", "\n", "# source_hids: srclen x bsz x output_embed_dim", "\n", "\n", "# x: bsz x output_embed_dim", "\n", "        ", "x", "=", "self", ".", "input_proj", "(", "input", ")", "\n", "\n", "# compute attention", "\n", "attn_scores", "=", "(", "source_hids", "*", "x", ".", "unsqueeze", "(", "0", ")", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# attn_scores.shape == [src_len, bsz]", "\n", "\n", "encoder_padding_mask", "=", "encoder_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# encoder_padding_mask.shape == [src_len, bsz]", "\n", "\n", "# don't attend over padding", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "attn_scores", "=", "attn_scores", ".", "float", "(", ")", ".", "masked_fill_", "(", "\n", "encoder_padding_mask", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", ".", "type_as", "(", "attn_scores", ")", "# FP16 support: cast to float and back", "\n", "\n", "", "attn_scores", "=", "F", ".", "softmax", "(", "attn_scores", ",", "dim", "=", "0", ")", "# srclen x bsz", "\n", "\n", "# sum weighted sources", "\n", "x", "=", "(", "attn_scores", ".", "unsqueeze", "(", "2", ")", "*", "source_hids", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "x", "=", "torch", ".", "tanh", "(", "self", ".", "output_proj", "(", "torch", ".", "cat", "(", "(", "x", ",", "input", ")", ",", "dim", "=", "1", ")", ")", ")", "\n", "return", "x", ",", "attn_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMDecoder.__init__": [[71, 136], ["decoder_base.Decoder.__init__", "embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "range", "decoder_flattened_lstm.AttentionLayer", "decoder_flattened_lstm.AttentionLayer", "tell.modules.GehringLinear", "vocab.get_vocab_size", "decoder_flattened_lstm.LSTMCell", "decoder_flattened_lstm.LSTMDecoder.layers.append", "decoder_flattened_lstm.LSTMDecoder.h.append", "decoder_flattened_lstm.LSTMDecoder.c.append", "tell.modules.GehringLinear", "isinstance", "tell.modules.AdaptiveSoftmax", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "hasattr", "tell.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMCell", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "embedder", ":", "TextFieldEmbedder", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", ",", "share_decoder_input_output_embed", ",", "\n", "vocab_size", "=", "None", ",", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "tie_adaptive_weights", "=", "False", ",", "adaptive_softmax_dropout", "=", "0", ",", "\n", "tie_adaptive_proj", "=", "False", ",", "adaptive_softmax_factor", "=", "0", ",", "\n", "article_embed_size", "=", "1024", ",", "image_embed_size", "=", "2048", ",", "\n", "namespace", "=", "'target_tokens'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embedder", ".", "get_output_dim", "(", ")", "\n", "embed_dim", "=", "input_embed_dim", "\n", "output_embed_dim", "=", "input_embed_dim", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "h", "=", "nn", ".", "ParameterList", "(", "[", "]", ")", "\n", "self", ".", "c", "=", "nn", ".", "ParameterList", "(", "[", "]", ")", "\n", "for", "layer", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "input_size", "=", "hidden_size", "+", "embed_dim", "if", "layer", "==", "0", "else", "hidden_size", "\n", "rnn", "=", "LSTMCell", "(", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ")", "\n", "self", ".", "layers", ".", "append", "(", "rnn", ")", "\n", "self", ".", "h", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "hidden_size", ")", ")", ")", "\n", "self", ".", "c", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "hidden_size", ")", ")", ")", "\n", "\n", "", "self", ".", "image_attention", "=", "AttentionLayer", "(", "\n", "hidden_size", ",", "image_embed_size", ",", "hidden_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "article_attention", "=", "AttentionLayer", "(", "\n", "hidden_size", ",", "article_embed_size", ",", "hidden_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "attn_proj", "=", "GehringLinear", "(", "hidden_size", "*", "2", ",", "hidden_size", ")", "\n", "\n", "self", ".", "embedder", "=", "embedder", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "GehringLinear", "(", "hidden_size", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "hidden_size", "!=", "output_embed_dim", "else", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "adaptive_inputs", "=", "None", "\n", "if", "isinstance", "(", "embedder", ",", "AdaptiveEmbedding", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", "\n", "", "elif", "hasattr", "(", "embedder", ",", "'token_embedder_adaptive'", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", ".", "token_embedder_adaptive", "\n", "", "elif", "tie_adaptive_weights", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot locate adaptive_inputs.'", ")", "\n", "", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "vocab_size", ",", "\n", "output_embed_dim", ",", "\n", "eval_str_list", "(", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "adaptive_inputs", ",", "\n", "factor", "=", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "vocab_size", ",", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "\n", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMDecoder.forward": [[137, 209], ["decoder_flattened_lstm.LSTMDecoder.embedder", "torch.dropout", "torch.dropout", "torch.dropout", "torch.linear.transpose", "len", "torch.linear.new_zeros", "torch.linear.new_zeros", "torch.linear.new_zeros", "range", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.linear.transpose", "decoder_flattened_lstm.LSTMDecoder.h[].expand", "decoder_flattened_lstm.LSTMDecoder.c[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "decoder_flattened_lstm.LSTMDecoder.image_attention", "decoder_flattened_lstm.LSTMDecoder.article_attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_flattened_lstm.LSTMDecoder.attn_proj", "outs.append", "decoder_flattened_lstm.LSTMDecoder.project_out_dim", "range", "range", "rnn", "torch.dropout", "torch.dropout", "torch.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "prev_target", ",", "contexts", ",", "incremental_state", "=", "None", ",", "\n", "use_layers", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "X", "=", "self", ".", "embedder", "(", "prev_target", ",", "incremental_state", "=", "incremental_state", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "T", ",", "B", ",", "_", "=", "X", ".", "shape", "\n", "C", "=", "contexts", "[", "'image'", "]", ".", "shape", "[", "0", "]", "\n", "S", "=", "contexts", "[", "'article'", "]", ".", "shape", "[", "0", "]", "\n", "n_layers", "=", "len", "(", "self", ".", "layers", ")", "\n", "\n", "prev_hiddens", "=", "[", "self", ".", "h", "[", "i", "]", ".", "expand", "(", "B", ",", "-", "1", ")", "for", "i", "in", "range", "(", "n_layers", ")", "]", "\n", "prev_cells", "=", "[", "self", ".", "c", "[", "i", "]", ".", "expand", "(", "B", ",", "-", "1", ")", "for", "i", "in", "range", "(", "n_layers", ")", "]", "\n", "input_feed", "=", "X", ".", "new_zeros", "(", "B", ",", "self", ".", "hidden_size", ")", "\n", "image_attn_scores", "=", "X", ".", "new_zeros", "(", "C", ",", "T", ",", "B", ")", "\n", "article_attn_scores", "=", "X", ".", "new_zeros", "(", "S", ",", "T", ",", "B", ")", "\n", "outs", "=", "[", "]", "\n", "\n", "for", "step", "in", "range", "(", "T", ")", ":", "\n", "# input feeding: concatenate context vector from previous time step", "\n", "            ", "rnn_input", "=", "torch", ".", "cat", "(", "(", "X", "[", "step", ",", ":", ",", ":", "]", ",", "input_feed", ")", ",", "dim", "=", "1", ")", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# recurrent cell", "\n", "                ", "hidden", ",", "cell", "=", "rnn", "(", "rnn_input", ",", "(", "prev_hiddens", "[", "i", "]", ",", "prev_cells", "[", "i", "]", ")", ")", "\n", "\n", "# hidden state becomes the input to the next layer", "\n", "rnn_input", "=", "F", ".", "dropout", "(", "hidden", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "\n", "# save state for next time step", "\n", "prev_hiddens", "[", "i", "]", "=", "hidden", "\n", "prev_cells", "[", "i", "]", "=", "cell", "\n", "\n", "# apply attention using the last layer's hidden state", "\n", "", "image_out", ",", "image_attn_scores", "[", ":", ",", "step", ",", ":", "]", "=", "self", ".", "image_attention", "(", "\n", "hidden", ",", "contexts", "[", "'image'", "]", ",", "contexts", "[", "'image_mask'", "]", ")", "\n", "\n", "article_out", ",", "article_attn_scores", "[", ":", ",", "step", ",", ":", "]", "=", "self", ".", "article_attention", "(", "\n", "hidden", ",", "contexts", "[", "'article'", "]", ",", "contexts", "[", "'article_mask'", "]", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "[", "image_out", ",", "article_out", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "# out.shape == [B, hidden_size * 2]", "\n", "\n", "out", "=", "self", ".", "attn_proj", "(", "out", ")", "\n", "# out.shape == [B, hidden_size]", "\n", "\n", "input_feed", "=", "out", "\n", "\n", "outs", ".", "append", "(", "out", ")", "\n", "\n", "# collect outputs across time steps", "\n", "", "X", "=", "torch", ".", "cat", "(", "outs", ",", "dim", "=", "0", ")", ".", "view", "(", "T", ",", "B", ",", "self", ".", "hidden_size", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "X", "=", "X", ".", "transpose", "(", "1", ",", "0", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_out_dim", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "\n", "X", ",", "self", ".", "embedder", ".", "token_embedder_bert", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "X", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "X", ",", "{", "'attn'", ":", "None", ",", "'inner_states'", ":", "None", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMDecoder.get_normalized_probs": [[210, 224], ["net_output[].float", "hasattr", "decoder_flattened_lstm.LSTMDecoder.adaptive_softmax.get_log_prob", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "decoder_flattened_lstm.LSTMDecoder.exp"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "'adaptive_softmax'", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "target", "=", "sample", "[", "'target'", "]", "if", "sample", "else", "None", "\n", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "\n", "net_output", "[", "0", "]", ",", "target", ")", "\n", "return", "out", ".", "exp", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMCell": [[21, 27], ["torch.LSTMCell", "nn.LSTMCell.named_parameters", "param.data.uniform_"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_flattened_lstm.LSTMCell"], ["def", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LSTMCell", "(", "input_size", ",", "hidden_size", ",", "**", "kwargs", ")", "\n", "for", "name", ",", "param", "in", "m", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'weight'", "in", "name", "or", "'bias'", "in", "name", ":", "\n", "            ", "param", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel.__init__": [[24, 66], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "initializer", "spacy.load", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "max_caption_len", ":", "int", "=", "50", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "max_caption_len", "=", "max_caption_len", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_lg'", ",", "\n", "disable", "=", "[", "'textcat'", ",", "'parser'", ",", "'tagger'", ",", "'ner'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel.forward": [[71, 139], ["baseline_glove.BaselineGloveModel._forward", "baseline_glove.BaselineGloveModel.decoder", "baseline_glove.BaselineGloveModel.criterion", "math.log", "baseline_glove.BaselineGloveModel._generate", "zip", "baseline_glove.BaselineGloveModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "zip", "gen_ids.cpu", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "context", "=", "[", "m", "[", "'context'", "]", "for", "m", "in", "metadata", "]", "\n", "caption_ids", ",", "target_ids", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "loss", "=", "loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", "/", "sample_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "# We ignore <s> and <pad>", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "\n", "# Remove punctuation", "\n", "gen_texts_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "if", "'rare_tokens'", "in", "caption", ":", "\n", "                ", "for", "gen", ",", "ref", ",", "rare_list", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ",", "caption", "[", "'rare_tokens'", "]", ")", ":", "\n", "                    ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rare_words", "=", "' '", ".", "join", "(", "rare_list", ")", "\n", "gen", "=", "gen", "+", "' '", "+", "rare_words", "\n", "\n", "if", "rare_words", ":", "\n", "                        ", "print", "(", "ref", ")", "\n", "print", "(", "gen", ")", "\n", "print", "(", ")", "\n", "\n", "", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1r'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "\n", "", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel.generate": [[140, 163], ["baseline_glove.BaselineGloveModel._forward", "baseline_glove.BaselineGloveModel._generate", "gen_ids.cpu.cpu.cpu", "baseline_glove.BaselineGloveModel.roberta.decode"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "_", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "\n", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generated_indices'", ":", "gen_ids", ",", "\n", "'generated_texts'", ":", "gen_texts", ",", "\n", "'captions'", ":", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", ",", "\n", "'web_url'", ":", "[", "m", "[", "'web_url'", "]", "for", "m", "in", "metadata", "]", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel._forward": [[164, 240], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "baseline_glove.BaselineGloveModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "baseline_glove.BaselineGloveModel.nlp.pipe", "max", "X_image.view.view.new_full", "enumerate", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "X_image.view.view.new_zeros().bool", "c.lower", "v_lens.append", "vs.append", "torch.from_numpy().type_as", "torch.from_numpy().type_as", "torch.from_numpy().type_as", "torch.from_numpy().type_as", "X_image.view.view.transpose", "X_article.transpose", "len", "numpy.array", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "X_image.view.view.new_zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "List", "[", "str", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# Truncate very long captions to avoid OOM errors", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "self", ".", "max_caption_len", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "self", ".", "max_caption_len", "]", "\n", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "context", "=", "[", "c", ".", "lower", "(", ")", "for", "c", "in", "context", "]", "\n", "context_docs", "=", "self", ".", "nlp", ".", "pipe", "(", "context", ")", "\n", "vs", "=", "[", "]", "\n", "v_lens", "=", "[", "]", "\n", "for", "doc", "in", "context_docs", ":", "\n", "            ", "v", "=", "[", "token", ".", "vector", "for", "token", "in", "doc", "if", "token", ".", "has_vector", "]", "\n", "v_lens", ".", "append", "(", "len", "(", "v", ")", ")", "\n", "vs", ".", "append", "(", "np", ".", "array", "(", "v", ")", ")", "\n", "", "max_len", "=", "max", "(", "v_lens", ")", "\n", "\n", "context_vector", "=", "X_image", ".", "new_full", "(", "(", "B", ",", "max_len", ",", "300", ")", ",", "np", ".", "nan", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "vs", ")", ":", "\n", "            ", "v_len", "=", "v", ".", "shape", "[", "0", "]", "\n", "v_tensor", "=", "torch", ".", "from_numpy", "(", "v", ")", ".", "type_as", "(", "context_vector", ")", "\n", "context_vector", "[", "i", ",", ":", "v_len", "]", "=", "v_tensor", "\n", "\n", "", "article_padding_mask", "=", "torch", ".", "isnan", "(", "context_vector", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "X_article", "=", "context_vector", "\n", "X_article", "[", "article_padding_mask", "]", "=", "0", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel._generate": [[241, 332], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "baseline_glove.BaselineGloveModel.decoder", "baseline_glove.BaselineGloveModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ")", ":", "\n", "# incremental_state: Dict[str, Any] = {}", "\n", "        ", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "# if i == 0:", "\n", "#     prev_target = {self.index: seed_input}", "\n", "# else:", "\n", "#     prev_target = {self.index: seed_input[:, -1:]}", "\n", "            ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "\n", "# self.decoder.filter_incremental_state(", "\n", "#     incremental_state, active_idx)", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "# incremental_state=incremental_state", "\n", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel.decode": [[333, 340], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.baseline_glove.BaselineGloveModel.get_metrics": [[341, 355], ["baseline_glove.BaselineGloveModel.sample_history.items", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel.__init__": [[25, 67], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "initializer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel.forward": [[72, 143], ["transformer_flattened.TransformerFlattenedModel._forward", "transformer_flattened.TransformerFlattenedModel.decoder", "transformer_flattened.TransformerFlattenedModel.criterion", "math.log", "isinstance", "zip", "transformer_flattened.TransformerFlattenedModel._generate_full", "transformer_flattened.TransformerFlattenedModel._generate", "transformer_flattened.TransformerFlattenedModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "zip", "gen_ids.cpu", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel._generate_full", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "target_ids", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "loss", "=", "loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", "/", "sample_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "decoder", ",", "LSTMDecoder", ")", ":", "\n", "                ", "_", ",", "gen_ids", "=", "self", ".", "_generate_full", "(", "caption_ids", ",", "contexts", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "# We ignore <s> and <pad>", "\n", "", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "\n", "# Remove punctuation", "\n", "gen_texts_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "if", "'rare_tokens'", "in", "caption", ":", "\n", "                ", "for", "gen", ",", "ref", ",", "rare_list", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ",", "caption", "[", "'rare_tokens'", "]", ")", ":", "\n", "                    ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rare_words", "=", "' '", ".", "join", "(", "rare_list", ")", "\n", "gen", "=", "gen", "+", "' '", "+", "rare_words", "\n", "\n", "if", "rare_words", ":", "\n", "                        ", "print", "(", "ref", ")", "\n", "print", "(", "gen", ")", "\n", "print", "(", ")", "\n", "\n", "", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1r'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "\n", "", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel.generate": [[144, 165], ["transformer_flattened.TransformerFlattenedModel._forward", "transformer_flattened.TransformerFlattenedModel._generate", "gen_ids.cpu.cpu.cpu", "context[].new_zeros", "transformer_flattened.TransformerFlattenedModel.roberta.decode"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "B", "=", "image", ".", "shape", "[", "0", "]", "\n", "caption", "=", "{", "self", ".", "index", ":", "context", "[", "self", ".", "index", "]", ".", "new_zeros", "(", "B", ",", "2", ")", "}", "\n", "caption_ids", ",", "_", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "\n", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generations'", ":", "gen_texts", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel._forward": [[166, 239], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer_flattened.TransformerFlattenedModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_flattened.TransformerFlattenedModel.roberta.extract_features", "X_image.view.view.new_zeros().bool", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "X_image.view.view.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "X_image.view.view.new_zeros", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "article_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "article_padding_mask", "=", "article_ids", "==", "self", ".", "padding_idx", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "B", ",", "S", "=", "article_ids", ".", "shape", "\n", "\n", "X_sections_hiddens", "=", "self", ".", "roberta", ".", "extract_features", "(", "\n", "article_ids", ",", "return_all_hiddens", "=", "True", ")", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel._generate": [[240, 329], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_flattened.TransformerFlattenedModel.decoder.filter_incremental_state", "transformer_flattened.TransformerFlattenedModel.decoder", "transformer_flattened.TransformerFlattenedModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel._generate_full": [[330, 421], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_flattened.TransformerFlattenedModel.decoder", "transformer_flattened.TransformerFlattenedModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate_full", "(", "self", ",", "caption_ids", ",", "contexts", ")", ":", "\n", "# incremental_state: Dict[str, Any] = {}", "\n", "        ", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "# if i == 0:", "\n", "#     prev_target = {self.index: seed_input}", "\n", "# else:", "\n", "#     prev_target = {self.index: seed_input[:, -1:]}", "\n", "            ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "\n", "# self.decoder.filter_incremental_state(", "\n", "#     incremental_state, active_idx)", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "# incremental_state=incremental_state", "\n", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel.decode": [[422, 429], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_flattened.TransformerFlattenedModel.get_metrics": [[430, 444], ["transformer_flattened.TransformerFlattenedModel.sample_history.items", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel.__init__": [[23, 65], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "initializer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel.forward": [[66, 136], ["transformer_faces.TransformerFacesModel._forward", "transformer_faces.TransformerFacesModel.decoder", "transformer_faces.TransformerFacesModel.criterion", "math.log", "transformer_faces.TransformerFacesModel._generate", "zip", "transformer_faces.TransformerFacesModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "zip", "gen_ids.cpu", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ":", "torch", ".", "Tensor", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "names", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "target_ids", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "loss", "=", "loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", "/", "sample_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "# We ignore <s> and <pad>", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "\n", "# Remove punctuation", "\n", "gen_texts", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts", ",", "captions", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "if", "'rare_tokens'", "in", "caption", ":", "\n", "                ", "for", "gen", ",", "ref", ",", "rare_list", "in", "zip", "(", "gen_texts", ",", "captions", ",", "caption", "[", "'rare_tokens'", "]", ")", ":", "\n", "                    ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rare_words", "=", "' '", ".", "join", "(", "rare_list", ")", "\n", "gen", "=", "gen", "+", "' '", "+", "rare_words", "\n", "\n", "if", "rare_words", ":", "\n", "                        ", "print", "(", "ref", ")", "\n", "print", "(", "gen", ")", "\n", "print", "(", ")", "\n", "\n", "", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1r'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "\n", "", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel.generate": [[137, 159], ["transformer_faces.TransformerFacesModel._forward", "transformer_faces.TransformerFacesModel._generate", "gen_ids.cpu.cpu.cpu", "context[].new_zeros", "transformer_faces.TransformerFacesModel.roberta.decode"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "face_embeds", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "B", "=", "image", ".", "shape", "[", "0", "]", "\n", "caption", "=", "{", "self", ".", "index", ":", "context", "[", "self", ".", "index", "]", ".", "new_zeros", "(", "B", ",", "2", ")", "}", "\n", "caption_ids", ",", "_", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "\n", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generations'", ":", "gen_texts", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel._forward": [[160, 240], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer_faces.TransformerFacesModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_faces.TransformerFacesModel.roberta.extract_features", "X_image.view.view.new_zeros().bool", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "X_image.view.view.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "face_embeds.transpose", "X_image.view.view.new_zeros", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "article_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "article_padding_mask", "=", "article_ids", "==", "self", ".", "padding_idx", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "B", ",", "S", "=", "article_ids", ".", "shape", "\n", "\n", "X_sections_hiddens", "=", "self", ".", "roberta", ".", "extract_features", "(", "\n", "article_ids", ",", "return_all_hiddens", "=", "True", ")", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# face_embeds.shape == [batch_size, n_faces, 512]", "\n", "face_masks", "=", "torch", ".", "isnan", "(", "face_embeds", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "face_embeds", "[", "face_masks", "]", "=", "0", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "'faces'", ":", "face_embeds", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'faces_mask'", ":", "face_masks", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel._generate": [[241, 332], ["range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_faces.TransformerFacesModel.decoder.filter_incremental_state", "transformer_faces.TransformerFacesModel.decoder", "transformer_faces.TransformerFacesModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'faces'", ":", "contexts", "[", "'faces'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'faces_mask'", ":", "contexts", "[", "'faces_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel.decode": [[333, 340], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_faces.TransformerFacesModel.get_metrics": [[341, 355], ["transformer_faces.TransformerFacesModel.sample_history.items", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor.__init__": [[14, 67], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNetFeatureExtractor._make_layer", "resnet.ResNetFeatureExtractor._make_layer", "resnet.ResNetFeatureExtractor._make_layer", "resnet.ResNetFeatureExtractor._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNetFeatureExtractor.modules", "len", "ValueError", "isinstance", "resnet.ResNetFeatureExtractor.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor._make_layer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor._make_layer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor._make_layer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor._make_layer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.convolutions.dynamic.Linear"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "# TODO: To save memory, remove this and set strict to False", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "\n", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor._make_layer": [[68, 91], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torchvision.models.resnet.conv1x1", "norm_layer", "block"], "methods", ["None"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilate", "=", "False", ")", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.ResNetFeatureExtractor.forward": [[92, 118], ["resnet.ResNetFeatureExtractor.conv1", "resnet.ResNetFeatureExtractor.bn1", "resnet.ResNetFeatureExtractor.relu", "resnet.ResNetFeatureExtractor.maxpool", "resnet.ResNetFeatureExtractor.layer1", "resnet.ResNetFeatureExtractor.layer2", "resnet.ResNetFeatureExtractor.layer3", "resnet.ResNetFeatureExtractor.layer4", "resnet.ResNetFeatureExtractor.avgpool", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "pool", "=", "False", ")", ":", "\n", "# x.shape == [B, 3, 224, 224]", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "# x.shape == [B, 64, 112, 112]", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "# x.shape == [B, 64, 56, 56]", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "# x.shape == [B, 256, 56, 56]", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "# x.shape == [B, 512, 28, 28]", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "# x.shape == [B, 1024, 14, 14]", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "# x.shape == [B, 2048, 7, 7]", "\n", "\n", "if", "pool", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "# x.shape == [B, 2048, 1, 1]", "\n", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "# x.shape == [B, 2048]", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext": [[129, 134], ["resnet.ResNetFeatureExtractor", "torch.hub.load_state_dict_from_url", "ResNetFeatureExtractor.load_state_dict", "torchvision.models.resnet.Bottleneck", "torchvision.models.resnet.Bottleneck", "torchvision.models.resnet.Bottleneck", "torchvision.models.resnet.Bottleneck", "torchvision.models.resnet.Bottleneck"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["def", "_resnext", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "ResNetFeatureExtractor", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "state_dict", "=", "load_state_dict_from_url", "(", "model_urls", "[", "arch", "]", ",", "progress", "=", "progress", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnext101_32x8d_wsl": [[136, 146], ["resnet._resnext"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext"], ["", "def", "resnext101_32x8d_wsl", "(", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "8", "\n", "return", "_resnext", "(", "'resnext101_32x8d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "True", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnext101_32x16d_wsl": [[148, 158], ["resnet._resnext"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext"], ["", "def", "resnext101_32x16d_wsl", "(", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x16 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "16", "\n", "return", "_resnext", "(", "'resnext101_32x16d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "True", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnext101_32x32d_wsl": [[160, 170], ["resnet._resnext"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext"], ["", "def", "resnext101_32x32d_wsl", "(", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x32 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "32", "\n", "return", "_resnext", "(", "'resnext101_32x32d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "True", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnext101_32x48d_wsl": [[172, 182], ["resnet._resnext"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext"], ["", "def", "resnext101_32x48d_wsl", "(", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNeXt-101 32x48 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"", "\n", "kwargs", "[", "'groups'", "]", "=", "32", "\n", "kwargs", "[", "'width_per_group'", "]", "=", "48", "\n", "return", "_resnext", "(", "'resnext101_32x48d'", ",", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "True", ",", "progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152": [[184, 193], ["resnet._resnext"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet._resnext"], ["", "def", "resnet152", "(", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-152 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>`_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnext", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "True", ",", "progress", ",", "\n", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel.__init__": [[23, 63], ["allennlp.nn.initializers.InitializerApplicator", "allennlp.models.model.Model.__init__", "resnet.resnet152", "torch.hub.load", "collections.defaultdict", "initializer", "spacy.load"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "\n", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_lg'", ",", "\n", "disable", "=", "[", "'textcat'", ",", "'parser'", ",", "'tagger'", ",", "'ner'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel.forward": [[68, 136], ["transformer_glove.TransformerGloveModel._forward", "transformer_glove.TransformerGloveModel.decoder", "transformer_glove.TransformerGloveModel.criterion", "math.log", "transformer_glove.TransformerGloveModel._generate", "zip", "transformer_glove.TransformerGloveModel.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "zip", "gen_ids.cpu", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "context", "=", "[", "m", "[", "'context'", "]", "for", "m", "in", "metadata", "]", "\n", "caption_ids", ",", "target_ids", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "loss", "=", "loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", "/", "sample_size", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "# We ignore <s> and <pad>", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "\n", "# Remove punctuation", "\n", "gen_texts_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions_2", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "if", "'rare_tokens'", "in", "caption", ":", "\n", "                ", "for", "gen", ",", "ref", ",", "rare_list", "in", "zip", "(", "gen_texts_2", ",", "captions_2", ",", "caption", "[", "'rare_tokens'", "]", ")", ":", "\n", "                    ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rare_words", "=", "' '", ".", "join", "(", "rare_list", ")", "\n", "gen", "=", "gen", "+", "' '", "+", "rare_words", "\n", "\n", "if", "rare_words", ":", "\n", "                        ", "print", "(", "ref", ")", "\n", "print", "(", "gen", ")", "\n", "print", "(", ")", "\n", "\n", "", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1r'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "\n", "", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel.generate": [[137, 160], ["transformer_glove.TransformerGloveModel._forward", "transformer_glove.TransformerGloveModel._generate", "gen_ids.cpu.cpu.cpu", "transformer_glove.TransformerGloveModel.roberta.decode"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "_", ",", "contexts", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ")", "\n", "\n", "_", ",", "gen_ids", "=", "self", ".", "_generate", "(", "caption_ids", ",", "contexts", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generated_indices'", ":", "gen_ids", ",", "\n", "'generated_texts'", ":", "gen_texts", ",", "\n", "'captions'", ":", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", ",", "\n", "'web_url'", ":", "[", "m", "[", "'web_url'", "]", "for", "m", "in", "metadata", "]", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel._forward": [[161, 231], ["torch.zeros_like", "transformer_glove.TransformerGloveModel.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_glove.TransformerGloveModel.nlp.pipe", "max", "X_image.view.view.new_full", "enumerate", "torch.isnan().any", "X_image.view.view.new_zeros().bool", "c.lower", "v_lens.append", "vs.append", "torch.from_numpy().type_as", "X_image.view.view.transpose", "X_article.transpose", "len", "numpy.array", "torch.isnan", "X_image.view.view.new_zeros", "torch.from_numpy"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "context", "=", "[", "c", ".", "lower", "(", ")", "for", "c", "in", "context", "]", "\n", "context_docs", "=", "self", ".", "nlp", ".", "pipe", "(", "context", ")", "\n", "vs", "=", "[", "]", "\n", "v_lens", "=", "[", "]", "\n", "for", "doc", "in", "context_docs", ":", "\n", "            ", "v", "=", "[", "token", ".", "vector", "for", "token", "in", "doc", "if", "token", ".", "has_vector", "]", "\n", "v_lens", ".", "append", "(", "len", "(", "v", ")", ")", "\n", "vs", ".", "append", "(", "np", ".", "array", "(", "v", ")", ")", "\n", "", "max_len", "=", "max", "(", "v_lens", ")", "\n", "\n", "context_vector", "=", "X_image", ".", "new_full", "(", "(", "B", ",", "max_len", ",", "300", ")", ",", "np", ".", "nan", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "vs", ")", ":", "\n", "            ", "v_len", "=", "v", ".", "shape", "[", "0", "]", "\n", "v_tensor", "=", "torch", ".", "from_numpy", "(", "v", ")", ".", "type_as", "(", "context_vector", ")", "\n", "context_vector", "[", "i", ",", ":", "v_len", "]", "=", "v_tensor", "\n", "\n", "", "article_padding_mask", "=", "torch", ".", "isnan", "(", "context_vector", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "X_article", "=", "context_vector", "\n", "X_article", "[", "article_padding_mask", "]", "=", "0", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel._generate": [[232, 321], ["range", "torch.cat", "torch.cat", "transformer_glove.TransformerGloveModel.decoder.filter_incremental_state", "transformer_glove.TransformerGloveModel.decoder", "transformer_glove.TransformerGloveModel.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "topk_indices.gather.squeeze", "active_idx.sum().item", "full_active_idx.nonzero", "active_idx.sum"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_index.shape == [batch_size, 1]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel.decode": [[322, 329], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_glove.TransformerGloveModel.get_metrics": [[330, 344], ["transformer_glove.TransformerGloveModel.sample_history.items", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.__init__": [[29, 99], ["allennlp.nn.initializers.InitializerApplicator", "tell.modules.LoadStateDictWithPrefix.__init__", "resnet.resnet152", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "torch.hub.load", "collections.defaultdict", "collections.defaultdict", "tell.modules.GehringLinear", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "tell.modules.GehringLinear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "tell.modules.SelfAttention", "initializer", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "logger.info", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "transformer_pointer_2.TransformerPointer2Model.load_state_dict", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict"], ["    ", "def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "decoder", ":", "Decoder", ",", "\n", "criterion", ":", "Criterion", ",", "\n", "evaluate_mode", ":", "bool", "=", "False", ",", "\n", "attention_dim", ":", "int", "=", "1024", ",", "\n", "hidden_size", ":", "int", "=", "1024", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "vocab_size", ":", "int", "=", "50264", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "index", ":", "str", "=", "'roberta'", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "use_context", ":", "bool", "=", "True", ",", "\n", "sampling_topk", ":", "int", "=", "1", ",", "\n", "sampling_temp", ":", "float", "=", "1.0", ",", "\n", "weigh_bert", ":", "bool", "=", "False", ",", "\n", "model_path", ":", "str", "=", "None", ",", "\n", "initializer", ":", "InitializerApplicator", "=", "InitializerApplicator", "(", ")", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ")", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "criterion", "=", "criterion", "\n", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "namespace", "=", "namespace", "\n", "self", ".", "resnet", "=", "resnet152", "(", ")", "\n", "self", ".", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "\n", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.large'", ")", "\n", "self", ".", "use_context", "=", "use_context", "\n", "self", ".", "padding_idx", "=", "padding_value", "\n", "self", ".", "evaluate_mode", "=", "evaluate_mode", "\n", "self", ".", "sampling_topk", "=", "sampling_topk", "\n", "self", ".", "sampling_temp", "=", "sampling_temp", "\n", "self", ".", "weigh_bert", "=", "weigh_bert", "\n", "if", "weigh_bert", ":", "\n", "            ", "self", ".", "bert_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight", ")", "\n", "\n", "self", ".", "bert_weight_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "25", ")", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bert_weight_2", ")", "\n", "\n", "", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "batch_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "self", ".", "entity_fc", "=", "GehringLinear", "(", "1024", ",", "2", ")", "\n", "self", ".", "entity_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "self", ".", "copy_loss", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "\n", "# Copy-related modules", "\n", "self", ".", "in_proj_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "2", "*", "1024", ",", "1024", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "2", "*", "1024", ")", ")", "\n", "self", ".", "out_proj", "=", "GehringLinear", "(", "1024", ",", "1024", ",", "bias", "=", "True", ")", "\n", "self", ".", "bias_k", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "1", ",", "1", ",", "1024", ")", ")", "\n", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "\n", "# Entity-related modules", "\n", "self", ".", "entity_attn", "=", "SelfAttention", "(", "\n", "out_channels", "=", "1024", ",", "embed_dim", "=", "1024", ",", "num_heads", "=", "16", ",", "gated", "=", "True", ")", "\n", "\n", "initializer", "(", "self", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "\n", "if", "model_path", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f'Recovering weights from {model_path}.'", ")", "\n", "model_state", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "self", ".", "load_state_dict", "(", "model_state", ")", "\n", "# Initialize the weight with first layer of BERT", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.forward": [[103, 179], ["transformer_pointer_2.TransformerPointer2Model._forward", "transformer_pointer_2.TransformerPointer2Model.decoder", "transformer_pointer_2.TransformerPointer2Model.criterion", "transformer_pointer_2.TransformerPointer2Model.pointer_loss", "math.log", "math.log", "math.log", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "gen_loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "entity_loss.item", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "copy_loss.item", "transformer_pointer_2.TransformerPointer2Model._generate", "zip", "transformer_pointer_2.TransformerPointer2Model.roberta.decode", "transformer_pointer_2.TransformerPointer2Model.roberta.decode", "re.sub", "re.sub", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "gen_ids.cpu", "enumerate", "gen_ids.cpu"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.pointer_loss", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ":", "torch", ".", "Tensor", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "names", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "caption_ids", ",", "target_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "caption", ",", "contexts", ")", "\n", "\n", "# Assume we're using adaptive loss", "\n", "gen_loss", ",", "sample_size", "=", "self", ".", "criterion", "(", "\n", "self", ".", "decoder", ".", "adaptive_softmax", ",", "decoder_out", ",", "target_ids", ")", "\n", "\n", "entity_loss", ",", "copy_loss", "=", "self", ".", "pointer_loss", "(", "\n", "decoder_out", ",", "context", ",", "caption", ",", "target_ids", ",", "X_sections_hiddens", ",", "article_padding_mask", ")", "\n", "\n", "gen_loss", "=", "gen_loss", "/", "sample_size", "/", "math", ".", "log", "(", "2", ")", "\n", "entity_loss", "=", "entity_loss", "/", "math", ".", "log", "(", "2", ")", "\n", "copy_loss", "=", "copy_loss", "/", "math", ".", "log", "(", "2", ")", "\n", "\n", "loss", "=", "entity_loss", "+", "copy_loss", "\n", "\n", "if", "(", "self", ".", "training", "and", "not", "loss", ".", "requires_grad", ")", "or", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "loss", "=", "None", "\n", "\n", "", "if", "not", "torch", ".", "isnan", "(", "gen_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'gen_loss'", "]", "+=", "gen_loss", ".", "item", "(", ")", "\n", "", "if", "not", "torch", ".", "isnan", "(", "entity_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'entity_loss'", "]", "+=", "entity_loss", ".", "item", "(", ")", "\n", "", "if", "not", "torch", ".", "isnan", "(", "copy_loss", ")", ":", "\n", "            ", "self", ".", "batch_history", "[", "'copy_loss'", "]", "+=", "copy_loss", ".", "item", "(", ")", "\n", "\n", "", "output_dict", "=", "{", "\n", "'loss'", ":", "loss", ",", "\n", "'sample_size'", ":", "sample_size", ",", "\n", "}", "\n", "\n", "# During evaluation, we will generate a caption and compute BLEU, etc.", "\n", "if", "not", "self", ".", "training", "and", "self", ".", "evaluate_mode", ":", "\n", "            ", "log_probs", ",", "copy_probs", ",", "should_copy_mask", ",", "gen_ids", "=", "self", ".", "_generate", "(", "\n", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "x", ">", "1", "]", ")", "for", "x", "in", "gen_ids", ".", "cpu", "(", ")", "]", "\n", "captions", "=", "[", "m", "[", "'caption'", "]", "for", "m", "in", "metadata", "]", "\n", "\n", "copied_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "should_copy_mask", "[", "i", "]", "]", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "gen_ids", ".", "cpu", "(", ")", ")", "]", "\n", "\n", "output_dict", "[", "'captions'", "]", "=", "captions", "\n", "output_dict", "[", "'generations'", "]", "=", "gen_texts", "\n", "output_dict", "[", "'metadata'", "]", "=", "metadata", "\n", "output_dict", "[", "'copied_texts'", "]", "=", "copied_texts", "\n", "\n", "# Remove punctuation", "\n", "gen_texts", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "gen_texts", "]", "\n", "captions", "=", "[", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "t", ")", "for", "t", "in", "captions", "]", "\n", "\n", "for", "gen", ",", "ref", "in", "zip", "(", "gen_texts", ",", "captions", ")", ":", "\n", "                ", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "bleu_scorer", "+=", "(", "gen", ",", "[", "ref", "]", ")", "\n", "score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "self", ".", "sample_history", "[", "'bleu-1'", "]", "+=", "score", "[", "0", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-2'", "]", "+=", "score", "[", "1", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-3'", "]", "+=", "score", "[", "2", "]", "*", "100", "\n", "self", ".", "sample_history", "[", "'bleu-4'", "]", "+=", "score", "[", "3", "]", "*", "100", "\n", "\n", "# rogue_scorer = Rouge()", "\n", "# score = rogue_scorer.calc_score([gen], [ref])", "\n", "# self.sample_history['rogue'] += score * 100", "\n", "\n", "", "", "self", ".", "n_samples", "+=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "self", ".", "n_batches", "+=", "1", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.pointer_loss": [[180, 315], ["X.transpose.transpose.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "transformer_pointer_2.TransformerPointer2Model.entity_attn", "X_entity.transpose.transpose.transpose", "transformer_pointer_2.TransformerPointer2Model.entity_fc", "entity_logits.view.view.view", "caption_copy_masks.clone().reshape", "transformer_pointer_2.TransformerPointer2Model.entity_loss", "tell.modules.multi_head_attention_score_forward", "context_copy_masks.expand_as.expand_as.unsqueeze", "context_copy_masks.expand_as.expand_as.expand_as", "tell.modules.multi_head_attention_score_forward.new_zeros", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "torch.cat().unique", "len", "torch.cat().unique.new_full", "torch.cat().unique.new_full", "torch.cat().unique.new_full", "torch.cat().unique.new_full.index_copy_", "torch.cat().unique.new_full.index_select", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.view", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.cat().unique.new_full.index_select", "new_caption_targets.reshape.reshape.reshape", "tell.modules.multi_head_attention_score_forward.new_zeros", "tell.modules.multi_head_attention_score_forward.new_zeros.scatter_add_", "tell.modules.multi_head_attention_score_forward.new_zeros.new_zeros", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "copy_lprobs.view.view.view", "caption_copy_masks.max().item", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "range", "caption_copy_masks[].bool().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "context_ids.reshape", "caption_targets.reshape", "new_caption_targets[].view", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "caption_copy_masks.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_context_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "caption_copy_masks.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "transformer_pointer_2.TransformerPointer2Model.copy_loss", "caption_copy_masks[].bool", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.multi_head_attention_score_forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "pointer_loss", "(", "self", ",", "decoder_out", ",", "context", ",", "caption", ",", "caption_targets", ",", "\n", "X_sections_hiddens", ",", "article_padding_mask", ")", ":", "\n", "        ", "X", "=", "decoder_out", "[", "0", "]", "\n", "# X.shape == [batch_size, target_len, embed_size]", "\n", "\n", "caption_copy_masks", "=", "caption", "[", "f'{self.index}_copy_masks'", "]", "\n", "caption_copy_masks", "=", "caption_copy_masks", "[", ":", ",", "1", ":", "]", "\n", "# caption_copy_masks.shape == [batch_size, target_len]", "\n", "\n", "if", "not", "caption_copy_masks", "[", "caption_copy_masks", ">=", "1", "]", ".", "bool", "(", ")", ".", "any", "(", ")", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "\n", "", "context_copy_masks", "=", "context", "[", "f'{self.index}_proper_masks'", "]", "\n", "# context_copy_masks.shape == [batch_size, source_len]", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight_2", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [target_len, batch_size, embed_size]", "\n", "\n", "X_article", "=", "X_article", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "X_entity", "=", "self", ".", "entity_attn", "(", "X", ")", "\n", "# X_entity.shape == [target_len, batch_size, embed_size]", "\n", "\n", "X_entity", "=", "X_entity", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_entity.shape == [batch_size, target_len, embed_size]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X_entity", ")", "\n", "# entity_logits.shape == [batch_size, target_len, 2]", "\n", "\n", "entity_logits", "=", "entity_logits", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "# entity_logits.shape == [batch_size * target_len, 2]", "\n", "\n", "targets", "=", "caption_copy_masks", ".", "clone", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "targets", "[", "targets", ">", "1", "]", "=", "1", "\n", "# targets.shape == [batch_size * target_len]", "\n", "\n", "entity_loss", "=", "self", ".", "entity_loss", "(", "entity_logits", ",", "targets", ")", "\n", "\n", "copy_attn", "=", "multi_head_attention_score_forward", "(", "\n", "X", ",", "X_article", ",", "1024", ",", "16", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "True", ",", "0.1", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "article_padding_mask", ")", "\n", "# copy_attn.shape == [batch_size, target_len, source_len + 2]", "\n", "\n", "copy_attn", "=", "copy_attn", "[", ":", ",", ":", ",", ":", "-", "2", "]", "\n", "# copy_attn.shape == [batch_size, target_len, source_len]", "\n", "\n", "context_copy_masks", "=", "context_copy_masks", ".", "unsqueeze", "(", "1", ")", "\n", "# context_copy_masks.shape == [batch_size, 1, source_len]", "\n", "\n", "context_copy_masks", "=", "context_copy_masks", ".", "expand_as", "(", "copy_attn", ")", "\n", "# context_copy_masks.shape == [batch_size, target_len, source_len]", "\n", "\n", "irrelevant_mask", "=", "context_copy_masks", "<", "1", "\n", "copy_attn", "[", "irrelevant_mask", "]", "=", "0", "\n", "# copy_attn.shape == [batch_size, target_len, source_len]", "\n", "\n", "B", ",", "L", ",", "S", "=", "copy_attn", ".", "shape", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B", ",", "L", ",", "self", ".", "vocab_size", ")", "\n", "# copy_probs.shape == [batch_size, target_len, vocab_size]", "\n", "\n", "context_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# context_ids.shape == [batch_size, source_len]", "\n", "\n", "########################################", "\n", "# Second attempt at calculating copy loss", "\n", "# First construct the reduced dictionary, containing only tokens", "\n", "# mentioned in the context.", "\n", "unique_ids", "=", "torch", ".", "cat", "(", "[", "context_ids", ",", "caption_targets", "]", ",", "dim", "=", "1", ")", ".", "unique", "(", ")", "\n", "V", "=", "len", "(", "unique_ids", ")", "\n", "# unique_ids.shape == [reduced_vocab_size]", "\n", "\n", "# Construct the inverse map of unique_ids", "\n", "inverse_unique_ids", "=", "unique_ids", ".", "new_full", "(", "[", "self", ".", "vocab_size", "]", ",", "-", "1", ")", "\n", "inverse_unique_ids", ".", "index_copy_", "(", "\n", "0", ",", "unique_ids", ",", "torch", ".", "arange", "(", "V", ")", ".", "to", "(", "unique_ids", ".", "device", ")", ")", "\n", "# inverse_unique_ids.shape == [vocab_size]", "\n", "# e.g. [-1, -1, 0, -1, -1, 1, 2, -1, 3, ....]", "\n", "\n", "# Next we need to remap the context_ids to the new dictionary.", "\n", "new_context_ids", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "context_ids", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_context_ids.shape == [batch_size * source_len]", "\n", "\n", "new_context_ids", "=", "new_context_ids", ".", "view", "(", "B", ",", "S", ")", "\n", "new_context_ids", "=", "new_context_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "copy_attn", ")", "\n", "# new_context_ids.shape == [batch_size, target_len, source_len]", "\n", "\n", "new_caption_targets", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "caption_targets", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_caption_targets.shape == [batch_size * target_len, 1]", "\n", "\n", "new_caption_targets", "=", "new_caption_targets", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "# new_caption_targets.shape == [batch_size * target_len, 1]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B", ",", "L", ",", "V", ")", "\n", "# copy_probs.shape == [batch_size, target_len, reduced_vocab_size]", "\n", "\n", "copy_probs", ".", "scatter_add_", "(", "2", ",", "new_context_ids", ",", "copy_attn", ")", "\n", "copy_lprobs", "=", "copy_probs", ".", "new_zeros", "(", "copy_probs", ".", "shape", ")", "\n", "copy_lprobs", "[", "copy_probs", ">", "0", "]", "=", "torch", ".", "log", "(", "copy_probs", "[", "copy_probs", ">", "0", "]", ")", "\n", "copy_lprobs", "=", "copy_lprobs", ".", "view", "(", "B", "*", "L", ",", "V", ")", "\n", "\n", "max_index", "=", "caption_copy_masks", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "copy_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "max_index", "+", "1", ")", ":", "\n", "            ", "relevant_mask", "=", "(", "caption_copy_masks", "==", "i", ")", ".", "view", "(", "-", "1", ")", "\n", "new_caption_targets_i", "=", "new_caption_targets", "[", "relevant_mask", "]", ".", "view", "(", "-", "1", ")", "\n", "# new_caption_targets_i.shape == [batch_size * n_entity_tokens, 1]", "\n", "\n", "copy_lprobs_i", "=", "copy_lprobs", "[", "relevant_mask", "]", "\n", "# copy_lprobs_i.shape == [batch_size * n_entity_tokens, reduced_vocab_size]", "\n", "\n", "if", "copy_lprobs_i", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "                ", "copy_loss", "+=", "self", ".", "copy_loss", "(", "copy_lprobs_i", ",", "\n", "new_caption_targets_i", ")", "\n", "\n", "", "", "return", "entity_loss", ",", "copy_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.generate": [[316, 344], ["transformer_pointer_2.TransformerPointer2Model._forward", "transformer_pointer_2.TransformerPointer2Model._generate", "gen_ids.cpu.cpu.cpu", "context[].new_zeros", "transformer_pointer_2.TransformerPointer2Model.roberta.decode", "transformer_pointer_2.TransformerPointer2Model.roberta.decode", "enumerate"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "generate", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "face_embeds", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "B", "=", "image", ".", "shape", "[", "0", "]", "\n", "caption", "=", "{", "self", ".", "index", ":", "context", "[", "self", ".", "index", "]", ".", "new_zeros", "(", "B", ",", "2", ")", "}", "\n", "caption_ids", ",", "_", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "=", "self", ".", "_forward", "(", "\n", "context", ",", "image", ",", "caption", ",", "face_embeds", ")", "\n", "\n", "log_probs", ",", "copy_probs", ",", "should_copy_mask", ",", "gen_ids", "=", "self", ".", "_generate", "(", "\n", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", "\n", "\n", "gen_ids", "=", "gen_ids", ".", "cpu", "(", ")", "\n", "gen_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "\n", "x", "[", "x", "!=", "self", ".", "padding_idx", "]", ")", "for", "x", "in", "gen_ids", "]", "\n", "\n", "# Get the copied words", "\n", "copied_texts", "=", "[", "self", ".", "roberta", ".", "decode", "(", "x", "[", "should_copy_mask", "[", "i", "]", "]", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "gen_ids", ")", "]", "\n", "\n", "output_dict", "=", "{", "\n", "'generations'", ":", "gen_texts", ",", "\n", "'copied_texts'", ":", "copied_texts", ",", "\n", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._forward": [[345, 427], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer_pointer_2.TransformerPointer2Model.resnet", "X_image.view.view.permute", "X_image.view.view.view", "transformer_pointer_2.TransformerPointer2Model.roberta.extract_features", "X_image.view.view.new_zeros().bool", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.isnan().any", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "X_image.view.view.transpose", "torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "face_embeds.transpose", "X_image.view.view.new_zeros", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "_forward", "(", "self", ",", "# type: ignore", "\n", "context", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "image", ":", "torch", ".", "Tensor", ",", "\n", "caption", ":", "Dict", "[", "str", ",", "torch", ".", "LongTensor", "]", ",", "\n", "face_embeds", ")", ":", "\n", "\n", "# We assume that the first token in target is the <s> token. We", "\n", "# shall use it to seed the decoder. Here decoder_target is simply", "\n", "# decoder_input but shifted to the right by one step.", "\n", "# For masks, 1 is padding, 2 is normal word, 3 is entity word", "\n", "        ", "caption_ids", "=", "caption", "[", "self", ".", "index", "]", "\n", "\n", "target_ids", "=", "torch", ".", "zeros_like", "(", "caption_ids", ")", "\n", "target_ids", "[", ":", ",", ":", "-", "1", "]", "=", "caption_ids", "[", ":", ",", "1", ":", "]", "\n", "\n", "# The final token is not used as input to the decoder, since otherwise", "\n", "# we'll be predicting the <pad> token.", "\n", "caption_ids", "=", "caption_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "target_ids", "=", "target_ids", "[", ":", ",", ":", "-", "1", "]", "\n", "caption", "[", "self", ".", "index", "]", "=", "caption_ids", "\n", "\n", "# Embed the image", "\n", "X_image", "=", "self", ".", "resnet", "(", "image", ")", "\n", "# X_image.shape == [batch_size, 2048, 7, 7]", "\n", "\n", "X_image", "=", "X_image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "# X_image.shape == [batch_size, 7, 7, 2048]", "\n", "\n", "# Flatten out the image", "\n", "B", ",", "H", ",", "W", ",", "C", "=", "X_image", ".", "shape", "\n", "P", "=", "H", "*", "W", "# number of pixels", "\n", "X_image", "=", "X_image", ".", "view", "(", "B", ",", "P", ",", "C", ")", "\n", "# X_image.shape == [batch_size, 49, 2048]", "\n", "\n", "article_ids", "=", "context", "[", "self", ".", "index", "]", "\n", "# article_ids.shape == [batch_size, seq_len]", "\n", "\n", "article_padding_mask", "=", "article_ids", "==", "self", ".", "padding_idx", "\n", "# article_padding_mask.shape == [batch_size, seq_len]", "\n", "\n", "B", ",", "S", "=", "article_ids", ".", "shape", "\n", "\n", "X_sections_hiddens", "=", "self", ".", "roberta", ".", "extract_features", "(", "\n", "article_ids", ",", "return_all_hiddens", "=", "True", ")", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "# Create padding mask (1 corresponds to the padding index)", "\n", "", "image_padding_mask", "=", "X_image", ".", "new_zeros", "(", "B", ",", "P", ")", ".", "bool", "(", ")", "\n", "\n", "# face_embeds.shape == [batch_size, n_faces, 512]", "\n", "face_masks", "=", "torch", ".", "isnan", "(", "face_embeds", ")", ".", "any", "(", "dim", "=", "-", "1", ")", "\n", "face_embeds", "[", "face_masks", "]", "=", "0", "\n", "\n", "# The quirks of dynamic convolution implementation: The context", "\n", "# embedding has dimension [seq_len, batch_size], but the mask has", "\n", "# dimension [batch_size, seq_len].", "\n", "contexts", "=", "{", "\n", "'image'", ":", "X_image", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'image_mask'", ":", "image_padding_mask", ",", "\n", "'article'", ":", "X_article", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'article_mask'", ":", "article_padding_mask", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "'faces'", ":", "face_embeds", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "'faces_mask'", ":", "face_masks", ",", "\n", "}", "\n", "\n", "return", "caption_ids", ",", "target_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model._generate": [[428, 697], ["torch.stack.transpose", "torch.stack.transpose", "torch.stack.transpose", "caption_ids.new_full", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_ones().bool", "torch.cat.new_ones().bool", "torch.cat.new_ones().bool", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "transformer_pointer_2.TransformerPointer2Model.decoder.filter_incremental_state", "transformer_pointer_2.TransformerPointer2Model.decoder", "transformer_pointer_2.TransformerPointer2Model.decoder.get_normalized_probs", "lprobs.squeeze.squeeze.squeeze", "Xs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "X_full.transpose.transpose.transpose", "transformer_pointer_2.TransformerPointer2Model.entity_attn", "X_entity.transpose.transpose.transpose", "transformer_pointer_2.TransformerPointer2Model.entity_fc", "transformer_pointer_2.TransformerPointer2Model.entity_fc", "X.transpose.transpose.transpose", "tell.modules.multi_head_attention_score_forward", "copy_attn.squeeze.squeeze.squeeze", "copy_attn.squeeze.squeeze.new_zeros", "context_ids.unique", "len", "context_ids.unique.new_full", "context_ids.unique.new_full.index_copy_", "context_ids.unique.new_full.index_select", "new_context_ids.view.view.view", "copy_attn.squeeze.squeeze.new_zeros", "copy_attn.squeeze.new_zeros.scatter_add_", "copy_attn.squeeze.new_zeros.topk", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_copy_probs.gather", "topk_copy_indices.gather", "context_ids.unique.gather", "selected_copy_index.unsqueeze.unsqueeze.unsqueeze", "selected_copy_index.unsqueeze.unsqueeze.expand_as", "selected_copy_index.unsqueeze.unsqueeze.new_full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "topk_copy_probs.gather.new_zeros", "copy_prob_list.append", "should_copy.new_zeros", "should_copy.unsqueeze", "should_copy_list.append", "lprobs.squeeze.squeeze.topk", "topk_lprobs.div_.div_.div_", "topk_lprobs.div_.div_.exp", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "topk_lprobs.div_.div_.gather", "topk_indices.gather", "topk_indices.gather.new_zeros", "topk_lprobs.div_.gather.new_zeros", "topk_indices.gather.new_zeros.new_full", "log_prob_list.append", "index_path_list.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer_pointer_2.TransformerPointer2Model.argmax", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "context_ids.reshape", "topk_indices.gather.new_zeros.squeeze", "active_idx.sum().item", "torch.cat.new_ones", "torch.cat.new_ones", "torch.cat.new_ones", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "topk_copy_indices.gather.squeeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "empty_copy.max", "full_active_idx.nonzero().squeeze", "full_active_idx.nonzero", "active_idx.sum", "weight.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "full_active_idx.nonzero"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.attention.multi_head.multi_head_attention_score_forward"], ["", "def", "_generate", "(", "self", ",", "caption_ids", ",", "contexts", ",", "X_sections_hiddens", ",", "article_padding_mask", ",", "context", ")", ":", "\n", "        ", "incremental_state", ":", "Dict", "[", "str", ",", "Any", "]", "=", "{", "}", "\n", "seed_input", "=", "caption_ids", "[", ":", ",", "0", ":", "1", "]", "\n", "B", "=", "caption_ids", ".", "shape", "[", "0", "]", "\n", "log_prob_list", "=", "[", "]", "\n", "copy_prob_list", "=", "[", "]", "\n", "should_copy_list", "=", "[", "seed_input", ".", "new_ones", "(", "B", ",", "1", ")", ".", "bool", "(", ")", "]", "\n", "index_path_list", "=", "[", "seed_input", "]", "\n", "eos", "=", "2", "\n", "active_idx", "=", "seed_input", "[", ":", ",", "-", "1", "]", "!=", "eos", "\n", "full_active_idx", "=", "active_idx", "\n", "gen_len", "=", "100", "\n", "\n", "context_copy_masks", "=", "context", "[", "f'{self.index}_proper_masks'", "]", "\n", "# context_copy_masks.shape == [batch_size, source_len]", "\n", "\n", "if", "self", ".", "weigh_bert", ":", "\n", "            ", "X_article", "=", "torch", ".", "stack", "(", "X_sections_hiddens", ",", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, src_len, 13, embed_size]", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "self", ".", "bert_weight_2", ",", "dim", "=", "0", ")", "\n", "weight", "=", "weight", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# weight.shape == [1, 1, 13, 1]", "\n", "\n", "X_article", "=", "(", "X_article", "*", "weight", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "else", ":", "\n", "            ", "X_article", "=", "X_sections_hiddens", "[", "-", "1", "]", "\n", "# X_article.shape == [batch_size, seq_len, embed_size]", "\n", "\n", "", "X_article", "=", "X_article", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_article.shape == [seq_len, batch_size, embed_size]", "\n", "\n", "Xs", "=", "[", "]", "\n", "\n", "copied_indices_full", "=", "caption_ids", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "-", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "gen_len", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "}", "\n", "", "else", ":", "\n", "                ", "prev_target", "=", "{", "self", ".", "index", ":", "seed_input", "[", ":", ",", "-", "1", ":", "]", "}", "\n", "\n", "", "self", ".", "decoder", ".", "filter_incremental_state", "(", "\n", "incremental_state", ",", "active_idx", ")", "\n", "\n", "contexts_i", "=", "{", "\n", "'image'", ":", "contexts", "[", "'image'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'image_mask'", ":", "contexts", "[", "'image_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'article'", ":", "contexts", "[", "'article'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'article_mask'", ":", "contexts", "[", "'article_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'faces'", ":", "contexts", "[", "'faces'", "]", "[", ":", ",", "full_active_idx", "]", ",", "\n", "'faces_mask'", ":", "contexts", "[", "'faces_mask'", "]", "[", "full_active_idx", "]", ",", "\n", "'sections'", ":", "None", ",", "\n", "'sections_mask'", ":", "None", ",", "\n", "}", "\n", "\n", "decoder_out", "=", "self", ".", "decoder", "(", "\n", "prev_target", ",", "\n", "contexts_i", ",", "\n", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# We're only interested in the current final word", "\n", "decoder_out", "=", "(", "decoder_out", "[", "0", "]", "[", ":", ",", "-", "1", ":", "]", ",", "None", ")", "\n", "\n", "lprobs", "=", "self", ".", "decoder", ".", "get_normalized_probs", "(", "\n", "decoder_out", ",", "log_probs", "=", "True", ")", "\n", "# lprobs.shape == [batch_size, 1, vocab_size]", "\n", "\n", "lprobs", "=", "lprobs", ".", "squeeze", "(", "1", ")", "\n", "# lprobs.shape == [batch_size, vocab_size]", "\n", "\n", "X", "=", "decoder_out", "[", "0", "]", "\n", "# X.shape == [batch_size, 1, embed_size]", "\n", "\n", "Xs", ".", "append", "(", "X", ")", "\n", "\n", "X_full", "=", "torch", ".", "cat", "(", "Xs", ",", "dim", "=", "1", ")", "\n", "# X.shape == [batch_size_i, target_len, embed_size]", "\n", "\n", "X_full", "=", "X_full", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [target_len, batch_size_i, embed_size]", "\n", "\n", "X_entity", "=", "self", ".", "entity_attn", "(", "X_full", ")", "\n", "# X_entity.shape == [target_len, batch_size_i, embed_size]", "\n", "\n", "X_entity", "=", "X_entity", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X_entity.shape == [batch_size_i, target_len, embed_size]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X", ")", "\n", "# entity_logits.shape == [batch_size, 1, 2]", "\n", "\n", "entity_logits", "=", "self", ".", "entity_fc", "(", "X_entity", "[", ":", ",", "-", "1", "]", ")", "\n", "# entity_logits.shape == [batch_size, 2]", "\n", "\n", "should_copy", "=", "entity_logits", ".", "argmax", "(", "dim", "=", "-", "1", ")", "==", "1", "\n", "# should_copy.shape == [batch_size]", "\n", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "# X.shape == [1, batch_size, embed_size]", "\n", "\n", "X_article_i", "=", "X_article", "[", ":", ",", "full_active_idx", "]", "\n", "article_padding_mask_i", "=", "article_padding_mask", "[", "full_active_idx", "]", "\n", "\n", "copy_attn", "=", "multi_head_attention_score_forward", "(", "\n", "X", ",", "X_article_i", ",", "1024", ",", "16", ",", "\n", "self", ".", "in_proj_weight", ",", "self", ".", "in_proj_bias", ",", "\n", "self", ".", "bias_k", ",", "True", ",", "0.1", ",", "self", ".", "out_proj", ".", "weight", ",", "self", ".", "out_proj", ".", "bias", ",", "\n", "training", "=", "self", ".", "training", ",", "\n", "key_padding_mask", "=", "article_padding_mask_i", ")", "\n", "# copy_attn.shape == [batch_size, target_len, source_len + 2]", "\n", "\n", "copy_attn", "=", "copy_attn", "[", ":", ",", ":", ",", ":", "-", "2", "]", "\n", "# copy_attn.shape == [batch_size, 1, source_len]", "\n", "\n", "copy_attn", "=", "copy_attn", ".", "squeeze", "(", "1", ")", "\n", "# copy_attn.shape == [batch_size, source_len]", "\n", "\n", "irrelevant_mask", "=", "context_copy_masks", "[", "full_active_idx", "]", "<", "1", "\n", "copy_attn", "[", "irrelevant_mask", "]", "=", "0", "\n", "# copy_attn.shape == [batch_size, source_len]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "\n", "copy_attn", ".", "shape", "[", "0", "]", ",", "self", ".", "vocab_size", ")", "\n", "# copy_probs.shape == [batch_size, vocab_size]", "\n", "\n", "context_ids", "=", "context", "[", "self", ".", "index", "]", "[", "full_active_idx", "]", "\n", "# context_ids.shape == [batch_size, source_len]", "\n", "\n", "# First construct the reduced dictionary, containing only tokens", "\n", "# mentioned in the context.", "\n", "unique_ids", "=", "context_ids", ".", "unique", "(", ")", "\n", "V", "=", "len", "(", "unique_ids", ")", "\n", "# unique_ids.shape == [reduced_vocab_size]", "\n", "\n", "# Construct the inverse map of unique_ids", "\n", "inverse_unique_ids", "=", "unique_ids", ".", "new_full", "(", "[", "self", ".", "vocab_size", "]", ",", "-", "1", ")", "\n", "inverse_unique_ids", ".", "index_copy_", "(", "\n", "0", ",", "unique_ids", ",", "torch", ".", "arange", "(", "V", ")", ".", "to", "(", "unique_ids", ".", "device", ")", ")", "\n", "# inverse_unique_ids.shape == [vocab_size]", "\n", "# e.g. [-1, -1, 0, -1, -1, 1, 2, -1, 3, ....]", "\n", "\n", "# Next we need to remap the context_ids to the new dictionary.", "\n", "new_context_ids", "=", "inverse_unique_ids", ".", "index_select", "(", "\n", "0", ",", "context_ids", ".", "reshape", "(", "-", "1", ")", ")", "\n", "# new_context_ids.shape == [batch_size * source_len]", "\n", "\n", "B_i", ",", "S", "=", "copy_attn", ".", "shape", "\n", "new_context_ids", "=", "new_context_ids", ".", "view", "(", "B_i", ",", "S", ")", "\n", "# new_context_ids.shape == [batch_size, source_len]", "\n", "\n", "copy_probs", "=", "copy_attn", ".", "new_zeros", "(", "B_i", ",", "V", ")", "\n", "# copy_probs.shape == [batch_size, reduced_vocab_size]", "\n", "\n", "copy_probs", ".", "scatter_add_", "(", "1", ",", "new_context_ids", ",", "copy_attn", ")", "\n", "\n", "topk_copy_probs", ",", "topk_copy_indices", "=", "copy_probs", ".", "topk", "(", "\n", "self", ".", "sampling_topk", ")", "\n", "# topk_copy_probs.shape == [batch_size, topk]", "\n", "\n", "# If the top probability is 0, then we simply don't copy", "\n", "empty_copy", "=", "topk_copy_probs", "<", "1e-6", "\n", "# Add small epsilon", "\n", "topk_copy_probs", "[", "empty_copy", "]", "=", "1e-6", "\n", "should_copy", "=", "should_copy", "&", "(", "~", "empty_copy", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", ")", "\n", "\n", "sampled_copy_index", "=", "torch", ".", "multinomial", "(", "\n", "topk_copy_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_copy_index.shape == [batch_size, 1]", "\n", "\n", "selected_copy_prob", "=", "topk_copy_probs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_copy_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_copy_new_index", "=", "topk_copy_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_copy_index", ")", "\n", "# selected_copy_new_index.shape == [batch_size, 1]", "\n", "\n", "# Convert back to old vocab space", "\n", "selected_copy_index", "=", "unique_ids", ".", "gather", "(", "\n", "dim", "=", "0", ",", "index", "=", "selected_copy_new_index", ".", "squeeze", "(", "1", ")", ")", "\n", "# selected_copy_index.shape == [batch_size]", "\n", "\n", "selected_copy_index", "=", "selected_copy_index", ".", "unsqueeze", "(", "1", ")", "\n", "# selected_copy_index.shape == [batch_size, 1]", "\n", "\n", "selection", "=", "selected_copy_index", ".", "expand_as", "(", "\n", "copied_indices_full", "[", "full_active_idx", "]", ")", "\n", "# selected_copy_index.shape == [batch_size_i, 1]", "\n", "\n", "has_copied", "=", "(", "\n", "selection", "==", "copied_indices_full", "[", "full_active_idx", "]", ")", ".", "any", "(", "dim", "=", "1", ")", "\n", "# has_copied.shape == [batch_size_i]", "\n", "\n", "should_copy", "=", "should_copy", "&", "(", "~", "has_copied", ")", "\n", "# should_copy.shape == [batch_size_i]", "\n", "\n", "copied_indices", "=", "selected_copy_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "-", "1", ")", "\n", "copied_indices", "[", "full_active_idx", ".", "nonzero", "(", ")", ".", "squeeze", "(", "1", ")", "[", "should_copy", "]", "]", "=", "selected_copy_index", "[", "should_copy", "]", "\n", "copied_indices_full", "=", "torch", ".", "cat", "(", "\n", "[", "copied_indices_full", ",", "copied_indices", "]", ",", "dim", "=", "1", ")", "\n", "\n", "copy_prob", "=", "selected_copy_prob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "copy_prob", "[", "full_active_idx", "]", "=", "selected_copy_prob", "\n", "\n", "copy_prob_list", ".", "append", "(", "copy_prob", ")", "\n", "\n", "should_copy_full", "=", "should_copy", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "should_copy_full", "[", "full_active_idx", "]", "=", "should_copy", ".", "unsqueeze", "(", "1", ")", "\n", "should_copy_list", ".", "append", "(", "should_copy_full", ")", "\n", "\n", "topk_lprobs", ",", "topk_indices", "=", "lprobs", ".", "topk", "(", "self", ".", "sampling_topk", ")", "\n", "topk_lprobs", "=", "topk_lprobs", ".", "div_", "(", "self", ".", "sampling_temp", ")", "\n", "# topk_lprobs.shape == [batch_size, topk]", "\n", "\n", "# Take a random sample from those top k", "\n", "topk_probs", "=", "topk_lprobs", ".", "exp", "(", ")", "\n", "sampled_index", "=", "torch", ".", "multinomial", "(", "topk_probs", ",", "num_samples", "=", "1", ")", "\n", "# sampled_index.shape == [batch_size, 1]", "\n", "\n", "selected_lprob", "=", "topk_lprobs", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_prob.shape == [batch_size, 1]", "\n", "\n", "selected_gen_index", "=", "topk_indices", ".", "gather", "(", "\n", "dim", "=", "-", "1", ",", "index", "=", "sampled_index", ")", "\n", "# selected_gen_index.shape == [batch_size, 1]", "\n", "\n", "selected_index", "=", "selected_gen_index", ".", "new_zeros", "(", "\n", "selected_gen_index", ".", "shape", ")", "\n", "selected_index", "[", "should_copy", "]", "=", "selected_copy_index", "[", "should_copy", "]", "\n", "selected_index", "[", "~", "should_copy", "]", "=", "selected_gen_index", "[", "~", "should_copy", "]", "\n", "\n", "log_prob", "=", "selected_lprob", ".", "new_zeros", "(", "B", ",", "1", ")", "\n", "log_prob", "[", "full_active_idx", "]", "=", "selected_lprob", "\n", "\n", "index_path", "=", "selected_index", ".", "new_full", "(", "(", "B", ",", "1", ")", ",", "self", ".", "padding_idx", ")", "\n", "index_path", "[", "full_active_idx", "]", "=", "selected_index", "\n", "\n", "log_prob_list", ".", "append", "(", "log_prob", ")", "\n", "index_path_list", ".", "append", "(", "index_path", ")", "\n", "\n", "seed_input", "=", "torch", ".", "cat", "(", "[", "seed_input", ",", "selected_index", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "is_eos", "=", "selected_index", ".", "squeeze", "(", "-", "1", ")", "==", "eos", "\n", "active_idx", "=", "~", "is_eos", "\n", "\n", "full_active_idx", "[", "full_active_idx", ".", "nonzero", "(", ")", "[", "~", "active_idx", "]", "]", "=", "0", "\n", "\n", "Xs", "=", "[", "x", "[", "active_idx", "]", "for", "x", "in", "Xs", "]", "\n", "\n", "seed_input", "=", "seed_input", "[", "active_idx", "]", "\n", "\n", "if", "active_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "", "log_probs", "=", "torch", ".", "cat", "(", "log_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "# log_probs.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "copy_probs", "=", "torch", ".", "cat", "(", "copy_prob_list", ",", "dim", "=", "-", "1", ")", "\n", "\n", "should_copy_probs", "=", "torch", ".", "cat", "(", "should_copy_list", ",", "dim", "=", "-", "1", ")", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "index_path_list", ",", "dim", "=", "-", "1", ")", "\n", "# token_ids.shape == [batch_size * beam_size, generate_len]", "\n", "\n", "return", "log_probs", ",", "copy_probs", ",", "should_copy_probs", ",", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode": [[698, 705], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "decode", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add ``\"label\"`` key to the dictionary with the result.\n        \"\"\"", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.get_metrics": [[706, 724], ["transformer_pointer_2.TransformerPointer2Model.sample_history.items", "transformer_pointer_2.TransformerPointer2Model.batch_history.items", "collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "metrics", ":", "Dict", "[", "str", ",", "float", "]", "=", "{", "}", "\n", "metrics", "[", "'_n_batches'", "]", "=", "self", ".", "n_batches", "\n", "metrics", "[", "'_n_samples'", "]", "=", "self", ".", "n_samples", "\n", "\n", "for", "key", ",", "value", "in", "self", ".", "sample_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_samples", "\n", "\n", "", "for", "key", ",", "value", "in", "self", ".", "batch_history", ".", "items", "(", ")", ":", "\n", "            ", "metrics", "[", "key", "]", "=", "value", "/", "self", ".", "n_batches", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "n_batches", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "sample_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "self", ".", "batch_history", ":", "Dict", "[", "str", ",", "float", "]", "=", "defaultdict", "(", "float", ")", "\n", "\n", "", "return", "metrics", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.__init__": [[23, 94], ["decoder_base.Decoder.__init__", "embedder.get_output_dim", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.layers.extend", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.register_buffer", "vocab.get_vocab_size", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "isinstance", "tell.modules.AdaptiveSoftmax", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "decoder_faces_objects.DynamicConvDecoderLayer", "hasattr", "tell.utils.eval_str_list", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.get_output_dim", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.options.eval_str_list"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ",", "embedder", ":", "TextFieldEmbedder", ",", "max_target_positions", ",", "dropout", ",", "\n", "share_decoder_input_output_embed", ",", "\n", "decoder_output_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "decoder_kernel_size_list", ",", "adaptive_softmax_cutoff", "=", "None", ",", "\n", "tie_adaptive_weights", "=", "False", ",", "adaptive_softmax_dropout", "=", "0", ",", "\n", "tie_adaptive_proj", "=", "False", ",", "adaptive_softmax_factor", "=", "0", ",", "decoder_layers", "=", "6", ",", "\n", "final_norm", "=", "True", ",", "padding_idx", "=", "0", ",", "namespace", "=", "'target_tokens'", ",", "\n", "vocab_size", "=", "None", ",", "section_attn", "=", "False", ",", "swap", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab", "=", "vocab", "\n", "vocab_size", "=", "vocab_size", "or", "vocab", ".", "get_vocab_size", "(", "namespace", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "share_input_output_embed", "=", "share_decoder_input_output_embed", "\n", "\n", "input_embed_dim", "=", "embedder", ".", "get_output_dim", "(", ")", "\n", "embed_dim", "=", "input_embed_dim", "\n", "output_embed_dim", "=", "input_embed_dim", "\n", "\n", "padding_idx", "=", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "max_target_positions", "\n", "\n", "self", ".", "embedder", "=", "embedder", "\n", "\n", "self", ".", "project_in_dim", "=", "GehringLinear", "(", "\n", "input_embed_dim", ",", "embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "input_embed_dim", "else", "None", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "DynamicConvDecoderLayer", "(", "embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "swap", ",", "\n", "kernel_size", "=", "decoder_kernel_size_list", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "decoder_layers", ")", "\n", "]", ")", "\n", "\n", "self", ".", "adaptive_softmax", "=", "None", "\n", "\n", "self", ".", "project_out_dim", "=", "GehringLinear", "(", "embed_dim", ",", "output_embed_dim", ",", "bias", "=", "False", ")", "if", "embed_dim", "!=", "output_embed_dim", "and", "not", "tie_adaptive_weights", "else", "None", "\n", "\n", "if", "adaptive_softmax_cutoff", "is", "not", "None", ":", "\n", "            ", "adaptive_inputs", "=", "None", "\n", "if", "isinstance", "(", "embedder", ",", "AdaptiveEmbedding", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", "\n", "", "elif", "hasattr", "(", "embedder", ",", "'token_embedder_adaptive'", ")", ":", "\n", "                ", "adaptive_inputs", "=", "embedder", ".", "token_embedder_adaptive", "\n", "", "elif", "tie_adaptive_weights", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot locate adaptive_inputs.'", ")", "\n", "", "self", ".", "adaptive_softmax", "=", "AdaptiveSoftmax", "(", "\n", "vocab_size", ",", "\n", "output_embed_dim", ",", "\n", "eval_str_list", "(", "adaptive_softmax_cutoff", ",", "type", "=", "int", ")", ",", "\n", "dropout", "=", "adaptive_softmax_dropout", ",", "\n", "adaptive_inputs", "=", "adaptive_inputs", ",", "\n", "factor", "=", "adaptive_softmax_factor", ",", "\n", "tie_proj", "=", "tie_adaptive_proj", ",", "\n", ")", "\n", "", "elif", "not", "self", ".", "share_input_output_embed", ":", "\n", "            ", "self", ".", "embed_out", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "Tensor", "(", "vocab_size", ",", "output_embed_dim", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "embed_out", ",", "mean", "=", "0", ",", "\n", "std", "=", "output_embed_dim", "**", "-", "0.5", ")", "\n", "", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "self", ".", "normalize", "=", "decoder_normalize_before", "and", "final_norm", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.forward": [[95, 143], ["decoder_faces_objects.DynamicConvFacesObjectsDecoder.embedder", "torch.dropout", "torch.dropout", "torch.dropout", "torch.linear.transpose", "enumerate", "torch.linear.transpose", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.project_in_dim", "attns.append", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.layer_norm", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.project_out_dim", "layer", "inner_states.append", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "prev_target", ",", "contexts", ",", "incremental_state", "=", "None", ",", "\n", "use_layers", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embed tokens and positions", "\n", "        ", "X", "=", "self", ".", "embedder", "(", "prev_target", ",", "incremental_state", "=", "incremental_state", ")", "\n", "\n", "# if incremental_state is not None:", "\n", "#     X = X[:, -1:]", "\n", "\n", "if", "self", ".", "project_in_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_in_dim", "(", "X", ")", "\n", "\n", "", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "attns", "=", "[", "]", "\n", "\n", "inner_states", "=", "[", "X", "]", "\n", "\n", "# decoder layers", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "not", "use_layers", "or", "i", "in", "use_layers", ":", "\n", "                ", "X", ",", "attn", "=", "layer", "(", "\n", "X", ",", "\n", "contexts", ",", "\n", "incremental_state", ",", "\n", ")", "\n", "inner_states", ".", "append", "(", "X", ")", "\n", "", "attns", ".", "append", "(", "attn", ")", "\n", "\n", "", "if", "self", ".", "normalize", ":", "\n", "            ", "X", "=", "self", ".", "layer_norm", "(", "X", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "X", "=", "X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "project_out_dim", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "project_out_dim", "(", "X", ")", "\n", "\n", "", "if", "self", ".", "adaptive_softmax", "is", "None", ":", "\n", "# project back to size of vocabulary", "\n", "            ", "if", "self", ".", "share_input_output_embed", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "\n", "X", ",", "self", ".", "embedder", ".", "token_embedder_bert", ".", "word_embeddings", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "X", "=", "F", ".", "linear", "(", "X", ",", "self", ".", "embed_out", ")", "\n", "\n", "", "", "return", "X", ",", "{", "'attn'", ":", "attns", ",", "'inner_states'", ":", "inner_states", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.max_positions": [[144, 147], ["None"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum output length supported by the decoder.\"\"\"", "\n", "return", "self", ".", "max_target_positions", "\n", "# return min(self.max_target_positions, self.embedder.max_positions())", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.buffered_future_mask": [[149, 159], ["tensor.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "decoder_faces_objects.DynamicConvFacesObjectsDecoder._future_mask.size", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "hasattr", "tell.utils.fill_with_neg_inf", "tell.utils.fill_with_neg_inf", "tensor.new", "decoder_faces_objects.DynamicConvFacesObjectsDecoder._future_mask.resize_"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.tensor.fill_with_neg_inf"], ["", "def", "buffered_future_mask", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "dim", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# pylint: disable=access-member-before-definition", "\n", "if", "not", "hasattr", "(", "self", ",", "'_future_mask'", ")", "or", "self", ".", "_future_mask", "is", "None", "or", "self", ".", "_future_mask", ".", "device", "!=", "tensor", ".", "device", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "\n", "fill_with_neg_inf", "(", "tensor", ".", "new", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "if", "self", ".", "_future_mask", ".", "size", "(", "0", ")", "<", "dim", ":", "\n", "            ", "self", ".", "_future_mask", "=", "torch", ".", "triu", "(", "fill_with_neg_inf", "(", "\n", "self", ".", "_future_mask", ".", "resize_", "(", "dim", ",", "dim", ")", ")", ",", "1", ")", "\n", "", "return", "self", ".", "_future_mask", "[", ":", "dim", ",", ":", "dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.get_normalized_probs": [[160, 174], ["net_output[].float", "hasattr", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.adaptive_softmax.get_log_prob", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax", "torch.softmax", "torch.softmax", "decoder_faces_objects.DynamicConvFacesObjectsDecoder.exp"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.softmax.AdaptiveSoftmax.get_log_prob", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.functional.softmax"], ["", "def", "get_normalized_probs", "(", "self", ",", "net_output", ",", "log_probs", ",", "sample", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get normalized probabilities (or log probs) from a net's output.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ",", "'adaptive_softmax'", ")", "and", "self", ".", "adaptive_softmax", "is", "not", "None", ":", "\n", "            ", "target", "=", "sample", "[", "'target'", "]", "if", "sample", "else", "None", "\n", "out", "=", "self", ".", "adaptive_softmax", ".", "get_log_prob", "(", "\n", "net_output", "[", "0", "]", ",", "target", ")", "\n", "return", "out", ".", "exp", "(", ")", "if", "not", "log_probs", "else", "out", "\n", "\n", "", "logits", "=", "net_output", "[", "0", "]", ".", "float", "(", ")", "\n", "if", "log_probs", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvFacesObjectsDecoder.filter_incremental_state": [[175, 181], ["None"], "methods", ["None"], ["", "", "def", "filter_incremental_state", "(", "self", ",", "incremental_state", ",", "active_idx", ")", ":", "\n", "        ", "if", "incremental_state", "is", "None", ":", "\n", "            ", "return", "\n", "", "for", "key", "in", "incremental_state", ":", "\n", "            ", "if", "'DynamicConv1dTBC'", "in", "key", ":", "\n", "                ", "incremental_state", "[", "key", "]", "=", "incremental_state", "[", "key", "]", "[", ":", ",", "active_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.__init__": [[185, 254], ["decoder_base.DecoderLayer.__init__", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.MultiHeadAttention", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "tell.modules.GehringLinear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "tell.modules.GehringLinear", "torch.GLU", "torch.GLU", "torch.GLU", "tell.modules.GehringLinear", "tell.modules.LightweightConv1dTBC", "tell.modules.DynamicConv1dTBC"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "decoder_embed_dim", ",", "decoder_conv_dim", ",", "decoder_glu", ",", "\n", "decoder_conv_type", ",", "weight_softmax", ",", "decoder_attention_heads", ",", "\n", "weight_dropout", ",", "dropout", ",", "relu_dropout", ",", "input_dropout", ",", "\n", "decoder_normalize_before", ",", "attention_dropout", ",", "decoder_ffn_embed_dim", ",", "\n", "swap", ",", "kernel_size", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "decoder_embed_dim", "\n", "self", ".", "conv_dim", "=", "decoder_conv_dim", "\n", "if", "decoder_glu", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "2", "*", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "nn", ".", "GLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linear1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "conv_dim", ")", "\n", "self", ".", "act", "=", "None", "\n", "", "if", "decoder_conv_type", "==", "'lightweight'", ":", "\n", "            ", "self", ".", "conv", "=", "LightweightConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "elif", "decoder_conv_type", "==", "'dynamic'", ":", "\n", "            ", "self", ".", "conv", "=", "DynamicConv1dTBC", "(", "self", ".", "conv_dim", ",", "kernel_size", ",", "padding_l", "=", "kernel_size", "-", "1", ",", "\n", "weight_softmax", "=", "weight_softmax", ",", "\n", "num_heads", "=", "decoder_attention_heads", ",", "\n", "weight_dropout", "=", "weight_dropout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "linear2", "=", "GehringLinear", "(", "self", ".", "conv_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "input_dropout", "=", "input_dropout", "\n", "self", ".", "normalize_before", "=", "decoder_normalize_before", "\n", "\n", "self", ".", "conv_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "context_attn_lns", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "C", "=", "2048", "\n", "\n", "self", ".", "context_attns", "[", "'image'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "C", ",", "vdim", "=", "C", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'article'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "1024", ",", "vdim", "=", "1024", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'faces'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "512", ",", "vdim", "=", "512", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "context_attns", "[", "'obj'", "]", "=", "MultiHeadAttention", "(", "\n", "self", ".", "embed_dim", ",", "decoder_attention_heads", ",", "kdim", "=", "2048", ",", "vdim", "=", "2048", ",", "\n", "dropout", "=", "attention_dropout", ")", "\n", "self", ".", "context_attn_lns", "[", "'obj'", "]", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "\n", "context_size", "=", "self", ".", "embed_dim", "*", "4", "\n", "\n", "self", ".", "context_fc", "=", "GehringLinear", "(", "context_size", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "fc1", "=", "GehringLinear", "(", "self", ".", "embed_dim", ",", "decoder_ffn_embed_dim", ")", "\n", "self", ".", "fc2", "=", "GehringLinear", "(", "decoder_ffn_embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "final_layer_norm", "=", "nn", ".", "LayerNorm", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "need_attn", "=", "True", "\n", "self", ".", "swap", "=", "swap", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.forward": [[255, 366], ["decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.linear1", "decoder_faces_objects.DynamicConvDecoderLayer.conv", "decoder_faces_objects.DynamicConvDecoderLayer.linear2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "X_contexts.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder_faces_objects.DynamicConvDecoderLayer.context_fc", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "decoder_faces_objects.DynamicConvDecoderLayer.act", "attn.cpu().detach().numpy", "attn.cpu().detach().numpy", "attn.cpu().detach().numpy", "attn.cpu().detach().numpy", "decoder_faces_objects.DynamicConvDecoderLayer.fc1", "attn.cpu().detach", "attn.cpu().detach", "attn.cpu().detach", "attn.cpu().detach", "attn.cpu", "attn.cpu", "attn.cpu", "attn.cpu"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm"], ["", "def", "forward", "(", "self", ",", "X", ",", "contexts", ",", "incremental_state", ")", ":", "\n", "        ", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "input_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "linear1", "(", "X", ")", "\n", "if", "self", ".", "act", "is", "not", "None", ":", "\n", "            ", "X", "=", "self", ".", "act", "(", "X", ")", "\n", "", "X", "=", "self", ".", "conv", "(", "X", ",", "incremental_state", "=", "incremental_state", ")", "\n", "X", "=", "self", ".", "linear2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "conv_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "\n", "attns", "=", "{", "}", "\n", "X_contexts", "=", "[", "]", "\n", "\n", "# Image attention", "\n", "residual", "=", "X", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_image", ",", "attn", "=", "self", ".", "context_attns", "[", "'image'", "]", "(", "\n", "query", "=", "X_image", ",", "\n", "key", "=", "contexts", "[", "'image'", "]", ",", "\n", "value", "=", "contexts", "[", "'image'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'image_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_image", "=", "F", ".", "dropout", "(", "X_image", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X_image", "=", "residual", "+", "X_image", "\n", "X_image", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'image'", "]", ",", "X_image", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_image", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "'image'", "]", "=", "attn", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Article attention", "\n", "", "residual", "=", "X", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_article", ",", "attn", "=", "self", ".", "context_attns", "[", "'article'", "]", "(", "\n", "query", "=", "X_article", ",", "\n", "key", "=", "contexts", "[", "'article'", "]", ",", "\n", "value", "=", "contexts", "[", "'article'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'article_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_article", "=", "F", ".", "dropout", "(", "X_article", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_article", "=", "residual", "+", "X_article", "\n", "X_article", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'article'", "]", ",", "X_article", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_article", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "'article'", "]", "=", "attn", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Face attention", "\n", "", "residual", "=", "X", "\n", "X_faces", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_faces", ",", "attn", "=", "self", ".", "context_attns", "[", "'faces'", "]", "(", "\n", "query", "=", "X_faces", ",", "\n", "key", "=", "contexts", "[", "'faces'", "]", ",", "\n", "value", "=", "contexts", "[", "'faces'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'faces_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_faces", "=", "F", ".", "dropout", "(", "X_faces", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_faces", "=", "residual", "+", "X_faces", "\n", "X_faces", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'faces'", "]", ",", "X_faces", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_faces", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "'faces'", "]", "=", "attn", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Object attention", "\n", "", "residual", "=", "X", "\n", "X_objs", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'obj'", "]", ",", "X", ",", "before", "=", "True", ")", "\n", "X_objs", ",", "attn", "=", "self", ".", "context_attns", "[", "'obj'", "]", "(", "\n", "query", "=", "X_objs", ",", "\n", "key", "=", "contexts", "[", "'obj'", "]", ",", "\n", "value", "=", "contexts", "[", "'obj'", "]", ",", "\n", "key_padding_mask", "=", "contexts", "[", "'obj_mask'", "]", ",", "\n", "incremental_state", "=", "None", ",", "\n", "static_kv", "=", "True", ",", "\n", "need_weights", "=", "(", "not", "self", ".", "training", "and", "self", ".", "need_attn", ")", ")", "\n", "X_objs", "=", "F", ".", "dropout", "(", "X_objs", ",", "p", "=", "self", ".", "dropout", ",", "\n", "training", "=", "self", ".", "training", ")", "\n", "X_objs", "=", "residual", "+", "X_objs", "\n", "X_objs", "=", "self", ".", "maybe_layer_norm", "(", "\n", "self", ".", "context_attn_lns", "[", "'obj'", "]", ",", "X_objs", ",", "after", "=", "True", ")", "\n", "X_contexts", ".", "append", "(", "X_objs", ")", "\n", "if", "attn", "is", "not", "None", ":", "\n", "            ", "attns", "[", "'obj'", "]", "=", "attn", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "X_context", "=", "torch", ".", "cat", "(", "X_contexts", ",", "dim", "=", "-", "1", ")", "\n", "X", "=", "self", ".", "context_fc", "(", "X_context", ")", "\n", "\n", "residual", "=", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "before", "=", "True", ")", "\n", "X", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "X", ")", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "self", ".", "fc2", "(", "X", ")", "\n", "X", "=", "F", ".", "dropout", "(", "X", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "X", "=", "residual", "+", "X", "\n", "X", "=", "self", ".", "maybe_layer_norm", "(", "self", ".", "final_layer_norm", ",", "X", ",", "after", "=", "True", ")", "\n", "return", "X", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.maybe_layer_norm": [[367, 373], ["layer_norm"], "methods", ["None"], ["", "def", "maybe_layer_norm", "(", "self", ",", "layer_norm", ",", "X", ",", "before", "=", "False", ",", "after", "=", "False", ")", ":", "\n", "        ", "assert", "before", "^", "after", "\n", "if", "after", "^", "self", ".", "normalize_before", ":", "\n", "            ", "return", "layer_norm", "(", "X", ")", "\n", "", "else", ":", "\n", "            ", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.make_generation_fast_": [[374, 376], ["None"], "methods", ["None"], ["", "", "def", "make_generation_fast_", "(", "self", ",", "need_attn", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "need_attn", "=", "need_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.decoder_faces_objects.DynamicConvDecoderLayer.extra_repr": [[377, 380], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'dropout={}, relu_dropout={}, input_dropout={}, normalize_before={}'", ".", "format", "(", "\n", "self", ".", "dropout", ",", "self", ".", "relu_dropout", ",", "self", ".", "input_dropout", ",", "self", ".", "normalize_before", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.__init__": [[15, 81], ["zmq.Context", "base.TellClient.context.socket", "base.TellClient.sender.setsockopt", "base.TellClient.sender.connect", "base.TellClient.context.socket", "base.TellClient.receiver.setsockopt", "base.TellClient.receiver.setsockopt", "base.TellClient.receiver.connect", "set", "str().encode", "AttributeError", "base.TellClient._print_dict", "str", "uuid.uuid4"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._print_dict"], ["\n", "from", "tell", ".", "tasks", "import", "WorkerRegistry", "\n", "\n", "from", ".", "utils", "import", "ServerCmd", ",", "auto_bind", ",", "set_logger", "\n", "from", ".", "zmq_decor", "import", "multi_socket", "\n", "\n", "__version__", "=", "'0.0.1'", "\n", "\n", "# See https://stackoverflow.com/a/48938860", "\n", "try", ":", "\n", "    ", "set_start_method", "(", "'spawn'", ")", "\n", "", "except", "RuntimeError", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "class", "NLPServer", "(", "threading", ".", "Thread", ")", ":", "\n", "    ", "\"\"\"For connecting two processes in the same server it is considered that IPC is the fastest option\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "port", "=", "5558", ",", "port_out", "=", "5559", ",", "n_workers", "=", "1", ",", "verbose", "=", "False", ",", "\n", "max_batch_size", "=", "32", ",", "task", "=", "'coref'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'VENTILATOR'", ",", "'magenta'", ")", ",", "verbose", ")", "\n", "self", ".", "port", "=", "port", "\n", "self", ".", "port_out", "=", "port_out", "\n", "self", ".", "processes", "=", "[", "]", "\n", "self", ".", "is_ready", "=", "threading", ".", "Event", "(", ")", "\n", "self", ".", "n_workers", "=", "n_workers", "\n", "self", ".", "n_concurrent_sockets", "=", "max", "(", "8", ",", "n_workers", "*", "2", ")", "\n", "self", ".", "max_batch_size", "=", "max_batch_size", "\n", "self", ".", "status_static", "=", "{", "\n", "'python_version'", ":", "sys", ".", "version", ",", "\n", "'server_version'", ":", "__version__", ",", "\n", "'pyzmq_version'", ":", "zmq", ".", "pyzmq_version", "(", ")", ",", "\n", "'zmq_version'", ":", "zmq", ".", "zmq_version", "(", ")", ",", "\n", "'server_start_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "}", "\n", "self", ".", "Worker", "=", "WorkerRegistry", "[", "task", "]", "\n", "\n", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start", "(", ")", "\n", "self", ".", "is_ready", ".", "wait", "(", ")", "\n", "return", "self", "\n", "\n", "", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_value", ",", "traceback", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'shutting down...'", ")", "\n", "self", ".", "_send_close_signal", "(", ")", "\n", "self", ".", "is_ready", ".", "clear", "(", ")", "\n", "self", ".", "join", "(", ")", "\n", "\n", "", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PUSH", ")", "\n", "def", "_send_close_signal", "(", "self", ",", "_", ",", "frontend", ")", ":", "\n", "        ", "frontend", ".", "connect", "(", "'tcp://localhost:%d'", "%", "self", ".", "port", ")", "\n", "frontend", ".", "send_multipart", "(", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "shutdown", "(", "args", ")", ":", "\n", "        ", "with", "zmq", ".", "Context", "(", ")", "as", "ctx", ":", "\n", "            ", "ctx", ".", "setsockopt", "(", "zmq", ".", "LINGER", ",", "args", ".", "timeout", ")", "\n", "with", "ctx", ".", "socket", "(", "zmq", ".", "PUSH", ")", "as", "frontend", ":", "\n", "                ", "try", ":", "\n", "                    ", "frontend", ".", "connect", "(", "'tcp://%s:%d'", "%", "(", "args", ".", "ip", ",", "args", ".", "port", ")", ")", "\n", "frontend", ".", "send_multipart", "(", "\n", "[", "b''", ",", "ServerCmd", ".", "terminate", ",", "b''", ",", "b''", "]", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close": [[82, 90], ["base.TellClient.sender.close", "base.TellClient.receiver.close", "base.TellClient.context.term"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close"], ["print", "(", "'shutdown signal sent to %d'", "%", "args", ".", "port", ")", "\n", "", "except", "zmq", ".", "error", ".", "Again", ":", "\n", "                    ", "raise", "TimeoutError", "(", "\n", "'no response from the server (with \"timeout\"=%d ms), please check the following:'", "\n", "'is the server still online? is the network broken? are \"port\" correct? '", "%", "args", ".", "timeout", ")", "\n", "\n", "", "", "", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "_run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._send": [[91, 97], ["base.TellClient.sender.send_multipart", "base.TellClient.pending_request.add"], "methods", ["None"], ["", "@", "zmqd", ".", "context", "(", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PULL", ")", "\n", "@", "zmqd", ".", "socket", "(", "zmq", ".", "PAIR", ")", "\n", "@", "multi_socket", "(", "zmq", ".", "PUSH", ",", "num_socket", "=", "'n_concurrent_sockets'", ")", "\n", "def", "_run", "(", "self", ",", "_", ",", "frontend", ",", "sink", ",", "*", "backend_socks", ")", ":", "\n", "\n", "        ", "def", "push_new_job", "(", "_job_id", ",", "_json_msg", ",", "_msg_len", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._recv": [[98, 122], ["base.TellClient.receiver.recv_multipart", "int", "base.TellClient.pending_request.remove", "base.TellClient.pending_response.pop", "_Response", "base.TellClient.pending_request.remove", "_Response"], "methods", ["None"], ["            ", "_sock", "=", "rand_backend_socket", "\n", "_sock", ".", "send_multipart", "(", "[", "_job_id", ",", "_json_msg", "]", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "f'Bind all sockets. Use ports '", "\n", "f'{self.port}/{self.port_out}'", ")", "\n", "frontend", ".", "bind", "(", "f'tcp://*:{self.port}'", ")", "\n", "addr_front2sink", "=", "auto_bind", "(", "sink", ")", "\n", "addr_backend_list", "=", "[", "auto_bind", "(", "b", ")", "for", "b", "in", "backend_socks", "]", "\n", "self", ".", "logger", ".", "info", "(", "f'open {len(addr_backend_list)} ventilator-worker '", "\n", "'sockets'", ")", "\n", "\n", "self", ".", "logger", ".", "info", "(", "'Start the sink'", ")", "\n", "proc_sink", "=", "Sink", "(", "self", ".", "port_out", ",", "addr_front2sink", ")", "\n", "self", ".", "processes", ".", "append", "(", "proc_sink", ")", "\n", "proc_sink", ".", "start", "(", ")", "\n", "addr_sink", "=", "sink", ".", "recv", "(", ")", ".", "decode", "(", "'ascii'", ")", "\n", "\n", "# start the backend processes", "\n", "device_map", "=", "[", "-", "1", "]", "*", "self", ".", "n_workers", "\n", "for", "idx", ",", "device_id", "in", "enumerate", "(", "device_map", ")", ":", "\n", "            ", "process", "=", "self", ".", "Worker", "(", "idx", ",", "addr_backend_list", ",", "addr_sink", ")", "\n", "self", ".", "processes", ".", "append", "(", "process", ")", "\n", "process", ".", "start", "(", ")", "\n", "\n", "", "rand_backend_socket", "=", "None", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._timeout": [[123, 145], ["functools.wraps", "base.TellClient.receiver.setsockopt", "base.TellClient.receiver.setsockopt", "func", "base.TellClient.receiver.setsockopt", "TimeoutError"], "methods", ["None"], ["server_status", "=", "ServerStatistic", "(", ")", "\n", "\n", "for", "p", "in", "self", ".", "processes", ":", "\n", "            ", "p", ".", "is_ready", ".", "wait", "(", ")", "\n", "\n", "", "self", ".", "is_ready", ".", "set", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'all set, ready to serve request!'", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "request", "=", "frontend", ".", "recv_multipart", "(", ")", "\n", "client", ",", "msg", ",", "req_id", ",", "msg_len", "=", "request", "\n", "", "except", "ValueError", ":", "\n", "                ", "self", ".", "logger", ".", "error", "(", "\n", "'received a wrongly-formatted request (expected 4 frames, got %d)'", "%", "len", "(", "request", ")", ")", "\n", "self", ".", "logger", ".", "error", "(", "'\\n'", ".", "join", "(", "'field %d: %s'", "%", "(", "idx", ",", "k", ")", "\n", "for", "idx", ",", "k", "in", "enumerate", "(", "request", ")", ")", ",", "exc_info", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "server_status", ".", "update", "(", "request", ")", "\n", "if", "msg", "==", "ServerCmd", ".", "terminate", ":", "\n", "                    ", "break", "\n", "", "elif", "msg", "==", "ServerCmd", ".", "show_config", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.status": [[146, 166], ["len"], "methods", ["None"], ["'new config request\\treq id: %d\\tclient: %s'", "%", "(", "int", "(", "req_id", ")", ",", "client", ")", ")", "\n", "status_runtime", "=", "{", "'client'", ":", "client", ".", "decode", "(", "'ascii'", ")", ",", "\n", "'num_process'", ":", "len", "(", "self", ".", "processes", ")", ",", "\n", "'ventilator -> worker'", ":", "addr_backend_list", ",", "\n", "'worker -> sink'", ":", "addr_sink", ",", "\n", "'ventilator <-> sink'", ":", "addr_front2sink", ",", "\n", "'server_current_time'", ":", "str", "(", "datetime", ".", "now", "(", ")", ")", ",", "\n", "'statistic'", ":", "server_status", ".", "value", ",", "\n", "'device_map'", ":", "device_map", ",", "\n", "'n_concurrent_sockets'", ":", "self", ".", "n_concurrent_sockets", "}", "\n", "\n", "sink", ".", "send_multipart", "(", "[", "client", ",", "msg", ",", "jsonapi", ".", "dumps", "(", "{", "**", "status_runtime", ",", "\n", "**", "self", ".", "status_static", "}", ")", ",", "req_id", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "'new encode request\\treq id: %d\\tsize: %d\\tclient: %s'", "%", "\n", "(", "int", "(", "req_id", ")", ",", "int", "(", "msg_len", ")", ",", "client", ")", ")", "\n", "# register a new job at sink", "\n", "sink", ".", "send_multipart", "(", "\n", "[", "client", ",", "ServerCmd", ".", "new_job", ",", "msg_len", ",", "req_id", "]", ")", "\n", "\n", "# renew the backend socket to prevent large job queueing up", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.server_status": [[168, 181], ["base.TellClient._send", "zmq.utils.jsonapi.loads", "base.TellClient._recv"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._send", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._recv"], ["# last used backennd shouldn't be selected either as it may be queued up already", "\n", "rand_backend_socket", "=", "random", ".", "choice", "(", "\n", "[", "b", "for", "b", "in", "backend_socks", "[", "1", ":", "]", "if", "b", "!=", "rand_backend_socket", "]", ")", "\n", "\n", "# push a new job, note super large job will be pushed to one socket only,", "\n", "# leaving other sockets free", "\n", "job_id", "=", "client", "+", "b'#'", "+", "req_id", "\n", "if", "int", "(", "msg_len", ")", ">", "self", ".", "max_batch_size", ":", "\n", "                        ", "seqs", "=", "jsonapi", ".", "loads", "(", "msg", ")", "\n", "job_gen", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "int", "(", "msg_len", ")", ",", "self", ".", "max_batch_size", ")", ":", "\n", "                            ", "pid", "=", "job_id", "+", "b'@%d'", "%", "i", "\n", "pjob", "=", "seqs", "[", "i", ":", "(", "i", "+", "self", ".", "max_batch_size", ")", "]", "\n", "job_gen", ".", "append", "(", "(", "pid", ",", "pjob", ")", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.parse": [[182, 194], ["base.TellClient._send", "base.TellClient._recv", "zmq.utils.jsonapi.loads", "zmq.utils.jsonapi.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._send", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._recv"], ["\n", "", "for", "partial_job_id", ",", "job", "in", "job_gen", ":", "\n", "                            ", "push_new_job", "(", "partial_job_id", ",", "\n", "jsonapi", ".", "dumps", "(", "job", ")", ",", "len", "(", "job", ")", ")", "\n", "", "", "else", ":", "\n", "                        ", "push_new_job", "(", "job_id", ",", "msg", ",", "int", "(", "msg_len", ")", ")", "\n", "\n", "", "", "", "", "for", "p", "in", "self", ".", "processes", ":", "\n", "            ", "p", ".", "close", "(", ")", "\n", "", "self", ".", "logger", ".", "info", "(", "'terminated!'", ")", "\n", "\n", "\n", "", "", "class", "Sink", "(", "Process", ")", ":", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.fetch": [[195, 200], ["base.TellClient._recv", "zmq.utils.jsonapi.loads"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._recv"], ["    ", "def", "__init__", "(", "self", ",", "port_out", ",", "front_sink_addr", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "port", "=", "port_out", "\n", "self", ".", "exit_flag", "=", "Event", "(", ")", "\n", "self", ".", "logger", "=", "set_logger", "(", "colored", "(", "'SINK'", ",", "'green'", ")", ",", "verbose", ")", "\n", "self", ".", "front_sink_addr", "=", "front_sink_addr", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._print_dict": [[201, 207], ["x.items", "print", "print"], "methods", ["None"], ["self", ".", "is_ready", "=", "Event", "(", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "'shutting down...'", ")", "\n", "self", ".", "is_ready", ".", "clear", "(", ")", "\n", "self", ".", "exit_flag", ".", "set", "(", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.__enter__": [[208, 210], ["None"], "methods", ["None"], ["self", ".", "terminate", "(", ")", "\n", "self", ".", "join", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "'terminated!'", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.__exit__": [[211, 213], ["base.TellClient.close"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close"], ["\n", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "_run", "(", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.caption.CaptioningClient.parse": [[8, 19], ["caption.CaptioningClient._send", "caption.CaptioningClient._recv", "zmq.utils.jsonapi.loads", "zmq.utils.jsonapi.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._send", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient._recv"], ["    ", "@", "overrides", "\n", "@", "TellClient", ".", "_timeout", "\n", "def", "parse", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Parse a text.\n\n        Overwrite this method in subclasses for different NLP tasks.\n        \"\"\"", "\n", "request_id", "=", "self", ".", "_send", "(", "jsonapi", ".", "dumps", "(", "inputs", ")", ",", "len", "(", "inputs", ")", ")", "\n", "request_id", ",", "response", "=", "self", ".", "_recv", "(", "request_id", ")", "\n", "client_id", ",", "output", ",", "request_id", "=", "response", "\n", "return", "jsonapi", ".", "loads", "(", "output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.data.vocabulary._RobertaTokenToIndexDefaultDict.__init__": [[12, 18], ["allennlp.data.vocabulary._NamespaceDependentDefaultDict.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "non_padded_namespaces", ":", "Set", "[", "str", "]", ",", "padding_token", ":", "str", ",", "\n", "oov_token", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "non_padded_namespaces", ",", "\n", "lambda", ":", "{", "padding_token", ":", "1", ",", "\n", "oov_token", ":", "3", "}", ",", "\n", "lambda", ":", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.data.vocabulary._RobertaIndexToTokenDefaultDict.__init__": [[21, 27], ["allennlp.data.vocabulary._NamespaceDependentDefaultDict.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "non_padded_namespaces", ":", "Set", "[", "str", "]", ",", "padding_token", ":", "str", ",", "\n", "oov_token", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "non_padded_namespaces", ",", "\n", "lambda", ":", "{", "1", ":", "padding_token", ",", "\n", "3", ":", "oov_token", "}", ",", "\n", "lambda", ":", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.data.vocabulary.RobertaVocabulary.__init__": [[37, 67], ["set", "vocabulary._RobertaTokenToIndexDefaultDict", "vocabulary._RobertaIndexToTokenDefaultDict", "vocabulary.RobertaVocabulary._extend"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "min_count", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "max_vocab_size", ":", "Union", "[", "int", ",", "Dict", "[", "str", ",", "int", "]", "]", "=", "None", ",", "\n", "non_padded_namespaces", ":", "Iterable", "[", "str", "]", "=", "DEFAULT_NON_PADDED_NAMESPACES", ",", "\n", "pretrained_files", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", "only_include_pretrained_words", ":", "bool", "=", "False", ",", "\n", "tokens_to_add", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "min_pretrained_embeddings", ":", "Dict", "[", "str", ",", "int", "]", "=", "None", ",", "\n", "padding_token", ":", "str", "=", "'<pad>'", ",", "\n", "oov_token", ":", "str", "=", "'<unk>'", ")", "->", "None", ":", "\n", "        ", "self", ".", "_padding_token", "=", "padding_token", "\n", "self", ".", "_oov_token", "=", "oov_token", "\n", "self", ".", "_non_padded_namespaces", "=", "set", "(", "non_padded_namespaces", ")", "\n", "self", ".", "_token_to_index", "=", "_RobertaTokenToIndexDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_index_to_token", "=", "_RobertaIndexToTokenDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_retained_counter", ":", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", "]", "=", "None", "\n", "# Made an empty vocabulary, now extend it.", "\n", "self", ".", "_extend", "(", "counter", ",", "\n", "min_count", ",", "\n", "max_vocab_size", ",", "\n", "non_padded_namespaces", ",", "\n", "pretrained_files", ",", "\n", "only_include_pretrained_words", ",", "\n", "tokens_to_add", ",", "\n", "min_pretrained_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.data.vocabulary.RobertaVocabulary._load_bert_vocab": [[68, 77], ["transformers.tokenization_bert.load_vocab", "vocab.items", "print", "type"], "methods", ["None"], ["", "def", "_load_bert_vocab", "(", "self", ",", "vocab_path", ",", "namespace", ")", ":", "\n", "        ", "vocab", ":", "Dict", "[", "str", ",", "int", "]", "=", "load_vocab", "(", "vocab_path", ")", "\n", "for", "word", ",", "idx", "in", "vocab", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_token_to_index", "[", "namespace", "]", "[", "word", "]", "=", "idx", "\n", "self", ".", "_index_to_token", "[", "namespace", "]", "[", "idx", "]", "=", "word", "\n", "", "except", ":", "\n", "                ", "print", "(", "word", ",", "type", "(", "word", ")", ",", "idx", ")", "\n", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.data.vocabulary.RobertaVocabulary.__setstate__": [[78, 95], ["copy.copy", "vocabulary._RobertaTokenToIndexDefaultDict", "vocabulary.RobertaVocabulary._token_to_index.update", "vocabulary._RobertaIndexToTokenDefaultDict", "vocabulary.RobertaVocabulary._index_to_token.update"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "", "", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Conversely, when we unpickle, we need to reload the plain dicts\n        into our special DefaultDict subclasses.\n        \"\"\"", "\n", "# pylint: disable=attribute-defined-outside-init", "\n", "self", ".", "__dict__", "=", "copy", ".", "copy", "(", "state", ")", "\n", "self", ".", "_token_to_index", "=", "_RobertaTokenToIndexDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_token_to_index", ".", "update", "(", "state", "[", "\"_token_to_index\"", "]", ")", "\n", "self", ".", "_index_to_token", "=", "_RobertaIndexToTokenDefaultDict", "(", "self", ".", "_non_padded_namespaces", ",", "\n", "self", ".", "_padding_token", ",", "\n", "self", ".", "_oov_token", ")", "\n", "self", ".", "_index_to_token", ".", "update", "(", "state", "[", "\"_index_to_token\"", "]", ")", "\n", "\n", "return", "vocab", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.tokenizers.word_splitter.JustSpacesKeepNewlinesWordSplitter.split_words": [[19, 22], ["allennlp.data.tokenizers.token.Token", "sentence.split"], "methods", ["None"], ["@", "overrides", "\n", "def", "split_words", "(", "self", ",", "sentence", ":", "str", ")", "->", "List", "[", "Token", "]", ":", "\n", "        ", "return", "[", "Token", "(", "t", ")", "for", "t", "in", "sentence", ".", "split", "(", "' '", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.__init__": [[35, 56], ["super().__init__", "torch.hub.load"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "legacy", ":", "bool", "=", "False", ",", "\n", "start_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "end_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "token_min_padding_length", ":", "int", "=", "0", ",", "\n", "padding_on_right", ":", "bool", "=", "True", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "max_len", ":", "int", "=", "512", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "token_min_padding_length", ")", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "source_dictionary", "=", "roberta", ".", "task", ".", "source_dictionary", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", ".", "bpe", "\n", "self", ".", "bpe_legacy", "=", "roberta", ".", "bpe", "\n", "self", ".", "_added_to_vocabulary", "=", "False", "\n", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_padding_on_right", "=", "padding_on_right", "\n", "self", ".", "_padding_value", "=", "padding_value", "\n", "self", ".", "_max_len", "=", "max_len", "\n", "self", ".", "legacy", "=", "legacy", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.count_vocab_items": [[57, 61], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If we only use pretrained models, we don't need to do anything here.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer._add_encoding_to_vocabulary": [[62, 66], ["roberta_indexer.RobertaTokenIndexer.source_dictionary.indices.items"], "methods", ["None"], ["", "def", "_add_encoding_to_vocabulary", "(", "self", ",", "vocabulary", ":", "Vocabulary", ")", "->", "None", ":", "\n", "        ", "for", "piece", ",", "idx", "in", "self", ".", "source_dictionary", ".", "indices", ".", "items", "(", ")", ":", "\n", "            ", "vocabulary", ".", "_token_to_index", "[", "self", ".", "_namespace", "]", "[", "piece", "]", "=", "idx", "\n", "vocabulary", ".", "_index_to_token", "[", "self", ".", "_namespace", "]", "[", "idx", "]", "=", "piece", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.tokens_to_indices": [[67, 87], ["roberta_indexer.RobertaTokenIndexer._add_encoding_to_vocabulary", "roberta_indexer.RobertaTokenIndexer.encode", "roberta_indexer.RobertaTokenIndexer.encode"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._add_encoding_to_vocabulary", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ",", "\n", "doc", ":", "Doc", "=", "None", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_added_to_vocabulary", ":", "\n", "            ", "self", ".", "_add_encoding_to_vocabulary", "(", "vocabulary", ")", "\n", "self", ".", "_added_to_vocabulary", "=", "True", "\n", "\n", "", "text", "=", "' '", ".", "join", "(", "[", "token", ".", "text", "for", "token", "in", "tokens", "]", ")", "\n", "if", "self", ".", "legacy", ":", "\n", "            ", "indices", "=", "self", ".", "encode", "(", "text", ",", "doc", ")", "\n", "copy_masks", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "indices", ",", "copy_masks", "=", "self", ".", "encode", "(", "text", ",", "doc", ")", "\n", "\n", "", "return", "{", "\n", "index_name", ":", "indices", ",", "\n", "f'{index_name}_copy_masks'", ":", "copy_masks", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.encode": [[89, 110], ["roberta_indexer.RobertaTokenIndexer._byte_pair_encode", "roberta_indexer.tokenize_line", "roberta_indexer.RobertaTokenIndexer.encode_legacy", "map", "len", "len", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._byte_pair_encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.encode_legacy"], ["", "def", "encode", "(", "self", ",", "sentence", ",", "doc", ")", ":", "\n", "        ", "if", "self", ".", "legacy", ":", "\n", "            ", "return", "self", ".", "encode_legacy", "(", "sentence", ")", "\n", "\n", "", "bpe_tokens", ",", "copy_masks", "=", "self", ".", "_byte_pair_encode", "(", "sentence", ",", "doc", ")", "\n", "sentence", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "bpe_tokens", ")", ")", "\n", "words", "=", "tokenize_line", "(", "sentence", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "copy_masks", ")", "\n", "\n", "# Enforce maximum length constraint", "\n", "words", "=", "words", "[", ":", "self", ".", "_max_len", "-", "2", "]", "\n", "copy_masks", "=", "copy_masks", "[", ":", "self", ".", "_max_len", "-", "2", "]", "\n", "words", "=", "[", "'<s>'", "]", "+", "words", "+", "[", "'</s>'", "]", "\n", "copy_masks", "=", "[", "0", "]", "+", "copy_masks", "+", "[", "0", "]", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "source_dictionary", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "\n", "", "return", "token_ids", ",", "copy_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.encode_legacy": [[111, 116], ["roberta_indexer.RobertaTokenIndexer.source_dictionary.encode_line", "roberta_indexer.RobertaTokenIndexer.long().tolist", "roberta_indexer.RobertaTokenIndexer.bpe_legacy.encode", "roberta_indexer.RobertaTokenIndexer.long"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "def", "encode_legacy", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "bpe_sentence", "=", "'<s> '", "+", "self", ".", "bpe_legacy", ".", "encode", "(", "sentence", ")", "+", "' </s>'", "\n", "tokens", "=", "self", ".", "source_dictionary", ".", "encode_line", "(", "\n", "bpe_sentence", ",", "append_eos", "=", "False", ")", "\n", "return", "tokens", ".", "long", "(", ")", ".", "tolist", "(", ")", "[", ":", "self", ".", "_max_len", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer._byte_pair_encode": [[117, 148], ["roberta_indexer.RobertaTokenIndexer.bpe.re.findall", "roberta_indexer.RobertaTokenIndexer.get_entity_mask", "zip", "bpe_tokens.extend", "bpe_copy_masks.extend", "bpe_copy_masks.extend", "roberta_indexer.RobertaTokenIndexer.bpe.bpe().split", "raw_token.encode", "len", "len", "roberta_indexer.RobertaTokenIndexer.bpe.bpe"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.get_entity_mask", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "def", "_byte_pair_encode", "(", "self", ",", "text", ",", "doc", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "bpe_copy_masks", "=", "[", "]", "\n", "\n", "raw_tokens", "=", "self", ".", "bpe", ".", "re", ".", "findall", "(", "self", ".", "bpe", ".", "pat", ",", "text", ")", "\n", "# e.g.[' Tomas', ' Maier', ',', ' autumn', '/', 'winter', ' 2014', ',', '\\n', ' in', 'Milan', '.']", "\n", "\n", "copy_masks", "=", "self", ".", "get_entity_mask", "(", "raw_tokens", ",", "doc", ")", "\n", "# Same length as raw_tokens", "\n", "\n", "for", "raw_token", ",", "entity_mask", "in", "zip", "(", "raw_tokens", ",", "copy_masks", ")", ":", "\n", "# e.g. raw_token == \" Tomas\"", "\n", "\n", "# I guess this step is used so that we can distinguish between", "\n", "# the space separator and the space character.", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "bpe", ".", "byte_encoder", "[", "b", "]", "\n", "for", "b", "in", "raw_token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "# e.g. token == \"\u0120Tomas\"", "\n", "\n", "token_ids", "=", "[", "self", ".", "bpe", ".", "encoder", "[", "bpe_token", "]", "\n", "for", "bpe_token", "in", "self", ".", "bpe", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", "\n", "# e.g. token_ids == [6669, 959]", "\n", "\n", "bpe_tokens", ".", "extend", "(", "token_ids", ")", "\n", "\n", "if", "entity_mask", "==", "0", ":", "\n", "                ", "bpe_copy_masks", ".", "extend", "(", "[", "0", "]", "*", "len", "(", "token_ids", ")", ")", "\n", "", "else", ":", "\n", "                ", "bpe_copy_masks", ".", "extend", "(", "[", "1", "]", "*", "len", "(", "token_ids", ")", ")", "\n", "\n", "", "", "return", "bpe_tokens", ",", "bpe_copy_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.get_entity_mask": [[149, 179], ["starts.append", "len", "ends.append", "len", "enumerate", "zip"], "methods", ["None"], ["", "def", "get_entity_mask", "(", "self", ",", "tokens", ",", "doc", ")", ":", "\n", "# We first compute the start and end points for each token.", "\n", "# End points are exclusive.", "\n", "# e.g. tokens = [' Tomas', ' Maier', ',', ' autumn', '/', 'winter', ' 2014', ',', '\\n', ' in', 'Milan', '.']", "\n", "        ", "starts", "=", "[", "]", "\n", "ends", "=", "[", "]", "\n", "current", "=", "0", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "starts", ".", "append", "(", "current", ")", "\n", "current", "+=", "len", "(", "token", ")", "\n", "ends", ".", "append", "(", "current", ")", "\n", "\n", "", "copy_masks", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "doc", "is", "None", ":", "\n", "            ", "return", "copy_masks", "\n", "\n", "# Next we get the character positions of named entities", "\n", "", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "# A token is part of an entity if it lies strictly inside it", "\n", "            ", "for", "i", ",", "(", "start", ",", "end", ",", "token", ")", "in", "enumerate", "(", "zip", "(", "starts", ",", "ends", ",", "tokens", ")", ")", ":", "\n", "                ", "entity_start", "=", "ent", ".", "start_char", "\n", "if", "token", "[", "0", "]", "==", "' '", ":", "\n", "                    ", "entity_start", "-=", "1", "\n", "", "entity_end", "=", "ent", ".", "end_char", "\n", "\n", "if", "start", ">=", "entity_start", "and", "end", "<=", "entity_end", ":", "\n", "                    ", "copy_masks", "[", "i", "]", "=", "1", "\n", "\n", "", "", "", "return", "copy_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.get_padding_lengths": [[180, 183], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.as_padded_tensor": [[184, 201], ["tokens.items", "allennlp.common.util.pad_sequence_to_length", "torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_padded_tensor", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "padded_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "{", "}", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", ":", "\n", "            ", "if", "'copy_masks'", "in", "key", ":", "\n", "                ", "def", "default_value", "(", ")", ":", "return", "-", "1", "\n", "", "else", ":", "\n", "                ", "def", "default_value", "(", ")", ":", "return", "self", ".", "_padding_value", "\n", "", "padded_val", "=", "pad_sequence_to_length", "(", "sequence", "=", "val", ",", "\n", "desired_length", "=", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "default_value", ",", "\n", "padding_on_right", "=", "self", ".", "_padding_on_right", ")", "\n", "padded_dict", "[", "key", "]", "=", "torch", ".", "LongTensor", "(", "padded_val", ")", "\n", "", "return", "padded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.RobertaTokenIndexer.get_keys": [[202, 209], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_keys", "(", "self", ",", "index_name", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        We need to override this because the indexer generates multiple keys.\n        \"\"\"", "\n", "# pylint: disable=no-self-use", "\n", "return", "[", "index_name", ",", "f'{index_name}_copy_masks'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.to_token_ids": [[15, 25], ["roberta.bpe.encode", "roberta_indexer.tokenize_line", "token_ids.append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["def", "to_token_ids", "(", "sentence", ",", "roberta", ")", ":", "\n", "    ", "bpe_tokens", "=", "roberta", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "bpe_tokens", "=", "f'<s> {bpe_tokens} </s>'", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "        ", "idx", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer.tokenize_line": [[27, 31], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["", "def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.__init__": [[34, 55], ["super().__init__", "torch.hub.load"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model_name", ":", "str", "=", "'roberta-base'", ",", "\n", "namespace", ":", "str", "=", "'bpe'", ",", "\n", "legacy", ":", "bool", "=", "False", ",", "\n", "start_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "end_tokens", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "token_min_padding_length", ":", "int", "=", "0", ",", "\n", "padding_on_right", ":", "bool", "=", "True", ",", "\n", "padding_value", ":", "int", "=", "1", ",", "\n", "max_len", ":", "int", "=", "512", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "token_min_padding_length", ")", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "source_dictionary", "=", "roberta", ".", "task", ".", "source_dictionary", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", ".", "bpe", "\n", "self", ".", "bpe_legacy", "=", "roberta", ".", "bpe", "\n", "self", ".", "_added_to_vocabulary", "=", "False", "\n", "self", ".", "_namespace", "=", "namespace", "\n", "self", ".", "_padding_on_right", "=", "padding_on_right", "\n", "self", ".", "_padding_value", "=", "padding_value", "\n", "self", ".", "_max_len", "=", "max_len", "\n", "self", ".", "legacy", "=", "legacy", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.count_vocab_items": [[56, 60], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "token", ":", "Token", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "# If we only use pretrained models, we don't need to do anything here.", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._add_encoding_to_vocabulary": [[61, 65], ["roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.source_dictionary.indices.items"], "methods", ["None"], ["", "def", "_add_encoding_to_vocabulary", "(", "self", ",", "vocabulary", ":", "Vocabulary", ")", "->", "None", ":", "\n", "        ", "for", "piece", ",", "idx", "in", "self", ".", "source_dictionary", ".", "indices", ".", "items", "(", ")", ":", "\n", "            ", "vocabulary", ".", "_token_to_index", "[", "self", ".", "_namespace", "]", "[", "piece", "]", "=", "idx", "\n", "vocabulary", ".", "_index_to_token", "[", "self", ".", "_namespace", "]", "[", "idx", "]", "=", "piece", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.tokens_to_indices": [[66, 91], ["roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._add_encoding_to_vocabulary"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._add_encoding_to_vocabulary"], ["", "", "@", "overrides", "\n", "def", "tokens_to_indices", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "vocabulary", ":", "Vocabulary", ",", "\n", "index_name", ":", "str", ",", "\n", "copy_infos", ":", "Dict", "[", "str", ",", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", "=", "None", ",", "\n", "proper_infos", "=", "None", ",", "\n", "key", ":", "str", "=", "None", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "if", "not", "self", ".", "_added_to_vocabulary", ":", "\n", "            ", "self", ".", "_add_encoding_to_vocabulary", "(", "vocabulary", ")", "\n", "self", ".", "_added_to_vocabulary", "=", "True", "\n", "\n", "", "text", "=", "' '", ".", "join", "(", "[", "token", ".", "text", "for", "token", "in", "tokens", "]", ")", "\n", "indices", ",", "copy_masks", ",", "proper_masks", "=", "self", ".", "encode", "(", "\n", "text", ",", "copy_infos", ",", "proper_infos", ",", "key", ")", "\n", "\n", "output", "=", "{", "\n", "index_name", ":", "indices", ",", "\n", "f'{index_name}_copy_masks'", ":", "copy_masks", ",", "\n", "}", "\n", "\n", "if", "proper_masks", "is", "not", "None", ":", "\n", "            ", "output", "[", "f'{index_name}_proper_masks'", "]", "=", "proper_masks", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode": [[92, 115], ["roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._byte_pair_encode", "roberta_indexer_names_matched.tokenize_line", "map", "len", "len", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._byte_pair_encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["", "def", "encode", "(", "self", ",", "sentence", ",", "copy_infos", ",", "proper_infos", ",", "key", ")", ":", "\n", "        ", "bpe_tokens", ",", "copy_masks", ",", "proper_masks", "=", "self", ".", "_byte_pair_encode", "(", "\n", "sentence", ",", "copy_infos", ",", "proper_infos", ",", "key", ")", "\n", "sentence", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "bpe_tokens", ")", ")", "\n", "words", "=", "tokenize_line", "(", "sentence", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "copy_masks", ")", "\n", "\n", "# Enforce maximum length constraint", "\n", "words", "=", "words", "[", ":", "self", ".", "_max_len", "-", "2", "]", "\n", "copy_masks", "=", "copy_masks", "[", ":", "self", ".", "_max_len", "-", "2", "]", "\n", "words", "=", "[", "'<s>'", "]", "+", "words", "+", "[", "'</s>'", "]", "\n", "copy_masks", "=", "[", "0", "]", "+", "copy_masks", "+", "[", "0", "]", "\n", "\n", "if", "proper_masks", "is", "not", "None", ":", "\n", "            ", "proper_masks", "=", "proper_masks", "[", ":", "self", ".", "_max_len", "-", "2", "]", "\n", "proper_masks", "=", "[", "0", "]", "+", "proper_masks", "+", "[", "0", "]", "\n", "\n", "", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "source_dictionary", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "\n", "", "return", "token_ids", ",", "copy_masks", ",", "proper_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer._byte_pair_encode": [[116, 169], ["roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.bpe.re.findall", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_copy_mask", "zip", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_copy_mask", "bpe_tokens.extend", "bpe_copy_masks.extend", "zip", "bpe_proper_masks.extend", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.bpe.bpe().split", "len", "raw_token.encode", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.bpe.bpe().split", "len", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.bpe.bpe", "raw_token.encode", "roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.bpe.bpe"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_copy_mask", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_copy_mask", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "def", "_byte_pair_encode", "(", "self", ",", "text", ",", "copy_infos", ",", "proper_infos", ",", "key", ")", ":", "\n", "        ", "bpe_tokens", "=", "[", "]", "\n", "bpe_copy_masks", "=", "[", "]", "\n", "\n", "raw_tokens", "=", "self", ".", "bpe", ".", "re", ".", "findall", "(", "self", ".", "bpe", ".", "pat", ",", "text", ")", "\n", "# e.g.[' Tomas', ' Maier', ',', ' autumn', '/', 'winter', ' 2014', ',', '\\n', ' in', 'Milan', '.']", "\n", "\n", "copy_masks", "=", "self", ".", "get_copy_mask", "(", "raw_tokens", ",", "copy_infos", ",", "key", ")", "\n", "# Same length as raw_tokens", "\n", "\n", "if", "proper_infos", "is", "not", "None", ":", "\n", "            ", "proper_masks", "=", "self", ".", "get_copy_mask", "(", "\n", "raw_tokens", ",", "proper_infos", ",", "key", ")", "\n", "", "else", ":", "\n", "            ", "proper_masks", "=", "None", "\n", "\n", "", "for", "raw_token", ",", "copy_mask", "in", "zip", "(", "raw_tokens", ",", "copy_masks", ")", ":", "\n", "# e.g. raw_token == \" Tomas\"", "\n", "\n", "# I guess this step is used so that we can distinguish between", "\n", "# the space separator and the space character.", "\n", "            ", "token", "=", "''", ".", "join", "(", "self", ".", "bpe", ".", "byte_encoder", "[", "b", "]", "\n", "for", "b", "in", "raw_token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "# e.g. token == \"\u0120Tomas\"", "\n", "\n", "token_ids", "=", "[", "self", ".", "bpe", ".", "encoder", "[", "bpe_token", "]", "\n", "for", "bpe_token", "in", "self", ".", "bpe", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", "\n", "# e.g. token_ids == [6669, 959]", "\n", "\n", "bpe_tokens", ".", "extend", "(", "token_ids", ")", "\n", "\n", "bpe_copy_masks", ".", "extend", "(", "[", "copy_mask", "]", "*", "len", "(", "token_ids", ")", ")", "\n", "\n", "", "if", "proper_masks", "is", "not", "None", ":", "\n", "            ", "bpe_proper_masks", "=", "[", "]", "\n", "for", "raw_token", ",", "copy_mask", "in", "zip", "(", "raw_tokens", ",", "proper_masks", ")", ":", "\n", "# e.g. raw_token == \" Tomas\"", "\n", "\n", "# I guess this step is used so that we can distinguish between", "\n", "# the space separator and the space character.", "\n", "                ", "token", "=", "''", ".", "join", "(", "self", ".", "bpe", ".", "byte_encoder", "[", "b", "]", "\n", "for", "b", "in", "raw_token", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "# e.g. token == \"\u0120Tomas\"", "\n", "\n", "token_ids", "=", "[", "self", ".", "bpe", ".", "encoder", "[", "bpe_token", "]", "\n", "for", "bpe_token", "in", "self", ".", "bpe", ".", "bpe", "(", "token", ")", ".", "split", "(", "' '", ")", "]", "\n", "# e.g. token_ids == [6669, 959]", "\n", "\n", "bpe_proper_masks", ".", "extend", "(", "[", "copy_mask", "]", "*", "len", "(", "token_ids", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "bpe_proper_masks", "=", "None", "\n", "\n", "", "return", "bpe_tokens", ",", "bpe_copy_masks", ",", "bpe_proper_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_copy_mask": [[170, 203], ["enumerate", "starts.append", "len", "ends.append", "len", "copy_infos.items", "enumerate", "zip"], "methods", ["None"], ["", "def", "get_copy_mask", "(", "self", ",", "tokens", ",", "copy_infos", ",", "key", ")", ":", "\n", "# We first compute the start and end points for each token.", "\n", "# End points are exclusive.", "\n", "# e.g. tokens = [' Tomas', ' Maier', ',', ' autumn', '/', 'winter', ' 2014', ',', '\\n', ' in', 'Milan', '.']", "\n", "        ", "starts", "=", "[", "]", "\n", "ends", "=", "[", "]", "\n", "current", "=", "0", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "starts", ".", "append", "(", "current", ")", "\n", "current", "+=", "len", "(", "token", ")", "\n", "ends", ".", "append", "(", "current", ")", "\n", "\n", "", "copy_masks", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "copy_infos", "is", "None", "and", "key", "is", "None", ":", "\n", "            ", "return", "copy_masks", "\n", "\n", "", "for", "idx", ",", "(", "name", ",", "info", ")", "in", "enumerate", "(", "copy_infos", ".", "items", "(", ")", ")", ":", "\n", "            ", "for", "c_start", ",", "c_end", "in", "info", "[", "key", "]", ":", "\n", "# A token is part of an entity if it lies strictly inside it", "\n", "                ", "for", "i", ",", "(", "start", ",", "end", ",", "token", ")", "in", "enumerate", "(", "zip", "(", "starts", ",", "ends", ",", "tokens", ")", ")", ":", "\n", "                    ", "if", "token", "[", "0", "]", "==", "' '", ":", "\n", "                        ", "c_start_adjusted", "=", "c_start", "-", "1", "\n", "", "else", ":", "\n", "                        ", "c_start_adjusted", "=", "c_start", "\n", "\n", "", "if", "start", ">=", "c_start_adjusted", "and", "end", "<=", "c_end", ":", "\n", "# if name not in token:", "\n", "#     print(name, token)", "\n", "# assert name in token", "\n", "                        ", "copy_masks", "[", "i", "]", "=", "idx", "+", "1", "\n", "\n", "", "", "", "", "return", "copy_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_padding_lengths": [[204, 207], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ",", "token", ":", "int", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.as_padded_tensor": [[208, 225], ["tokens.items", "allennlp.common.util.pad_sequence_to_length", "torch.LongTensor"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_padded_tensor", "(", "self", ",", "\n", "tokens", ":", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ",", "\n", "desired_num_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "# pylint: disable=unused-argument", "\n", "        ", "padded_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "{", "}", "\n", "for", "key", ",", "val", "in", "tokens", ".", "items", "(", ")", ":", "\n", "            ", "if", "'copy_masks'", "in", "key", "or", "'proper_masks'", "in", "key", ":", "\n", "                ", "def", "default_value", "(", ")", ":", "return", "-", "1", "\n", "", "else", ":", "\n", "                ", "def", "default_value", "(", ")", ":", "return", "self", ".", "_padding_value", "\n", "", "padded_val", "=", "pad_sequence_to_length", "(", "sequence", "=", "val", ",", "\n", "desired_length", "=", "desired_num_tokens", "[", "key", "]", ",", "\n", "default_value", "=", "default_value", ",", "\n", "padding_on_right", "=", "self", ".", "_padding_on_right", ")", "\n", "padded_dict", "[", "key", "]", "=", "torch", ".", "LongTensor", "(", "padded_val", ")", "\n", "", "return", "padded_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.get_keys": [[226, 233], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_keys", "(", "self", ",", "index_name", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        We need to override this because the indexer generates multiple keys.\n        \"\"\"", "\n", "# pylint: disable=no-self-use", "\n", "return", "[", "index_name", ",", "f'{index_name}_copy_masks'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.to_token_ids": [[14, 24], ["roberta.bpe.encode", "roberta_indexer_names_matched.tokenize_line", "token_ids.append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["def", "to_token_ids", "(", "sentence", ",", "roberta", ")", ":", "\n", "    ", "bpe_tokens", "=", "roberta", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "bpe_tokens", "=", "f'<s> {bpe_tokens} </s>'", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "        ", "idx", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.tokenize_line": [[26, 30], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["", "def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.__init__": [[52, 78], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torch.hub.load", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "use_caption_names", ":", "bool", "=", "True", ",", "\n", "n_faces", ":", "int", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "nytimes", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "use_caption_names", "=", "use_caption_names", "\n", "self", ".", "n_faces", "=", "n_faces", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", "\n", "self", ".", "indices", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._read": [[79, 200], ["logger.info", "nytimes_copy_matched.NYTimesCopyMatchedReader.db.articles.find().sort", "numpy.array", "nytimes_copy_matched.NYTimesCopyMatchedReader.close", "nytimes_copy_matched.NYTimesCopyMatchedReader.rs.shuffle", "ValueError", "nytimes_copy_matched.NYTimesCopyMatchedReader.db.articles.find_one", "nytimes_copy_matched.NYTimesCopyMatchedReader.db.articles.find", "set", "[].strip", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_caption_names", "enumerate", "os.path.join", "nytimes_copy_matched.NYTimesCopyMatchedReader._process_copy_tokens", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_context_names", "sorted", "tqdm.tqdm.tqdm", "[].strip", "paragraphs.append", "pos_pars.append", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_named_entities", "ner_pars.append", "sorted.union", "len", "PIL.Image.open", "numpy.array", "numpy.array", "nytimes_copy_matched.NYTimesCopyMatchedReader.article_to_instance", "nytimes_copy_matched.NYTimesCopyMatchedReader.to_token_ids", "len", "paragraphs.append", "pos_pars.append", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_named_entities", "ner_pars.append", "before.insert", "before_pos.insert", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_named_entities", "before_ners.append", "len", "after.append", "after_pos.append", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_named_entities", "after_ners.append", "len", "nytimes_copy_matched.NYTimesCopyMatchedReader._get_person_names", "nytimes_copy_matched.NYTimesCopyMatchedReader.to_token_ids", "len", "nytimes_copy_matched.NYTimesCopyMatchedReader.to_token_ids", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_caption_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._process_copy_tokens", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_context_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "# validation and test sets contain 10K examples each", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "split", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "'parsed_section.parts_of_speech'", ",", "\n", "'parsed_section.facenet_details'", ",", "\n", "'parsed_section.named_entities'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "\n", "'web_url'", ",", "'n_images_with_faces'", "]", "\n", "\n", "for", "article_id", "in", "ids", ":", "\n", "            ", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "\n", "{", "'_id'", ":", "{", "'$eq'", ":", "article_id", "}", "}", ",", "projection", "=", "projection", ")", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "for", "pos", "in", "image_positions", ":", "\n", "                ", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "", "paragraphs", "=", "[", "]", "\n", "pos_pars", "=", "[", "]", "\n", "ner_pars", "=", "[", "]", "\n", "named_entities", "=", "set", "(", ")", "\n", "n_words", "=", "0", "\n", "if", "title", ":", "\n", "                    ", "paragraphs", ".", "append", "(", "title", ")", "\n", "pos_pars", ".", "append", "(", "article", "[", "'headline'", "]", "[", "'parts_of_speech'", "]", ")", "\n", "ners", "=", "self", ".", "_get_named_entities", "(", "article", "[", "'headline'", "]", ")", "\n", "ner_pars", ".", "append", "(", "ners", ")", "\n", "named_entities", ".", "union", "(", "ners", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "title", ")", ")", "\n", "\n", "", "caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "not", "caption", ":", "\n", "                    ", "continue", "\n", "\n", "", "copy_infos", "=", "self", ".", "_get_caption_names", "(", "sections", "[", "pos", "]", ")", "\n", "\n", "if", "self", ".", "n_faces", "is", "not", "None", ":", "\n", "                    ", "n_persons", "=", "self", ".", "n_faces", "\n", "", "elif", "self", ".", "use_caption_names", ":", "\n", "                    ", "n_persons", "=", "len", "(", "self", ".", "_get_person_names", "(", "sections", "[", "pos", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "n_persons", "=", "4", "\n", "\n", "", "before", "=", "[", "]", "\n", "before_pos", "=", "[", "]", "\n", "before_ners", "=", "[", "]", "\n", "after", "=", "[", "]", "\n", "after_pos", "=", "[", "]", "\n", "after_ners", "=", "[", "]", "\n", "i", "=", "pos", "-", "1", "\n", "j", "=", "pos", "+", "1", "\n", "for", "k", ",", "section", "in", "enumerate", "(", "sections", ")", ":", "\n", "                    ", "if", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "paragraphs", ".", "append", "(", "section", "[", "'text'", "]", ")", "\n", "pos_pars", ".", "append", "(", "section", "[", "'parts_of_speech'", "]", ")", "\n", "ners", "=", "self", ".", "_get_named_entities", "(", "section", ")", "\n", "ner_pars", ".", "append", "(", "ners", ")", "\n", "named_entities", "|=", "ners", "\n", "break", "\n", "\n", "", "", "while", "True", ":", "\n", "                    ", "if", "i", ">", "k", "and", "sections", "[", "i", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "i", "]", "[", "'text'", "]", "\n", "before", ".", "insert", "(", "0", ",", "text", ")", "\n", "before_pos", ".", "insert", "(", "0", ",", "sections", "[", "i", "]", "[", "'parts_of_speech'", "]", ")", "\n", "ners", "=", "self", ".", "_get_named_entities", "(", "sections", "[", "i", "]", ")", "\n", "before_ners", ".", "append", "(", "ners", ")", "\n", "named_entities", "|=", "ners", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "i", "-=", "1", "\n", "\n", "if", "k", "<", "j", "<", "len", "(", "sections", ")", "and", "sections", "[", "j", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "j", "]", "[", "'text'", "]", "\n", "after", ".", "append", "(", "text", ")", "\n", "after_pos", ".", "append", "(", "sections", "[", "j", "]", "[", "'parts_of_speech'", "]", ")", "\n", "ners", "=", "self", ".", "_get_named_entities", "(", "sections", "[", "j", "]", ")", "\n", "after_ners", ".", "append", "(", "ners", ")", "\n", "named_entities", "|=", "ners", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "j", "+=", "1", "\n", "\n", "if", "n_words", ">=", "510", "or", "(", "i", "<=", "k", "and", "j", ">=", "len", "(", "sections", ")", ")", ":", "\n", "                        ", "break", "\n", "\n", "", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_dir", ",", "f\"{sections[pos]['hash']}.jpg\"", ")", "\n", "try", ":", "\n", "                    ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "'facenet_details'", "not", "in", "sections", "[", "pos", "]", "or", "n_persons", "==", "0", ":", "\n", "                    ", "face_embeds", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "face_embeds", "=", "sections", "[", "pos", "]", "[", "'facenet_details'", "]", "[", "'embeddings'", "]", "\n", "# Keep only the top faces (sorted by size)", "\n", "face_embeds", "=", "np", ".", "array", "(", "face_embeds", "[", ":", "n_persons", "]", ")", "\n", "\n", "", "paragraphs", "=", "paragraphs", "+", "before", "+", "after", "\n", "pos_pars", "=", "pos_pars", "+", "before_pos", "+", "after_pos", "\n", "ner_pars", "=", "ner_pars", "+", "before_ners", "+", "after_ners", "\n", "self", ".", "_process_copy_tokens", "(", "copy_infos", ",", "paragraphs", ",", "pos_pars", ")", "\n", "proper_infos", "=", "self", ".", "_get_context_names", "(", "\n", "paragraphs", ",", "pos_pars", ",", "ner_pars", ")", "\n", "named_entities", "=", "sorted", "(", "named_entities", ")", "\n", "\n", "yield", "self", ".", "article_to_instance", "(", "copy_infos", ",", "proper_infos", ",", "paragraphs", ",", "named_entities", ",", "image", ",", "caption", ",", "image_path", ",", "article", "[", "'web_url'", "]", ",", "pos", ",", "face_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.article_to_instance": [[201, 233], ["nytimes_copy_matched.NYTimesCopyMatchedReader._tokenizer.tokenize", "nytimes_copy_matched.NYTimesCopyMatchedReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "nytimes_copy_matched.NYTimesCopyMatchedReader._tokenizer.tokenize", "tell.data.fields.ListTextField", "tell.data.fields.ListTextField.empty_field", "tell.data.fields.CopyTextField", "tell.data.fields.ListTextField", "tell.data.fields.ImageField", "tell.data.fields.CopyTextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.empty_field"], ["", "", "", "def", "article_to_instance", "(", "self", ",", "copy_infos", ",", "proper_infos", ",", "paragraphs", ",", "named_entities", ",", "image", ",", "caption", ",", "image_path", ",", "web_url", ",", "pos", ",", "face_embeds", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "name_token_list", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "n", ")", "for", "n", "in", "named_entities", "]", "\n", "\n", "if", "name_token_list", ":", "\n", "            ", "name_field", "=", "[", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "for", "tokens", "in", "name_token_list", "]", "\n", "", "else", ":", "\n", "            ", "stub_field", "=", "ListTextField", "(", "\n", "[", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", "]", ")", "\n", "name_field", "=", "stub_field", ".", "empty_field", "(", ")", "\n", "\n", "", "fields", "=", "{", "\n", "'context'", ":", "CopyTextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ",", "copy_infos", ",", "proper_infos", ",", "'context'", ")", ",", "\n", "'names'", ":", "ListTextField", "(", "name_field", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "CopyTextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ",", "copy_infos", ",", "None", ",", "'caption'", ")", ",", "\n", "'face_embeds'", ":", "ArrayField", "(", "face_embeds", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "# 'names': named_entities,", "\n", "'web_url'", ":", "web_url", ",", "\n", "'image_path'", ":", "image_path", ",", "\n", "'image_pos'", ":", "pos", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._get_named_entities": [[234, 245], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_named_entities", "(", "self", ",", "section", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'named_entities'", "in", "section", ":", "\n", "            ", "ners", "=", "section", "[", "'named_entities'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", ",", "'ORG'", ",", "'GPE'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._get_person_names": [[246, 257], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_person_names", "(", "self", ",", "section", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'named_entities'", "in", "section", ":", "\n", "            ", "ners", "=", "section", "[", "'named_entities'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.to_token_ids": [[258, 267], ["nytimes_copy_matched.NYTimesCopyMatchedReader.bpe.encode", "nytimes_copy_matched.tokenize_line", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["", "def", "to_token_ids", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "bpe_tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._get_caption_names": [[268, 284], ["nytimes_copy_matched.NYTimesCopyMatchedReader.is_in_ner", "collections.OrderedDict", "[].append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner"], ["", "def", "_get_caption_names", "(", "self", ",", "section", ")", ":", "\n", "        ", "copy_infos", "=", "{", "}", "\n", "\n", "parts_of_speech", "=", "section", "[", "'parts_of_speech'", "]", "\n", "for", "pos", "in", "parts_of_speech", ":", "\n", "            ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "self", ".", "is_in_ner", "(", "pos", "[", "'text'", "]", ",", "section", ")", ":", "\n", "                ", "if", "pos", "[", "'text'", "]", "not", "in", "copy_infos", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "=", "OrderedDict", "(", "{", "\n", "'caption'", ":", "[", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", "]", ",", "\n", "'context'", ":", "[", "]", "\n", "}", ")", "\n", "", "else", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "[", "'caption'", "]", ".", "append", "(", "\n", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", ")", "\n", "\n", "", "", "", "return", "copy_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._get_context_names": [[285, 301], ["zip", "len", "nytimes_copy_matched.NYTimesCopyMatchedReader.isin_set", "collections.OrderedDict", "[].append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.isin_set"], ["", "def", "_get_context_names", "(", "self", ",", "paragraphs", ",", "pos_pars", ",", "ner_pars", ")", ":", "\n", "        ", "offset", "=", "0", "\n", "copy_infos", "=", "{", "}", "\n", "for", "par", ",", "pos_par", ",", "ner_par", "in", "zip", "(", "paragraphs", ",", "pos_pars", ",", "ner_pars", ")", ":", "\n", "            ", "for", "pos", "in", "pos_par", ":", "\n", "                ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "self", ".", "isin_set", "(", "pos", "[", "'text'", "]", ",", "ner_par", ")", ":", "\n", "                    ", "if", "pos", "[", "'text'", "]", "not", "in", "copy_infos", ":", "\n", "                        ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "=", "OrderedDict", "(", "{", "\n", "'context'", ":", "[", "(", "pos", "[", "'start'", "]", "+", "offset", ",", "pos", "[", "'end'", "]", "+", "offset", ")", "]", ",", "\n", "}", ")", "\n", "", "else", ":", "\n", "                        ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "[", "'context'", "]", ".", "append", "(", "\n", "(", "pos", "[", "'start'", "]", "+", "offset", ",", "pos", "[", "'end'", "]", "+", "offset", ")", ")", "\n", "", "", "", "offset", "+=", "len", "(", "par", ")", "+", "1", "\n", "\n", "", "return", "copy_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader._process_copy_tokens": [[302, 313], ["copy_infos.items", "zip", "len", "info[].append"], "methods", ["None"], ["", "def", "_process_copy_tokens", "(", "self", ",", "copy_infos", ",", "paragraphs", ",", "pos_pars", ")", ":", "\n", "        ", "for", "name", ",", "info", "in", "copy_infos", ".", "items", "(", ")", ":", "\n", "            ", "offset", "=", "0", "\n", "for", "par", ",", "pos_par", "in", "zip", "(", "paragraphs", ",", "pos_pars", ")", ":", "\n", "                ", "for", "pos", "in", "pos_par", ":", "\n", "                    ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "pos", "[", "'text'", "]", "==", "name", ":", "\n", "                        ", "info", "[", "'context'", "]", ".", "append", "(", "(", "\n", "pos", "[", "'start'", "]", "+", "offset", ",", "\n", "pos", "[", "'end'", "]", "+", "offset", ",", "\n", ")", ")", "\n", "", "", "offset", "+=", "len", "(", "par", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.is_in_ner": [[314, 321], ["None"], "methods", ["None"], ["", "", "", "def", "is_in_ner", "(", "self", ",", "text", ",", "section", ")", ":", "\n", "        ", "if", "'named_entities'", "in", "section", ":", "\n", "            ", "ners", "=", "section", "[", "'named_entities'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "text", "in", "ner", "[", "'text'", "]", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.NYTimesCopyMatchedReader.isin_set": [[322, 327], ["None"], "methods", ["None"], ["", "def", "isin_set", "(", "self", ",", "text", ",", "test_set", ")", ":", "\n", "        ", "for", "ner", "in", "test_set", ":", "\n", "            ", "if", "text", "in", "ner", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_copy_matched.tokenize_line": [[30, 34], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.__init__": [[41, 68], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "eval_limit", ":", "int", "=", "5120", ",", "\n", "use_caption_names", ":", "bool", "=", "True", ",", "\n", "use_objects", ":", "bool", "=", "False", ",", "\n", "n_faces", ":", "int", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "goodnews", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "# Resize(256), CenterCrop(224),", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "eval_limit", "=", "eval_limit", "\n", "self", ".", "use_caption_names", "=", "use_caption_names", "\n", "self", ".", "use_objects", "=", "use_objects", "\n", "self", ".", "n_faces", "=", "n_faces", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._read": [[69, 135], ["logger.info", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.db.splits.find().sort", "numpy.array", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.close", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.rs.shuffle", "ValueError", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.db.splits.find_one", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.db.articles.find_one", "os.path.join", "sorted", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.db.splits.find", "PIL.Image.open", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._get_named_entities", "numpy.array", "numpy.array", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.db.objects.find_one", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.article_to_instance", "tqdm.tqdm.tqdm", "len", "numpy.array", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._get_person_names", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "# Setting the batch size is needed to avoid cursor timing out", "\n", "# We limit the validation set to 1000", "\n", "", "limit", "=", "self", ".", "eval_limit", "if", "split", "==", "'val'", "else", "0", "\n", "\n", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "splits", ".", "find", "(", "{", "\n", "'split'", ":", "{", "'$eq'", ":", "split", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ",", "limit", "=", "limit", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "for", "sample_id", "in", "ids", ":", "\n", "            ", "sample", "=", "self", ".", "db", ".", "splits", ".", "find_one", "(", "{", "'_id'", ":", "{", "'$eq'", ":", "sample_id", "}", "}", ")", "\n", "\n", "# Find the corresponding article", "\n", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", ",", "'context'", ",", "'images'", ",", "'web_url'", ",", "'caption_ner'", ",", "'context_ner'", "]", ")", "\n", "\n", "# Load the image", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "try", ":", "\n", "                ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "named_entities", "=", "sorted", "(", "self", ".", "_get_named_entities", "(", "article", ")", ")", "\n", "\n", "if", "self", ".", "n_faces", "is", "not", "None", ":", "\n", "                ", "n_persons", "=", "self", ".", "n_faces", "\n", "", "elif", "self", ".", "use_caption_names", ":", "\n", "                ", "n_persons", "=", "len", "(", "self", ".", "_get_person_names", "(", "\n", "article", ",", "sample", "[", "'image_index'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "n_persons", "=", "4", "\n", "\n", "", "if", "'facenet_details'", "not", "in", "sample", "or", "n_persons", "==", "0", ":", "\n", "                ", "face_embeds", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "face_embeds", "=", "sample", "[", "'facenet_details'", "]", "[", "'embeddings'", "]", "\n", "# Keep only the top faces (sorted by size)", "\n", "face_embeds", "=", "np", ".", "array", "(", "face_embeds", "[", ":", "n_persons", "]", ")", "\n", "\n", "", "obj_feats", "=", "None", "\n", "if", "self", ".", "use_objects", ":", "\n", "                ", "obj", "=", "self", ".", "db", ".", "objects", ".", "find_one", "(", "{", "'_id'", ":", "sample", "[", "'_id'", "]", "}", ")", "\n", "if", "obj", "is", "not", "None", ":", "\n", "                    ", "obj_feats", "=", "obj", "[", "'object_features'", "]", "\n", "if", "len", "(", "obj_feats", ")", "==", "0", ":", "\n", "                        ", "obj_feats", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                        ", "obj_feats", "=", "np", ".", "array", "(", "obj_feats", ")", "\n", "", "", "else", ":", "\n", "                    ", "obj_feats", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "\n", "", "", "yield", "self", ".", "article_to_instance", "(", "article", ",", "named_entities", ",", "face_embeds", ",", "\n", "image", ",", "sample", "[", "'image_index'", "]", ",", "\n", "image_path", ",", "obj_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader.article_to_instance": [[136, 175], ["caption.strip.strip.strip", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._tokenizer.tokenize", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._tokenizer.tokenize", "tell.data.fields.ListTextField", "tell.data.fields.ListTextField.empty_field", "allennlp.data.fields.TextField", "tell.data.fields.ListTextField", "tell.data.fields.ImageField", "allennlp.data.fields.TextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "article[].strip().split", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "article[].strip"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.empty_field"], ["", "", "def", "article_to_instance", "(", "self", ",", "article", ",", "named_entities", ",", "face_embeds", ",", "image", ",", "\n", "image_index", ",", "image_path", ",", "obj_feats", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "' '", ".", "join", "(", "article", "[", "'context'", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "500", "]", ")", "\n", "\n", "caption", "=", "article", "[", "'images'", "]", "[", "image_index", "]", "\n", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "name_token_list", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "n", ")", "for", "n", "in", "named_entities", "]", "\n", "\n", "if", "name_token_list", ":", "\n", "            ", "name_field", "=", "[", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "for", "tokens", "in", "name_token_list", "]", "\n", "", "else", ":", "\n", "            ", "stub_field", "=", "ListTextField", "(", "\n", "[", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", "]", ")", "\n", "name_field", "=", "stub_field", ".", "empty_field", "(", ")", "\n", "\n", "", "fields", "=", "{", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'names'", ":", "ListTextField", "(", "name_field", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'face_embeds'", ":", "ArrayField", "(", "face_embeds", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "}", "\n", "\n", "if", "obj_feats", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'obj_embeds'", "]", "=", "ArrayField", "(", "obj_feats", ",", "padding_value", "=", "np", ".", "nan", ")", "\n", "\n", "", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'names'", ":", "named_entities", ",", "\n", "'web_url'", ":", "article", "[", "'web_url'", "]", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._get_named_entities": [[176, 187], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_named_entities", "(", "self", ",", "article", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'context_ner'", "in", "article", ":", "\n", "            ", "ners", "=", "article", "[", "'context_ner'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", ",", "'ORG'", ",", "'GPE'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_face_ner_matched.GoodNewsFaceNERMatchedReader._get_person_names": [[188, 199], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_person_names", "(", "self", ",", "article", ",", "pos", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'caption_ner'", "in", "article", ":", "\n", "            ", "ners", "=", "article", "[", "'caption_ner'", "]", "[", "pos", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_glove.NYTimesGloveReader.__init__": [[41, 59], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "nytimes", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_glove.NYTimesGloveReader._read": [[60, 110], ["logger.info", "nytimes_glove.NYTimesGloveReader.db.articles.find().sort", "numpy.array", "nytimes_glove.NYTimesGloveReader.close", "nytimes_glove.NYTimesGloveReader.rs.shuffle", "ValueError", "nytimes_glove.NYTimesGloveReader.db.articles.find_one", "nytimes_glove.NYTimesGloveReader.db.articles.find", "[].strip", "os.path.join", "enumerate", "tqdm.tqdm.tqdm", "[].strip", "s[].strip", "paragraphs.insert", "PIL.Image.open", "len", "nytimes_glove.NYTimesGloveReader.article_to_instance", "par.split"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "# validation and test sets contain 10K examples each", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "split", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "'web_url'", "]", "\n", "\n", "for", "article_id", "in", "ids", ":", "\n", "            ", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "\n", "{", "'_id'", ":", "{", "'$eq'", ":", "article_id", "}", "}", ",", "projection", "=", "projection", ")", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "for", "pos", "in", "image_positions", ":", "\n", "                ", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "", "paragraphs", "=", "[", "s", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "for", "s", "in", "sections", "if", "s", "[", "'type'", "]", "==", "'paragraph'", "]", "\n", "if", "title", ":", "\n", "                    ", "paragraphs", ".", "insert", "(", "0", ",", "title", ")", "\n", "", "caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "not", "caption", ":", "\n", "                    ", "continue", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_dir", ",", "f\"{sections[pos]['hash']}.jpg\"", ")", "\n", "try", ":", "\n", "                    ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "n_words", "=", "0", "\n", "for", "i", ",", "par", "in", "enumerate", "(", "paragraphs", ")", ":", "\n", "                    ", "n_words", "+=", "len", "(", "par", ".", "split", "(", ")", ")", "\n", "if", "n_words", ">", "500", ":", "\n", "                        ", "break", "\n", "\n", "", "", "yield", "self", ".", "article_to_instance", "(", "paragraphs", "[", ":", "i", "+", "1", "]", ",", "image", ",", "caption", ",", "image_path", ",", "article", "[", "'web_url'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_glove.NYTimesGloveReader.article_to_instance": [[111, 128], ["nytimes_glove.NYTimesGloveReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "tell.data.fields.ImageField", "allennlp.data.fields.TextField"], "methods", ["None"], ["", "", "", "def", "article_to_instance", "(", "self", ",", "paragraphs", ",", "image", ",", "caption", ",", "image_path", ",", "web_url", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", "\n", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "fields", "=", "{", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'web_url'", ":", "web_url", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.__init__": [[51, 79], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torch.hub.load", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "use_caption_names", ":", "bool", "=", "True", ",", "\n", "use_objects", ":", "bool", "=", "False", ",", "\n", "n_faces", ":", "int", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "nytimes", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "use_caption_names", "=", "use_caption_names", "\n", "self", ".", "use_objects", "=", "use_objects", "\n", "self", ".", "n_faces", "=", "n_faces", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", "\n", "self", ".", "indices", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._read": [[80, 191], ["logger.info", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.db.articles.find().sort", "numpy.array", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.close", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.rs.shuffle", "ValueError", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.db.articles.find_one", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.db.articles.find", "set", "[].strip", "enumerate", "os.path.join", "sorted", "tqdm.tqdm.tqdm", "[].strip", "paragraphs.append", "sorted.union", "len", "PIL.Image.open", "numpy.array", "numpy.array", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.db.objects.find_one", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.article_to_instance", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_named_entities", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.to_token_ids", "len", "paragraphs.append", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_named_entities", "before.insert", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_named_entities", "len", "after.append", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_named_entities", "len", "numpy.array", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_person_names", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.to_token_ids", "len", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.to_token_ids", "len", "numpy.array", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "# validation and test sets contain 10K examples each", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "split", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "'parsed_section.parts_of_speech'", ",", "\n", "'parsed_section.facenet_details'", ",", "'parsed_section.named_entities'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "\n", "'web_url'", ",", "'n_images_with_faces'", "]", "\n", "\n", "for", "article_id", "in", "ids", ":", "\n", "            ", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "\n", "{", "'_id'", ":", "{", "'$eq'", ":", "article_id", "}", "}", ",", "projection", "=", "projection", ")", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "for", "pos", "in", "image_positions", ":", "\n", "                ", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "", "paragraphs", "=", "[", "]", "\n", "named_entities", "=", "set", "(", ")", "\n", "n_words", "=", "0", "\n", "if", "title", ":", "\n", "                    ", "paragraphs", ".", "append", "(", "title", ")", "\n", "named_entities", ".", "union", "(", "\n", "self", ".", "_get_named_entities", "(", "article", "[", "'headline'", "]", ")", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "title", ")", ")", "\n", "\n", "", "caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "not", "caption", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "self", ".", "n_faces", "is", "not", "None", ":", "\n", "                    ", "n_persons", "=", "self", ".", "n_faces", "\n", "", "elif", "self", ".", "use_caption_names", ":", "\n", "                    ", "n_persons", "=", "len", "(", "self", ".", "_get_person_names", "(", "sections", "[", "pos", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "n_persons", "=", "4", "\n", "\n", "", "before", "=", "[", "]", "\n", "after", "=", "[", "]", "\n", "i", "=", "pos", "-", "1", "\n", "j", "=", "pos", "+", "1", "\n", "for", "k", ",", "section", "in", "enumerate", "(", "sections", ")", ":", "\n", "                    ", "if", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "paragraphs", ".", "append", "(", "section", "[", "'text'", "]", ")", "\n", "named_entities", "|=", "self", ".", "_get_named_entities", "(", "section", ")", "\n", "break", "\n", "\n", "", "", "while", "True", ":", "\n", "                    ", "if", "i", ">", "k", "and", "sections", "[", "i", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "i", "]", "[", "'text'", "]", "\n", "before", ".", "insert", "(", "0", ",", "text", ")", "\n", "named_entities", "|=", "self", ".", "_get_named_entities", "(", "sections", "[", "i", "]", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "i", "-=", "1", "\n", "\n", "if", "k", "<", "j", "<", "len", "(", "sections", ")", "and", "sections", "[", "j", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "j", "]", "[", "'text'", "]", "\n", "after", ".", "append", "(", "text", ")", "\n", "named_entities", "|=", "self", ".", "_get_named_entities", "(", "sections", "[", "j", "]", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "j", "+=", "1", "\n", "\n", "if", "n_words", ">=", "510", "or", "(", "i", "<=", "k", "and", "j", ">=", "len", "(", "sections", ")", ")", ":", "\n", "                        ", "break", "\n", "\n", "", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_dir", ",", "f\"{sections[pos]['hash']}.jpg\"", ")", "\n", "try", ":", "\n", "                    ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "'facenet_details'", "not", "in", "sections", "[", "pos", "]", "or", "n_persons", "==", "0", ":", "\n", "                    ", "face_embeds", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "face_embeds", "=", "sections", "[", "pos", "]", "[", "'facenet_details'", "]", "[", "'embeddings'", "]", "\n", "# Keep only the top faces (sorted by size)", "\n", "face_embeds", "=", "np", ".", "array", "(", "face_embeds", "[", ":", "n_persons", "]", ")", "\n", "\n", "", "paragraphs", "=", "paragraphs", "+", "before", "+", "after", "\n", "named_entities", "=", "sorted", "(", "named_entities", ")", "\n", "\n", "obj_feats", "=", "None", "\n", "if", "self", ".", "use_objects", ":", "\n", "                    ", "obj", "=", "self", ".", "db", ".", "objects", ".", "find_one", "(", "\n", "{", "'_id'", ":", "sections", "[", "pos", "]", "[", "'hash'", "]", "}", ")", "\n", "if", "obj", "is", "not", "None", ":", "\n", "                        ", "obj_feats", "=", "obj", "[", "'object_features'", "]", "\n", "if", "len", "(", "obj_feats", ")", "==", "0", ":", "\n", "                            ", "obj_feats", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                            ", "obj_feats", "=", "np", ".", "array", "(", "obj_feats", ")", "\n", "", "", "else", ":", "\n", "                        ", "obj_feats", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "\n", "", "", "yield", "self", ".", "article_to_instance", "(", "\n", "paragraphs", ",", "named_entities", ",", "image", ",", "caption", ",", "image_path", ",", "\n", "article", "[", "'web_url'", "]", ",", "pos", ",", "face_embeds", ",", "obj_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.article_to_instance": [[192, 228], ["nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._tokenizer.tokenize", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._tokenizer.tokenize", "tell.data.fields.ListTextField", "tell.data.fields.ListTextField.empty_field", "allennlp.data.fields.TextField", "tell.data.fields.ListTextField", "tell.data.fields.ImageField", "allennlp.data.fields.TextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.empty_field"], ["", "", "", "def", "article_to_instance", "(", "self", ",", "paragraphs", ",", "named_entities", ",", "image", ",", "caption", ",", "\n", "image_path", ",", "web_url", ",", "pos", ",", "face_embeds", ",", "obj_feats", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "name_token_list", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "n", ")", "for", "n", "in", "named_entities", "]", "\n", "\n", "if", "name_token_list", ":", "\n", "            ", "name_field", "=", "[", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "for", "tokens", "in", "name_token_list", "]", "\n", "", "else", ":", "\n", "            ", "stub_field", "=", "ListTextField", "(", "\n", "[", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", "]", ")", "\n", "name_field", "=", "stub_field", ".", "empty_field", "(", ")", "\n", "\n", "", "fields", "=", "{", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'names'", ":", "ListTextField", "(", "name_field", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'face_embeds'", ":", "ArrayField", "(", "face_embeds", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "}", "\n", "\n", "if", "obj_feats", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'obj_embeds'", "]", "=", "ArrayField", "(", "obj_feats", ",", "padding_value", "=", "np", ".", "nan", ")", "\n", "\n", "", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'names'", ":", "named_entities", ",", "\n", "'web_url'", ":", "web_url", ",", "\n", "'image_path'", ":", "image_path", ",", "\n", "'image_pos'", ":", "pos", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_named_entities": [[229, 240], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_named_entities", "(", "self", ",", "section", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'named_entities'", "in", "section", ":", "\n", "            ", "ners", "=", "section", "[", "'named_entities'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", ",", "'ORG'", ",", "'GPE'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader._get_person_names": [[241, 252], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_person_names", "(", "self", ",", "section", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'named_entities'", "in", "section", ":", "\n", "            ", "ners", "=", "section", "[", "'named_entities'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.to_token_ids": [[253, 262], ["nytimes_faces_ner_matched.NYTimesFacesNERMatchedReader.bpe.encode", "nytimes_faces_ner_matched.tokenize_line", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["", "def", "to_token_ids", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "bpe_tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_faces_ner_matched.tokenize_line": [[29, 33], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened.FlattenedGoodNewsReader.__init__": [[41, 62], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "eval_limit", ":", "int", "=", "5120", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "goodnews", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "# Resize(256), CenterCrop(224),", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "eval_limit", "=", "eval_limit", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened.FlattenedGoodNewsReader._read": [[63, 96], ["logger.info", "goodnews_flattened.FlattenedGoodNewsReader.db.splits.find().sort", "numpy.array", "goodnews_flattened.FlattenedGoodNewsReader.close", "goodnews_flattened.FlattenedGoodNewsReader.rs.shuffle", "ValueError", "goodnews_flattened.FlattenedGoodNewsReader.db.splits.find_one", "goodnews_flattened.FlattenedGoodNewsReader.db.articles.find_one", "os.path.join", "goodnews_flattened.FlattenedGoodNewsReader.db.splits.find", "PIL.Image.open", "goodnews_flattened.FlattenedGoodNewsReader.article_to_instance", "tqdm.tqdm.tqdm"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "# Setting the batch size is needed to avoid cursor timing out", "\n", "# We limit the validation set to 1000", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "limit", "=", "self", ".", "eval_limit", "if", "split", "==", "'val'", "else", "0", "\n", "sample_cursor", "=", "self", ".", "db", ".", "splits", ".", "find", "(", "{", "\n", "'split'", ":", "{", "'$eq'", ":", "split", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ",", "limit", "=", "limit", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "for", "sample_id", "in", "ids", ":", "\n", "            ", "sample", "=", "self", ".", "db", ".", "splits", ".", "find_one", "(", "{", "'_id'", ":", "{", "'$eq'", ":", "sample_id", "}", "}", ")", "\n", "\n", "# Find the corresponding article", "\n", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", ",", "'context'", ",", "'images'", ",", "'web_url'", "]", ")", "\n", "\n", "# Load the image", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "try", ":", "\n", "                ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "yield", "self", ".", "article_to_instance", "(", "article", ",", "image", ",", "sample", "[", "'image_index'", "]", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened.FlattenedGoodNewsReader.article_to_instance": [[97, 119], ["caption.strip.strip.strip", "goodnews_flattened.FlattenedGoodNewsReader._tokenizer.tokenize", "goodnews_flattened.FlattenedGoodNewsReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "allennlp.data.fields.TextField", "tell.data.fields.ImageField", "allennlp.data.fields.TextField", "article[].strip().split", "article[].strip"], "methods", ["None"], ["", "", "def", "article_to_instance", "(", "self", ",", "article", ",", "image", ",", "image_index", ",", "image_path", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "' '", ".", "join", "(", "article", "[", "'context'", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "500", "]", ")", "\n", "\n", "caption", "=", "article", "[", "'images'", "]", "[", "image_index", "]", "\n", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "fields", "=", "{", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'web_url'", ":", "article", "[", "'web_url'", "]", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.__init__": [[51, 73], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torch.hub.load", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "nytimes", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n", "roberta", "=", "torch", ".", "hub", ".", "load", "(", "'pytorch/fairseq:2f7e3f3323'", ",", "'roberta.base'", ")", "\n", "self", ".", "bpe", "=", "roberta", ".", "bpe", "\n", "self", ".", "indices", "=", "roberta", ".", "task", ".", "source_dictionary", ".", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader._read": [[74, 147], ["logger.info", "nytimes_position.NYTimesPositionReader.db.articles.find().sort", "numpy.array", "nytimes_position.NYTimesPositionReader.close", "nytimes_position.NYTimesPositionReader.rs.shuffle", "ValueError", "nytimes_position.NYTimesPositionReader.db.articles.find_one", "nytimes_position.NYTimesPositionReader.db.articles.find", "[].strip", "enumerate", "os.path.join", "tqdm.tqdm.tqdm", "[].strip", "paragraphs.append", "len", "PIL.Image.open", "nytimes_position.NYTimesPositionReader.article_to_instance", "nytimes_position.NYTimesPositionReader.to_token_ids", "paragraphs.append", "before.insert", "len", "after.append", "len", "nytimes_position.NYTimesPositionReader.to_token_ids", "len", "nytimes_position.NYTimesPositionReader.to_token_ids", "len"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "# validation and test sets contain 10K examples each", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "split", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "'web_url'", "]", "\n", "\n", "for", "article_id", "in", "ids", ":", "\n", "            ", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "\n", "{", "'_id'", ":", "{", "'$eq'", ":", "article_id", "}", "}", ",", "projection", "=", "projection", ")", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "for", "pos", "in", "image_positions", ":", "\n", "                ", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "", "paragraphs", "=", "[", "]", "\n", "n_words", "=", "0", "\n", "if", "title", ":", "\n", "                    ", "paragraphs", ".", "append", "(", "title", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "title", ")", ")", "\n", "\n", "", "caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "not", "caption", ":", "\n", "                    ", "continue", "\n", "\n", "", "before", "=", "[", "]", "\n", "after", "=", "[", "]", "\n", "i", "=", "pos", "-", "1", "\n", "j", "=", "pos", "+", "1", "\n", "for", "k", ",", "section", "in", "enumerate", "(", "sections", ")", ":", "\n", "                    ", "if", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "paragraphs", ".", "append", "(", "section", "[", "'text'", "]", ")", "\n", "break", "\n", "\n", "", "", "while", "True", ":", "\n", "                    ", "if", "i", ">", "k", "and", "sections", "[", "i", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "i", "]", "[", "'text'", "]", "\n", "before", ".", "insert", "(", "0", ",", "text", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "i", "-=", "1", "\n", "\n", "if", "k", "<", "j", "<", "len", "(", "sections", ")", "and", "sections", "[", "j", "]", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                        ", "text", "=", "sections", "[", "j", "]", "[", "'text'", "]", "\n", "after", ".", "append", "(", "text", ")", "\n", "n_words", "+=", "len", "(", "self", ".", "to_token_ids", "(", "text", ")", ")", "\n", "", "j", "+=", "1", "\n", "\n", "if", "n_words", ">=", "510", "or", "(", "i", "<=", "k", "and", "j", ">=", "len", "(", "sections", ")", ")", ":", "\n", "                        ", "break", "\n", "\n", "", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_dir", ",", "f\"{sections[pos]['hash']}.jpg\"", ")", "\n", "try", ":", "\n", "                    ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "paragraphs", "=", "paragraphs", "+", "before", "+", "after", "\n", "\n", "yield", "self", ".", "article_to_instance", "(", "paragraphs", ",", "image", ",", "caption", ",", "image_path", ",", "article", "[", "'web_url'", "]", ",", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.article_to_instance": [[148, 168], ["nytimes_position.NYTimesPositionReader._tokenizer.tokenize", "nytimes_position.NYTimesPositionReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "allennlp.data.fields.TextField", "tell.data.fields.ImageField", "allennlp.data.fields.TextField"], "methods", ["None"], ["", "", "", "def", "article_to_instance", "(", "self", ",", "paragraphs", ",", "image", ",", "caption", ",", "image_path", ",", "web_url", ",", "pos", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "fields", "=", "{", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'web_url'", ":", "web_url", ",", "\n", "'image_path'", ":", "image_path", ",", "\n", "'image_pos'", ":", "pos", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.NYTimesPositionReader.to_token_ids": [[169, 178], ["nytimes_position.NYTimesPositionReader.bpe.encode", "nytimes_position.tokenize_line", "token_ids.append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line"], ["", "def", "to_token_ids", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "bpe_tokens", "=", "self", ".", "bpe", ".", "encode", "(", "sentence", ")", "\n", "words", "=", "tokenize_line", "(", "bpe_tokens", ")", "\n", "\n", "token_ids", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "idx", "=", "self", ".", "indices", "[", "word", "]", "\n", "token_ids", ".", "append", "(", "idx", ")", "\n", "", "return", "token_ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes_position.tokenize_line": [[29, 33], ["SPACE_NORMALIZER.sub", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "tokenize_line", "(", "line", ")", ":", "\n", "    ", "line", "=", "SPACE_NORMALIZER", ".", "sub", "(", "\" \"", ",", "line", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "return", "line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened_glove.FlattenedGloveGoodNewsReader.__init__": [[40, 62], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "eval_limit", ":", "int", "=", "5120", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "goodnews", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "# Resize(256), CenterCrop(224),", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "eval_limit", "=", "eval_limit", "\n", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened_glove.FlattenedGloveGoodNewsReader._read": [[63, 96], ["logger.info", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.db.splits.find().sort", "numpy.array", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.close", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.rs.shuffle", "ValueError", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.db.splits.find_one", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.db.articles.find_one", "os.path.join", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.db.splits.find", "PIL.Image.open", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader.article_to_instance", "tqdm.tqdm.tqdm"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "# Setting the batch size is needed to avoid cursor timing out", "\n", "# We limit the validation set to 1000", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "limit", "=", "self", ".", "eval_limit", "if", "split", "==", "'val'", "else", "0", "\n", "sample_cursor", "=", "self", ".", "db", ".", "splits", ".", "find", "(", "{", "\n", "'split'", ":", "{", "'$eq'", ":", "split", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ",", "limit", "=", "limit", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "for", "sample_id", "in", "ids", ":", "\n", "            ", "sample", "=", "self", ".", "db", ".", "splits", ".", "find_one", "(", "{", "'_id'", ":", "{", "'$eq'", ":", "sample_id", "}", "}", ")", "\n", "\n", "# Find the corresponding article", "\n", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", ",", "'context'", ",", "'images'", ",", "'web_url'", "]", ")", "\n", "\n", "# Load the image", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "try", ":", "\n", "                ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "yield", "self", ".", "article_to_instance", "(", "article", ",", "image", ",", "sample", "[", "'image_index'", "]", ",", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_flattened_glove.FlattenedGloveGoodNewsReader.article_to_instance": [[97, 116], ["caption.strip.strip.strip", "goodnews_flattened_glove.FlattenedGloveGoodNewsReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "tell.data.fields.ImageField", "allennlp.data.fields.TextField", "article[].strip().split", "article[].strip"], "methods", ["None"], ["", "", "def", "article_to_instance", "(", "self", ",", "article", ",", "image", ",", "image_index", ",", "image_path", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "' '", ".", "join", "(", "article", "[", "'context'", "]", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", ":", "500", "]", ")", "\n", "caption", "=", "article", "[", "'images'", "]", "[", "image_index", "]", "\n", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "fields", "=", "{", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'web_url'", ":", "article", "[", "'web_url'", "]", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes.NYTimesReader.__init__": [[41, 60], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "nytimes", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes.NYTimesReader._read": [[61, 111], ["logger.info", "nytimes.NYTimesReader.db.articles.find().sort", "numpy.array", "nytimes.NYTimesReader.close", "nytimes.NYTimesReader.rs.shuffle", "ValueError", "nytimes.NYTimesReader.db.articles.find_one", "nytimes.NYTimesReader.db.articles.find", "[].strip", "os.path.join", "enumerate", "tqdm.tqdm.tqdm", "[].strip", "s[].strip", "paragraphs.insert", "PIL.Image.open", "len", "nytimes.NYTimesReader.article_to_instance", "par.split"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "# validation and test sets contain 10K examples each", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "split", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "'web_url'", "]", "\n", "\n", "for", "article_id", "in", "ids", ":", "\n", "            ", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "\n", "{", "'_id'", ":", "{", "'$eq'", ":", "article_id", "}", "}", ",", "projection", "=", "projection", ")", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "for", "pos", "in", "image_positions", ":", "\n", "                ", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "", "paragraphs", "=", "[", "s", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "for", "s", "in", "sections", "if", "s", "[", "'type'", "]", "==", "'paragraph'", "]", "\n", "if", "title", ":", "\n", "                    ", "paragraphs", ".", "insert", "(", "0", ",", "title", ")", "\n", "", "caption", "=", "sections", "[", "pos", "]", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "if", "not", "caption", ":", "\n", "                    ", "continue", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "image_dir", ",", "f\"{sections[pos]['hash']}.jpg\"", ")", "\n", "try", ":", "\n", "                    ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "n_words", "=", "0", "\n", "for", "i", ",", "par", "in", "enumerate", "(", "paragraphs", ")", ":", "\n", "                    ", "n_words", "+=", "len", "(", "par", ".", "split", "(", ")", ")", "\n", "if", "n_words", ">", "500", ":", "\n", "                        ", "break", "\n", "\n", "", "", "yield", "self", ".", "article_to_instance", "(", "paragraphs", "[", ":", "i", "+", "1", "]", ",", "image", ",", "caption", ",", "image_path", ",", "article", "[", "'web_url'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.nytimes.NYTimesReader.article_to_instance": [[112, 131], ["nytimes.NYTimesReader._tokenizer.tokenize", "nytimes.NYTimesReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "allennlp.data.fields.TextField", "tell.data.fields.ImageField", "allennlp.data.fields.TextField"], "methods", ["None"], ["", "", "", "def", "article_to_instance", "(", "self", ",", "paragraphs", ",", "image", ",", "caption", ",", "image_path", ",", "web_url", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "fields", "=", "{", "\n", "'context'", ":", "TextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'web_url'", ":", "web_url", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.__init__": [[42, 67], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "pymongo.MongoClient", "torchvision.transforms.Compose", "random.seed", "numpy.random.RandomState", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "Tokenizer", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "image_dir", ":", "str", ",", "\n", "mongo_host", ":", "str", "=", "'localhost'", ",", "\n", "mongo_port", ":", "int", "=", "27017", ",", "\n", "eval_limit", ":", "int", "=", "5120", ",", "\n", "use_caption_names", ":", "bool", "=", "True", ",", "\n", "n_faces", ":", "int", "=", "None", ",", "\n", "lazy", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "lazy", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_token_indexers", "=", "token_indexers", "\n", "self", ".", "client", "=", "MongoClient", "(", "host", "=", "mongo_host", ",", "port", "=", "mongo_port", ")", "\n", "self", ".", "db", "=", "self", ".", "client", ".", "goodnews", "\n", "self", ".", "image_dir", "=", "image_dir", "\n", "self", ".", "preprocess", "=", "Compose", "(", "[", "\n", "# Resize(256), CenterCrop(224),", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "self", ".", "eval_limit", "=", "eval_limit", "\n", "self", ".", "use_caption_names", "=", "use_caption_names", "\n", "self", ".", "n_faces", "=", "n_faces", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "self", ".", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "1234", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._read": [[68, 130], ["logger.info", "goodnews_copy_matched.GoodNewsCopyMatchedReader.db.splits.find().sort", "numpy.array", "goodnews_copy_matched.GoodNewsCopyMatchedReader.close", "goodnews_copy_matched.GoodNewsCopyMatchedReader.rs.shuffle", "ValueError", "goodnews_copy_matched.GoodNewsCopyMatchedReader.db.splits.find_one", "goodnews_copy_matched.GoodNewsCopyMatchedReader.db.articles.find_one", "os.path.join", "sorted", "goodnews_copy_matched.GoodNewsCopyMatchedReader._get_caption_names", "goodnews_copy_matched.GoodNewsCopyMatchedReader._process_copy_tokens", "goodnews_copy_matched.GoodNewsCopyMatchedReader._get_context_names", "goodnews_copy_matched.GoodNewsCopyMatchedReader.db.splits.find", "PIL.Image.open", "goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "numpy.array", "numpy.array", "goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "tqdm.tqdm.tqdm", "len", "goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.client.base.TellClient.close", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_caption_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._process_copy_tokens", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_context_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "split", ":", "str", ")", ":", "\n", "# split can be either train, valid, or test", "\n", "        ", "if", "split", "not", "in", "[", "'train'", ",", "'val'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f'Unknown split: {split}'", ")", "\n", "\n", "# Setting the batch size is needed to avoid cursor timing out", "\n", "# We limit the validation set to 1000", "\n", "", "limit", "=", "self", ".", "eval_limit", "if", "split", "==", "'val'", "else", "0", "\n", "\n", "logger", ".", "info", "(", "'Grabbing all article IDs'", ")", "\n", "sample_cursor", "=", "self", ".", "db", ".", "splits", ".", "find", "(", "{", "\n", "'split'", ":", "{", "'$eq'", ":", "split", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", "]", ",", "limit", "=", "limit", ")", ".", "sort", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", "\n", "\n", "ids", "=", "np", ".", "array", "(", "[", "article", "[", "'_id'", "]", "for", "article", "in", "tqdm", "(", "sample_cursor", ")", "]", ")", "\n", "sample_cursor", ".", "close", "(", ")", "\n", "self", ".", "rs", ".", "shuffle", "(", "ids", ")", "\n", "\n", "for", "sample_id", "in", "ids", ":", "\n", "            ", "sample", "=", "self", ".", "db", ".", "splits", ".", "find_one", "(", "{", "'_id'", ":", "{", "'$eq'", ":", "sample_id", "}", "}", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'context'", ",", "'images'", ",", "\n", "'web_url'", ",", "'caption_ner'", ",", "'context_ner'", ",", "\n", "'context_parts_of_speech'", ",", "'caption_parts_of_speech'", "]", "\n", "\n", "# Find the corresponding article", "\n", "article", "=", "self", ".", "db", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "projection", ")", "\n", "\n", "# Load the image", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "image_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "try", ":", "\n", "                ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "named_entities", "=", "sorted", "(", "self", ".", "_get_named_entities", "(", "article", ")", ")", "\n", "\n", "if", "self", ".", "n_faces", "is", "not", "None", ":", "\n", "                ", "n_persons", "=", "self", ".", "n_faces", "\n", "", "elif", "self", ".", "use_caption_names", ":", "\n", "                ", "n_persons", "=", "len", "(", "self", ".", "_get_person_names", "(", "\n", "article", ",", "sample", "[", "'image_index'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "n_persons", "=", "4", "\n", "\n", "", "if", "'facenet_details'", "not", "in", "sample", "or", "n_persons", "==", "0", ":", "\n", "                ", "face_embeds", "=", "np", ".", "array", "(", "[", "[", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "face_embeds", "=", "sample", "[", "'facenet_details'", "]", "[", "'embeddings'", "]", "\n", "# Keep only the top faces (sorted by size)", "\n", "face_embeds", "=", "np", ".", "array", "(", "face_embeds", "[", ":", "n_persons", "]", ")", "\n", "\n", "", "copy_infos", "=", "self", ".", "_get_caption_names", "(", "\n", "article", ",", "sample", "[", "'image_index'", "]", ")", "\n", "\n", "self", ".", "_process_copy_tokens", "(", "copy_infos", ",", "article", ")", "\n", "proper_infos", "=", "self", ".", "_get_context_names", "(", "article", ")", "\n", "\n", "yield", "self", ".", "article_to_instance", "(", "article", ",", "named_entities", ",", "face_embeds", ",", "image", ",", "sample", "[", "'image_index'", "]", ",", "image_path", ",", "copy_infos", ",", "proper_infos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.article_to_instance": [[131, 166], ["article[].strip", "caption.strip.strip.strip", "goodnews_copy_matched.GoodNewsCopyMatchedReader._tokenizer.tokenize", "goodnews_copy_matched.GoodNewsCopyMatchedReader._tokenizer.tokenize", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "goodnews_copy_matched.GoodNewsCopyMatchedReader._tokenizer.tokenize", "tell.data.fields.ListTextField", "tell.data.fields.ListTextField.empty_field", "tell.data.fields.CopyTextField", "tell.data.fields.ListTextField", "tell.data.fields.ImageField", "tell.data.fields.CopyTextField", "allennlp.data.fields.ArrayField", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.empty_field"], ["", "", "def", "article_to_instance", "(", "self", ",", "article", ",", "named_entities", ",", "face_embeds", ",", "image", ",", "image_index", ",", "image_path", ",", "copy_infos", ",", "proper_infos", ")", "->", "Instance", ":", "\n", "        ", "context", "=", "article", "[", "'context'", "]", ".", "strip", "(", ")", "\n", "\n", "caption", "=", "article", "[", "'images'", "]", "[", "image_index", "]", "\n", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "\n", "context_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "context", ")", "\n", "caption_tokens", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "\n", "name_token_list", "=", "[", "self", ".", "_tokenizer", ".", "tokenize", "(", "n", ")", "for", "n", "in", "named_entities", "]", "\n", "\n", "if", "name_token_list", ":", "\n", "            ", "name_field", "=", "[", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "for", "tokens", "in", "name_token_list", "]", "\n", "", "else", ":", "\n", "            ", "stub_field", "=", "ListTextField", "(", "\n", "[", "TextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ")", "]", ")", "\n", "name_field", "=", "stub_field", ".", "empty_field", "(", ")", "\n", "\n", "", "fields", "=", "{", "\n", "'context'", ":", "CopyTextField", "(", "context_tokens", ",", "self", ".", "_token_indexers", ",", "copy_infos", ",", "proper_infos", ",", "'context'", ")", ",", "\n", "'names'", ":", "ListTextField", "(", "name_field", ")", ",", "\n", "'image'", ":", "ImageField", "(", "image", ",", "self", ".", "preprocess", ")", ",", "\n", "'caption'", ":", "CopyTextField", "(", "caption_tokens", ",", "self", ".", "_token_indexers", ",", "copy_infos", ",", "None", ",", "'caption'", ")", ",", "\n", "'face_embeds'", ":", "ArrayField", "(", "face_embeds", ",", "padding_value", "=", "np", ".", "nan", ")", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "'context'", ":", "context", ",", "\n", "'caption'", ":", "caption", ",", "\n", "'names'", ":", "named_entities", ",", "\n", "'web_url'", ":", "article", "[", "'web_url'", "]", ",", "\n", "'image_path'", ":", "image_path", "}", "\n", "fields", "[", "'metadata'", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "\n", "return", "Instance", "(", "fields", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_named_entities": [[167, 178], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_named_entities", "(", "self", ",", "article", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'context_ner'", "in", "article", ":", "\n", "            ", "ners", "=", "article", "[", "'context_ner'", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", ",", "'ORG'", ",", "'GPE'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_person_names": [[179, 190], ["set", "set.add"], "methods", ["None"], ["", "def", "_get_person_names", "(", "self", ",", "article", ",", "pos", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "        ", "names", "=", "set", "(", ")", "\n", "\n", "if", "'caption_ner'", "in", "article", ":", "\n", "            ", "ners", "=", "article", "[", "'caption_ner'", "]", "[", "pos", "]", "\n", "for", "ner", "in", "ners", ":", "\n", "                ", "if", "ner", "[", "'label'", "]", "in", "[", "'PERSON'", "]", ":", "\n", "                    ", "names", ".", "add", "(", "ner", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_caption_names": [[191, 208], ["goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner", "collections.OrderedDict", "[].append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner"], ["", "def", "_get_caption_names", "(", "self", ",", "article", ",", "idx", ")", ":", "\n", "        ", "copy_infos", "=", "{", "}", "\n", "\n", "parts_of_speech", "=", "article", "[", "'caption_parts_of_speech'", "]", "[", "idx", "]", "\n", "caption_ner", "=", "article", "[", "'caption_ner'", "]", "[", "idx", "]", "\n", "for", "pos", "in", "parts_of_speech", ":", "\n", "            ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "self", ".", "is_in_ner", "(", "pos", "[", "'text'", "]", ",", "caption_ner", ")", ":", "\n", "                ", "if", "pos", "[", "'text'", "]", "not", "in", "copy_infos", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "=", "OrderedDict", "(", "{", "\n", "'caption'", ":", "[", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", "]", ",", "\n", "'context'", ":", "[", "]", "\n", "}", ")", "\n", "", "else", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "[", "'caption'", "]", ".", "append", "(", "\n", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", ")", "\n", "\n", "", "", "", "return", "copy_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._get_context_names": [[209, 225], ["goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner", "collections.OrderedDict", "[].append"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner"], ["", "def", "_get_context_names", "(", "self", ",", "article", ")", ":", "\n", "        ", "copy_infos", "=", "{", "}", "\n", "\n", "context_pos", "=", "article", "[", "'context_parts_of_speech'", "]", "\n", "context_ners", "=", "article", "[", "'context_ner'", "]", "\n", "for", "pos", "in", "context_pos", ":", "\n", "            ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "self", ".", "is_in_ner", "(", "pos", "[", "'text'", "]", ",", "context_ners", ")", ":", "\n", "                ", "if", "pos", "[", "'text'", "]", "not", "in", "copy_infos", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "=", "OrderedDict", "(", "{", "\n", "'context'", ":", "[", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", "]", "\n", "}", ")", "\n", "", "else", ":", "\n", "                    ", "copy_infos", "[", "pos", "[", "'text'", "]", "]", "[", "'context'", "]", ".", "append", "(", "\n", "(", "pos", "[", "'start'", "]", ",", "pos", "[", "'end'", "]", ")", ")", "\n", "\n", "", "", "", "return", "copy_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader._process_copy_tokens": [[226, 234], ["copy_infos.items", "info[].append"], "methods", ["None"], ["", "def", "_process_copy_tokens", "(", "self", ",", "copy_infos", ",", "article", ")", ":", "\n", "        ", "context_pos", "=", "article", "[", "'context_parts_of_speech'", "]", "\n", "for", "name", ",", "info", "in", "copy_infos", ".", "items", "(", ")", ":", "\n", "            ", "for", "pos", "in", "context_pos", ":", "\n", "                ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "and", "pos", "[", "'text'", "]", "==", "name", ":", "\n", "                    ", "info", "[", "'context'", "]", ".", "append", "(", "(", "\n", "pos", "[", "'start'", "]", ",", "\n", "pos", "[", "'end'", "]", ",", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.dataset_readers.goodnews_copy_matched.GoodNewsCopyMatchedReader.is_in_ner": [[236, 241], ["None"], "methods", ["None"], ["", "", "", "", "def", "is_in_ner", "(", "self", ",", "text", ",", "ners", ")", ":", "\n", "        ", "for", "ner", "in", "ners", ":", "\n", "            ", "if", "text", "in", "ner", "[", "'text'", "]", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.list_text_field.ListTextField.get_padding_lengths": [[8, 14], ["super().get_padding_lengths"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.get_padding_lengths"], ["    ", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "padding_lengths", "=", "super", "(", ")", ".", "get_padding_lengths", "(", ")", "\n", "padding_lengths", "[", "'total_num_tokens'", "]", "=", "padding_lengths", "[", "'num_fields'", "]", "*", "padding_lengths", "[", "'list_num_tokens'", "]", "\n", "return", "padding_lengths", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.copy_text_field.CopyTextField.__init__": [[13, 23], ["allennlp.data.fields.TextField.__init__"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "tokens", ":", "List", "[", "Token", "]", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", ",", "\n", "copy_infos", ":", "Dict", "[", "str", ",", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", ",", "\n", "proper_infos", ",", "\n", "key", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tokens", ",", "token_indexers", ")", "\n", "self", ".", "copy_infos", "=", "copy_infos", "\n", "self", ".", "proper_infos", "=", "proper_infos", "\n", "self", ".", "key", "=", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.copy_text_field.CopyTextField.index": [[24, 40], ["copy_text_field.CopyTextField._token_indexers.items", "indexer.tokens_to_indices", "token_arrays.update", "list", "indexer.tokens_to_indices.keys"], "methods", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.tokens_to_indices", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "token_arrays", ":", "Dict", "[", "str", ",", "TokenList", "]", "=", "{", "}", "\n", "indexer_name_to_indexed_token", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "{", "}", "\n", "token_index_to_indexer_name", ":", "Dict", "[", "str", ",", "str", "]", "=", "{", "}", "\n", "for", "indexer_name", ",", "indexer", "in", "self", ".", "_token_indexers", ".", "items", "(", ")", ":", "\n", "            ", "token_indices", "=", "indexer", ".", "tokens_to_indices", "(", "\n", "self", ".", "tokens", ",", "vocab", ",", "indexer_name", ",", "self", ".", "copy_infos", ",", "self", ".", "proper_infos", ",", "self", ".", "key", ")", "\n", "token_arrays", ".", "update", "(", "token_indices", ")", "\n", "indexer_name_to_indexed_token", "[", "indexer_name", "]", "=", "list", "(", "\n", "token_indices", ".", "keys", "(", ")", ")", "\n", "for", "token_index", "in", "token_indices", ":", "\n", "                ", "token_index_to_indexer_name", "[", "token_index", "]", "=", "indexer_name", "\n", "", "", "self", ".", "_indexed_tokens", "=", "token_arrays", "\n", "self", ".", "_indexer_name_to_indexed_token", "=", "indexer_name_to_indexed_token", "\n", "self", ".", "_token_index_to_indexer_name", "=", "token_index_to_indexer_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__init__": [[23, 30], ["preprocess"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "image", ":", "Image", ",", "\n", "preprocess", ":", "Compose", ",", "\n", "padding_value", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "image", "=", "preprocess", "(", "image", ")", "\n", "self", ".", "padding_value", "=", "padding_value", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.get_padding_lengths": [[31, 37], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "\n", "'channels'", ":", "self", ".", "image", ".", "shape", "[", "0", "]", ",", "\n", "'height'", ":", "self", ".", "image", ".", "shape", "[", "1", "]", ",", "\n", "'width'", ":", "self", ".", "image", ".", "shape", "[", "2", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.as_tensor": [[39, 42], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.empty_field": [[43, 47], ["image_field.ImageField", "numpy.empty", "torchvision.transforms.Compose"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", ":", "# pylint: disable=no-self-use", "\n", "        ", "return", "ImageField", "(", "np", ".", "empty", "(", "self", ".", "image", ".", "shape", ")", ",", "Compose", "(", "[", "]", ")", ",", "\n", "padding_value", "=", "self", ".", "padding_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.fields.image_field.ImageField.__str__": [[48, 50], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "f\"ImageField with shape: {self.image.shape}.\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.evaluate_from_file": [[31, 87], ["torch.cuda.is_available", "archive_path.endswith", "allennlp.training.util.datasets_from_params", "allennlp.data.vocabulary.Vocabulary.from_params", "allennlp.models.Model.from_params", "allennlp.training.util.datasets_from_params.get", "allennlp.data.iterators.DataIterator.from_params", "DataIterator.from_params.index_with", "Model.from_params.eval().to", "evaluate.evaluate", "logger.info", "logger.info", "evaluate.items", "os.path.join", "torch.device", "torch.device", "allennlp.models.archival.load_archive", "allennlp.common.util.prepare_environment", "os.path.dirname", "archive_path.endswith", "train.yaml_to_params.pop", "torch.load", "Model.from_params.load_state_dict", "train.yaml_to_params.pop", "logger.info", "train.yaml_to_params", "allennlp.common.util.prepare_environment", "os.path.dirname", "os.path.join", "train.yaml_to_params.pop", "Model.from_params.eval", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_embedders.sum_text_field_embedder.SumTextFieldEmbedder.from_params", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.evaluate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.yaml_to_params"], ["def", "evaluate_from_file", "(", "archive_path", ",", "model_path", ",", "overrides", "=", "None", ",", "eval_suffix", "=", "''", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "if", "archive_path", ".", "endswith", "(", "'gz'", ")", ":", "\n", "        ", "archive", "=", "load_archive", "(", "archive_path", ",", "device", ",", "overrides", ")", "\n", "config", "=", "archive", ".", "config", "\n", "prepare_environment", "(", "config", ")", "\n", "model", "=", "archive", ".", "model", "\n", "serialization_dir", "=", "os", ".", "path", ".", "dirname", "(", "archive_path", ")", "\n", "", "elif", "archive_path", ".", "endswith", "(", "'yaml'", ")", ":", "\n", "        ", "config", "=", "yaml_to_params", "(", "archive_path", ",", "overrides", ")", "\n", "prepare_environment", "(", "config", ")", "\n", "config_dir", "=", "os", ".", "path", ".", "dirname", "(", "archive_path", ")", "\n", "serialization_dir", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "'serialization'", ")", "\n", "\n", "", "all_datasets", "=", "datasets_from_params", "(", "config", ")", "\n", "\n", "# We want to create the vocab from scratch since it might be of a", "\n", "# different type. Vocabulary.from_files will always create the base", "\n", "# Vocabulary instance.", "\n", "# if os.path.exists(os.path.join(serialization_dir, \"vocabulary\")):", "\n", "#     vocab_path = os.path.join(serialization_dir, \"vocabulary\")", "\n", "#     vocab = Vocabulary.from_files(vocab_path)", "\n", "\n", "vocab", "=", "Vocabulary", ".", "from_params", "(", "config", ".", "pop", "(", "'vocabulary'", ")", ")", "\n", "model", "=", "Model", ".", "from_params", "(", "vocab", "=", "vocab", ",", "params", "=", "config", ".", "pop", "(", "'model'", ")", ")", "\n", "\n", "if", "model_path", ":", "\n", "        ", "best_model_state", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "device", ")", "\n", "model", ".", "load_state_dict", "(", "best_model_state", ")", "\n", "\n", "", "instances", "=", "all_datasets", ".", "get", "(", "'test'", ")", "\n", "iterator", "=", "DataIterator", ".", "from_params", "(", "\n", "config", ".", "pop", "(", "\"validation_iterator\"", ")", ")", "\n", "\n", "iterator", ".", "index_with", "(", "model", ".", "vocab", ")", "\n", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "evaluate_mode", "=", "True", "\n", "\n", "metrics", "=", "evaluate", "(", "model", ",", "instances", ",", "iterator", ",", "\n", "device", ",", "serialization_dir", ",", "eval_suffix", ",", "batch_weight_key", "=", "''", ")", "\n", "\n", "logger", ".", "info", "(", "\"Finished evaluating.\"", ")", "\n", "logger", ".", "info", "(", "\"Metrics:\"", ")", "\n", "for", "key", ",", "metric", "in", "metrics", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"%s: %s\"", ",", "key", ",", "metric", ")", "\n", "\n", "", "output_file", "=", "os", ".", "path", ".", "join", "(", "\n", "serialization_dir", ",", "f\"evaluate-metrics{eval_suffix}.json\"", ")", "\n", "if", "output_file", ":", "\n", "        ", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "file", ":", "\n", "            ", "json", ".", "dump", "(", "metrics", ",", "file", ",", "indent", "=", "4", ")", "\n", "", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.evaluate": [[89, 177], ["spacy.load", "os.path.exists", "os.path.exists", "torch.no_grad", "model.eval", "data_iterator", "logger.info", "allennlp.common.tqdm.Tqdm.tqdm", "model.get_metrics", "os.path.exists", "os.path.join", "open", "pickle.load", "torch.cuda.is_available", "model", "model.get", "evaluate.write_to_json", "model.get_metrics", "Tqdm.tqdm.set_description", "open", "pickle.dump", "data_iterator.get_num_batches", "allennlp.nn.util.move_to_device", "any", "logger.warning", "output_dict[].item", "output_dict.get.item", "metric_name.startswith", "model.get_metrics.items", "name.startswith"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.get_metrics", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.write_to_json", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.get_metrics", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning"], ["", "def", "evaluate", "(", "model", ":", "Model", ",", "\n", "instances", ":", "Iterable", "[", "Instance", "]", ",", "\n", "data_iterator", ":", "DataIterator", ",", "\n", "cuda_device", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "eval_suffix", ":", "str", ",", "\n", "batch_weight_key", ":", "str", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "# check_for_gpu(cuda_device)", "\n", "    ", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_lg\"", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "\n", "serialization_dir", ",", "f'generations{eval_suffix}.jsonl'", ")", ")", "\n", "\n", "# caching saves us extra 30 minutes", "\n", "if", "'goodnews'", "in", "serialization_dir", ":", "\n", "        ", "cache_path", "=", "'data/goodnews/evaluation_cache.pkl'", "\n", "", "elif", "'nytimes'", "in", "serialization_dir", ":", "\n", "        ", "cache_path", "=", "'data/nytimes/evaluation_cache.pkl'", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "with", "open", "(", "cache_path", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "cache", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "cache", "=", "{", "}", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "iterator", "=", "data_iterator", "(", "instances", ",", "\n", "num_epochs", "=", "1", ",", "\n", "shuffle", "=", "False", ")", "\n", "logger", ".", "info", "(", "\"Iterating over dataset\"", ")", "\n", "generator_tqdm", "=", "Tqdm", ".", "tqdm", "(", "\n", "iterator", ",", "total", "=", "data_iterator", ".", "get_num_batches", "(", "instances", ")", ")", "\n", "\n", "# Number of batches in instances.", "\n", "batch_count", "=", "0", "\n", "# Number of batches where the model produces a loss.", "\n", "loss_count", "=", "0", "\n", "# Cumulative weighted loss", "\n", "total_loss", "=", "0.0", "\n", "# Cumulative weight across all batches.", "\n", "total_weight", "=", "0.0", "\n", "\n", "for", "batch", "in", "generator_tqdm", ":", "\n", "            ", "batch_count", "+=", "1", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "batch", "=", "nn_util", ".", "move_to_device", "(", "batch", ",", "cuda_device", ")", "\n", "", "output_dict", "=", "model", "(", "**", "batch", ")", "\n", "loss", "=", "output_dict", ".", "get", "(", "\"loss\"", ")", "\n", "\n", "write_to_json", "(", "output_dict", ",", "serialization_dir", ",", "\n", "nlp", ",", "eval_suffix", ",", "cache", ")", "\n", "\n", "metrics", "=", "model", ".", "get_metrics", "(", ")", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss_count", "+=", "1", "\n", "if", "batch_weight_key", ":", "\n", "                    ", "weight", "=", "output_dict", "[", "batch_weight_key", "]", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                    ", "weight", "=", "1.0", "\n", "\n", "", "total_weight", "+=", "weight", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "*", "weight", "\n", "# Report the average loss so far.", "\n", "metrics", "[", "\"loss\"", "]", "=", "total_loss", "/", "total_weight", "\n", "\n", "", "if", "(", "not", "HasBeenWarned", ".", "tqdm_ignores_underscores", "and", "\n", "any", "(", "metric_name", ".", "startswith", "(", "\"_\"", ")", "for", "metric_name", "in", "metrics", ")", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Metrics with names beginning with \\\"_\\\" will \"", "\n", "\"not be logged to the tqdm progress bar.\"", ")", "\n", "HasBeenWarned", ".", "tqdm_ignores_underscores", "=", "True", "\n", "", "description", "=", "', '", ".", "join", "(", "[", "\"%s: %.2f\"", "%", "(", "name", ",", "value", ")", "for", "name", ",", "value", "\n", "in", "metrics", ".", "items", "(", ")", "if", "not", "name", ".", "startswith", "(", "\"_\"", ")", "]", ")", "+", "\" ||\"", "\n", "generator_tqdm", ".", "set_description", "(", "description", ",", "refresh", "=", "False", ")", "\n", "\n", "", "final_metrics", "=", "model", ".", "get_metrics", "(", "reset", "=", "True", ")", "\n", "if", "loss_count", ">", "0", ":", "\n", "# Sanity check", "\n", "# if loss_count != batch_count:", "\n", "#     raise RuntimeError(\"The model you are trying to evaluate only sometimes \" +", "\n", "#                        \"produced a loss!\")", "\n", "            ", "final_metrics", "[", "\"loss\"", "]", "=", "total_loss", "/", "total_weight", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "cache", ",", "f", ")", "\n", "\n", "", "", "return", "final_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.write_to_json": [[179, 224], ["os.path.join", "open", "enumerate", "evaluate.spacize", "nlp", "evaluate.spacize", "f.write", "range", "evaluate.get_proper_nouns", "evaluate.get_proper_nouns", "evaluate.get_proper_nouns", "evaluate.get_entities", "evaluate.get_entities", "evaluate.get_entities", "evaluate.get_readability_scores", "evaluate.get_readability_scores", "evaluate.get_narrative_productivity", "evaluate.get_narrative_productivity", "len", "json.dumps"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.spacize", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.spacize", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_proper_nouns", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_proper_nouns", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_proper_nouns", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_readability_scores", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_readability_scores", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_narrative_productivity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_narrative_productivity"], ["", "def", "write_to_json", "(", "output_dict", ",", "serialization_dir", ",", "nlp", ",", "eval_suffix", ",", "cache", ")", ":", "\n", "    ", "if", "'captions'", "not", "in", "output_dict", ":", "\n", "        ", "return", "\n", "\n", "", "captions", "=", "output_dict", "[", "'captions'", "]", "\n", "generations", "=", "output_dict", "[", "'generations'", "]", "\n", "metadatas", "=", "output_dict", "[", "'metadata'", "]", "\n", "if", "'copied_texts'", "in", "output_dict", ":", "\n", "        ", "copied_texts", "=", "output_dict", "[", "'copied_texts'", "]", "\n", "", "else", ":", "\n", "        ", "copied_texts", "=", "[", "''", "for", "_", "in", "range", "(", "len", "(", "captions", ")", ")", "]", "\n", "\n", "", "out_path", "=", "os", ".", "path", ".", "join", "(", "\n", "serialization_dir", ",", "f'generations{eval_suffix}.jsonl'", ")", "\n", "with", "open", "(", "out_path", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "for", "i", ",", "caption", "in", "enumerate", "(", "captions", ")", ":", "\n", "            ", "m", "=", "metadatas", "[", "i", "]", "\n", "generation", "=", "generations", "[", "i", "]", "\n", "caption_doc", "=", "spacize", "(", "m", "[", "'caption'", "]", ",", "cache", ",", "nlp", ")", "\n", "gen_doc", "=", "nlp", "(", "generation", ")", "\n", "context_doc", "=", "spacize", "(", "m", "[", "'context'", "]", ",", "cache", ",", "nlp", ")", "\n", "obj", "=", "{", "\n", "'caption'", ":", "caption", ",", "\n", "'raw_caption'", ":", "m", "[", "'caption'", "]", ",", "\n", "'generation'", ":", "generation", ",", "\n", "'copied_texts'", ":", "copied_texts", "[", "i", "]", ",", "\n", "'web_url'", ":", "m", "[", "'web_url'", "]", ",", "\n", "'image_path'", ":", "m", "[", "'image_path'", "]", ",", "\n", "'context'", ":", "m", "[", "'context'", "]", ",", "\n", "'caption_names'", ":", "get_proper_nouns", "(", "caption_doc", ")", ",", "\n", "'generated_names'", ":", "get_proper_nouns", "(", "gen_doc", ")", ",", "\n", "'context_names'", ":", "get_proper_nouns", "(", "context_doc", ")", ",", "\n", "'caption_entities'", ":", "get_entities", "(", "caption_doc", ")", ",", "\n", "'generated_entities'", ":", "get_entities", "(", "gen_doc", ")", ",", "\n", "'context_entities'", ":", "get_entities", "(", "context_doc", ")", ",", "\n", "'caption_readability'", ":", "get_readability_scores", "(", "m", "[", "'caption'", "]", ")", ",", "\n", "'gen_readability'", ":", "get_readability_scores", "(", "generation", ")", ",", "\n", "'caption_np'", ":", "get_narrative_productivity", "(", "m", "[", "'caption'", "]", ")", ",", "\n", "'gen_np'", ":", "get_narrative_productivity", "(", "generation", ")", ",", "\n", "}", "\n", "\n", "if", "'copied_texts'", "in", "output_dict", ":", "\n", "                ", "obj", "[", "'copied_text'", "]", "=", "output_dict", "[", "'copied_texts'", "]", "[", "i", "]", "\n", "\n", "", "f", ".", "write", "(", "f'{json.dumps(obj)}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.spacize": [[226, 232], ["hashlib.sha256().hexdigest", "spacy.tokens.Doc().from_bytes", "nlp().to_bytes", "hashlib.sha256", "spacy.tokens.Doc", "text.encode", "nlp"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "", "", "def", "spacize", "(", "text", ",", "cache", ",", "nlp", ")", ":", "\n", "    ", "key", "=", "hashlib", ".", "sha256", "(", "text", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", "\n", "if", "key", "not", "in", "cache", ":", "\n", "        ", "cache", "[", "key", "]", "=", "nlp", "(", "text", ")", ".", "to_bytes", "(", ")", "\n", "\n", "", "return", "Doc", "(", "nlp", ".", "vocab", ")", ".", "from_bytes", "(", "cache", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.get_proper_nouns": [[234, 240], ["proper_nouns.append"], "function", ["None"], ["", "def", "get_proper_nouns", "(", "doc", ")", ":", "\n", "    ", "proper_nouns", "=", "[", "]", "\n", "for", "token", "in", "doc", ":", "\n", "        ", "if", "token", ".", "pos_", "==", "'PROPN'", ":", "\n", "            ", "proper_nouns", ".", "append", "(", "token", ".", "text", ")", "\n", "", "", "return", "proper_nouns", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.get_entities": [[242, 251], ["entities.append"], "function", ["None"], ["", "def", "get_entities", "(", "doc", ")", ":", "\n", "    ", "entities", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "        ", "entities", ".", "append", "(", "{", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "'tokens'", ":", "[", "{", "'text'", ":", "tok", ".", "text", ",", "'pos'", ":", "tok", ".", "pos_", "}", "for", "tok", "in", "ent", "]", ",", "\n", "}", ")", "\n", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.get_readability_scores": [[253, 267], ["textstat.flesch_reading_ease", "textstat.flesch_kincaid_grade", "textstat.gunning_fog", "textstat.smog_index", "textstat.automated_readability_index", "textstat.coleman_liau_index", "textstat.linsear_write_formula", "textstat.dale_chall_readability_score", "textstat.text_standard", "textstat.difficult_words", "len", "text.split"], "function", ["None"], ["", "def", "get_readability_scores", "(", "text", ")", ":", "\n", "    ", "scores", "=", "{", "\n", "'flesch_reading_ease'", ":", "textstat", ".", "flesch_reading_ease", "(", "text", ")", ",", "\n", "'flesch_kincaid_grade'", ":", "textstat", ".", "flesch_kincaid_grade", "(", "text", ")", ",", "\n", "'gunning_fog'", ":", "textstat", ".", "gunning_fog", "(", "text", ")", ",", "\n", "'smog_index'", ":", "textstat", ".", "smog_index", "(", "text", ")", ",", "\n", "'automated_readability_index'", ":", "textstat", ".", "automated_readability_index", "(", "text", ")", ",", "\n", "'coleman_liau_index'", ":", "textstat", ".", "coleman_liau_index", "(", "text", ")", ",", "\n", "'linsear_write_formula'", ":", "textstat", ".", "linsear_write_formula", "(", "text", ")", ",", "\n", "'dale_chall_readability_score'", ":", "textstat", ".", "dale_chall_readability_score", "(", "text", ")", ",", "\n", "'text_standard'", ":", "textstat", ".", "text_standard", "(", "text", ",", "float_output", "=", "True", ")", ",", "\n", "'difficult_words'", ":", "textstat", ".", "difficult_words", "(", "text", ")", "/", "len", "(", "text", ".", "split", "(", ")", ")", ",", "\n", "}", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.is_word": [[269, 271], ["None"], "function", ["None"], ["", "def", "is_word", "(", "tok", ")", ":", "\n", "    ", "return", "tok", "not", "in", "string", ".", "punctuation", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.get_narrative_productivity": [[273, 289], ["nltk.tokenize.word_tokenize", "list", "len", "len", "filter", "set", "evaluate.basic_ttr", "evaluate.root_ttr", "evaluate.corrected_ttr", "evaluate.herdan", "evaluate.summer", "evaluate.maas"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.basic_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.root_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.corrected_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.herdan", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.summer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.maas"], ["", "def", "get_narrative_productivity", "(", "text", ")", ":", "\n", "    ", "doc", "=", "word_tokenize", "(", "text", ")", "\n", "doc", "=", "list", "(", "filter", "(", "is_word", ",", "doc", ")", ")", "\n", "n_words", "=", "len", "(", "doc", ")", "\n", "n_terms", "=", "len", "(", "set", "(", "doc", ")", ")", "\n", "\n", "scores", "=", "{", "\n", "'basic_ttr'", ":", "basic_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'root_ttr'", ":", "root_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'corrected_ttr'", ":", "corrected_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'herdan'", ":", "herdan", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'summer'", ":", "summer", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'maas'", ":", "maas", "(", "n_terms", ",", "n_words", ")", ",", "\n", "}", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.basic_ttr": [[291, 299], ["None"], "function", ["None"], ["", "def", "basic_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Type-token ratio (TTR) computed as t/w, where t is the number of unique\n    terms/vocab, and w is the total number of words.\n    (Chotlos 1944, Templin 1957)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.root_ttr": [[301, 310], ["math.sqrt"], "function", ["None"], ["", "def", "root_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Root TTR (RTTR) computed as t/sqrt(w), where t is the number of unique terms/vocab,\n        and w is the total number of words.\n        Also known as Guiraud's R and Guiraud's index.\n        (Guiraud 1954, 1960)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "math", ".", "sqrt", "(", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.corrected_ttr": [[312, 320], ["math.sqrt"], "function", ["None"], ["", "def", "corrected_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Corrected TTR (CTTR) computed as t/sqrt(2 * w), where t is the number of unique terms/vocab,\n        and w is the total number of words.\n        (Carrol 1964)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "math", ".", "sqrt", "(", "2", "*", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.herdan": [[322, 331], ["math.log", "math.log"], "function", ["None"], ["", "def", "herdan", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Computed as log(t)/log(w), where t is the number of unique terms/vocab, and w is the\n        total number of words.\n        Also known as Herdan's C.\n        (Herdan 1960, 1964)\n    \"\"\"", "\n", "if", "n_words", "<=", "1", ":", "\n", "        ", "return", "0", "\n", "", "return", "math", ".", "log", "(", "n_terms", ")", "/", "math", ".", "log", "(", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.summer": [[333, 342], ["math.log", "math.log", "math.log", "math.log"], "function", ["None"], ["", "def", "summer", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Computed as log(log(t)) / log(log(w)), where t is the number of unique terms/vocab, and\n        w is the total number of words.\n        (Summer 1966)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "math", ".", "log", "(", "math", ".", "log", "(", "n_terms", ")", ")", "/", "math", ".", "log", "(", "math", ".", "log", "(", "n_words", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.maas": [[344, 356], ["min", "math.log", "math.log", "math.log"], "function", ["None"], ["", "", "def", "maas", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Maas's TTR, computed as (log(w) - log(t)) / (log(w) * log(w)), where t is the number of\n        unique terms/vocab, and w is the total number of words. Unlike the other measures, lower\n        maas measure indicates higher lexical richness.\n        (Maas 1972)\n    \"\"\"", "\n", "# We cap this score at 0.2", "\n", "if", "n_words", "<=", "1", ":", "\n", "        ", "return", "0.2", "\n", "", "score", "=", "(", "math", ".", "log", "(", "n_words", ")", "-", "math", ".", "log", "(", "n_terms", ")", ")", "/", "(", "math", ".", "log", "(", "n_words", ")", "**", "2", ")", "\n", "return", "min", "(", "score", ",", "0.2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.train_model_from_file": [[12, 65], ["parameter_filename.endswith", "allennlp.commands.train.train_model", "train.yaml_to_params", "allennlp.common.params.Params.from_file", "os.path.dirname", "os.path.join"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.yaml_to_params"], ["def", "train_model_from_file", "(", "parameter_filename", ":", "str", ",", "\n", "serialization_dir", ":", "str", ",", "\n", "overrides", ":", "str", "=", "\"\"", ",", "\n", "file_friendly_logging", ":", "bool", "=", "False", ",", "\n", "recover", ":", "bool", "=", "False", ",", "\n", "force", ":", "bool", "=", "False", ",", "\n", "cache_directory", ":", "str", "=", "None", ",", "\n", "cache_prefix", ":", "str", "=", "None", ")", "->", "Model", ":", "\n", "    ", "\"\"\"\n    A wrapper around :func:`train_model` which loads the params from a file.\n\n    We overwrite the AllenNLP function to support YAML config files. We also\n    set the default serialization directory to be where the config file lives.\n\n    Parameters\n    ----------\n    parameter_filename : ``str``\n        A json parameter file specifying an AllenNLP experiment.\n    serialization_dir : ``str``\n        The directory in which to save results and logs. We just pass this along to\n        :func:`train_model`.\n    overrides : ``str``\n        A JSON string that we will use to override values in the input parameter file.\n    file_friendly_logging : ``bool``, optional (default=False)\n        If ``True``, we make our output more friendly to saved model files.  We just pass this\n        along to :func:`train_model`.\n    recover : ``bool`, optional (default=False)\n        If ``True``, we will try to recover a training run from an existing serialization\n        directory.  This is only intended for use when something actually crashed during the middle\n        of a run.  For continuing training a model on new data, see the ``fine-tune`` command.\n    force : ``bool``, optional (default=False)\n        If ``True``, we will overwrite the serialization directory if it already exists.\n    cache_directory : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n    cache_prefix : ``str``, optional\n        For caching data pre-processing.  See :func:`allennlp.training.util.datasets_from_params`.\n    \"\"\"", "\n", "# Load the experiment config from a file and pass it to ``train_model``.", "\n", "if", "parameter_filename", ".", "endswith", "(", "(", "'.yaml'", ",", "'.yml'", ")", ")", ":", "\n", "        ", "params", "=", "yaml_to_params", "(", "parameter_filename", ",", "overrides", ")", "\n", "", "else", ":", "\n", "        ", "params", "=", "Params", ".", "from_file", "(", "parameter_filename", ",", "overrides", ")", "\n", "\n", "", "if", "not", "serialization_dir", ":", "\n", "        ", "config_dir", "=", "os", ".", "path", ".", "dirname", "(", "parameter_filename", ")", "\n", "serialization_dir", "=", "os", ".", "path", ".", "join", "(", "config_dir", ",", "'serialization'", ")", "\n", "\n", "", "return", "train_model", "(", "params", ",", "\n", "serialization_dir", ",", "\n", "file_friendly_logging", ",", "\n", "recover", ",", "\n", "force", ",", "\n", "cache_directory", ",", "cache_prefix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.yaml_to_params": [[67, 78], ["allennlp.common.file_utils.cached_path", "allennlp.common.params.parse_overrides", "allennlp.common.params.with_fallback", "allennlp.common.params.Params", "open", "yaml.safe_load"], "function", ["None"], ["", "def", "yaml_to_params", "(", "params_file", ":", "str", ",", "overrides", ":", "str", "=", "\"\"", ")", "->", "Params", ":", "\n", "# redirect to cache, if necessary", "\n", "    ", "params_file", "=", "cached_path", "(", "params_file", ")", "\n", "\n", "with", "open", "(", "params_file", ")", "as", "f", ":", "\n", "        ", "file_dict", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "overrides_dict", "=", "parse_overrides", "(", "overrides", ")", "\n", "param_dict", "=", "with_fallback", "(", "preferred", "=", "overrides_dict", ",", "fallback", "=", "file_dict", ")", "\n", "\n", "return", "Params", "(", "param_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.__main__.validate": [[51, 65], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Or", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["        ", "pudb", ".", "set_trace", "(", ")", "\n", "\n", "", "with", "NLPServer", "(", "task", "=", "args", "[", "'task'", "]", ",", "\n", "n_workers", "=", "args", "[", "'n_workers'", "]", ",", "\n", "port", "=", "args", "[", "'port'", "]", ",", "\n", "port_out", "=", "args", "[", "'port_out'", "]", ")", "as", "server", ":", "\n", "        ", "server", ".", "join", "(", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.__main__.main": [[67, 100], ["docopt.docopt", "__main__.validate", "logger.setLevel", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "logging.getLogger().setLevel", "train.train_model_from_file", "pudb.set_trace", "logging.getLogger", "logging.getLogger", "evaluate.evaluate_from_file", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.train.train_model_from_file", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.commands.evaluate.evaluate_from_file"], []], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.strip_html": [[31, 40], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.get_text"], "function", ["None"], ["def", "strip_html", "(", "text", ")", ":", "\n", "    ", "\"\"\"Remove/replace HTML elements, e.g.\n\n    An auction at Christie&apos;s in New York.\n    <b> PRECEDENT </b> The 1885 label of a drink made by the inventor of Coca-Cola.\n    <strong>CHANGING TECHNOLOGY</strong>  Sandbags are the traditional solution, but Fargo is turning to newer innovations like TrapBags.\n    \"\"\"", "\n", "soup", "=", "BeautifulSoup", "(", "text", ",", "\"html.parser\"", ")", "\n", "return", "soup", ".", "get_text", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.remove_between_square_brackets": [[42, 59], ["re.sub"], "function", ["None"], ["", "def", "remove_between_square_brackets", "(", "text", ")", ":", "\n", "    ", "\"\"\"Remove square annotations, e.g.\n\n    Cora Bissett and Matthew Pidgeon in \"Midsummer [a play with songs].\"\n    \u201cPanthers Indoctrinate The Young,\u201d Aug. 18, 1969. [Click to read on desktop]\n    \"[To be titled],\" 2015.\n\n    But not all squares are bad, e.g.\n\n    Hujar\u2019s \u201cSusan Sontag,\u201d 1975, and \u201cFran Lebowitz [at Home in Morristown],\u201d 1974.\n    Pau Poch in \u201c[REC]2,\u201d about a paramilitary team in Barcelona.\n    Chadwick Boseman: \u201cA lot of times, being [a black man] in Hollywood, when you get material you\u2019ll read it and you\u2019ll be like, \u2018That\u2019s not us.\u2019\u201d\n    Will Rawls performing in \u201cI make me [sic].\u201d\n\n    We keep this anyway to be consistent with the original dataset.\n    \"\"\"", "\n", "return", "re", ".", "sub", "(", "'\\[[^]]*\\]'", ",", "''", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.denoise_text": [[61, 65], ["get_articles_goodnews.strip_html", "get_articles_goodnews.remove_between_square_brackets"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.strip_html", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.remove_between_square_brackets"], ["", "def", "denoise_text", "(", "text", ")", ":", "\n", "    ", "text", "=", "strip_html", "(", "text", ")", "\n", "text", "=", "remove_between_square_brackets", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.get_goodnews_articles": [[67, 122], ["logger.info", "tqdm.tqdm", "db.splits.create_index", "open", "json.load", "open", "json.load", "open", "json.load", "logger.info", "tqdm.tqdm", "logger.info", "tqdm.tqdm", "json.load.items", "links.items", "os.path.join", "os.path.join", "os.path.join", "json.load.items", "db.articles.find_one", "json.load.items", "db.splits.find_one", "os.path.join", "article[].items", "article[].strip", "langdetect.detect", "db.articles.insert_one", "db.splits.insert_one", "os.path.exists", "caption.strip.strip", "get_articles_goodnews.denoise_text", "[].strip", "requests.get", "open", "f.write", "id_.split", "id_.split"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.detect", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.denoise_text"], ["", "def", "get_goodnews_articles", "(", "root_dir", ",", "db", ",", "resume", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'img_splits.json'", ")", ")", "as", "f", ":", "\n", "        ", "img_splits", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'article_caption.json'", ")", ")", "as", "f", ":", "\n", "        ", "article_captions", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'image_urls.json'", ")", ")", "as", "f", ":", "\n", "        ", "img_urls", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "not", "resume", ":", "\n", "        ", "logger", ".", "info", "(", "'Inserting Good News articles.'", ")", "\n", "for", "id_", ",", "article", "in", "tqdm", "(", "article_captions", ".", "items", "(", ")", ")", ":", "\n", "            ", "result", "=", "db", ".", "articles", ".", "find_one", "(", "{", "'_id'", ":", "id_", "}", ")", "\n", "if", "result", "is", "None", ":", "\n", "                ", "article", "[", "'_id'", "]", "=", "id_", "\n", "article", "[", "'web_url'", "]", "=", "article", "[", "'article_url'", "]", "\n", "\n", "for", "idx", ",", "caption", "in", "article", "[", "'images'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "article", "[", "'images'", "]", "[", "idx", "]", "=", "denoise_text", "(", "caption", ")", "\n", "\n", "", "context", "=", "article", "[", "'article'", "]", ".", "strip", "(", ")", "\n", "article", "[", "'language'", "]", "=", "detect", "(", "article", "[", "'article'", "]", ")", "\n", "try", ":", "\n", "                    ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "context", "=", "title", "+", "'\\n\\n'", "+", "context", "\n", "", "except", "KeyError", ":", "\n", "                    ", "pass", "\n", "", "article", "[", "'context'", "]", "=", "context", "\n", "\n", "db", ".", "articles", ".", "insert_one", "(", "article", ")", "\n", "\n", "", "", "", "if", "not", "resume", ":", "\n", "        ", "logger", ".", "info", "(", "'Storing splits.'", ")", "\n", "for", "id_", ",", "split", "in", "tqdm", "(", "img_splits", ".", "items", "(", ")", ")", ":", "\n", "            ", "result", "=", "db", ".", "splits", ".", "find_one", "(", "{", "'_id'", ":", "id_", "}", ")", "\n", "if", "result", "is", "None", ":", "\n", "                ", "db", ".", "splits", ".", "insert_one", "(", "{", "\n", "'_id'", ":", "id_", ",", "\n", "'article_id'", ":", "id_", ".", "split", "(", "'_'", ")", "[", "0", "]", ",", "\n", "'image_index'", ":", "id_", ".", "split", "(", "'_'", ")", "[", "1", "]", ",", "\n", "'split'", ":", "split", ",", "\n", "}", ")", "\n", "\n", "", "", "", "logger", ".", "info", "(", "'Downloading images.'", ")", "\n", "for", "id_", ",", "links", "in", "tqdm", "(", "img_urls", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "ix", ",", "img_url", "in", "links", ".", "items", "(", ")", ":", "\n", "            ", "img_path", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'images'", ",", "f\"{id_}_{ix}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                ", "img_data", "=", "requests", ".", "get", "(", "img_url", ",", "stream", "=", "True", ")", ".", "content", "\n", "with", "open", "(", "img_path", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "f", ".", "write", "(", "img_data", ")", "\n", "\n", "", "", "", "", "db", ".", "splits", ".", "create_index", "(", "[", "\n", "(", "'split'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.validate": [[125, 136], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'root_dir'", ":", "os", ".", "path", ".", "exists", ",", "\n", "'resume'", ":", "bool", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.main": [[138, 156], ["docopt.docopt", "get_articles_goodnews.validate", "os.path.join", "os.makedirs", "pymongo.MongoClient", "get_articles_goodnews.get_goodnews_articles", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_goodnews.get_goodnews_articles"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "root_dir", "=", "args", "[", "'root_dir'", "]", "\n", "img_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'images'", ")", "\n", "os", ".", "makedirs", "(", "img_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get the nytimes database", "\n", "client", "=", "MongoClient", "(", "host", "=", "'localhost'", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "goodnews", "\n", "\n", "get_goodnews_articles", "(", "root_dir", ",", "db", ",", "args", "[", "'resume'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.detect": [[50, 170], ["tell.models.resnet.resnet152", "resnet.to().eval.to().eval", "pymongo.MongoClient", "tell.yolov3.utils.torch_utils.select_device", "os.makedirs", "tell.yolov3.models.Darknet", "tell.yolov3.models.attempt_download", "weights.endswith", "tell.yolov3.models.Darknet.to().eval", "tell.yolov3.utils.datasets.LoadImages", "tell.yolov3.utils.utils.load_classes", "time.time", "tqdm.tqdm", "logger.info", "torch.device", "torch.device", "tell.yolov3.models.Darknet.load_state_dict", "tell.yolov3.models.load_darknet_weights", "torch.from_numpy().to", "img.unsqueeze.float", "PIL.Image.open", "tell.yolov3.utils.utils.non_max_suppression", "str", "os.path.splitext", "db.objects.find_one", "str", "cv2.imwrite", "db.objects.insert_one", "resnet.to().eval.to", "tell.yolov3.models.Darknet.to", "random.randint", "range", "img.unsqueeze.ndimension", "img.unsqueeze.unsqueeze", "tell.yolov3.models.Darknet.", "len", "len", "tell.yolov3.utils.utils.scale_coords().round", "det[].unique", "enumerate", "time.time", "torch.load", "range", "len", "torch.from_numpy", "len", "pathlib.Path", "pathlib.Path", "os.path.join", "annotate_yolo3.get_obj_embeddings", "obj_feats.append", "confidences.append", "classes.append", "tell.yolov3.utils.utils.plot_one_box", "tell.yolov3.utils.utils.scale_coords", "conf.item", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.resnet.resnet152", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.torch_utils.select_device", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.attempt_download", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.load_classes", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.modules.mixins.LoadStateDictWithPrefix.load_state_dict", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.load_darknet_weights", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.non_max_suppression", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.get_obj_embeddings", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.plot_one_box", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.utils.utils.scale_coords"], ["def", "detect", "(", "opt", ")", ":", "\n", "    ", "if", "opt", "[", "'device'", "]", "==", "'cpu'", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "f\"cuda:{opt['device']}\"", ")", "\n", "\n", "", "resnet", "=", "resnet152", "(", ")", "\n", "resnet", "=", "resnet", ".", "to", "(", "device", ")", ".", "eval", "(", ")", "\n", "\n", "client", "=", "MongoClient", "(", "host", "=", "'localhost'", ",", "port", "=", "27017", ")", "\n", "if", "opt", "[", "'dataset'", "]", "==", "'nytimes'", ":", "\n", "        ", "db", "=", "client", ".", "nytimes", "\n", "", "elif", "opt", "[", "'dataset'", "]", "==", "'goodnews'", ":", "\n", "        ", "db", "=", "client", ".", "goodnews", "\n", "\n", "# (320, 192) or (416, 256) or (608, 352) for (height, width)", "\n", "", "img_size", "=", "opt", "[", "'img_size'", "]", "\n", "out_dir", ",", "source", ",", "weights", "=", "opt", "[", "'output'", "]", ",", "opt", "[", "'source'", "]", ",", "opt", "[", "'weights'", "]", "\n", "\n", "# Initialize", "\n", "device", "=", "torch_utils", ".", "select_device", "(", "opt", "[", "'device'", "]", ")", "\n", "os", ".", "makedirs", "(", "out_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Initialize model", "\n", "model", "=", "Darknet", "(", "opt", "[", "'cfg'", "]", ",", "img_size", ")", "\n", "\n", "# Load weights", "\n", "attempt_download", "(", "weights", ")", "\n", "if", "weights", ".", "endswith", "(", "'.pt'", ")", ":", "# pytorch format", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\n", "weights", ",", "map_location", "=", "device", ")", "[", "'model'", "]", ")", "\n", "", "else", ":", "# darknet format", "\n", "        ", "load_darknet_weights", "(", "model", ",", "weights", ")", "\n", "\n", "", "model", ".", "to", "(", "device", ")", ".", "eval", "(", ")", "\n", "\n", "dataset", "=", "LoadImages", "(", "source", ",", "img_size", "=", "img_size", ")", "\n", "\n", "# Get names and colors", "\n", "names", "=", "load_classes", "(", "opt", "[", "'names'", "]", ")", "\n", "colors", "=", "[", "[", "random", ".", "randint", "(", "0", ",", "255", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "for", "_", "in", "range", "(", "len", "(", "names", ")", ")", "]", "\n", "\n", "# Run inference", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "for", "path", ",", "img", ",", "im0s", ",", "_", "in", "tqdm", "(", "dataset", ")", ":", "\n", "        ", "if", "img", "is", "None", ":", "\n", "            ", "continue", "\n", "\n", "", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "to", "(", "device", ")", "\n", "img", "=", "img", ".", "float", "(", ")", "\n", "img", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "if", "img", ".", "ndimension", "(", ")", "==", "3", ":", "\n", "            ", "img", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "pil_image", "=", "Image", ".", "open", "(", "path", ")", "\n", "\n", "# Inference", "\n", "pred", "=", "model", "(", "img", ")", "[", "0", "]", "\n", "\n", "# Apply NMS", "\n", "# We ignore the person class (class 0)", "\n", "pred", "=", "non_max_suppression", "(", "pred", ",", "opt", "[", "'conf_thres'", "]", ",", "opt", "[", "'iou_thres'", "]", ",", "\n", "classes", "=", "None", ",", "agnostic", "=", "opt", "[", "'agnostic_nms'", "]", ")", "\n", "\n", "# Process detections", "\n", "assert", "len", "(", "pred", ")", "==", "1", ",", "f'Length of pred is {len(pred)}'", "\n", "det", "=", "pred", "[", "0", "]", "\n", "p", ",", "s", ",", "im0", "=", "path", ",", "''", ",", "im0s", "\n", "\n", "filename", "=", "str", "(", "Path", "(", "p", ")", ".", "name", ")", "\n", "basename", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "\n", "\n", "if", "db", ".", "objects", ".", "find_one", "(", "{", "'_id'", ":", "basename", "}", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "save_path", "=", "str", "(", "Path", "(", "out_dir", ")", "/", "filename", ")", "\n", "s", "+=", "'%gx%g '", "%", "img", ".", "shape", "[", "2", ":", "]", "# print string", "\n", "\n", "obj_feats", "=", "[", "]", "\n", "confidences", "=", "[", "]", "\n", "classes", "=", "[", "]", "\n", "if", "det", "is", "not", "None", "and", "len", "(", "det", ")", ":", "\n", "# Rescale boxes from img_size to im0 size", "\n", "            ", "det", "[", ":", ",", ":", "4", "]", "=", "scale_coords", "(", "\n", "img", ".", "shape", "[", "2", ":", "]", ",", "det", "[", ":", ",", ":", "4", "]", ",", "im0", ".", "shape", ")", ".", "round", "(", ")", "\n", "\n", "# Print results", "\n", "for", "c", "in", "det", "[", ":", ",", "-", "1", "]", ".", "unique", "(", ")", ":", "\n", "                ", "n", "=", "(", "det", "[", ":", ",", "-", "1", "]", "==", "c", ")", ".", "sum", "(", ")", "# detections per class", "\n", "s", "+=", "'%g %ss, '", "%", "(", "n", ",", "names", "[", "int", "(", "c", ")", "]", ")", "# add to string", "\n", "\n", "# Write results", "\n", "", "for", "j", ",", "(", "*", "xyxy", ",", "conf", ",", "class_", ")", "in", "enumerate", "(", "det", ")", ":", "\n", "                ", "if", "j", ">=", "64", ":", "\n", "                    ", "break", "\n", "", "obj_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "f'{basename}_{j:02}.{ext}'", ")", "\n", "\n", "obj_feat", "=", "get_obj_embeddings", "(", "\n", "xyxy", ",", "pil_image", ",", "obj_path", ",", "resnet", ")", "\n", "obj_feats", ".", "append", "(", "obj_feat", ")", "\n", "confidences", ".", "append", "(", "conf", ".", "item", "(", ")", ")", "\n", "classes", ".", "append", "(", "int", "(", "class_", ")", ")", "\n", "\n", "label", "=", "'%s %.2f'", "%", "(", "names", "[", "int", "(", "class_", ")", "]", ",", "conf", ")", "\n", "plot_one_box", "(", "xyxy", ",", "im0", ",", "label", "=", "label", ",", "\n", "color", "=", "colors", "[", "int", "(", "class_", ")", "]", ")", "\n", "\n", "# Save results (image with detections)", "\n", "", "", "cv2", ".", "imwrite", "(", "save_path", ",", "im0", ")", "\n", "\n", "db", ".", "objects", ".", "insert_one", "(", "{", "\n", "'_id'", ":", "basename", ",", "\n", "'object_features'", ":", "obj_feats", ",", "\n", "'confidences'", ":", "confidences", ",", "\n", "'classes'", ":", "classes", ",", "\n", "}", ")", "\n", "\n", "", "elapsed", "=", "(", "time", ".", "time", "(", ")", "-", "t0", ")", "/", "3600", "\n", "logger", ".", "info", "(", "f'Done. Results saved to {out_dir}. Object detection takes '", "\n", "f'{elapsed:.1f} hours.'", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.get_obj_embeddings": [[173, 195], ["pil_image.convert.convert", "annotate_yolo3.extract_object", "torchvision.transforms.Compose", "torchvision.transforms.Compose.", "obj_image.unsqueeze().to.unsqueeze().to", "resnet", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu().numpy().tolist", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "obj_image.unsqueeze().to.unsqueeze", "next", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu().numpy", "resnet.parameters", "X_image.squeeze().cpu().numpy().tolist.squeeze().cpu", "X_image.squeeze().cpu().numpy().tolist.squeeze"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.extract_object"], ["", "def", "get_obj_embeddings", "(", "xyxy", ",", "pil_image", ",", "obj_path", ",", "resnet", ")", ":", "\n", "    ", "pil_image", "=", "pil_image", ".", "convert", "(", "'RGB'", ")", "\n", "obj_image", "=", "extract_object", "(", "pil_image", ",", "xyxy", ",", "save_path", "=", "obj_path", ")", "\n", "\n", "preprocess", "=", "Compose", "(", "[", "\n", "ToTensor", "(", ")", ",", "\n", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "obj_image", "=", "preprocess", "(", "obj_image", ")", "\n", "# obj_image.shape == [n_channels, height, width]", "\n", "\n", "# Add a batch dimension", "\n", "obj_image", "=", "obj_image", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "next", "(", "resnet", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "# obj_image.shape == [1, n_channels, height, width]", "\n", "\n", "X_image", "=", "resnet", "(", "obj_image", ",", "pool", "=", "True", ")", "\n", "# X_image.shape == [1, 2048]", "\n", "\n", "X_image", "=", "X_image", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "# X_image.shape == [2048]", "\n", "\n", "return", "X_image", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.extract_object": [[197, 232], ["img.crop().resize", "int", "int", "int", "int", "os.makedirs", "img.crop().resize.save", "max", "max", "min", "min", "img.crop", "os.path.dirname"], "function", ["None"], ["", "def", "extract_object", "(", "img", ",", "box", ",", "image_size", "=", "224", ",", "margin", "=", "0", ",", "save_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract object + margin from PIL Image given bounding box.\n\n    Arguments:\n        img {PIL.Image} -- A PIL Image.\n        box {numpy.ndarray} -- Four-element bounding box.\n        image_size {int} -- Output image size in pixels. The image will be square.\n        margin {int} -- Margin to add to bounding box, in terms of pixels in the final image.\n            Note that the application of the margin differs slightly from the davidsandberg/facenet\n            repo, which applies the margin to the original image before resizing, making the margin\n            dependent on the original image size.\n        save_path {str} -- Save path for extracted object image. (default: {None})\n\n    Returns:\n        torch.tensor -- tensor representing the extracted object.\n    \"\"\"", "\n", "margin", "=", "[", "\n", "margin", "*", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "/", "(", "image_size", "-", "margin", ")", ",", "\n", "margin", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "/", "(", "image_size", "-", "margin", ")", "\n", "]", "\n", "box", "=", "[", "\n", "int", "(", "max", "(", "box", "[", "0", "]", "-", "margin", "[", "0", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "max", "(", "box", "[", "1", "]", "-", "margin", "[", "1", "]", "/", "2", ",", "0", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "2", "]", "+", "margin", "[", "0", "]", "/", "2", ",", "img", ".", "size", "[", "0", "]", ")", ")", ",", "\n", "int", "(", "min", "(", "box", "[", "3", "]", "+", "margin", "[", "1", "]", "/", "2", ",", "img", ".", "size", "[", "1", "]", ")", ")", "\n", "]", "\n", "\n", "obj", "=", "img", ".", "crop", "(", "box", ")", ".", "resize", "(", "(", "image_size", ",", "image_size", ")", ",", "2", ")", "\n", "\n", "if", "save_path", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "+", "'/'", ",", "exist_ok", "=", "True", ")", "\n", "save_args", "=", "{", "'compress_level'", ":", "0", "}", "if", "'.png'", "in", "save_path", "else", "{", "}", "\n", "obj", ".", "save", "(", "save_path", ",", "**", "save_args", ")", "\n", "\n", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.validate": [[234, 247], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Use", "schema.Use", "schema.Use", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'iou_thres'", ":", "Use", "(", "float", ")", ",", "\n", "'conf_thres'", ":", "Use", "(", "float", ")", ",", "\n", "'img_size'", ":", "Use", "(", "int", ")", ",", "\n", "object", ":", "object", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.main": [[249, 261], ["docopt.docopt", "annotate_yolo3.validate", "os.makedirs", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.no_grad", "annotate_yolo3.detect"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.detect"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "os", ".", "makedirs", "(", "'data'", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "detect", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.validate": [[26, 36], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'host'", ":", "str", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.compute_nytimes": [[38, 68], ["datetime.datetime", "datetime.datetime", "collections.Counter", "collections.Counter", "nytimes.articles.find().batch_size", "tqdm.tqdm", "compute_name_statistics.get_proper_names", "open", "pickle.dump", "nytimes.articles.find", "compute_name_statistics.get_proper_names", "compute_name_statistics.get_proper_names", "ValueError"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names"], ["", "def", "compute_nytimes", "(", "client", ")", ":", "\n", "    ", "nytimes", "=", "client", ".", "nytimes", "\n", "start", "=", "datetime", "(", "2000", ",", "1", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2019", ",", "5", ",", "1", ")", "\n", "\n", "caption_counter", "=", "Counter", "(", ")", "\n", "context_counter", "=", "Counter", "(", ")", "\n", "\n", "article_cursor", "=", "nytimes", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "'train'", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "get_proper_names", "(", "article", "[", "'headline'", "]", ",", "context_counter", ")", "\n", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "for", "section", "in", "sections", ":", "\n", "            ", "if", "section", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                ", "get_proper_names", "(", "section", ",", "caption_counter", ")", "\n", "", "elif", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                ", "get_proper_names", "(", "section", ",", "context_counter", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Unknown type: {section['type']}\"", ")", "\n", "\n", "", "", "", "counters", "=", "{", "\n", "'caption'", ":", "caption_counter", ",", "\n", "'context'", ":", "context_counter", ",", "\n", "}", "\n", "with", "open", "(", "'./data/nytimes/name_counters.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "counters", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.compute_goodnews": [[70, 102], ["collections.Counter", "collections.Counter", "goodnews.splits.find().batch_size", "set", "tqdm.tqdm", "set.add", "goodnews.articles.find_one", "compute_name_statistics.get_proper_goodnews_names", "article[].keys", "open", "pickle.dump", "goodnews.splits.find", "compute_name_statistics.get_caption_proper_names"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.get_proper_goodnews_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.get_caption_proper_names"], ["", "", "def", "compute_goodnews", "(", "client", ")", ":", "\n", "    ", "goodnews", "=", "client", ".", "goodnews", "\n", "\n", "caption_counter", "=", "Counter", "(", ")", "\n", "context_counter", "=", "Counter", "(", ")", "\n", "\n", "sample_cursor", "=", "goodnews", ".", "splits", ".", "find", "(", "\n", "{", "'split'", ":", "'train'", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "done_article_ids", "=", "set", "(", ")", "\n", "for", "sample", "in", "tqdm", "(", "sample_cursor", ")", ":", "\n", "        ", "if", "sample", "[", "'article_id'", "]", "in", "done_article_ids", ":", "\n", "            ", "continue", "\n", "", "done_article_ids", ".", "add", "(", "sample", "[", "'article_id'", "]", ")", "\n", "\n", "article", "=", "goodnews", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ")", "\n", "\n", "get_proper_goodnews_names", "(", "\n", "article", ",", "context_counter", ",", "'context_parts_of_speech'", ")", "\n", "\n", "for", "idx", "in", "article", "[", "'images'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "get_caption_proper_names", "(", "article", ",", "idx", ",", "caption_counter", ")", "\n", "\n", "", "", "counters", "=", "{", "\n", "'caption'", ":", "caption_counter", ",", "\n", "'context'", ":", "context_counter", ",", "\n", "}", "\n", "\n", "with", "open", "(", "'./data/goodnews/name_counters.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "counters", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.main": [[104, 117], ["docopt.docopt", "compute_name_statistics.validate", "pymongo.MongoClient", "compute_name_statistics.compute_nytimes", "compute_name_statistics.compute_goodnews", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.compute_nytimes", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.compute_goodnews"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "client", "=", "MongoClient", "(", "host", "=", "args", "[", "'host'", "]", ",", "port", "=", "27017", ")", "\n", "\n", "compute_nytimes", "(", "client", ")", "\n", "compute_goodnews", "(", "client", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.get_proper_names": [[119, 126], ["counter.update"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "def", "get_proper_names", "(", "section", ",", "counter", ")", ":", "\n", "    ", "if", "'parts_of_speech'", "in", "section", ":", "\n", "        ", "parts_of_speech", "=", "section", "[", "'parts_of_speech'", "]", "\n", "proper_names", "=", "[", "pos", "[", "'text'", "]", "for", "pos", "in", "parts_of_speech", "\n", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "]", "\n", "\n", "counter", ".", "update", "(", "proper_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.get_proper_goodnews_names": [[128, 135], ["counter.update"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "", "def", "get_proper_goodnews_names", "(", "section", ",", "counter", ",", "pos_field", ")", ":", "\n", "    ", "if", "pos_field", "in", "section", ":", "\n", "        ", "parts_of_speech", "=", "section", "[", "pos_field", "]", "\n", "proper_names", "=", "[", "pos", "[", "'text'", "]", "for", "pos", "in", "parts_of_speech", "\n", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "]", "\n", "\n", "counter", ".", "update", "(", "proper_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_name_statistics.get_caption_proper_names": [[137, 144], ["counter.update"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.base.ServerStatistic.update"], ["", "", "def", "get_caption_proper_names", "(", "article", ",", "idx", ",", "counter", ")", ":", "\n", "    ", "if", "'caption_parts_of_speech'", "in", "article", ":", "\n", "        ", "parts_of_speech", "=", "article", "[", "'caption_parts_of_speech'", "]", "[", "idx", "]", "\n", "proper_names", "=", "[", "pos", "[", "'text'", "]", "for", "pos", "in", "parts_of_speech", "\n", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", "]", "\n", "\n", "counter", ".", "update", "(", "proper_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_nytimes.validate": [[32, 45], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Use", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'image_dir'", ":", "str", ",", "\n", "'face_dir'", ":", "str", ",", "\n", "'batch'", ":", "Use", "(", "int", ")", ",", "\n", "'host'", ":", "str", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_nytimes.detect_faces": [[47, 98], ["len", "os.path.join", "os.path.join", "article[].append", "nytimes.articles.find_one_and_update", "os.path.exists", "logger.warning", "PIL.Image.open", "img.convert.convert", "torch.no_grad", "resnet", "len", "logger.warning", "logger.warning", "mtcnn", "embeddings.cpu().tolist", "probs.tolist", "logger.warning", "embeddings.cpu"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning"], ["", "def", "detect_faces", "(", "article", ",", "nytimes", ",", "image_dir", ",", "face_dir", ",", "mtcnn", ",", "resnet", ")", ":", "\n", "    ", "if", "'detected_face_positions'", "in", "article", ":", "\n", "        ", "return", "\n", "\n", "", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "image_positions", "=", "article", "[", "'image_positions'", "]", "\n", "article", "[", "'detected_face_positions'", "]", "=", "[", "]", "\n", "\n", "for", "pos", "in", "image_positions", ":", "\n", "        ", "section", "=", "sections", "[", "pos", "]", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "f\"{section['hash']}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Image not found: {image_path} from article \"", "\n", "f\"{article['_id']} at position {pos}\"", ")", "\n", "continue", "\n", "\n", "", "try", ":", "\n", "            ", "img", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "img", "=", "img", ".", "convert", "(", "'RGB'", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"OSError on image: {image_path} from article \"", "\n", "f\"{article['_id']} at position {pos}\"", ")", "\n", "continue", "\n", "", "face_path", "=", "os", ".", "path", ".", "join", "(", "face_dir", ",", "f\"{section['hash']}_{pos:02}.jpg\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "faces", ",", "probs", "=", "mtcnn", "(", "img", ",", "save_path", "=", "face_path", ",", "\n", "return_prob", "=", "True", ")", "\n", "", "except", "IndexError", ":", "# Strange index error on line 135 in utils/detect_face.py", "\n", "                ", "logger", ".", "warning", "(", "f\"IndexError on image: {image_path} from article \"", "\n", "f\"{article['_id']} at position {pos}\"", ")", "\n", "faces", "=", "None", "\n", "", "if", "faces", "is", "None", ":", "\n", "                ", "continue", "\n", "", "embeddings", ",", "_", "=", "resnet", "(", "faces", ")", "\n", "\n", "", "section", "[", "'facenet_details'", "]", "=", "{", "\n", "'n_faces'", ":", "len", "(", "faces", "[", ":", "10", "]", ")", ",", "\n", "'embeddings'", ":", "embeddings", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "[", ":", "10", "]", ",", "\n", "'detect_probs'", ":", "probs", ".", "tolist", "(", ")", "[", ":", "10", "]", ",", "\n", "}", "\n", "\n", "article", "[", "'detected_face_positions'", "]", ".", "append", "(", "pos", ")", "\n", "\n", "", "article", "[", "'n_images_with_faces'", "]", "=", "len", "(", "article", "[", "'detected_face_positions'", "]", ")", "\n", "\n", "try", ":", "\n", "        ", "nytimes", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "", "except", "DocumentTooLarge", ":", "\n", "        ", "logger", ".", "warning", "(", "f\"Document too large: {article['_id']}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_nytimes.main": [[100, 136], ["docopt.docopt", "detect_facenet_nytimes.validate", "os.makedirs", "pymongo.MongoClient", "nytimes.articles.find().batch_size", "logger.info", "tell.facenet.MTCNN", "tell.facenet.InceptionResnetV1().eval", "logger.info", "tqdm.tqdm", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "datetime.datetime", "datetime.datetime", "detect_facenet_nytimes.detect_faces", "datetime.datetime", "datetime.datetime", "ValueError", "nytimes.articles.find", "tell.facenet.InceptionResnetV1"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_goodnews.detect_faces"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "image_dir", "=", "args", "[", "'image_dir'", "]", "\n", "face_dir", "=", "args", "[", "'face_dir'", "]", "\n", "\n", "os", ".", "makedirs", "(", "face_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "client", "=", "MongoClient", "(", "host", "=", "args", "[", "'host'", "]", ",", "port", "=", "27017", ")", "\n", "nytimes", "=", "client", ".", "nytimes", "\n", "\n", "if", "args", "[", "'batch'", "]", "==", "1", ":", "\n", "        ", "start", "=", "datetime", "(", "2000", ",", "1", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2013", ",", "2", ",", "1", ")", "\n", "", "elif", "args", "[", "'batch'", "]", "==", "2", ":", "\n", "        ", "start", "=", "datetime", "(", "2013", ",", "2", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2019", ",", "9", ",", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unknown batch: {args['batch']}\"", ")", "\n", "\n", "", "article_cursor", "=", "nytimes", ".", "articles", ".", "find", "(", "{", "\n", "'pub_date'", ":", "{", "'$gte'", ":", "start", ",", "'$lt'", ":", "end", "}", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "logger", ".", "info", "(", "'Loading model.'", ")", "\n", "mtcnn", "=", "MTCNN", "(", "keep_all", "=", "True", ",", "device", "=", "'cuda'", ")", "\n", "resnet", "=", "InceptionResnetV1", "(", "pretrained", "=", "'vggface2'", ")", ".", "eval", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'Detecting faces.'", ")", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "detect_faces", "(", "article", ",", "nytimes", ",", "image_dir", ",", "face_dir", ",", "mtcnn", ",", "resnet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.generate_tables.display": [[32, 48], ["print", "len", "float", "len", "float", "float", "float"], "function", ["None"], ["def", "display", "(", "number", ",", "m", "=", "100", ",", "sf", "=", "3", ",", "end", "=", "' & '", ")", ":", "\n", "    ", "rounded_str", "=", "'{:.3g}'", ".", "format", "(", "number", "*", "m", ")", "\n", "if", "rounded_str", "==", "'0'", ":", "\n", "        ", "out", "=", "'0'", "\n", "", "elif", "'.'", "not", "in", "rounded_str", "and", "len", "(", "rounded_str", ")", "==", "1", ":", "\n", "        ", "out", "=", "'{:2}'", ".", "format", "(", "float", "(", "rounded_str", ")", ")", "\n", "", "elif", "'.'", "not", "in", "rounded_str", "and", "len", "(", "rounded_str", ")", "==", "2", ":", "\n", "        ", "out", "=", "'{:1}'", ".", "format", "(", "float", "(", "rounded_str", ")", ")", "\n", "", "elif", "rounded_str", "[", "1", "]", "==", "'.'", ":", "\n", "        ", "out", "=", "'{:.2f}'", ".", "format", "(", "float", "(", "rounded_str", ")", ")", "\n", "", "elif", "rounded_str", "[", "2", "]", "==", "'.'", ":", "\n", "        ", "out", "=", "'{:.1f}'", ".", "format", "(", "float", "(", "rounded_str", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "\n", "\n", "", "print", "(", "out", ",", "end", "=", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.dump_database.dump_text": [[26, 68], ["pymongo.MongoClient", "db.articles.find().sort", "set", "set", "tqdm.tqdm", "articles.append", "set.add", "set.add", "open", "db.articles.find", "s[].strip", "str", "f.write", "json.dumps"], "function", ["None"], ["def", "dump_text", "(", "dump_path", ")", ":", "\n", "    ", "client", "=", "MongoClient", "(", "host", "=", "'localhost'", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "nytimes", "\n", "\n", "articles", "=", "[", "]", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'headline.main'", ",", "'web_url'", ",", "'pub_date'", ",", "'type_of_material'", ",", "\n", "'news_desk'", ",", "'abstract'", "]", "\n", "\n", "cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "}", ",", "projection", "=", "projection", ")", ".", "sort", "(", "\n", "'pub_date'", ",", "pymongo", ".", "DESCENDING", ")", "\n", "\n", "news_desks", "=", "set", "(", ")", "\n", "type_of_materials", "=", "set", "(", ")", "\n", "\n", "for", "a", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "sections", "=", "a", "[", "'parsed_section'", "]", "\n", "paragraphs", "=", "[", "s", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "for", "s", "in", "sections", "if", "s", "[", "'type'", "]", "==", "'paragraph'", "]", "\n", "\n", "article", "=", "{", "\n", "'id'", ":", "a", "[", "'_id'", "]", ",", "\n", "'url'", ":", "a", "[", "'web_url'", "]", ",", "\n", "'pub_date'", ":", "str", "(", "a", "[", "'pub_date'", "]", ")", ",", "\n", "'content'", ":", "'\\n'", ".", "join", "(", "paragraphs", ")", ".", "strip", "(", ")", ",", "\n", "'type_of_material'", ":", "a", "[", "'type_of_material'", "]", ",", "\n", "'news_desk'", ":", "a", "[", "'news_desk'", "]", ",", "\n", "}", "\n", "\n", "if", "'main'", "in", "a", "[", "'headline'", "]", ":", "\n", "            ", "article", "[", "'headline'", "]", "=", "a", "[", "'headline'", "]", "[", "'main'", "]", "\n", "", "if", "'abstract'", "in", "a", ":", "\n", "            ", "article", "[", "'abstract'", "]", "=", "a", "[", "'abstract'", "]", "\n", "\n", "", "articles", ".", "append", "(", "article", ")", "\n", "news_desks", ".", "add", "(", "a", "[", "'news_desk'", "]", ")", "\n", "type_of_materials", ".", "add", "(", "a", "[", "'type_of_material'", "]", ")", "\n", "\n", "", "with", "open", "(", "dump_path", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "for", "a", "in", "articles", ":", "\n", "            ", "f", ".", "write", "(", "f'{json.dumps(a)}\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.dump_database.validate": [[79, 89], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "", "", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "object", ":", "object", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.dump_database.main": [[91, 101], ["docopt", "dump_database.validate", "dump_database.dump_text", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.dump_database.dump_text"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "dump_text", "(", "args", "[", "'dump_path'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.validate": [[24, 34], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'host'", ":", "str", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.main": [[36, 83], ["docopt.docopt", "annotate_goodnews.validate", "logger.info", "spacy.load", "pymongo.MongoClient", "db.splits.find().batch_size", "set", "tqdm.tqdm", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "set.add", "db.articles.find_one", "db.splits.find", "article[].items", "article[].strip", "spacy.load.", "annotate_goodnews.get_context_ner", "annotate_goodnews.get_context_parts_of_speech", "db.articles.find_one_and_update", "caption.strip.strip", "spacy.load.", "annotate_goodnews.get_caption_ner", "annotate_goodnews.get_caption_parts_of_speech"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_context_ner", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_context_parts_of_speech", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_caption_ner", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_caption_parts_of_speech"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "'Loading spacy.'", ")", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_lg\"", ")", "\n", "client", "=", "MongoClient", "(", "host", "=", "args", "[", "'host'", "]", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "goodnews", "\n", "\n", "sample_cursor", "=", "db", ".", "splits", ".", "find", "(", "{", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "done_article_ids", "=", "set", "(", ")", "\n", "for", "sample", "in", "tqdm", "(", "sample_cursor", ")", ":", "\n", "        ", "if", "sample", "[", "'article_id'", "]", "in", "done_article_ids", ":", "\n", "            ", "continue", "\n", "", "done_article_ids", ".", "add", "(", "sample", "[", "'article_id'", "]", ")", "\n", "\n", "article", "=", "db", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ")", "\n", "\n", "changed", "=", "False", "\n", "if", "'caption_ner'", "not", "in", "article", "or", "'caption_parts_of_speech'", "not", "in", "article", ":", "\n", "            ", "changed", "=", "True", "\n", "article", "[", "'caption_parts_of_speech'", "]", "=", "{", "}", "\n", "article", "[", "'caption_ner'", "]", "=", "{", "}", "\n", "for", "idx", ",", "caption", "in", "article", "[", "'images'", "]", ".", "items", "(", ")", ":", "\n", "                ", "caption", "=", "caption", ".", "strip", "(", ")", "\n", "caption_doc", "=", "nlp", "(", "caption", ")", "\n", "get_caption_ner", "(", "caption_doc", ",", "article", ",", "idx", ")", "\n", "get_caption_parts_of_speech", "(", "caption_doc", ",", "article", ",", "idx", ")", "\n", "\n", "", "", "if", "'context_ner'", "not", "in", "article", "or", "'context_parts_of_speech'", "not", "in", "article", ":", "\n", "            ", "changed", "=", "True", "\n", "context", "=", "article", "[", "'context'", "]", ".", "strip", "(", ")", "\n", "context_doc", "=", "nlp", "(", "context", ")", "\n", "get_context_ner", "(", "context_doc", ",", "article", ")", "\n", "get_context_parts_of_speech", "(", "context_doc", ",", "article", ")", "\n", "\n", "", "if", "changed", ":", "\n", "            ", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_caption_ner": [[85, 97], ["ner.append"], "function", ["None"], ["", "", "", "def", "get_caption_ner", "(", "doc", ",", "article", ",", "idx", ")", ":", "\n", "    ", "ner", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "        ", "ent_info", "=", "{", "\n", "'start'", ":", "ent", ".", "start_char", ",", "\n", "'end'", ":", "ent", ".", "end_char", ",", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "}", "\n", "ner", ".", "append", "(", "ent_info", ")", "\n", "\n", "", "article", "[", "'caption_ner'", "]", "[", "idx", "]", "=", "ner", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_context_ner": [[99, 111], ["ner.append"], "function", ["None"], ["", "def", "get_context_ner", "(", "doc", ",", "article", ")", ":", "\n", "    ", "ner", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "        ", "ent_info", "=", "{", "\n", "'start'", ":", "ent", ".", "start_char", ",", "\n", "'end'", ":", "ent", ".", "end_char", ",", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "}", "\n", "ner", ".", "append", "(", "ent_info", ")", "\n", "\n", "", "article", "[", "'context_ner'", "]", "=", "ner", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_context_parts_of_speech": [[113, 125], ["parts_of_speech.append", "len"], "function", ["None"], ["", "def", "get_context_parts_of_speech", "(", "doc", ",", "article", ")", ":", "\n", "    ", "parts_of_speech", "=", "[", "]", "\n", "for", "tok", "in", "doc", ":", "\n", "        ", "pos", "=", "{", "\n", "'start'", ":", "tok", ".", "idx", ",", "\n", "'end'", ":", "tok", ".", "idx", "+", "len", "(", "tok", ".", "text", ")", ",", "# exclude right endpoint", "\n", "'text'", ":", "tok", ".", "text", ",", "\n", "'pos'", ":", "tok", ".", "pos_", ",", "\n", "}", "\n", "parts_of_speech", ".", "append", "(", "pos", ")", "\n", "\n", "", "article", "[", "'context_parts_of_speech'", "]", "=", "parts_of_speech", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_goodnews.get_caption_parts_of_speech": [[127, 139], ["parts_of_speech.append", "len"], "function", ["None"], ["", "def", "get_caption_parts_of_speech", "(", "doc", ",", "article", ",", "idx", ")", ":", "\n", "    ", "parts_of_speech", "=", "[", "]", "\n", "for", "tok", "in", "doc", ":", "\n", "        ", "pos", "=", "{", "\n", "'start'", ":", "tok", ".", "idx", ",", "\n", "'end'", ":", "tok", ".", "idx", "+", "len", "(", "tok", ".", "text", ")", ",", "# exclude right endpoint", "\n", "'text'", ":", "tok", ".", "text", ",", "\n", "'pos'", ":", "tok", ".", "pos_", ",", "\n", "}", "\n", "parts_of_speech", ".", "append", "(", "pos", ")", "\n", "\n", "", "article", "[", "'caption_parts_of_speech'", "]", "[", "idx", "]", "=", "parts_of_speech", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_goodnews.validate": [[30, 42], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'image_dir'", ":", "str", ",", "\n", "'face_dir'", ":", "str", ",", "\n", "'host'", ":", "str", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_goodnews.detect_faces": [[44, 80], ["os.path.join", "os.path.join", "PIL.Image.open", "image.convert.convert", "torch.no_grad", "resnet", "len", "goodnews.splits.find_one_and_update", "mtcnn", "embeddings.cpu().tolist", "probs.tolist", "logger.warning", "logger.warning", "embeddings.cpu"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.warning"], ["", "def", "detect_faces", "(", "sample", ",", "goodnews", ",", "image_dir", ",", "face_dir", ",", "mtcnn", ",", "resnet", ")", ":", "\n", "    ", "if", "'facenet_details'", "in", "sample", ":", "\n", "        ", "return", "\n", "\n", "", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "try", ":", "\n", "        ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "image", "=", "image", ".", "convert", "(", "'RGB'", ")", "\n", "", "except", "(", "FileNotFoundError", ",", "OSError", ")", ":", "\n", "        ", "return", "\n", "\n", "", "face_path", "=", "os", ".", "path", ".", "join", "(", "face_dir", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "faces", ",", "probs", "=", "mtcnn", "(", "image", ",", "save_path", "=", "face_path", ",", "\n", "return_prob", "=", "True", ")", "\n", "", "except", "IndexError", ":", "# Strange index error on line 135 in utils/detect_face.py", "\n", "            ", "logger", ".", "warning", "(", "f\"IndexError on image: {image_path} from sample \"", "\n", "f\"{sample['_id']}\"", ")", "\n", "faces", "=", "None", "\n", "", "if", "faces", "is", "None", ":", "\n", "            ", "return", "\n", "", "embeddings", ",", "face_probs", "=", "resnet", "(", "faces", ")", "\n", "\n", "# We keep only top 10 faces", "\n", "", "sample", "[", "'facenet_details'", "]", "=", "{", "\n", "'n_faces'", ":", "len", "(", "faces", "[", ":", "10", "]", ")", ",", "\n", "'embeddings'", ":", "embeddings", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "[", ":", "10", "]", ",", "\n", "'detect_probs'", ":", "probs", ".", "tolist", "(", ")", "[", ":", "10", "]", ",", "\n", "}", "\n", "\n", "try", ":", "\n", "        ", "goodnews", ".", "splits", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "sample", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "sample", "}", ")", "\n", "", "except", "DocumentTooLarge", ":", "\n", "        ", "logger", ".", "warning", "(", "f\"Document too large: {sample['_id']}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_goodnews.main": [[82, 108], ["docopt.docopt", "detect_facenet_goodnews.validate", "os.makedirs", "pymongo.MongoClient", "goodnews.splits.find().batch_size", "logger.info", "tell.facenet.MTCNN", "tell.facenet.InceptionResnetV1().eval", "logger.info", "tqdm.tqdm", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "detect_facenet_goodnews.detect_faces", "goodnews.splits.find", "tell.facenet.InceptionResnetV1"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.detect_facenet_goodnews.detect_faces"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "image_dir", "=", "args", "[", "'image_dir'", "]", "\n", "face_dir", "=", "args", "[", "'face_dir'", "]", "\n", "\n", "os", ".", "makedirs", "(", "face_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "client", "=", "MongoClient", "(", "host", "=", "args", "[", "'host'", "]", ",", "port", "=", "27017", ")", "\n", "goodnews", "=", "client", ".", "goodnews", "\n", "\n", "sample_cursor", "=", "goodnews", ".", "splits", ".", "find", "(", "\n", "{", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "logger", ".", "info", "(", "'Loading model.'", ")", "\n", "mtcnn", "=", "MTCNN", "(", "keep_all", "=", "True", ",", "device", "=", "'cuda'", ")", "\n", "resnet", "=", "InceptionResnetV1", "(", "pretrained", "=", "'vggface2'", ")", ".", "eval", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'Detecting faces.'", ")", "\n", "for", "sample", "in", "tqdm", "(", "sample_cursor", ")", ":", "\n", "        ", "detect_faces", "(", "sample", ",", "goodnews", ",", "image_dir", ",", "face_dir", ",", "mtcnn", ",", "resnet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_nytimes_stats": [[26, 133], ["nytimes.articles.find", "collections.defaultdict", "collections.defaultdict", "datetime.datetime", "datetime.datetime", "logger.info", "tqdm.tqdm", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "len", "len", "os.path.join", "captions.append", "os.path.exists", "s[].strip", "len", "len", "len", "len", "len", "len", "len", "e[].split", "len", "e[].split"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["def", "compute_nytimes_stats", "(", "nytimes", ")", ":", "\n", "    ", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'pub_date'", ",", "'split'", ",", "\n", "'parsed_section.parts_of_speech'", ",", "\n", "'parsed_section.named_entities'", ",", "\n", "'parsed_section.hash'", ",", "'parsed_section.text'", "]", "\n", "cursor", "=", "nytimes", ".", "articles", ".", "find", "(", "\n", "{", "'split'", ":", "{", "'$in'", ":", "[", "'train'", ",", "'valid'", ",", "'test'", "]", "}", "}", ",", "\n", "projection", "=", "projection", ")", "\n", "\n", "n_article_words", "=", "0", "\n", "n_caption_words", "=", "0", "\n", "n_captions", "=", "0", "\n", "n_articles", "=", "0", "\n", "article_splits", "=", "defaultdict", "(", "int", ")", "\n", "caption_splits", "=", "defaultdict", "(", "int", ")", "\n", "\n", "n_words", "=", "0", "\n", "n_nouns", "=", "0", "\n", "n_adjs", "=", "0", "\n", "n_verbs", "=", "0", "\n", "n_pnouns", "=", "0", "\n", "n_propers", "=", "0", "\n", "n_entity_words", "=", "0", "\n", "n_ent_sents", "=", "0", "\n", "n_person_names", "=", "0", "\n", "n_pers_sents", "=", "0", "\n", "\n", "max_date", "=", "datetime", "(", "2000", ",", "1", ",", "1", ")", "\n", "min_date", "=", "datetime", "(", "2020", ",", "1", ",", "1", ")", "\n", "\n", "logger", ".", "info", "(", "'Computing NYTimes statistics.'", ")", "\n", "for", "article", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "pars", "=", "[", "s", "[", "'text'", "]", "for", "s", "in", "sections", "if", "s", "[", "'type'", "]", "==", "'paragraph'", "]", "\n", "captions", "=", "[", "]", "\n", "\n", "has_image", "=", "False", "\n", "for", "s", "in", "sections", ":", "\n", "            ", "if", "s", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                ", "image_path", "=", "os", ".", "path", ".", "join", "(", "'data/nytimes/images_processed'", ",", "\n", "f\"{s['hash']}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "not", "s", "[", "'text'", "]", ".", "strip", "(", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "has_image", "=", "True", "\n", "captions", ".", "append", "(", "s", "[", "'text'", "]", ")", "\n", "\n", "if", "'parts_of_speech'", "in", "s", ":", "\n", "                    ", "pos", "=", "s", "[", "'parts_of_speech'", "]", "\n", "n_words", "+=", "len", "(", "pos", ")", "\n", "n_nouns", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'NOUN'", "]", ")", "\n", "n_verbs", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'VERB'", "]", ")", "\n", "n_adjs", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'ADJ'", "]", ")", "\n", "n_pnouns", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'PRON'", "]", ")", "\n", "n_propers", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'PROPN'", "]", ")", "\n", "\n", "", "has_person", "=", "False", "\n", "if", "'named_entities'", "in", "s", ":", "\n", "                    ", "for", "e", "in", "s", "[", "'named_entities'", "]", ":", "\n", "                        ", "n_entity_words", "+=", "len", "(", "e", "[", "'text'", "]", ".", "split", "(", ")", ")", "\n", "if", "e", "[", "'label'", "]", "==", "'PERSON'", ":", "\n", "                            ", "n_person_names", "+=", "len", "(", "e", "[", "'text'", "]", ".", "split", "(", ")", ")", "\n", "has_person", "=", "True", "\n", "", "", "if", "s", "[", "'named_entities'", "]", ":", "\n", "                        ", "n_ent_sents", "+=", "1", "\n", "", "if", "has_person", ":", "\n", "                        ", "n_pers_sents", "+=", "1", "\n", "\n", "", "", "", "", "if", "not", "captions", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "has_image", ":", "\n", "            ", "n_article_words", "+=", "len", "(", "' '", ".", "join", "(", "pars", ")", ".", "split", "(", ")", ")", "\n", "n_articles", "+=", "1", "\n", "n_caption_words", "+=", "len", "(", "' '", ".", "join", "(", "captions", ")", ".", "split", "(", ")", ")", "\n", "n_captions", "+=", "len", "(", "captions", ")", "\n", "caption_splits", "[", "article", "[", "'split'", "]", "]", "+=", "len", "(", "captions", ")", "\n", "article_splits", "[", "article", "[", "'split'", "]", "]", "+=", "1", "\n", "\n", "if", "article", "[", "'pub_date'", "]", "<", "min_date", ":", "\n", "                ", "min_date", "=", "article", "[", "'pub_date'", "]", "\n", "", "if", "article", "[", "'pub_date'", "]", ">", "max_date", ":", "\n", "                ", "max_date", "=", "article", "[", "'pub_date'", "]", "\n", "\n", "", "", "", "print", "(", "'Full NYTimes Dataset:'", ")", "\n", "print", "(", "'No of articles:'", ",", "n_articles", ")", "\n", "print", "(", "'No of captions:'", ",", "n_captions", ")", "\n", "print", "(", "'Average article len:'", ",", "n_article_words", "/", "n_articles", ")", "\n", "print", "(", "'Average caption len:'", ",", "n_caption_words", "/", "n_captions", ")", "\n", "print", "(", "'Min date:'", ",", "min_date", ")", "\n", "print", "(", "'Max date:'", ",", "max_date", ")", "\n", "print", "(", "f'Words: {n_words}'", ")", "\n", "print", "(", "f'Nouns: {n_nouns} ({n_nouns / n_words:.2%})'", ")", "\n", "print", "(", "f'Verbs: {n_verbs} ({n_verbs / n_words:.2%})'", ")", "\n", "print", "(", "f'Adjectives: {n_adjs} ({n_adjs / n_words:.2%})'", ")", "\n", "print", "(", "f'Pronouns: {n_pnouns} ({n_pnouns / n_words:.2%})'", ")", "\n", "print", "(", "f'Proper nouns: {n_propers} ({n_propers / n_words:.2%})'", ")", "\n", "print", "(", "f'Entity words: {n_entity_words} ({n_entity_words / n_words:.2%})'", ")", "\n", "print", "(", "f'Entity sents: {n_ent_sents} ({n_ent_sents / n_captions:.2%})'", ")", "\n", "print", "(", "f'Person names: {n_person_names} ({n_person_names / n_words:.2%})'", ")", "\n", "print", "(", "f'Person sents: {n_pers_sents} ({n_pers_sents / n_captions:.2%})'", ")", "\n", "print", "(", "'Caption splits:'", ",", "caption_splits", ")", "\n", "print", "(", "'Article splits:'", ",", "article_splits", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_nytimes_exact_subset_statistics": [[135, 215], ["goodnews.splits.find", "set", "datetime.datetime", "datetime.datetime", "logger.info", "tqdm.tqdm", "print", "print", "print", "print", "print", "print", "print", "print", "print", "goodnews.articles.find_one", "open", "pickle.dump", "set.add", "nytimes.articles.find_one", "len", "len", "len", "len", "len", "os.path.join", "os.path.exists", "captions.append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["", "def", "compute_nytimes_exact_subset_statistics", "(", "nytimes", ",", "goodnews", ")", ":", "\n", "    ", "cursor", "=", "goodnews", ".", "splits", ".", "find", "(", "\n", "{", "}", ",", "projection", "=", "[", "'_id'", ",", "'article_id'", "]", ",", "no_cursor_timeout", "=", "True", ")", "\n", "article_ids", "=", "set", "(", "{", "}", ")", "\n", "\n", "n_article_words", "=", "0", "\n", "n_caption_words", "=", "0", "\n", "n_captions", "=", "0", "\n", "n_articles", "=", "0", "\n", "\n", "n_total_nytimes_captions", "=", "0", "\n", "n_total_goodnews_captions", "=", "0", "\n", "\n", "diff_articles", "=", "{", "}", "\n", "\n", "max_date", "=", "datetime", "(", "2000", ",", "1", ",", "1", ")", "\n", "min_date", "=", "datetime", "(", "2020", ",", "1", ",", "1", ")", "\n", "\n", "logger", ".", "info", "(", "'Computing exact subset of NYTimes statistics.'", ")", "\n", "for", "sample", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "goodnews_article", "=", "goodnews", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "[", "'_id'", ",", "'images'", "]", ")", "\n", "\n", "if", "sample", "[", "'article_id'", "]", "not", "in", "article_ids", ":", "\n", "            ", "article_ids", ".", "add", "(", "sample", "[", "'article_id'", "]", ")", "\n", "article", "=", "nytimes", ".", "articles", ".", "find_one", "(", "{", "'_id'", ":", "sample", "[", "'article_id'", "]", "}", ")", "\n", "\n", "if", "article", "is", "None", "or", "'parsed_section'", "not", "in", "article", ":", "\n", "                ", "continue", "\n", "\n", "", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "pars", "=", "[", "s", "[", "'text'", "]", "for", "s", "in", "sections", "if", "s", "[", "'type'", "]", "==", "'paragraph'", "]", "\n", "\n", "n_new_captions", "=", "len", "(", "[", "1", "for", "s", "in", "sections", "\n", "if", "s", "[", "'type'", "]", "==", "'caption'", "]", ")", "\n", "n_total_nytimes_captions", "+=", "n_new_captions", "\n", "\n", "n_old_captions", "=", "len", "(", "goodnews_article", "[", "'images'", "]", ")", "\n", "n_total_goodnews_captions", "+=", "n_old_captions", "\n", "\n", "if", "n_new_captions", "!=", "n_old_captions", ":", "\n", "                ", "diff_articles", "[", "sample", "[", "'article_id'", "]", "]", "=", "{", "\n", "'n_new_captions'", ":", "n_new_captions", ",", "\n", "'n_old_captions'", ":", "n_old_captions", ",", "\n", "}", "\n", "\n", "", "captions", "=", "[", "]", "\n", "for", "s", "in", "sections", ":", "\n", "                ", "if", "s", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                    ", "image_path", "=", "os", ".", "path", ".", "join", "(", "'data/nytimes/images_processed'", ",", "\n", "f\"{s['hash']}.jpg\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "                        ", "captions", ".", "append", "(", "s", "[", "'text'", "]", ")", "\n", "\n", "", "", "", "if", "not", "captions", ":", "\n", "                ", "continue", "\n", "\n", "", "n_article_words", "+=", "len", "(", "' '", ".", "join", "(", "pars", ")", ".", "split", "(", ")", ")", "\n", "n_articles", "+=", "1", "\n", "n_caption_words", "+=", "len", "(", "' '", ".", "join", "(", "captions", ")", ".", "split", "(", ")", ")", "\n", "n_captions", "+=", "len", "(", "captions", ")", "\n", "\n", "if", "article", "[", "'pub_date'", "]", "<", "min_date", ":", "\n", "                ", "min_date", "=", "article", "[", "'pub_date'", "]", "\n", "", "if", "article", "[", "'pub_date'", "]", ">", "max_date", ":", "\n", "                ", "max_date", "=", "article", "[", "'pub_date'", "]", "\n", "\n", "", "", "", "with", "open", "(", "'data/diff_articles.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "diff_articles", ",", "f", ")", "\n", "\n", "", "print", "(", "'Subset of NYTimes Dataset:'", ")", "\n", "print", "(", "'No of articles:'", ",", "n_articles", ")", "\n", "print", "(", "'No of total NYTimes captions:'", ",", "n_total_nytimes_captions", ")", "\n", "print", "(", "'No of total GoodNews captions:'", ",", "n_total_goodnews_captions", ")", "\n", "print", "(", "'Average article len:'", ",", "n_article_words", "/", "n_articles", ")", "\n", "print", "(", "'Average caption len:'", ",", "n_caption_words", "/", "n_captions", ")", "\n", "print", "(", "'Min date:'", ",", "min_date", ")", "\n", "print", "(", "'Max date:'", ",", "max_date", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_goodnews_stats": [[217, 316], ["goodnews.splits.find", "set", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "logger.info", "tqdm.tqdm", "print", "print", "print", "print", "print", "print", "print", "collections.defaultdict.items", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "goodnews.articles.find_one", "os.path.join", "[].strip", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "print", "os.path.exists", "set.add", "len", "split_ids[].add", "[].strip.split", "len", "len", "article[].strip().split", "e[].split", "len", "e[].split", "article[].strip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info"], ["", "def", "compute_goodnews_stats", "(", "goodnews", ")", ":", "\n", "    ", "cursor", "=", "goodnews", ".", "splits", ".", "find", "(", "{", "}", ")", "\n", "article_ids", "=", "set", "(", "{", "}", ")", "\n", "split_ids", "=", "defaultdict", "(", "set", ")", "\n", "n_article_words", "=", "0", "\n", "n_caption_words", "=", "0", "\n", "n_captions", "=", "0", "\n", "n_original_captions", "=", "0", "\n", "language_counter", "=", "defaultdict", "(", "int", ")", "\n", "\n", "n_words", "=", "0", "\n", "n_nouns", "=", "0", "\n", "n_adjs", "=", "0", "\n", "n_verbs", "=", "0", "\n", "n_pnouns", "=", "0", "\n", "n_propers", "=", "0", "\n", "n_entity_words", "=", "0", "\n", "n_ent_sents", "=", "0", "\n", "n_person_names", "=", "0", "\n", "n_pers_sents", "=", "0", "\n", "\n", "caption_splits", "=", "defaultdict", "(", "int", ")", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'article'", ",", "'language'", ",", "'images'", ",", "'split'", ",", "\n", "'caption_parts_of_speech'", ",", "'caption_ner'", "]", "\n", "\n", "logger", ".", "info", "(", "'Computing GoodNews statistics.'", ")", "\n", "for", "sample", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "n_original_captions", "+=", "1", "\n", "article", "=", "goodnews", ".", "articles", ".", "find_one", "(", "{", "\n", "'_id'", ":", "{", "'$eq'", ":", "sample", "[", "'article_id'", "]", "}", ",", "\n", "}", ",", "projection", "=", "projection", ")", "\n", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "\n", "'data/goodnews/images_processed'", ",", "f\"{sample['_id']}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "sample", "[", "'article_id'", "]", "not", "in", "article_ids", ":", "\n", "            ", "article_ids", ".", "add", "(", "sample", "[", "'article_id'", "]", ")", "\n", "n_article_words", "+=", "len", "(", "article", "[", "'article'", "]", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "language_counter", "[", "article", "[", "'language'", "]", "]", "+=", "1", "\n", "\n", "", "if", "sample", "[", "'article_id'", "]", "not", "in", "split_ids", "[", "sample", "[", "'split'", "]", "]", ":", "\n", "            ", "split_ids", "[", "sample", "[", "'split'", "]", "]", ".", "add", "(", "sample", "[", "'article_id'", "]", ")", "\n", "\n", "", "caption", "=", "article", "[", "'images'", "]", "[", "sample", "[", "'image_index'", "]", "]", ".", "strip", "(", ")", "\n", "n_caption_words", "+=", "len", "(", "caption", ".", "split", "(", ")", ")", "\n", "n_captions", "+=", "1", "\n", "caption_splits", "[", "sample", "[", "'split'", "]", "]", "+=", "1", "\n", "\n", "pos", "=", "article", "[", "'caption_parts_of_speech'", "]", "[", "sample", "[", "'image_index'", "]", "]", "\n", "n_words", "+=", "len", "(", "pos", ")", "\n", "n_nouns", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'NOUN'", "]", ")", "\n", "n_verbs", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'VERB'", "]", ")", "\n", "n_adjs", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'ADJ'", "]", ")", "\n", "n_pnouns", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'PRON'", "]", ")", "\n", "n_propers", "+=", "len", "(", "[", "1", "for", "p", "in", "pos", "if", "p", "[", "'pos'", "]", "==", "'PROPN'", "]", ")", "\n", "\n", "ners", "=", "article", "[", "'caption_ner'", "]", "[", "sample", "[", "'image_index'", "]", "]", "\n", "has_person", "=", "False", "\n", "for", "e", "in", "ners", ":", "\n", "            ", "n_entity_words", "+=", "len", "(", "e", "[", "'text'", "]", ".", "split", "(", ")", ")", "\n", "if", "e", "[", "'label'", "]", "==", "'PERSON'", ":", "\n", "                ", "n_person_names", "+=", "len", "(", "e", "[", "'text'", "]", ".", "split", "(", ")", ")", "\n", "has_person", "=", "True", "\n", "", "", "if", "ners", ":", "\n", "            ", "n_ent_sents", "+=", "1", "\n", "", "if", "has_person", ":", "\n", "            ", "n_pers_sents", "+=", "1", "\n", "\n", "", "", "article_splits", "=", "{", "\n", "'train'", ":", "len", "(", "split_ids", "[", "'train'", "]", ")", ",", "\n", "'val'", ":", "len", "(", "split_ids", "[", "'val'", "]", ")", ",", "\n", "'test'", ":", "len", "(", "split_ids", "[", "'test'", "]", ")", ",", "\n", "}", "\n", "\n", "print", "(", "'Subset of GoodNews Dataset:'", ")", "\n", "print", "(", "'No of articles:'", ",", "len", "(", "article_ids", ")", ")", "\n", "print", "(", "'No of captions:'", ",", "n_captions", ")", "\n", "print", "(", "'No of original captions:'", ",", "n_original_captions", ")", "\n", "print", "(", "'Average article len:'", ",", "n_article_words", "/", "len", "(", "article_ids", ")", ")", "\n", "print", "(", "'Average caption len:'", ",", "n_caption_words", "/", "n_captions", ")", "\n", "print", "(", "'Language stats'", ")", "\n", "for", "lang", ",", "count", "in", "language_counter", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "lang", ",", "count", ")", "\n", "", "print", "(", "f'Words: {n_words}'", ")", "\n", "print", "(", "f'Nouns: {n_nouns} ({n_nouns / n_words:.2%})'", ")", "\n", "print", "(", "f'Verbs: {n_verbs} ({n_verbs / n_words:.2%})'", ")", "\n", "print", "(", "f'Adjectives: {n_adjs} ({n_adjs / n_words:.2%})'", ")", "\n", "print", "(", "f'Pronouns: {n_pnouns} ({n_pnouns / n_words:.2%})'", ")", "\n", "print", "(", "f'Proper nouns: {n_propers} ({n_propers / n_words:.2%})'", ")", "\n", "print", "(", "f'Entity words: {n_entity_words} ({n_entity_words / n_words:.2%})'", ")", "\n", "print", "(", "f'Entity sents: {n_ent_sents} ({n_ent_sents / n_captions:.2%})'", ")", "\n", "print", "(", "f'Person names: {n_person_names} ({n_person_names / n_words:.2%})'", ")", "\n", "print", "(", "f'Person sents: {n_pers_sents} ({n_pers_sents / n_captions:.2%})'", ")", "\n", "print", "(", "'Caption splits:'", ",", "caption_splits", ")", "\n", "print", "(", "'Article splits:'", ",", "article_splits", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_face_stats": [[318, 366], ["nytimes.articles.find", "collections.defaultdict", "collections.defaultdict", "tqdm.tqdm", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "compute_face_stats", "(", "nytimes", ")", ":", "\n", "    ", "projection", "=", "[", "'_id'", ",", "'n_images'", ",", "'n_images_with_faces'", ",", "'image_positions'", ",", "\n", "'detected_face_positions'", ",", "'parsed_section.facenet_details'", ",", "\n", "'parsed_section.named_entities'", "]", "\n", "cursor", "=", "nytimes", ".", "articles", ".", "find", "(", "{", "'split'", ":", "'train'", "}", ",", "projection", "=", "projection", ")", "\n", "\n", "n_images_with_faces", "=", "0", "\n", "n_images", "=", "0", "\n", "n_articles", "=", "0", "\n", "n_articles_with_faces", "=", "0", "\n", "face_count", "=", "defaultdict", "(", "int", ")", "\n", "name_count", "=", "defaultdict", "(", "int", ")", "\n", "\n", "for", "article", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "n_images", "+=", "article", "[", "'n_images'", "]", "\n", "n_articles", "+=", "1", "\n", "\n", "if", "'n_images_with_faces'", "in", "article", "and", "article", "[", "'n_images_with_faces'", "]", ":", "\n", "            ", "n_images_with_faces", "+=", "article", "[", "'n_images_with_faces'", "]", "\n", "n_articles_with_faces", "+=", "1", "\n", "\n", "", "if", "'detected_face_positions'", "not", "in", "article", ":", "\n", "            ", "continue", "\n", "\n", "", "for", "pos", "in", "article", "[", "'detected_face_positions'", "]", ":", "\n", "            ", "section", "=", "article", "[", "'parsed_section'", "]", "[", "pos", "]", "\n", "if", "'facenet_details'", "in", "section", ":", "\n", "                ", "n_faces", "=", "section", "[", "'facenet_details'", "]", "[", "'n_faces'", "]", "\n", "face_count", "[", "n_faces", "]", "+=", "1", "\n", "\n", "", "", "for", "pos", "in", "article", "[", "'image_positions'", "]", ":", "\n", "            ", "section", "=", "article", "[", "'parsed_section'", "]", "[", "pos", "]", "\n", "if", "'named_entities'", "in", "section", ":", "\n", "                ", "c", "=", "0", "\n", "for", "ner", "in", "section", "[", "'named_entities'", "]", ":", "\n", "                    ", "if", "ner", "[", "'label'", "]", "==", "'PERSON'", ":", "\n", "                        ", "c", "+=", "1", "\n", "", "", "name_count", "[", "c", "]", "+=", "1", "\n", "\n", "", "", "", "print", "(", "'No of images with faces:'", ",", "n_images_with_faces", ")", "\n", "print", "(", "'No of images:'", ",", "n_images", ")", "\n", "print", "(", "'No of articles:'", ",", "n_articles", ")", "\n", "print", "(", "'No of articles with faces:'", ",", "n_articles_with_faces", ")", "\n", "print", "(", "'Face count:'", ")", "\n", "print", "(", "face_count", ")", "\n", "print", "(", "'Name count:'", ")", "\n", "print", "(", "name_count", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_rare_stats": [[368, 409], ["nytimes.articles.find", "tqdm.tqdm", "print", "print", "print", "print", "print", "open", "pickle.load", "os.path.join", "os.path.exists", "len"], "function", ["None"], ["", "def", "compute_rare_stats", "(", "nytimes", ")", ":", "\n", "    ", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.hash'", ",", "\n", "'parsed_section.parts_of_speech'", "]", "\n", "cursor", "=", "nytimes", ".", "articles", ".", "find", "(", "{", "'split'", ":", "'test'", "}", ",", "projection", "=", "projection", ")", "\n", "\n", "path", "=", "'./data/nytimes/name_counters.pkl'", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "name_counters", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "full_counter", "=", "name_counters", "[", "'caption'", "]", "+", "name_counters", "[", "'context'", "]", "\n", "\n", "n_words", "=", "0", "\n", "n_propers", "=", "0", "\n", "n_rare_propers", "=", "0", "\n", "n_very_rare_propers", "=", "0", "\n", "\n", "for", "article", "in", "tqdm", "(", "cursor", ")", ":", "\n", "        ", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "for", "s", "in", "sections", ":", "\n", "            ", "if", "s", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                ", "image_path", "=", "os", ".", "path", ".", "join", "(", "'data/nytimes/images_processed'", ",", "\n", "f\"{s['hash']}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "if", "'parts_of_speech'", "in", "s", ":", "\n", "                    ", "pos", "=", "s", "[", "'parts_of_speech'", "]", "\n", "n_words", "+=", "len", "(", "pos", ")", "\n", "for", "p", "in", "pos", ":", "\n", "                        ", "if", "p", "[", "'pos'", "]", "==", "'PROPN'", ":", "\n", "                            ", "n_propers", "+=", "1", "\n", "if", "p", "[", "'text'", "]", "not", "in", "name_counters", "[", "'caption'", "]", ":", "\n", "                                ", "n_rare_propers", "+=", "1", "\n", "", "if", "p", "[", "'text'", "]", "not", "in", "full_counter", ":", "\n", "                                ", "n_very_rare_propers", "+=", "1", "\n", "\n", "", "", "", "", "", "", "", "print", "(", "'No of words'", ",", "n_words", ")", "\n", "print", "(", "'No of proper nouns'", ",", "n_propers", ")", "\n", "print", "(", "'No of rare proper nouns'", ",", "n_rare_propers", ")", "\n", "print", "(", "'No of very rare proper nouns'", ",", "n_very_rare_propers", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.validate": [[411, 420], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.main": [[422, 440], ["docopt.docopt", "compute_data_statistics.validate", "pymongo.MongoClient", "compute_data_statistics.compute_nytimes_stats", "compute_data_statistics.compute_goodnews_stats", "compute_data_statistics.compute_nytimes_exact_subset_statistics", "compute_data_statistics.compute_face_stats", "compute_data_statistics.compute_rare_stats", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_nytimes_stats", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_goodnews_stats", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_nytimes_exact_subset_statistics", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_face_stats", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_data_statistics.compute_rare_stats"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "client", "=", "MongoClient", "(", "host", "=", "'localhost'", ",", "port", "=", "27017", ")", "\n", "nytimes", "=", "client", ".", "nytimes", "\n", "goodnews", "=", "client", ".", "goodnews", "\n", "\n", "compute_nytimes_stats", "(", "nytimes", ")", "\n", "compute_goodnews_stats", "(", "goodnews", ")", "\n", "compute_nytimes_exact_subset_statistics", "(", "nytimes", ",", "goodnews", ")", "\n", "compute_face_stats", "(", "nytimes", ")", "\n", "compute_rare_stats", "(", "nytimes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.open_json": [[23, 26], ["open", "json.load"], "function", ["None"], ["def", "open_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.score": [[28, 50], ["scorer.compute_score", "pycocoevalcap.bleu.bleu.Bleu", "pycocoevalcap.meteor.meteor.Meteor", "pycocoevalcap.rouge.rouge.Rouge", "pycocoevalcap.cider.cider.Cider", "type", "zip", "zip"], "function", ["None"], ["", "", "def", "score", "(", "ref", ",", "hypo", ")", ":", "\n", "    ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "(", "Meteor", "(", ")", ",", "\"METEOR\"", ")", ",", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", ",", "\n", "]", "\n", "final_scores", "=", "{", "}", "\n", "all_scores", "=", "{", "}", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "        ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "ref", ",", "hypo", ")", "\n", "\n", "if", "type", "(", "score", ")", "==", "list", ":", "\n", "            ", "for", "m", ",", "s", "in", "zip", "(", "method", ",", "score", ")", ":", "\n", "                ", "final_scores", "[", "m", "]", "=", "s", "\n", "", "for", "m", ",", "s", "in", "zip", "(", "method", ",", "scores", ")", ":", "\n", "                ", "all_scores", "[", "m", "]", "=", "s", "\n", "", "", "else", ":", "\n", "            ", "final_scores", "[", "method", "]", "=", "score", "\n", "all_scores", "[", "method", "]", "=", "scores", "\n", "\n", "", "", "return", "final_scores", ",", "all_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.evaluate": [[52, 75], ["enumerate", "enumerate", "goodnews_insert.score", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.score"], ["", "def", "evaluate", "(", "ref", ",", "cand", ",", "get_scores", "=", "True", ")", ":", "\n", "# make dictionary", "\n", "    ", "hypo", "=", "{", "}", "\n", "for", "i", ",", "caption", "in", "enumerate", "(", "cand", ")", ":", "\n", "        ", "hypo", "[", "i", "]", "=", "[", "caption", "]", "\n", "", "truth", "=", "{", "}", "\n", "for", "i", ",", "caption", "in", "enumerate", "(", "ref", ")", ":", "\n", "        ", "truth", "[", "i", "]", "=", "[", "caption", "]", "\n", "\n", "# compute bleu score", "\n", "", "final_scores", "=", "score", "(", "truth", ",", "hypo", ")", "\n", "\n", "#     print out scores", "\n", "print", "(", "'Bleu_1:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'Bleu_1'", "]", ")", "\n", "print", "(", "'Bleu_2:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'Bleu_2'", "]", ")", "\n", "print", "(", "'Bleu_3:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'Bleu_3'", "]", ")", "\n", "print", "(", "'Bleu_4:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'Bleu_4'", "]", ")", "\n", "print", "(", "'METEOR:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'METEOR'", "]", ")", "\n", "print", "(", "'ROUGE_L: ;'", ",", "final_scores", "[", "0", "]", "[", "'ROUGE_L'", "]", ")", "\n", "print", "(", "'CIDEr:\\t ;'", ",", "final_scores", "[", "0", "]", "[", "'CIDEr'", "]", ")", "\n", "\n", "if", "get_scores", ":", "\n", "        ", "return", "final_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.organize_ner": [[77, 84], ["collections.defaultdict", "ner.items", "k.split", "new[].append"], "function", ["None"], ["", "", "def", "organize_ner", "(", "ner", ")", ":", "\n", "    ", "new", "=", "defaultdict", "(", "list", ")", "\n", "for", "k", ",", "v", "in", "ner", ".", "items", "(", ")", ":", "\n", "        ", "value", "=", "' '", ".", "join", "(", "k", ".", "split", "(", ")", ")", "\n", "if", "value", "not", "in", "stopwords", ":", "\n", "            ", "new", "[", "v", "]", ".", "append", "(", "value", ")", "\n", "", "", "return", "new", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.fill_random": [[86, 101], ["c.isupper", "filled.append", "c.split", "numpy.random.choice", "filled.append", "filled.append", "c.split"], "function", ["None"], ["", "def", "fill_random", "(", "cap", ",", "ner_dict", ")", ":", "\n", "    ", "assert", "cap", "!=", "list", "\n", "filled", "=", "[", "]", "\n", "for", "c", "in", "cap", ":", "\n", "        ", "if", "c", ".", "split", "(", "'_'", ")", "[", "0", "]", "in", "named_entities", "and", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "ent", "=", "c", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "ner_dict", "[", "ent", "]", ":", "\n", "                ", "ner", "=", "np", ".", "random", ".", "choice", "(", "ner_dict", "[", "ent", "]", ")", "\n", "filled", ".", "append", "(", "ner", ")", "\n", "", "else", ":", "\n", "                ", "filled", ".", "append", "(", "c", ")", "\n", "", "", "else", ":", "\n", "            ", "filled", ".", "append", "(", "c", ")", "\n", "\n", "", "", "return", "filled", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.rank_sentences": [[103, 115], ["str", "nlp", "sorted", "str", "nlp", "s.similarity", "zip"], "function", ["None"], ["", "def", "rank_sentences", "(", "cap", ",", "sent", ")", ":", "\n", "# make them unicode, spacy accepts only unicode", "\n", "    ", "cap", "=", "str", "(", "cap", ")", "\n", "sent", "=", "[", "str", "(", "s", ")", "for", "s", "in", "sent", "]", "\n", "# feed them to spacy to get the vectors", "\n", "cap", "=", "nlp", "(", "cap", ")", "\n", "list_sent", "=", "[", "nlp", "(", "s", ")", "for", "s", "in", "sent", "]", "\n", "compare", "=", "[", "s", ".", "similarity", "(", "cap", ")", "for", "s", "in", "list_sent", "]", "\n", "# we sort the article sentences according to their similarity to produced caption", "\n", "similarity", "=", "sorted", "(", "[", "(", "s", ",", "c", ")", "for", "s", ",", "c", "in", "zip", "(", "\n", "list_sent", ",", "compare", ")", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "return", "similarity", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.ner_finder": [[117, 125], ["zip", "sen.find", "float", "float", "len"], "function", ["None"], ["", "def", "ner_finder", "(", "ranked_sen", ",", "score_sen", ",", "word", ")", ":", "\n", "    ", "for", "sen", ",", "sc", "in", "zip", "(", "ranked_sen", ",", "score_sen", ")", ":", "\n", "        ", "beg", "=", "sen", ".", "find", "(", "word", ")", "\n", "if", "beg", "is", "not", "-", "1", ":", "\n", "            ", "end", "=", "beg", "+", "len", "(", "word", ")", "\n", "return", "sen", "[", "beg", ":", "end", "]", ",", "sc", "\n", "", "", "else", ":", "\n", "        ", "return", "float", "(", "'-inf'", ")", ",", "float", "(", "'-inf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.fill_word2vec": [[127, 171], ["goodnews_insert.rank_sentences", "ner_dict.items", "collections.deque", "goodnews_insert.ner_finder", "goodnews_insert.ner_finder", "new.items", "c.isupper", "filled.append", "re.sub", "goodnews_insert.ner_finder", "c.split", "new[].popleft", "new[].append", "filled.append", "filled.append", "sorted", "c.split", "ners.append", "v.items", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.rank_sentences", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.ner_finder", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.ner_finder", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.ner_finder"], ["", "", "def", "fill_word2vec", "(", "cap", ",", "ner_dict", ",", "ner_articles", ",", "return_ners", "=", "False", ")", ":", "\n", "    ", "assert", "cap", "!=", "list", "\n", "filled", "=", "[", "]", "\n", "similarity", "=", "rank_sentences", "(", "' '", ".", "join", "(", "cap", ")", ",", "ner_articles", ")", "\n", "ranked_sen", "=", "[", "s", "[", "0", "]", ".", "text", "for", "s", "in", "similarity", "]", "\n", "score_sen", "=", "[", "s", "[", "1", "]", "for", "s", "in", "similarity", "]", "\n", "if", "return_ners", ":", "\n", "        ", "ners", "=", "[", "]", "\n", "\n", "", "new", "=", "{", "}", "\n", "for", "key", ",", "values", "in", "ner_dict", ".", "items", "(", ")", ":", "\n", "        ", "temp", "=", "{", "}", "\n", "for", "word", "in", "values", ":", "\n", "            ", "found", ",", "sc1", "=", "ner_finder", "(", "\n", "ranked_sen", ",", "score_sen", ",", "re", ".", "sub", "(", "'[^A-Za-z0-9]+'", ",", "' '", ",", "word", ")", ")", "\n", "found2", ",", "sc2", "=", "ner_finder", "(", "ranked_sen", ",", "score_sen", ",", "word", ")", "\n", "if", "found", ":", "\n", "                ", "temp", "[", "word", "]", "=", "sc1", "\n", "", "elif", "ner_finder", "(", "ranked_sen", ",", "score_sen", ",", "word", ")", ":", "\n", "                ", "temp", "[", "word", "]", "=", "sc2", "\n", "", "else", ":", "\n", "                ", "temp", "[", "word", "]", "=", "0", "\n", "", "", "new", "[", "key", "]", "=", "temp", "\n", "", "new", "=", "{", "k", ":", "deque", "(", "[", "i", "for", "i", ",", "_", "in", "sorted", "(", "v", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ",", "reverse", "=", "True", ")", "]", ")", "for", "k", ",", "v", "in", "\n", "new", ".", "items", "(", ")", "}", "\n", "\n", "for", "c", "in", "cap", ":", "\n", "        ", "if", "c", ".", "split", "(", "'_'", ")", "[", "0", "]", "in", "named_entities", "and", "c", ".", "isupper", "(", ")", ":", "\n", "            ", "ent", "=", "c", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "ner_dict", "[", "ent", "]", ":", "\n", "                ", "ner", "=", "new", "[", "ent", "]", ".", "popleft", "(", ")", "\n", "# append it again, we might need to reuse some entites.", "\n", "new", "[", "ent", "]", ".", "append", "(", "ner", ")", "\n", "filled", ".", "append", "(", "ner", ")", "\n", "if", "return_ners", ":", "\n", "                    ", "ners", ".", "append", "(", "(", "ner", ",", "ent", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "filled", ".", "append", "(", "c", ")", "\n", "", "", "else", ":", "\n", "            ", "filled", ".", "append", "(", "c", ")", "\n", "", "", "if", "return_ners", ":", "\n", "        ", "return", "filled", ",", "ners", "\n", "", "else", ":", "\n", "        ", "return", "filled", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert_word": [[173, 190], ["len", "sorted", "art_sen.find", "art_sen.find"], "function", ["None"], ["", "", "def", "insert_word", "(", "ner_test", ",", "sen_att", ",", "ix", ",", "ner_dict", ",", "return_ner", "=", "False", ")", ":", "\n", "    ", "if", "ner_test", "in", "named_entities", ":", "\n", "        ", "for", "ii", "in", "sen_att", "[", "ix", "]", ":", "\n", "            ", "if", "ii", "<", "len", "(", "article", "[", "'sentence'", "]", ")", ":", "\n", "                ", "art_sen", "=", "article", "[", "'sentence'", "]", "[", "ii", "]", "\n", "temp", "=", "[", "(", "art_sen", ".", "find", "(", "ner", ")", ",", "ner", ")", "\n", "for", "ner", "in", "ner_dict", "[", "ner_test", "]", "if", "art_sen", ".", "find", "(", "ner", ")", "!=", "-", "1", "]", "\n", "\n", "temp", "=", "sorted", "(", "temp", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "if", "temp", "and", "return_ner", ":", "\n", "                    ", "return", "temp", "[", "0", "]", "[", "1", "]", ",", "ner_test", "\n", "", "if", "temp", ":", "\n", "                    ", "return", "temp", "[", "0", "]", "[", "1", "]", ",", "None", "\n", "", "", "", "else", ":", "\n", "            ", "return", "ner_test", ",", "None", "\n", "", "", "else", ":", "\n", "        ", "return", "ner_test", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert": [[192, 209], ["enumerate", "goodnews_insert.insert_word", "words.append", "c.split", "ners.append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.insert_word"], ["", "", "def", "insert", "(", "cap", ",", "sen_att", ",", "ner_dict", ",", "return_ners", "=", "False", ")", ":", "\n", "    ", "new_sen", "=", "''", "\n", "words", "=", "[", "]", "\n", "if", "return_ners", ":", "\n", "        ", "ners", "=", "[", "]", "\n", "\n", "", "for", "ix", ",", "c", "in", "enumerate", "(", "cap", ")", ":", "\n", "        ", "ner_test", "=", "c", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "word", ",", "ner", "=", "insert_word", "(", "ner_test", ",", "sen_att", ",", "ix", ",", "ner_dict", ",", "return_ners", ")", "\n", "if", "ner", ":", "\n", "            ", "ners", ".", "append", "(", "(", "word", ",", "ner", ")", ")", "\n", "", "words", ".", "append", "(", "word", ")", "\n", "#         new_sen += ' ' +", "\n", "", "if", "return_ners", ":", "\n", "        ", "return", "' '", ".", "join", "(", "words", ")", ",", "ners", "\n", "", "else", ":", "\n", "        ", "return", "' '", ".", "join", "(", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_proper_nouns": [[211, 218], ["nlp", "proper_nouns.append"], "function", ["None"], ["", "", "def", "get_proper_nouns", "(", "text", ",", "nlp", ")", ":", "\n", "    ", "doc", "=", "nlp", "(", "text", ")", "\n", "proper_nouns", "=", "[", "]", "\n", "for", "token", "in", "doc", ":", "\n", "        ", "if", "token", ".", "pos_", "==", "'PROPN'", ":", "\n", "            ", "proper_nouns", ".", "append", "(", "token", ".", "text", ")", "\n", "", "", "return", "proper_nouns", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_entities": [[220, 229], ["entities.append"], "function", ["None"], ["", "def", "get_entities", "(", "doc", ")", ":", "\n", "    ", "entities", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "        ", "entities", ".", "append", "(", "{", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "'tokens'", ":", "[", "{", "'text'", ":", "tok", ".", "text", ",", "'pos'", ":", "tok", ".", "pos_", "}", "for", "tok", "in", "ent", "]", ",", "\n", "}", ")", "\n", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_readability_scores": [[231, 245], ["textstat.flesch_reading_ease", "textstat.flesch_kincaid_grade", "textstat.gunning_fog", "textstat.smog_index", "textstat.automated_readability_index", "textstat.coleman_liau_index", "textstat.linsear_write_formula", "textstat.dale_chall_readability_score", "textstat.text_standard", "textstat.difficult_words", "len", "text.split"], "function", ["None"], ["", "def", "get_readability_scores", "(", "text", ")", ":", "\n", "    ", "scores", "=", "{", "\n", "'flesch_reading_ease'", ":", "textstat", ".", "flesch_reading_ease", "(", "text", ")", ",", "\n", "'flesch_kincaid_grade'", ":", "textstat", ".", "flesch_kincaid_grade", "(", "text", ")", ",", "\n", "'gunning_fog'", ":", "textstat", ".", "gunning_fog", "(", "text", ")", ",", "\n", "'smog_index'", ":", "textstat", ".", "smog_index", "(", "text", ")", ",", "\n", "'automated_readability_index'", ":", "textstat", ".", "automated_readability_index", "(", "text", ")", ",", "\n", "'coleman_liau_index'", ":", "textstat", ".", "coleman_liau_index", "(", "text", ")", ",", "\n", "'linsear_write_formula'", ":", "textstat", ".", "linsear_write_formula", "(", "text", ")", ",", "\n", "'dale_chall_readability_score'", ":", "textstat", ".", "dale_chall_readability_score", "(", "text", ")", ",", "\n", "'text_standard'", ":", "textstat", ".", "text_standard", "(", "text", ",", "float_output", "=", "True", ")", ",", "\n", "'difficult_words'", ":", "textstat", ".", "difficult_words", "(", "text", ")", "/", "len", "(", "text", ".", "split", "(", ")", ")", ",", "\n", "}", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.is_word": [[247, 249], ["None"], "function", ["None"], ["", "def", "is_word", "(", "tok", ")", ":", "\n", "    ", "return", "tok", "not", "in", "string", ".", "punctuation", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.get_narrative_productivity": [[251, 267], ["nltk.tokenize.word_tokenize", "list", "len", "len", "filter", "set", "goodnews_insert.basic_ttr", "goodnews_insert.root_ttr", "goodnews_insert.corrected_ttr", "goodnews_insert.herdan", "goodnews_insert.summer", "goodnews_insert.maas"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.basic_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.root_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.corrected_ttr", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.herdan", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.summer", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.maas"], ["", "def", "get_narrative_productivity", "(", "text", ")", ":", "\n", "    ", "doc", "=", "word_tokenize", "(", "text", ")", "\n", "doc", "=", "list", "(", "filter", "(", "is_word", ",", "doc", ")", ")", "\n", "n_words", "=", "len", "(", "doc", ")", "\n", "n_terms", "=", "len", "(", "set", "(", "doc", ")", ")", "\n", "\n", "scores", "=", "{", "\n", "'basic_ttr'", ":", "basic_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'root_ttr'", ":", "root_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'corrected_ttr'", ":", "corrected_ttr", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'herdan'", ":", "herdan", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'summer'", ":", "summer", "(", "n_terms", ",", "n_words", ")", ",", "\n", "'maas'", ":", "maas", "(", "n_terms", ",", "n_words", ")", ",", "\n", "}", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.basic_ttr": [[269, 277], ["None"], "function", ["None"], ["", "def", "basic_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Type-token ratio (TTR) computed as t/w, where t is the number of unique\n    terms/vocab, and w is the total number of words.\n    (Chotlos 1944, Templin 1957)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.root_ttr": [[279, 288], ["math.sqrt"], "function", ["None"], ["", "def", "root_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Root TTR (RTTR) computed as t/sqrt(w), where t is the number of unique terms/vocab,\n        and w is the total number of words.\n        Also known as Guiraud's R and Guiraud's index.\n        (Guiraud 1954, 1960)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "math", ".", "sqrt", "(", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.corrected_ttr": [[290, 298], ["math.sqrt"], "function", ["None"], ["", "def", "corrected_ttr", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Corrected TTR (CTTR) computed as t/sqrt(2 * w), where t is the number of unique terms/vocab,\n        and w is the total number of words.\n        (Carrol 1964)\n    \"\"\"", "\n", "if", "n_words", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "return", "n_terms", "/", "math", ".", "sqrt", "(", "2", "*", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.herdan": [[300, 309], ["math.log", "math.log"], "function", ["None"], ["", "def", "herdan", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Computed as log(t)/log(w), where t is the number of unique terms/vocab, and w is the\n        total number of words.\n        Also known as Herdan's C.\n        (Herdan 1960, 1964)\n    \"\"\"", "\n", "if", "n_words", "<=", "1", ":", "\n", "        ", "return", "0", "\n", "", "return", "math", ".", "log", "(", "n_terms", ")", "/", "math", ".", "log", "(", "n_words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.summer": [[311, 320], ["math.log", "math.log", "math.log", "math.log"], "function", ["None"], ["", "def", "summer", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Computed as log(log(t)) / log(log(w)), where t is the number of unique terms/vocab, and\n        w is the total number of words.\n        (Summer 1966)\n    \"\"\"", "\n", "try", ":", "\n", "        ", "math", ".", "log", "(", "math", ".", "log", "(", "n_terms", ")", ")", "/", "math", ".", "log", "(", "math", ".", "log", "(", "n_words", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.goodnews_insert.maas": [[322, 334], ["min", "math.log", "math.log", "math.log"], "function", ["None"], ["", "", "def", "maas", "(", "n_terms", ",", "n_words", ")", ":", "\n", "    ", "\"\"\" Maas's TTR, computed as (log(w) - log(t)) / (log(w) * log(w)), where t is the number of\n        unique terms/vocab, and w is the total number of words. Unlike the other measures, lower\n        maas measure indicates higher lexical richness.\n        (Maas 1972)\n    \"\"\"", "\n", "# We cap this score at 0.2", "\n", "if", "n_words", "<=", "1", ":", "\n", "        ", "return", "0.2", "\n", "", "score", "=", "(", "math", ".", "log", "(", "n_words", ")", "-", "math", ".", "log", "(", "n_terms", ")", ")", "/", "(", "math", ".", "log", "(", "n_words", ")", "**", "2", ")", "\n", "return", "min", "(", "score", ",", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics._stat": [[36, 45], ["hypothesis_str.replace().replace.replace().replace", "score_line.replace().replace.replace().replace", "compute_metrics..meteor_p.stdin.write", "compute_metrics..meteor_p.stdin.flush", "compute_metrics..meteor_p.stdout.readline().decode().strip", "hypothesis_str.replace().replace.replace", "score_line.replace().replace.replace", "compute_metrics..meteor_p.stdout.readline().decode", "compute_metrics..meteor_p.stdout.readline"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["def", "_stat", "(", "self", ",", "hypothesis_str", ",", "reference_list", ")", ":", "\n", "# SCORE ||| reference 1 words ||| reference n words ||| hypothesis words", "\n", "    ", "hypothesis_str", "=", "hypothesis_str", ".", "replace", "(", "'|||'", ",", "''", ")", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "score_line", "=", "' ||| '", ".", "join", "(", "\n", "(", "'SCORE'", ",", "' ||| '", ".", "join", "(", "reference_list", ")", ",", "hypothesis_str", ")", ")", "\n", "score_line", "=", "score_line", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "replace", "(", "'\\r'", ",", "''", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "score_line", ")", ".", "encode", "(", ")", ")", "\n", "self", ".", "meteor_p", ".", "stdin", ".", "flush", "(", ")", "\n", "return", "self", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "decode", "(", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.validate": [[47, 59], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'file'", ":", "os", ".", "path", ".", "exists", ",", "\n", "'counters'", ":", "Or", "(", "None", ",", "os", ".", "path", ".", "exists", ")", ",", "\n", "'use_processed'", ":", "bool", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.main": [[61, 289], ["docopt.docopt", "compute_metrics.validate", "pycocoevalcap.bleu.bleu_scorer.BleuScorer", "pycocoevalcap.rouge.rouge.Rouge", "pycocoevalcap.cider.cider_scorer.CiderScorer", "pycocoevalcap.meteor.meteor.Meteor", "types.MethodType", "pycocoevalcap.meteor.meteor.Meteor.lock.acquire", "collections.defaultdict", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdin.write", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdin.flush", "range", "float", "pycocoevalcap.meteor.meteor.Meteor.lock.release", "pycocoevalcap.bleu.bleu_scorer.BleuScorer.compute_score", "numpy.mean", "pycocoevalcap.cider.cider_scorer.CiderScorer.compute_score", "os.path.dirname", "os.path.join", "final_metrics.items", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "open", "pickle.load", "open", "tqdm.tqdm", "meteor_scores.append", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdout.readline().strip", "numpy.array", "os.path.basename().split", "open", "json.dump", "print", "json.loads", "compute_metrics.compute_full_recall", "compute_metrics.compute_full_precision", "compute_metrics.compute_rare_recall", "compute_metrics.compute_rare_precision", "compute_metrics.compute_rare_recall", "compute_metrics.compute_rare_precision", "re.sub", "re.sub", "lengths.append", "gt_lengths.append", "n_uniques.append", "gt_n_uniques.append", "pycocoevalcap.rouge.rouge.Rouge.calc_score", "rouge_scores.append", "pycocoevalcap.meteor.meteor.Meteor._stat", "gen_ttrs.append", "cap_ttrs.append", "gen_flesch.append", "cap_flesch.append", "compute_metrics.compute_entities", "float", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "sum", "len", "recalls.append", "precisions.append", "len", "len", "len", "len", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdout.readline().strip", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdout.readline", "os.path.basename", "compute_metrics.compute_recall", "compute_metrics.compute_precision", "re.sub.split", "re.sub.split", "set", "set", "re.sub.split", "re.sub.split", "pycocoevalcap.meteor.meteor.Meteor.meteor_p.stdout.readline"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_full_recall", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_full_precision", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_recall", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_precision", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_recall", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_precision", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics._stat", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_entities", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_recall", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_precision"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "with", "open", "(", "args", "[", "'counters'", "]", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "counters", "=", "pickle", ".", "load", "(", "f", ")", "\n", "\n", "", "full_counter", "=", "counters", "[", "'context'", "]", "+", "counters", "[", "'caption'", "]", "\n", "\n", "bleu_scorer", "=", "BleuScorer", "(", "n", "=", "4", ")", "\n", "rouge_scorer", "=", "Rouge", "(", ")", "\n", "rouge_scores", "=", "[", "]", "\n", "cider_scorer", "=", "CiderScorer", "(", "n", "=", "4", ",", "sigma", "=", "6.0", ")", "\n", "meteor_scorer", "=", "Meteor", "(", ")", "\n", "meteor_scorer", ".", "_stat", "=", "types", ".", "MethodType", "(", "_stat", ",", "meteor_scorer", ")", "\n", "meteor_scores", "=", "[", "]", "\n", "eval_line", "=", "'EVAL'", "\n", "meteor_scorer", ".", "lock", ".", "acquire", "(", ")", "\n", "count", "=", "0", "\n", "recalls", ",", "precisions", "=", "[", "]", ",", "[", "]", "\n", "rare_recall", ",", "rare_recall_total", "=", "0", ",", "0", "\n", "rare_precision", ",", "rare_precision_total", "=", "0", ",", "0", "\n", "full_recall", ",", "full_recall_total", "=", "0", ",", "0", "\n", "full_precision", ",", "full_precision_total", "=", "0", ",", "0", "\n", "full_rare_recall", ",", "full_rare_recall_total", "=", "0", ",", "0", "\n", "full_rare_precision", ",", "full_rare_precision_total", "=", "0", ",", "0", "\n", "lengths", ",", "gt_lengths", "=", "[", "]", ",", "[", "]", "\n", "n_uniques", ",", "gt_n_uniques", "=", "[", "]", ",", "[", "]", "\n", "\n", "gen_ttrs", ",", "cap_ttrs", "=", "[", "]", ",", "[", "]", "\n", "gen_flesch", ",", "cap_flesch", "=", "[", "]", ",", "[", "]", "\n", "\n", "ent_counter", "=", "defaultdict", "(", "int", ")", "\n", "\n", "with", "open", "(", "args", "[", "'file'", "]", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "            ", "obj", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "args", "[", "'use_processed'", "]", ":", "\n", "                ", "caption", "=", "obj", "[", "'caption'", "]", "\n", "obj", "[", "'caption_names'", "]", "=", "obj", "[", "'processed_caption_names'", "]", "\n", "", "else", ":", "\n", "                ", "caption", "=", "obj", "[", "'raw_caption'", "]", "\n", "\n", "", "generation", "=", "obj", "[", "'generation'", "]", "\n", "\n", "if", "obj", "[", "'caption_names'", "]", ":", "\n", "                ", "recalls", ".", "append", "(", "compute_recall", "(", "obj", ")", ")", "\n", "", "if", "obj", "[", "'generated_names'", "]", ":", "\n", "                ", "precisions", ".", "append", "(", "compute_precision", "(", "obj", ")", ")", "\n", "\n", "", "c", ",", "t", "=", "compute_full_recall", "(", "obj", ")", "\n", "full_recall", "+=", "c", "\n", "full_recall_total", "+=", "t", "\n", "\n", "c", ",", "t", "=", "compute_full_precision", "(", "obj", ")", "\n", "full_precision", "+=", "c", "\n", "full_precision_total", "+=", "t", "\n", "\n", "c", ",", "t", "=", "compute_rare_recall", "(", "obj", ",", "counters", "[", "'caption'", "]", ")", "\n", "rare_recall", "+=", "c", "\n", "rare_recall_total", "+=", "t", "\n", "\n", "c", ",", "t", "=", "compute_rare_precision", "(", "obj", ",", "counters", "[", "'caption'", "]", ")", "\n", "rare_precision", "+=", "c", "\n", "rare_precision_total", "+=", "t", "\n", "\n", "c", ",", "t", "=", "compute_rare_recall", "(", "obj", ",", "full_counter", ")", "\n", "full_rare_recall", "+=", "c", "\n", "full_rare_recall_total", "+=", "t", "\n", "\n", "c", ",", "t", "=", "compute_rare_precision", "(", "obj", ",", "full_counter", ")", "\n", "full_rare_precision", "+=", "c", "\n", "full_rare_precision_total", "+=", "t", "\n", "\n", "# Remove punctuation", "\n", "caption", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "caption", ")", "\n", "generation", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "generation", ")", "\n", "\n", "lengths", ".", "append", "(", "len", "(", "generation", ".", "split", "(", ")", ")", ")", "\n", "gt_lengths", ".", "append", "(", "len", "(", "caption", ".", "split", "(", ")", ")", ")", "\n", "\n", "n_uniques", ".", "append", "(", "len", "(", "set", "(", "generation", ".", "split", "(", ")", ")", ")", ")", "\n", "gt_n_uniques", ".", "append", "(", "len", "(", "set", "(", "caption", ".", "split", "(", ")", ")", ")", ")", "\n", "\n", "bleu_scorer", "+=", "(", "generation", ",", "[", "caption", "]", ")", "\n", "rouge_score", "=", "rouge_scorer", ".", "calc_score", "(", "[", "generation", "]", ",", "[", "caption", "]", ")", "\n", "rouge_scores", ".", "append", "(", "rouge_score", ")", "\n", "cider_scorer", "+=", "(", "generation", ",", "[", "caption", "]", ")", "\n", "\n", "stat", "=", "meteor_scorer", ".", "_stat", "(", "generation", ",", "[", "caption", "]", ")", "\n", "eval_line", "+=", "' ||| {}'", ".", "format", "(", "stat", ")", "\n", "count", "+=", "1", "\n", "\n", "gen_ttrs", ".", "append", "(", "obj", "[", "'gen_np'", "]", "[", "'basic_ttr'", "]", ")", "\n", "cap_ttrs", ".", "append", "(", "obj", "[", "'caption_np'", "]", "[", "'basic_ttr'", "]", ")", "\n", "gen_flesch", ".", "append", "(", "obj", "[", "'gen_readability'", "]", "[", "'flesch_reading_ease'", "]", ")", "\n", "cap_flesch", ".", "append", "(", "obj", "[", "'caption_readability'", "]", "\n", "[", "'flesch_reading_ease'", "]", ")", "\n", "\n", "compute_entities", "(", "obj", ",", "ent_counter", ")", "\n", "\n", "", "", "meteor_scorer", ".", "meteor_p", ".", "stdin", ".", "write", "(", "'{}\\n'", ".", "format", "(", "eval_line", ")", ".", "encode", "(", ")", ")", "\n", "meteor_scorer", ".", "meteor_p", ".", "stdin", ".", "flush", "(", ")", "\n", "for", "_", "in", "range", "(", "count", ")", ":", "\n", "        ", "meteor_scores", ".", "append", "(", "float", "(", "\n", "meteor_scorer", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", ")", "\n", "", "meteor_score", "=", "float", "(", "meteor_scorer", ".", "meteor_p", ".", "stdout", ".", "readline", "(", ")", ".", "strip", "(", ")", ")", "\n", "meteor_scorer", ".", "lock", ".", "release", "(", ")", "\n", "\n", "blue_score", ",", "_", "=", "bleu_scorer", ".", "compute_score", "(", "option", "=", "'closest'", ")", "\n", "rouge_score", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "rouge_scores", ")", ")", "\n", "cider_score", ",", "_", "=", "cider_scorer", ".", "compute_score", "(", ")", "\n", "\n", "final_metrics", "=", "{", "\n", "'BLEU-1'", ":", "blue_score", "[", "0", "]", ",", "\n", "'BLEU-2'", ":", "blue_score", "[", "1", "]", ",", "\n", "'BLEU-3'", ":", "blue_score", "[", "2", "]", ",", "\n", "'BLEU-4'", ":", "blue_score", "[", "3", "]", ",", "\n", "'ROUGE'", ":", "rouge_score", ",", "\n", "'METEOR'", ":", "meteor_score", ",", "\n", "'CIDEr'", ":", "cider_score", ",", "\n", "'All names - recall'", ":", "{", "\n", "'count'", ":", "full_recall", ",", "\n", "'total'", ":", "full_recall_total", ",", "\n", "'percentage'", ":", "(", "full_recall", "/", "full_recall_total", ")", "if", "full_recall_total", "else", "None", ",", "\n", "}", ",", "\n", "'All names - precision'", ":", "{", "\n", "'count'", ":", "full_precision", ",", "\n", "'total'", ":", "full_precision_total", ",", "\n", "'percentage'", ":", "(", "full_precision", "/", "full_precision_total", ")", "if", "full_precision_total", "else", "None", ",", "\n", "}", ",", "\n", "'Caption rare names - recall'", ":", "{", "\n", "'count'", ":", "rare_recall", ",", "\n", "'total'", ":", "rare_recall_total", ",", "\n", "'percentage'", ":", "(", "rare_recall", "/", "rare_recall_total", ")", "if", "rare_recall_total", "else", "None", ",", "\n", "}", ",", "\n", "'Caption rare names - precision'", ":", "{", "\n", "'count'", ":", "rare_precision", ",", "\n", "'total'", ":", "rare_precision_total", ",", "\n", "'percentage'", ":", "(", "rare_precision", "/", "rare_precision_total", ")", "if", "rare_precision_total", "else", "None", ",", "\n", "}", ",", "\n", "'Article rare names - recall'", ":", "{", "\n", "'count'", ":", "full_rare_recall", ",", "\n", "'total'", ":", "full_rare_recall_total", ",", "\n", "'percentage'", ":", "(", "full_rare_recall", "/", "full_rare_recall_total", ")", "if", "full_rare_recall_total", "else", "None", ",", "\n", "}", ",", "\n", "'Article rare names - precision'", ":", "{", "\n", "'count'", ":", "full_rare_precision", ",", "\n", "'total'", ":", "full_rare_precision_total", ",", "\n", "'percentage'", ":", "(", "full_rare_precision", "/", "full_rare_precision_total", ")", "if", "full_rare_precision_total", "else", "None", ",", "\n", "}", ",", "\n", "'Length - generation'", ":", "sum", "(", "lengths", ")", "/", "len", "(", "lengths", ")", ",", "\n", "'Length - reference'", ":", "sum", "(", "gt_lengths", ")", "/", "len", "(", "gt_lengths", ")", ",", "\n", "'Unique words - generation'", ":", "sum", "(", "n_uniques", ")", "/", "len", "(", "n_uniques", ")", ",", "\n", "'Unique words - reference'", ":", "sum", "(", "gt_n_uniques", ")", "/", "len", "(", "gt_n_uniques", ")", ",", "\n", "'Caption TTR'", ":", "sum", "(", "cap_ttrs", ")", "/", "len", "(", "cap_ttrs", ")", ",", "\n", "'Generation TTR'", ":", "sum", "(", "gen_ttrs", ")", "/", "len", "(", "gen_ttrs", ")", ",", "\n", "'Caption Flesch Reading Ease'", ":", "sum", "(", "cap_flesch", ")", "/", "len", "(", "cap_flesch", ")", ",", "\n", "'Generation Flesch Reading Ease'", ":", "sum", "(", "gen_flesch", ")", "/", "len", "(", "gen_flesch", ")", ",", "\n", "'Entity all - recall'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_caption_ent_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_caption_ents'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_caption_ent_matches'", "]", "/", "ent_counter", "[", "'n_caption_ents'", "]", ",", "\n", "}", ",", "\n", "'Entity all - precision'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_gen_ent_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_gen_ents'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_gen_ent_matches'", "]", "/", "ent_counter", "[", "'n_gen_ents'", "]", ",", "\n", "}", ",", "\n", "'Entity person - recall'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_caption_person_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_caption_persons'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_caption_person_matches'", "]", "/", "ent_counter", "[", "'n_caption_persons'", "]", ",", "\n", "}", ",", "\n", "'Entity person - precision'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_gen_person_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_gen_persons'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_gen_person_matches'", "]", "/", "ent_counter", "[", "'n_gen_persons'", "]", ",", "\n", "}", ",", "\n", "'Entity GPE - recall'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_caption_gpes_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_caption_gpes'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_caption_gpes_matches'", "]", "/", "ent_counter", "[", "'n_caption_gpes'", "]", ",", "\n", "}", ",", "\n", "'Entity GPE - precision'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_gen_gpes_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_gen_gpes'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_gen_gpes_matches'", "]", "/", "ent_counter", "[", "'n_gen_gpes'", "]", ",", "\n", "}", ",", "\n", "'Entity ORG - recall'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_caption_orgs_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_caption_orgs'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_caption_orgs_matches'", "]", "/", "ent_counter", "[", "'n_caption_orgs'", "]", ",", "\n", "}", ",", "\n", "'Entity ORG - precision'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_gen_orgs_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_gen_orgs'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_gen_orgs_matches'", "]", "/", "ent_counter", "[", "'n_gen_orgs'", "]", ",", "\n", "}", ",", "\n", "'Entity DATE - recall'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_caption_date_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_caption_date'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_caption_date_matches'", "]", "/", "ent_counter", "[", "'n_caption_date'", "]", ",", "\n", "}", ",", "\n", "'Entity DATE - precision'", ":", "{", "\n", "'count'", ":", "ent_counter", "[", "'n_gen_date_matches'", "]", ",", "\n", "'total'", ":", "ent_counter", "[", "'n_gen_date'", "]", ",", "\n", "'percentage'", ":", "ent_counter", "[", "'n_gen_date_matches'", "]", "/", "ent_counter", "[", "'n_gen_date'", "]", ",", "\n", "}", ",", "\n", "}", "\n", "\n", "serialization_dir", "=", "os", ".", "path", ".", "dirname", "(", "args", "[", "'file'", "]", ")", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "args", "[", "'file'", "]", ")", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "args", "[", "'use_processed'", "]", ":", "\n", "        ", "filename", "+=", "'_processed'", "\n", "\n", "", "output_file", "=", "os", ".", "path", ".", "join", "(", "\n", "serialization_dir", ",", "f'{filename}_reported_metrics.json'", ")", "\n", "with", "open", "(", "output_file", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "json", ".", "dump", "(", "final_metrics", ",", "file", ",", "indent", "=", "4", ")", "\n", "\n", "", "for", "key", ",", "metric", "in", "final_metrics", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f\"{key}: {metric}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_entities": [[291, 350], ["len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity", "compute_metrics.contain_entity"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity"], ["", "", "def", "compute_entities", "(", "obj", ",", "c", ")", ":", "\n", "    ", "caption_entities", "=", "obj", "[", "'caption_entities'", "]", "\n", "gen_entities", "=", "obj", "[", "'generated_entities'", "]", "\n", "# context_entities = obj['context_entities']", "\n", "\n", "c", "[", "'n_caption_ents'", "]", "+=", "len", "(", "caption_entities", ")", "\n", "c", "[", "'n_gen_ents'", "]", "+=", "len", "(", "gen_entities", ")", "\n", "for", "ent", "in", "gen_entities", ":", "\n", "        ", "if", "contain_entity", "(", "caption_entities", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_gen_ent_matches'", "]", "+=", "1", "\n", "", "", "for", "ent", "in", "caption_entities", ":", "\n", "        ", "if", "contain_entity", "(", "gen_entities", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_caption_ent_matches'", "]", "+=", "1", "\n", "\n", "", "", "caption_persons", "=", "[", "e", "for", "e", "in", "caption_entities", "if", "e", "[", "'label'", "]", "==", "'PERSON'", "]", "\n", "gen_persons", "=", "[", "e", "for", "e", "in", "gen_entities", "if", "e", "[", "'label'", "]", "==", "'PERSON'", "]", "\n", "c", "[", "'n_caption_persons'", "]", "+=", "len", "(", "caption_persons", ")", "\n", "c", "[", "'n_gen_persons'", "]", "+=", "len", "(", "gen_persons", ")", "\n", "for", "ent", "in", "gen_persons", ":", "\n", "        ", "if", "contain_entity", "(", "caption_persons", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_gen_person_matches'", "]", "+=", "1", "\n", "", "", "for", "ent", "in", "caption_persons", ":", "\n", "        ", "if", "contain_entity", "(", "gen_persons", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_caption_person_matches'", "]", "+=", "1", "\n", "\n", "", "", "caption_orgs", "=", "[", "e", "for", "e", "in", "caption_entities", "if", "e", "[", "'label'", "]", "==", "'ORG'", "]", "\n", "gen_orgs", "=", "[", "e", "for", "e", "in", "gen_entities", "if", "e", "[", "'label'", "]", "==", "'ORG'", "]", "\n", "c", "[", "'n_caption_orgs'", "]", "+=", "len", "(", "caption_orgs", ")", "\n", "c", "[", "'n_gen_orgs'", "]", "+=", "len", "(", "gen_orgs", ")", "\n", "for", "ent", "in", "gen_orgs", ":", "\n", "        ", "if", "contain_entity", "(", "caption_orgs", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_gen_orgs_matches'", "]", "+=", "1", "\n", "", "", "for", "ent", "in", "caption_orgs", ":", "\n", "        ", "if", "contain_entity", "(", "gen_orgs", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_caption_orgs_matches'", "]", "+=", "1", "\n", "\n", "", "", "caption_gpes", "=", "[", "e", "for", "e", "in", "caption_entities", "if", "e", "[", "'label'", "]", "==", "'GPE'", "]", "\n", "gen_gpes", "=", "[", "e", "for", "e", "in", "gen_entities", "if", "e", "[", "'label'", "]", "==", "'GPE'", "]", "\n", "c", "[", "'n_caption_gpes'", "]", "+=", "len", "(", "caption_gpes", ")", "\n", "c", "[", "'n_gen_gpes'", "]", "+=", "len", "(", "gen_gpes", ")", "\n", "for", "ent", "in", "gen_gpes", ":", "\n", "        ", "if", "contain_entity", "(", "caption_gpes", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_gen_gpes_matches'", "]", "+=", "1", "\n", "", "", "for", "ent", "in", "caption_gpes", ":", "\n", "        ", "if", "contain_entity", "(", "gen_gpes", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_caption_gpes_matches'", "]", "+=", "1", "\n", "\n", "", "", "caption_date", "=", "[", "e", "for", "e", "in", "caption_entities", "if", "e", "[", "'label'", "]", "==", "'DATE'", "]", "\n", "gen_date", "=", "[", "e", "for", "e", "in", "gen_entities", "if", "e", "[", "'label'", "]", "==", "'DATE'", "]", "\n", "c", "[", "'n_caption_date'", "]", "+=", "len", "(", "caption_date", ")", "\n", "c", "[", "'n_gen_date'", "]", "+=", "len", "(", "gen_date", ")", "\n", "for", "ent", "in", "gen_date", ":", "\n", "        ", "if", "contain_entity", "(", "caption_date", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_gen_date_matches'", "]", "+=", "1", "\n", "", "", "for", "ent", "in", "caption_date", ":", "\n", "        ", "if", "contain_entity", "(", "gen_date", ",", "ent", ")", ":", "\n", "            ", "c", "[", "'n_caption_date_matches'", "]", "+=", "1", "\n", "\n", "", "", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.contain_entity": [[352, 357], ["None"], "function", ["None"], ["", "def", "contain_entity", "(", "entities", ",", "target", ")", ":", "\n", "    ", "for", "ent", "in", "entities", ":", "\n", "        ", "if", "ent", "[", "'text'", "]", "==", "target", "[", "'text'", "]", "and", "ent", "[", "'label'", "]", "==", "target", "[", "'label'", "]", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_recall": [[359, 366], ["len"], "function", ["None"], ["", "def", "compute_recall", "(", "obj", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "name", "in", "obj", "[", "'caption_names'", "]", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'generated_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", "/", "len", "(", "obj", "[", "'caption_names'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_precision": [[368, 375], ["len"], "function", ["None"], ["", "def", "compute_precision", "(", "obj", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "name", "in", "obj", "[", "'generated_names'", "]", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'caption_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", "/", "len", "(", "obj", "[", "'generated_names'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_full_recall": [[377, 384], ["len"], "function", ["None"], ["", "def", "compute_full_recall", "(", "obj", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "name", "in", "obj", "[", "'caption_names'", "]", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'generated_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", ",", "len", "(", "obj", "[", "'caption_names'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_full_precision": [[386, 393], ["len"], "function", ["None"], ["", "def", "compute_full_precision", "(", "obj", ")", ":", "\n", "    ", "count", "=", "0", "\n", "for", "name", "in", "obj", "[", "'generated_names'", "]", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'caption_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", ",", "len", "(", "obj", "[", "'generated_names'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_recall": [[395, 403], ["len"], "function", ["None"], ["", "def", "compute_rare_recall", "(", "obj", ",", "counter", ")", ":", "\n", "    ", "count", "=", "0", "\n", "rare_names", "=", "[", "n", "for", "n", "in", "obj", "[", "'caption_names'", "]", "if", "n", "not", "in", "counter", "]", "\n", "for", "name", "in", "rare_names", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'generated_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", ",", "len", "(", "rare_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.compute_metrics.compute_rare_precision": [[405, 413], ["len"], "function", ["None"], ["", "def", "compute_rare_precision", "(", "obj", ",", "counter", ")", ":", "\n", "    ", "count", "=", "0", "\n", "rare_names", "=", "[", "n", "for", "n", "in", "obj", "[", "'generated_names'", "]", "if", "n", "not", "in", "counter", "]", "\n", "for", "name", "in", "rare_names", ":", "\n", "        ", "if", "name", "in", "obj", "[", "'caption_names'", "]", ":", "\n", "            ", "count", "+=", "1", "\n", "\n", "", "", "return", "count", ",", "len", "(", "rare_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.validate": [[29, 40], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "schema.Use", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'host'", ":", "str", ",", "\n", "'batch'", ":", "Use", "(", "int", ")", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.get_parts_of_speech": [[42, 61], ["parts_of_speech.append", "annotate_nytimes.assign_pos_to_section", "annotate_nytimes.assign_pos_to_section", "len"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.assign_pos_to_section", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.assign_pos_to_section"], ["", "def", "get_parts_of_speech", "(", "doc", ",", "article", ")", ":", "\n", "    ", "parts_of_speech", "=", "[", "]", "\n", "for", "tok", "in", "doc", ":", "\n", "        ", "pos", "=", "{", "\n", "'start'", ":", "tok", ".", "idx", ",", "\n", "'end'", ":", "tok", ".", "idx", "+", "len", "(", "tok", ".", "text", ")", ",", "# exclude right endpoint", "\n", "'text'", ":", "tok", ".", "text", ",", "\n", "'pos'", ":", "tok", ".", "pos_", ",", "\n", "}", "\n", "parts_of_speech", ".", "append", "(", "pos", ")", "\n", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "            ", "section", "=", "article", "[", "'headline'", "]", "\n", "assign_pos_to_section", "(", "section", ",", "pos", ")", "\n", "\n", "", "for", "section", "in", "article", "[", "'parsed_section'", "]", ":", "\n", "            ", "assign_pos_to_section", "(", "section", ",", "pos", ")", "\n", "\n", "", "", "article", "[", "'parts_of_speech'", "]", "=", "parts_of_speech", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.assign_pos_to_section": [[63, 72], ["section[].append"], "function", ["None"], ["", "def", "assign_pos_to_section", "(", "section", ",", "pos", ")", ":", "\n", "    ", "s", "=", "section", "[", "'spacy_start'", "]", "\n", "e", "=", "section", "[", "'spacy_end'", "]", "\n", "if", "pos", "[", "'start'", "]", ">=", "s", "and", "pos", "[", "'end'", "]", "<=", "e", ":", "\n", "        ", "section", "[", "'parts_of_speech'", "]", ".", "append", "(", "{", "\n", "'start'", ":", "pos", "[", "'start'", "]", "-", "s", ",", "\n", "'end'", ":", "pos", "[", "'end'", "]", "-", "s", ",", "\n", "'text'", ":", "pos", "[", "'text'", "]", ",", "\n", "'pos'", ":", "pos", "[", "'pos'", "]", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.calculate_spacy_positions": [[75, 91], ["[].strip", "section[].strip", "len", "len"], "function", ["None"], ["", "", "def", "calculate_spacy_positions", "(", "article", ")", ":", "\n", "    ", "title", "=", "''", "\n", "cursor", "=", "0", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "        ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "article", "[", "'headline'", "]", "[", "'spacy_start'", "]", "=", "cursor", "\n", "cursor", "+=", "len", "(", "title", ")", "+", "1", "# newline", "\n", "article", "[", "'headline'", "]", "[", "'spacy_end'", "]", "=", "cursor", "\n", "article", "[", "'headline'", "]", "[", "'parts_of_speech'", "]", "=", "[", "]", "\n", "\n", "", "for", "section", "in", "article", "[", "'parsed_section'", "]", ":", "\n", "        ", "text", "=", "section", "[", "'text'", "]", ".", "strip", "(", ")", "\n", "section", "[", "'spacy_start'", "]", "=", "cursor", "\n", "cursor", "+=", "len", "(", "text", ")", "+", "1", "# newline", "\n", "section", "[", "'spacy_end'", "]", "=", "cursor", "\n", "section", "[", "'parts_of_speech'", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.annotate_pos": [[93, 115], ["annotate_nytimes.calculate_spacy_positions", "nlp", "annotate_nytimes.get_parts_of_speech", "db.articles.find_one_and_update", "[].strip", "s[].strip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.calculate_spacy_positions", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.get_parts_of_speech"], ["", "", "def", "annotate_pos", "(", "article", ",", "nlp", ",", "db", ")", ":", "\n", "    ", "if", "'parts_of_speech'", "in", "article", "[", "'parsed_section'", "]", "[", "0", "]", ":", "\n", "        ", "return", "\n", "\n", "", "calculate_spacy_positions", "(", "article", ")", "\n", "\n", "title", "=", "''", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", ":", "\n", "        ", "title", "=", "article", "[", "'headline'", "]", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "\n", "", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "\n", "paragraphs", "=", "[", "s", "[", "'text'", "]", ".", "strip", "(", ")", "for", "s", "in", "sections", "]", "\n", "paragraphs", "=", "[", "title", "]", "+", "paragraphs", "\n", "\n", "combined", "=", "'\\n'", ".", "join", "(", "paragraphs", ")", "\n", "\n", "doc", "=", "nlp", "(", "combined", ")", "\n", "get_parts_of_speech", "(", "doc", ",", "article", ")", "\n", "\n", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.parse_article": [[117, 155], ["annotate_nytimes.annotate_pos", "section[].strip", "nlp", "db.articles.find_one_and_update", "section[].append", "nlp", "section[].strip", "section[].append"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.annotate_pos"], ["", "def", "parse_article", "(", "article", ",", "nlp", ",", "db", ")", ":", "\n", "    ", "annotate_pos", "(", "article", ",", "nlp", ",", "db", ")", "\n", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "changed", "=", "False", "\n", "\n", "if", "'main'", "in", "article", "[", "'headline'", "]", "and", "'named_entities'", "not", "in", "article", "[", "'headline'", "]", ":", "\n", "        ", "section", "=", "article", "[", "'headline'", "]", "\n", "title", "=", "section", "[", "'main'", "]", ".", "strip", "(", ")", "\n", "doc", "=", "nlp", "(", "title", ")", "\n", "section", "[", "'named_entities'", "]", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "            ", "changed", "=", "True", "\n", "ent_info", "=", "{", "\n", "'start'", ":", "ent", ".", "start_char", ",", "\n", "'end'", ":", "ent", ".", "end_char", ",", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "}", "\n", "section", "[", "'named_entities'", "]", ".", "append", "(", "ent_info", ")", "\n", "\n", "", "", "for", "section", "in", "sections", ":", "\n", "        ", "if", "'named_entities'", "not", "in", "section", ":", "\n", "            ", "doc", "=", "nlp", "(", "section", "[", "'text'", "]", ".", "strip", "(", ")", ")", "\n", "section", "[", "'named_entities'", "]", "=", "[", "]", "\n", "for", "ent", "in", "doc", ".", "ents", ":", "\n", "                ", "changed", "=", "True", "\n", "ent_info", "=", "{", "\n", "'start'", ":", "ent", ".", "start_char", ",", "\n", "'end'", ":", "ent", ".", "end_char", ",", "\n", "'text'", ":", "ent", ".", "text", ",", "\n", "'label'", ":", "ent", ".", "label_", ",", "\n", "}", "\n", "section", "[", "'named_entities'", "]", ".", "append", "(", "ent_info", ")", "\n", "\n", "", "", "", "if", "changed", ":", "\n", "        ", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.annotate_with_host": [[157, 169], ["spacy.load", "pymongo.MongoClient", "db.articles.find().batch_size", "tqdm.tqdm", "annotate_nytimes.parse_article", "db.articles.find"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.parse_article"], ["", "", "def", "annotate_with_host", "(", "host", ",", "period", ")", ":", "\n", "    ", "start", ",", "end", "=", "period", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_lg\"", ")", "\n", "client", "=", "MongoClient", "(", "host", "=", "host", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "nytimes", "\n", "\n", "article_cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "\n", "'pub_date'", ":", "{", "'$gte'", ":", "start", ",", "'$lt'", ":", "end", "}", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "parse_article", "(", "article", ",", "nlp", ",", "db", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_nytimes.main": [[171, 197], ["docopt.docopt", "annotate_nytimes.validate", "functools.partial", "multiprocessing.Pool", "multiprocessing.Pool.map", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime", "datetime.datetime"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "periods", "=", "[", "(", "datetime", "(", "2000", ",", "1", ",", "1", ")", ",", "datetime", "(", "2007", ",", "8", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2007", ",", "8", ",", "1", ")", ",", "datetime", "(", "2009", ",", "1", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2009", ",", "1", ",", "1", ")", ",", "datetime", "(", "2010", ",", "5", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2010", ",", "5", ",", "1", ")", ",", "datetime", "(", "2011", ",", "7", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2011", ",", "7", ",", "1", ")", ",", "datetime", "(", "2012", ",", "11", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2012", ",", "11", ",", "1", ")", ",", "datetime", "(", "2014", ",", "2", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2014", ",", "2", ",", "1", ")", ",", "datetime", "(", "2015", ",", "5", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2015", ",", "5", ",", "1", ")", ",", "datetime", "(", "2016", ",", "5", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2016", ",", "5", ",", "1", ")", ",", "datetime", "(", "2017", ",", "5", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2017", ",", "5", ",", "1", ")", ",", "datetime", "(", "2018", ",", "8", ",", "1", ")", ")", ",", "\n", "(", "datetime", "(", "2018", ",", "8", ",", "1", ")", ",", "datetime", "(", "2019", ",", "9", ",", "1", ")", ")", ",", "\n", "]", "\n", "\n", "annotate", "=", "functools", ".", "partial", "(", "annotate_with_host", ",", "args", "[", "'host'", "]", ")", "\n", "\n", "pool", "=", "Pool", "(", "processes", "=", "11", ")", "\n", "pool", ".", "map", "(", "annotate", ",", "periods", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.process_images.process_images": [[27, 43], ["glob.glob", "tqdm.tqdm", "os.path.basename", "os.path.join", "os.path.exists", "PIL.Image.open", "F.center_crop.convert", "torchvision.resize", "torchvision.center_crop", "F.center_crop.save"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.yolov3.models.convert"], ["def", "process_images", "(", "in_dir", ",", "out_dir", ")", ":", "\n", "    ", "image_paths", "=", "glob", "(", "f'{in_dir}/*.jpg'", ")", "\n", "for", "path", "in", "tqdm", "(", "image_paths", ")", ":", "\n", "        ", "image_name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "image_name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "try", ":", "\n", "            ", "with", "Image", ".", "open", "(", "path", ")", "as", "image", ":", "\n", "                ", "image", "=", "image", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "F", ".", "resize", "(", "image", ",", "256", ",", "Image", ".", "ANTIALIAS", ")", "\n", "image", "=", "F", ".", "center_crop", "(", "image", ",", "(", "224", ",", "224", ")", ")", "\n", "image", ".", "save", "(", "out_path", ",", "image", ".", "format", ")", "\n", "", "", "except", "OSError", ":", "\n", "            ", "continue", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.process_images.validate": [[45, 56], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "", "", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'in_dir'", ":", "os", ".", "path", ".", "exists", ",", "\n", "'out_dir'", ":", "str", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.process_images.main": [[58, 70], ["docopt.docopt", "process_images.validate", "os.makedirs", "process_images.process_images", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.process_images.process_images"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "args", "[", "'out_dir'", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "process_images", "(", "args", "[", "'in_dir'", "]", ",", "args", "[", "'out_dir'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_urls.validate": [[27, 37], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "object", ":", "object", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_urls.month_year_iter": [[39, 46], ["range", "divmod"], "function", ["None"], ["", "def", "month_year_iter", "(", "end_month", ",", "end_year", ",", "start_month", ",", "start_year", ")", ":", "\n", "# The first month is excluded", "\n", "    ", "ym_start", "=", "12", "*", "start_year", "+", "start_month", "-", "1", "\n", "ym_end", "=", "12", "*", "end_year", "+", "end_month", "-", "1", "\n", "for", "ym", "in", "range", "(", "ym_end", ",", "ym_start", ",", "-", "1", ")", ":", "\n", "        ", "y", ",", "m", "=", "divmod", "(", "ym", ",", "12", ")", "\n", "yield", "y", ",", "m", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_urls.main": [[48, 89], ["docopt.docopt", "get_urls.validate", "os.makedirs", "tqdm.tqdm", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "get_urls.month_year_iter", "os.path.exists", "time.time", "urllib.request.urlopen.read", "json.loads", "time.sleep", "open", "json.dump", "time.time", "max", "urllib.request.urlopen", "time.sleep"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.month_year_iter"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "api_key", "=", "args", "[", "'api_key'", "]", "\n", "url", "=", "'http://api.nytimes.com/svc/archive/v1/%s/%s.json?api-key=%s'", "\n", "\n", "data_dir", "=", "'data/nytimes/archive'", "\n", "os", ".", "makedirs", "(", "data_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "for", "year", ",", "month", "in", "tqdm", "(", "month_year_iter", "(", "8", ",", "2019", ",", "12", ",", "1979", ")", ")", ":", "\n", "        ", "out_path", "=", "f'{data_dir}/{year}_{month:02}.json'", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "request_string", "=", "url", "%", "(", "year", ",", "month", ",", "api_key", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "response", "=", "urlopen", "(", "request_string", ")", "\n", "", "except", "HTTPError", ":", "\n", "                ", "time", ".", "sleep", "(", "10", ")", "\n", "continue", "\n", "", "break", "\n", "\n", "", "raw_content", "=", "response", ".", "read", "(", ")", "\n", "content", "=", "json", ".", "loads", "(", "raw_content", ")", "\n", "with", "open", "(", "out_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "content", ",", "f", ")", "\n", "\n", "# Note that there's a limit of 4,000 requests per day and 10", "\n", "# requests per minute. We should sleep 6 seconds between calls to", "\n", "# avoid hitting the per minute rate limit.", "\n", "", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "time", ".", "sleep", "(", "max", "(", "0", ",", "6", "-", "elapsed", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.validate": [[24, 34], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'host'", ":", "str", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_name_stats": [[36, 80], ["pymongo.MongoClient", "db.articles.find().batch_size", "tqdm.tqdm", "print", "print", "print", "set", "set", "set", "len", "len", "len", "open", "pickle.dump", "db.articles.find", "sorted", "get_unknown_caption_names.get_proper_names", "set.add", "get_unknown_caption_names.get_proper_names"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names"], ["", "def", "get_name_stats", "(", "host", ")", ":", "\n", "    ", "client", "=", "MongoClient", "(", "host", "=", "host", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "nytimes", "\n", "\n", "projection", "=", "[", "'_id'", ",", "'parsed_section.type'", ",", "'parsed_section.text'", ",", "\n", "'parsed_section.hash'", ",", "'parsed_section.parts_of_speech'", ",", "\n", "'parsed_section.named_entities'", ",", "\n", "'image_positions'", ",", "'headline'", ",", "\n", "'web_url'", ",", "'n_images_with_faces'", "]", "\n", "\n", "article_cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "\n", "'split'", ":", "'train'", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ",", "projection", "=", "projection", ")", ".", "batch_size", "(", "128", ")", "\n", "\n", "results", "=", "{", "}", "\n", "count", ",", "total", "=", "0", ",", "0", "\n", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "article_names", "=", "set", "(", ")", "\n", "caption_names", "=", "set", "(", ")", "\n", "\n", "sections", "=", "article", "[", "'parsed_section'", "]", "\n", "for", "section", "in", "sections", ":", "\n", "            ", "if", "section", "[", "'type'", "]", "==", "'paragraph'", ":", "\n", "                ", "article_names", "|=", "get_proper_names", "(", "section", ")", "\n", "", "elif", "section", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                ", "caption_names", "|=", "get_proper_names", "(", "section", ")", "\n", "\n", "", "", "unknown_names", "=", "set", "(", ")", "\n", "for", "name", "in", "caption_names", ":", "\n", "            ", "if", "name", "not", "in", "article_names", ":", "\n", "                ", "unknown_names", ".", "add", "(", "name", ")", "\n", "\n", "", "", "if", "unknown_names", ":", "\n", "            ", "results", "[", "article", "[", "'_id'", "]", "]", "=", "sorted", "(", "unknown_names", ")", "\n", "", "count", "+=", "len", "(", "unknown_names", ")", "\n", "total", "+=", "len", "(", "caption_names", ")", "\n", "\n", "", "print", "(", "'Count:'", ",", "count", ")", "\n", "print", "(", "'Total:'", ",", "total", ")", "\n", "print", "(", "'No articles with unknown names:'", ",", "len", "(", "results", ")", ")", "\n", "\n", "with", "open", "(", "'./data/nytimes/unknown_caption_names.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "results", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_proper_names": [[82, 92], ["set", "set.add"], "function", ["None"], ["", "", "def", "get_proper_names", "(", "section", ")", ":", "\n", "# These name indices have the right end point excluded", "\n", "    ", "names", "=", "set", "(", ")", "\n", "\n", "parts_of_speech", "=", "section", "[", "'parts_of_speech'", "]", "\n", "for", "pos", "in", "parts_of_speech", ":", "\n", "        ", "if", "pos", "[", "'pos'", "]", "==", "'PROPN'", ":", "\n", "            ", "names", ".", "add", "(", "pos", "[", "'text'", "]", ")", "\n", "\n", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.main": [[94, 104], ["docopt.docopt", "get_unknown_caption_names.validate", "get_unknown_caption_names.get_name_stats", "ptvsd.enable_attach", "ptvsd.wait_for_attach"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_unknown_caption_names.get_name_stats"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "get_name_stats", "(", "args", "[", "'host'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url": [[38, 54], ["urllib.parse.urlparse", "posixpath.normpath", "urllib.parse.urlparse.path.endswith", "urllib.parse.urlparse._replace", "parsed._replace.geturl"], "function", ["None"], ["def", "resolve_url", "(", "url", ")", ":", "\n", "    ", "\"\"\"\n    resolve_url('http://www.example.com/foo/bar/../../baz/bux/')\n    'http://www.example.com/baz/bux/'\n    resolve_url('http://www.example.com/some/path/../file.ext')\n    'http://www.example.com/some/file.ext'\n    \"\"\"", "\n", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "new_path", "=", "normpath", "(", "parsed", ".", "path", ")", "\n", "if", "parsed", ".", "path", ".", "endswith", "(", "'/'", ")", ":", "\n", "# Compensate for issue1707768", "\n", "        ", "new_path", "+=", "'/'", "\n", "", "cleaned", "=", "parsed", ".", "_replace", "(", "path", "=", "new_path", ")", "\n", "\n", "return", "cleaned", ".", "geturl", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags": [[56, 62], ["any", "filter", "get_articles_nytimes.get_tags", "d.attrs.get", "params.get().items", "isinstance", "params.get"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags"], ["", "def", "get_tags", "(", "d", ",", "params", ")", ":", "\n", "# See https://stackoverflow.com/a/57683816/3790116", "\n", "    ", "if", "any", "(", "(", "lambda", "x", ":", "b", "in", "x", "if", "a", "==", "'class'", "else", "b", "==", "x", ")", "(", "d", ".", "attrs", ".", "get", "(", "a", ",", "[", "]", ")", ")", "for", "a", ",", "b", "in", "params", ".", "get", "(", "d", ".", "name", ",", "{", "}", ")", ".", "items", "(", ")", ")", ":", "\n", "        ", "yield", "d", "\n", "", "for", "i", "in", "filter", "(", "lambda", "x", ":", "x", "!=", "'\\n'", "and", "not", "isinstance", "(", "x", ",", "bs4", ".", "element", ".", "NavigableString", ")", ",", "d", ".", "contents", ")", ":", "\n", "        ", "yield", "from", "get_tags", "(", "i", ",", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_new": [[64, 107], ["soup.find", "get_articles_nytimes.get_tags", "part.find_all", "get_articles_nytimes.resolve_url", "sections.append", "sections.append", "part.parent.attrs.get", "part.find", "part.attrs.get", "part.find.text.strip", "hashlib.sha256().hexdigest", "p.text.strip", "part.find", "hashlib.sha256", "resolve_url.encode"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "", "def", "extract_text_new", "(", "soup", ")", ":", "\n", "# For articles between 2013 and 2019", "\n", "    ", "sections", "=", "[", "]", "\n", "article_node", "=", "soup", ".", "find", "(", "'article'", ")", "\n", "\n", "params", "=", "{", "\n", "'div'", ":", "{", "'class'", ":", "'StoryBodyCompanionColumn'", "}", ",", "\n", "'figcaption'", ":", "{", "'itemprop'", ":", "'caption description'", "}", ",", "\n", "'figure'", ":", "{", "'class'", ":", "'e1g7ppur0'", "}", ",", "\n", "}", "\n", "\n", "article_parts", "=", "get_tags", "(", "article_node", ",", "params", ")", "\n", "i", "=", "0", "\n", "\n", "for", "part", "in", "article_parts", ":", "\n", "        ", "has_caption", "=", "False", "\n", "if", "part", ".", "name", "==", "'div'", ":", "\n", "            ", "paragraphs", "=", "part", ".", "find_all", "(", "[", "'p'", ",", "'h2'", "]", ")", "\n", "for", "p", "in", "paragraphs", ":", "\n", "                ", "sections", ".", "append", "(", "{", "'type'", ":", "'paragraph'", ",", "'text'", ":", "p", ".", "text", ".", "strip", "(", ")", "}", ")", "\n", "", "", "elif", "part", ".", "name", "==", "'figcaption'", ":", "\n", "            ", "if", "part", ".", "parent", ".", "attrs", ".", "get", "(", "'itemid'", ",", "0", ")", ":", "\n", "                ", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'e13ogyst0'", "}", ")", "\n", "raw_url", "=", "part", ".", "parent", ".", "attrs", "[", "'itemid'", "]", "\n", "has_caption", "=", "True", "\n", "", "", "elif", "part", ".", "name", "==", "'figure'", ":", "\n", "            ", "if", "part", ".", "attrs", ".", "get", "(", "'itemid'", ",", "0", ")", ":", "\n", "                ", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'e13ogyst0'", "}", ")", "\n", "raw_url", "=", "part", ".", "attrs", "[", "'itemid'", "]", "\n", "has_caption", "=", "True", "\n", "\n", "", "", "if", "has_caption", "and", "caption", ":", "\n", "            ", "url", "=", "resolve_url", "(", "raw_url", ")", "\n", "sections", ".", "append", "(", "{", "\n", "'type'", ":", "'caption'", ",", "\n", "'order'", ":", "i", ",", "\n", "'text'", ":", "caption", ".", "text", ".", "strip", "(", ")", ",", "\n", "'url'", ":", "url", ",", "\n", "'hash'", ":", "hashlib", ".", "sha256", "(", "url", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", ",", "\n", "}", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "return", "sections", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_old": [[109, 139], ["get_articles_nytimes.get_tags", "sections.append", "part.parent.attrs.get", "part.text.strip", "part.find", "get_articles_nytimes.resolve_url", "sections.append", "part.find.text.strip", "hashlib.sha256().hexdigest", "hashlib.sha256", "resolve_url.encode"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.get_tags", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.token_indexers.roberta_indexer_names_matched.RobertaNamesMatchedTokenIndexer.encode"], ["", "def", "extract_text_old", "(", "soup", ")", ":", "\n", "# For articles in 2012 and earlier", "\n", "    ", "sections", "=", "[", "]", "\n", "\n", "params", "=", "{", "\n", "'p'", ":", "{", "'class'", ":", "'story-body-text'", "}", ",", "\n", "'figcaption'", ":", "{", "'itemprop'", ":", "'caption description'", "}", ",", "\n", "'span'", ":", "{", "'class'", ":", "'caption-text'", "}", ",", "\n", "}", "\n", "\n", "article_parts", "=", "get_tags", "(", "soup", ",", "params", ")", "\n", "i", "=", "0", "\n", "for", "part", "in", "article_parts", ":", "\n", "        ", "if", "part", ".", "name", "==", "'p'", ":", "\n", "            ", "sections", ".", "append", "(", "{", "'type'", ":", "'paragraph'", ",", "'text'", ":", "part", ".", "text", ".", "strip", "(", ")", "}", ")", "\n", "", "elif", "part", ".", "name", "==", "'figcaption'", ":", "\n", "            ", "if", "part", ".", "parent", ".", "attrs", ".", "get", "(", "'itemid'", ",", "0", ")", ":", "\n", "                ", "caption", "=", "part", ".", "find", "(", "'span'", ",", "{", "'class'", ":", "'caption-text'", "}", ")", "\n", "if", "caption", ":", "\n", "                    ", "url", "=", "resolve_url", "(", "part", ".", "parent", ".", "attrs", "[", "'itemid'", "]", ")", "\n", "sections", ".", "append", "(", "{", "\n", "'type'", ":", "'caption'", ",", "\n", "'order'", ":", "i", ",", "\n", "'text'", ":", "caption", ".", "text", ".", "strip", "(", ")", ",", "\n", "'url'", ":", "url", ",", "\n", "'hash'", ":", "hashlib", ".", "sha256", "(", "url", ".", "encode", "(", "'utf-8'", ")", ")", ".", "hexdigest", "(", ")", ",", "\n", "}", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "", "", "return", "sections", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text": [[141, 153], ["bs4.BeautifulSoup", "bs4.BeautifulSoup.find", "bs4.BeautifulSoup.find().find_all", "get_articles_nytimes.extract_text_new", "bs4.BeautifulSoup.find_all", "get_articles_nytimes.extract_text_old", "bs4.BeautifulSoup.find"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_new", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text_old"], ["", "def", "extract_text", "(", "html", ")", ":", "\n", "    ", "soup", "=", "bs4", ".", "BeautifulSoup", "(", "html", ",", "'html.parser'", ")", "\n", "\n", "# Newer articles use StoryBodyCompanionColumn", "\n", "if", "soup", ".", "find", "(", "'article'", ")", "and", "soup", ".", "find", "(", "'article'", ")", ".", "find_all", "(", "'div'", ",", "{", "'class'", ":", "'StoryBodyCompanionColumn'", "}", ")", ":", "\n", "        ", "return", "extract_text_new", "(", "soup", ")", "\n", "\n", "# Older articles use story-body", "\n", "", "elif", "soup", ".", "find_all", "(", "'p'", ",", "{", "'class'", ":", "'story-body-text'", "}", ")", ":", "\n", "        ", "return", "extract_text_old", "(", "soup", ")", "\n", "\n", "", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.retrieve_articles": [[155, 167], ["db.scraping.find_one", "os.path.join", "db.scraping.insert_one", "open", "json.load", "tqdm.tqdm", "get_articles_nytimes.retrieve_article"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.retrieve_article"], ["", "def", "retrieve_articles", "(", "root_dir", ",", "year", ",", "month", ",", "db", ")", ":", "\n", "    ", "result", "=", "db", ".", "scraping", ".", "find_one", "(", "{", "'year'", ":", "year", ",", "'month'", ":", "month", "}", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "        ", "return", "\n", "\n", "", "in_path", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'archive'", ",", "f'{year}_{month:02}.json'", ")", "\n", "with", "open", "(", "in_path", ")", "as", "f", ":", "\n", "        ", "content", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "article", "in", "tqdm", "(", "content", "[", "'response'", "]", "[", "'docs'", "]", ",", "desc", "=", "f'{year}-{month:02}'", ")", ":", "\n", "            ", "retrieve_article", "(", "article", ",", "root_dir", ",", "db", ")", "\n", "\n", "", "", "db", ".", "scraping", ".", "insert_one", "(", "{", "'year'", ":", "year", ",", "'month'", ":", "month", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.retrieve_article": [[169, 263], ["article[].startswith", "db.source.find_one", "datetime.datetime.strptime", "get_articles_nytimes.resolve_url", "range", "get_articles_nytimes.extract_text", "langdetect.detect", "db.source.insert_one", "urllib.request.urlopen.read().decode", "enumerate", "len", "db.text_articles.insert_one", "db.articles.insert_one", "urllib.request.urlopen", "time.sleep", "urllib.request.urlopen.read", "image_positions.append", "os.path.join", "os.path.exists", "requests.get", "db.images.update_one", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.resolve_url", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.extract_text", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.annotate_yolo3.detect", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.models.transformer_pointer_2.TransformerPointer2Model.decode"], ["", "def", "retrieve_article", "(", "article", ",", "root_dir", ",", "db", ")", ":", "\n", "    ", "if", "article", "[", "'_id'", "]", ".", "startswith", "(", "'nyt://article/'", ")", ":", "\n", "        ", "article", "[", "'_id'", "]", "=", "article", "[", "'_id'", "]", "[", "14", ":", "]", "\n", "\n", "", "result", "=", "db", ".", "source", ".", "find_one", "(", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ")", "\n", "if", "result", "is", "not", "None", ":", "\n", "        ", "return", "\n", "\n", "", "data", "=", "article", "\n", "data", "[", "'scraped'", "]", "=", "False", "\n", "data", "[", "'parsed'", "]", "=", "False", "\n", "data", "[", "'error'", "]", "=", "False", "\n", "data", "[", "'pub_date'", "]", "=", "datetime", ".", "strptime", "(", "article", "[", "'pub_date'", "]", ",", "\n", "'%Y-%m-%dT%H:%M:%S%z'", ")", "\n", "\n", "if", "not", "article", "[", "'web_url'", "]", ":", "\n", "        ", "return", "\n", "\n", "", "url", "=", "resolve_url", "(", "article", "[", "'web_url'", "]", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "urlopen", "(", "url", ",", "timeout", "=", "20", ")", "\n", "break", "\n", "", "except", "(", "ValueError", ",", "HTTPError", ")", ":", "\n", "# ValueError: unknown url type: '/interactive/2018/12/05/business/05Markets.html'", "\n", "# urllib.error.HTTPError: HTTP Error 404: Not Found", "\n", "            ", "return", "\n", "", "except", "(", "URLError", ",", "ConnectionResetError", ")", ":", "\n", "            ", "time", ".", "sleep", "(", "60", ")", "\n", "continue", "\n", "", "except", "socket", ".", "timeout", ":", "\n", "            ", "pass", "\n", "# urllib.error.URLError: <urlopen error [Errno 110] Connection timed out>", "\n", "", "return", "\n", "\n", "", "data", "[", "'web_url'", "]", "=", "url", "\n", "try", ":", "\n", "        ", "raw_html", "=", "response", ".", "read", "(", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "        ", "return", "\n", "\n", "", "raw_data", "=", "{", "\n", "'_id'", ":", "article", "[", "'_id'", "]", ",", "\n", "'raw_html'", ":", "raw_html", ",", "\n", "}", "\n", "\n", "parsed_sections", "=", "extract_text", "(", "raw_html", ")", "\n", "data", "[", "'parsed_section'", "]", "=", "parsed_sections", "\n", "\n", "text_list", "=", "[", "sec", "[", "'text'", "]", "for", "sec", "in", "article", "[", "'parsed_section'", "]", "]", "\n", "text", "=", "'\\n'", ".", "join", "(", "text_list", ")", "\n", "data", "[", "'language'", "]", "=", "detect", "(", "text", ")", "\n", "\n", "if", "parsed_sections", ":", "\n", "        ", "image_positions", "=", "[", "]", "\n", "for", "i", ",", "section", "in", "enumerate", "(", "parsed_sections", ")", ":", "\n", "            ", "if", "section", "[", "'type'", "]", "==", "'caption'", ":", "\n", "                ", "image_positions", ".", "append", "(", "i", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'images'", ",", "\n", "f\"{section['hash']}.jpg\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "img_response", "=", "requests", ".", "get", "(", "\n", "section", "[", "'url'", "]", ",", "stream", "=", "True", ")", "\n", "img_data", "=", "img_response", ".", "content", "\n", "with", "open", "(", "img_path", ",", "'wb'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "img_data", ")", "\n", "\n", "", "db", ".", "images", ".", "update_one", "(", "\n", "{", "'_id'", ":", "section", "[", "'hash'", "]", "}", ",", "\n", "{", "'$push'", ":", "{", "'captions'", ":", "{", "\n", "'id'", ":", "article", "[", "'_id'", "]", ",", "\n", "'caption'", ":", "section", "[", "'text'", "]", ",", "\n", "}", "}", "}", ",", "upsert", "=", "True", ")", "\n", "\n", "", "except", "requests", ".", "exceptions", ".", "MissingSchema", ":", "\n", "                        ", "section", "[", "'downloaded'", "]", "=", "False", "\n", "", "else", ":", "\n", "                        ", "section", "[", "'downloaded'", "]", "=", "True", "\n", "\n", "", "", "", "", "data", "[", "'parsed'", "]", "=", "True", "\n", "article", "[", "'image_positions'", "]", "=", "image_positions", "\n", "article", "[", "'n_images'", "]", "=", "len", "(", "image_positions", ")", "\n", "", "else", ":", "\n", "        ", "article", "[", "'n_images'", "]", "=", "0", "\n", "\n", "", "data", "[", "'scraped'", "]", "=", "True", "\n", "\n", "db", ".", "source", ".", "insert_one", "(", "{", "'_id'", ":", "raw_data", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "raw_data", "}", ")", "\n", "\n", "if", "not", "article", "[", "'parsed'", "]", "or", "article", "[", "'n_images'", "]", "==", "0", "or", "article", "[", "'language'", "]", "!=", "'en'", ":", "\n", "        ", "db", ".", "text_articles", ".", "insert_one", "(", "article", ")", "\n", "", "else", ":", "\n", "        ", "db", ".", "articles", ".", "insert_one", "(", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "data", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate": [[265, 275], ["schema.Schema", "schema.Schema.validate", "k.lstrip().lower().replace", "schema.validate.items", "schema.Or", "k.lstrip().lower", "schema.And", "schema.Use", "k.lstrip"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate"], ["", "", "def", "validate", "(", "args", ")", ":", "\n", "    ", "\"\"\"Validate command line arguments.\"\"\"", "\n", "args", "=", "{", "k", ".", "lstrip", "(", "'-'", ")", ".", "lower", "(", ")", ".", "replace", "(", "'-'", ",", "'_'", ")", ":", "v", "\n", "for", "k", ",", "v", "in", "args", ".", "items", "(", ")", "}", "\n", "schema", "=", "Schema", "(", "{", "\n", "'ptvsd'", ":", "Or", "(", "None", ",", "And", "(", "Use", "(", "int", ")", ",", "lambda", "port", ":", "1", "<=", "port", "<=", "65535", ")", ")", ",", "\n", "'root_dir'", ":", "os", ".", "path", ".", "exists", ",", "\n", "}", ")", "\n", "args", "=", "schema", ".", "validate", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.month_year_iter": [[277, 284], ["range", "divmod"], "function", ["None"], ["", "def", "month_year_iter", "(", "end_month", ",", "end_year", ",", "start_month", ",", "start_year", ")", ":", "\n", "# The first month is excluded", "\n", "    ", "ym_start", "=", "12", "*", "start_year", "+", "start_month", "-", "1", "\n", "ym_end", "=", "12", "*", "end_year", "+", "end_month", "-", "1", "\n", "for", "ym", "in", "range", "(", "ym_end", ",", "ym_start", ",", "-", "1", ")", ":", "\n", "        ", "y", ",", "m", "=", "divmod", "(", "ym", ",", "12", ")", "\n", "yield", "y", ",", "m", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.main": [[286, 357], ["docopt.docopt", "get_articles_nytimes.validate", "os.path.join", "os.makedirs", "pymongo.MongoClient", "datetime.datetime", "datetime.datetime", "db.articles.find().batch_size", "tqdm.tqdm", "datetime.datetime", "datetime.datetime", "db.articles.find().batch_size", "tqdm.tqdm", "datetime.datetime", "datetime.datetime", "db.articles.find().batch_size", "tqdm.tqdm", "logger.info", "db.articles.create_index", "db.articles.create_index", "db.articles.create_index", "db.articles.create_index", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "joblib.Parallel", "parallel", "db.articles.find_one_and_update", "db.articles.find_one_and_update", "db.articles.find_one_and_update", "db.articles.find", "db.articles.find", "db.articles.find", "joblib.delayed", "get_articles_nytimes.month_year_iter"], "function", ["home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.validate", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.server.utils.NTLogger.info", "home.repos.pwc.inspect_result.alasdairtran_transform-and-tell.scripts.get_articles_nytimes.month_year_iter"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "docopt", "(", "__doc__", ",", "version", "=", "'0.0.1'", ")", "\n", "args", "=", "validate", "(", "args", ")", "\n", "\n", "if", "args", "[", "'ptvsd'", "]", ":", "\n", "        ", "address", "=", "(", "'0.0.0.0'", ",", "args", "[", "'ptvsd'", "]", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "", "root_dir", "=", "args", "[", "'root_dir'", "]", "\n", "img_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'images'", ")", "\n", "os", ".", "makedirs", "(", "img_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get the nytimes database", "\n", "client", "=", "MongoClient", "(", "host", "=", "'localhost'", ",", "port", "=", "27017", ")", "\n", "db", "=", "client", ".", "nytimes", "\n", "\n", "with", "Parallel", "(", "n_jobs", "=", "12", ",", "backend", "=", "'threading'", ")", "as", "parallel", ":", "\n", "        ", "parallel", "(", "delayed", "(", "retrieve_articles", ")", "(", "root_dir", ",", "year", ",", "month", ",", "db", ")", "\n", "for", "year", ",", "month", "in", "month_year_iter", "(", "8", ",", "2019", ",", "12", ",", "2003", ")", ")", "\n", "\n", "", "start", "=", "datetime", "(", "2019", ",", "6", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2019", ",", "9", ",", "1", ")", "\n", "article_cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "\n", "'pub_date'", ":", "{", "'$gte'", ":", "start", ",", "'$lt'", ":", "end", "}", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "article", "[", "'split'", "]", "=", "'test'", "\n", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n", "", "start", "=", "datetime", "(", "2000", ",", "1", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2019", ",", "5", ",", "1", ")", "\n", "article_cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "\n", "'pub_date'", ":", "{", "'$gte'", ":", "start", ",", "'$lt'", ":", "end", "}", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "article", "[", "'split'", "]", "=", "'train'", "\n", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n", "", "start", "=", "datetime", "(", "2019", ",", "5", ",", "1", ")", "\n", "end", "=", "datetime", "(", "2019", ",", "6", ",", "1", ")", "\n", "article_cursor", "=", "db", ".", "articles", ".", "find", "(", "{", "\n", "'pub_date'", ":", "{", "'$gte'", ":", "start", ",", "'$lt'", ":", "end", "}", ",", "\n", "}", ",", "no_cursor_timeout", "=", "True", ")", ".", "batch_size", "(", "128", ")", "\n", "for", "article", "in", "tqdm", "(", "article_cursor", ")", ":", "\n", "        ", "article", "[", "'split'", "]", "=", "'valid'", "\n", "db", ".", "articles", ".", "find_one_and_update", "(", "\n", "{", "'_id'", ":", "article", "[", "'_id'", "]", "}", ",", "{", "'$set'", ":", "article", "}", ")", "\n", "\n", "# Build indices", "\n", "", "logger", ".", "info", "(", "'Building indices'", ")", "\n", "db", ".", "articles", ".", "create_index", "(", "[", "\n", "(", "'pub_date'", ",", "pymongo", ".", "DESCENDING", ")", ",", "\n", "]", ")", "\n", "\n", "db", ".", "articles", ".", "create_index", "(", "[", "\n", "(", "'pub_date'", ",", "pymongo", ".", "DESCENDING", ")", ",", "\n", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "]", ")", "\n", "\n", "db", ".", "articles", ".", "create_index", "(", "[", "\n", "(", "'split'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "(", "'_id'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "]", ")", "\n", "\n", "db", ".", "articles", ".", "create_index", "(", "[", "\n", "(", "'n_images'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "(", "'n_images_with_faces'", ",", "pymongo", ".", "ASCENDING", ")", ",", "\n", "(", "'pub_date'", ",", "pymongo", ".", "DESCENDING", ")", ",", "\n", "]", ")", "\n"]]}