{"home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.04-git.main": [[15, 36], ["configparser.ConfigParser", "configparser.ConfigParser.read", "requests.auth.HTTPBasicAuth", "list", "tqdm.tqdm", "open", "json.load", "filter", "requests.get", "requests.get.json", "git.Repo.clone_from", "os.path.join", "data[].replace"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "auth_name", "=", "config", "[", "'03-repoinfos'", "]", "[", "'AuthName'", "]", "\n", "auth_password", "=", "config", "[", "'03-repoinfos'", "]", "[", "'AuthPassword'", "]", "\n", "\n", "auth", "=", "HTTPBasicAuth", "(", "auth_name", ",", "auth_password", ")", "\n", "\n", "with", "open", "(", "'results.json'", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "data", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "[", "'isJava'", "]", "and", "x", "[", "'doc_count'", "]", ">", "10", ",", "data", ")", ")", "\n", "\n", "for", "elem", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "temp", "=", "requests", ".", "get", "(", "elem", "[", "'key'", "]", ",", "auth", "=", "auth", ")", "\n", "if", "temp", ".", "status_code", "!=", "200", ":", "\n", "            ", "return", "None", "\n", "", "langObj", "=", "temp", ".", "json", "(", ")", "\n", "url", "=", "langObj", "[", "'git_url'", "]", "\n", "Repo", ".", "clone_from", "(", "url", ",", "os", ".", "path", ".", "join", "(", "'git'", ",", "data", "[", "'full_name'", "]", ".", "replace", "(", "'/'", ",", "'-'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.01-retrieve.generate_combos": [[25, 27], ["itertools.product"], "function", ["None"], ["def", "generate_combos", "(", "ranges", ")", ":", "\n", "    ", "return", "product", "(", "*", "ranges", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.01-retrieve.convert_to_range": [[29, 32], ["range", "int", "int"], "function", ["None"], ["", "def", "convert_to_range", "(", "group", ")", "->", "range", ":", "\n", "    ", "start", ",", "end", "=", "group", "\n", "return", "range", "(", "int", "(", "start", ")", ",", "int", "(", "end", ")", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.01-retrieve.report_hook": [[34, 50], ["progressbar.ProgressBar.update", "progressbar.ProgressBar", "progressbar.ProgressBar.start", "min", "progressbar.Percentage", "progressbar.Bar", "datetime.timedelta", "datetime.datetime.now"], "function", ["None"], ["", "def", "report_hook", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "bar", "=", "bar_wrap", "[", "0", "]", "\n", "if", "bar", "is", "None", ":", "\n", "        ", "bar", "=", "progressbar", ".", "ProgressBar", "(", "\n", "maxval", "=", "total_size", ",", "\n", "widgets", "=", "[", "\n", "'File #{} of {}: '", ".", "format", "(", "current_num", "+", "1", ",", "max_num", ")", ",", "\n", "progressbar", ".", "Percentage", "(", ")", ",", "\n", "' '", ",", "\n", "progressbar", ".", "Bar", "(", ")", ",", "\n", "' '", ",", "\n", "'Total elapsed time: {}'", ".", "format", "(", "timedelta", "(", "seconds", "=", "(", "datetime", ".", "now", "(", ")", "-", "start_time", ")", ".", "seconds", ")", ")", ",", "\n", "]", ")", "\n", "bar", ".", "start", "(", ")", "\n", "bar_wrap", "[", "0", "]", "=", "bar", "\n", "", "bar", ".", "update", "(", "min", "(", "count", "*", "block_size", ",", "total_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.01-retrieve.main": [[52, 88], ["configparser.ConfigParser", "configparser.ConfigParser.read", "re.sub", "re.sub", "re.findall", "list", "01-retrieve.generate_combos", "len", "urllib.request.build_opener", "urllib.request.install_opener", "enumerate", "logging.info", "pattern.replace", "map", "urls_to_retrieve.append", "re.sub.format", "urllib.request.urlretrieve", "url_to_retrieve.rfind", "print", "print"], "function", ["home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.01-retrieve.generate_combos"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "bar_wrap", ",", "current_num", ",", "max_num", ",", "start_time", "\n", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "url", "=", "config", "[", "'01-retrieve'", "]", "[", "'URL'", "]", "\n", "path", "=", "config", "[", "'general'", "]", "[", "'ArchivePath'", "]", "\n", "pattern", "=", "r'\\{([0-9]*)\\.\\.([0-9]*)}'", "\n", "preformatted_url", "=", "re", ".", "sub", "(", "pattern", ".", "replace", "(", "'*'", ",", "''", ",", "1", ")", ",", "'{:d}'", ",", "url", ")", "# substitute patterns without leading zeros", "\n", "preformatted_url", "=", "re", ".", "sub", "(", "pattern", ",", "'{:02d}'", ",", "preformatted_url", ")", "\n", "\n", "groups", "=", "re", ".", "findall", "(", "pattern", ",", "url", ")", "\n", "ranges", "=", "list", "(", "map", "(", "convert_to_range", ",", "groups", ")", ")", "\n", "\n", "urls_to_retrieve", "=", "[", "]", "\n", "for", "combo", "in", "generate_combos", "(", "ranges", ")", ":", "\n", "        ", "urls_to_retrieve", ".", "append", "(", "preformatted_url", ".", "format", "(", "*", "combo", ")", ")", "\n", "\n", "", "max_num", "=", "len", "(", "urls_to_retrieve", ")", "\n", "\n", "opener", "=", "urllib", ".", "request", ".", "build_opener", "(", ")", "\n", "opener", ".", "addheaders", "=", "[", "(", "'User-agent'", ",", "'Mozilla/5.0'", ")", "]", "# Dirty hack, otherwise we get a 403, as GitHub blocks those", "\n", "urllib", ".", "request", ".", "install_opener", "(", "opener", ")", "\n", "\n", "for", "idx", ",", "url_to_retrieve", "in", "enumerate", "(", "urls_to_retrieve", ")", ":", "\n", "        ", "current_num", "=", "idx", "\n", "filename", "=", "url_to_retrieve", "[", "url_to_retrieve", ".", "rfind", "(", "'/'", ")", ":", "]", "\n", "bar_wrap", "=", "[", "None", "]", "\n", "try", ":", "\n", "            ", "urllib", ".", "request", ".", "urlretrieve", "(", "url_to_retrieve", ",", "path", "+", "filename", ",", "reporthook", "=", "report_hook", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ",", "end", "=", "' at '", ")", "\n", "print", "(", "url_to_retrieve", ")", "\n", "continue", "\n", "\n", "", "", "logging", ".", "info", "(", "'\\nAll done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.08-train.main": [[20, 74], ["tokenizers.Tokenizer.from_file", "tokenizers.pre_tokenizers.PreTokenizer.custom", "transformers.PreTrainedTokenizerFast", "print", "transformers.PreTrainedTokenizerFast.add_special_tokens", "list", "load_dataset", "load_dataset.map", "transformers.DataCollatorForLanguageModeling", "transformers.BertConfig", "transformers.BertForMaskedLM", "transformers.TrainingArguments", "transformers.Trainer", "transformers.Trainer.train", "JavaPreTokenizer.JavaPreTokenizer", "open", "json.load", "map", "transformers.PreTrainedTokenizerFast."], "function", ["None"], ["def", "main", "(", "tokenizer", ",", "output", ")", ":", "\n", "    ", "tokenizer", "=", "Tokenizer", ".", "from_file", "(", "tokenizer", ")", "\n", "tokenizer", ".", "pre_tokenizer", "=", "PreTokenizer", ".", "custom", "(", "JavaPreTokenizer", "(", ")", ")", "\n", "tok", "=", "PreTrainedTokenizerFast", "(", "tokenizer_object", "=", "tokenizer", ")", "\n", "print", "(", "tok", ".", "unk_token", ")", "\n", "tok", ".", "add_special_tokens", "(", "{", "\n", "'unk_token'", ":", "'[UNK]'", ",", "\n", "'mask_token'", ":", "'[MASK]'", ",", "\n", "'pad_token'", ":", "'[PAD]'", ",", "\n", "'cls_token'", ":", "'[CLS]'", "\n", "}", ")", "\n", "\n", "from", "datasets", "import", "load_dataset", "\n", "\n", "with", "open", "(", "'train-split.json'", ")", "as", "fp", ":", "\n", "        ", "train_files", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "data", "=", "list", "(", "map", "(", "lambda", "x", ":", "'../'", "+", "x", "[", "'filename'", "]", ",", "train_files", ")", ")", "\n", "\n", "ds", "=", "load_dataset", "(", "'JavaDataset'", ",", "split", "=", "'train'", ",", "data_files", "=", "data", ")", "\n", "ds_mapped", "=", "ds", ".", "map", "(", "lambda", "batch", ":", "tok", "(", "batch", "[", "'code'", "]", ",", "truncation", "=", "True", ",", "padding", "=", "True", ",", "max_length", "=", "512", ")", ",", "batched", "=", "True", ")", "\n", "\n", "data_collator", "=", "DataCollatorForLanguageModeling", "(", "\n", "tokenizer", "=", "tok", ",", "mlm", "=", "True", ",", "mlm_probability", "=", "0.15", "\n", ")", "\n", "\n", "config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "8000", ",", "\n", "max_position_embeddings", "=", "514", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "num_hidden_layers", "=", "6", ",", "\n", "type_vocab_size", "=", "1", ",", "\n", ")", "\n", "\n", "model", "=", "BertForMaskedLM", "(", "config", "=", "config", ")", "\n", "\n", "training_args", "=", "TrainingArguments", "(", "\n", "output_dir", "=", "output", ",", "\n", "overwrite_output_dir", "=", "True", ",", "\n", "num_train_epochs", "=", "1", ",", "\n", "# per_gpu_train_batch_size=64,", "\n", "save_steps", "=", "10_000", ",", "\n", "save_total_limit", "=", "2", ",", "\n", "prediction_loss_only", "=", "True", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "train_dataset", "=", "ds_mapped", ",", "\n", ")", "\n", "\n", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.get_lang_obj": [[21, 28], ["tenacity.retry", "requests.get", "requests.get.json", "tenacity.stop_after_attempt", "tenacity.wait_exponential"], "function", ["None"], ["@", "retry", "(", "stop", "=", "stop_after_attempt", "(", "10", ")", ",", "wait", "=", "wait_exponential", "(", "multiplier", "=", "1", ",", "min", "=", "5", ",", "max", "=", "60", ")", ")", "\n", "def", "get_lang_obj", "(", "lang_url", ",", "auth", ")", ":", "\n", "    ", "temp", "=", "requests", ".", "get", "(", "lang_url", ",", "auth", "=", "auth", ")", "\n", "if", "temp", ".", "status_code", "!=", "200", ":", "\n", "        ", "return", "None", "\n", "", "lang_obj", "=", "temp", ".", "json", "(", ")", "\n", "return", "lang_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.sort_lang_obj": [[30, 32], ["sorted", "lang_obj.items"], "function", ["None"], ["", "def", "sort_lang_obj", "(", "lang_obj", ")", ":", "\n", "    ", "return", "sorted", "(", "lang_obj", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.is_java_repo": [[34, 36], ["len", "list", "filter"], "function", ["None"], ["", "def", "is_java_repo", "(", "lang_list", ")", ":", "\n", "    ", "return", "len", "(", "list", "(", "filter", "(", "lambda", "x", ":", "x", "[", "0", "]", "==", "'Java'", ",", "lang_list", "[", ":", "3", "]", ")", ")", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.get_and_check_java_repo": [[38, 44], ["03-repoinfos.get_lang_obj", "03-repoinfos.sort_lang_obj", "03-repoinfos.is_java_repo"], "function", ["home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.get_lang_obj", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.sort_lang_obj", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.is_java_repo"], ["", "def", "get_and_check_java_repo", "(", "repo_url", ",", "auth", ")", ":", "\n", "    ", "obj", "=", "get_lang_obj", "(", "repo_url", "+", "'/languages'", ",", "auth", ")", "\n", "if", "obj", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "sorted_obj", "=", "sort_lang_obj", "(", "obj", ")", "\n", "return", "is_java_repo", "(", "sorted_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.elasticsearch_helper": [[46, 52], ["tenacity.retry", "es.search", "tenacity.stop_after_attempt", "tenacity.wait_exponential"], "function", ["None"], ["", "@", "retry", "(", "stop", "=", "stop_after_attempt", "(", "10", ")", ",", "wait", "=", "wait_exponential", "(", "multiplier", "=", "1", ",", "min", "=", "5", ",", "max", "=", "60", ")", ")", "\n", "def", "elasticsearch_helper", "(", "es", ",", "index_name", ",", "body", ")", ":", "\n", "    ", "\"\"\"\n    Small helper to exploit decorator\n    \"\"\"", "\n", "return", "es", ".", "search", "(", "index", "=", "index_name", ",", "body", "=", "body", ",", "size", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.save_data": [[54, 57], ["open", "json.dump"], "function", ["None"], ["", "def", "save_data", "(", "java_repos", ")", ":", "\n", "    ", "with", "open", "(", "'results.json'", ",", "'w'", ")", "as", "g", ":", "\n", "        ", "json", ".", "dump", "(", "java_repos", ",", "g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.clone": [[59, 62], ["git.Repo.clone_from", "os.path.join", "data[].replace"], "function", ["None"], ["", "", "def", "clone", "(", "data", ")", ":", "\n", "    ", "url", "=", "data", "[", "'git_url'", "]", "\n", "Repo", ".", "clone_from", "(", "url", ",", "os", ".", "path", ".", "join", "(", "'git'", ",", "data", "[", "'full_name'", "]", ".", "replace", "(", "'/'", ",", "'-'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.filter_license": [[64, 66], ["list", "filter"], "function", ["None"], ["", "def", "filter_license", "(", "data", ")", ":", "\n", "    ", "list", "(", "filter", "(", "lambda", "x", ":", "x", "[", "'license'", "]", "in", "(", "'mit'", ",", "'apache-2.0'", ")", ",", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.main": [[68, 140], ["configparser.ConfigParser", "configparser.ConfigParser.read", "elasticsearch.Elasticsearch", "multiprocessing.Pool", "requests.auth.HTTPBasicAuth", "tqdm.tqdm", "03-repoinfos.save_data", "tqdm.tqdm", "open", "json.load", "java_repos.append", "time.sleep", "process.wait", "03-repoinfos.get_and_check_java_repo", "03-repoinfos.elasticsearch_helper", "processes.append", "body.replace", "03-repoinfos.save_data", "multiprocessing.Pool.apply_async"], "function", ["home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.save_data", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.get_and_check_java_repo", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.elasticsearch_helper", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.03-repoinfos.save_data"], ["", "def", "main", "(", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "host", "=", "config", "[", "'elasticsearch'", "]", "[", "'Host'", "]", "\n", "port", "=", "config", "[", "'elasticsearch'", "]", "[", "'Port'", "]", "\n", "index_name", "=", "config", "[", "'elasticsearch'", "]", "[", "'IndexName'", "]", "\n", "\n", "auth_name", "=", "config", "[", "'03-repoinfos'", "]", "[", "'AuthName'", "]", "\n", "auth_password", "=", "config", "[", "'03-repoinfos'", "]", "[", "'AuthPassword'", "]", "\n", "\n", "es", "=", "Elasticsearch", "(", "host", ",", "port", "=", "port", ")", "\n", "\n", "pool", "=", "Pool", "(", "1", ")", "\n", "processes", "=", "[", "]", "\n", "\n", "# Get list of all repos for 2020", "\n", "with", "open", "(", "'comments.json'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "aggs", "=", "data", "[", "'aggregations'", "]", "[", "'types_count'", "]", "\n", "buckets", "=", "aggs", "[", "'buckets'", "]", "\n", "auth", "=", "HTTPBasicAuth", "(", "auth_name", ",", "auth_password", ")", "\n", "java_repos", "=", "[", "]", "\n", "\n", "body", "=", "'''\n    {\n      \"_source\": [\n        \"payload.pull_request.base.repo.license.key\",\n        \"payload.pull_request.base.repo.git_url\",\n        \"payload.pull_request.base.repo.full_name\"\n      ],\n      \"query\": {\n        \"bool\": {\n          \"must\": [\n            {\n              \"match\": {\n                \"type\": \"PullRequestReviewCommentEvent\"\n              }\n            },\n            {\n              \"match\": {\n                \"repo.url.keyword\": \"https://api.github.com/repos/elastic/kibana\"\n              }\n            }\n          ]\n        }\n      }\n    }\n    '''", "\n", "for", "elem", "in", "tqdm", "(", "buckets", ")", ":", "\n", "        ", "key", "=", "elem", "[", "'key'", "]", "\n", "try", ":", "\n", "            ", "is_java", "=", "get_and_check_java_repo", "(", "key", ",", "auth", ")", "\n", "elem", "[", "'isJava'", "]", "=", "is_java", "\n", "response", "=", "elasticsearch_helper", "(", "es", ",", "index_name", ",", "body", ".", "replace", "(", "'***'", ",", "key", ")", ")", "\n", "", "except", ":", "\n", "            ", "save_data", "(", "java_repos", ")", "\n", "raise", "\n", "", "source", "=", "response", "[", "'hits'", "]", "[", "'hits'", "]", "[", "0", "]", "[", "'_source'", "]", "\n", "if", "'payload'", "in", "source", ":", "\n", "            ", "elem", "[", "'license'", "]", "=", "source", "[", "'payload'", "]", "[", "'pull_request'", "]", "[", "'base'", "]", "[", "'repo'", "]", "[", "'license'", "]", "[", "'key'", "]", "\n", "", "else", ":", "\n", "            ", "elem", "[", "'license'", "]", "=", "None", "\n", "", "java_repos", ".", "append", "(", "elem", ")", "\n", "if", "elem", "[", "'license'", "]", "in", "(", "'mit'", ",", "'apache-2.0'", ")", ":", "\n", "            ", "processes", ".", "append", "(", "pool", ".", "apply_async", "(", "clone", ",", "source", "[", "'payload'", "]", "[", "'pull_request'", "]", "[", "'base'", "]", "[", "'repo'", "]", ")", ")", "\n", "", "time", ".", "sleep", "(", "0.9", ")", "\n", "\n", "", "save_data", "(", "java_repos", ")", "\n", "for", "process", "in", "tqdm", "(", "processes", ")", ":", "\n", "        ", "process", ".", "wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load-bulk.bulk_helper": [[21, 27], ["retry", "elasticsearch.helpers.bulk", "stop_after_attempt", "wait_fixed"], "function", ["None"], ["@", "retry", "(", "stop", "=", "stop_after_attempt", "(", "3", ")", ",", "wait", "=", "wait_fixed", "(", "45", ")", ")", "\n", "def", "bulk_helper", "(", "es", ",", "data", ")", ":", "\n", "    ", "\"\"\"\n    Just a small helper to simplify code and make use of the retry decorator.\n    \"\"\"", "\n", "bulk", "(", "es", ",", "data", ",", "max_retries", "=", "10", ",", "initial_backoff", "=", "5", ",", "chunk_size", "=", "2000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load-bulk.remove_already_processed_docs": [[29, 32], ["file_list.index"], "function", ["None"], ["", "def", "remove_already_processed_docs", "(", "pointer", ",", "file_list", ")", ":", "\n", "    ", "index", "=", "file_list", ".", "index", "(", "pointer", ")", "\n", "return", "file_list", "[", "index", "+", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load-bulk.main": [[34, 82], ["configparser.ConfigParser", "configparser.ConfigParser.read", "elasticsearch.Elasticsearch", "glob.glob", "remove_already_processed_docs.sort", "os.path.exists", "tqdm.tqdm", "os.remove", "logging.info", "logging.info", "02-load-bulk.remove_already_processed_docs", "open", "json.dump", "open", "f.readline().replace", "gzip.open", "f.readlines", "02-load-bulk.bulk_helper", "open", "f.write", "len", "enumerate", "02-load-bulk.main.provide"], "function", ["home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load-bulk.remove_already_processed_docs", "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load-bulk.bulk_helper"], ["", "def", "main", "(", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "host", "=", "config", "[", "'elasticsearch'", "]", "[", "'Host'", "]", "\n", "port", "=", "config", "[", "'elasticsearch'", "]", "[", "'Port'", "]", "\n", "index_name", "=", "config", "[", "'elasticsearch'", "]", "[", "'IndexName'", "]", "\n", "\n", "es", "=", "Elasticsearch", "(", "host", ",", "port", "=", "port", ")", "\n", "\n", "archives", "=", "glob", ".", "glob", "(", "config", "[", "'general'", "]", "[", "'ArchivePath'", "]", "+", "'*'", ")", "\n", "archives", ".", "sort", "(", ")", "\n", "\n", "files_with_errors", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "'.loader_lastfile'", ")", ":", "\n", "        ", "with", "open", "(", "'.loader_lastfile'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "last_file", "=", "f", ".", "readline", "(", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "archives", "=", "remove_already_processed_docs", "(", "last_file", ",", "archives", ")", "\n", "\n", "", "for", "filename", "in", "tqdm", "(", "archives", ")", ":", "\n", "        ", "with", "gzip", ".", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "def", "provide", "(", "lines", ")", ":", "\n", "                ", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "", "except", ":", "\n", "                        ", "files_with_errors", ".", "append", "(", "{", "'file'", ":", "filename", ",", "'line'", ":", "idx", "}", ")", "\n", "continue", "\n", "", "yield", "{", "\n", "\"_index\"", ":", "index_name", ",", "\n", "\"_op_type\"", ":", "\"update\"", ",", "\n", "\"_id\"", ":", "data", "[", "'id'", "]", ",", "\n", "\"doc\"", ":", "data", ",", "\n", "\"doc_as_upsert\"", ":", "True", "\n", "}", "\n", "\n", "", "", "bulk_helper", "(", "es", ",", "provide", "(", "lines", ")", ")", "\n", "# bulk(es, provide(), max_retries=10, initial_backoff=5, chunk_size=2000)", "\n", "", "with", "open", "(", "'.loader_lastfile'", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "filename", ")", "\n", "\n", "", "", "os", ".", "remove", "(", "'.loader_lastfile'", ")", "\n", "logging", ".", "info", "(", "'Finished'", ")", "\n", "logging", ".", "info", "(", "'{} errors occurred'", ".", "format", "(", "len", "(", "files_with_errors", ")", ")", ")", "\n", "with", "open", "(", "'02-errors.json'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "files_with_errors", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.06-sample.process": [[19, 34], ["os.path.isdir", "open", "f.read", "list", "len", "os.path.isfile", "javalang.tokenizer.tokenize"], "function", ["None"], ["def", "process", "(", "file_name", ")", ":", "\n", "    ", "\"\"\"\n    Opens a file and counts the tokens.\n    Returns a object with filename and the token count depicted as len.\n    If filename is a directory, a len of 0 will be returned.\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "file_name", ")", "or", "not", "os", ".", "path", ".", "isfile", "(", "file_name", ")", ":", "\n", "        ", "return", "{", "'filename'", ":", "file_name", ",", "'len'", ":", "0", "}", "\n", "", "with", "open", "(", "file_name", ",", "encoding", "=", "\"ISO-8859-1\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", "\n", "", "try", ":", "\n", "        ", "tokens", "=", "list", "(", "javalang", ".", "tokenizer", ".", "tokenize", "(", "data", ")", ")", "\n", "", "except", "LexerError", ":", "\n", "        ", "tokens", "=", "[", "]", "\n", "", "return", "{", "'filename'", ":", "file_name", ",", "'len'", ":", "len", "(", "tokens", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.06-sample.main": [[36, 64], ["configparser.ConfigParser", "configparser.ConfigParser.read", "logging.info", "logging.info", "multiprocessing.Pool", "tqdm.tqdm", "pandas.DataFrame.from_dict", "df.sample.describe", "df.sample.describe", "df.sample.sample", "df.sample.sample", "df.sample.drop", "df.sample.to_json", "df.drop.to_json", "open", "multiprocessing.Pool.imap_unordered", "results.append", "files.append", "len", "line[].replace"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "upper", "=", "config", "[", "'06-sample'", "]", "[", "'UpperBound'", "]", "\n", "lower", "=", "config", "[", "'06-sample'", "]", "[", "'LowerBound'", "]", "\n", "\n", "logging", ".", "info", "(", "'Load javafiles list'", ")", "\n", "files", "=", "[", "]", "\n", "with", "open", "(", "'java-files.txt'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "files", ".", "append", "(", "'git'", "+", "line", "[", "1", ":", "]", ".", "replace", "(", "'\\n'", ",", "''", ")", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "'Start tokenize processes'", ")", "\n", "pool", "=", "Pool", "(", "processes", "=", "28", ")", "\n", "results", "=", "[", "]", "\n", "for", "elem", "in", "tqdm", "(", "pool", ".", "imap_unordered", "(", "process", ",", "files", ")", ",", "total", "=", "len", "(", "files", ")", ")", ":", "\n", "        ", "results", ".", "append", "(", "elem", ")", "\n", "", "df", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "results", ")", "\n", "df", ".", "describe", "(", ")", "\n", "df", "=", "df", "[", "(", "(", "df", "[", "'len'", "]", ">", "lower", ")", "&", "df", "[", "'len'", "]", "<", "upper", ")", "]", "\n", "df", ".", "describe", "(", ")", "\n", "df", "=", "df", ".", "sample", "(", "frac", "=", "0.5", ")", "\n", "train", "=", "df", ".", "sample", "(", "frac", "=", "0.7", ",", "random_state", "=", "42", ")", "\n", "test", "=", "df", ".", "drop", "(", "train", ".", "index", ")", "\n", "\n", "train", ".", "to_json", "(", "'train-sample.json'", ",", "orient", "=", "'records'", ")", "\n", "test", ".", "to_json", "(", "'test-sample.json'", ",", "orient", "=", "'records'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.02-load.main": [[17, 40], ["configparser.ConfigParser", "configparser.ConfigParser.read", "pandarallel.pandarallel.initialize", "elasticsearch.Elasticsearch", "pandas.DataFrame", "archives[].parallel_apply", "glob.glob", "int", "gzip.open", "f.readlines", "json.loads", "elasticsearch.Elasticsearch.index"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "config", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "config", ".", "read", "(", "'config.ini'", ")", "\n", "\n", "pandarallel", ".", "initialize", "(", "nb_workers", "=", "int", "(", "config", "[", "'02-load'", "]", "[", "'Worker'", "]", ")", ",", "progress_bar", "=", "True", ")", "\n", "\n", "host", "=", "config", "[", "'elasticsearch'", "]", "[", "'Host'", "]", "\n", "port", "=", "config", "[", "'elasticsearch'", "]", "[", "'Port'", "]", "\n", "index_name", "=", "config", "[", "'elasticsearch'", "]", "[", "'IndexName'", "]", "\n", "\n", "es", "=", "Elasticsearch", "(", "host", ",", "port", "=", "port", ")", "\n", "\n", "archives", "=", "pd", ".", "DataFrame", "(", "glob", ".", "glob", "(", "config", "[", "'general'", "]", "[", "'ArchivePath'", "]", "+", "'*'", ")", ")", "\n", "\n", "def", "load", "(", "filename", ")", ":", "\n", "        ", "with", "gzip", ".", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "data", "=", "json", ".", "loads", "(", "line", ")", "\n", "es", ".", "index", "(", "index", "=", "index_name", ",", "body", "=", "data", ")", "\n", "", "", "return", "filename", "\n", "\n", "", "archives", "[", "0", "]", ".", "parallel_apply", "(", "load", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.07-tokenizer.main": [[19, 38], ["tokenizers.Tokenizer", "tokenizers.pre_tokenizers.PreTokenizer.custom", "logging.info", "logging.info", "list", "list", "tokenizers.trainers.WordPieceTrainer", "tokenizers.Tokenizer.train", "tokenizers.pre_tokenizers.Whitespace", "tokenizers.Tokenizer.save", "tokenizers.models.WordPiece", "JavaPreTokenizer.JavaPreTokenizer", "open", "json.load", "open", "json.load", "open", "map", "filter", "json.load", "os.path.isfile"], "function", ["None"], ["def", "main", "(", "file_name", ")", ":", "\n", "    ", "tokenizer", "=", "Tokenizer", "(", "WordPiece", "(", "unk_token", "=", "'[UNK]'", ")", ")", "\n", "tokenizer", ".", "pre_tokenizer", "=", "PreTokenizer", ".", "custom", "(", "JavaPreTokenizer", "(", ")", ")", "\n", "with", "open", "(", "'specials.json'", ")", "as", "fp", ":", "\n", "        ", "special_tokens", "=", "json", ".", "load", "(", "fp", ")", "\n", "\n", "", "logging", ".", "info", "(", "'loading file names'", ")", "\n", "with", "open", "(", "'train-sample.json'", ")", "as", "fp", ":", "\n", "        ", "files", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "with", "open", "(", "'test-sample.json'", ")", "as", "fp", ":", "\n", "        ", "files", "=", "files", "+", "json", ".", "load", "(", "fp", ")", "\n", "", "logging", ".", "info", "(", "'commence training'", ")", "\n", "\n", "mapped_files", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'filename'", "]", "+", "'utf-8'", ",", "files", ")", ")", "\n", "filtered_files", "=", "list", "(", "filter", "(", "lambda", "x", ":", "os", ".", "path", ".", "isfile", "(", "x", ")", ",", "mapped_files", ")", ")", "\n", "trainer", "=", "WordPieceTrainer", "(", "vocab_size", "=", "15000", ",", "special_tokens", "=", "special_tokens", ")", "\n", "tokenizer", ".", "train", "(", "filtered_files", ",", "trainer", "=", "trainer", ")", "\n", "tokenizer", ".", "pre_tokenizer", "=", "Whitespace", "(", ")", "\n", "tokenizer", ".", "save", "(", "file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.JavaPreTokenizer.JavaPreTokenizer.java_tokenize": [[7, 18], ["javalang.tokenizer.tokenize", "values.append", "len"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "java_tokenize", "(", "i", ",", "normalized_string", ")", ":", "\n", "        ", "values", "=", "[", "]", "\n", "try", ":", "\n", "            ", "for", "elem", "in", "javalang", ".", "tokenizer", ".", "tokenize", "(", "normalized_string", ".", "normalized", ")", ":", "\n", "                ", "start", "=", "elem", ".", "position", ".", "column", "-", "1", "\n", "stop", "=", "start", "+", "len", "(", "elem", ".", "value", ")", "\n", "values", ".", "append", "(", "normalized_string", "[", "start", ":", "stop", "]", ")", "\n", "", "", "except", ":", "\n", "            ", "values", "=", "[", "]", "\n", "", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.JavaPreTokenizer.JavaPreTokenizer.pre_tokenize": [[19, 21], ["pretok.split"], "methods", ["None"], ["", "def", "pre_tokenize", "(", "self", ",", "pretok", ")", ":", "\n", "        ", "pretok", ".", "split", "(", "self", ".", "java_tokenize", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.JavaDataset.JavaDataset._info": [[26, 38], ["datasets.Features", "datasets.DatasetInfo", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "        ", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"code\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "}", "\n", ")", "\n", "return", "datasets", ".", "DatasetInfo", "(", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "supervised_keys", "=", "None", ",", "\n", "homepage", "=", "_HOMEPAGE", ",", "\n", "license", "=", "_LICENSE", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.JavaDataset.JavaDataset._split_generators": [[40, 50], ["dl_manager.download_and_extract", "datasets.SplitGenerator"], "methods", ["None"], ["", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "my_files", "=", "self", ".", "config", ".", "data_files", "\n", "data_dir", "=", "dl_manager", ".", "download_and_extract", "(", "my_files", ")", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "data_dir", "[", "'train'", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n"]], "home.repos.pwc.inspect_result.cau-se_gh-archive-code-retrieval.None.JavaDataset.JavaDataset._generate_examples": [[54, 62], ["open", "str", "f.read", "hashlib.sha1", "filepath.encode"], "methods", ["None"], ["", "def", "_generate_examples", "(", "self", ",", "filepath", ",", "split", ")", ":", "\n", "        ", "\"\"\" Yields examples as (key, example) tuples. \"\"\"", "\n", "\n", "with", "open", "(", "filepath", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "id_", "=", "str", "(", "hashlib", ".", "sha1", "(", "filepath", ".", "encode", "(", "'utf-8'", ")", ")", ")", "\n", "data", "=", "f", ".", "read", "(", ")", "\n", "yield", "id_", ",", "{", "\n", "\"code\"", ":", "data", "\n", "}", "\n"]]}