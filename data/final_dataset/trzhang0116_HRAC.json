{"home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.Actor.__init__": [[7, 15], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "max_action", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "l1", "=", "nn", ".", "Linear", "(", "state_dim", "+", "goal_dim", ",", "300", ")", "\n", "self", ".", "l2", "=", "nn", ".", "Linear", "(", "300", ",", "300", ")", "\n", "self", ".", "l3", "=", "nn", ".", "Linear", "(", "300", ",", "action_dim", ")", "\n", "\n", "self", ".", "max_action", "=", "max_action", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.Actor.forward": [[16, 27], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "models.Actor.l2", "models.Actor.l1", "models.Actor.l1", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Actor.l3", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "models.Actor.l3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "g", "=", "None", ",", "nonlinearity", "=", "'tanh'", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "torch", ".", "cat", "(", "[", "x", ",", "g", "]", ",", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "x", ")", ")", "\n", "", "x", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "x", ")", ")", "\n", "if", "nonlinearity", "==", "'tanh'", ":", "\n", "            ", "x", "=", "self", ".", "max_action", "*", "torch", ".", "tanh", "(", "self", ".", "l3", "(", "x", ")", ")", "\n", "", "elif", "nonlinearity", "==", "'sigmoid'", ":", "\n", "            ", "x", "=", "self", ".", "max_action", "*", "torch", ".", "sigmoid", "(", "self", ".", "l3", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.Critic.__init__": [[30, 42], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Q1 architecture", "\n", "self", ".", "l1", "=", "nn", ".", "Linear", "(", "state_dim", "+", "goal_dim", "+", "action_dim", ",", "300", ")", "\n", "self", ".", "l2", "=", "nn", ".", "Linear", "(", "300", ",", "300", ")", "\n", "self", ".", "l3", "=", "nn", ".", "Linear", "(", "300", ",", "1", ")", "\n", "\n", "# Q2 architecture", "\n", "self", ".", "l4", "=", "nn", ".", "Linear", "(", "state_dim", "+", "goal_dim", "+", "action_dim", ",", "300", ")", "\n", "self", ".", "l5", "=", "nn", ".", "Linear", "(", "300", ",", "300", ")", "\n", "self", ".", "l6", "=", "nn", ".", "Linear", "(", "300", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.Critic.forward": [[43, 57], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "models.Critic.l3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "models.Critic.l6", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Critic.l1", "models.Critic.l2", "models.Critic.l4", "models.Critic.l5"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "g", "=", "None", ",", "u", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "x", ",", "g", ",", "u", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "x", ",", "u", "]", ",", "1", ")", "\n", "\n", "", "x1", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "xu", ")", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "x1", ")", ")", "\n", "x1", "=", "self", ".", "l3", "(", "x1", ")", "\n", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "l4", "(", "xu", ")", ")", "\n", "x2", "=", "F", ".", "relu", "(", "self", ".", "l5", "(", "x2", ")", ")", "\n", "x2", "=", "self", ".", "l6", "(", "x2", ")", "\n", "return", "x1", ",", "x2", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.Critic.Q1": [[58, 68], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "models.Critic.l3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.Critic.l1", "models.Critic.l2"], "methods", ["None"], ["", "def", "Q1", "(", "self", ",", "x", ",", "g", "=", "None", ",", "u", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "x", ",", "g", ",", "u", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "xu", "=", "torch", ".", "cat", "(", "[", "x", ",", "u", "]", ",", "1", ")", "\n", "\n", "", "x1", "=", "F", ".", "relu", "(", "self", ".", "l1", "(", "xu", ")", ")", "\n", "x1", "=", "F", ".", "relu", "(", "self", ".", "l2", "(", "x1", ")", ")", "\n", "x1", "=", "self", ".", "l3", "(", "x1", ")", "\n", "return", "x1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ControllerActor.__init__": [[71, 78], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "models.Actor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "scale", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "scale", "is", "None", ":", "\n", "            ", "scale", "=", "torch", ".", "ones", "(", "state_dim", ")", "\n", "", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "scale", ")", ".", "float", "(", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "actor", "=", "Actor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ControllerActor.forward": [[79, 81], ["models.ControllerActor.actor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "g", ")", ":", "\n", "        ", "return", "self", ".", "scale", "*", "self", ".", "actor", "(", "x", ",", "g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ControllerCritic.__init__": [[84, 88], ["torch.Module.__init__", "models.Critic"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "critic", "=", "Critic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ControllerCritic.forward": [[89, 91], ["models.ControllerCritic.critic"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sg", ",", "u", ")", ":", "\n", "        ", "return", "self", ".", "critic", "(", "x", ",", "sg", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ControllerCritic.Q1": [[92, 94], ["models.ControllerCritic.critic.Q1"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.Q1"], ["", "def", "Q1", "(", "self", ",", "x", ",", "sg", ",", "u", ")", ":", "\n", "        ", "return", "self", ".", "critic", ".", "Q1", "(", "x", ",", "sg", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerActor.__init__": [[97, 104], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "models.Actor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "scale", "=", "None", ",", "absolute_goal", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "scale", "is", "None", ":", "\n", "            ", "scale", "=", "torch", ".", "ones", "(", "action_dim", ")", "\n", "", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "scale", "[", ":", "action_dim", "]", ")", ".", "float", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "actor", "=", "Actor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "1", ")", "\n", "self", ".", "absolute_goal", "=", "absolute_goal", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerActor.forward": [[105, 110], ["models.ManagerActor.actor", "models.ManagerActor.actor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "g", ")", ":", "\n", "        ", "if", "self", ".", "absolute_goal", ":", "\n", "            ", "return", "self", ".", "scale", "*", "self", ".", "actor", "(", "x", ",", "g", ",", "nonlinearity", "=", "'sigmoid'", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "scale", "*", "self", ".", "actor", "(", "x", ",", "g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.__init__": [[113, 116], ["torch.Module.__init__", "models.Critic"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "critic", "=", "Critic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.forward": [[117, 119], ["models.ManagerCritic.critic"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "g", ",", "u", ")", ":", "\n", "        ", "return", "self", ".", "critic", "(", "x", ",", "g", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.Q1": [[120, 122], ["models.ManagerCritic.critic.Q1"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.Q1"], ["", "def", "Q1", "(", "self", ",", "x", ",", "g", ",", "u", ")", ":", "\n", "        ", "return", "self", ".", "critic", ".", "Q1", "(", "x", ",", "g", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ANet.__init__": [[126, 132], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "hidden_dim", ",", "embedding_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "state_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc4", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ANet.forward": [[133, 139], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "models.ANet.fc4", "models.ANet.fc1", "models.ANet.fc2", "models.ANet.fc3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc3", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc4", "(", "x", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.__init__": [[36, 67], ["hrac.models.ManagerActor().to", "hrac.models.ManagerActor().to", "hrac.Manager.actor_target.load_state_dict", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "hrac.models.ManagerCritic().to", "hrac.models.ManagerCritic().to", "hrac.Manager.critic_target.load_state_dict", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "hrac.Manager.actor.state_dict", "hrac.Manager.actor.parameters", "hrac.Manager.critic.state_dict", "hrac.Manager.critic.parameters", "hrac.models.ManagerActor", "hrac.models.ManagerActor", "hrac.models.ManagerCritic", "hrac.models.ManagerCritic"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "actor_lr", ",", "\n", "critic_lr", ",", "candidate_goals", ",", "correction", "=", "True", ",", "\n", "scale", "=", "10", ",", "actions_norm_reg", "=", "0", ",", "policy_noise", "=", "0.2", ",", "\n", "noise_clip", "=", "0.5", ",", "goal_loss_coeff", "=", "0", ",", "absolute_goal", "=", "False", ")", ":", "\n", "        ", "self", ".", "scale", "=", "scale", "\n", "self", ".", "actor", "=", "ManagerActor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "\n", "scale", "=", "scale", ",", "absolute_goal", "=", "absolute_goal", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "actor_target", "=", "ManagerActor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "\n", "scale", "=", "scale", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "actor_target", ".", "load_state_dict", "(", "self", ".", "actor", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "actor_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "lr", "=", "actor_lr", ")", "\n", "\n", "self", ".", "critic", "=", "ManagerCritic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "critic_target", "=", "ManagerCritic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "critic_target", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "critic_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "critic_lr", ",", "weight_decay", "=", "0.0001", ")", "\n", "\n", "self", ".", "action_norm_reg", "=", "0", "\n", "\n", "self", ".", "criterion", "=", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "# self.criterion = nn.MSELoss()", "\n", "self", ".", "state_dim", "=", "state_dim", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "candidate_goals", "=", "candidate_goals", "\n", "self", ".", "correction", "=", "correction", "\n", "self", ".", "policy_noise", "=", "policy_noise", "\n", "self", ".", "noise_clip", "=", "noise_clip", "\n", "self", ".", "goal_loss_coeff", "=", "goal_loss_coeff", "\n", "self", ".", "absolute_goal", "=", "absolute_goal", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_eval": [[68, 71], ["hrac.Manager.actor.set_eval", "hrac.Manager.actor_target.set_eval"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_eval", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_eval"], ["", "def", "set_eval", "(", "self", ")", ":", "\n", "        ", "self", ".", "actor", ".", "set_eval", "(", ")", "\n", "self", ".", "actor_target", ".", "set_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_train": [[72, 75], ["hrac.Manager.actor.set_train", "hrac.Manager.actor_target.set_train"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_train", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.set_train"], ["", "def", "set_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "actor", ".", "set_train", "(", ")", "\n", "self", ".", "actor_target", ".", "set_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.sample_goal": [[76, 84], ["hrac.get_tensor", "hrac.get_tensor", "hrac.Manager.actor().cpu().data.numpy().squeeze", "hrac.Manager.actor().squeeze", "hrac.Manager.actor().cpu().data.numpy", "hrac.Manager.actor", "hrac.Manager.actor().cpu", "hrac.Manager.actor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor"], ["", "def", "sample_goal", "(", "self", ",", "state", ",", "goal", ",", "to_numpy", "=", "True", ")", ":", "\n", "        ", "state", "=", "get_tensor", "(", "state", ")", "\n", "goal", "=", "get_tensor", "(", "goal", ")", "\n", "\n", "if", "to_numpy", ":", "\n", "            ", "return", "self", ".", "actor", "(", "state", ",", "goal", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "actor", "(", "state", ",", "goal", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.value_estimate": [[85, 87], ["hrac.Manager.critic"], "methods", ["None"], ["", "", "def", "value_estimate", "(", "self", ",", "state", ",", "goal", ",", "subgoal", ")", ":", "\n", "        ", "return", "self", ".", "critic", "(", "state", ",", "goal", ",", "subgoal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.actor_loss": [[88, 98], ["hrac.Manager.actor", "hrac.Manager.critic.Q1().mean", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "hrac.Manager.critic.Q1", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "a_net", "a_net"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.Q1"], ["", "def", "actor_loss", "(", "self", ",", "state", ",", "goal", ",", "a_net", ",", "r_margin", ")", ":", "\n", "        ", "actions", "=", "self", ".", "actor", "(", "state", ",", "goal", ")", "\n", "eval", "=", "-", "self", ".", "critic", ".", "Q1", "(", "state", ",", "goal", ",", "actions", ")", ".", "mean", "(", ")", "\n", "norm", "=", "torch", ".", "norm", "(", "actions", ")", "*", "self", ".", "action_norm_reg", "\n", "if", "a_net", "is", "None", ":", "\n", "            ", "return", "eval", "+", "norm", "\n", "", "else", ":", "\n", "            ", "goal_loss", "=", "torch", ".", "clamp", "(", "F", ".", "pairwise_distance", "(", "\n", "a_net", "(", "state", "[", ":", ",", ":", "self", ".", "action_dim", "]", ")", ",", "a_net", "(", "state", "[", ":", ",", ":", "self", ".", "action_dim", "]", "+", "actions", ")", ")", "-", "r_margin", ",", "min", "=", "0.", ")", ".", "mean", "(", ")", "\n", "return", "eval", "+", "norm", ",", "goal_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.off_policy_corrections": [[99, 144], ["numpy.random.normal", "random_goals.clip.clip.clip", "numpy.concatenate", "numpy.array", "len", "numpy.array.reshape", "x_seq.reshape", "numpy.zeros", "range", "numpy.where", "difference.reshape().transpose.reshape().transpose.reshape().transpose", "numpy.argmax", "numpy.array", "numpy.array", "controller_policy.multi_subgoal_transition", "candidate.reshape.reshape.reshape", "controller_policy.select_action", "numpy.sum", "numpy.array", "numpy.array", "difference.reshape().transpose.reshape().transpose.reshape", "numpy.linalg.norm", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.multi_subgoal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.select_action"], ["", "", "def", "off_policy_corrections", "(", "self", ",", "controller_policy", ",", "batch_size", ",", "subgoals", ",", "x_seq", ",", "a_seq", ")", ":", "\n", "        ", "first_x", "=", "[", "x", "[", "0", "]", "for", "x", "in", "x_seq", "]", "\n", "last_x", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "x_seq", "]", "\n", "\n", "# Shape: (batchsz, 1, subgoal_dim)", "\n", "diff_goal", "=", "(", "np", ".", "array", "(", "last_x", ")", "-", "np", ".", "array", "(", "first_x", ")", ")", "[", ":", ",", "np", ".", "newaxis", ",", ":", "self", ".", "action_dim", "]", "\n", "\n", "# Shape: (batchsz, 1, subgoal_dim)", "\n", "original_goal", "=", "np", ".", "array", "(", "subgoals", ")", "[", ":", ",", "np", ".", "newaxis", ",", ":", "]", "\n", "random_goals", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "diff_goal", ",", "scale", "=", ".5", "*", "self", ".", "scale", "[", "None", ",", "None", ",", ":", "self", ".", "action_dim", "]", ",", "\n", "size", "=", "(", "batch_size", ",", "self", ".", "candidate_goals", ",", "original_goal", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "random_goals", "=", "random_goals", ".", "clip", "(", "-", "self", ".", "scale", "[", ":", "self", ".", "action_dim", "]", ",", "self", ".", "scale", "[", ":", "self", ".", "action_dim", "]", ")", "\n", "\n", "# Shape: (batchsz, 10, subgoal_dim)", "\n", "candidates", "=", "np", ".", "concatenate", "(", "[", "original_goal", ",", "diff_goal", ",", "random_goals", "]", ",", "axis", "=", "1", ")", "\n", "# print(np.array(x_seq).shape)", "\n", "x_seq", "=", "np", ".", "array", "(", "x_seq", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", "a_seq", "=", "np", ".", "array", "(", "a_seq", ")", "\n", "seq_len", "=", "len", "(", "x_seq", "[", "0", "]", ")", "\n", "\n", "# For ease", "\n", "new_batch_sz", "=", "seq_len", "*", "batch_size", "\n", "action_dim", "=", "a_seq", "[", "0", "]", "[", "0", "]", ".", "shape", "\n", "obs_dim", "=", "x_seq", "[", "0", "]", "[", "0", "]", ".", "shape", "\n", "ncands", "=", "candidates", ".", "shape", "[", "1", "]", "\n", "\n", "true_actions", "=", "a_seq", ".", "reshape", "(", "(", "new_batch_sz", ",", ")", "+", "action_dim", ")", "\n", "observations", "=", "x_seq", ".", "reshape", "(", "(", "new_batch_sz", ",", ")", "+", "obs_dim", ")", "\n", "goal_shape", "=", "(", "new_batch_sz", ",", "self", ".", "action_dim", ")", "\n", "\n", "policy_actions", "=", "np", ".", "zeros", "(", "(", "ncands", ",", "new_batch_sz", ")", "+", "action_dim", ")", "\n", "\n", "for", "c", "in", "range", "(", "ncands", ")", ":", "\n", "            ", "candidate", "=", "controller_policy", ".", "multi_subgoal_transition", "(", "x_seq", ",", "candidates", "[", ":", ",", "c", "]", ")", "\n", "candidate", "=", "candidate", ".", "reshape", "(", "*", "goal_shape", ")", "\n", "policy_actions", "[", "c", "]", "=", "controller_policy", ".", "select_action", "(", "observations", ",", "candidate", ")", "\n", "\n", "", "difference", "=", "(", "policy_actions", "-", "true_actions", ")", "\n", "difference", "=", "np", ".", "where", "(", "difference", "!=", "-", "np", ".", "inf", ",", "difference", ",", "0", ")", "\n", "difference", "=", "difference", ".", "reshape", "(", "(", "ncands", ",", "batch_size", ",", "seq_len", ")", "+", "action_dim", ")", ".", "transpose", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "logprob", "=", "-", "0.5", "*", "np", ".", "sum", "(", "np", ".", "linalg", ".", "norm", "(", "difference", ",", "axis", "=", "-", "1", ")", "**", "2", ",", "axis", "=", "-", "1", ")", "\n", "max_indices", "=", "np", ".", "argmax", "(", "logprob", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "candidates", "[", "np", ".", "arange", "(", "batch_size", ")", ",", "max_indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.train": [[145, 225], ["range", "replay_buffer.sample", "min", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "noise.clamp.clamp.clamp", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "hrac.Manager.critic_target", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min.detach", "torch.min.detach", "torch.min.detach", "hrac.Manager.value_estimate", "hrac.Manager.critic_optimizer.zero_grad", "critic_loss.backward", "hrac.Manager.critic_optimizer.step", "hrac.Manager.actor_optimizer.zero_grad", "hrac.Manager.backward", "hrac.Manager.actor_optimizer.step", "zip", "zip", "hrac.Manager.off_policy_corrections", "hrac.Manager.actor_target", "hrac.Manager.criterion", "hrac.Manager.criterion", "hrac.Manager.actor_loss", "hrac.Manager.actor_loss", "hrac.Manager.critic.parameters", "hrac.Manager.critic_target.parameters", "target_param.data.copy_", "hrac.Manager.actor.parameters", "hrac.Manager.actor_target.parameters", "target_param.data.copy_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.sample", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.value_estimate", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.off_policy_corrections", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.actor_loss", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.actor_loss"], ["", "def", "train", "(", "self", ",", "controller_policy", ",", "replay_buffer", ",", "iterations", ",", "batch_size", "=", "100", ",", "discount", "=", "0.99", ",", "\n", "tau", "=", "0.005", ",", "a_net", "=", "None", ",", "r_margin", "=", "None", ")", ":", "\n", "        ", "avg_act_loss", ",", "avg_crit_loss", "=", "0.", ",", "0.", "\n", "if", "a_net", "is", "not", "None", ":", "\n", "            ", "avg_goal_loss", "=", "0.", "\n", "", "for", "it", "in", "range", "(", "iterations", ")", ":", "\n", "# Sample replay buffer", "\n", "            ", "x", ",", "y", ",", "g", ",", "sgorig", ",", "r", ",", "d", ",", "xobs_seq", ",", "a_seq", "=", "replay_buffer", ".", "sample", "(", "batch_size", ")", "\n", "batch_size", "=", "min", "(", "batch_size", ",", "x", ".", "shape", "[", "0", "]", ")", "\n", "\n", "if", "self", ".", "correction", "and", "not", "self", ".", "absolute_goal", ":", "\n", "                ", "sg", "=", "self", ".", "off_policy_corrections", "(", "controller_policy", ",", "batch_size", ",", "\n", "sgorig", ",", "xobs_seq", ",", "a_seq", ")", "\n", "", "else", ":", "\n", "                ", "sg", "=", "sgorig", "\n", "\n", "", "state", "=", "get_tensor", "(", "x", ")", "\n", "next_state", "=", "get_tensor", "(", "y", ")", "\n", "# print(g)", "\n", "goal", "=", "get_tensor", "(", "g", ")", "\n", "subgoal", "=", "get_tensor", "(", "sg", ")", "\n", "\n", "reward", "=", "get_tensor", "(", "r", ")", "\n", "done", "=", "get_tensor", "(", "1", "-", "d", ")", "\n", "\n", "noise", "=", "torch", ".", "FloatTensor", "(", "sgorig", ")", ".", "data", ".", "normal_", "(", "0", ",", "self", ".", "policy_noise", ")", ".", "to", "(", "device", ")", "\n", "noise", "=", "noise", ".", "clamp", "(", "-", "self", ".", "noise_clip", ",", "self", ".", "noise_clip", ")", "\n", "next_action", "=", "(", "self", ".", "actor_target", "(", "next_state", ",", "goal", ")", "+", "noise", ")", "\n", "next_action", "=", "torch", ".", "min", "(", "next_action", ",", "self", ".", "actor", ".", "scale", ")", "\n", "next_action", "=", "torch", ".", "max", "(", "next_action", ",", "-", "self", ".", "actor", ".", "scale", ")", "\n", "\n", "target_Q1", ",", "target_Q2", "=", "self", ".", "critic_target", "(", "next_state", ",", "goal", ",", "\n", "next_action", ")", "\n", "\n", "target_Q", "=", "torch", ".", "min", "(", "target_Q1", ",", "target_Q2", ")", "\n", "target_Q", "=", "reward", "+", "(", "done", "*", "discount", "*", "target_Q", ")", "\n", "target_Q_no_grad", "=", "target_Q", ".", "detach", "(", ")", "\n", "\n", "# Get current Q estimate", "\n", "current_Q1", ",", "current_Q2", "=", "self", ".", "value_estimate", "(", "state", ",", "goal", ",", "subgoal", ")", "\n", "\n", "# Compute critic loss", "\n", "critic_loss", "=", "self", ".", "criterion", "(", "current_Q1", ",", "target_Q_no_grad", ")", "+", "self", ".", "criterion", "(", "current_Q2", ",", "target_Q_no_grad", ")", "\n", "\n", "# Optimize the critic", "\n", "self", ".", "critic_optimizer", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optimizer", ".", "step", "(", ")", "\n", "\n", "# Compute actor loss", "\n", "if", "a_net", "is", "None", ":", "\n", "                ", "actor_loss", "=", "self", ".", "actor_loss", "(", "state", ",", "goal", ",", "a_net", ",", "r_margin", ")", "\n", "", "else", ":", "\n", "                ", "actor_loss", ",", "goal_loss", "=", "self", ".", "actor_loss", "(", "state", ",", "goal", ",", "a_net", ",", "r_margin", ")", "\n", "actor_loss", "=", "actor_loss", "+", "self", ".", "goal_loss_coeff", "*", "goal_loss", "\n", "\n", "# Optimize the actor", "\n", "", "self", ".", "actor_optimizer", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "self", ".", "actor_optimizer", ".", "step", "(", ")", "\n", "\n", "avg_act_loss", "+=", "actor_loss", "\n", "avg_crit_loss", "+=", "critic_loss", "\n", "if", "a_net", "is", "not", "None", ":", "\n", "                ", "avg_goal_loss", "+=", "goal_loss", "\n", "\n", "# Update the frozen target models", "\n", "", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "\n", "self", ".", "critic_target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "target_param", ".", "data", ".", "copy_", "(", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n", "", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "\n", "self", ".", "actor_target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "target_param", ".", "data", ".", "copy_", "(", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n", "", "", "if", "a_net", "is", "None", ":", "\n", "            ", "return", "avg_act_loss", "/", "iterations", ",", "avg_crit_loss", "/", "iterations", "\n", "", "else", ":", "\n", "            ", "return", "avg_act_loss", "/", "iterations", ",", "avg_crit_loss", "/", "iterations", ",", "avg_goal_loss", "/", "iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.load_pretrained_weights": [[226, 231], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "hrac.Manager.actor.encoder.load_state_dict", "hrac.Manager.actor_target.encoder.load_state_dict", "print"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load"], ["", "", "def", "load_pretrained_weights", "(", "self", ",", "filename", ")", ":", "\n", "        ", "state", "=", "torch", ".", "load", "(", "filename", ")", "\n", "self", ".", "actor", ".", "encoder", ".", "load_state_dict", "(", "state", ")", "\n", "self", ".", "actor_target", ".", "encoder", ".", "load_state_dict", "(", "state", ")", "\n", "print", "(", "\"Successfully loaded Manager encoder.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.save": [[232, 237], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "hrac.Manager.actor.state_dict", "hrac.Manager.critic.state_dict", "hrac.Manager.actor_target.state_dict", "hrac.Manager.critic_target.state_dict"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save"], ["", "def", "save", "(", "self", ",", "dir", ",", "env_name", ",", "algo", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "actor", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ManagerActor.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ManagerCritic.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "actor_target", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ManagerActorTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic_target", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ManagerCriticTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "# torch.save(self.actor_optimizer.state_dict(), \"{}/{}_{}_ManagerActorOptim.pth\".format(dir, env_name, algo))", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.load": [[240, 245], ["hrac.Manager.actor.load_state_dict", "hrac.Manager.critic.load_state_dict", "hrac.Manager.actor_target.load_state_dict", "hrac.Manager.critic_target.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load"], ["", "def", "load", "(", "self", ",", "dir", ",", "env_name", ",", "algo", ")", ":", "\n", "        ", "self", ".", "actor", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ManagerActor.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ManagerCritic.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "actor_target", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ManagerActorTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "critic_target", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ManagerCriticTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "# self.actor_optimizer.load_state_dict(torch.load(\"{}/{}_{}_ManagerActorOptim.pth\".format(dir, env_name, algo)))", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.__init__": [[250, 278], ["torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "hrac.models.ControllerActor().to", "hrac.models.ControllerActor().to", "hrac.Controller.actor_target.load_state_dict", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "hrac.models.ControllerCritic().to", "hrac.models.ControllerCritic().to", "hrac.Controller.critic_target.load_state_dict", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "hrac.Controller.actor.state_dict", "hrac.Controller.actor.parameters", "hrac.Controller.critic.state_dict", "hrac.Controller.critic.parameters", "hrac.models.ControllerActor", "hrac.models.ControllerActor", "hrac.models.ControllerCritic", "hrac.models.ControllerCritic"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "max_action", ",", "actor_lr", ",", "\n", "critic_lr", ",", "repr_dim", "=", "15", ",", "no_xy", "=", "True", ",", "policy_noise", "=", "0.2", ",", "noise_clip", "=", "0.5", ",", "\n", "absolute_goal", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "state_dim", "=", "state_dim", "\n", "self", ".", "goal_dim", "=", "goal_dim", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "max_action", "=", "max_action", "\n", "self", ".", "no_xy", "=", "no_xy", "\n", "self", ".", "policy_noise", "=", "policy_noise", "\n", "self", ".", "noise_clip", "=", "noise_clip", "\n", "self", ".", "absolute_goal", "=", "absolute_goal", "\n", "self", ".", "criterion", "=", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "# self.criterion = nn.MSELoss()", "\n", "\n", "self", ".", "actor", "=", "ControllerActor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "\n", "scale", "=", "max_action", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "actor_target", "=", "ControllerActor", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "\n", "scale", "=", "max_action", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "actor_target", ".", "load_state_dict", "(", "self", ".", "actor", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "actor_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "actor_lr", ")", "\n", "\n", "self", ".", "critic", "=", "ControllerCritic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "critic_target", "=", "ControllerCritic", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "critic_target", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "critic_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "critic_lr", ",", "weight_decay", "=", "0.0001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.clean_obs": [[280, 294], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "len", "len", "len"], "methods", ["None"], ["", "def", "clean_obs", "(", "self", ",", "state", ",", "dims", "=", "2", ")", ":", "\n", "        ", "if", "self", ".", "no_xy", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mask", "=", "torch", ".", "ones_like", "(", "state", ")", "\n", "if", "len", "(", "state", ".", "shape", ")", "==", "3", ":", "\n", "                    ", "mask", "[", ":", ",", ":", ",", ":", "dims", "]", "=", "0", "\n", "", "elif", "len", "(", "state", ".", "shape", ")", "==", "2", ":", "\n", "                    ", "mask", "[", ":", ",", ":", "dims", "]", "=", "0", "\n", "", "elif", "len", "(", "state", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "mask", "[", ":", "dims", "]", "=", "0", "\n", "\n", "", "return", "state", "*", "mask", "\n", "", "", "else", ":", "\n", "            ", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.select_action": [[295, 299], ["hrac.Controller.clean_obs", "hrac.get_tensor", "hrac.Controller.actor().cpu().data.numpy().squeeze", "hrac.get_tensor", "hrac.Controller.actor().cpu().data.numpy", "hrac.Controller.actor().cpu", "hrac.Controller.actor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.clean_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor"], ["", "", "def", "select_action", "(", "self", ",", "state", ",", "sg", ",", "evaluation", "=", "False", ")", ":", "\n", "        ", "state", "=", "self", ".", "clean_obs", "(", "get_tensor", "(", "state", ")", ")", "\n", "sg", "=", "get_tensor", "(", "sg", ")", "\n", "return", "self", ".", "actor", "(", "state", ",", "sg", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.value_estimate": [[300, 305], ["hrac.Controller.clean_obs", "hrac.get_tensor", "hrac.get_tensor", "hrac.Controller.critic", "hrac.get_tensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.clean_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor"], ["", "def", "value_estimate", "(", "self", ",", "state", ",", "sg", ",", "action", ")", ":", "\n", "        ", "state", "=", "self", ".", "clean_obs", "(", "get_tensor", "(", "state", ")", ")", "\n", "sg", "=", "get_tensor", "(", "sg", ")", "\n", "action", "=", "get_tensor", "(", "action", ")", "\n", "return", "self", ".", "critic", "(", "state", ",", "sg", ",", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.actor_loss": [[306, 308], ["hrac.Controller.critic.Q1().mean", "hrac.Controller.critic.Q1", "hrac.Controller.actor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.models.ManagerCritic.Q1"], ["", "def", "actor_loss", "(", "self", ",", "state", ",", "sg", ")", ":", "\n", "        ", "return", "-", "self", ".", "critic", ".", "Q1", "(", "state", ",", "sg", ",", "self", ".", "actor", "(", "state", ",", "sg", ")", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.subgoal_transition": [[309, 318], ["len"], "methods", ["None"], ["", "def", "subgoal_transition", "(", "self", ",", "state", ",", "subgoal", ",", "next_state", ")", ":", "\n", "        ", "if", "self", ".", "absolute_goal", ":", "\n", "            ", "return", "subgoal", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "state", ".", "shape", ")", "==", "1", ":", "# check if batched", "\n", "                ", "return", "state", "[", ":", "self", ".", "goal_dim", "]", "+", "subgoal", "-", "next_state", "[", ":", "self", ".", "goal_dim", "]", "\n", "", "else", ":", "\n", "                ", "return", "state", "[", ":", ",", ":", "self", ".", "goal_dim", "]", "+", "subgoal", "-", "next_state", "[", ":", ",", ":", "self", ".", "goal_dim", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.multi_subgoal_transition": [[319, 323], ["None"], "methods", ["None"], ["", "", "", "def", "multi_subgoal_transition", "(", "self", ",", "states", ",", "subgoal", ")", ":", "\n", "        ", "subgoals", "=", "(", "subgoal", "+", "states", "[", ":", ",", "0", ",", ":", "self", ".", "goal_dim", "]", ")", "[", ":", ",", "None", "]", "-", "states", "[", ":", ",", ":", ",", ":", "self", ".", "goal_dim", "]", "\n", "return", "subgoals", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.train": [[324, 378], ["range", "replay_buffer.sample", "hrac.get_tensor", "hrac.Controller.clean_obs", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "hrac.get_tensor", "hrac.Controller.clean_obs", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "torch.FloatTensor().data.normal_().to", "noise.clamp.clamp.clamp", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "hrac.Controller.critic_target", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min.detach", "torch.min.detach", "torch.min.detach", "hrac.Controller.critic", "hrac.Controller.critic_optimizer.zero_grad", "critic_loss.backward", "hrac.Controller.critic_optimizer.step", "hrac.Controller.actor_loss", "hrac.Controller.actor_optimizer.zero_grad", "hrac.Controller.backward", "hrac.Controller.actor_optimizer.step", "zip", "zip", "hrac.Controller.subgoal_transition", "hrac.get_tensor", "hrac.get_tensor", "hrac.Controller.actor_target", "hrac.Controller.criterion", "hrac.Controller.criterion", "hrac.Controller.critic.parameters", "hrac.Controller.critic_target.parameters", "target_param.data.copy_", "hrac.Controller.actor.parameters", "hrac.Controller.actor_target.parameters", "target_param.data.copy_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor().data.normal_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.sample", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.clean_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.clean_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.actor_loss", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.subgoal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor"], ["", "def", "train", "(", "self", ",", "replay_buffer", ",", "iterations", ",", "batch_size", "=", "100", ",", "discount", "=", "0.99", ",", "tau", "=", "0.005", ")", ":", "\n", "        ", "avg_act_loss", ",", "avg_crit_loss", "=", "0.", ",", "0.", "\n", "for", "it", "in", "range", "(", "iterations", ")", ":", "\n", "            ", "x", ",", "y", ",", "sg", ",", "u", ",", "r", ",", "d", ",", "_", ",", "_", "=", "replay_buffer", ".", "sample", "(", "batch_size", ")", "\n", "next_g", "=", "get_tensor", "(", "self", ".", "subgoal_transition", "(", "x", ",", "sg", ",", "y", ")", ")", "\n", "state", "=", "self", ".", "clean_obs", "(", "get_tensor", "(", "x", ")", ")", "\n", "action", "=", "get_tensor", "(", "u", ")", "\n", "sg", "=", "get_tensor", "(", "sg", ")", "\n", "done", "=", "get_tensor", "(", "1", "-", "d", ")", "\n", "reward", "=", "get_tensor", "(", "r", ")", "\n", "next_state", "=", "self", ".", "clean_obs", "(", "get_tensor", "(", "y", ")", ")", "\n", "\n", "noise", "=", "torch", ".", "FloatTensor", "(", "u", ")", ".", "data", ".", "normal_", "(", "0", ",", "self", ".", "policy_noise", ")", ".", "to", "(", "device", ")", "\n", "noise", "=", "noise", ".", "clamp", "(", "-", "self", ".", "noise_clip", ",", "self", ".", "noise_clip", ")", "\n", "next_action", "=", "(", "self", ".", "actor_target", "(", "next_state", ",", "next_g", ")", "+", "noise", ")", "\n", "next_action", "=", "torch", ".", "min", "(", "next_action", ",", "self", ".", "actor", ".", "scale", ")", "\n", "next_action", "=", "torch", ".", "max", "(", "next_action", ",", "-", "self", ".", "actor", ".", "scale", ")", "\n", "\n", "target_Q1", ",", "target_Q2", "=", "self", ".", "critic_target", "(", "next_state", ",", "next_g", ",", "next_action", ")", "\n", "target_Q", "=", "torch", ".", "min", "(", "target_Q1", ",", "target_Q2", ")", "\n", "target_Q", "=", "reward", "+", "(", "done", "*", "discount", "*", "target_Q", ")", "\n", "target_Q_no_grad", "=", "target_Q", ".", "detach", "(", ")", "\n", "\n", "# Get current Q estimate", "\n", "current_Q1", ",", "current_Q2", "=", "self", ".", "critic", "(", "state", ",", "sg", ",", "action", ")", "\n", "\n", "# Compute critic loss", "\n", "critic_loss", "=", "self", ".", "criterion", "(", "current_Q1", ",", "target_Q_no_grad", ")", "+", "self", ".", "criterion", "(", "current_Q2", ",", "target_Q_no_grad", ")", "\n", "\n", "# Optimize the critic", "\n", "self", ".", "critic_optimizer", ".", "zero_grad", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "self", ".", "critic_optimizer", ".", "step", "(", ")", "\n", "\n", "# Compute actor loss", "\n", "actor_loss", "=", "self", ".", "actor_loss", "(", "state", ",", "sg", ")", "\n", "\n", "# Optimize the actor", "\n", "self", ".", "actor_optimizer", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "self", ".", "actor_optimizer", ".", "step", "(", ")", "\n", "\n", "avg_act_loss", "+=", "actor_loss", "\n", "avg_crit_loss", "+=", "critic_loss", "\n", "\n", "# Update the target models", "\n", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "self", ".", "critic_target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "target_param", ".", "data", ".", "copy_", "(", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n", "", "for", "param", ",", "target_param", "in", "zip", "(", "self", ".", "actor", ".", "parameters", "(", ")", ",", "self", ".", "actor_target", ".", "parameters", "(", ")", ")", ":", "\n", "                ", "target_param", ".", "data", ".", "copy_", "(", "tau", "*", "param", ".", "data", "+", "(", "1", "-", "tau", ")", "*", "target_param", ".", "data", ")", "\n", "\n", "", "", "return", "avg_act_loss", "/", "iterations", ",", "avg_crit_loss", "/", "iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.save": [[379, 384], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "hrac.Controller.actor.state_dict", "hrac.Controller.critic.state_dict", "hrac.Controller.actor_target.state_dict", "hrac.Controller.critic_target.state_dict"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save"], ["", "def", "save", "(", "self", ",", "dir", ",", "env_name", ",", "algo", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "actor", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ControllerActor.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ControllerCritic.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "actor_target", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ControllerActorTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "critic_target", ".", "state_dict", "(", ")", ",", "\"{}/{}_{}_ControllerCriticTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", "\n", "# torch.save(self.actor_optimizer.state_dict(), \"{}/{}_{}_ControllerActorOptim.pth\".format(dir, env_name, algo))", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.load": [[387, 392], ["hrac.Controller.actor.load_state_dict", "hrac.Controller.critic.load_state_dict", "hrac.Controller.actor_target.load_state_dict", "hrac.Controller.critic_target.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load"], ["", "def", "load", "(", "self", ",", "dir", ",", "env_name", ",", "algo", ")", ":", "\n", "        ", "self", ".", "actor", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ControllerActor.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ControllerCritic.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "actor_target", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ControllerActorTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "self", ".", "critic_target", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"{}/{}_{}_ControllerCriticTarget.pth\"", ".", "format", "(", "dir", ",", "env_name", ",", "algo", ")", ")", ")", "\n", "# self.actor_optimizer.load_state_dict(torch.load(\"{}/{}_{}_ControllerActorOptim.pth\".format(dir, env_name, algo)))", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.var": [[20, 22], ["tensor.to"], "function", ["None"], ["def", "var", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.get_tensor": [[24, 33], ["numpy.dtype", "len", "var().unsqueeze", "hrac.var", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "hrac.var", "z.copy", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "z.copy"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.var", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.var"], ["", "def", "get_tensor", "(", "z", ")", ":", "\n", "    ", "if", "z", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "z", "[", "0", "]", ".", "dtype", "==", "np", ".", "dtype", "(", "\"O\"", ")", ":", "\n", "        ", "return", "None", "\n", "", "if", "len", "(", "z", ".", "shape", ")", "==", "1", ":", "\n", "        ", "return", "var", "(", "torch", ".", "FloatTensor", "(", "z", ".", "copy", "(", ")", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "var", "(", "torch", ".", "FloatTensor", "(", "z", ".", "copy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.eval.evaluate_policy": [[12, 71], ["print", "torch.no_grad", "range", "print", "print", "print", "print", "env.reset", "print", "print", "controller_policy.select_action", "env.step", "controller_policy.subgoal_transition", "calculate_controller_reward", "manager_policy.sample_goal", "env.success_fn"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.select_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.subgoal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.sample_goal"], ["parser", ".", "add_argument", "(", "\"--env_name\"", ",", "default", "=", "\"AntMaze\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_episodes\"", ",", "default", "=", "100", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--load\"", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_dir\"", ",", "default", "=", "\"./pretrained_models\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--manager_propose_freq\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--absolute_goal\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--binary_int_reward\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "eval_hrac", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.eval.get_reward_function": [[73, 100], ["float", "numpy.linalg.norm", "numpy.linalg.norm", "float", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], []], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.eval.eval_hrac": [[102, 195], ["numpy.array", "float", "envs.EnvWithGoal.reset", "torch.cuda.set_device", "torch.device", "torch.manual_seed", "numpy.random.seed", "hrac.Controller", "hrac.Manager", "eval.get_reward_function", "eval.evaluate_policy", "envs.GatherEnv", "envs.EnvWithGoal.seed", "envs.create_gather_env.create_gather_env", "envs.EnvWithGoal", "envs.EnvWithGoal.seed", "torch.cuda.is_available", "hrac.Manager.load", "hrac.Controller.load", "print", "envs.create_maze_env.create_maze_env", "print"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.get_reward_function", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.evaluate_policy", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_gather_env.create_gather_env", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_maze_env.create_maze_env"], []], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.evaluate_policy": [[25, 84], ["print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "print", "print", "print", "print", "env.reset", "print", "print", "controller_policy.select_action", "env.step", "controller_policy.subgoal_transition", "calculate_controller_reward", "manager_policy.sample_goal", "env.success_fn"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.select_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.subgoal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.sample_goal"], ["def", "evaluate_policy", "(", "env", ",", "env_name", ",", "manager_policy", ",", "controller_policy", ",", "\n", "calculate_controller_reward", ",", "ctrl_rew_scale", ",", "\n", "manager_propose_frequency", "=", "10", ",", "eval_idx", "=", "0", ",", "eval_episodes", "=", "5", ")", ":", "\n", "    ", "print", "(", "\"Starting evaluation number {}...\"", ".", "format", "(", "eval_idx", ")", ")", "\n", "env", ".", "evaluate", "=", "True", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "avg_reward", "=", "0.", "\n", "avg_controller_rew", "=", "0.", "\n", "global_steps", "=", "0", "\n", "goals_achieved", "=", "0", "\n", "for", "eval_ep", "in", "range", "(", "eval_episodes", ")", ":", "\n", "            ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "goal", "=", "obs", "[", "\"desired_goal\"", "]", "\n", "state", "=", "obs", "[", "\"observation\"", "]", "\n", "\n", "done", "=", "False", "\n", "step_count", "=", "0", "\n", "env_goals_achieved", "=", "0", "\n", "while", "not", "done", ":", "\n", "                ", "if", "step_count", "%", "manager_propose_frequency", "==", "0", ":", "\n", "                    ", "subgoal", "=", "manager_policy", ".", "sample_goal", "(", "state", ",", "goal", ")", "\n", "\n", "", "step_count", "+=", "1", "\n", "global_steps", "+=", "1", "\n", "action", "=", "controller_policy", ".", "select_action", "(", "state", ",", "subgoal", ",", "evaluation", "=", "True", ")", "\n", "new_obs", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "env_name", "!=", "\"AntGather\"", "and", "env", ".", "success_fn", "(", "reward", ")", ":", "\n", "                    ", "env_goals_achieved", "+=", "1", "\n", "goals_achieved", "+=", "1", "\n", "done", "=", "True", "\n", "\n", "", "goal", "=", "new_obs", "[", "\"desired_goal\"", "]", "\n", "new_state", "=", "new_obs", "[", "\"observation\"", "]", "\n", "\n", "subgoal", "=", "controller_policy", ".", "subgoal_transition", "(", "state", ",", "subgoal", ",", "new_state", ")", "\n", "\n", "avg_reward", "+=", "reward", "\n", "avg_controller_rew", "+=", "calculate_controller_reward", "(", "state", ",", "subgoal", ",", "new_state", ",", "ctrl_rew_scale", ")", "\n", "\n", "state", "=", "new_state", "\n", "\n", "", "", "avg_reward", "/=", "eval_episodes", "\n", "avg_controller_rew", "/=", "global_steps", "\n", "avg_step_count", "=", "global_steps", "/", "eval_episodes", "\n", "avg_env_finish", "=", "goals_achieved", "/", "eval_episodes", "\n", "\n", "print", "(", "\"---------------------------------------\"", ")", "\n", "print", "(", "\"Evaluation over {} episodes:\\nAvg Ctrl Reward: {:.3f}\"", ".", "format", "(", "eval_episodes", ",", "avg_controller_rew", ")", ")", "\n", "if", "env_name", "==", "\"AntGather\"", ":", "\n", "            ", "print", "(", "\"Avg reward: {:.1f}\"", ".", "format", "(", "avg_reward", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Goals achieved: {:.1f}%\"", ".", "format", "(", "100", "*", "avg_env_finish", ")", ")", "\n", "", "print", "(", "\"Avg Steps to finish: {:.1f}\"", ".", "format", "(", "avg_step_count", ")", ")", "\n", "print", "(", "\"---------------------------------------\"", ")", "\n", "\n", "env", ".", "evaluate", "=", "False", "\n", "return", "avg_reward", ",", "avg_controller_rew", ",", "avg_step_count", ",", "avg_env_finish", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.get_reward_function": [[86, 113], ["float", "numpy.linalg.norm", "numpy.linalg.norm", "float", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "", "def", "get_reward_function", "(", "dims", ",", "absolute_goal", "=", "False", ",", "binary_reward", "=", "False", ")", ":", "\n", "    ", "if", "absolute_goal", "and", "binary_reward", ":", "\n", "        ", "def", "controller_reward", "(", "z", ",", "subgoal", ",", "next_z", ",", "scale", ")", ":", "\n", "            ", "z", "=", "z", "[", ":", "dims", "]", "\n", "next_z", "=", "next_z", "[", ":", "dims", "]", "\n", "reward", "=", "float", "(", "np", ".", "linalg", ".", "norm", "(", "subgoal", "-", "next_z", ",", "axis", "=", "-", "1", ")", "<=", "1.414", ")", "*", "scale", "\n", "return", "reward", "\n", "", "", "elif", "absolute_goal", ":", "\n", "        ", "def", "controller_reward", "(", "z", ",", "subgoal", ",", "next_z", ",", "scale", ")", ":", "\n", "            ", "z", "=", "z", "[", ":", "dims", "]", "\n", "next_z", "=", "next_z", "[", ":", "dims", "]", "\n", "reward", "=", "-", "np", ".", "linalg", ".", "norm", "(", "subgoal", "-", "next_z", ",", "axis", "=", "-", "1", ")", "*", "scale", "\n", "return", "reward", "\n", "", "", "elif", "binary_reward", ":", "\n", "        ", "def", "controller_reward", "(", "z", ",", "subgoal", ",", "next_z", ",", "scale", ")", ":", "\n", "            ", "z", "=", "z", "[", ":", "dims", "]", "\n", "next_z", "=", "next_z", "[", ":", "dims", "]", "\n", "reward", "=", "float", "(", "np", ".", "linalg", ".", "norm", "(", "z", "+", "subgoal", "-", "next_z", ",", "axis", "=", "-", "1", ")", "<=", "1.414", ")", "*", "scale", "\n", "return", "reward", "\n", "", "", "else", ":", "\n", "        ", "def", "controller_reward", "(", "z", ",", "subgoal", ",", "next_z", ",", "scale", ")", ":", "\n", "            ", "z", "=", "z", "[", ":", "dims", "]", "\n", "next_z", "=", "next_z", "[", ":", "dims", "]", "\n", "reward", "=", "-", "np", ".", "linalg", ".", "norm", "(", "z", "+", "subgoal", "-", "next_z", ",", "axis", "=", "-", "1", ")", "*", "scale", "\n", "return", "reward", "\n", "\n", "", "", "return", "controller_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.update_amat_and_train_anet": [[115, 152], ["traj_buffer.get_trajectory", "print", "numpy.ones", "print", "traj_buffer.reset", "range", "print", "hrac.train_adj_net", "len", "range", "os.path.join", "torch.save", "torch.save", "torch.save", "print", "min", "tuple", "tuple", "a_net.state_dict", "numpy.round().astype", "numpy.round().astype", "state_list.append", "state_list.append", "int", "int", "len", "numpy.round", "numpy.round"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.get_trajectory", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.train_adj_net", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "update_amat_and_train_anet", "(", "n_states", ",", "adj_mat", ",", "state_list", ",", "state_dict", ",", "a_net", ",", "traj_buffer", ",", "\n", "optimizer_r", ",", "controller_goal_dim", ",", "device", ",", "args", ")", ":", "\n", "    ", "for", "traj", "in", "traj_buffer", ".", "get_trajectory", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "traj", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "1", ",", "min", "(", "args", ".", "manager_propose_freq", ",", "len", "(", "traj", ")", "-", "i", ")", ")", ":", "\n", "                ", "s1", "=", "tuple", "(", "np", ".", "round", "(", "traj", "[", "i", "]", "[", ":", "controller_goal_dim", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "s2", "=", "tuple", "(", "np", ".", "round", "(", "traj", "[", "i", "+", "j", "]", "[", ":", "controller_goal_dim", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "if", "s1", "not", "in", "state_list", ":", "\n", "                    ", "state_list", ".", "append", "(", "s1", ")", "\n", "state_dict", "[", "s1", "]", "=", "n_states", "\n", "n_states", "+=", "1", "\n", "", "if", "s2", "not", "in", "state_list", ":", "\n", "                    ", "state_list", ".", "append", "(", "s2", ")", "\n", "state_dict", "[", "s2", "]", "=", "n_states", "\n", "n_states", "+=", "1", "\n", "", "adj_mat", "[", "state_dict", "[", "s1", "]", ",", "state_dict", "[", "s2", "]", "]", "=", "1", "\n", "adj_mat", "[", "state_dict", "[", "s2", "]", ",", "state_dict", "[", "s1", "]", "]", "=", "1", "\n", "", "", "", "print", "(", "\"Explored states: {}\"", ".", "format", "(", "n_states", ")", ")", "\n", "flags", "=", "np", ".", "ones", "(", "(", "30", ",", "30", ")", ")", "\n", "for", "s", "in", "state_list", ":", "\n", "        ", "flags", "[", "int", "(", "s", "[", "0", "]", ")", ",", "int", "(", "s", "[", "1", "]", ")", "]", "=", "0", "\n", "", "print", "(", "flags", ")", "\n", "if", "not", "args", ".", "load_adj_net", ":", "\n", "        ", "print", "(", "\"Training adjacency network...\"", ")", "\n", "utils", ".", "train_adj_net", "(", "a_net", ",", "state_list", ",", "adj_mat", "[", ":", "n_states", ",", ":", "n_states", "]", ",", "\n", "optimizer_r", ",", "args", ".", "r_margin_pos", ",", "args", ".", "r_margin_neg", ",", "\n", "n_epochs", "=", "args", ".", "r_training_epochs", ",", "batch_size", "=", "args", ".", "r_batch_size", ",", "\n", "device", "=", "device", ",", "verbose", "=", "False", ")", "\n", "\n", "if", "args", ".", "save_models", ":", "\n", "            ", "r_filename", "=", "os", ".", "path", ".", "join", "(", "\"./models\"", ",", "\"{}_{}_a_network.pth\"", ".", "format", "(", "args", ".", "env_name", ",", "args", ".", "algo", ")", ")", "\n", "torch", ".", "save", "(", "a_net", ".", "state_dict", "(", ")", ",", "r_filename", ")", "\n", "print", "(", "\"----- Adjacency network {} saved. -----\"", ".", "format", "(", "episode_num", ")", ")", "\n", "\n", "", "", "traj_buffer", ".", "reset", "(", ")", "\n", "\n", "return", "n_states", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.run_hrac": [[154, 461], ["os.path.join", "print", "numpy.array", "float", "envs.EnvWithGoal.reset", "torch.utils.tensorboard.SummaryWriter", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.device", "torch.device", "torch.device", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "hrac.Controller", "hrac.Controller", "hrac.Manager", "hrac.Manager", "train.get_reward_function", "hrac.ReplayBuffer", "hrac.ReplayBuffer", "numpy.diag", "hrac.TrajectoryBuffer", "hrac.models.ANet", "hrac.models.ANet.to", "torch.Adam", "train.evaluate_policy", "evaluations.append", "output_data[].append", "output_data[].append", "torch.utils.tensorboard.SummaryWriter.close", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "os.path.exists", "os.makedirs", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "envs.GatherEnv", "envs.EnvWithGoal.seed", "hrac.OUNoise", "hrac.OUNoise", "numpy.ones", "print", "hrac.models.ANet.load_state_dict", "hrac.models.ANet.parameters", "hrac.Controller.select_action", "utils.NormalNoise.perturb_action", "ctrl_noise.perturb_action.copy", "envs.EnvWithGoal.step", "manager_transition[].append", "manager_transition[].append", "utils.TrajectoryBuffer.append", "get_reward_function.", "hrac.Controller.subgoal_transition", "utils.ReplayBuffer.add", "len", "output_data[].append", "output_data[].append", "hrac.Controller.save", "hrac.Manager.save", "os.path.join", "os.path.exists", "os.path.join", "os.path.join", "envs.create_gather_env.create_gather_env", "envs.EnvWithGoal", "envs.EnvWithGoal.seed", "os.path.join", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "hrac.NormalNoise", "hrac.NormalNoise", "torch.load", "torch.load", "torch.load", "hrac.Manager.load", "hrac.Controller.load", "print", "envs.EnvWithGoal.reset", "utils.TrajectoryBuffer.create_new_trajectory", "utils.TrajectoryBuffer.append", "hrac.Manager.sample_goal", "float", "utils.ReplayBuffer.add", "hrac.Manager.sample_goal", "envs.create_maze_env.create_maze_env", "print", "hrac.Controller.train", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "utils.TrajectoryBuffer.full", "utils.NormalNoise.perturb_action", "utils.NormalNoise.perturb_action", "float", "utils.NormalNoise.perturb_action", "utils.NormalNoise.perturb_action", "print", "print", "print", "hrac.Manager.train", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "train.evaluate_policy", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "evaluations.append", "output_data[].append", "output_data[].append", "train.update_amat_and_train_anet", "len", "float", "utils.ReplayBuffer.add", "math.ceil", "print", "print", "print", "len", "output_data[].append", "output_data[].append", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "hrac.Controller.save", "hrac.Manager.save", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.get_reward_function", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.evaluate_policy", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.select_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Controller.subgoal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_gather_env.create_gather_env", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.create_new_trajectory", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.sample_goal", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.hrac.Manager.sample_goal", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_maze_env.create_maze_env", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.full", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.evaluate_policy", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.train.update_amat_and_train_anet", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save"], ["", "def", "run_hrac", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "\"./results\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"./results\"", ")", "\n", "", "if", "args", ".", "save_models", "and", "not", "os", ".", "path", ".", "exists", "(", "\"./models\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"./models\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "log_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "algo", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "algo", ")", ")", "\n", "", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "algo", ")", "\n", "print", "(", "\"Logging in {}\"", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "if", "args", ".", "env_name", "==", "\"AntGather\"", ":", "\n", "        ", "env", "=", "GatherEnv", "(", "create_gather_env", "(", "args", ".", "env_name", ",", "args", ".", "seed", ")", ",", "args", ".", "env_name", ")", "\n", "env", ".", "seed", "(", "args", ".", "seed", ")", "\n", "", "elif", "args", ".", "env_name", "in", "[", "\"AntMaze\"", ",", "\"AntMazeSparse\"", ",", "\"AntPush\"", ",", "\"AntFall\"", "]", ":", "\n", "        ", "env", "=", "EnvWithGoal", "(", "create_maze_env", "(", "args", ".", "env_name", ",", "args", ".", "seed", ")", ",", "args", ".", "env_name", ")", "\n", "env", ".", "seed", "(", "args", ".", "seed", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "low", "=", "np", ".", "array", "(", "(", "-", "10", ",", "-", "10", ",", "-", "0.5", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "\n", "-", "0.5", ",", "-", "0.3", ",", "-", "0.5", ",", "-", "0.3", ",", "-", "0.5", ",", "-", "0.3", ",", "-", "0.5", ",", "-", "0.3", ")", ")", "\n", "max_action", "=", "float", "(", "env", ".", "action_space", ".", "high", "[", "0", "]", ")", "\n", "policy_noise", "=", "0.2", "\n", "noise_clip", "=", "0.5", "\n", "high", "=", "-", "low", "\n", "man_scale", "=", "(", "high", "-", "low", ")", "/", "2", "\n", "if", "args", ".", "env_name", "==", "\"AntFall\"", ":", "\n", "        ", "controller_goal_dim", "=", "3", "\n", "", "else", ":", "\n", "        ", "controller_goal_dim", "=", "2", "\n", "", "if", "args", ".", "absolute_goal", ":", "\n", "        ", "man_scale", "[", "0", "]", "=", "30", "\n", "man_scale", "[", "1", "]", "=", "30", "\n", "no_xy", "=", "False", "\n", "", "else", ":", "\n", "        ", "no_xy", "=", "True", "\n", "", "action_dim", "=", "env", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "goal", "=", "obs", "[", "\"desired_goal\"", "]", "\n", "state", "=", "obs", "[", "\"observation\"", "]", "\n", "\n", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "algo", ")", ")", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gid", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "file_name", "=", "\"{}_{}_{}\"", ".", "format", "(", "args", ".", "env_name", ",", "args", ".", "algo", ",", "args", ".", "seed", ")", "\n", "output_data", "=", "{", "\"frames\"", ":", "[", "]", ",", "\"reward\"", ":", "[", "]", ",", "\"dist\"", ":", "[", "]", "}", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n", "state_dim", "=", "state", ".", "shape", "[", "0", "]", "\n", "if", "args", ".", "env_name", "in", "[", "\"AntMaze\"", ",", "\"AntPush\"", ",", "\"AntFall\"", "]", ":", "\n", "        ", "goal_dim", "=", "goal", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "goal_dim", "=", "0", "\n", "\n", "", "controller_policy", "=", "hrac", ".", "Controller", "(", "\n", "state_dim", "=", "state_dim", ",", "\n", "goal_dim", "=", "controller_goal_dim", ",", "\n", "action_dim", "=", "action_dim", ",", "\n", "max_action", "=", "max_action", ",", "\n", "actor_lr", "=", "args", ".", "ctrl_act_lr", ",", "\n", "critic_lr", "=", "args", ".", "ctrl_crit_lr", ",", "\n", "no_xy", "=", "no_xy", ",", "\n", "absolute_goal", "=", "args", ".", "absolute_goal", ",", "\n", "policy_noise", "=", "policy_noise", ",", "\n", "noise_clip", "=", "noise_clip", "\n", ")", "\n", "\n", "manager_policy", "=", "hrac", ".", "Manager", "(", "\n", "state_dim", "=", "state_dim", ",", "\n", "goal_dim", "=", "goal_dim", ",", "\n", "action_dim", "=", "controller_goal_dim", ",", "\n", "actor_lr", "=", "args", ".", "man_act_lr", ",", "\n", "critic_lr", "=", "args", ".", "man_crit_lr", ",", "\n", "candidate_goals", "=", "args", ".", "candidate_goals", ",", "\n", "correction", "=", "not", "args", ".", "no_correction", ",", "\n", "scale", "=", "man_scale", ",", "\n", "goal_loss_coeff", "=", "args", ".", "goal_loss_coeff", ",", "\n", "absolute_goal", "=", "args", ".", "absolute_goal", "\n", ")", "\n", "\n", "calculate_controller_reward", "=", "get_reward_function", "(", "\n", "controller_goal_dim", ",", "absolute_goal", "=", "args", ".", "absolute_goal", ",", "binary_reward", "=", "args", ".", "binary_int_reward", ")", "\n", "\n", "if", "args", ".", "noise_type", "==", "\"ou\"", ":", "\n", "        ", "man_noise", "=", "utils", ".", "OUNoise", "(", "state_dim", ",", "sigma", "=", "args", ".", "man_noise_sigma", ")", "\n", "ctrl_noise", "=", "utils", ".", "OUNoise", "(", "action_dim", ",", "sigma", "=", "args", ".", "ctrl_noise_sigma", ")", "\n", "\n", "", "elif", "args", ".", "noise_type", "==", "\"normal\"", ":", "\n", "        ", "man_noise", "=", "utils", ".", "NormalNoise", "(", "sigma", "=", "args", ".", "man_noise_sigma", ")", "\n", "ctrl_noise", "=", "utils", ".", "NormalNoise", "(", "sigma", "=", "args", ".", "ctrl_noise_sigma", ")", "\n", "\n", "", "manager_buffer", "=", "utils", ".", "ReplayBuffer", "(", "maxsize", "=", "args", ".", "man_buffer_size", ")", "\n", "controller_buffer", "=", "utils", ".", "ReplayBuffer", "(", "maxsize", "=", "args", ".", "ctrl_buffer_size", ")", "\n", "\n", "# Initialize adjacency matrix and adjacency network", "\n", "n_states", "=", "0", "\n", "state_list", "=", "[", "]", "\n", "state_dict", "=", "{", "}", "\n", "adj_mat", "=", "np", ".", "diag", "(", "np", ".", "ones", "(", "1500", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "traj_buffer", "=", "utils", ".", "TrajectoryBuffer", "(", "capacity", "=", "args", ".", "traj_buffer_size", ")", "\n", "a_net", "=", "ANet", "(", "controller_goal_dim", ",", "args", ".", "r_hidden_dim", ",", "args", ".", "r_embedding_dim", ")", "\n", "if", "args", ".", "load_adj_net", ":", "\n", "        ", "print", "(", "\"Loading adjacency network...\"", ")", "\n", "a_net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "\"./models/a_network.pth\"", ")", ")", "\n", "", "a_net", ".", "to", "(", "device", ")", "\n", "optimizer_r", "=", "optim", ".", "Adam", "(", "a_net", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr_r", ")", "\n", "\n", "if", "args", ".", "load", ":", "\n", "        ", "try", ":", "\n", "            ", "manager_policy", ".", "load", "(", "\"./models\"", ")", "\n", "controller_policy", ".", "load", "(", "\"./models\"", ")", "\n", "print", "(", "\"Loaded successfully.\"", ")", "\n", "just_loaded", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "just_loaded", "=", "False", "\n", "print", "(", "e", ",", "\"Loading failed.\"", ")", "\n", "", "", "else", ":", "\n", "        ", "just_loaded", "=", "False", "\n", "\n", "# Logging Parameters", "\n", "", "total_timesteps", "=", "0", "\n", "timesteps_since_eval", "=", "0", "\n", "timesteps_since_manager", "=", "0", "\n", "episode_timesteps", "=", "0", "\n", "timesteps_since_subgoal", "=", "0", "\n", "episode_num", "=", "0", "\n", "done", "=", "True", "\n", "evaluations", "=", "[", "]", "\n", "\n", "# Train", "\n", "while", "total_timesteps", "<", "args", ".", "max_timesteps", ":", "\n", "        ", "if", "done", ":", "\n", "            ", "if", "total_timesteps", "!=", "0", "and", "not", "just_loaded", ":", "\n", "                ", "if", "episode_num", "%", "10", "==", "0", ":", "\n", "                    ", "print", "(", "\"Episode {}\"", ".", "format", "(", "episode_num", ")", ")", "\n", "# Train controller", "\n", "", "ctrl_act_loss", ",", "ctrl_crit_loss", "=", "controller_policy", ".", "train", "(", "controller_buffer", ",", "episode_timesteps", ",", "\n", "batch_size", "=", "args", ".", "ctrl_batch_size", ",", "discount", "=", "args", ".", "ctrl_discount", ",", "tau", "=", "args", ".", "ctrl_soft_sync_rate", ")", "\n", "if", "episode_num", "%", "10", "==", "0", ":", "\n", "                    ", "print", "(", "\"Controller actor loss: {:.3f}\"", ".", "format", "(", "ctrl_act_loss", ")", ")", "\n", "print", "(", "\"Controller critic loss: {:.3f}\"", ".", "format", "(", "ctrl_crit_loss", ")", ")", "\n", "", "writer", ".", "add_scalar", "(", "\"data/controller_actor_loss\"", ",", "ctrl_act_loss", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"data/controller_critic_loss\"", ",", "ctrl_crit_loss", ",", "total_timesteps", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\"data/controller_ep_rew\"", ",", "episode_reward", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"data/manager_ep_rew\"", ",", "manager_transition", "[", "4", "]", ",", "total_timesteps", ")", "\n", "\n", "# Train manager", "\n", "if", "timesteps_since_manager", ">=", "args", ".", "train_manager_freq", ":", "\n", "                    ", "timesteps_since_manager", "=", "0", "\n", "r_margin", "=", "(", "args", ".", "r_margin_pos", "+", "args", ".", "r_margin_neg", ")", "/", "2", "\n", "\n", "man_act_loss", ",", "man_crit_loss", ",", "man_goal_loss", "=", "manager_policy", ".", "train", "(", "controller_policy", ",", "\n", "manager_buffer", ",", "ceil", "(", "episode_timesteps", "/", "args", ".", "train_manager_freq", ")", ",", "\n", "batch_size", "=", "args", ".", "man_batch_size", ",", "discount", "=", "args", ".", "man_discount", ",", "tau", "=", "args", ".", "man_soft_sync_rate", ",", "\n", "a_net", "=", "a_net", ",", "r_margin", "=", "r_margin", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\"data/manager_actor_loss\"", ",", "man_act_loss", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"data/manager_critic_loss\"", ",", "man_crit_loss", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"data/manager_goal_loss\"", ",", "man_goal_loss", ",", "total_timesteps", ")", "\n", "\n", "if", "episode_num", "%", "10", "==", "0", ":", "\n", "                        ", "print", "(", "\"Manager actor loss: {:.3f}\"", ".", "format", "(", "man_act_loss", ")", ")", "\n", "print", "(", "\"Manager critic loss: {:.3f}\"", ".", "format", "(", "man_crit_loss", ")", ")", "\n", "print", "(", "\"Manager goal loss: {:.3f}\"", ".", "format", "(", "man_goal_loss", ")", ")", "\n", "\n", "# Evaluate", "\n", "", "", "if", "timesteps_since_eval", ">=", "args", ".", "eval_freq", ":", "\n", "                    ", "timesteps_since_eval", "=", "0", "\n", "avg_ep_rew", ",", "avg_controller_rew", ",", "avg_steps", ",", "avg_env_finish", "=", "evaluate_policy", "(", "env", ",", "args", ".", "env_name", ",", "manager_policy", ",", "controller_policy", ",", "\n", "calculate_controller_reward", ",", "args", ".", "ctrl_rew_scale", ",", "args", ".", "manager_propose_freq", ",", "\n", "len", "(", "evaluations", ")", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\"eval/avg_ep_rew\"", ",", "avg_ep_rew", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"eval/avg_controller_rew\"", ",", "avg_controller_rew", ",", "total_timesteps", ")", "\n", "\n", "evaluations", ".", "append", "(", "[", "avg_ep_rew", ",", "avg_controller_rew", ",", "avg_steps", "]", ")", "\n", "output_data", "[", "\"frames\"", "]", ".", "append", "(", "total_timesteps", ")", "\n", "if", "args", ".", "env_name", "==", "\"AntGather\"", ":", "\n", "                        ", "output_data", "[", "\"reward\"", "]", ".", "append", "(", "avg_ep_rew", ")", "\n", "", "else", ":", "\n", "                        ", "output_data", "[", "\"reward\"", "]", ".", "append", "(", "avg_env_finish", ")", "\n", "writer", ".", "add_scalar", "(", "\"eval/avg_steps_to_finish\"", ",", "avg_steps", ",", "total_timesteps", ")", "\n", "writer", ".", "add_scalar", "(", "\"eval/perc_env_goal_achieved\"", ",", "avg_env_finish", ",", "total_timesteps", ")", "\n", "", "output_data", "[", "\"dist\"", "]", ".", "append", "(", "-", "avg_controller_rew", ")", "\n", "\n", "if", "args", ".", "save_models", ":", "\n", "                        ", "controller_policy", ".", "save", "(", "\"./models\"", ",", "args", ".", "env_name", ",", "args", ".", "algo", ")", "\n", "manager_policy", ".", "save", "(", "\"./models\"", ",", "args", ".", "env_name", ",", "args", ".", "algo", ")", "\n", "\n", "", "", "if", "traj_buffer", ".", "full", "(", ")", ":", "\n", "                     ", "n_states", "=", "update_amat_and_train_anet", "(", "n_states", ",", "adj_mat", ",", "state_list", ",", "state_dict", ",", "a_net", ",", "traj_buffer", ",", "\n", "optimizer_r", ",", "controller_goal_dim", ",", "device", ",", "args", ")", "\n", "\n", "", "if", "len", "(", "manager_transition", "[", "-", "2", "]", ")", "!=", "1", ":", "\n", "                    ", "manager_transition", "[", "1", "]", "=", "state", "\n", "manager_transition", "[", "5", "]", "=", "float", "(", "True", ")", "\n", "manager_buffer", ".", "add", "(", "manager_transition", ")", "\n", "\n", "", "", "obs", "=", "env", ".", "reset", "(", ")", "\n", "goal", "=", "obs", "[", "\"desired_goal\"", "]", "\n", "state", "=", "obs", "[", "\"observation\"", "]", "\n", "traj_buffer", ".", "create_new_trajectory", "(", ")", "\n", "traj_buffer", ".", "append", "(", "state", ")", "\n", "done", "=", "False", "\n", "episode_reward", "=", "0", "\n", "episode_timesteps", "=", "0", "\n", "just_loaded", "=", "False", "\n", "episode_num", "+=", "1", "\n", "\n", "subgoal", "=", "manager_policy", ".", "sample_goal", "(", "state", ",", "goal", ")", "\n", "if", "not", "args", ".", "absolute_goal", ":", "\n", "                ", "subgoal", "=", "man_noise", ".", "perturb_action", "(", "subgoal", ",", "\n", "min_action", "=", "-", "man_scale", "[", ":", "controller_goal_dim", "]", ",", "max_action", "=", "man_scale", "[", ":", "controller_goal_dim", "]", ")", "\n", "", "else", ":", "\n", "                ", "subgoal", "=", "man_noise", ".", "perturb_action", "(", "subgoal", ",", "\n", "min_action", "=", "np", ".", "zeros", "(", "controller_goal_dim", ")", ",", "max_action", "=", "2", "*", "man_scale", "[", ":", "controller_goal_dim", "]", ")", "\n", "\n", "", "timesteps_since_subgoal", "=", "0", "\n", "manager_transition", "=", "[", "state", ",", "None", ",", "goal", ",", "subgoal", ",", "0", ",", "False", ",", "[", "state", "]", ",", "[", "]", "]", "\n", "\n", "", "action", "=", "controller_policy", ".", "select_action", "(", "state", ",", "subgoal", ")", "\n", "action", "=", "ctrl_noise", ".", "perturb_action", "(", "action", ",", "-", "max_action", ",", "max_action", ")", "\n", "action_copy", "=", "action", ".", "copy", "(", ")", "\n", "\n", "next_tup", ",", "manager_reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action_copy", ")", "\n", "\n", "manager_transition", "[", "4", "]", "+=", "manager_reward", "*", "args", ".", "man_rew_scale", "\n", "manager_transition", "[", "-", "1", "]", ".", "append", "(", "action", ")", "\n", "\n", "next_goal", "=", "next_tup", "[", "\"desired_goal\"", "]", "\n", "next_state", "=", "next_tup", "[", "\"observation\"", "]", "\n", "\n", "manager_transition", "[", "-", "2", "]", ".", "append", "(", "next_state", ")", "\n", "traj_buffer", ".", "append", "(", "next_state", ")", "\n", "\n", "controller_reward", "=", "calculate_controller_reward", "(", "state", ",", "subgoal", ",", "next_state", ",", "args", ".", "ctrl_rew_scale", ")", "\n", "subgoal", "=", "controller_policy", ".", "subgoal_transition", "(", "state", ",", "subgoal", ",", "next_state", ")", "\n", "\n", "controller_goal", "=", "subgoal", "\n", "episode_reward", "+=", "controller_reward", "\n", "\n", "if", "args", ".", "inner_dones", ":", "\n", "            ", "ctrl_done", "=", "done", "or", "timesteps_since_subgoal", "%", "args", ".", "manager_propose_freq", "==", "0", "\n", "", "else", ":", "\n", "            ", "ctrl_done", "=", "done", "\n", "\n", "", "controller_buffer", ".", "add", "(", "\n", "(", "state", ",", "next_state", ",", "controller_goal", ",", "action", ",", "controller_reward", ",", "float", "(", "ctrl_done", ")", ",", "[", "]", ",", "[", "]", ")", ")", "\n", "\n", "state", "=", "next_state", "\n", "goal", "=", "next_goal", "\n", "\n", "episode_timesteps", "+=", "1", "\n", "total_timesteps", "+=", "1", "\n", "timesteps_since_eval", "+=", "1", "\n", "timesteps_since_manager", "+=", "1", "\n", "timesteps_since_subgoal", "+=", "1", "\n", "\n", "if", "timesteps_since_subgoal", "%", "args", ".", "manager_propose_freq", "==", "0", ":", "\n", "            ", "manager_transition", "[", "1", "]", "=", "state", "\n", "manager_transition", "[", "5", "]", "=", "float", "(", "done", ")", "\n", "\n", "manager_buffer", ".", "add", "(", "manager_transition", ")", "\n", "subgoal", "=", "manager_policy", ".", "sample_goal", "(", "state", ",", "goal", ")", "\n", "\n", "if", "not", "args", ".", "absolute_goal", ":", "\n", "                ", "subgoal", "=", "man_noise", ".", "perturb_action", "(", "subgoal", ",", "\n", "min_action", "=", "-", "man_scale", "[", ":", "controller_goal_dim", "]", ",", "max_action", "=", "man_scale", "[", ":", "controller_goal_dim", "]", ")", "\n", "", "else", ":", "\n", "                ", "subgoal", "=", "man_noise", ".", "perturb_action", "(", "subgoal", ",", "\n", "min_action", "=", "np", ".", "zeros", "(", "controller_goal_dim", ")", ",", "max_action", "=", "2", "*", "man_scale", "[", ":", "controller_goal_dim", "]", ")", "\n", "\n", "", "timesteps_since_subgoal", "=", "0", "\n", "manager_transition", "=", "[", "state", ",", "None", ",", "goal", ",", "subgoal", ",", "0", ",", "False", ",", "[", "state", "]", ",", "[", "]", "]", "\n", "\n", "# Final evaluation", "\n", "", "", "avg_ep_rew", ",", "avg_controller_rew", ",", "avg_steps", ",", "avg_env_finish", "=", "evaluate_policy", "(", "\n", "env", ",", "args", ".", "env_name", ",", "manager_policy", ",", "controller_policy", ",", "calculate_controller_reward", ",", "\n", "args", ".", "ctrl_rew_scale", ",", "args", ".", "manager_propose_freq", ",", "len", "(", "evaluations", ")", ")", "\n", "evaluations", ".", "append", "(", "[", "avg_ep_rew", ",", "avg_controller_rew", ",", "avg_steps", "]", ")", "\n", "output_data", "[", "\"frames\"", "]", ".", "append", "(", "total_timesteps", ")", "\n", "if", "args", ".", "env_name", "==", "'AntGather'", ":", "\n", "        ", "output_data", "[", "\"reward\"", "]", ".", "append", "(", "avg_ep_rew", ")", "\n", "", "else", ":", "\n", "        ", "output_data", "[", "\"reward\"", "]", ".", "append", "(", "avg_env_finish", ")", "\n", "", "output_data", "[", "\"dist\"", "]", ".", "append", "(", "-", "avg_controller_rew", ")", "\n", "\n", "if", "args", ".", "save_models", ":", "\n", "        ", "controller_policy", ".", "save", "(", "\"./models\"", ",", "args", ".", "env_name", ",", "args", ".", "algo", ")", "\n", "manager_policy", ".", "save", "(", "\"./models\"", ",", "args", ".", "env_name", ",", "args", ".", "algo", ")", "\n", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n", "output_df", "=", "pd", ".", "DataFrame", "(", "output_data", ")", "\n", "output_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "\"./results\"", ",", "file_name", "+", "\".csv\"", ")", ",", "float_format", "=", "\"%.4f\"", ",", "index", "=", "False", ")", "\n", "print", "(", "\"Training finished.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.__init__": [[14, 18], ["range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "maxsize", "=", "1e6", ")", ":", "\n", "        ", "self", ".", "storage", "=", "[", "[", "]", "for", "_", "in", "range", "(", "8", ")", "]", "\n", "self", ".", "maxsize", "=", "maxsize", "\n", "self", ".", "next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.clear": [[19, 22], ["range"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "storage", "=", "[", "[", "]", "for", "_", "in", "range", "(", "8", ")", "]", "\n", "self", ".", "next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add": [[24, 32], ["int", "len", "array.append", "array.__setitem__", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "add", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "next_idx", "=", "int", "(", "self", ".", "next_idx", ")", "\n", "if", "self", ".", "next_idx", ">=", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ":", "\n", "            ", "[", "array", ".", "append", "(", "datapoint", ")", "for", "array", ",", "datapoint", "in", "zip", "(", "self", ".", "storage", ",", "data", ")", "]", "\n", "", "else", ":", "\n", "            ", "[", "array", ".", "__setitem__", "(", "self", ".", "next_idx", ",", "datapoint", ")", "for", "array", ",", "datapoint", "in", "zip", "(", "self", ".", "storage", ",", "data", ")", "]", "\n", "\n", "", "self", ".", "next_idx", "=", "(", "self", ".", "next_idx", "+", "1", ")", "%", "self", ".", "maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.sample": [[33, 57], ["len", "numpy.arange", "numpy.random.randint", "x.append", "y.append", "g.append", "u.append", "r.append", "d.append", "x_seq.append", "a_seq.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array().reshape", "numpy.array().reshape", "len", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "storage", "[", "0", "]", ")", "<=", "batch_size", ":", "\n", "            ", "ind", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "x", ",", "y", ",", "g", ",", "u", ",", "r", ",", "d", ",", "x_seq", ",", "a_seq", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "ind", ":", "\n", "            ", "X", ",", "Y", ",", "G", ",", "U", ",", "R", ",", "D", ",", "obs_seq", ",", "acts", "=", "(", "array", "[", "i", "]", "for", "array", "in", "self", ".", "storage", ")", "\n", "x", ".", "append", "(", "np", ".", "array", "(", "X", ",", "copy", "=", "False", ")", ")", "\n", "y", ".", "append", "(", "np", ".", "array", "(", "Y", ",", "copy", "=", "False", ")", ")", "\n", "g", ".", "append", "(", "np", ".", "array", "(", "G", ",", "copy", "=", "False", ")", ")", "\n", "u", ".", "append", "(", "np", ".", "array", "(", "U", ",", "copy", "=", "False", ")", ")", "\n", "r", ".", "append", "(", "np", ".", "array", "(", "R", ",", "copy", "=", "False", ")", ")", "\n", "d", ".", "append", "(", "np", ".", "array", "(", "D", ",", "copy", "=", "False", ")", ")", "\n", "\n", "# For off-policy goal correction", "\n", "x_seq", ".", "append", "(", "np", ".", "array", "(", "obs_seq", ",", "copy", "=", "False", ")", ")", "\n", "a_seq", ".", "append", "(", "np", ".", "array", "(", "acts", ",", "copy", "=", "False", ")", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "x", ")", ",", "np", ".", "array", "(", "y", ")", ",", "np", ".", "array", "(", "g", ")", ",", "np", ".", "array", "(", "u", ")", ",", "np", ".", "array", "(", "r", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "np", ".", "array", "(", "d", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "x_seq", ",", "a_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save": [[58, 63], ["numpy.savez_compressed", "numpy.array"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "file", ")", ":", "\n", "        ", "np", ".", "savez_compressed", "(", "file", ",", "idx", "=", "np", ".", "array", "(", "[", "self", ".", "next_idx", "]", ")", ",", "x", "=", "self", ".", "storage", "[", "0", "]", ",", "\n", "y", "=", "self", ".", "storage", "[", "1", "]", ",", "g", "=", "self", ".", "storage", "[", "2", "]", ",", "u", "=", "self", ".", "storage", "[", "3", "]", ",", "\n", "r", "=", "self", ".", "storage", "[", "4", "]", ",", "d", "=", "self", ".", "storage", "[", "5", "]", ",", "xseq", "=", "self", ".", "storage", "[", "6", "]", ",", "\n", "aseq", "=", "self", ".", "storage", "[", "7", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load": [[64, 70], ["numpy.load", "int", "list"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load"], ["", "def", "load", "(", "self", ",", "file", ")", ":", "\n", "        ", "with", "np", ".", "load", "(", "file", ")", "as", "data", ":", "\n", "            ", "self", ".", "next_idx", "=", "int", "(", "data", "[", "'idx'", "]", "[", "0", "]", ")", "\n", "self", ".", "storage", "=", "[", "data", "[", "'x'", "]", ",", "data", "[", "'y'", "]", ",", "data", "[", "'g'", "]", ",", "data", "[", "'u'", "]", ",", "data", "[", "'r'", "]", ",", "\n", "data", "[", "'d'", "]", ",", "data", "[", "'xseq'", "]", ",", "data", "[", "'aseq'", "]", "]", "\n", "self", ".", "storage", "=", "[", "list", "(", "l", ")", "for", "l", "in", "self", ".", "storage", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.__len__": [[71, 73], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "storage", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.__init__": [[77, 80], ["utils.TrajectoryBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "self", ".", "_capacity", "=", "capacity", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.reset": [[81, 85], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_num_traj", "=", "0", "# number of trajectories", "\n", "self", ".", "_size", "=", "0", "# number of game frames", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.__len__": [[86, 88], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_traj", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.size": [[89, 91], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.get_traj_num": [[92, 94], ["None"], "methods", ["None"], ["", "def", "get_traj_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_traj", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.full": [[95, 97], ["None"], "methods", ["None"], ["", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", ">=", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.create_new_trajectory": [[98, 101], ["utils.TrajectoryBuffer.trajectory.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "create_new_trajectory", "(", "self", ")", ":", "\n", "        ", "self", ".", "trajectory", ".", "append", "(", "[", "]", ")", "\n", "self", ".", "_num_traj", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.append": [[102, 105], ["utils.TrajectoryBuffer.trajectory[].append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "append", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "trajectory", "[", "self", ".", "_num_traj", "-", "1", "]", ".", "append", "(", "s", ")", "\n", "self", ".", "_size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.get_trajectory": [[106, 108], ["None"], "methods", ["None"], ["", "def", "get_trajectory", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "trajectory", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.TrajectoryBuffer.set_capacity": [[109, 112], ["None"], "methods", ["None"], ["", "def", "set_capacity", "(", "self", ",", "new_capacity", ")", ":", "\n", "        ", "assert", "self", ".", "_size", "<=", "new_capacity", "\n", "self", ".", "_capacity", "=", "new_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.NormalNoise.__init__": [[115, 117], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sigma", ")", ":", "\n", "        ", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.NormalNoise.perturb_action": [[118, 122], ["numpy.random.normal"], "methods", ["None"], ["", "def", "perturb_action", "(", "self", ",", "action", ",", "min_action", "=", "-", "np", ".", "inf", ",", "max_action", "=", "np", ".", "inf", ")", ":", "\n", "        ", "action", "=", "(", "action", "+", "np", ".", "random", ".", "normal", "(", "0", ",", "self", ".", "sigma", ",", "\n", "size", "=", "action", ".", "shape", ")", ")", ".", "clip", "(", "min_action", ",", "max_action", ")", "\n", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.__init__": [[125, 131], ["numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "action_dim", ",", "mu", "=", "0", ",", "theta", "=", "0.15", ",", "sigma", "=", "0.3", ")", ":", "\n", "        ", "self", ".", "mu", "=", "mu", "\n", "self", ".", "theta", "=", "theta", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "X", "=", "np", ".", "ones", "(", "self", ".", "action_dim", ")", "*", "self", ".", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.reset": [[132, 134], ["numpy.ones"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "X", "=", "np", ".", "ones", "(", "self", ".", "action_dim", ")", "*", "self", ".", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.OUNoise.perturb_action": [[135, 140], ["numpy.random.randn", "len"], "methods", ["None"], ["", "def", "perturb_action", "(", "self", ",", "action", ",", "min_action", "=", "-", "np", ".", "inf", ",", "max_action", "=", "np", ".", "inf", ")", ":", "\n", "        ", "dx", "=", "self", ".", "theta", "*", "(", "self", ".", "mu", "-", "self", ".", "X", ")", "\n", "dx", "=", "dx", "+", "self", ".", "sigma", "*", "np", ".", "random", ".", "randn", "(", "len", "(", "self", ".", "X", ")", ")", "\n", "self", ".", "X", "=", "self", ".", "X", "+", "dx", "\n", "return", "(", "self", ".", "X", "+", "action", ")", ".", "clip", "(", "min_action", ",", "max_action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ContrastiveLoss.__init__": [[178, 183], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin_pos", ",", "margin_neg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "margin_pos", "<=", "margin_neg", "\n", "self", ".", "margin_pos", "=", "margin_pos", "\n", "self", ".", "margin_neg", "=", "margin_neg", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ContrastiveLoss.forward": [[184, 189], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "label", ")", ":", "\n", "# mutually reachable states correspond to label = 1", "\n", "        ", "dist", "=", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "x", "-", "y", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "1e-12", ")", "\n", "loss", "=", "(", "label", "*", "(", "dist", "-", "self", ".", "margin_pos", ")", ".", "clamp", "(", "min", "=", "0", ")", ")", ".", "mean", "(", ")", "+", "(", "(", "1", "-", "label", ")", "*", "(", "self", ".", "margin_neg", "-", "dist", ")", ".", "clamp", "(", "min", "=", "0", ")", ")", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.MetricDataset.__init__": [[193, 207], ["torch.Dataset.__init__", "range", "numpy.array", "numpy.array", "numpy.array", "range", "utils.MetricDataset.x.append", "utils.MetricDataset.y.append", "utils.MetricDataset.label.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["    ", "def", "__init__", "(", "self", ",", "states", ",", "adj_mat", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "n_samples", "=", "adj_mat", ".", "shape", "[", "0", "]", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "label", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_samples", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "n_samples", ")", ":", "\n", "                ", "self", ".", "x", ".", "append", "(", "states", "[", "i", "]", ")", "\n", "self", ".", "y", ".", "append", "(", "states", "[", "j", "]", ")", "\n", "self", ".", "label", ".", "append", "(", "adj_mat", "[", "i", ",", "j", "]", ")", "\n", "", "", "self", ".", "x", "=", "np", ".", "array", "(", "self", ".", "x", ")", "\n", "self", ".", "y", "=", "np", ".", "array", "(", "self", ".", "y", ")", "\n", "self", ".", "label", "=", "np", ".", "array", "(", "self", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.MetricDataset.__len__": [[208, 210], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "x", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.MetricDataset.__getitem__": [[211, 213], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "x", "[", "idx", "]", ",", "self", ".", "y", "[", "idx", "]", ",", "self", ".", "label", "[", "idx", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.train_adj_net": [[142, 174], ["utils.MetricDataset", "torch.DataLoader", "len", "utils.ContrastiveLoss", "range", "print", "print", "enumerate", "a_net.float().to", "a_net.float().to", "label.long().to.long().to", "a_net", "a_net", "ContrastiveLoss.", "optimizer.zero_grad", "loss_func.backward", "optimizer.step", "epoch_loss.append", "print", "len", "print", "loss_func.item", "a_net.float", "a_net.float", "label.long().to.long", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "", "def", "train_adj_net", "(", "a_net", ",", "states", ",", "adj_mat", ",", "optimizer", ",", "margin_pos", ",", "margin_neg", ",", "\n", "n_epochs", "=", "100", ",", "batch_size", "=", "64", ",", "device", "=", "'cpu'", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "if", "verbose", ":", "\n", "        ", "print", "(", "'Generating training data...'", ")", "\n", "", "dataset", "=", "MetricDataset", "(", "states", ",", "adj_mat", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Totally {} training pairs.'", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "", "dataloader", "=", "Data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "drop_last", "=", "False", ")", "\n", "n_batches", "=", "len", "(", "dataloader", ")", "\n", "\n", "loss_func", "=", "ContrastiveLoss", "(", "margin_pos", ",", "margin_neg", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "epoch_loss", "=", "[", "]", "\n", "for", "j", ",", "data", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "x", ",", "y", ",", "label", "=", "data", "\n", "x", "=", "x", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "y", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "label", "=", "label", ".", "long", "(", ")", ".", "to", "(", "device", ")", "\n", "x", "=", "a_net", "(", "x", ")", "\n", "y", "=", "a_net", "(", "y", ")", "\n", "loss", "=", "loss_func", "(", "x", ",", "y", ",", "label", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "verbose", "and", "(", "j", "%", "50", "==", "0", "or", "j", "==", "n_batches", "-", "1", ")", ":", "\n", "                ", "print", "(", "'Training metric network: epoch {}/{}, batch {}/{}'", ".", "format", "(", "i", "+", "1", ",", "n_epochs", ",", "j", "+", "1", ",", "n_batches", ")", ")", "\n", "\n", "", "epoch_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Mean loss: {:.4f}'", ".", "format", "(", "np", ".", "mean", "(", "epoch_loss", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_maze_env.create_maze_env": [[19, 35], ["env_name.endswith", "ant_maze_env.AntMazeEnv", "env_name.endswith", "ant_maze_env.AntMazeEnv", "env_name.endswith", "ant_maze_env.AntMazeEnv", "env_name.endswith", "ant_maze_env.AntMazeEnv", "ValueError"], "function", ["None"], ["def", "create_maze_env", "(", "env_name", "=", "None", ",", "seed", "=", "0", ")", ":", "\n", "  ", "maze_id", "=", "None", "\n", "if", "env_name", ".", "endswith", "(", "'Maze'", ")", ":", "\n", "    ", "maze_id", "=", "'Maze'", "\n", "return", "AntMazeEnv", "(", "maze_id", "=", "maze_id", ",", "maze_size_scaling", "=", "8", ",", "seed", "=", "seed", ")", "\n", "", "elif", "env_name", ".", "endswith", "(", "'MazeSparse'", ")", ":", "\n", "    ", "maze_id", "=", "'Maze2'", "\n", "return", "AntMazeEnv", "(", "maze_id", "=", "maze_id", ",", "maze_size_scaling", "=", "2", ",", "seed", "=", "seed", ")", "\n", "", "elif", "env_name", ".", "endswith", "(", "'Push'", ")", ":", "\n", "  \t", "maze_id", "=", "'Push'", "\n", "return", "AntMazeEnv", "(", "maze_id", "=", "maze_id", ",", "maze_size_scaling", "=", "8", ",", "seed", "=", "seed", ")", "\n", "", "elif", "env_name", ".", "endswith", "(", "'Fall'", ")", ":", "\n", "  \t", "maze_id", "=", "'Fall'", "\n", "return", "AntMazeEnv", "(", "maze_id", "=", "maze_id", ",", "maze_size_scaling", "=", "8", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Unknown maze environment %s'", "%", "env_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.__init__": [[41, 52], ["numpy.random.RandomState", "gym.envs.mujoco.mujoco_env.MujocoEnv.__init__", "gym.utils.EzPickle.__init__"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["def", "__init__", "(", "self", ",", "file_path", "=", "None", ",", "expose_all_qpos", "=", "True", ",", "\n", "expose_body_coms", "=", "None", ",", "expose_body_comvels", "=", "None", ",", "seed", "=", "0", ")", ":", "\n", "    ", "self", ".", "_expose_all_qpos", "=", "expose_all_qpos", "\n", "self", ".", "_expose_body_coms", "=", "expose_body_coms", "\n", "self", ".", "_expose_body_comvels", "=", "expose_body_comvels", "\n", "self", ".", "_body_com_indices", "=", "{", "}", "\n", "self", ".", "_body_comvel_indices", "=", "{", "}", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "mujoco_env", ".", "MujocoEnv", ".", "__init__", "(", "self", ",", "file_path", ",", "5", ")", "\n", "utils", ".", "EzPickle", ".", "__init__", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.physics": [[53, 62], ["mujoco_py.get_version"], "methods", ["None"], ["", "@", "property", "\n", "def", "physics", "(", "self", ")", ":", "\n", "# check mujoco version is greater than version 1.50 to call correct physics", "\n", "# model containing PyMjData object for getting and setting position/velocity", "\n", "# check https://github.com/openai/mujoco-py/issues/80 for updates to api", "\n", "    ", "if", "mujoco_py", ".", "get_version", "(", ")", ">=", "'1.50'", ":", "\n", "      ", "return", "self", ".", "sim", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv._step": [[63, 65], ["ant.AntEnv.step"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step"], ["", "", "def", "_step", "(", "self", ",", "a", ")", ":", "\n", "    ", "return", "self", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.step": [[66, 88], ["ant.AntEnv.do_simulation", "ant.AntEnv.state_vector", "ant.AntEnv._get_obs", "ant.AntEnv.get_body_com", "ant.AntEnv.get_body_com", "numpy.square().sum", "dict", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "    ", "xposbefore", "=", "self", ".", "get_body_com", "(", "\"torso\"", ")", "[", "0", "]", "\n", "self", ".", "do_simulation", "(", "a", ",", "self", ".", "frame_skip", ")", "\n", "\n", "# stochasticity", "\n", "# qpos = np.copy(self.physics.data.qpos)", "\n", "# qvel = np.copy(self.physics.data.qvel)", "\n", "# qpos[:2] += self.rng.normal(scale=0.05, size=2)", "\n", "# self.set_state(qpos, qvel)", "\n", "\n", "xposafter", "=", "self", ".", "get_body_com", "(", "\"torso\"", ")", "[", "0", "]", "\n", "forward_reward", "=", "(", "xposafter", "-", "xposbefore", ")", "/", "self", ".", "dt", "\n", "ctrl_cost", "=", ".5", "*", "np", ".", "square", "(", "a", ")", ".", "sum", "(", ")", "\n", "survive_reward", "=", "1.0", "\n", "reward", "=", "forward_reward", "-", "ctrl_cost", "+", "survive_reward", "\n", "state", "=", "self", ".", "state_vector", "(", ")", "\n", "done", "=", "False", "\n", "ob", "=", "self", ".", "_get_obs", "(", ")", "\n", "return", "ob", ",", "reward", ",", "done", ",", "dict", "(", "\n", "reward_forward", "=", "forward_reward", ",", "\n", "reward_ctrl", "=", "-", "ctrl_cost", ",", "\n", "reward_survive", "=", "survive_reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv._get_obs": [[89, 118], ["numpy.concatenate", "numpy.concatenate", "ant.AntEnv.get_body_com", "numpy.concatenate", "ant.AntEnv.get_body_comvel", "numpy.concatenate", "range", "range", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "# No cfrc observation", "\n", "    ", "if", "self", ".", "_expose_all_qpos", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "data", ".", "qpos", ".", "flat", "[", ":", "15", "]", ",", "# Ensures only ant obs.", "\n", "self", ".", "data", ".", "qvel", ".", "flat", "[", ":", "14", "]", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "      ", "obs", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "data", ".", "qpos", ".", "flat", "[", "2", ":", "15", "]", ",", "\n", "self", ".", "data", ".", "qvel", ".", "flat", "[", ":", "14", "]", ",", "\n", "]", ")", "\n", "\n", "", "if", "self", ".", "_expose_body_coms", "is", "not", "None", ":", "\n", "      ", "for", "name", "in", "self", ".", "_expose_body_coms", ":", "\n", "        ", "com", "=", "self", ".", "get_body_com", "(", "name", ")", "\n", "if", "name", "not", "in", "self", ".", "_body_com_indices", ":", "\n", "          ", "indices", "=", "range", "(", "len", "(", "obs", ")", ",", "len", "(", "obs", ")", "+", "len", "(", "com", ")", ")", "\n", "self", ".", "_body_com_indices", "[", "name", "]", "=", "indices", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "com", "]", ")", "\n", "\n", "", "", "if", "self", ".", "_expose_body_comvels", "is", "not", "None", ":", "\n", "      ", "for", "name", "in", "self", ".", "_expose_body_comvels", ":", "\n", "        ", "comvel", "=", "self", ".", "get_body_comvel", "(", "name", ")", "\n", "if", "name", "not", "in", "self", ".", "_body_comvel_indices", ":", "\n", "          ", "indices", "=", "range", "(", "len", "(", "obs", ")", ",", "len", "(", "obs", ")", "+", "len", "(", "comvel", ")", ")", "\n", "self", ".", "_body_comvel_indices", "[", "name", "]", "=", "indices", "\n", "", "obs", "=", "np", ".", "concatenate", "(", "[", "obs", ",", "comvel", "]", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.reset_model": [[119, 129], ["ant.AntEnv.set_state", "ant.AntEnv._get_obs", "ant.AntEnv.rng.uniform", "ant.AntEnv.rng.randn"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "def", "reset_model", "(", "self", ")", ":", "\n", "    ", "qpos", "=", "self", ".", "init_qpos", "+", "self", ".", "rng", ".", "uniform", "(", "\n", "size", "=", "self", ".", "model", ".", "nq", ",", "low", "=", "-", ".1", ",", "high", "=", ".1", ")", "\n", "qvel", "=", "self", ".", "init_qvel", "+", "self", ".", "rng", ".", "randn", "(", "self", ".", "model", ".", "nv", ")", "*", ".1", "\n", "\n", "# Set everything other than ant to original position and 0 velocity.", "\n", "qpos", "[", "15", ":", "]", "=", "self", ".", "init_qpos", "[", "15", ":", "]", "\n", "qvel", "[", "14", ":", "]", "=", "0.", "\n", "self", ".", "set_state", "(", "qpos", ",", "qvel", ")", "\n", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.get_ori": [[130, 136], ["math.atan2", "ant.q_mult", "ant.q_mult", "ant.q_inv"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.q_mult", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.q_mult", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.q_inv"], ["", "def", "get_ori", "(", "self", ")", ":", "\n", "    ", "ori", "=", "[", "0", ",", "1", ",", "0", ",", "0", "]", "\n", "rot", "=", "self", ".", "physics", ".", "data", ".", "qpos", "[", "self", ".", "__class__", ".", "ORI_IND", ":", "self", ".", "__class__", ".", "ORI_IND", "+", "4", "]", "# take the quaternion", "\n", "ori", "=", "q_mult", "(", "q_mult", "(", "rot", ",", "ori", ")", ",", "q_inv", "(", "rot", ")", ")", "[", "1", ":", "3", "]", "# project onto x-y plane", "\n", "ori", "=", "math", ".", "atan2", "(", "ori", "[", "1", "]", ",", "ori", "[", "0", "]", ")", "\n", "return", "ori", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.set_xy": [[137, 144], ["numpy.copy", "ant.AntEnv.set_state"], "methods", ["None"], ["", "def", "set_xy", "(", "self", ",", "xy", ")", ":", "\n", "    ", "qpos", "=", "np", ".", "copy", "(", "self", ".", "physics", ".", "data", ".", "qpos", ")", "\n", "qpos", "[", "0", "]", "=", "xy", "[", "0", "]", "\n", "qpos", "[", "1", "]", "=", "xy", "[", "1", "]", "\n", "\n", "qvel", "=", "self", ".", "physics", ".", "data", ".", "qvel", "\n", "self", ".", "set_state", "(", "qpos", ",", "qvel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.get_xy": [[145, 147], ["None"], "methods", ["None"], ["", "def", "get_xy", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "physics", ".", "data", ".", "qpos", "[", ":", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.viewer_setup": [[148, 152], ["None"], "methods", ["None"], ["", "def", "viewer_setup", "(", "self", ")", ":", "\n", "    ", "self", ".", "viewer", ".", "cam", ".", "trackbodyid", "=", "-", "1", "\n", "self", ".", "viewer", ".", "cam", ".", "distance", "=", "50", "\n", "self", ".", "viewer", ".", "cam", ".", "elevation", "=", "-", "90", "", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.q_inv": [[25, 27], ["None"], "function", ["None"], ["def", "q_inv", "(", "a", ")", ":", "\n", "  ", "return", "[", "a", "[", "0", "]", ",", "-", "a", "[", "1", "]", ",", "-", "a", "[", "2", "]", ",", "-", "a", "[", "3", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.q_mult": [[29, 35], ["None"], "function", ["None"], ["", "def", "q_mult", "(", "a", ",", "b", ")", ":", "# multiply two quaternion", "\n", "  ", "w", "=", "a", "[", "0", "]", "*", "b", "[", "0", "]", "-", "a", "[", "1", "]", "*", "b", "[", "1", "]", "-", "a", "[", "2", "]", "*", "b", "[", "2", "]", "-", "a", "[", "3", "]", "*", "b", "[", "3", "]", "\n", "i", "=", "a", "[", "0", "]", "*", "b", "[", "1", "]", "+", "a", "[", "1", "]", "*", "b", "[", "0", "]", "+", "a", "[", "2", "]", "*", "b", "[", "3", "]", "-", "a", "[", "3", "]", "*", "b", "[", "2", "]", "\n", "j", "=", "a", "[", "0", "]", "*", "b", "[", "2", "]", "-", "a", "[", "1", "]", "*", "b", "[", "3", "]", "+", "a", "[", "2", "]", "*", "b", "[", "0", "]", "+", "a", "[", "3", "]", "*", "b", "[", "1", "]", "\n", "k", "=", "a", "[", "0", "]", "*", "b", "[", "3", "]", "+", "a", "[", "1", "]", "*", "b", "[", "2", "]", "-", "a", "[", "2", "]", "*", "b", "[", "1", "]", "+", "a", "[", "3", "]", "*", "b", "[", "0", "]", "\n", "return", "[", "w", ",", "i", ",", "j", ",", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.__init__": [[38, 199], ["os.path.join", "xml.parse", "xml.parse.find", "envs.maze_env_utils.construct_maze", "any", "any", "maze_env.MazeEnv._find_robot", "numpy.random.RandomState", "range", "xml.parse.find", "ET.parse.find.findall", "tempfile.mkstemp", "xml.parse.write", "model_cls", "xml.parse.find", "ET.parse.find.set", "xml.parse.find", "ET.parse.find.find().set", "len", "range", "any", "maze_env.MazeEnv._find_all_robots", "len", "Exception", "ET.parse.find.find", "xml.SubElement", "xml.SubElement", "envs.maze_env_utils.can_move", "envs.maze_env_utils.can_move", "envs.maze_env_utils.can_move_z", "xml.SubElement", "xml.SubElement", "envs.maze_env_utils.can_move_x", "envs.maze_env_utils.can_move_y", "envs.maze_env_utils.can_move_z", "xml.SubElement", "xml.SubElement", "xml.SubElement"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.construct_maze", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._find_robot", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._find_all_robots", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_z", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_x", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_y", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_z"], ["def", "__init__", "(", "\n", "self", ",", "\n", "maze_id", "=", "None", ",", "\n", "maze_height", "=", "0.5", ",", "\n", "maze_size_scaling", "=", "8", ",", "\n", "seed", "=", "0", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "self", ".", "_maze_id", "=", "maze_id", "\n", "\n", "model_cls", "=", "self", ".", "__class__", ".", "MODEL_CLASS", "\n", "if", "model_cls", "is", "None", ":", "\n", "      ", "raise", "\"MODEL_CLASS unspecified!\"", "\n", "", "xml_path", "=", "os", ".", "path", ".", "join", "(", "\"envs\"", ",", "MODEL_DIR", ",", "model_cls", ".", "FILE", ")", "\n", "tree", "=", "ET", ".", "parse", "(", "xml_path", ")", "\n", "worldbody", "=", "tree", ".", "find", "(", "\".//worldbody\"", ")", "\n", "\n", "self", ".", "MAZE_HEIGHT", "=", "height", "=", "maze_height", "\n", "self", ".", "MAZE_SIZE_SCALING", "=", "size_scaling", "=", "maze_size_scaling", "\n", "self", ".", "MAZE_STRUCTURE", "=", "structure", "=", "maze_env_utils", ".", "construct_maze", "(", "maze_id", "=", "self", ".", "_maze_id", ")", "\n", "self", ".", "elevated", "=", "any", "(", "-", "1", "in", "row", "for", "row", "in", "structure", ")", "# Elevate the maze to allow for falling.", "\n", "self", ".", "blocks", "=", "any", "(", "\n", "any", "(", "maze_env_utils", ".", "can_move", "(", "r", ")", "for", "r", "in", "row", ")", "\n", "for", "row", "in", "structure", ")", "# Are there any movable blocks?", "\n", "\n", "torso_x", ",", "torso_y", "=", "self", ".", "_find_robot", "(", ")", "\n", "self", ".", "_init_torso_x", "=", "torso_x", "\n", "self", ".", "_init_torso_y", "=", "torso_y", "\n", "self", ".", "_init_positions", "=", "[", "\n", "(", "x", "-", "torso_x", ",", "y", "-", "torso_y", ")", "\n", "for", "x", ",", "y", "in", "self", ".", "_find_all_robots", "(", ")", "]", "\n", "\n", "height_offset", "=", "0.", "\n", "if", "self", ".", "elevated", ":", "\n", "# Increase initial z-pos of ant.", "\n", "      ", "height_offset", "=", "height", "*", "size_scaling", "\n", "torso", "=", "tree", ".", "find", "(", "\".//body[@name='torso']\"", ")", "\n", "torso", ".", "set", "(", "'pos'", ",", "'0 0 %.2f'", "%", "(", "0.75", "+", "height_offset", ")", ")", "\n", "", "if", "self", ".", "blocks", ":", "\n", "# If there are movable blocks, change simulation settings to perform", "\n", "# better contact detection.", "\n", "      ", "default", "=", "tree", ".", "find", "(", "\".//default\"", ")", "\n", "default", ".", "find", "(", "'.//geom'", ")", ".", "set", "(", "'solimp'", ",", "'.995 .995 .01'", ")", "\n", "\n", "", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "self", ".", "elevated", "and", "structure", "[", "i", "]", "[", "j", "]", "not", "in", "[", "-", "1", "]", ":", "\n", "# Create elevated platform.", "\n", "          ", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"elevated_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.9 0.9 1\"", ",", "\n", ")", "\n", "", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "1", ":", "# Unmovable block.", "\n", "# Offset all coordinates so that robot starts at the origin.", "\n", "          ", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height_offset", "+", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", ",", "\n", "0.5", "*", "size_scaling", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.4 0.4 0.4 1\"", ",", "\n", ")", "\n", "", "elif", "maze_env_utils", ".", "can_move", "(", "structure", "[", "i", "]", "[", "j", "]", ")", ":", "# Movable block.", "\n", "# The \"falling\" blocks are shrunk slightly and increased in mass to", "\n", "# ensure that it can fall easily through a gap in the platform blocks.", "\n", "          ", "falling", "=", "maze_env_utils", ".", "can_move_z", "(", "structure", "[", "i", "]", "[", "j", "]", ")", "\n", "shrink", "=", "0.99", "if", "falling", "else", "1.0", "\n", "moveable_body", "=", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"body\"", ",", "\n", "name", "=", "\"moveable_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"%f %f %f\"", "%", "(", "j", "*", "size_scaling", "-", "torso_x", ",", "\n", "i", "*", "size_scaling", "-", "torso_y", ",", "\n", "height_offset", "+", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", ")", "\n", "ET", ".", "SubElement", "(", "\n", "moveable_body", ",", "\"geom\"", ",", "\n", "name", "=", "\"block_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "size", "=", "\"%f %f %f\"", "%", "(", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "0.5", "*", "size_scaling", "*", "shrink", ",", "\n", "height", "/", "2", "*", "size_scaling", ")", ",", "\n", "type", "=", "\"box\"", ",", "\n", "material", "=", "\"\"", ",", "\n", "mass", "=", "\"0.001\"", "if", "falling", "else", "\"0.0002\"", ",", "\n", "contype", "=", "\"1\"", ",", "\n", "conaffinity", "=", "\"1\"", ",", "\n", "rgba", "=", "\"0.9 0.1 0.1 1\"", "\n", ")", "\n", "if", "maze_env_utils", ".", "can_move_x", "(", "structure", "[", "i", "]", "[", "j", "]", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "moveable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"1 0 0\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", "if", "falling", "else", "\"false\"", ",", "\n", "range", "=", "\"%f %f\"", "%", "(", "-", "size_scaling", ",", "size_scaling", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"moveable_x_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_move_y", "(", "structure", "[", "i", "]", "[", "j", "]", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "moveable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 1 0\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", "if", "falling", "else", "\"false\"", ",", "\n", "range", "=", "\"%f %f\"", "%", "(", "-", "size_scaling", ",", "size_scaling", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"moveable_y_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "", "if", "maze_env_utils", ".", "can_move_z", "(", "structure", "[", "i", "]", "[", "j", "]", ")", ":", "\n", "            ", "ET", ".", "SubElement", "(", "\n", "moveable_body", ",", "\"joint\"", ",", "\n", "armature", "=", "\"0\"", ",", "\n", "axis", "=", "\"0 0 1\"", ",", "\n", "damping", "=", "\"0.0\"", ",", "\n", "limited", "=", "\"true\"", ",", "\n", "range", "=", "\"%f 0\"", "%", "(", "-", "height_offset", ")", ",", "\n", "margin", "=", "\"0.01\"", ",", "\n", "name", "=", "\"moveable_z_%d_%d\"", "%", "(", "i", ",", "j", ")", ",", "\n", "pos", "=", "\"0 0 0\"", ",", "\n", "type", "=", "\"slide\"", "\n", ")", "\n", "\n", "", "", "", "", "torso", "=", "tree", ".", "find", "(", "\".//body[@name='torso']\"", ")", "\n", "geoms", "=", "torso", ".", "findall", "(", "\".//geom\"", ")", "\n", "for", "geom", "in", "geoms", ":", "\n", "      ", "if", "'name'", "not", "in", "geom", ".", "attrib", ":", "\n", "        ", "raise", "Exception", "(", "\"Every geom of the torso must have a name \"", "\n", "\"defined\"", ")", "\n", "\n", "", "", "_", ",", "file_path", "=", "tempfile", ".", "mkstemp", "(", "text", "=", "True", ",", "suffix", "=", "\".xml\"", ")", "\n", "tree", ".", "write", "(", "file_path", ")", "\n", "\n", "self", ".", "wrapped_env", "=", "model_cls", "(", "*", "args", ",", "file_path", "=", "file_path", ",", "seed", "=", "seed", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs": [[200, 203], ["numpy.concatenate", "maze_env.MazeEnv.wrapped_env._get_obs"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "def", "_get_obs", "(", "self", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "self", ".", "wrapped_env", ".", "_get_obs", "(", ")", ",", "\n", "[", "self", ".", "t", "*", "0.001", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.reset": [[204, 212], ["maze_env.MazeEnv.wrapped_env.reset", "maze_env.MazeEnv._get_obs", "len", "maze_env.MazeEnv.rng.randint", "maze_env.MazeEnv.wrapped_env.set_xy", "len"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.ant.AntEnv.set_xy"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "self", ".", "t", "=", "0", "\n", "self", ".", "wrapped_env", ".", "reset", "(", ")", "\n", "if", "len", "(", "self", ".", "_init_positions", ")", ">", "1", ":", "\n", "      ", "idx", "=", "self", ".", "rng", ".", "randint", "(", "len", "(", "self", ".", "_init_positions", ")", ")", "\n", "xy", "=", "self", ".", "_init_positions", "[", "idx", "]", "\n", "self", ".", "wrapped_env", ".", "set_xy", "(", "xy", ")", "\n", "", "return", "self", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.viewer": [[213, 216], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "viewer", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "viewer", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.render": [[217, 219], ["maze_env.MazeEnv.wrapped_env.render"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.observation_space": [[220, 226], ["gym.spaces.Box", "maze_env.MazeEnv._get_obs", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "    ", "shape", "=", "self", ".", "_get_obs", "(", ")", ".", "shape", "\n", "high", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "shape", ")", "\n", "low", "=", "-", "high", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "low", ",", "high", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.action_space": [[227, 230], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "wrapped_env", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._find_robot": [[231, 239], ["range", "len", "range", "len"], "methods", ["None"], ["", "def", "_find_robot", "(", "self", ")", ":", "\n", "    ", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "'r'", ":", "\n", "          ", "return", "j", "*", "size_scaling", ",", "i", "*", "size_scaling", "\n", "", "", "", "assert", "False", ",", "'No robot in maze specification.'", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._find_all_robots": [[240, 249], ["range", "len", "range", "len", "coords.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "_find_all_robots", "(", "self", ")", ":", "\n", "    ", "structure", "=", "self", ".", "MAZE_STRUCTURE", "\n", "size_scaling", "=", "self", ".", "MAZE_SIZE_SCALING", "\n", "coords", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", ")", ")", ":", "\n", "      ", "for", "j", "in", "range", "(", "len", "(", "structure", "[", "0", "]", ")", ")", ":", "\n", "        ", "if", "structure", "[", "i", "]", "[", "j", "]", "==", "'r'", ":", "\n", "          ", "coords", ".", "append", "(", "(", "j", "*", "size_scaling", ",", "i", "*", "size_scaling", ")", ")", "\n", "", "", "", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv.step": [[250, 256], ["maze_env.MazeEnv.wrapped_env.step", "maze_env.MazeEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "    ", "self", ".", "t", "+=", "1", "\n", "inner_next_obs", ",", "inner_reward", ",", "done", ",", "info", "=", "self", ".", "wrapped_env", ".", "step", "(", "action", ")", "\n", "next_obs", "=", "self", ".", "_get_obs", "(", ")", "\n", "done", "=", "False", "\n", "return", "next_obs", ",", "inner_reward", ",", "done", ",", "info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.create_gather_env.create_gather_env": [[4, 17], ["env_name.startswith", "cls", "cls.reset"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["def", "create_gather_env", "(", "env_name", "=", "None", ",", "seed", "=", "0", ")", ":", "\n", "  ", "if", "env_name", ".", "startswith", "(", "'Ant'", ")", ":", "\n", "    ", "cls", "=", "AntGatherEnv", "\n", "env_name", "=", "env_name", "[", "3", ":", "]", "\n", "", "else", ":", "\n", "    ", "assert", "False", ",", "'unknown env %s'", "%", "env_name", "\n", "\n", "", "gym_mujoco_kwargs", "=", "{", "\n", "'seed'", ":", "seed", "\n", "}", "\n", "gym_env", "=", "cls", "(", "**", "gym_mujoco_kwargs", ")", "\n", "gym_env", ".", "reset", "(", ")", "\n", "return", "gym_env", "\n", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.GatherEnv.__init__": [[47, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "base_env", ",", "env_name", ")", ":", "\n", "        ", "self", ".", "base_env", "=", "base_env", "\n", "self", ".", "env_name", "=", "env_name", "\n", "self", ".", "evaluate", "=", "False", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.GatherEnv.seed": [[53, 55], ["__init__.GatherEnv.base_env.seed"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed"], ["", "def", "seed", "(", "self", ",", "seed", ")", ":", "\n", "        ", "self", ".", "base_env", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.GatherEnv.reset": [[56, 63], ["__init__.GatherEnv.base_env.reset", "__init__.GatherEnv.copy"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "base_env", ".", "reset", "(", ")", "\n", "self", ".", "count", "=", "0", "\n", "return", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "obs", "[", ":", "2", "]", ",", "\n", "'desired_goal'", ":", "None", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.GatherEnv.step": [[65, 74], ["__init__.GatherEnv.base_env.step", "obs.copy"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "base_env", ".", "step", "(", "a", ")", "\n", "self", ".", "count", "+=", "1", "\n", "next_obs", "=", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "obs", "[", ":", "2", "]", ",", "\n", "'desired_goal'", ":", "None", ",", "\n", "}", "\n", "return", "next_obs", ",", "reward", ",", "done", "or", "self", ".", "count", ">=", "500", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.GatherEnv.action_space": [[75, 78], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "base_env", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.__init__": [[82, 93], ["__init__.get_reward_fn", "__init__.get_success_fn"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_reward_fn", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_success_fn"], ["    ", "def", "__init__", "(", "self", ",", "base_env", ",", "env_name", ")", ":", "\n", "        ", "self", ".", "base_env", "=", "base_env", "\n", "self", ".", "env_name", "=", "env_name", "\n", "self", ".", "evaluate", "=", "False", "\n", "self", ".", "reward_fn", "=", "get_reward_fn", "(", "env_name", ")", "\n", "self", ".", "success_fn", "=", "get_success_fn", "(", "env_name", ")", "\n", "self", ".", "goal", "=", "None", "\n", "self", ".", "distance_threshold", "=", "5", "if", "env_name", "in", "[", "'AntMaze'", ",", "'AntPush'", ",", "'AntFall'", "]", "else", "1", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "early_stop", "=", "False", "if", "env_name", "in", "[", "'AntMaze'", ",", "'AntPush'", ",", "'AntFall'", "]", "else", "True", "\n", "self", ".", "early_stop_flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed": [[94, 96], ["__init__.EnvWithGoal.base_env.seed"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed"], ["", "def", "seed", "(", "self", ",", "seed", ")", ":", "\n", "        ", "self", ".", "base_env", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.reset": [[97, 109], ["__init__.get_goal_sample_fn", "__init__.EnvWithGoal.base_env.reset", "__init__.EnvWithGoal.goal_sample_fn", "__init__.EnvWithGoal.copy"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_goal_sample_fn", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# self.viewer_setup()", "\n", "        ", "self", ".", "early_stop_flag", "=", "False", "\n", "self", ".", "goal_sample_fn", "=", "get_goal_sample_fn", "(", "self", ".", "env_name", ",", "self", ".", "evaluate", ")", "\n", "obs", "=", "self", ".", "base_env", ".", "reset", "(", ")", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "goal", "=", "self", ".", "goal_sample_fn", "(", ")", "\n", "self", ".", "desired_goal", "=", "self", ".", "goal", "if", "self", ".", "env_name", "in", "[", "'AntMaze'", ",", "'AntPush'", ",", "'AntFall'", "]", "else", "None", "\n", "return", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "obs", "[", ":", "2", "]", ",", "\n", "'desired_goal'", ":", "self", ".", "desired_goal", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.step": [[111, 124], ["__init__.EnvWithGoal.base_env.step", "__init__.EnvWithGoal.reward_fn", "__init__.EnvWithGoal.success_fn", "obs.copy"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "        ", "obs", ",", "_", ",", "done", ",", "info", "=", "self", ".", "base_env", ".", "step", "(", "a", ")", "\n", "reward", "=", "self", ".", "reward_fn", "(", "obs", ",", "self", ".", "goal", ")", "\n", "if", "self", ".", "early_stop", "and", "self", ".", "success_fn", "(", "reward", ")", ":", "\n", "            ", "self", ".", "early_stop_flag", "=", "True", "\n", "", "self", ".", "count", "+=", "1", "\n", "done", "=", "self", ".", "early_stop_flag", "and", "self", ".", "count", "%", "10", "==", "0", "\n", "next_obs", "=", "{", "\n", "'observation'", ":", "obs", ".", "copy", "(", ")", ",", "\n", "'achieved_goal'", ":", "obs", "[", ":", "2", "]", ",", "\n", "'desired_goal'", ":", "self", ".", "desired_goal", ",", "\n", "}", "\n", "return", "next_obs", ",", "reward", ",", "done", "or", "self", ".", "count", ">=", "500", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.render": [[125, 127], ["__init__.EnvWithGoal.base_env.render"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.render"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "self", ".", "base_env", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.action_space": [[128, 131], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "base_env", ".", "action_space", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_goal_sample_fn": [[9, 23], ["numpy.array", "numpy.random.uniform", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["def", "get_goal_sample_fn", "(", "env_name", ",", "evaluate", ")", ":", "\n", "    ", "if", "env_name", "==", "'AntMaze'", ":", "\n", "        ", "if", "evaluate", ":", "\n", "            ", "return", "lambda", ":", "np", ".", "array", "(", "[", "0.", ",", "16.", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "lambda", ":", "np", ".", "random", ".", "uniform", "(", "(", "-", "4", ",", "-", "4", ")", ",", "(", "20", ",", "20", ")", ")", "\n", "", "", "elif", "env_name", "==", "'AntMazeSparse'", ":", "\n", "        ", "return", "lambda", ":", "np", ".", "array", "(", "[", "2.", ",", "9.", "]", ")", "\n", "", "elif", "env_name", "==", "'AntPush'", ":", "\n", "        ", "return", "lambda", ":", "np", ".", "array", "(", "[", "0.", ",", "19.", "]", ")", "\n", "", "elif", "env_name", "==", "'AntFall'", ":", "\n", "        ", "return", "lambda", ":", "np", ".", "array", "(", "[", "0.", ",", "27.", ",", "4.5", "]", ")", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'Unknown env'", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_reward_fn": [[25, 34], ["float", "numpy.sum", "numpy.square", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square"], "function", ["None"], ["", "", "def", "get_reward_fn", "(", "env_name", ")", ":", "\n", "    ", "if", "env_name", "in", "[", "'AntMaze'", ",", "'AntPush'", "]", ":", "\n", "        ", "return", "lambda", "obs", ",", "goal", ":", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "obs", "[", ":", "2", "]", "-", "goal", ")", ")", "**", "0.5", "\n", "", "elif", "env_name", "==", "'AntMazeSparse'", ":", "\n", "        ", "return", "lambda", "obs", ",", "goal", ":", "float", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "obs", "[", ":", "2", "]", "-", "goal", ")", ")", "**", "0.5", "<", "1", ")", "\n", "", "elif", "env_name", "==", "'AntFall'", ":", "\n", "        ", "return", "lambda", "obs", ",", "goal", ":", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "obs", "[", ":", "3", "]", "-", "goal", ")", ")", "**", "0.5", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'Unknown env'", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.get_success_fn": [[36, 43], ["None"], "function", ["None"], ["", "", "def", "get_success_fn", "(", "env_name", ")", ":", "\n", "    ", "if", "env_name", "in", "[", "'AntMaze'", ",", "'AntPush'", ",", "'AntFall'", "]", ":", "\n", "        ", "return", "lambda", "reward", ":", "reward", ">", "-", "5.0", "\n", "", "elif", "env_name", "==", "'AntMazeSparse'", ":", "\n", "        ", "return", "lambda", "reward", ":", "reward", ">", "1e-6", "\n", "", "else", ":", "\n", "        ", "assert", "False", ",", "'Unknown env'", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_x": [[31, 33], ["None"], "function", ["None"], ["", "def", "can_move_x", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "X", ",", "Move", ".", "XY", ",", "Move", ".", "XZ", ",", "Move", ".", "XYZ", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_y": [[35, 37], ["None"], "function", ["None"], ["", "def", "can_move_y", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "Y", ",", "Move", ".", "XY", ",", "Move", ".", "YZ", ",", "Move", ".", "XYZ", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_z": [[39, 41], ["None"], "function", ["None"], ["", "def", "can_move_z", "(", "movable", ")", ":", "\n", "  ", "return", "movable", "in", "[", "Move", ".", "Z", ",", "Move", ".", "XZ", ",", "Move", ".", "YZ", ",", "Move", ".", "XYZ", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move": [[43, 45], ["maze_env_utils.can_move_x", "maze_env_utils.can_move_y", "maze_env_utils.can_move_z"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_x", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_y", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.can_move_z"], ["", "def", "can_move", "(", "movable", ")", ":", "\n", "  ", "return", "can_move_x", "(", "movable", ")", "or", "can_move_y", "(", "movable", ")", "or", "can_move_z", "(", "movable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env_utils.construct_maze": [[47, 91], ["NotImplementedError"], "function", ["None"], ["", "def", "construct_maze", "(", "maze_id", "=", "'Maze'", ")", ":", "\n", "  ", "if", "maze_id", "==", "'Maze'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "'r'", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Maze2'", ":", "\n", "    ", "O", "=", "'r'", "\n", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "O", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Push'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "'r'", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "Move", ".", "XY", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "0", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "elif", "maze_id", "==", "'Fall'", ":", "\n", "    ", "structure", "=", "[", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "'r'", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "Move", ".", "YZ", ",", "1", "]", ",", "\n", "[", "1", ",", "-", "1", ",", "-", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\n", "]", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", "'The provided MazeId %s is not recognized'", "%", "maze_id", ")", "\n", "\n", "", "return", "structure", "\n", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.__init__": [[21, 88], ["numpy.random.RandomState", "os.join", "xml.parse", "xml.parse.find", "dict", "xml.SubElement", "xml.SubElement", "xml.SubElement", "xml.SubElement", "tempfile.mkstemp", "xml.parse.write", "model_cls", "dict", "dict", "dict", "dict"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_apples", "=", "8", ",", "\n", "n_bombs", "=", "8", ",", "\n", "activity_range", "=", "10.", ",", "\n", "robot_object_spacing", "=", "2.", ",", "\n", "catch_range", "=", "1.", ",", "\n", "n_bins", "=", "10", ",", "\n", "sensor_range", "=", "6.", ",", "\n", "sensor_span", "=", "2", "*", "math", ".", "pi", ",", "\n", "coef_inner_rew", "=", "0.", ",", "\n", "dying_cost", "=", "-", "10", ",", "\n", "seed", "=", "0", ",", "\n", "*", "args", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "n_apples", "=", "n_apples", "\n", "self", ".", "n_bombs", "=", "n_bombs", "\n", "self", ".", "activity_range", "=", "activity_range", "\n", "self", ".", "robot_object_spacing", "=", "robot_object_spacing", "\n", "self", ".", "catch_range", "=", "catch_range", "\n", "self", ".", "n_bins", "=", "n_bins", "\n", "self", ".", "sensor_range", "=", "sensor_range", "\n", "self", ".", "sensor_span", "=", "sensor_span", "\n", "self", ".", "coef_inner_rew", "=", "coef_inner_rew", "\n", "self", ".", "dying_cost", "=", "dying_cost", "\n", "self", ".", "objects", "=", "[", "]", "\n", "self", ".", "viewer", "=", "None", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "\n", "model_cls", "=", "self", ".", "__class__", ".", "MODEL_CLASS", "\n", "if", "model_cls", "is", "None", ":", "\n", "            ", "raise", "\"MODEL_CLASS unspecified!\"", "\n", "", "xml_path", "=", "osp", ".", "join", "(", "MODEL_DIR", ",", "model_cls", ".", "FILE", ")", "\n", "tree", "=", "ET", ".", "parse", "(", "xml_path", ")", "\n", "worldbody", "=", "tree", ".", "find", "(", "\".//worldbody\"", ")", "\n", "attrs", "=", "dict", "(", "\n", "type", "=", "\"box\"", ",", "conaffinity", "=", "\"1\"", ",", "rgba", "=", "\"0.8 0.9 0.8 1\"", ",", "condim", "=", "\"3\"", "\n", ")", "\n", "walldist", "=", "self", ".", "activity_range", "+", "1", "\n", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "dict", "(", "\n", "attrs", ",", "\n", "name", "=", "\"wall1\"", ",", "\n", "pos", "=", "\"0 -%d 0\"", "%", "walldist", ",", "\n", "size", "=", "\"%d.5 0.5 1\"", "%", "walldist", ")", ")", "\n", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "dict", "(", "\n", "attrs", ",", "\n", "name", "=", "\"wall2\"", ",", "\n", "pos", "=", "\"0 %d 0\"", "%", "walldist", ",", "\n", "size", "=", "\"%d.5 0.5 1\"", "%", "walldist", ")", ")", "\n", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "dict", "(", "\n", "attrs", ",", "\n", "name", "=", "\"wall3\"", ",", "\n", "pos", "=", "\"-%d 0 0\"", "%", "walldist", ",", "\n", "size", "=", "\"0.5 %d.5 1\"", "%", "walldist", ")", ")", "\n", "ET", ".", "SubElement", "(", "\n", "worldbody", ",", "\"geom\"", ",", "dict", "(", "\n", "attrs", ",", "\n", "name", "=", "\"wall4\"", ",", "\n", "pos", "=", "\"%d 0 0\"", "%", "walldist", ",", "\n", "size", "=", "\"0.5 %d.5 1\"", "%", "walldist", ")", ")", "\n", "_", ",", "file_path", "=", "tempfile", ".", "mkstemp", "(", "text", "=", "True", ",", "suffix", "=", "'.xml'", ")", "\n", "tree", ".", "write", "(", "file_path", ")", "\n", "\n", "self", ".", "wrapped_env", "=", "model_cls", "(", "*", "args", ",", "file_path", "=", "file_path", ",", "seed", "=", "seed", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.reset": [[89, 123], ["set", "gather_env.GatherEnv.get_current_obs", "len", "gather_env.GatherEnv.objects.append", "set.add", "len", "gather_env.GatherEnv.objects.append", "set.add", "gather_env.GatherEnv.wrapped_env.reset", "gather_env.GatherEnv.rng.randint", "gather_env.GatherEnv.rng.randint", "gather_env.GatherEnv.rng.randint", "gather_env.GatherEnv.rng.randint"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.add", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["", "def", "reset", "(", "self", ",", "also_wrapped", "=", "True", ")", ":", "\n", "        ", "self", ".", "t", "=", "0", "\n", "self", ".", "objects", "=", "[", "]", "\n", "existing", "=", "set", "(", ")", "\n", "while", "len", "(", "self", ".", "objects", ")", "<", "self", ".", "n_apples", ":", "\n", "            ", "x", "=", "self", ".", "rng", ".", "randint", "(", "-", "self", ".", "activity_range", "/", "2", ",", "\n", "self", ".", "activity_range", "/", "2", ")", "*", "2", "\n", "y", "=", "self", ".", "rng", ".", "randint", "(", "-", "self", ".", "activity_range", "/", "2", ",", "\n", "self", ".", "activity_range", "/", "2", ")", "*", "2", "\n", "# regenerate, since it is too close to the robot's initial position", "\n", "if", "x", "**", "2", "+", "y", "**", "2", "<", "self", ".", "robot_object_spacing", "**", "2", ":", "\n", "                ", "continue", "\n", "", "if", "(", "x", ",", "y", ")", "in", "existing", ":", "\n", "                ", "continue", "\n", "", "typ", "=", "APPLE", "\n", "self", ".", "objects", ".", "append", "(", "(", "x", ",", "y", ",", "typ", ")", ")", "\n", "existing", ".", "add", "(", "(", "x", ",", "y", ")", ")", "\n", "", "while", "len", "(", "self", ".", "objects", ")", "<", "self", ".", "n_apples", "+", "self", ".", "n_bombs", ":", "\n", "            ", "x", "=", "self", ".", "rng", ".", "randint", "(", "-", "self", ".", "activity_range", "/", "2", ",", "\n", "self", ".", "activity_range", "/", "2", ")", "*", "2", "\n", "y", "=", "self", ".", "rng", ".", "randint", "(", "-", "self", ".", "activity_range", "/", "2", ",", "\n", "self", ".", "activity_range", "/", "2", ")", "*", "2", "\n", "# regenerate, since it is too close to the robot's initial position", "\n", "if", "x", "**", "2", "+", "y", "**", "2", "<", "self", ".", "robot_object_spacing", "**", "2", ":", "\n", "                ", "continue", "\n", "", "if", "(", "x", ",", "y", ")", "in", "existing", ":", "\n", "                ", "continue", "\n", "", "typ", "=", "BOMB", "\n", "self", ".", "objects", ".", "append", "(", "(", "x", ",", "y", ",", "typ", ")", ")", "\n", "existing", ".", "add", "(", "(", "x", ",", "y", ")", ")", "\n", "\n", "", "if", "also_wrapped", ":", "\n", "            ", "self", ".", "wrapped_env", ".", "reset", "(", ")", "\n", "", "return", "self", ".", "get_current_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.step": [[124, 151], ["gather_env.GatherEnv.wrapped_env.step", "gather_env.GatherEnv.wrapped_env.get_body_com", "len", "gather_env.GatherEnv.get_current_obs", "gather_env.GatherEnv.get_current_obs", "new_objs.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "t", "+=", "1", "\n", "\n", "_", ",", "inner_rew", ",", "done", ",", "info", "=", "self", ".", "wrapped_env", ".", "step", "(", "action", ")", "\n", "info", "[", "'inner_rew'", "]", "=", "inner_rew", "\n", "info", "[", "'outer_rew'", "]", "=", "0", "\n", "if", "done", ":", "\n", "            ", "return", "self", ".", "get_current_obs", "(", ")", ",", "self", ".", "dying_cost", ",", "done", ",", "info", "# give a -10 rew if the robot dies", "\n", "", "com", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "\"torso\"", ")", "\n", "x", ",", "y", "=", "com", "[", ":", "2", "]", "\n", "reward", "=", "self", ".", "coef_inner_rew", "*", "inner_rew", "\n", "new_objs", "=", "[", "]", "\n", "for", "obj", "in", "self", ".", "objects", ":", "\n", "            ", "ox", ",", "oy", ",", "typ", "=", "obj", "\n", "# object within zone!", "\n", "if", "(", "ox", "-", "x", ")", "**", "2", "+", "(", "oy", "-", "y", ")", "**", "2", "<", "self", ".", "catch_range", "**", "2", ":", "\n", "                ", "if", "typ", "==", "APPLE", ":", "\n", "                    ", "reward", "=", "reward", "+", "1", "\n", "info", "[", "'outer_rew'", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "reward", "=", "reward", "-", "1", "\n", "info", "[", "'outer_rew'", "]", "=", "-", "1", "\n", "", "", "else", ":", "\n", "                ", "new_objs", ".", "append", "(", "obj", ")", "\n", "", "", "self", ".", "objects", "=", "new_objs", "\n", "done", "=", "len", "(", "self", ".", "objects", ")", "==", "0", "\n", "return", "self", ".", "get_current_obs", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_readings": [[152, 193], ["numpy.zeros", "numpy.zeros", "gather_env.GatherEnv.get_ori", "gather_env.GatherEnv.wrapped_env.get_body_com", "sorted", "math.isnan", "int", "math.atan2", "ipdb.set_trace", "abs"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_ori"], ["", "def", "get_readings", "(", "self", ")", ":", "# equivalent to get_current_maze_obs in maze_env.py", "\n", "# compute sensor readings", "\n", "# first, obtain current orientation", "\n", "        ", "apple_readings", "=", "np", ".", "zeros", "(", "self", ".", "n_bins", ")", "\n", "bomb_readings", "=", "np", ".", "zeros", "(", "self", ".", "n_bins", ")", "\n", "robot_x", ",", "robot_y", "=", "self", ".", "wrapped_env", ".", "get_body_com", "(", "\"torso\"", ")", "[", ":", "2", "]", "\n", "# sort objects by distance to the robot, so that farther objects'", "\n", "# signals will be occluded by the closer ones'", "\n", "sorted_objects", "=", "sorted", "(", "\n", "self", ".", "objects", ",", "key", "=", "lambda", "o", ":", "\n", "(", "o", "[", "0", "]", "-", "robot_x", ")", "**", "2", "+", "(", "o", "[", "1", "]", "-", "robot_y", ")", "**", "2", ")", "[", ":", ":", "-", "1", "]", "\n", "# fill the readings", "\n", "bin_res", "=", "self", ".", "sensor_span", "/", "self", ".", "n_bins", "\n", "\n", "ori", "=", "self", ".", "get_ori", "(", ")", "# overwrite this for Ant!", "\n", "\n", "for", "ox", ",", "oy", ",", "typ", "in", "sorted_objects", ":", "\n", "# compute distance between object and robot", "\n", "            ", "dist", "=", "(", "(", "oy", "-", "robot_y", ")", "**", "2", "+", "(", "ox", "-", "robot_x", ")", "**", "2", ")", "**", "0.5", "\n", "# only include readings for objects within range", "\n", "if", "dist", ">", "self", ".", "sensor_range", ":", "\n", "                ", "continue", "\n", "", "angle", "=", "math", ".", "atan2", "(", "oy", "-", "robot_y", ",", "ox", "-", "robot_x", ")", "-", "ori", "\n", "if", "math", ".", "isnan", "(", "angle", ")", ":", "\n", "                ", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "", "angle", "=", "angle", "%", "(", "2", "*", "math", ".", "pi", ")", "\n", "if", "angle", ">", "math", ".", "pi", ":", "\n", "                ", "angle", "=", "angle", "-", "2", "*", "math", ".", "pi", "\n", "", "if", "angle", "<", "-", "math", ".", "pi", ":", "\n", "                ", "angle", "=", "angle", "+", "2", "*", "math", ".", "pi", "\n", "# outside of sensor span - skip this", "\n", "", "half_span", "=", "self", ".", "sensor_span", "*", "0.5", "\n", "if", "abs", "(", "angle", ")", ">", "half_span", ":", "\n", "                ", "continue", "\n", "", "bin_number", "=", "int", "(", "(", "angle", "+", "half_span", ")", "/", "bin_res", ")", "\n", "intensity", "=", "1.0", "-", "dist", "/", "self", ".", "sensor_range", "\n", "if", "typ", "==", "APPLE", ":", "\n", "                ", "apple_readings", "[", "bin_number", "]", "=", "intensity", "\n", "", "else", ":", "\n", "                ", "bomb_readings", "[", "bin_number", "]", "=", "intensity", "\n", "", "", "return", "apple_readings", ",", "bomb_readings", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_robot_obs": [[194, 196], ["gather_env.GatherEnv.wrapped_env._get_obs"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs"], ["", "def", "get_current_robot_obs", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_env", ".", "_get_obs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_obs": [[197, 202], ["gather_env.GatherEnv.wrapped_env._get_obs", "gather_env.GatherEnv.get_readings", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.maze_env.MazeEnv._get_obs", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_readings"], ["", "def", "get_current_obs", "(", "self", ")", ":", "\n", "# return sensor data along with data about itself", "\n", "        ", "self_obs", "=", "self", ".", "wrapped_env", ".", "_get_obs", "(", ")", "\n", "apple_readings", ",", "bomb_readings", "=", "self", ".", "get_readings", "(", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "self_obs", ",", "apple_readings", ",", "bomb_readings", "]", "+", "[", "[", "self", ".", "t", "*", "0.01", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.observation_space": [[203, 208], ["gym.spaces.Box", "gather_env.GatherEnv.get_current_obs", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_obs"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "shp", "=", "self", ".", "get_current_obs", "(", ")", ".", "shape", "\n", "ub", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "shp", ")", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "ub", "*", "-", "1", ",", "ub", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.robot_observation_space": [[210, 215], ["gym.spaces.Box", "gather_env.GatherEnv.get_current_robot_obs", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_current_robot_obs"], ["", "@", "property", "\n", "def", "robot_observation_space", "(", "self", ")", ":", "\n", "        ", "shp", "=", "self", ".", "get_current_robot_obs", "(", ")", ".", "shape", "\n", "ub", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "shp", ")", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "ub", "*", "-", "1", ",", "ub", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.maze_observation_space": [[216, 221], ["gym.spaces.Box", "numpy.concatenate", "numpy.ones", "gather_env.GatherEnv.get_readings"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_readings"], ["", "@", "property", "\n", "def", "maze_observation_space", "(", "self", ")", ":", "\n", "        ", "shp", "=", "np", ".", "concatenate", "(", "self", ".", "get_readings", "(", ")", ")", ".", "shape", "\n", "ub", "=", "np", ".", "inf", "*", "np", ".", "ones", "(", "shp", ")", "\n", "return", "gym", ".", "spaces", ".", "Box", "(", "ub", "*", "-", "1", ",", "ub", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.action_space": [[222, 225], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_env", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.action_bounds": [[226, 229], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_bounds", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_env", ".", "action_bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.action_from_key": [[234, 236], ["gather_env.GatherEnv.wrapped_env.action_from_key"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.action_from_key"], ["", "def", "action_from_key", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "wrapped_env", ".", "action_from_key", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_viewer": [[237, 243], ["None"], "methods", ["None"], ["", "def", "get_viewer", "(", "self", ")", ":", "\n", "# if self.wrapped_env.viewer is None:", "\n", "#     self.wrapped_env.viewer = GatherViewer(self)", "\n", "#     self.wrapped_env.viewer.start()", "\n", "#     self.wrapped_env.viewer.set_model(self.wrapped_env.model)", "\n", "        ", "return", "self", ".", "wrapped_env", ".", "viewer", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.stop_viewer": [[244, 247], ["gather_env.GatherEnv.wrapped_env.viewer.finish"], "methods", ["None"], ["", "def", "stop_viewer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "wrapped_env", ".", "viewer", ":", "\n", "            ", "self", ".", "wrapped_env", ".", "viewer", ".", "finish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.render": [[248, 258], ["gather_env.GatherEnv.get_viewer().render", "gather_env.GatherEnv.get_viewer().get_image", "gather_env.GatherEnv.stop_viewer", "numpy.fromstring().reshape", "gather_env.GatherEnv.get_viewer", "gather_env.GatherEnv.wrapped_env.render", "gather_env.GatherEnv.get_viewer", "gather_env.GatherEnv.get_viewer", "numpy.fromstring"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.render", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.stop_viewer", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_viewer", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.render", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_viewer", "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_viewer"], ["", "", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "False", ")", ":", "\n", "        ", "if", "mode", "==", "'rgb_array'", ":", "\n", "            ", "self", ".", "get_viewer", "(", ")", ".", "render", "(", ")", "\n", "data", ",", "width", ",", "height", "=", "self", ".", "get_viewer", "(", ")", ".", "get_image", "(", ")", "\n", "return", "np", ".", "fromstring", "(", "data", ",", "dtype", "=", "'uint8'", ")", ".", "reshape", "(", "height", ",", "width", ",", "3", ")", "[", ":", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "", "elif", "mode", "==", "'human'", ":", "\n", "            ", "self", ".", "get_viewer", "(", ")", "\n", "self", ".", "wrapped_env", ".", "render", "(", ")", "\n", "", "if", "close", ":", "\n", "            ", "self", ".", "stop_viewer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_ori": [[259, 268], ["obj.get_ori", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.gather_env.GatherEnv.get_ori"], ["", "", "def", "get_ori", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        First it tries to use a get_ori from the wrapped env. If not successfull, falls\n        back to the default based on the ORI_IND specified in Maze (not accurate for quaternions)\n        \"\"\"", "\n", "obj", "=", "self", ".", "wrapped_env", "\n", "while", "not", "hasattr", "(", "obj", ",", "'get_ori'", ")", "and", "hasattr", "(", "obj", ",", "'wrapped_env'", ")", ":", "\n", "            ", "obj", "=", "obj", ".", "wrapped_env", "\n", "", "return", "obj", ".", "get_ori", "(", ")", "\n", "# try:", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.main.main": [[7, 10], ["solver.Solver", "solver.Solver.train"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train"], ["    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--algo\"", ",", "default", "=", "\"hrac\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_freq\"", ",", "default", "=", "5e3", ",", "type", "=", "float", ")", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.__init__": [[9, 12], ["solver.Solver.set_seed", "agent.Agent"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.set_seed"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "set_seed", "(", "args", ".", "seed", ")", "\n", "self", ".", "agent", "=", "Agent", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.set_seed": [[13, 19], ["torch.manual_seed", "numpy.random.seed"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.envs.__init__.EnvWithGoal.seed"], ["", "def", "set_seed", "(", "self", ",", "seed", ")", ":", "\n", "# set random seed for reproducibility", "\n", "        ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.train": [[20, 22], ["solver.Solver.agent.train"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.show": [[23, 25], ["solver.Solver.agent.show"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.solver.Solver.show"], ["", "def", "show", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "show", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.__init__": [[23, 114], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "datetime.datetime.now().strftime", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils.make_path", "utils.make_path", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "memory.HighLevelReplayBuffer", "memory.LowLevelMemory", "agent.Agent.build_model", "numpy.diag", "memory.TrajectoryMemory", "env.MazeEnv", "env.MazeEnv", "utils.make_path", "open", "json.dump", "agent.Agent.load_model", "numpy.ones", "env.KeyChestEnv", "env.KeyChestEnv", "datetime.datetime.now", "os.path.join", "vars"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.make_path", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.make_path", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.build_model", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.make_path", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.load_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "algo", "=", "args", ".", "algo", "\n", "self", ".", "k", "=", "args", ".", "manager_propose_freq", "\n", "self", ".", "goal_loss_coeff", "=", "args", ".", "goal_loss_coeff", "\n", "self", ".", "n_noisy_goals", "=", "args", ".", "n_noisy_goals", "\n", "self", ".", "man_discount", "=", "args", ".", "man_discount", "\n", "self", ".", "ctrl_discount", "=", "args", ".", "ctrl_discount", "\n", "\n", "self", ".", "r_margin_pos", "=", "args", ".", "r_margin_pos", "\n", "self", ".", "r_margin_neg", "=", "args", ".", "r_margin_neg", "\n", "self", ".", "r_init_epochs", "=", "args", ".", "r_init_epochs", "\n", "self", ".", "r_training_epochs", "=", "args", ".", "r_training_epochs", "\n", "self", ".", "r_training_freq", "=", "args", ".", "r_training_freq", "\n", "self", ".", "r_batch_size", "=", "args", ".", "r_batch_size", "\n", "\n", "self", ".", "man_noise_sigma", "=", "args", ".", "man_noise_sigma", "\n", "self", ".", "man_policy_update_freq", "=", "args", ".", "man_policy_update_freq", "\n", "\n", "self", ".", "ctrl_entropy", "=", "args", ".", "ctrl_entropy", "\n", "\n", "self", ".", "man_rew_scale", "=", "args", ".", "man_rew_scale", "\n", "self", ".", "ctrl_rew_scale", "=", "args", ".", "ctrl_rew_scale", "\n", "\n", "self", ".", "eval_freq", "=", "args", ".", "eval_freq", "\n", "self", ".", "eval_episodes", "=", "args", ".", "eval_episodes", "\n", "self", ".", "save_models", "=", "args", ".", "save_models", "\n", "self", ".", "model_save_freq", "=", "10000", "\n", "self", ".", "log_freq", "=", "1", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:{}'", ".", "format", "(", "args", ".", "gid", ")", ")", "\n", "\n", "if", "args", ".", "env_name", "==", "'Maze'", ":", "\n", "            ", "self", ".", "env", "=", "MazeEnv", "(", "step_limit", "=", "200", ",", "seed", "=", "args", ".", "seed", ")", "\n", "self", ".", "eval_env", "=", "MazeEnv", "(", "step_limit", "=", "200", ",", "seed", "=", "args", ".", "seed", "+", "100", ")", "\n", "self", ".", "x_range", "=", "self", ".", "env", ".", "h", "\n", "self", ".", "y_range", "=", "self", ".", "env", ".", "w", "\n", "self", ".", "action_scale_l", "=", "None", "\n", "self", ".", "total_training_frames", "=", "1000000", "\n", "self", ".", "random_start", "=", "False", "\n", "", "elif", "args", ".", "env_name", "==", "'KeyChest'", ":", "\n", "            ", "self", ".", "env", "=", "KeyChestEnv", "(", "step_limit", "=", "500", ",", "random_start", "=", "True", ",", "seed", "=", "args", ".", "seed", ")", "\n", "self", ".", "eval_env", "=", "KeyChestEnv", "(", "step_limit", "=", "500", ",", "random_start", "=", "True", ",", "seed", "=", "args", ".", "seed", "+", "100", ")", "\n", "self", ".", "x_range", "=", "self", ".", "env", ".", "h", "\n", "self", ".", "y_range", "=", "self", ".", "env", ".", "w", "\n", "self", ".", "action_scale_l", "=", "None", "\n", "self", ".", "total_training_frames", "=", "2000000", "\n", "self", ".", "random_start", "=", "True", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "obs_dim", "=", "self", ".", "env", ".", "obs_dim", "\n", "self", ".", "action_dim", "=", "self", ".", "env", ".", "action_dim", "\n", "self", ".", "goal_dim", "=", "2", "\n", "\n", "self", ".", "origin_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%m%d-%H%M'", ")", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "'output'", ",", "args", ".", "env_name", ",", "self", ".", "origin_time", ")", "\n", "self", ".", "model_load_path", "=", "os", ".", "path", ".", "join", "(", "'trained_models'", ",", "args", ".", "env_name", ")", "\n", "self", ".", "model_save_path", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "'models'", ")", "\n", "self", ".", "log_path", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "'log'", ")", "\n", "self", ".", "result_path", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "'results'", ")", "\n", "self", ".", "output_data", "=", "{", "'frames'", ":", "[", "]", ",", "'reward'", ":", "[", "]", "}", "\n", "self", ".", "output_filename", "=", "'{}_{}_{}.csv'", ".", "format", "(", "args", ".", "env_name", ",", "self", ".", "algo", ",", "args", ".", "seed", ")", "\n", "\n", "if", "self", ".", "save_models", ":", "\n", "            ", "utils", ".", "make_path", "(", "self", ".", "model_save_path", ")", "\n", "", "utils", ".", "make_path", "(", "self", ".", "log_path", ")", "\n", "utils", ".", "make_path", "(", "self", ".", "result_path", ")", "\n", "self", ".", "summary_writer", "=", "SummaryWriter", "(", "self", ".", "log_path", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "result_path", ",", "'params.json'", ")", ",", "'w'", ")", "as", "json_file", ":", "\n", "            ", "json", ".", "dump", "(", "vars", "(", "args", ")", ",", "json_file", ",", "indent", "=", "0", ")", "\n", "\n", "", "self", ".", "replay_buffer_h", "=", "HighLevelReplayBuffer", "(", "args", ".", "man_buffer_size", ",", "args", ".", "man_batch_size", ",", "\n", "self", ".", "obs_dim", ",", "self", ".", "goal_dim", ")", "\n", "self", ".", "memory_l", "=", "LowLevelMemory", "(", ")", "\n", "\n", "self", ".", "build_model", "(", "args", ")", "\n", "if", "args", ".", "load_model", ":", "\n", "            ", "self", ".", "load_model", "(", ")", "\n", "\n", "", "self", ".", "n_states", "=", "0", "\n", "self", ".", "state_list", "=", "[", "]", "\n", "self", ".", "state_dict", "=", "{", "}", "\n", "self", ".", "adj_mat", "=", "np", ".", "diag", "(", "np", ".", "ones", "(", "500", ",", "dtype", "=", "np", ".", "uint8", ")", ")", "\n", "self", ".", "traj_memory", "=", "TrajectoryMemory", "(", "capacity", "=", "args", ".", "r_init_steps", ")", "\n", "\n", "self", ".", "_episodes", "=", "0", "\n", "self", ".", "_frames", "=", "0", "\n", "self", ".", "policy_update_it", "=", "0", "\n", "self", ".", "loss_l", "=", "None", "\n", "self", ".", "loss_h", "=", "None", "\n", "self", ".", "mean_int_reward", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.build_model": [[115, 129], ["model.HRLNet", "agent.Agent.net.to", "model.ANet", "agent.Agent.a_net.to", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "agent.Agent.a_net.parameters", "agent.Agent.net.actor_h.parameters", "agent.Agent.net.critic_h.parameters", "agent.Agent.net.policy_l.parameters"], "methods", ["None"], ["", "def", "build_model", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "net", "=", "HRLNet", "(", "self", ".", "obs_dim", ",", "self", ".", "goal_dim", ",", "self", ".", "action_dim", ",", "args", ".", "hidden_dim", ",", "\n", "self", ".", "x_range", ",", "self", ".", "y_range", ",", "self", ".", "k", ",", "self", ".", "n_noisy_goals", ",", "args", ".", "man_soft_sync_rate", ",", "\n", "low_action_scale", "=", "self", ".", "action_scale_l", ")", "\n", "self", ".", "net", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "a_net", "=", "ANet", "(", "self", ".", "goal_dim", ",", "args", ".", "r_hidden_dim", ",", "args", ".", "r_embedding_dim", ")", "\n", "self", ".", "a_net", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "optimizer_r", "=", "optim", ".", "Adam", "(", "self", ".", "a_net", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr_r", ")", "\n", "self", ".", "optimizer_actor_h", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "actor_h", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "man_act_lr", ")", "\n", "self", ".", "optimizer_critic_h", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "critic_h", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "man_crit_lr", ",", "weight_decay", "=", "args", ".", "weight_decay_critic", ")", "\n", "\n", "self", ".", "optimizer_l", "=", "optim", ".", "Adam", "(", "self", ".", "net", ".", "policy_l", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "ctrl_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.load_model": [[130, 134], ["os.path.join", "print", "agent.Agent.net.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.load"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_load_path", ",", "'{}.pth'", ".", "format", "(", "self", ".", "algo", ")", ")", "\n", "print", "(", "'Loading the trained model: {}...'", ".", "format", "(", "filename", ")", ")", "\n", "self", ".", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.save_model": [[135, 142], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.join", "os.path.join", "agent.Agent.net.state_dict"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save"], ["", "def", "save_model", "(", "self", ",", "episode", "=", "None", ")", ":", "\n", "        ", "if", "episode", "is", "not", "None", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_path", ",", "'{}_{}.pth'", ".", "format", "(", "self", ".", "algo", ",", "episode", ")", ")", "\n", "", "else", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_path", ",", "'{}.pth'", ".", "format", "(", "self", ".", "algo", ")", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "net", ".", "state_dict", "(", ")", ",", "filename", ")", "\n", "print", "(", "'************** Model {} saved. **************'", ".", "format", "(", "episode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train": [[143, 196], ["print", "time.time", "print", "agent.Agent.update_adj_mat", "metric.train_anet", "agent.Agent.test_adjacency_acc", "agent.Agent.traj_memory.reset", "agent.Agent.traj_memory.set_capacity", "agent.Agent.summary_writer.close", "pandas.DataFrame", "pandas.DataFrame.to_csv", "print", "agent.Agent.traj_memory.full", "agent.Agent.interact_one_episode", "agent.Agent.interact_one_episode", "agent.Agent.train_one_episode", "agent.Agent.traj_memory.full", "agent.Agent.save_model", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "agent.Agent.test", "print", "agent.Agent.update_adj_mat", "metric.train_anet", "agent.Agent.test_adjacency_acc", "agent.Agent.traj_memory.reset", "agent.Agent.log_train", "agent.Agent.test", "agent.Agent.save_model", "agent.Agent.a_net.state_dict"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.update_adj_mat", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.train_anet", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test_adjacency_acc", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.set_capacity", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.full", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.interact_one_episode", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.interact_one_episode", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_one_episode", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.full", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.save_model", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.hrac.utils.ReplayBuffer.save", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.update_adj_mat", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.train_anet", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test_adjacency_acc", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.log_train", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.save_model"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"===================== Training {} starts =====================\"", ".", "format", "(", "self", ".", "algo", ")", ")", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'Pre-training adjacency network...'", ")", "\n", "self", ".", "env", ".", "pure_exploration", "=", "True", "\n", "self", ".", "env", ".", "random_start", "=", "True", "\n", "while", "not", "self", ".", "traj_memory", ".", "full", "(", ")", ":", "\n", "            ", "self", ".", "_episodes", "+=", "1", "\n", "self", ".", "interact_one_episode", "(", "train", "=", "False", ")", "\n", "# print('Gathered samples: {} / {}'.format(self.traj_memory.size(), self.traj_memory._capacity))", "\n", "", "self", ".", "update_adj_mat", "(", ")", "\n", "train_anet", "(", "self", ".", "a_net", ",", "self", ".", "state_list", ",", "self", ".", "adj_mat", "[", ":", "self", ".", "n_states", ",", ":", "self", ".", "n_states", "]", ",", "self", ".", "optimizer_r", ",", "\n", "self", ".", "r_margin_pos", ",", "self", ".", "r_margin_neg", ",", "n_epochs", "=", "self", ".", "r_init_epochs", ",", "batch_size", "=", "self", ".", "r_batch_size", ",", "\n", "device", "=", "self", ".", "device", ",", "verbose", "=", "False", ")", "\n", "self", ".", "test_adjacency_acc", "(", ")", "\n", "self", ".", "env", ".", "pure_exploration", "=", "False", "\n", "self", ".", "env", ".", "random_start", "=", "self", ".", "random_start", "\n", "\n", "self", ".", "traj_memory", ".", "reset", "(", ")", "\n", "self", ".", "traj_memory", ".", "set_capacity", "(", "self", ".", "r_training_freq", ")", "\n", "\n", "while", "self", ".", "_frames", "<=", "self", ".", "total_training_frames", ":", "\n", "            ", "if", "self", ".", "_episodes", "==", "0", ":", "\n", "                ", "self", ".", "test", "(", ")", "\n", "", "self", ".", "interact_one_episode", "(", ")", "\n", "self", ".", "train_one_episode", "(", ")", "\n", "self", ".", "_episodes", "+=", "1", "\n", "if", "self", ".", "traj_memory", ".", "full", "(", ")", ":", "\n", "                ", "print", "(", "'Training adjacency network...'", ")", "\n", "self", ".", "update_adj_mat", "(", ")", "\n", "train_anet", "(", "self", ".", "a_net", ",", "self", ".", "state_list", ",", "self", ".", "adj_mat", "[", ":", "self", ".", "n_states", ",", ":", "self", ".", "n_states", "]", ",", "self", ".", "optimizer_r", ",", "\n", "self", ".", "r_margin_pos", ",", "self", ".", "r_margin_neg", ",", "n_epochs", "=", "self", ".", "r_training_epochs", ",", "\n", "batch_size", "=", "self", ".", "r_batch_size", ",", "device", "=", "self", ".", "device", ",", "verbose", "=", "False", ")", "\n", "self", ".", "test_adjacency_acc", "(", ")", "\n", "self", ".", "traj_memory", ".", "reset", "(", ")", "\n", "\n", "", "if", "self", ".", "_episodes", "%", "self", ".", "log_freq", "==", "0", ":", "\n", "                ", "self", ".", "log_train", "(", ")", "\n", "", "if", "self", ".", "_episodes", "%", "self", ".", "eval_freq", "==", "0", ":", "\n", "                ", "self", ".", "test", "(", ")", "\n", "", "if", "self", ".", "_episodes", "%", "self", ".", "model_save_freq", "==", "0", "and", "self", ".", "save_models", ":", "\n", "                ", "self", ".", "save_model", "(", "self", ".", "_episodes", ")", "\n", "\n", "", "", "if", "self", ".", "save_models", ":", "\n", "            ", "self", ".", "save_model", "(", "'last'", ")", "\n", "r_filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_save_path", ",", "'a_network.pth'", ".", "format", "(", "self", ".", "_episodes", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "a_net", ".", "state_dict", "(", ")", ",", "r_filename", ")", "\n", "", "self", ".", "summary_writer", ".", "close", "(", ")", "\n", "output_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "output_data", ")", "\n", "output_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "self", ".", "result_path", ",", "self", ".", "output_filename", ")", ",", "float_format", "=", "'%.4f'", ",", "index", "=", "False", ")", "\n", "\n", "print", "(", "\"======================= Training {} ends =======================\"", ".", "format", "(", "self", ".", "algo", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test": [[197, 213], ["print", "range", "print", "agent.Agent.output_data[].append", "agent.Agent.output_data[].append", "agent.Agent.summary_writer.add_scalar", "agent.Agent.summary_writer.add_scalar", "agent.Agent.test_one_episode"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test_one_episode"], ["", "def", "test", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"[@@ {} @@] ************** Testing at episode {} **************\"", ".", "format", "(", "self", ".", "algo", ",", "self", ".", "_episodes", ")", ")", "\n", "reward_total", "=", "0.", "\n", "dist_total", "=", "0.", "\n", "for", "i", "in", "range", "(", "self", ".", "eval_episodes", ")", ":", "\n", "            ", "reward", ",", "dist", "=", "self", ".", "test_one_episode", "(", ")", "\n", "reward_total", "+=", "reward", "\n", "dist_total", "+=", "dist", "\n", "", "reward_avg", "=", "reward_total", "/", "self", ".", "eval_episodes", "\n", "dist_avg", "=", "dist_total", "/", "self", ".", "eval_episodes", "\n", "print", "(", "'Average reward: {:.4f}, average dist: {:.4f}'", ".", "format", "(", "reward_avg", ",", "dist_avg", ")", ")", "\n", "self", ".", "output_data", "[", "'frames'", "]", ".", "append", "(", "self", ".", "_frames", ")", "\n", "self", ".", "output_data", "[", "'reward'", "]", ".", "append", "(", "reward_avg", ")", "\n", "# self.output_data['dist'].append(dist_avg)", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'average test reward'", ",", "reward_avg", ",", "self", ".", "_frames", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'average test dist'", ",", "dist_avg", ",", "self", ".", "_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.interact_one_episode": [[214, 276], ["agent.Agent.env.new_episode", "agent.Agent.env.get_state", "agent.Agent.memory_l.reset", "agent.Agent.traj_memory.create_new_trajectory", "agent.Agent.replay_buffer_h.start", "utils.single_input_transform", "agent.Agent.step", "action.copy", "agent.Agent.env.get_state", "agent.Agent.env.is_episode_finished", "last_goal.detach().squeeze().cpu().numpy", "dict", "agent.Agent.memory_l.append", "agent.Agent.traj_memory.append", "utils.single_input_transform", "agent.Agent.traj_memory.append", "agent.Agent.step", "agent.Agent.env.make_action", "agent.Agent.env.get_state", "agent.Agent.env.is_episode_finished", "agent.Agent.env.make_action", "last_goal.detach().squeeze().cpu().numpy", "agent.Agent.replay_buffer_h.append", "utils.single_input_transform", "agent.Agent.memory_l.states.append", "agent.Agent.traj_memory.append", "agent.Agent.env.get_current_step", "agent.Agent.env.get_total_reward", "agent.Agent.traj_memory.append", "agent.Agent.env.get_current_step", "agent.Agent.env.get_current_step", "last_goal.detach().squeeze().cpu", "agent.Agent.replay_buffer_h.append", "agent.Agent.env.get_current_step", "agent.Agent.env.get_current_step", "agent.Agent.env.get_current_step", "last_goal.detach().squeeze().cpu", "last_goal.detach().squeeze", "last_goal.detach().squeeze", "last_goal.detach", "last_goal.detach"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.new_episode", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.get_state", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.create_new_trajectory", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.start", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.single_input_transform", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.get_state", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.is_episode_finished", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.single_input_transform", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.make_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.get_state", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.is_episode_finished", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.make_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.single_input_transform", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_total_reward", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step"], ["", "def", "interact_one_episode", "(", "self", ",", "train", "=", "True", ")", ":", "\n", "        ", "self", ".", "env", ".", "new_episode", "(", ")", "\n", "obs_curr", "=", "self", ".", "env", ".", "get_state", "(", ")", "\n", "self", ".", "memory_l", ".", "reset", "(", ")", "\n", "self", ".", "traj_memory", ".", "create_new_trajectory", "(", ")", "\n", "last_state", "=", "None", "\n", "last_goal", "=", "None", "\n", "\n", "if", "train", ":", "\n", "            ", "r_horizon", "=", "0.", "\n", "start_flag", "=", "self", ".", "replay_buffer_h", ".", "start", "(", ")", "\n", "while", "True", ":", "\n", "                ", "obs_var", "=", "utils", ".", "single_input_transform", "(", "obs_curr", ",", "device", "=", "self", ".", "device", ")", "\n", "flag", "=", "(", "self", ".", "env", ".", "get_current_step", "(", ")", "%", "self", ".", "k", "==", "0", ")", "\n", "\n", "action", ",", "last_goal", ",", "last_state", ",", "(", "prob", ",", "log_prob", ",", "log_prob_act", ",", "value_l", ")", "=", "self", ".", "step", "(", "\n", "obs_var", ",", "last_state", ",", "last_goal", ",", "flag", ",", "start_flag", "=", "start_flag", ")", "\n", "\n", "action_copy", "=", "action", ".", "copy", "(", ")", "\n", "r", "=", "self", ".", "man_rew_scale", "*", "self", ".", "env", ".", "make_action", "(", "action_copy", ")", "\n", "obs_new", "=", "self", ".", "env", ".", "get_state", "(", ")", "\n", "done", "=", "self", ".", "env", ".", "is_episode_finished", "(", ")", "\n", "last_goal_np", "=", "last_goal", ".", "detach", "(", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "(", "self", ".", "env", ".", "get_current_step", "(", ")", "-", "1", ")", "%", "self", ".", "k", "!=", "0", ":", "\n", "                    ", "r_horizon", "+=", "r", "\n", "", "else", ":", "\n", "                    ", "if", "(", "self", ".", "env", ".", "get_current_step", "(", ")", "-", "1", ")", "!=", "0", ":", "\n", "                        ", "self", ".", "replay_buffer_h", ".", "append", "(", "state_store", ",", "goal_store", ",", "r_horizon", ",", "obs_curr", ",", "done", ")", "\n", "", "goal_store", "=", "last_goal", ".", "detach", "(", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "state_store", "=", "obs_curr", "\n", "r_horizon", "=", "r", "\n", "\n", "", "info_low", "=", "dict", "(", "prob", "=", "prob", ",", "log_prob", "=", "log_prob", ",", "log_prob_act", "=", "log_prob_act", ",", "value_l", "=", "value_l", ")", "\n", "self", ".", "memory_l", ".", "append", "(", "last_state", ",", "last_goal", ",", "action", ",", "info_low", ")", "\n", "self", ".", "traj_memory", ".", "append", "(", "obs_curr", ")", "\n", "obs_curr", "=", "obs_new", "\n", "\n", "if", "done", ":", "\n", "                    ", "self", ".", "replay_buffer_h", ".", "append", "(", "state_store", ",", "goal_store", ",", "r_horizon", ",", "obs_curr", ",", "done", ")", "\n", "obs_var", "=", "utils", ".", "single_input_transform", "(", "obs_curr", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "memory_l", ".", "states", ".", "append", "(", "obs_var", ")", "\n", "self", ".", "traj_memory", ".", "append", "(", "obs_curr", ")", "\n", "self", ".", "_frames", "+=", "self", ".", "env", ".", "get_current_step", "(", ")", "\n", "self", ".", "curr_reward", "=", "self", ".", "env", ".", "get_total_reward", "(", ")", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "obs_var", "=", "utils", ".", "single_input_transform", "(", "obs_curr", ",", "device", "=", "self", ".", "device", ")", "\n", "flag", "=", "(", "self", ".", "env", ".", "get_current_step", "(", ")", "%", "self", ".", "k", "==", "0", ")", "\n", "self", ".", "traj_memory", ".", "append", "(", "obs_curr", ")", "\n", "\n", "action", ",", "last_goal", ",", "last_state", ",", "_", "=", "self", ".", "step", "(", "\n", "obs_var", ",", "last_state", ",", "last_goal", ",", "flag", ",", "start_flag", "=", "False", ",", "evaluate", "=", "False", ")", "\n", "self", ".", "env", ".", "make_action", "(", "action", ")", "\n", "obs_new", "=", "self", ".", "env", ".", "get_state", "(", ")", "\n", "done", "=", "self", ".", "env", ".", "is_episode_finished", "(", ")", "\n", "obs_curr", "=", "obs_new", "\n", "if", "done", ":", "\n", "                    ", "self", ".", "traj_memory", ".", "append", "(", "obs_curr", ")", "\n", "self", ".", "_frames", "+=", "self", ".", "env", ".", "get_current_step", "(", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.step": [[277, 316], ["agent.Agent.net", "torch.softmax.multinomial", "torch.log_softmax.gather().squeeze", "F.softmax.multinomial.squeeze().detach().cpu().numpy", "agent.Agent.net.policy_l", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax.multinomial", "torch.log_softmax.gather().squeeze", "agent.Agent.net.policy_l", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.softmax.multinomial", "torch.log_softmax.gather().squeeze", "torch.log_softmax.gather", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.rand().unsqueeze().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "agent.Agent.goal_transition", "agent.Agent.net.actor_h", "agent.Agent.goal_transition", "F.softmax.multinomial.squeeze().detach().cpu", "torch.log_softmax.gather", "goals[].unsqueeze", "agent.Agent.sample_adjacent_subgoal", "torch.log_softmax.gather", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.rand().unsqueeze", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "F.softmax.multinomial.squeeze().detach", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "F.softmax.multinomial.squeeze"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.goal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.goal_transition", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.sample_adjacent_subgoal"], ["", "", "", "", "def", "step", "(", "self", ",", "state", ",", "last_state", ",", "last_goal", ",", "flag", ",", "start_flag", "=", "True", ",", "evaluate", "=", "False", ")", ":", "\n", "        ", "if", "evaluate", ":", "\n", "            ", "goal", ",", "prob", ",", "log_prob", ",", "value_l", "=", "self", ".", "net", "(", "\n", "state", ",", "last_state", ",", "last_goal", ",", "flag", ",", "\n", "self", ".", "man_noise_sigma", ",", "evaluate", "=", "True", ")", "\n", "action", "=", "prob", ".", "multinomial", "(", "1", ")", "\n", "log_prob_act", "=", "log_prob", ".", "gather", "(", "1", ",", "action", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "start_flag", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "goal", "=", "torch", ".", "rand", "(", "self", ".", "goal_dim", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "scale", "=", "torch", ".", "FloatTensor", "(", "[", "self", ".", "x_range", ",", "self", ".", "y_range", "]", ")", ".", "expand_as", "(", "goal", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "goal", "=", "goal", "*", "scale", "\n", "", "else", ":", "\n", "                    ", "goal", "=", "self", ".", "goal_transition", "(", "state", ",", "last_state", ",", "last_goal", ")", "\n", "", "policy", ",", "value_l", "=", "self", ".", "net", ".", "policy_l", "(", "state", ",", "goal", ")", "\n", "prob", "=", "F", ".", "softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "action", "=", "prob", ".", "multinomial", "(", "1", ")", "\n", "log_prob_act", "=", "log_prob", ".", "gather", "(", "1", ",", "action", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "goals", "=", "self", ".", "net", ".", "actor_h", "(", "state", ",", "self", ".", "man_noise_sigma", ",", "evaluate", "=", "False", ")", "\n", "if", "self", ".", "n_noisy_goals", ">", "0", ":", "\n", "                        ", "noised_goals", "=", "goals", "[", ":", "self", ".", "n_noisy_goals", "]", "\n", "raw_goal", "=", "goals", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "goal", "=", "self", ".", "sample_adjacent_subgoal", "(", "noised_goals", ",", "state", ")", "\n", "if", "goal", "is", "None", ":", "\n", "                            ", "goal", "=", "raw_goal", "\n", "", "", "else", ":", "\n", "                        ", "goal", "=", "goals", "\n", "", "", "else", ":", "\n", "                    ", "goal", "=", "self", ".", "goal_transition", "(", "state", ",", "last_state", ",", "last_goal", ")", "\n", "", "policy", ",", "value_l", "=", "self", ".", "net", ".", "policy_l", "(", "state", ",", "goal", ")", "\n", "prob", "=", "F", ".", "softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "action", "=", "prob", ".", "multinomial", "(", "1", ")", "\n", "log_prob_act", "=", "log_prob", ".", "gather", "(", "1", ",", "action", ")", ".", "squeeze", "(", ")", "\n", "", "", "return", "action", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "goal", ",", "state", ",", "(", "prob", ",", "log_prob", ",", "log_prob_act", ",", "value_l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.sample_adjacent_subgoal": [[317, 334], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "agent.Agent.a_net", "outputs[].unsqueeze", "utils.euclidean_dist().squeeze", "sel_goal.unsqueeze.unsqueeze.unsqueeze", "idx.size", "utils.euclidean_dist", "len", "idx.size", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.euclidean_dist", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size"], ["", "def", "sample_adjacent_subgoal", "(", "self", ",", "goals", ",", "state", ")", ":", "\n", "# Randomly sample an adjacent subgoal from a goal list", "\n", "        ", "inputs", "=", "torch", ".", "cat", "(", "(", "state", "[", ":", ",", ":", "self", ".", "goal_dim", "]", ",", "goals", ")", ",", "dim", "=", "0", ")", "\n", "outputs", "=", "self", ".", "a_net", "(", "inputs", ")", "\n", "s_embedding", "=", "outputs", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", "\n", "goal_embeddings", "=", "outputs", "[", "1", ":", "]", "\n", "dists", "=", "utils", ".", "euclidean_dist", "(", "s_embedding", ",", "goal_embeddings", ")", ".", "squeeze", "(", ")", "\n", "idx", "=", "(", "dists", "<", "(", "self", ".", "r_margin_neg", "+", "self", ".", "r_margin_pos", ")", "/", "2", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "if", "idx", ".", "size", "(", ")", "and", "len", "(", "idx", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "elif", "not", "idx", ".", "size", "(", ")", ":", "# one index", "\n", "            ", "sel_goal", "=", "goals", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "idx", ")", ")", "\n", "sel_goal", "=", "goals", "[", "idx", "[", "sample_idx", "]", "]", "\n", "", "sel_goal", "=", "sel_goal", ".", "unsqueeze", "(", "0", ")", "\n", "return", "sel_goal", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.goal_transition": [[335, 337], ["None"], "methods", ["None"], ["", "def", "goal_transition", "(", "self", ",", "state", ",", "last_state", ",", "last_goal", ")", ":", "\n", "        ", "return", "last_goal", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_one_episode": [[338, 361], ["agent.Agent.replay_buffer_h.start", "agent.Agent.replay_buffer_h.start", "agent.Agent.train_low_level_a2c", "max", "range", "agent.Agent.memory_l.size", "agent.Agent.train_high_level", "agent.Agent.env.get_current_step"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.start", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.start", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_low_level_a2c", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_high_level", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step"], ["", "def", "train_one_episode", "(", "self", ")", ":", "\n", "# train low level", "\n", "        ", "if", "self", ".", "replay_buffer_h", ".", "start", "(", ")", "and", "self", ".", "memory_l", ".", "size", "(", ")", ">", "0", ":", "\n", "            ", "self", ".", "loss_policy_l", ",", "self", ".", "loss_value_l", ",", "self", ".", "loss_entropy_l", "=", "self", ".", "train_low_level_a2c", "(", ")", "\n", "self", ".", "loss_l", "=", "self", ".", "loss_policy_l", "+", "self", ".", "loss_value_l", "+", "self", ".", "ctrl_entropy", "*", "self", ".", "loss_entropy_l", "\n", "# train high level", "\n", "", "if", "self", ".", "replay_buffer_h", ".", "start", "(", ")", ":", "\n", "            ", "self", ".", "loss_policy_h", "=", "0.", "\n", "self", ".", "loss_value_h", "=", "0.", "\n", "self", ".", "loss_goal_h", "=", "0.", "\n", "high_train_steps", "=", "max", "(", "self", ".", "env", ".", "get_current_step", "(", ")", "//", "self", ".", "k", ",", "1", ")", "\n", "for", "_", "in", "range", "(", "high_train_steps", ")", ":", "\n", "                ", "loss_policy_h", ",", "loss_value_h", ",", "loss_goal_h", "=", "self", ".", "train_high_level", "(", ")", "\n", "self", ".", "loss_policy_h", "+=", "loss_policy_h", "\n", "self", ".", "loss_value_h", "+=", "loss_value_h", "\n", "self", ".", "loss_goal_h", "+=", "loss_goal_h", "\n", "", "self", ".", "loss_policy_h", "/=", "high_train_steps", "\n", "self", ".", "loss_value_h", "/=", "high_train_steps", "\n", "self", ".", "loss_goal_h", "/=", "high_train_steps", "\n", "self", ".", "loss_h", "=", "self", ".", "loss_policy_h", "+", "self", ".", "loss_value_h", "+", "self", ".", "goal_loss_coeff", "*", "self", ".", "loss_goal_h", "\n", "\n", "", "if", "self", ".", "loss_h", "is", "not", "None", "and", "self", ".", "loss_l", "is", "not", "None", ":", "\n", "            ", "self", ".", "loss", "=", "self", ".", "loss_h", "+", "self", ".", "loss_l", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_high_level": [[362, 397], ["agent.Agent.replay_buffer_h.sample", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "torch.from_numpy().bool", "agent.Agent.net.actor_h_tgt", "agent.Agent.net.critic_h_tgt", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "agent.Agent.net.critic_h", "agent.Agent.optimizer_critic_h.zero_grad", "loss_value_h.backward", "agent.Agent.optimizer_critic_h.step", "agent.Agent.net.actor_h", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "torch.clamp().mean", "agent.Agent.optimizer_actor_h.zero_grad", "loss_actor_h.backward", "agent.Agent.optimizer_actor_h.step", "agent.Agent.net.soft_sync_high", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "torch.tensor().to.item", "loss_value_h.item", "torch.clamp().mean.item", "torch.clamp().mean.item", "torch.clamp().mean.item", "torch.clamp().mean.item", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "ref_vals.detach", "ref_vals.detach", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "agent.Agent.net.critic_h.value().mean", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "agent.Agent.net.critic_h.value", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "agent.Agent.a_net", "agent.Agent.a_net"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.sample", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.soft_sync_high", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.CriticNet.value"], ["", "", "def", "train_high_level", "(", "self", ")", ":", "\n", "        ", "states", ",", "goals", ",", "rewards", ",", "next_states", ",", "dones", "=", "self", ".", "replay_buffer_h", ".", "sample", "(", ")", "\n", "states", "=", "torch", ".", "from_numpy", "(", "states", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "goals", "=", "torch", ".", "from_numpy", "(", "goals", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "rewards", "=", "torch", ".", "from_numpy", "(", "rewards", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "next_states", "=", "torch", ".", "from_numpy", "(", "next_states", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dones", "=", "torch", ".", "from_numpy", "(", "dones", ")", ".", "bool", "(", ")", "\n", "\n", "next_goals", "=", "self", ".", "net", ".", "actor_h_tgt", "(", "next_states", ",", "explore_sigma", "=", "0.", ")", "\n", "next_vals_1", ",", "next_vals_2", "=", "self", ".", "net", ".", "critic_h_tgt", "(", "next_states", ",", "next_goals", ")", "\n", "next_vals", "=", "torch", ".", "min", "(", "next_vals_1", ",", "next_vals_2", ")", "\n", "next_vals", "[", "dones", "]", "=", "0.", "\n", "ref_vals", "=", "rewards", "+", "next_vals", "*", "self", ".", "man_discount", "\n", "vals_1", ",", "vals_2", "=", "self", ".", "net", ".", "critic_h", "(", "states", ",", "goals", ")", "\n", "loss_value_h", "=", "F", ".", "mse_loss", "(", "vals_1", ",", "ref_vals", ".", "detach", "(", ")", ")", "+", "F", ".", "mse_loss", "(", "vals_2", ",", "ref_vals", ".", "detach", "(", ")", ")", "\n", "\n", "self", ".", "optimizer_critic_h", ".", "zero_grad", "(", ")", "\n", "loss_value_h", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_critic_h", ".", "step", "(", ")", "\n", "\n", "curr_goals", "=", "self", ".", "net", ".", "actor_h", "(", "states", ",", "explore_sigma", "=", "0.", ")", "\n", "loss_policy_h", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "self", ".", "policy_update_it", "%", "self", ".", "man_policy_update_freq", "==", "0", ":", "\n", "            ", "loss_policy_h", "=", "-", "self", ".", "net", ".", "critic_h", ".", "value", "(", "states", ",", "curr_goals", ")", ".", "mean", "(", ")", "\n", "", "loss_goal_h", "=", "torch", ".", "clamp", "(", "F", ".", "pairwise_distance", "(", "self", ".", "a_net", "(", "states", "[", ":", ",", ":", "self", ".", "goal_dim", "]", ")", ",", "self", ".", "a_net", "(", "curr_goals", ")", ")", "-", "(", "self", ".", "r_margin_neg", "+", "self", ".", "r_margin_pos", ")", "/", "2", ",", "min", "=", "0.", ")", ".", "mean", "(", ")", "\n", "loss_actor_h", "=", "loss_policy_h", "+", "self", ".", "goal_loss_coeff", "*", "loss_goal_h", "\n", "\n", "self", ".", "optimizer_actor_h", ".", "zero_grad", "(", ")", "\n", "loss_actor_h", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_actor_h", ".", "step", "(", ")", "\n", "\n", "self", ".", "net", ".", "soft_sync_high", "(", ")", "\n", "self", ".", "policy_update_it", "+=", "1", "\n", "return", "loss_policy_h", ".", "item", "(", ")", ",", "loss_value_h", ".", "item", "(", ")", ",", "loss_goal_h", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train_low_level_a2c": [[398, 426], ["agent.Agent.memory_l.get_experience", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "agent.Agent.compute_int_reward", "agent.Agent.compute_return", "range", "agent.Agent.memory_l.size", "agent.Agent.memory_l.size", "agent.Agent.memory_l.size", "agent.Agent.optimizer_l.zero_grad", "loss.backward", "agent.Agent.optimizer_l.step", "agent.Agent.memory_l.size", "adv.pow", "loss_policy_l.item", "loss_value_l.item", "loss_entropy_l.item", "adv.detach"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.get_experience", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_int_reward", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_return", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size"], ["", "def", "train_low_level_a2c", "(", "self", ")", ":", "\n", "        ", "states", ",", "goals", ",", "actions", ",", "info", "=", "self", ".", "memory_l", ".", "get_experience", "(", ")", "\n", "next_states", "=", "states", "[", "1", ":", "]", "\n", "states", "=", "states", "[", ":", "-", "1", "]", "\n", "states", "=", "torch", ".", "cat", "(", "states", ",", "dim", "=", "0", ")", "\n", "next_states", "=", "torch", ".", "cat", "(", "next_states", ",", "dim", "=", "0", ")", "\n", "goals", "=", "torch", ".", "cat", "(", "goals", ",", "dim", "=", "0", ")", "\n", "rewards", "=", "self", ".", "compute_int_reward", "(", "states", ",", "goals", ",", "next_states", ")", "\n", "returns", "=", "self", ".", "compute_return", "(", "rewards", ",", "self", ".", "ctrl_discount", ",", "horizon", "=", "self", ".", "k", ")", "\n", "\n", "loss_policy_l", "=", "0.", "\n", "loss_value_l", "=", "0.", "\n", "loss_entropy_l", "=", "0.", "\n", "for", "i", "in", "range", "(", "self", ".", "memory_l", ".", "size", "(", ")", ")", ":", "\n", "            ", "adv", "=", "returns", "[", "i", "]", "-", "info", "[", "'value_l'", "]", "[", "i", "]", "\n", "loss_policy_l", "-=", "adv", ".", "detach", "(", ")", "*", "info", "[", "'log_prob_act'", "]", "[", "i", "]", "\n", "loss_value_l", "+=", "adv", ".", "pow", "(", "2", ")", "\n", "entropy", "=", "-", "(", "info", "[", "'prob'", "]", "[", "i", "]", "*", "info", "[", "'log_prob'", "]", "[", "i", "]", ")", ".", "sum", "(", "-", "1", ")", "\n", "loss_entropy_l", "-=", "entropy", "\n", "", "loss_policy_l", "/=", "self", ".", "memory_l", ".", "size", "(", ")", "\n", "loss_value_l", "/=", "self", ".", "memory_l", ".", "size", "(", ")", "\n", "loss_entropy_l", "/=", "self", ".", "memory_l", ".", "size", "(", ")", "\n", "\n", "loss", "=", "loss_policy_l", "+", "loss_value_l", "+", "self", ".", "ctrl_entropy", "*", "loss_entropy_l", "\n", "self", ".", "optimizer_l", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_l", ".", "step", "(", ")", "\n", "return", "loss_policy_l", ".", "item", "(", ")", ",", "loss_value_l", ".", "item", "(", ")", ",", "loss_entropy_l", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_state_goal_similarity": [[427, 429], ["torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance", "torch.pairwise_distance"], "methods", ["None"], ["", "def", "compute_state_goal_similarity", "(", "self", ",", "states", ",", "next_states", ",", "goals", ")", ":", "\n", "        ", "return", "-", "F", ".", "pairwise_distance", "(", "next_states", "[", ":", ",", ":", "self", ".", "goal_dim", "]", ",", "goals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_goal_reaching_reward": [[430, 433], ["torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "compute_goal_reaching_reward", "(", "self", ",", "states", ",", "next_states", ",", "goals", ")", ":", "\n", "        ", "diff", "=", "(", "next_states", "[", ":", ",", ":", "self", ".", "goal_dim", "]", "-", "goals", ")", ".", "abs", "(", ")", "\n", "return", "(", "diff", "<=", "0.5", "*", "torch", ".", "ones", "(", "self", ".", "goal_dim", ")", ".", "to", "(", "self", ".", "device", ")", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_int_reward": [[434, 438], ["float", "agent.Agent.compute_goal_reaching_reward", "rewards.mean"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_goal_reaching_reward"], ["", "def", "compute_int_reward", "(", "self", ",", "states", ",", "goals", ",", "next_states", ")", ":", "\n", "        ", "rewards", "=", "self", ".", "ctrl_rew_scale", "*", "self", ".", "compute_goal_reaching_reward", "(", "states", ",", "next_states", ",", "goals", ")", "\n", "self", ".", "mean_int_reward", "=", "float", "(", "rewards", ".", "mean", "(", ")", ")", "\n", "return", "rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_return": [[439, 457], ["len", "numpy.zeros", "reversed", "range", "range", "range"], "methods", ["None"], ["", "def", "compute_return", "(", "self", ",", "rewards", ",", "gamma", "=", "0.99", ",", "horizon", "=", "None", ")", ":", "\n", "        ", "episode_length", "=", "len", "(", "rewards", ")", "\n", "returns", "=", "np", ".", "zeros", "(", "episode_length", ")", "\n", "if", "horizon", "is", "None", ":", "\n", "            ", "returns", "[", "episode_length", "-", "1", "]", "=", "rewards", "[", "episode_length", "-", "1", "]", "\n", "for", "i", "in", "reversed", "(", "range", "(", "episode_length", "-", "1", ")", ")", ":", "\n", "                ", "returns", "[", "i", "]", "=", "rewards", "[", "i", "]", "+", "returns", "[", "i", "+", "1", "]", "*", "gamma", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "horizon", ",", "episode_length", ",", "horizon", ")", ":", "\n", "                ", "returns", "[", "i", "-", "1", "]", "=", "rewards", "[", "i", "-", "1", "]", "\n", "for", "j", "in", "range", "(", "1", ",", "horizon", ")", ":", "\n", "                    ", "returns", "[", "i", "-", "1", "-", "j", "]", "=", "rewards", "[", "i", "-", "1", "-", "j", "]", "+", "returns", "[", "i", "-", "j", "]", "*", "gamma", "\n", "", "", "returns", "[", "episode_length", "-", "1", "]", "=", "rewards", "[", "episode_length", "-", "1", "]", "\n", "j", "=", "1", "\n", "while", "(", "episode_length", "-", "j", ")", "%", "horizon", "!=", "0", ":", "\n", "                ", "returns", "[", "episode_length", "-", "1", "-", "j", "]", "=", "rewards", "[", "episode_length", "-", "1", "-", "j", "]", "+", "returns", "[", "episode_length", "-", "j", "]", "*", "gamma", "\n", "j", "+=", "1", "\n", "", "", "return", "returns", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test_one_episode": [[458, 491], ["agent.Agent.eval_env.new_episode", "agent.Agent.replay_buffer_h.start", "last_obs_list.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "agent.Agent.eval_env.get_state", "utils.single_input_transform", "agent.Agent.step", "agent.Agent.eval_env.make_action", "agent.Agent.eval_env.is_episode_finished", "agent.Agent.compute_state_goal_similarity().mean().item", "agent.Agent.eval_env.get_total_reward", "agent.Agent.eval_env.get_current_step", "agent.Agent.eval_env.get_current_step", "goal_list.append", "obs_list.append", "last_obs_list.append", "agent.Agent.compute_state_goal_similarity().mean", "agent.Agent.compute_state_goal_similarity"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.new_episode", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.start", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.get_state", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.single_input_transform", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.make_action", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.is_episode_finished", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_total_reward", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.compute_state_goal_similarity"], ["", "def", "test_one_episode", "(", "self", ")", ":", "\n", "        ", "self", ".", "eval_env", ".", "new_episode", "(", ")", "\n", "last_state", "=", "None", "\n", "last_goal", "=", "None", "\n", "goal_list", "=", "[", "]", "\n", "last_obs_list", "=", "[", "]", "\n", "obs_list", "=", "[", "]", "\n", "done", "=", "False", "\n", "start_flag", "=", "self", ".", "replay_buffer_h", ".", "start", "(", ")", "\n", "while", "True", ":", "\n", "            ", "flag", "=", "(", "self", ".", "eval_env", ".", "get_current_step", "(", ")", "%", "self", ".", "k", "==", "0", ")", "\n", "obs", "=", "self", ".", "eval_env", ".", "get_state", "(", ")", "\n", "obs_var", "=", "utils", ".", "single_input_transform", "(", "obs", ",", "device", "=", "self", ".", "device", ")", "\n", "if", "flag", ":", "\n", "                ", "if", "self", ".", "eval_env", ".", "get_current_step", "(", ")", "!=", "0", ":", "\n", "                    ", "goal_list", ".", "append", "(", "last_goal", ")", "\n", "obs_list", ".", "append", "(", "obs_var", ")", "\n", "", "else", ":", "\n", "                    ", "last_obs_list", ".", "append", "(", "obs_var", ")", "\n", "\n", "", "", "action", ",", "last_goal", ",", "last_state", ",", "_", "=", "self", ".", "step", "(", "\n", "obs_var", ",", "last_state", ",", "last_goal", ",", "flag", ",", "start_flag", "=", "start_flag", ",", "evaluate", "=", "True", ")", "\n", "\n", "self", ".", "eval_env", ".", "make_action", "(", "action", ")", "\n", "if", "self", ".", "eval_env", ".", "is_episode_finished", "(", ")", ":", "\n", "                ", "reward", "=", "self", ".", "eval_env", ".", "get_total_reward", "(", ")", "\n", "break", "\n", "", "", "last_obs_list", ".", "extend", "(", "obs_list", "[", ":", "-", "1", "]", ")", "\n", "goals", "=", "torch", ".", "cat", "(", "goal_list", ",", "dim", "=", "0", ")", "\n", "last_obs", "=", "torch", ".", "cat", "(", "last_obs_list", ",", "dim", "=", "0", ")", "\n", "obs", "=", "torch", ".", "cat", "(", "obs_list", ",", "dim", "=", "0", ")", "\n", "dist", "=", "-", "self", ".", "compute_state_goal_similarity", "(", "last_obs", ",", "obs", ",", "goals", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "return", "reward", ",", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.update_adj_mat": [[492, 509], ["agent.Agent.traj_memory.get_trajectory", "range", "len", "range", "min", "tuple", "tuple", "numpy.round().astype", "numpy.round().astype", "agent.Agent.state_list.append", "agent.Agent.state_list.append", "len", "numpy.round", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.get_trajectory", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "update_adj_mat", "(", "self", ")", ":", "\n", "        ", "for", "traj", "in", "self", ".", "traj_memory", ".", "get_trajectory", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "traj", ")", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "1", ",", "min", "(", "self", ".", "k", ",", "len", "(", "traj", ")", "-", "i", ")", ")", ":", "\n", "                    ", "s1", "=", "tuple", "(", "np", ".", "round", "(", "traj", "[", "i", "]", "[", ":", "self", ".", "goal_dim", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "s2", "=", "tuple", "(", "np", ".", "round", "(", "traj", "[", "i", "+", "j", "]", "[", ":", "self", ".", "goal_dim", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "if", "s1", "not", "in", "self", ".", "state_list", ":", "\n", "                        ", "self", ".", "state_list", ".", "append", "(", "s1", ")", "\n", "self", ".", "state_dict", "[", "s1", "]", "=", "self", ".", "n_states", "\n", "self", ".", "n_states", "+=", "1", "\n", "", "if", "s2", "not", "in", "self", ".", "state_list", ":", "\n", "                        ", "self", ".", "state_list", ".", "append", "(", "s2", ")", "\n", "self", ".", "state_dict", "[", "s2", "]", "=", "self", ".", "n_states", "\n", "self", ".", "n_states", "+=", "1", "\n", "# assume that the environment is symmetric", "\n", "", "self", ".", "adj_mat", "[", "self", ".", "state_dict", "[", "s1", "]", ",", "self", ".", "state_dict", "[", "s2", "]", "]", "=", "1", "\n", "self", ".", "adj_mat", "[", "self", ".", "state_dict", "[", "s2", "]", ",", "self", ".", "state_dict", "[", "s1", "]", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.test_adjacency_acc": [[510, 528], ["torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "torch.tensor().float().to", "agent.Agent.a_net.eval", "agent.Agent.a_net", "utils.euclidean_dist().detach().cpu().numpy", "range", "print", "agent.Agent.a_net.train", "agent.Agent.eval_env.calc_r_dist", "range", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "utils.euclidean_dist().detach().cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.euclidean_dist().detach", "tuple", "utils.euclidean_dist"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.train", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.calc_r_dist", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.euclidean_dist"], ["", "", "", "", "def", "test_adjacency_acc", "(", "self", ")", ":", "\n", "        ", "states", "=", "torch", ".", "tensor", "(", "self", ".", "eval_env", ".", "states_all", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "a_net", ".", "eval", "(", ")", "\n", "embeddings", "=", "self", ".", "a_net", "(", "states", ")", "\n", "dists", "=", "utils", ".", "euclidean_dist", "(", "embeddings", ",", "embeddings", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "n_correct", "=", "0", "\n", "n_total", "=", "0", "\n", "r_dists", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "eval_env", ".", "n_states", ")", ":", "\n", "            ", "r_dist", "=", "self", ".", "eval_env", ".", "calc_r_dist", "(", "self", ".", "eval_env", ".", "states_all", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ",", "self", ".", "eval_env", ".", "n_states", ")", ":", "\n", "                ", "y", "=", "r_dist", "[", "tuple", "(", "self", ".", "eval_env", ".", "states_all", "[", "j", "]", ")", "]", "<=", "self", ".", "k", "\n", "pred", "=", "dists", "[", "i", ",", "j", "]", "<=", "(", "self", ".", "r_margin_neg", "+", "self", ".", "r_margin_pos", ")", "/", "2", "\n", "if", "pred", "==", "y", ":", "\n", "                    ", "n_correct", "+=", "1", "\n", "", "n_total", "+=", "1", "\n", "", "", "print", "(", "'Adjacency acc = {:.4f}'", ".", "format", "(", "n_correct", "/", "n_total", ")", ")", "\n", "self", ".", "a_net", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.agent.Agent.log_train": [[529, 560], ["print", "utils.print_localtime", "time.time", "print", "print", "print", "print", "print", "agent.Agent.summary_writer.add_scalar", "agent.Agent.summary_writer.add_scalar", "agent.Agent.summary_writer.add_scalar", "print", "print", "agent.Agent.summary_writer.add_scalar", "agent.Agent.summary_writer.add_scalar", "agent.Agent.summary_writer.add_scalar", "print", "agent.Agent.summary_writer.add_scalar", "print", "print", "agent.Agent.env.get_current_step", "agent.Agent.env.get_current_step", "agent.Agent.replay_buffer_h.size"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.print_localtime", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size"], ["", "def", "log_train", "(", "self", ")", ":", "\n", "        ", "print", "(", "\"[@@ {} @@] ************** Training at episode {} **************\"", ".", "format", "(", "self", ".", "algo", ",", "self", ".", "_episodes", ")", ")", "\n", "utils", ".", "print_localtime", "(", ")", "\n", "self", ".", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'  Frames {}, Episode #{} (( costs {:.2f} s ))'", ".", "format", "(", "self", ".", "_frames", ",", "self", ".", "_episodes", ",", "self", ".", "end_time", "-", "self", ".", "start_time", ")", ")", "\n", "if", "self", ".", "mean_int_reward", "is", "None", ":", "\n", "            ", "print", "(", "'  Gets (( {:.3f} reward )) in (( {} steps ))'", ".", "format", "(", "self", ".", "curr_reward", ",", "self", ".", "env", ".", "get_current_step", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'  Gets (( {:.3f} reward, {:.5f} mean int reward )) in (( {} steps ))'", ".", "format", "(", "\n", "self", ".", "curr_reward", ",", "self", ".", "mean_int_reward", ",", "self", ".", "env", ".", "get_current_step", "(", ")", ")", ")", "\n", "", "self", ".", "start_time", "=", "self", ".", "end_time", "\n", "if", "self", ".", "loss_h", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"    High-level (( Policy loss = {:5f}  ||  Value loss = {:5f} ))\"", ".", "format", "(", "self", ".", "loss_policy_h", ",", "self", ".", "loss_value_h", ")", ")", "\n", "print", "(", "\"               (( Goal loss = {:.5f} ))\"", ".", "format", "(", "self", ".", "loss_goal_h", ")", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'high-level/policy loss'", ",", "self", ".", "loss_policy_h", ",", "self", ".", "_frames", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'high-level/value loss'", ",", "self", ".", "loss_value_h", ",", "self", ".", "_frames", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'high-level/goal loss'", ",", "self", ".", "loss_goal_h", ",", "self", ".", "_frames", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"    High-level (( Has not started training yet. Current replay size = {} ))\"", ".", "format", "(", "self", ".", "replay_buffer_h", ".", "size", "(", ")", ")", ")", "\n", "", "if", "self", ".", "loss_l", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"    Low-level  (( Policy loss = {:5f}  ||  Value loss = {:5f} ))\"", ".", "format", "(", "self", ".", "loss_policy_l", ",", "self", ".", "loss_value_l", ")", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'low-level/policy loss'", ",", "self", ".", "loss_policy_l", ",", "self", ".", "_frames", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'low-level/value loss'", ",", "self", ".", "loss_value_l", ",", "self", ".", "_frames", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'low-level/mean int reward'", ",", "self", ".", "mean_int_reward", ",", "self", ".", "_frames", ")", "\n", "print", "(", "\"               (( Entropy = {:5f} ))\"", ".", "format", "(", "-", "self", ".", "loss_entropy_l", ")", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'low-level/entropy'", ",", "-", "self", ".", "loss_entropy_l", ",", "self", ".", "_frames", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"    Low-level  (( Has not started training yet. ))\"", ")", "\n", "\n", "", "if", "self", ".", "loss_h", "is", "not", "None", "and", "self", ".", "loss_l", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"    Total loss = {:5f}\"", ".", "format", "(", "self", ".", "loss", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.__init__": [[10, 23], ["torch.Module.__init__", "model.HighLevelActorNet", "model.CriticNet", "copy.deepcopy", "copy.deepcopy", "model.LowLevelPolicyNet"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "hidden_dim", ",", "x_range", ",", "y_range", ",", "horizon", ",", "\n", "n_noisy_goals", ",", "soft_sync_rate", ",", "low_action_scale", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "goal_dim", "=", "goal_dim", "\n", "self", ".", "soft_sync_rate", "=", "soft_sync_rate", "\n", "self", ".", "low_action_scale", "=", "low_action_scale", "\n", "\n", "self", ".", "actor_h", "=", "HighLevelActorNet", "(", "state_dim", ",", "goal_dim", ",", "hidden_dim", ",", "x_range", ",", "y_range", ",", "horizon", ",", "n_noisy_goals", ")", "\n", "self", ".", "critic_h", "=", "CriticNet", "(", "state_dim", ",", "goal_dim", ",", "hidden_dim", ")", "\n", "self", ".", "actor_h_tgt", "=", "copy", ".", "deepcopy", "(", "self", ".", "actor_h", ")", "\n", "self", ".", "critic_h_tgt", "=", "copy", ".", "deepcopy", "(", "self", ".", "critic_h", ")", "\n", "\n", "self", ".", "policy_l", "=", "LowLevelPolicyNet", "(", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "hidden_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.soft_sync_high": [[24, 27], ["model.HRLNet._soft_sync", "model.HRLNet._soft_sync"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet._soft_sync", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet._soft_sync"], ["", "def", "soft_sync_high", "(", "self", ")", ":", "\n", "        ", "self", ".", "_soft_sync", "(", "self", ".", "actor_h", ",", "self", ".", "actor_h_tgt", ")", "\n", "self", ".", "_soft_sync", "(", "self", ".", "critic_h", ",", "self", ".", "critic_h_tgt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet._soft_sync": [[28, 31], ["zip", "net.parameters", "tgt_net.parameters", "tgt_param.data.copy_"], "methods", ["None"], ["", "def", "_soft_sync", "(", "self", ",", "net", ",", "tgt_net", ")", ":", "\n", "        ", "for", "param", ",", "tgt_param", "in", "zip", "(", "net", ".", "parameters", "(", ")", ",", "tgt_net", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "tgt_param", ".", "data", ".", "copy_", "(", "self", ".", "soft_sync_rate", "*", "param", ".", "data", "+", "(", "1", "-", "self", ".", "soft_sync_rate", ")", "*", "tgt_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.goal_transition": [[32, 34], ["None"], "methods", ["None"], ["", "", "def", "goal_transition", "(", "self", ",", "state", ",", "last_state", ",", "last_goal", ")", ":", "\n", "        ", "return", "last_goal", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.forward": [[35, 45], ["model.HRLNet.policy_l", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "model.HRLNet.actor_h", "model.HRLNet.goal_transition"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HRLNet.goal_transition"], ["", "def", "forward", "(", "self", ",", "state", ",", "last_state", ",", "last_goal", ",", "flag", ",", "explore_sigma_high", ",", "evaluate", "=", "False", ")", ":", "\n", "        ", "if", "flag", ":", "\n", "            ", "goal", "=", "self", ".", "actor_h", "(", "state", ",", "explore_sigma_high", ",", "evaluate", "=", "evaluate", ")", "\n", "", "else", ":", "\n", "            ", "goal", "=", "self", ".", "goal_transition", "(", "state", ",", "last_state", ",", "last_goal", ")", "\n", "\n", "", "policy", ",", "value", "=", "self", ".", "policy_l", "(", "state", ",", "goal", ")", "\n", "prob", "=", "F", ".", "softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "policy", ",", "dim", "=", "-", "1", ")", "\n", "return", "goal", ",", "prob", ",", "log_prob", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.ANet.__init__": [[49, 55], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "goal_dim", ",", "hidden_dim", ",", "embedding_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "goal_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "fc4", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.ANet.forward": [[56, 62], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.ANet.fc4", "model.ANet.fc1", "model.ANet.fc2", "model.ANet.fc3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc3", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc4", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HighLevelActorNet.__init__": [[66, 78], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "hidden_dim", ",", "x_range", ",", "y_range", ",", "horizon", ",", "n_noisy_goals", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "x_range", "=", "x_range", "\n", "self", ".", "y_range", "=", "y_range", "\n", "self", ".", "horizon", "=", "horizon", "\n", "self", ".", "n_noisy_goals", "=", "n_noisy_goals", "\n", "\n", "self", ".", "goal_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "state_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "goal_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.HighLevelActorNet.forward": [[79, 95], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "torch.FloatTensor().expand_as().to", "model.HighLevelActorNet.goal_fc", "goal.expand.expand.expand", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "goal.expand.expand.size", "goal.expand.expand.size", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.FloatTensor().expand_as", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "goal.expand.expand.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size"], ["", "def", "forward", "(", "self", ",", "state", ",", "explore_sigma", ",", "evaluate", "=", "False", ")", ":", "\n", "        ", "goal", "=", "torch", ".", "sigmoid", "(", "self", ".", "goal_fc", "(", "state", ")", ")", "\n", "noise_flag", "=", "self", ".", "n_noisy_goals", ">", "0", "and", "goal", ".", "size", "(", "0", ")", "==", "1", "and", "not", "evaluate", "\n", "if", "noise_flag", ":", "\n", "            ", "raw_goal", "=", "goal", "\n", "goal", "=", "goal", ".", "expand", "(", "self", ".", "n_noisy_goals", ",", "goal", ".", "size", "(", "1", ")", ")", "\n", "", "noise", "=", "explore_sigma", "*", "torch", ".", "randn", "(", "goal", ".", "size", "(", ")", ")", ".", "to", "(", "goal", ".", "device", ")", "\n", "scale", "=", "torch", ".", "FloatTensor", "(", "[", "self", ".", "x_range", ",", "self", ".", "y_range", "]", ")", ".", "expand_as", "(", "goal", ")", ".", "to", "(", "goal", ".", "device", ")", "\n", "goal", "=", "goal", "*", "scale", "\n", "if", "evaluate", ":", "\n", "            ", "output", "=", "goal", "\n", "", "else", ":", "\n", "            ", "output", "=", "torch", ".", "min", "(", "torch", ".", "clamp", "(", "goal", "+", "noise", ",", "min", "=", "0", ")", ",", "scale", ")", "\n", "if", "noise_flag", ":", "\n", "                ", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "raw_goal", ")", ",", "dim", "=", "0", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.CriticNet.__init__": [[99, 112], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "action_dim", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "value_fc_1", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "state_dim", "+", "action_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", ")", "\n", "\n", "self", ".", "value_fc_2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "state_dim", "+", "action_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.CriticNet.forward": [[113, 116], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.CriticNet.value_fc_1().squeeze", "model.CriticNet.value_fc_2().squeeze", "model.CriticNet.value_fc_1", "model.CriticNet.value_fc_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "state", ",", "action", ")", ",", "dim", "=", "-", "1", ")", "\n", "return", "self", ".", "value_fc_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", ",", "self", ".", "value_fc_2", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.CriticNet.value": [[117, 119], ["model.CriticNet.value_fc_1().squeeze", "model.CriticNet.value_fc_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "state", ",", "action", ")", ":", "\n", "        ", "return", "self", ".", "value_fc_1", "(", "torch", ".", "cat", "(", "(", "state", ",", "action", ")", ",", "dim", "=", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.LowLevelPolicyNet.__init__": [[123, 136], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", ",", "goal_dim", ",", "action_dim", ",", "hidden_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "state_dim", "+", "goal_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "action_dim", ")", ")", "\n", "\n", "self", ".", "value_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "state_dim", "+", "goal_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.model.LowLevelPolicyNet.forward": [[137, 143], ["goal.detach.detach.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.LowLevelPolicyNet.action_fc", "model.LowLevelPolicyNet.value_fc().squeeze", "model.LowLevelPolicyNet.value_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "state", ",", "goal", ")", ":", "\n", "        ", "goal", "=", "goal", ".", "detach", "(", ")", "# no gradient", "\n", "x", "=", "torch", ".", "cat", "(", "(", "state", ",", "goal", ")", ",", "dim", "=", "-", "1", ")", "\n", "policy", "=", "self", ".", "action_fc", "(", "x", ")", "\n", "value", "=", "self", ".", "value_fc", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "policy", ",", "value", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.ContrastiveLoss.__init__": [[41, 46], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin_pos", ",", "margin_neg", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "margin_pos", "<=", "margin_neg", "\n", "self", ".", "margin_pos", "=", "margin_pos", "\n", "self", ".", "margin_neg", "=", "margin_neg", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.ContrastiveLoss.forward": [[47, 53], ["label.float.float.float", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "label", ")", ":", "\n", "        ", "label", "=", "label", ".", "float", "(", ")", "\n", "dist", "=", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "x", "-", "y", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "1e-12", ")", "\n", "loss", "=", "(", "label", "*", "(", "dist", "-", "self", ".", "margin_pos", ")", ".", "clamp", "(", "min", "=", "0", ")", ")", ".", "mean", "(", ")", "+", "(", "(", "1", "-", "label", ")", "*", "(", "self", ".", "margin_neg", "-", "dist", ")", ".", "clamp", "(", "min", "=", "0", ")", ")", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.MetricDataset.__init__": [[57, 71], ["torch.Dataset.__init__", "range", "numpy.array", "numpy.array", "numpy.array", "range", "metric.MetricDataset.x.append", "metric.MetricDataset.y.append", "metric.MetricDataset.label.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["    ", "def", "__init__", "(", "self", ",", "states", ",", "adj_mat", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "n_samples", "=", "adj_mat", ".", "shape", "[", "0", "]", "\n", "self", ".", "x", "=", "[", "]", "\n", "self", ".", "y", "=", "[", "]", "\n", "self", ".", "label", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_samples", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "n_samples", ")", ":", "\n", "                ", "self", ".", "x", ".", "append", "(", "states", "[", "i", "]", ")", "\n", "self", ".", "y", ".", "append", "(", "states", "[", "j", "]", ")", "\n", "self", ".", "label", ".", "append", "(", "adj_mat", "[", "i", ",", "j", "]", ")", "\n", "", "", "self", ".", "x", "=", "np", ".", "array", "(", "self", ".", "x", ")", "\n", "self", ".", "y", "=", "np", ".", "array", "(", "self", ".", "y", ")", "\n", "self", ".", "label", "=", "np", ".", "array", "(", "self", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.MetricDataset.__len__": [[72, 74], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "x", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.MetricDataset.__getitem__": [[75, 77], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "x", "[", "idx", "]", ",", "self", ".", "y", "[", "idx", "]", ",", "self", ".", "label", "[", "idx", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.metric.train_anet": [[8, 37], ["metric.MetricDataset", "torch.DataLoader", "len", "metric.ContrastiveLoss", "range", "print", "print", "enumerate", "a_net.float().to", "a_net.float().to", "label.long().to.long().to", "a_net", "a_net", "ContrastiveLoss.", "optimizer.zero_grad", "loss_func.backward", "optimizer.step", "epoch_loss.append", "print", "len", "print", "loss_func.item", "a_net.float", "a_net.float", "label.long().to.long", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["def", "train_anet", "(", "a_net", ",", "states", ",", "adj_mat", ",", "optimizer", ",", "margin_pos", ",", "margin_neg", ",", "\n", "n_epochs", "=", "100", ",", "batch_size", "=", "64", ",", "device", "=", "'cpu'", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "if", "verbose", ":", "\n", "        ", "print", "(", "'Generating training data...'", ")", "\n", "", "dataset", "=", "MetricDataset", "(", "states", ",", "adj_mat", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Totally {} training pairs.'", ".", "format", "(", "len", "(", "dataset", ")", ")", ")", "\n", "", "dataloader", "=", "Data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "drop_last", "=", "False", ")", "\n", "n_batches", "=", "len", "(", "dataloader", ")", "\n", "loss_func", "=", "ContrastiveLoss", "(", "margin_pos", ",", "margin_neg", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "epoch_loss", "=", "[", "]", "\n", "for", "j", ",", "data", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "            ", "x", ",", "y", ",", "label", "=", "data", "\n", "x", "=", "x", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "y", "=", "y", ".", "float", "(", ")", ".", "to", "(", "device", ")", "\n", "label", "=", "label", ".", "long", "(", ")", ".", "to", "(", "device", ")", "\n", "x", "=", "a_net", "(", "x", ")", "\n", "y", "=", "a_net", "(", "y", ")", "\n", "loss", "=", "loss_func", "(", "x", ",", "y", ",", "label", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "verbose", "and", "(", "j", "%", "100", "==", "0", "or", "j", "==", "n_batches", "-", "1", ")", ":", "\n", "                ", "print", "(", "'Training adjacency network: epoch {}/{}, batch {}/{}'", ".", "format", "(", "i", "+", "1", ",", "n_epochs", ",", "j", "+", "1", ",", "n_batches", ")", ")", "\n", "", "epoch_loss", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Mean loss: {:.4f}'", ".", "format", "(", "np", ".", "mean", "(", "epoch_loss", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.euclidean_dist": [[7, 29], ["x.unsqueeze().expand.size", "y.unsqueeze().expand.size", "x.unsqueeze().expand.size", "x.unsqueeze().expand.unsqueeze().expand", "y.unsqueeze().expand.unsqueeze().expand", "torch.pow().sum", "y.unsqueeze().expand.size", "Exception", "torch.sqrt", "x.unsqueeze().expand.unsqueeze", "y.unsqueeze().expand.unsqueeze", "torch.pow"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size"], ["\n", "\n", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "\n", "# Simple replay buffer", "\n", "class", "ReplayBuffer", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "maxsize", "=", "1e6", ")", ":", "\n", "        ", "self", ".", "storage", "=", "[", "[", "]", "for", "_", "in", "range", "(", "8", ")", "]", "\n", "self", ".", "maxsize", "=", "maxsize", "\n", "self", ".", "next_idx", "=", "0", "\n", "\n", "", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "storage", "=", "[", "[", "]", "for", "_", "in", "range", "(", "8", ")", "]", "\n", "self", ".", "next_idx", "=", "0", "\n", "\n", "# Expects tuples of (x, x', g, u, r, d, x_seq, a_seq)", "\n", "", "def", "add", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "next_idx", "=", "int", "(", "self", ".", "next_idx", ")", "\n", "if", "self", ".", "next_idx", ">=", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ":", "\n", "            ", "[", "array", ".", "append", "(", "datapoint", ")", "for", "array", ",", "datapoint", "in", "zip", "(", "self", ".", "storage", ",", "data", ")", "]", "\n", "", "else", ":", "\n", "            ", "[", "array", ".", "__setitem__", "(", "self", ".", "next_idx", ",", "datapoint", ")", "for", "array", ",", "datapoint", "in", "zip", "(", "self", ".", "storage", ",", "data", ")", "]", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.to_tensor": [[31, 35], ["torch.from_numpy().float", "x.to.to", "torch.from_numpy"], "function", ["None"], ["", "self", ".", "next_idx", "=", "(", "self", ".", "next_idx", "+", "1", ")", "%", "self", ".", "maxsize", "\n", "\n", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "storage", "[", "0", "]", ")", "<=", "batch_size", ":", "\n", "            ", "ind", "=", "np", ".", "arange", "(", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.make_path": [[37, 41], ["os.path.exists", "os.makedirs"], "function", ["None"], ["            ", "ind", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "storage", "[", "0", "]", ")", ",", "size", "=", "batch_size", ")", "\n", "\n", "", "x", ",", "y", ",", "g", ",", "u", ",", "r", ",", "d", ",", "x_seq", ",", "a_seq", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "ind", ":", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.single_input_transform": [[43, 47], ["utils.to_tensor", "obs_var.unsqueeze.unsqueeze"], "function", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.to_tensor"], ["x", ".", "append", "(", "np", ".", "array", "(", "X", ",", "copy", "=", "False", ")", ")", "\n", "y", ".", "append", "(", "np", ".", "array", "(", "Y", ",", "copy", "=", "False", ")", ")", "\n", "g", ".", "append", "(", "np", ".", "array", "(", "G", ",", "copy", "=", "False", ")", ")", "\n", "u", ".", "append", "(", "np", ".", "array", "(", "U", ",", "copy", "=", "False", ")", ")", "\n", "r", ".", "append", "(", "np", ".", "array", "(", "R", ",", "copy", "=", "False", ")", ")", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.utils.print_localtime": [[49, 53], ["time.localtime", "print"], "function", ["None"], ["\n", "# For off-policy goal correction", "\n", "x_seq", ".", "append", "(", "np", ".", "array", "(", "obs_seq", ",", "copy", "=", "False", ")", ")", "\n", "a_seq", ".", "append", "(", "np", ".", "array", "(", "acts", ",", "copy", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.__init__": [[8, 20], ["numpy.random.RandomState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "random_start", "=", "False", ",", "seed", "=", "0", ")", ":", "\n", "        ", "self", ".", "random_start", "=", "random_start", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "seed", ")", "\n", "\n", "self", ".", "h", "=", "None", "\n", "self", ".", "w", "=", "None", "\n", "self", ".", "world", "=", "None", "\n", "self", ".", "states_all", "=", "None", "\n", "self", ".", "n_states", "=", "None", "\n", "self", ".", "start_pos", "=", "None", "\n", "self", ".", "start_states", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.reset": [[21, 32], ["env.BaseEnv.rng.randint"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "random_start", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "start_states", "[", "self", ".", "rng", ".", "randint", "(", "self", ".", "n_states", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "start_pos", "\n", "", "self", ".", "r_total", "=", "0.", "\n", "self", ".", "done", "=", "False", "\n", "self", ".", "info", "=", "None", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "last_action", "=", "None", "\n", "return", "self", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.step": [[33, 35], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.new_episode": [[36, 38], ["env.BaseEnv.reset"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["", "def", "new_episode", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_state": [[39, 41], ["None"], "methods", ["None"], ["", "def", "get_state", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.make_action": [[42, 45], ["env.BaseEnv.step"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step"], ["", "def", "make_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "_", ",", "r", ",", "_", ",", "_", "=", "self", ".", "step", "(", "action", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.is_episode_finished": [[46, 48], ["None"], "methods", ["None"], ["", "def", "is_episode_finished", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_total_reward": [[49, 51], ["None"], "methods", ["None"], ["", "def", "get_total_reward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "r_total", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_current_step": [[52, 54], ["None"], "methods", ["None"], ["", "def", "get_current_step", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_step", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.render": [[55, 57], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.calc_r_dist": [[58, 76], ["numpy.zeros", "collections.deque", "env.BaseEnv._adj_pos", "numpy.ones().astype", "collections.deque.popleft", "numpy.min", "env.BaseEnv._adj_pos", "collections.deque.append", "numpy.ones", "env.BaseEnv._adj_pos", "collections.deque.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv._adj_pos", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv._adj_pos", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv._adj_pos", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "calc_r_dist", "(", "self", ",", "target", ")", ":", "\n", "        ", "r_dist", "=", "np", ".", "Inf", "*", "np", ".", "ones", "(", "(", "self", ".", "h", ",", "self", ".", "w", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "flags", "=", "np", ".", "zeros", "(", "(", "self", ".", "h", ",", "self", ".", "w", ")", ",", "dtype", "=", "bool", ")", "\n", "r_dist", "[", "target", "[", "0", "]", ",", "target", "[", "1", "]", "]", "=", "0", "\n", "buf", "=", "deque", "(", ")", "\n", "for", "p", "in", "self", ".", "_adj_pos", "(", "target", ")", ":", "\n", "            ", "if", "r_dist", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "==", "np", ".", "Inf", ":", "\n", "                ", "buf", ".", "append", "(", "p", ")", "\n", "flags", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "=", "True", "\n", "", "", "while", "buf", ":", "\n", "            ", "pos", "=", "buf", ".", "popleft", "(", ")", "\n", "dists", "=", "[", "r_dist", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "+", "1", "for", "p", "in", "self", ".", "_adj_pos", "(", "pos", ")", "]", "\n", "r_dist", "[", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", "]", "=", "np", ".", "min", "(", "dists", ")", "\n", "for", "p", "in", "self", ".", "_adj_pos", "(", "pos", ")", ":", "\n", "                ", "if", "not", "flags", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "and", "r_dist", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "==", "np", ".", "Inf", ":", "\n", "                    ", "buf", ".", "append", "(", "p", ")", "\n", "flags", "[", "p", "[", "0", "]", ",", "p", "[", "1", "]", "]", "=", "True", "\n", "", "", "", "return", "r_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.get_adj_mat": [[77, 85], ["numpy.zeros", "enumerate", "env.BaseEnv.calc_r_dist", "enumerate"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.calc_r_dist"], ["", "def", "get_adj_mat", "(", "self", ",", "k", ")", ":", "\n", "        ", "adj_mat", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_states", ",", "self", ".", "n_states", ")", ")", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "self", ".", "states_all", ")", ":", "\n", "            ", "r_dist", "=", "self", ".", "calc_r_dist", "(", "s", ")", "\n", "for", "j", ",", "t", "in", "enumerate", "(", "self", ".", "states_all", ")", ":", "\n", "                ", "if", "r_dist", "[", "t", "[", "0", "]", ",", "t", "[", "1", "]", "]", "<=", "k", ":", "\n", "                    ", "adj_mat", "[", "i", ",", "j", "]", "=", "1", "\n", "", "", "", "return", "adj_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv._adj_pos": [[86, 93], ["range", "pos_list.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "_adj_pos", "(", "self", ",", "pos", ")", ":", "\n", "        ", "pos_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "next_pos", "=", "pos", "+", "self", ".", "acts", "[", "i", "]", "\n", "if", "self", ".", "world", "[", "next_pos", "[", "0", "]", ",", "next_pos", "[", "1", "]", "]", "!=", "1", ":", "\n", "                ", "pos_list", ".", "append", "(", "next_pos", ")", "\n", "", "", "return", "pos_list", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.MazeEnv.__init__": [[97, 158], ["env.BaseEnv.__init__", "numpy.array", "enumerate", "gym.spaces.Discrete", "gym.spaces.Box", "range", "layout.splitlines", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "env.MazeEnv.calc_r_dist", "list", "env.MazeEnv.states_walls_all.append", "map", "layout.splitlines", "numpy.array", "max", "numpy.array", "env.MazeEnv.states_all.append", "numpy.array", "numpy.array", "env.MazeEnv.start_states.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.BaseEnv.calc_r_dist", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["    ", "def", "__init__", "(", "self", ",", "step_limit", "=", "200", ",", "reward_shaping", "=", "True", ",", "reward_shaping_scale", "=", "0.1", ",", "\n", "random_start", "=", "False", ",", "pure_exploration", "=", "False", ",", "random_action_prob", "=", "0.25", ",", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "random_start", "=", "random_start", ",", "seed", "=", "seed", ")", "\n", "layout", "=", "\"\"\"\\\nwwwwwwwwwwwwwwwww\nw               w\nw               w\nw  wwwwwwwwwww  w\nw  wG        w  w\nw  w         w  w\nw  wwwwwwww  w  w\nw            w  w\nw            w  w\nwwwwwwwwwwwwww  w\nw               w\nwS              w\nwwwwwwwwwwwwwwwww\n\"\"\"", "\n", "self", ".", "step_limit", "=", "step_limit", "\n", "self", ".", "reward_shaping", "=", "reward_shaping", "\n", "self", ".", "reward_shaping_scale", "=", "reward_shaping_scale", "\n", "self", ".", "pure_exploration", "=", "pure_exploration", "\n", "self", ".", "random_action_prob", "=", "random_action_prob", "\n", "\n", "self", ".", "obs_dim", "=", "2", "\n", "self", ".", "action_dim", "=", "4", "\n", "\n", "self", ".", "world", "=", "np", ".", "array", "(", "[", "list", "(", "map", "(", "lambda", "c", ":", "1", "if", "c", "==", "'w'", "else", "0", ",", "line", ")", ")", "for", "line", "in", "layout", ".", "splitlines", "(", ")", "]", ")", "\n", "self", ".", "h", ",", "self", ".", "w", "=", "self", ".", "world", ".", "shape", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "layout", ".", "splitlines", "(", ")", ")", ":", "\n", "            ", "for", "j", ",", "c", "in", "enumerate", "(", "line", ")", ":", "\n", "                ", "if", "c", "==", "'S'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "2", "\n", "self", ".", "start_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "", "elif", "c", "==", "'G'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "3", "\n", "self", ".", "goal_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "\n", "", "", "", "self", ".", "acts", "=", "[", "np", ".", "array", "(", "(", "-", "1", ",", "0", ")", ")", ",", "np", ".", "array", "(", "(", "1", ",", "0", ")", ")", ",", "np", ".", "array", "(", "(", "0", ",", "-", "1", ")", ")", ",", "np", ".", "array", "(", "(", "0", ",", "1", ")", ")", "]", "\n", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "4", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "max", "(", "self", ".", "h", ",", "self", ".", "w", ")", "-", "1", ",", "shape", "=", "(", "self", ".", "obs_dim", ",", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "self", ".", "n_states", "=", "0", "\n", "self", ".", "start_states", "=", "[", "]", "\n", "self", ".", "states_all", "=", "[", "]", "\n", "self", ".", "states_walls_all", "=", "[", "]", "\n", "self", ".", "state_inds_dict", "=", "{", "}", "\n", "self", ".", "state_wall_inds_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "h", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "w", ")", ":", "\n", "                ", "self", ".", "states_walls_all", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "self", ".", "state_wall_inds_dict", "[", "(", "i", ",", "j", ")", "]", "=", "self", ".", "n_states", "\n", "if", "self", ".", "world", "[", "i", ",", "j", "]", "!=", "1", ":", "\n", "                    ", "self", ".", "states_all", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "self", ".", "state_inds_dict", "[", "(", "i", ",", "j", ")", "]", "=", "self", ".", "n_states", "\n", "if", "self", ".", "world", "[", "i", ",", "j", "]", "in", "[", "0", ",", "2", "]", ":", "\n", "                        ", "self", ".", "start_states", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "", "self", ".", "n_states", "+=", "1", "\n", "\n", "", "", "", "if", "self", ".", "reward_shaping", ":", "\n", "            ", "self", ".", "r_dist", "=", "self", ".", "calc_r_dist", "(", "self", ".", "goal_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.MazeEnv.step": [[159, 181], ["env.MazeEnv.rng.rand", "env.MazeEnv.rng.randint", "env.MazeEnv._relative_dist"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.MazeEnv._relative_dist"], ["", "", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "not", "self", ".", "done", ":", "\n", "            ", "r", "=", "0.", "\n", "state", "=", "self", ".", "state", "\n", "if", "self", ".", "rng", ".", "rand", "(", ")", "<", "self", ".", "random_action_prob", ":", "\n", "                ", "action", "=", "self", ".", "rng", ".", "randint", "(", "self", ".", "action_dim", ")", "\n", "", "self", ".", "last_action", "=", "action", "\n", "next_state", "=", "self", ".", "state", "+", "self", ".", "acts", "[", "action", "]", "\n", "if", "self", ".", "world", "[", "next_state", "[", "0", "]", ",", "next_state", "[", "1", "]", "]", "!=", "1", ":", "# not wall", "\n", "                ", "self", ".", "state", "=", "next_state", "\n", "if", "self", ".", "world", "[", "next_state", "[", "0", "]", ",", "next_state", "[", "1", "]", "]", "==", "3", ":", "# goal reached", "\n", "                    ", "r", "=", "0.1", "\n", "if", "not", "self", ".", "pure_exploration", ":", "\n", "                        ", "self", ".", "done", "=", "True", "\n", "", "", "elif", "self", ".", "reward_shaping", ":", "\n", "                    ", "r", "=", "self", ".", "reward_shaping_scale", "*", "self", ".", "_relative_dist", "(", "state", ",", "next_state", ")", "\n", "", "self", ".", "r_total", "+=", "r", "\n", "\n", "", "self", ".", "_step", "+=", "1", "\n", "if", "self", ".", "_step", ">=", "self", ".", "step_limit", ":", "\n", "                ", "self", ".", "done", "=", "True", "\n", "", "return", "self", ".", "state", ",", "r", ",", "self", ".", "done", ",", "self", ".", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.MazeEnv._relative_dist": [[182, 190], ["None"], "methods", ["None"], ["", "", "def", "_relative_dist", "(", "self", ",", "last_pos", ",", "pos", ")", ":", "\n", "        ", "last_dist", "=", "self", ".", "r_dist", "[", "last_pos", "[", "0", "]", ",", "last_pos", "[", "1", "]", "]", "\n", "dist", "=", "self", ".", "r_dist", "[", "pos", "[", "0", "]", ",", "pos", "[", "1", "]", "]", "\n", "if", "last_dist", ">", "dist", ":", "\n", "            ", "return", "1", "\n", "", "if", "last_dist", "<", "dist", ":", "\n", "            ", "return", "-", "1", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.__init__": [[194, 256], ["env.BaseEnv.__init__", "numpy.array", "enumerate", "gym.spaces.Discrete", "gym.spaces.Box", "range", "layout.splitlines", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "list", "env.KeyChestEnv.states_walls_all.append", "map", "layout.splitlines", "numpy.array", "max", "numpy.array", "env.KeyChestEnv.states_all.append", "env.KeyChestEnv.start_states.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["    ", "def", "__init__", "(", "self", ",", "step_limit", "=", "500", ",", "random_start", "=", "False", ",", "pure_exploration", "=", "False", ",", "\n", "random_action_prob", "=", "0.25", ",", "seed", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "random_start", "=", "random_start", ",", "seed", "=", "seed", ")", "\n", "layout", "=", "\"\"\"\\\nwwwwwwwwwwwwwwwww\nw               w\nwB              w\nwwwwwwwwwwwwww  w\nw               w\nw               w\nwK wwwwwwwwwww  w\nw               w\nw               w\nwwwwwwwwwwwwww  w\nw               w\nw      S        w\nwwwwwwwwwwwwwwwww\n\"\"\"", "\n", "self", ".", "step_limit", "=", "step_limit", "\n", "self", ".", "pure_exploration", "=", "pure_exploration", "\n", "self", ".", "random_action_prob", "=", "random_action_prob", "\n", "\n", "self", ".", "obs_dim", "=", "3", "\n", "self", ".", "action_dim", "=", "4", "\n", "\n", "self", ".", "world", "=", "np", ".", "array", "(", "[", "list", "(", "map", "(", "lambda", "c", ":", "1", "if", "c", "==", "'w'", "else", "0", ",", "line", ")", ")", "for", "line", "in", "layout", ".", "splitlines", "(", ")", "]", ")", "\n", "self", ".", "h", ",", "self", ".", "w", "=", "self", ".", "world", ".", "shape", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "layout", ".", "splitlines", "(", ")", ")", ":", "\n", "            ", "for", "j", ",", "c", "in", "enumerate", "(", "line", ")", ":", "\n", "                ", "if", "c", "==", "'S'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "2", "\n", "self", ".", "start_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "", "elif", "c", "==", "'G'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "3", "\n", "self", ".", "goal_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "", "elif", "c", "==", "'K'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "4", "\n", "self", ".", "key_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "", "elif", "c", "==", "'B'", ":", "\n", "                    ", "self", ".", "world", "[", "i", ",", "j", "]", "=", "5", "\n", "self", ".", "box_pos", "=", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", "\n", "\n", "", "", "", "self", ".", "acts", "=", "[", "np", ".", "array", "(", "(", "-", "1", ",", "0", ")", ")", ",", "np", ".", "array", "(", "(", "1", ",", "0", ")", ")", ",", "np", ".", "array", "(", "(", "0", ",", "-", "1", ")", ")", ",", "np", ".", "array", "(", "(", "0", ",", "1", ")", ")", "]", "\n", "self", ".", "action_space", "=", "spaces", ".", "Discrete", "(", "4", ")", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "max", "(", "self", ".", "h", ",", "self", ".", "w", ")", "-", "1", ",", "shape", "=", "(", "self", ".", "obs_dim", ",", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "self", ".", "n_states", "=", "0", "\n", "self", ".", "start_states", "=", "[", "]", "\n", "self", ".", "states_all", "=", "[", "]", "\n", "self", ".", "states_walls_all", "=", "[", "]", "\n", "self", ".", "state_inds_dict", "=", "{", "}", "\n", "self", ".", "state_wall_inds_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "h", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "w", ")", ":", "\n", "                ", "self", ".", "states_walls_all", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "self", ".", "state_wall_inds_dict", "[", "(", "i", ",", "j", ")", "]", "=", "self", ".", "n_states", "\n", "if", "self", ".", "world", "[", "i", ",", "j", "]", "!=", "1", ":", "\n", "                    ", "self", ".", "states_all", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "self", ".", "state_inds_dict", "[", "(", "i", ",", "j", ")", "]", "=", "self", ".", "n_states", "\n", "self", ".", "start_states", ".", "append", "(", "np", ".", "array", "(", "(", "i", ",", "j", ")", ")", ")", "\n", "self", ".", "n_states", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.reset": [[257, 269], ["numpy.append", "env.KeyChestEnv.rng.randint"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "", "", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "random_start", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "start_states", "[", "self", ".", "rng", ".", "randint", "(", "self", ".", "n_states", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "start_pos", "\n", "", "self", ".", "r_total", "=", "0.", "\n", "self", ".", "done", "=", "False", "\n", "self", ".", "info", "=", "None", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "last_action", "=", "None", "\n", "self", ".", "has_key", "=", "0", "\n", "return", "np", ".", "append", "(", "self", ".", "state", ",", "self", ".", "has_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.step": [[270, 294], ["env.KeyChestEnv.rng.rand", "env.KeyChestEnv.rng.randint", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "not", "self", ".", "done", ":", "\n", "            ", "r", "=", "0.", "\n", "state", "=", "self", ".", "state", "\n", "if", "self", ".", "rng", ".", "rand", "(", ")", "<", "self", ".", "random_action_prob", ":", "\n", "                ", "action", "=", "self", ".", "rng", ".", "randint", "(", "self", ".", "action_dim", ")", "\n", "", "self", ".", "last_action", "=", "action", "\n", "next_state", "=", "self", ".", "state", "+", "self", ".", "acts", "[", "action", "]", "\n", "if", "self", ".", "world", "[", "next_state", "[", "0", "]", ",", "next_state", "[", "1", "]", "]", "!=", "1", ":", "# not wall", "\n", "                ", "self", ".", "state", "=", "next_state", "\n", "if", "self", ".", "world", "[", "next_state", "[", "0", "]", ",", "next_state", "[", "1", "]", "]", "==", "4", ":", "# pick up the key", "\n", "                    ", "if", "self", ".", "has_key", "==", "0", ":", "\n", "                        ", "r", "=", "1.", "\n", "self", ".", "has_key", "=", "1", "\n", "", "", "if", "self", ".", "world", "[", "next_state", "[", "0", "]", ",", "next_state", "[", "1", "]", "]", "==", "5", "and", "self", ".", "has_key", "==", "1", ":", "# reach the box with the key", "\n", "                    ", "r", "=", "5.", "\n", "if", "not", "self", ".", "pure_exploration", ":", "\n", "                        ", "self", ".", "done", "=", "True", "\n", "", "", "self", ".", "r_total", "+=", "r", "\n", "\n", "", "self", ".", "_step", "+=", "1", "\n", "if", "self", ".", "_step", ">=", "self", ".", "step_limit", ":", "\n", "                ", "self", ".", "done", "=", "True", "\n", "", "return", "np", ".", "append", "(", "self", ".", "state", ",", "self", ".", "has_key", ")", ",", "r", ",", "self", ".", "done", ",", "self", ".", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.env.KeyChestEnv.get_state": [[295, 297], ["numpy.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "", "def", "get_state", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "append", "(", "self", ".", "state", ",", "self", ".", "has_key", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.__init__": [[6, 12], ["memory.HighLevelReplayBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ",", "batch_size", ",", "obs_dim", ",", "action_dim", ")", ":", "\n", "        ", "self", ".", "_capacity", "=", "capacity", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_obs_dim", "=", "obs_dim", "\n", "self", ".", "_action_dim", "=", "action_dim", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.reset": [[13, 22], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "np", ".", "zeros", "(", "(", "self", ".", "_capacity", ",", "self", ".", "_obs_dim", ")", ")", "\n", "self", ".", "next_state", "=", "np", ".", "zeros", "(", "(", "self", ".", "_capacity", ",", "self", ".", "_obs_dim", ")", ")", "\n", "self", ".", "action", "=", "np", ".", "zeros", "(", "(", "self", ".", "_capacity", ",", "self", ".", "_action_dim", ")", ")", "\n", "self", ".", "reward", "=", "np", ".", "zeros", "(", "self", ".", "_capacity", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "done", "=", "np", ".", "zeros", "(", "self", ".", "_capacity", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "self", ".", "_ptr", "=", "0", "\n", "self", ".", "_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.append": [[23, 32], ["min"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "state", ",", "action", ",", "reward", ",", "next_state", ",", "done", ")", ":", "\n", "        ", "self", ".", "state", "[", "self", ".", "_ptr", "]", "=", "state", "\n", "self", ".", "next_state", "[", "self", ".", "_ptr", "]", "=", "next_state", "\n", "self", ".", "action", "[", "self", ".", "_ptr", "]", "=", "action", "\n", "self", ".", "reward", "[", "self", ".", "_ptr", "]", "=", "reward", "\n", "self", ".", "done", "[", "self", ".", "_ptr", "]", "=", "done", "\n", "\n", "self", ".", "_ptr", "=", "(", "self", ".", "_ptr", "+", "1", ")", "%", "self", ".", "_capacity", "\n", "self", ".", "_size", "=", "min", "(", "self", ".", "_size", "+", "1", ",", "self", ".", "_capacity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.sample": [[33, 36], ["numpy.random.choice"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "ind", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "_size", ",", "self", ".", "_batch_size", ",", "replace", "=", "False", ")", "\n", "return", "self", ".", "state", "[", "ind", "]", ",", "self", ".", "action", "[", "ind", "]", ",", "self", ".", "reward", "[", "ind", "]", ",", "self", ".", "next_state", "[", "ind", "]", ",", "self", ".", "done", "[", "ind", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.size": [[37, 39], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.start": [[40, 42], ["None"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", ">=", "0.5", "*", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.HighLevelReplayBuffer.full": [[43, 45], ["None"], "methods", ["None"], ["", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", ">=", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.__init__": [[49, 51], ["memory.LowLevelMemory.reset"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.reset": [[52, 59], ["dict"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "states", "=", "[", "]", "\n", "self", ".", "goals", "=", "[", "]", "\n", "self", ".", "actions", "=", "[", "]", "\n", "self", ".", "info", "=", "dict", "(", "prob", "=", "[", "]", ",", "log_prob", "=", "[", "]", ",", "log_prob_act", "=", "[", "]", ",", "value_l", "=", "[", "]", ")", "\n", "\n", "self", ".", "_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.append": [[60, 70], ["memory.LowLevelMemory.states.append", "memory.LowLevelMemory.goals.append", "memory.LowLevelMemory.actions.append", "memory.LowLevelMemory.info[].append", "memory.LowLevelMemory.info[].append", "memory.LowLevelMemory.info[].append", "memory.LowLevelMemory.info[].append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append", "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "append", "(", "self", ",", "state", ",", "goal", ",", "action", ",", "info", ")", ":", "\n", "        ", "self", ".", "states", ".", "append", "(", "state", ")", "\n", "self", ".", "goals", ".", "append", "(", "goal", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "info", "[", "'prob'", "]", ".", "append", "(", "info", "[", "'prob'", "]", ")", "\n", "self", ".", "info", "[", "'log_prob'", "]", ".", "append", "(", "info", "[", "'log_prob'", "]", ")", "\n", "self", ".", "info", "[", "'log_prob_act'", "]", ".", "append", "(", "info", "[", "'log_prob_act'", "]", ")", "\n", "self", ".", "info", "[", "'value_l'", "]", ".", "append", "(", "info", "[", "'value_l'", "]", ")", "\n", "\n", "self", ".", "_size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.get_experience": [[71, 73], ["None"], "methods", ["None"], ["", "def", "get_experience", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "states", ",", "self", ".", "goals", ",", "self", ".", "actions", ",", "self", ".", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.LowLevelMemory.size": [[74, 76], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__init__": [[80, 83], ["memory.TrajectoryMemory.reset"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "self", ".", "_capacity", "=", "capacity", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.reset": [[84, 88], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_num_traj", "=", "0", "# number of trajectories", "\n", "self", ".", "_size", "=", "0", "# number of game frames", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.__len__": [[89, 91], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_traj", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.size": [[92, 94], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.get_traj_num": [[95, 97], ["None"], "methods", ["None"], ["", "def", "get_traj_num", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_num_traj", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.full": [[98, 100], ["None"], "methods", ["None"], ["", "def", "full", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_size", ">=", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.create_new_trajectory": [[101, 104], ["memory.TrajectoryMemory.trajectory.append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "create_new_trajectory", "(", "self", ")", ":", "\n", "        ", "self", ".", "trajectory", ".", "append", "(", "[", "]", ")", "\n", "self", ".", "_num_traj", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append": [[105, 108], ["memory.TrajectoryMemory.trajectory[].append"], "methods", ["home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.append"], ["", "def", "append", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "trajectory", "[", "self", ".", "_num_traj", "-", "1", "]", ".", "append", "(", "s", ")", "\n", "self", ".", "_size", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.get_trajectory": [[109, 111], ["None"], "methods", ["None"], ["", "def", "get_trajectory", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "trajectory", "\n", "\n"]], "home.repos.pwc.inspect_result.trzhang0116_HRAC.discrete.memory.TrajectoryMemory.set_capacity": [[112, 115], ["None"], "methods", ["None"], ["", "def", "set_capacity", "(", "self", ",", "new_capacity", ")", ":", "\n", "        ", "assert", "self", ".", "_size", "<=", "new_capacity", "\n", "self", ".", "_capacity", "=", "new_capacity", "\n", "", "", ""]]}