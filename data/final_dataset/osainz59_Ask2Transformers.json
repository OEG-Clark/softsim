{"home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.generate_silver_train.main": [[20, 50], ["numpy.load", "a2t.relation_classification.utils.apply_threshold", "numpy.load", "zip", "print", "open", "json.load", "os.path.join", "os.path.join", "open", "labels_.append", "preds_.append", "inst.copy", "new_train_instances.append", "a2t.relation_classification.utils.f1_score_", "a2t.relation_classification.utils.f1_score_", "open", "json.dump", "enumerate", "line.strip", "os.path.join"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.f1_score_", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.f1_score_"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "data", ")", "as", "f", ":", "\n", "        ", "train_data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "preds", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "preds", ",", "\"output.npy\"", ")", ")", "\n", "preds", "=", "apply_threshold", "(", "preds", ",", "threshold", "=", "args", ".", "threshold", ")", "\n", "labels", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "preds", ",", "\"labels.npy\"", ")", ")", "\n", "\n", "label2id", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "TACRED_LABELS", ")", "}", "\n", "\n", "with", "open", "(", "args", ".", "split", ")", "as", "f", ":", "\n", "        ", "labeled_split", "=", "[", "line", ".", "strip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "", "new_train_instances", "=", "[", "]", "\n", "labels_", ",", "preds_", "=", "[", "]", ",", "[", "]", "\n", "for", "pred", ",", "inst", "in", "zip", "(", "preds", ",", "train_data", ")", ":", "\n", "        ", "if", "inst", "[", "\"id\"", "]", "in", "labeled_split", ":", "\n", "            ", "continue", "\n", "# FOR TESTING", "\n", "", "labels_", ".", "append", "(", "label2id", "[", "inst", "[", "\"relation\"", "]", "]", ")", "\n", "preds_", ".", "append", "(", "pred", ")", "\n", "#", "\n", "new_inst", "=", "inst", ".", "copy", "(", ")", "\n", "new_inst", "[", "\"relation\"", "]", "=", "TACRED_LABELS", "[", "pred", "]", "\n", "new_train_instances", ".", "append", "(", "new_inst", ")", "\n", "\n", "", "print", "(", "args", ".", "preds", ",", "f1_score_", "(", "labels", ",", "preds", ")", ",", "f1_score_", "(", "labels_", ",", "preds_", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "preds", ",", "\"train.silver.json\"", ")", ",", "\"wt\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "new_train_instances", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.sample.normalize_idx": [[29, 34], ["idx.startswith", "idx.startswith", "idx.startswith", "idx.startswith"], "function", ["None"], ["", "def", "normalize_idx", "(", "idx", ")", ":", "\n", "    ", "if", "idx", ".", "startswith", "(", "\"n\"", ")", "or", "idx", ".", "startswith", "(", "\"a\"", ")", "or", "idx", ".", "startswith", "(", "\"v\"", ")", "or", "idx", ".", "startswith", "(", "\"r\"", ")", ":", "\n", "        ", "idx", "=", "idx", "[", "1", ":", "]", "+", "\"-\"", "+", "idx", "[", "0", "]", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_positive_example": [[38, 62], ["wikievents2mnli.MNLIInputFeatures", "random.sample", "template.format", "min", "len", "instance.trigger_type.split"], "function", ["None"], ["def", "generate_positive_example", "(", "\n", "instance", ":", "SlotFeatures", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "type2role", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "n", ":", "int", "=", "1", ",", "\n", "label2id", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Generates an entailment example from a positive argument instance by sampling a random template\n    from the correct argument role. Satisfies type constraints.\n    \"\"\"", "\n", "if", "instance", ".", "role", "in", "[", "\"no_relation\"", ",", "\"OOR\"", "]", ":", "\n", "        ", "return", "[", "]", "\n", "", "templates_", "=", "templates", "[", "instance", ".", "role", "]", "\n", "return", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "template", ".", "format", "(", "\n", "trg", "=", "instance", ".", "trigger", ",", "\n", "obj", "=", "instance", ".", "arg", ",", "\n", "trg_subtype", "=", "instance", ".", "trigger_type", ".", "split", "(", "\".\"", ")", "[", "1", "]", ",", "\n", ")", ",", "\n", "label", "=", "label2id", "[", "\"entailment\"", "]", ",", "\n", ")", "\n", "for", "template", "in", "random", ".", "sample", "(", "templates_", ",", "k", "=", "min", "(", "n", ",", "len", "(", "templates_", ")", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_neutral_example": [[65, 95], ["list", "len", "templates_.extend", "wikievents2mnli.MNLIInputFeatures", "set", "set", "random.sample", "template.format", "min", "len", "instance.trigger_type.split"], "function", ["None"], ["", "def", "generate_neutral_example", "(", "\n", "instance", ":", "SlotFeatures", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "type2role", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "n", ":", "int", "=", "1", ",", "\n", "label2id", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Generates a neutral example from a positive argument instance by sampling a random template\n    from a random incorrect argument role. Satisfies type constraints.\n    \"\"\"", "\n", "if", "instance", ".", "role", "in", "[", "\"no_relation\"", ",", "\"OOR\"", "]", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "posible_fake_roles", "=", "list", "(", "set", "(", "type2role", "[", "instance", ".", "pair_type", "]", ")", "-", "set", "(", "[", "instance", ".", "role", "]", ")", ")", "\n", "if", "not", "len", "(", "posible_fake_roles", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "templates_", "=", "[", "]", "\n", "for", "role", "in", "posible_fake_roles", ":", "\n", "        ", "templates_", ".", "extend", "(", "templates", "[", "role", "]", ")", "\n", "", "return", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "template", ".", "format", "(", "\n", "trg", "=", "instance", ".", "trigger", ",", "\n", "obj", "=", "instance", ".", "arg", ",", "\n", "trg_subtype", "=", "instance", ".", "trigger_type", ".", "split", "(", "\".\"", ")", "[", "1", "]", ",", "\n", ")", ",", "\n", "label", "=", "label2id", "[", "\"neutral\"", "]", ",", "\n", ")", "\n", "for", "template", "in", "random", ".", "sample", "(", "templates_", ",", "k", "=", "min", "(", "n", ",", "len", "(", "templates_", ")", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_negative_example": [[98, 128], ["len", "templates_.extend", "wikievents2mnli.MNLIInputFeatures", "random.sample", "template.format", "min", "len", "instance.trigger_type.split"], "function", ["None"], ["", "def", "generate_negative_example", "(", "\n", "instance", ":", "SlotFeatures", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "type2role", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "n", ":", "int", "=", "1", ",", "\n", "label2id", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Generates a contradiction example from a negative argument instance by sampling a random template\n    from a positive argument role. Satisfies type constraints.\n    \"\"\"", "\n", "if", "instance", ".", "role", "not", "in", "[", "\"no_relation\"", "]", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "posible_fake_roles", "=", "type2role", "[", "instance", ".", "pair_type", "]", "\n", "if", "not", "len", "(", "posible_fake_roles", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "templates_", "=", "[", "]", "\n", "for", "role", "in", "posible_fake_roles", ":", "\n", "        ", "templates_", ".", "extend", "(", "templates", "[", "role", "]", ")", "\n", "", "return", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "template", ".", "format", "(", "\n", "trg", "=", "instance", ".", "trigger", ",", "\n", "obj", "=", "instance", ".", "arg", ",", "\n", "trg_subtype", "=", "instance", ".", "trigger_type", ".", "split", "(", "\".\"", ")", "[", "1", "]", ",", "\n", ")", ",", "\n", "label", "=", "label2id", "[", "\"contradiction\"", "]", ",", "\n", ")", "\n", "for", "template", "in", "random", ".", "sample", "(", "templates_", ",", "k", "=", "min", "(", "n", ",", "len", "(", "templates_", ")", ")", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.to_nli": [[131, 146], ["wikievents2mnli.generate_positive_example", "wikievents2mnli.generate_neutral_example", "wikievents2mnli.generate_negative_example"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_positive_example", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_neutral_example", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.generate_negative_example"], ["", "def", "to_nli", "(", "\n", "instance", ":", "SlotFeatures", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "type2role", ":", "Dict", "[", "str", ",", "list", "]", ",", "\n", "negn", ":", "int", "=", "1", ",", "\n", "posn", ":", "int", "=", "1", ",", "\n", "label2id", "=", "None", ",", "\n", ")", ":", "\n", "    ", "nli_examples", "=", "[", "\n", "*", "generate_positive_example", "(", "instance", ",", "templates", ",", "type2role", ",", "n", "=", "posn", ",", "label2id", "=", "label2id", ")", ",", "\n", "*", "generate_neutral_example", "(", "instance", ",", "templates", ",", "type2role", ",", "n", "=", "negn", ",", "label2id", "=", "label2id", ")", ",", "\n", "*", "generate_negative_example", "(", "instance", ",", "templates", ",", "type2role", ",", "n", "=", "negn", ",", "label2id", "=", "label2id", ")", ",", "\n", "]", "\n", "\n", "return", "nli_examples", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.main": [[148, 196], ["a2t.slot_classification.wikievents.WikiEventsArgumentDataset", "collections.defaultdict", "config[].items", "transformers.AutoConfig.from_pretrained", "open", "nli_examples.extend", "open", "key.lower", "json.load", "config.get", "type2role[].append", "wikievents2mnli.to_nli", "f.write", "AutoConfig.from_pretrained.label2id.items", "json.dumps"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.wikievents2mnli.to_nli"], ["", "def", "main", "(", "opt", ")", ":", "\n", "\n", "    ", "if", "opt", ".", "model_name_or_path", ":", "\n", "        ", "model_config", "=", "AutoConfig", ".", "from_pretrained", "(", "opt", ".", "model_name_or_path", ")", "\n", "label2id", "=", "{", "key", ".", "lower", "(", ")", ":", "value", "for", "key", ",", "value", "in", "model_config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "if", "\"not_entailment\"", "in", "label2id", ":", "\n", "            ", "label2id", "=", "{", "\n", "\"entailment\"", ":", "label2id", "[", "\"entailment\"", "]", ",", "\n", "\"neutral\"", ":", "label2id", "[", "\"not_entailment\"", "]", ",", "\n", "\"contradiction\"", ":", "label2id", "[", "\"not_entailment\"", "]", ",", "\n", "}", "\n", "", "", "else", ":", "\n", "        ", "label2id", "=", "{", "\"entailment\"", ":", "2", ",", "\"neutral\"", ":", "1", ",", "\"contradiction\"", ":", "0", "}", "\n", "\n", "", "with", "open", "(", "opt", ".", "config_file", ")", "as", "f", ":", "\n", "        ", "config", "=", "json", ".", "load", "(", "f", ")", "[", "0", "]", "\n", "\n", "", "dataset", "=", "WikiEventsArgumentDataset", "(", "\n", "opt", ".", "input_file", ",", "\n", "create_negatives", "=", "True", ",", "\n", "max_sentence_distance", "=", "config", ".", "get", "(", "\"max_sentence_distance\"", ",", "None", ")", ",", "\n", "mark_trigger", "=", "True", ",", "\n", ")", "\n", "\n", "type2role", "=", "defaultdict", "(", "list", ")", "\n", "for", "role", ",", "type_pair_list", "in", "config", "[", "\"valid_conditions\"", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "role", "not", "in", "config", "[", "\"labels\"", "]", ":", "\n", "            ", "continue", "\n", "", "for", "type_pair", "in", "type_pair_list", ":", "\n", "            ", "type2role", "[", "type_pair", "]", ".", "append", "(", "role", ")", "\n", "\n", "", "", "nli_examples", "=", "[", "]", "\n", "for", "instance", "in", "dataset", ":", "\n", "        ", "nli_examples", ".", "extend", "(", "\n", "to_nli", "(", "\n", "instance", ",", "\n", "config", "[", "\"template_mapping\"", "]", ",", "\n", "type2role", ",", "\n", "opt", ".", "negn", ",", "\n", "opt", ".", "posn", ",", "\n", "label2id", "=", "label2id", ",", "\n", ")", "\n", ")", "\n", "\n", "", "with", "open", "(", "opt", ".", "output_file", ",", "\"wt\"", ")", "as", "f", ":", "\n", "        ", "for", "example", "in", "nli_examples", ":", "\n", "            ", "f", ".", "write", "(", "f\"{json.dumps(example.__dict__)}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.threshold_estimation.main": [[26, 75], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "find_optimal_threshold", "collections.defaultdict", "result_dict[].append", "find_optimal_threshold", "precision_recall_fscore_", "result_dict[].append", "print", "sorted", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "apply_threshold", "sklearn.model_selection.StratifiedKFold", "sklearn.model_selection.StratifiedKFold.split", "numpy.mean", "numpy.mean", "print", "os.makedirs", "abs", "abs", "find_optimal_threshold", "precision_recall_fscore_", "result_dict[].append", "isinstance", "open", "json.dump", "apply_threshold", "collections.defaultdict.keys", "os.path.join", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.precision_recall_fscore_", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.precision_recall_fscore_", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold"], ["def", "main", "(", "args", ")", ":", "\n", "# Read dev and test outputs", "\n", "    ", "dev_labels", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dev", ",", "\"labels.npy\"", ")", ")", "\n", "dev_output", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "dev", ",", "\"output.npy\"", ")", ")", "\n", "\n", "test_labels", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "test", ",", "\"labels.npy\"", ")", ")", "\n", "test_output", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "test", ",", "\"output.npy\"", ")", ")", "\n", "\n", "# Compute the best threshold", "\n", "best_threshold", ",", "best_f1", "=", "find_optimal_threshold", "(", "test_labels", ",", "test_output", ")", "\n", "\n", "# Define the result dict", "\n", "result_dict", "=", "defaultdict", "(", "list", ")", "\n", "result_dict", "[", "\"best\"", "]", ".", "append", "(", "[", "best_threshold", ",", "best_f1", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "threshold", ",", "_", "=", "find_optimal_threshold", "(", "dev_labels", ",", "dev_output", ")", "\n", "p", ",", "r", ",", "f1", "=", "precision_recall_fscore_", "(", "test_labels", ",", "apply_threshold", "(", "test_output", ",", "threshold", "=", "threshold", ")", ")", "\n", "result_dict", "[", "1", "]", ".", "append", "(", "[", "threshold", ",", "f1", ",", "abs", "(", "best_threshold", "-", "threshold", ")", ",", "abs", "(", "best_f1", "-", "f1", ")", ",", "p", ",", "r", "]", ")", "\n", "\n", "# Estimate the threshold for each split", "\n", "for", "n_splits", "in", "args", ".", "splits", ":", "\n", "        ", "kfold", "=", "StratifiedKFold", "(", "n_splits", "=", "n_splits", ")", "\n", "for", "_", ",", "idx", "in", "kfold", ".", "split", "(", "dev_output", ",", "dev_labels", ")", ":", "\n", "            ", "splitted_output", ",", "splitted_labels", "=", "dev_output", "[", "idx", "]", ",", "dev_labels", "[", "idx", "]", "\n", "threshold", ",", "_", "=", "find_optimal_threshold", "(", "splitted_labels", ",", "splitted_output", ")", "\n", "p", ",", "r", ",", "f1", "=", "precision_recall_fscore_", "(", "test_labels", ",", "apply_threshold", "(", "test_output", ",", "threshold", "=", "threshold", ")", ")", "\n", "result_dict", "[", "n_splits", "]", ".", "append", "(", "\n", "[", "\n", "threshold", ",", "\n", "f1", ",", "\n", "abs", "(", "best_threshold", "-", "threshold", ")", ",", "\n", "abs", "(", "best_f1", "-", "f1", ")", ",", "\n", "p", ",", "\n", "r", ",", "\n", "]", "\n", ")", "\n", "\n", "", "", "print", "(", "f\"Dev %\\tMAbsE\\tMean F1\"", ")", "\n", "for", "key", "in", "sorted", "(", "[", "key", "for", "key", "in", "result_dict", ".", "keys", "(", ")", "if", "key", "!=", "\"best\"", "]", ")", ":", "\n", "        ", "mean_error", "=", "np", ".", "mean", "(", "[", "x", "[", "2", "]", "for", "x", "in", "result_dict", "[", "key", "]", "]", ")", "\n", "mean_f1", "=", "np", ".", "mean", "(", "[", "x", "[", "1", "]", "for", "x", "in", "result_dict", "[", "key", "]", "]", ")", "\n", "name", "=", "f\"{100/key:.1f}\"", "if", "isinstance", "(", "key", ",", "int", ")", "else", "key", "\n", "print", "(", "f\"{name}\\t{mean_error:.4f}\\t{mean_f1*100:.2f}\"", ")", "\n", "# pprint(result_dict)", "\n", "\n", "", "if", "args", ".", "output", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output", ",", "\"result_dict.json\"", ")", ",", "\"wt\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "result_dict", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.tacred2mnli.tacred2mnli": [[98, 145], ["random.choices", "mnli_instances.extend", "random.choices", "mnli_instances.extend", "random.choices", "tacred2mnli.MNLIInputFeatures", "tacred2mnli.MNLIInputFeatures", "tacred2mnli.MNLIInputFeatures", "t.format", "t.format", "t.format"], "function", ["None"], ["", "", "", "def", "tacred2mnli", "(", "\n", "instance", ":", "REInputFeatures", ",", "\n", "positive_templates", ",", "\n", "negative_templates", ",", "\n", "templates", ",", "\n", "negn", "=", "1", ",", "\n", "posn", "=", "1", ",", "\n", ")", ":", "\n", "    ", "if", "instance", ".", "label", "==", "\"no_relation\"", ":", "\n", "        ", "template", "=", "random", ".", "choices", "(", "templates", ",", "k", "=", "negn", ")", "\n", "return", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "f\"{t.format(subj=instance.subj, obj=instance.obj)}.\"", ",", "\n", "label", "=", "labels2id", "[", "\"contradiction\"", "]", ",", "\n", ")", "\n", "for", "t", "in", "template", "\n", "]", "\n", "\n", "# Generate the positive examples", "\n", "", "mnli_instances", "=", "[", "]", "\n", "positive_template", "=", "random", ".", "choices", "(", "positive_templates", "[", "instance", ".", "label", "]", ",", "k", "=", "posn", ")", "\n", "mnli_instances", ".", "extend", "(", "\n", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "f\"{t.format(subj=instance.subj, obj=instance.obj)}.\"", ",", "\n", "label", "=", "labels2id", "[", "\"entailment\"", "]", ",", "\n", ")", "\n", "for", "t", "in", "positive_template", "\n", "]", "\n", ")", "\n", "\n", "# Generate the negative templates", "\n", "negative_template", "=", "random", ".", "choices", "(", "negative_templates", "[", "instance", ".", "label", "]", ",", "k", "=", "negn", ")", "\n", "mnli_instances", ".", "extend", "(", "\n", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "f\"{t.format(subj=instance.subj, obj=instance.obj)}.\"", ",", "\n", "label", "=", "labels2id", "[", "\"neutral\"", "]", ",", "\n", ")", "\n", "for", "t", "in", "negative_template", "\n", "]", "\n", ")", "\n", "\n", "return", "mnli_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.tacred2mnli.tacred2mnli_with_negative_pattern": [[147, 193], ["random.choices", "mnli_instances.extend", "random.choices", "mnli_instances.extend", "mnli_instances.append", "tacred2mnli.MNLIInputFeatures", "tacred2mnli.MNLIInputFeatures", "tacred2mnli.MNLIInputFeatures", "t.format", "t.format"], "function", ["None"], ["", "def", "tacred2mnli_with_negative_pattern", "(", "\n", "instance", ":", "REInputFeatures", ",", "\n", "positive_templates", ",", "\n", "negative_templates", ",", "\n", "templates", ",", "\n", "negn", "=", "1", ",", "\n", "posn", "=", "1", ",", "\n", ")", ":", "\n", "    ", "mnli_instances", "=", "[", "]", "\n", "# Generate the positive examples", "\n", "positive_template", "=", "random", ".", "choices", "(", "positive_templates", "[", "instance", ".", "label", "]", ",", "k", "=", "posn", ")", "\n", "mnli_instances", ".", "extend", "(", "\n", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "f\"{t.format(subj=instance.subj, obj=instance.obj)}.\"", ",", "\n", "label", "=", "labels2id", "[", "\"entailment\"", "]", ",", "\n", ")", "\n", "for", "t", "in", "positive_template", "\n", "]", "\n", ")", "\n", "\n", "# Generate the negative templates", "\n", "negative_template", "=", "random", ".", "choices", "(", "negative_templates", "[", "instance", ".", "label", "]", ",", "k", "=", "negn", ")", "\n", "mnli_instances", ".", "extend", "(", "\n", "[", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "f\"{t.format(subj=instance.subj, obj=instance.obj)}.\"", ",", "\n", "label", "=", "labels2id", "[", "\"neutral\"", "]", "if", "instance", ".", "label", "!=", "\"no_relation\"", "else", "labels2id", "[", "\"contradiction\"", "]", ",", "\n", ")", "\n", "for", "t", "in", "negative_template", "\n", "]", "\n", ")", "\n", "\n", "# Add the contradiction regarding the no_relation pattern if the relation is not no_relation", "\n", "if", "instance", ".", "label", "!=", "\"no_relation\"", ":", "\n", "        ", "mnli_instances", ".", "append", "(", "\n", "MNLIInputFeatures", "(", "\n", "premise", "=", "instance", ".", "context", ",", "\n", "hypothesis", "=", "\"{subj} and {obj} are not related.\"", ".", "format", "(", "subj", "=", "instance", ".", "subj", ",", "obj", "=", "instance", ".", "obj", ")", ",", "\n", "label", "=", "labels2id", "[", "\"contradiction\"", "]", ",", "\n", ")", "\n", ")", "\n", "\n", "", "return", "mnli_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.output_mistakes.main": [[37, 67], ["numpy.load", "numpy.load", "numpy.argmax", "open", "numpy.array", "open", "numpy.array", "open", "zip", "f.write", "f.write", "f.write", "f.write", "range", "f.write", "topic.rstrip().replace", "line.rstrip().split", "out.argsort", "f.write", "topic.rstrip", "line.rstrip"], "function", ["None"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "with", "open", "(", "opt", ".", "label_names", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "topics", "=", "np", ".", "array", "(", "[", "topic", ".", "rstrip", "(", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "topic", "in", "f", "]", ")", "\n", "\n", "", "with", "open", "(", "opt", ".", "glosses", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "info", "=", "np", ".", "array", "(", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "for", "line", "in", "f", "]", ")", "\n", "\n", "", "output", "=", "np", ".", "load", "(", "opt", ".", "predictions", ")", "\n", "labels", "=", "np", ".", "load", "(", "opt", ".", "labels", ")", "\n", "\n", "output_", "=", "np", ".", "argmax", "(", "output", ",", "axis", "=", "-", "1", ")", "\n", "wrong_predictions", "=", "labels", "!=", "output_", "\n", "\n", "assert", "output", "[", "wrong_predictions", "]", ".", "shape", "[", "0", "]", "==", "labels", "[", "wrong_predictions", "]", ".", "shape", "[", "0", "]", "\n", "\n", "with", "open", "(", "opt", ".", "output", ",", "\"wt\"", ")", "as", "f", ":", "\n", "\n", "        ", "for", "(", "sense_id", ",", "l", ",", "gloss", ")", ",", "out", ",", "true", "in", "zip", "(", "\n", "info", "[", "wrong_predictions", "]", ",", "\n", "output", "[", "wrong_predictions", "]", ",", "\n", "labels", "[", "wrong_predictions", "]", ",", "\n", ")", ":", "\n", "            ", "f", ".", "write", "(", "f\"Sense-id:\\t{sense_id}\\n\"", ")", "\n", "f", ".", "write", "(", "f\"Gloss:\\t\\t{gloss}\\n\"", ")", "\n", "f", ".", "write", "(", "f\"Correct label:\\t{l}\\n\"", ")", "\n", "f", ".", "write", "(", "f\"Top-5 Predictions:\\n\"", ")", "\n", "idxs", "=", "out", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"   {out[idxs[i]]:.4f}\\t{topics[idxs[i]]}\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.evaluate_re.main": [[14, 40], ["glob.iglob", "glob.iglob", "numpy.std", "print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "precision_recall_fscore_", "pre.append", "rec.append", "f1.append", "sorted", "find_optimal_threshold", "apply_threshold", "list", "zip", "len", "file_name.replace"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.precision_recall_fscore_", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold"], ["def", "main", "(", "name", ")", ":", "\n", "# Load dev data", "\n", "    ", "dev_data", "=", "{", "}", "\n", "for", "split", "in", "[", "0.01", ",", "0.05", ",", "0.1", "]", ":", "\n", "        ", "for", "file_name", "in", "glob", ".", "iglob", "(", "f\"experiments/re_dev_{name}_{split}_*\"", ")", ":", "\n", "            ", "labels", "=", "np", ".", "load", "(", "f\"{file_name}/labels.npy\"", ")", "\n", "output", "=", "np", ".", "load", "(", "f\"{file_name}/output.npy\"", ")", "\n", "dev_data", "[", "file_name", "]", "=", "find_optimal_threshold", "(", "labels", ",", "output", ")", "[", "0", "]", "\n", "\n", "", "", "test_data", "=", "{", "}", "\n", "for", "split", "in", "[", "0.01", ",", "0.05", ",", "0.1", "]", ":", "\n", "        ", "pre", ",", "rec", ",", "f1", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "file_name", "in", "glob", ".", "iglob", "(", "f\"experiments/re_test_{name}_{split}_*\"", ")", ":", "\n", "            ", "labels", "=", "np", ".", "load", "(", "f\"{file_name}/labels.npy\"", ")", "\n", "output", "=", "np", ".", "load", "(", "f\"{file_name}/output.npy\"", ")", "\n", "p", ",", "r", ",", "f", "=", "precision_recall_fscore_", "(", "\n", "labels", ",", "\n", "apply_threshold", "(", "output", ",", "dev_data", "[", "file_name", ".", "replace", "(", "\"test\"", ",", "\"dev\"", ")", "]", ")", ",", "\n", ")", "\n", "pre", ".", "append", "(", "p", "*", "100", ")", "\n", "rec", ".", "append", "(", "r", "*", "100", ")", "\n", "f1", ".", "append", "(", "f", "*", "100", ")", "\n", "\n", "", "std", "=", "np", ".", "std", "(", "f1", ")", "\n", "output", "=", "sorted", "(", "list", "(", "zip", "(", "pre", ",", "rec", ",", "f1", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", "[", "len", "(", "f1", ")", "//", "2", "]", "\n", "print", "(", "f\"{split} - P/R/F1: {output} +/- {std}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.extract_patterns_re.main": [[13, 35], ["collections.defaultdict", "open", "json.load", "open", "json.dump", "min", "patterns[].append", "abs", "abs"], "function", ["None"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "with", "open", "(", "opt", ".", "input_file", ",", "\"rt\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "patterns", "=", "defaultdict", "(", "list", ")", "\n", "for", "instance", "in", "data", ":", "\n", "        ", "if", "(", "\n", "min", "(", "\n", "abs", "(", "instance", "[", "\"obj_start\"", "]", "-", "instance", "[", "\"subj_end\"", "]", ")", ",", "\n", "abs", "(", "instance", "[", "\"obj_end\"", "]", "-", "instance", "[", "\"subj_start\"", "]", ")", ",", "\n", ")", "\n", "<=", "opt", ".", "max_dist", "\n", ")", ":", "\n", "\n", "            ", "if", "instance", "[", "\"subj_start\"", "]", "<", "instance", "[", "\"obj_start\"", "]", ":", "\n", "                ", "pattern", "=", "[", "\"{subj}\"", "]", "+", "instance", "[", "\"token\"", "]", "[", "instance", "[", "\"subj_end\"", "]", "+", "1", ":", "instance", "[", "\"obj_start\"", "]", "]", "+", "[", "\"{obj}\"", "]", "\n", "", "else", ":", "\n", "                ", "pattern", "=", "[", "\"{obj}\"", "]", "+", "instance", "[", "\"token\"", "]", "[", "instance", "[", "\"obj_end\"", "]", "+", "1", ":", "instance", "[", "\"subj_start\"", "]", "]", "+", "[", "\"{subj}\"", "]", "\n", "", "patterns", "[", "instance", "[", "\"relation\"", "]", "]", ".", "append", "(", "\" \"", ".", "join", "(", "pattern", ")", ")", "\n", "\n", "", "", "with", "open", "(", "opt", ".", "output_file", ",", "\"wt\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "patterns", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.run_glue.DataTrainingArguments.__post_init__": [[146, 165], ["run_glue.DataTrainingArguments.task_name.lower", "task_to_keys.keys", "ValueError", "ValueError", "run_glue.DataTrainingArguments.train_file.split", "run_glue.DataTrainingArguments.validation_file.split", "task_to_keys.keys"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "self", ".", "task_name", "=", "self", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "self", ".", "task_name", "not", "in", "task_to_keys", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown task, you should pick one in \"", "+", "\",\"", ".", "join", "(", "task_to_keys", ".", "keys", "(", ")", ")", ")", "\n", "", "", "elif", "self", ".", "dataset_name", "is", "not", "None", ":", "\n", "            ", "pass", "\n", "", "elif", "self", ".", "train_file", "is", "None", "or", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a GLUE task, a training/validation file or a dataset name.\"", ")", "\n", "", "else", ":", "\n", "            ", "train_extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "train_extension", "in", "[", "\n", "\"csv\"", ",", "\n", "\"json\"", ",", "\n", "]", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "validation_extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "validation_extension", "==", "train_extension", "\n", ")", ",", "\"`validation_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.run_glue.main": [[205, 576], ["transformers.HfArgumentParser", "logging.basicConfig", "training_args.get_process_log_level", "logger.setLevel", "datasets.utils.logging.set_verbosity", "transformers.utils.logging.set_verbosity", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "min", "transformers.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "datasets.load_dataset", "logger.warning", "AutoTokenizer.from_pretrained.", "training_args.main_process_first", "datasets.load_dataset.map", "random.sample", "datasets.load_metric", "datasets.load_metric", "transformers.Trainer.train", "min", "transformers.Trainer.save_model", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "transformers.Trainer.save_state", "logger.info", "zip", "logger.info", "zip", "transformers.Trainer.push_to_hub", "len", "ValueError", "datasets.load_dataset", "data_files.keys", "data_args.train_file.endswith", "len", "raw_datasets[].unique", "raw_datasets[].unique.sort", "len", "bool", "k.lower", "list", "list", "logger.warning", "ValueError", "train_dataset.select.select", "ValueError", "eval_dataset.select.select", "ValueError", "predict_dataset.remove_columns.select", "range", "logger.info", "isinstance", "numpy.squeeze", "numpy.argmax", "datasets.load_metric.compute", "transformers.DataCollatorWithPadding", "len", "len", "tasks.append", "eval_datasets.append", "transformers.Trainer.evaluate", "min", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "tasks.append", "predict_datasets.append", "predict_dataset.remove_columns.remove_columns", "os.path.join", "transformers.Trainer.is_world_process_zero", "os.path.abspath", "logging.StreamHandler", "len", "logger.info", "logger.info", "datasets.load_dataset", "datasets.load_dataset", "len", "transformers.PretrainedConfig", "AutoModelForSequenceClassification.from_pretrained.config.label2id.items", "sorted", "sorted", "int", "AutoConfig.from_pretrained.label2id.items", "range", "range", "range", "len", "len", "numpy.mean().item", "len", "len", "transformers.Trainer.predict", "numpy.squeeze", "numpy.argmax", "bool", "os.listdir", "ValueError", "label_name_to_id.keys", "range", "enumerate", "open", "logger.info", "writer.write", "enumerate", "data_args.task_name.upper", "data_args.train_file.split", "data_args.test_file.split", "list", "list", "numpy.mean", "sorted", "sorted", "list", "writer.write", "writer.write", "label_name_to_id.keys", "metric.compute.values"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.train", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier.predict"], ["", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or specify a GLUE benchmark task (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use as labels the column called 'label' and as pair of sentences the", "\n", "# sentences in columns called 'sentence1' and 'sentence2' if such column exists or the first two columns not named", "\n", "# label if at least two columns are provided.", "\n", "#", "\n", "# If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this", "\n", "# single column. You can easily tweak this behavior (see below)", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"glue\"", ",", "data_args", ".", "task_name", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "elif", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from your local files.", "\n", "# CSV/JSON training and evaluation files are needed.", "\n", "        ", "data_files", "=", "{", "\n", "\"train\"", ":", "data_args", ".", "train_file", ",", "\n", "\"validation\"", ":", "data_args", ".", "validation_file", ",", "\n", "}", "\n", "\n", "# Get the test dataset: you can provide your own CSV/JSON test file (see below)", "\n", "# when you use `do_predict` without specifying a GLUE benchmark task.", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "            ", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "                ", "train_extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "test_extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "test_extension", "==", "train_extension", "\n", ")", ",", "\"`test_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Need either a GLUE task or a test file for `do_predict`.\"", ")", "\n", "\n", "", "", "for", "key", "in", "data_files", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"load a local file for {key}: {data_files[key]}\"", ")", "\n", "\n", "", "if", "data_args", ".", "train_file", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "# Loading a dataset from local csv files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\"csv\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from local json files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "# See more about loading any type of standard or custom dataset at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Labels", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "is_regression", "=", "data_args", ".", "task_name", "==", "\"stsb\"", "\n", "if", "not", "is_regression", ":", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "names", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "", "else", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "", "else", ":", "\n", "# Trying to have good defaults here, don't hesitate to tweak to your needs.", "\n", "        ", "is_regression", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "dtype", "in", "[", "\n", "\"float32\"", ",", "\n", "\"float64\"", ",", "\n", "]", "\n", "if", "is_regression", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "else", ":", "\n", "# A useful fast method:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "unique", "(", "\"label\"", ")", "\n", "label_list", ".", "sort", "(", ")", "# Let's sort it for determinism", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "data_args", ".", "task_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Preprocessing the raw_datasets", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "sentence1_key", ",", "sentence2_key", "=", "task_to_keys", "[", "data_args", ".", "task_name", "]", "\n", "", "else", ":", "\n", "# Again, we try to have some nice defaults but don't hesitate to tweak to your use case.", "\n", "        ", "non_label_column_names", "=", "[", "name", "for", "name", "in", "raw_datasets", "[", "\"train\"", "]", ".", "column_names", "if", "name", "!=", "\"label\"", "]", "\n", "if", "\"sentence1\"", "in", "non_label_column_names", "and", "\"sentence2\"", "in", "non_label_column_names", ":", "\n", "            ", "sentence1_key", ",", "sentence2_key", "=", "\"sentence1\"", ",", "\"sentence2\"", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "non_label_column_names", ")", ">=", "2", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", "0", "]", ",", "None", "\n", "\n", "# Padding strategy", "\n", "", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "# We will pad later, dynamically at batch creation, to the max sequence length in each batch", "\n", "        ", "padding", "=", "False", "\n", "\n", "# Some models have set the order of the labels to use, so let's make sure we do use it.", "\n", "", "label_to_id", "=", "None", "\n", "if", "(", "\n", "model", ".", "config", ".", "label2id", "!=", "PretrainedConfig", "(", "num_labels", "=", "num_labels", ")", ".", "label2id", "\n", "and", "data_args", ".", "task_name", "is", "not", "None", "\n", "and", "not", "is_regression", "\n", ")", ":", "\n", "# Some have all caps in their config, some don't.", "\n", "        ", "label_name_to_id", "=", "{", "k", ".", "lower", "(", ")", ":", "v", "for", "k", ",", "v", "in", "model", ".", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "if", "list", "(", "sorted", "(", "label_name_to_id", ".", "keys", "(", ")", ")", ")", "==", "list", "(", "sorted", "(", "label_list", ")", ")", ":", "\n", "            ", "label_to_id", "=", "{", "i", ":", "int", "(", "label_name_to_id", "[", "label_list", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "num_labels", ")", "}", "\n", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Your model seems to have been trained with labels, but they don't match the dataset: \"", ",", "\n", "f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"", "\n", "\"\\nIgnoring the model labels as a result.\"", ",", "\n", ")", "\n", "", "", "elif", "data_args", ".", "task_name", "is", "None", "and", "not", "is_regression", ":", "\n", "        ", "label_to_id", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "", "if", "label_to_id", "is", "not", "None", ":", "\n", "        ", "model", ".", "config", ".", "label2id", "=", "label_to_id", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "# Map labels to IDs (not necessary for GLUE tasks)", "\n", "if", "label_to_id", "is", "not", "None", "and", "\"label\"", "in", "examples", ":", "\n", "            ", "result", "[", "\"label\"", "]", "=", "[", "(", "label_to_id", "[", "l", "]", "if", "l", "!=", "-", "1", "else", "-", "1", ")", "for", "l", "in", "examples", "[", "\"label\"", "]", "]", "\n", "", "return", "result", "\n", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"dataset map pre-processing\"", ")", ":", "\n", "        ", "raw_datasets", "=", "raw_datasets", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on dataset\"", ",", "\n", ")", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "if", "\"validation\"", "not", "in", "raw_datasets", "and", "\"validation_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", "or", "data_args", ".", "task_name", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "        ", "if", "\"test\"", "not", "in", "raw_datasets", "and", "\"test_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {train_dataset[index]}.\"", ")", "\n", "\n", "# Get the metric function", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"glue\"", ",", "data_args", ".", "task_name", ")", "\n", "", "else", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"accuracy\"", ")", "\n", "\n", "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a", "\n", "# predictions and label_ids field) and has to return a dictionary string to float.", "\n", "", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "preds", ",", "references", "=", "p", ".", "label_ids", ")", "\n", "if", "len", "(", "result", ")", ">", "1", ":", "\n", "                ", "result", "[", "\"combined_score\"", "]", "=", "np", ".", "mean", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", ".", "item", "(", ")", "\n", "", "return", "result", "\n", "", "elif", "is_regression", ":", "\n", "            ", "return", "{", "\"mse\"", ":", "(", "(", "preds", "-", "p", ".", "label_ids", ")", "**", "2", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"accuracy\"", ":", "(", "preds", "==", "p", ".", "label_ids", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "training_args", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "max_train_samples", "=", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "eval_dataset", "]", "\n", "if", "data_args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "tasks", ".", "append", "(", "\"mnli-mm\"", ")", "\n", "eval_datasets", ".", "append", "(", "raw_datasets", "[", "\"validation_mismatched\"", "]", ")", "\n", "\n", "", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ")", "\n", "\n", "max_eval_samples", "=", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "predict_datasets", "=", "[", "predict_dataset", "]", "\n", "if", "data_args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "tasks", ".", "append", "(", "\"mnli-mm\"", ")", "\n", "predict_datasets", ".", "append", "(", "raw_datasets", "[", "\"test_mismatched\"", "]", ")", "\n", "\n", "", "for", "predict_dataset", ",", "task", "in", "zip", "(", "predict_datasets", ",", "tasks", ")", ":", "\n", "# Removing the `label` columns because it contains -1 and Trainer won't like that.", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "remove_columns", "(", "\"label\"", ")", "\n", "predictions", "=", "trainer", ".", "predict", "(", "predict_dataset", ",", "metric_key_prefix", "=", "\"predict\"", ")", ".", "predictions", "\n", "predictions", "=", "np", ".", "squeeze", "(", "predictions", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "\n", "output_predict_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "f\"predict_results_{task}.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "                ", "with", "open", "(", "output_predict_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"***** Predict results {task} *****\"", ")", "\n", "writer", ".", "write", "(", "\"index\\tprediction\\n\"", ")", "\n", "for", "index", ",", "item", "in", "enumerate", "(", "predictions", ")", ":", "\n", "                        ", "if", "is_regression", ":", "\n", "                            ", "writer", ".", "write", "(", "f\"{index}\\t{item:3.3f}\\n\"", ")", "\n", "", "else", ":", "\n", "                            ", "item", "=", "label_list", "[", "item", "]", "\n", "writer", ".", "write", "(", "f\"{index}\\t{item}\\n\"", ")", "\n", "\n", "", "", "", "", "", "", "if", "training_args", ".", "push_to_hub", ":", "\n", "        ", "kwargs", "=", "{", "\n", "\"finetuned_from\"", ":", "model_args", ".", "model_name_or_path", ",", "\n", "\"tasks\"", ":", "\"text-classification\"", ",", "\n", "}", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "kwargs", "[", "\"language\"", "]", "=", "\"en\"", "\n", "kwargs", "[", "\"dataset_tags\"", "]", "=", "\"glue\"", "\n", "kwargs", "[", "\"dataset_args\"", "]", "=", "data_args", ".", "task_name", "\n", "kwargs", "[", "\"dataset\"", "]", "=", "f\"GLUE {data_args.task_name.upper()}\"", "\n", "\n", "", "trainer", ".", "push_to_hub", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.scripts.run_glue._mp_fn": [[578, 581], ["run_glue.main"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_glue.main"], ["", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.Classifier.__init__": [[42, 65], ["object.__init__", "torch.device", "base.Classifier.model.to", "base.Classifier.model.eval", "open", "base.Classifier._initialize", "base.Classifier._initialize", "torch.cuda.is_available", "base.Classifier.model.half", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._initialize", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._initialize"], ["def", "__init__", "(", "\n", "self", ",", "labels", ":", "List", "[", "str", "]", ",", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "use_cuda", "=", "True", ",", "half", "=", "False", ",", "verbose", "=", "True", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "use_cuda", "else", "\"cpu\"", ")", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "use_cuda", "=", "use_cuda", "\n", "self", ".", "half", "=", "half", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "# Supress stdout printing for model downloads", "\n", "if", "not", "verbose", ":", "\n", "            ", "sys", ".", "stdout", "=", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", "\n", "self", ".", "_initialize", "(", "pretrained_model", ")", "\n", "sys", ".", "stdout", "=", "sys", ".", "__stdout__", "\n", "", "else", ":", "\n", "            ", "self", ".", "_initialize", "(", "pretrained_model", ")", "\n", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "self", ".", "use_cuda", "and", "self", ".", "half", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "half", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.Classifier._initialize": [[66, 68], ["None"], "methods", ["None"], ["", "", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.Classifier.__call__": [[69, 71], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "context", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.Classifier.clear_gpu_memory": [[72, 77], ["base.Classifier.model.cpu", "gc.collect", "torch.cuda.empty_cache"], "methods", ["None"], ["", "def", "clear_gpu_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cpu", "(", ")", "\n", "del", "self", ".", "model", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.EntailmentClassifier.__init__": [[86, 104], ["base.Classifier.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "use_cuda", ":", "bool", "=", "True", ",", "\n", "half", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pretrained_model (str, optional): The name or path of the pretrained model. Defaults to \"roberta-large-mnli\".\n            use_cuda (bool, optional): Use the GPU if possible. Defaults to True.\n            half (bool, optional): Use half precision if possible. Defaults to False.\n            verbose (bool, optional): Output log information. Defaults to True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "None", ",", "pretrained_model", ",", "use_cuda", ",", "half", ",", "verbose", ")", "\n", "self", ".", "use_tqdm", "=", "use_tqdm", "and", "_use_tqdm", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.EntailmentClassifier._initialize": [[105, 114], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "base.EntailmentClassifier.config.label2id.get", "base.EntailmentClassifier.config.label2id.get", "ValueError", "int"], "methods", ["None"], ["", "def", "_initialize", "(", "self", ",", "pretrained_model", ":", "str", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "ent_pos", "=", "self", ".", "config", ".", "label2id", ".", "get", "(", "\"ENTAILMENT\"", ",", "self", ".", "config", ".", "label2id", ".", "get", "(", "\"entailment\"", ",", "None", ")", ")", "\n", "if", "self", ".", "ent_pos", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"The model config must contain ENTAILMENT label in the label2id dict.\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ent_pos", "=", "int", "(", "self", ".", "ent_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.EntailmentClassifier.apply_threshold": [[115, 146], ["output.copy", "ValueError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "apply_threshold", "(", "\n", "output", ":", "np", ".", "ndarray", ",", "\n", "threshold", ":", "float", "=", "0.0", ",", "\n", "ignore_negative_prediction", ":", "bool", "=", "True", ",", "\n", "application_type", ":", "str", "=", "\"prediction\"", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            output (ndarray): (batch_size, n_labels) The predicted probabilities.\n            threshold (float): The threshold value to apply.\n            ignore_negative_prediction (bool): Ignore the negative prediction probabilites. Default to True.\n            application_type (str): How to apply the threshold: Options:\n\n                * **\"prediction\"**: Set to 1.0 the probability of the negative class if the no prediction is higher than the threshold.\n                * **\"mask\"**: Set to 0.0 the probabilities of the positive classes that are lower or equal to the threshold.\n        \"\"\"", "\n", "output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n", "            ", "output_", "[", ":", ",", "0", "]", "=", "0.0", "\n", "", "if", "application_type", "==", "\"prediction\"", ":", "\n", "            ", "activations", "=", "(", "output_", ">=", "threshold", ")", ".", "sum", "(", "-", "1", ")", ".", "astype", "(", "int", ")", "\n", "output_", "[", "activations", "==", "0", ",", "0", "]", "=", "1.00", "\n", "", "elif", "application_type", "==", "\"mask\"", ":", "\n", "            ", "activations", "=", "output_", "<", "threshold", "\n", "output_", "[", "activations", "]", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"application_type argument must be \"prediction\" or \"mask\".\"\"\"", ")", "\n", "\n", "", "return", "output_", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.EntailmentClassifier.__call__": [[147, 231], ["task.assert_features_class", "numpy.vstack", "outputs[].reshape", "task.reverse_to_labels", "task.apply_valid_conditions", "tqdm", "torch.no_grad", "len", "base.np_softmax", "base.EntailmentClassifier.apply_threshold", "numpy.argsort", "task.idx2label", "numpy.stack().tolist", "predictions.tolist.tolist.tolist", "task.generate_premise_hypotheses_pairs", "data.to.to.to", "[].detach().cpu().numpy", "outputs[].reshape.append", "numpy.exp", "numpy.exp().sum", "numpy.sort", "len", "base.EntailmentClassifier.tokenizer", "numpy.stack", "[].detach().cpu", "numpy.exp", "int", "float", "float", "[].detach", "base.EntailmentClassifier.model"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.reverse_to_labels", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.apply_valid_conditions", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "task", ":", "Task", ",", "\n", "features", ":", "List", "[", "Features", "]", ",", "\n", "negative_threshold", ":", "float", "=", "0.5", ",", "\n", "topk", ":", "int", "=", "1", ",", "\n", "return_labels", ":", "bool", "=", "False", ",", "\n", "return_confidences", ":", "bool", "=", "False", ",", "\n", "ignore_negative_prediction", ":", "bool", "=", "False", ",", "\n", "return_raw_output", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", ":", "\n", "        ", "\"\"\"Call method for the EntailmentClassifier.\n\n\n        TODO: Add output documentation.\n\n        Args:\n            task (Task): The task instance used for inference.\n            features (List[Features]): The list of features to classify.\n            negative_threshold (float, optional): The threshold used if necessary. Defaults to 0.5.\n            topk (int, optional): Return the first `k` predictions with higher probabilities. Defaults to 1.\n            return_labels (bool, optional): Whether to return the label ids or names. Defaults to False (ids).\n            return_confidences (bool, optional): Whether to return prediction confidences or not. Defaults to False.\n            ignore_negative_prediction (bool, optional): Whether to ignore the predictions of the negative class. Defaults to False.\n            return_raw_output (bool, optional): Return the raw output along with the processed one. Defaults to False.\n\n        Returns:\n            List: A list with the predictions.\n        \"\"\"", "\n", "task", ".", "assert_features_class", "(", "features", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "iterator", "=", "features", "if", "not", "self", ".", "use_tqdm", "else", "tqdm", "(", "features", ",", "total", "=", "len", "(", "features", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "feature", "in", "iterator", ":", "\n", "                ", "sentence_pairs", "=", "task", ".", "generate_premise_hypotheses_pairs", "(", "[", "feature", "]", ",", "self", ".", "tokenizer", ".", "sep_token", ")", "\n", "data", "=", "self", ".", "tokenizer", "(", "sentence_pairs", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ")", ".", "input_ids", "\n", "data", "=", "data", ".", "to", "(", "self", ".", "device", ")", "\n", "output", "=", "self", ".", "model", "(", "data", ")", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "if", "task", ".", "multi_label", ":", "\n", "            ", "outputs", "=", "np", ".", "exp", "(", "outputs", ")", "/", "np", ".", "exp", "(", "outputs", ")", ".", "sum", "(", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "", "outputs", "=", "outputs", "[", "...", ",", "self", ".", "ent_pos", "]", ".", "reshape", "(", "len", "(", "features", ")", ",", "-", "1", ")", "\n", "\n", "preds", "=", "task", ".", "reverse_to_labels", "(", "outputs", ")", "\n", "if", "not", "task", ".", "multi_label", ":", "\n", "            ", "preds", "=", "np_softmax", "(", "preds", ")", "\n", "\n", "", "preds", "=", "task", ".", "apply_valid_conditions", "(", "features", ",", "preds", ")", "\n", "\n", "apply_threshold", "=", "task", ".", "multi_label", "and", "negative_threshold", ">", "0", "\n", "if", "apply_threshold", ":", "\n", "            ", "preds", "=", "self", ".", "apply_threshold", "(", "\n", "preds", ",", "threshold", "=", "negative_threshold", ",", "ignore_negative_prediction", "=", "ignore_negative_prediction", "\n", ")", "\n", "\n", "", "predictions", "=", "np", ".", "argsort", "(", "preds", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "if", "topk", ">", "0", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", ",", ":", "topk", "]", "\n", "", "if", "return_labels", ":", "\n", "            ", "predictions", "=", "task", ".", "idx2label", "(", "predictions", ")", "\n", "", "if", "return_confidences", ":", "\n", "            ", "confidences", "=", "np", ".", "sort", "(", "preds", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "if", "topk", ">", "0", ":", "\n", "                ", "confidences", "=", "confidences", "[", ":", ",", ":", "topk", "]", "\n", "\n", "", "predictions", "=", "np", ".", "stack", "(", "(", "predictions", ",", "confidences", ")", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "predictions", "=", "[", "\n", "[", "(", "int", "(", "label", ")", ",", "float", "(", "conf", ")", ")", "if", "not", "return_labels", "else", "(", "label", ",", "float", "(", "conf", ")", ")", "for", "label", ",", "conf", "in", "row", "]", "\n", "for", "row", "in", "predictions", "\n", "]", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "predictions", ".", "tolist", "(", ")", "\n", "", "if", "topk", "==", "1", ":", "\n", "            ", "predictions", "=", "[", "row", "[", "0", "]", "for", "row", "in", "predictions", "]", "\n", "\n", "", "if", "return_raw_output", ":", "\n", "            ", "return", "(", "predictions", ",", "preds", ")", "\n", "", "else", ":", "\n", "            ", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.np_softmax": [[30, 33], ["numpy.exp", "numpy.sum"], "function", ["None"], ["", "def", "np_softmax", "(", "x", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "e", "=", "np", ".", "exp", "(", "x", ")", "\n", "return", "e", "/", "np", ".", "sum", "(", "e", ",", "axis", "=", "dim", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.np_sigmoid": [[35, 37], ["numpy.exp"], "function", ["None"], ["", "def", "np_sigmoid", "(", "x", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "return", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.f1_score_": [[7, 10], ["sklearn.metrics.f1_score", "max", "list", "range"], "function", ["None"], ["def", "f1_score_", "(", "labels", ",", "preds", ",", "n_labels", "=", "None", ")", ":", "\n", "    ", "n_labels", "=", "max", "(", "labels", ")", "+", "1", "if", "n_labels", "is", "None", "else", "n_labels", "\n", "return", "f1_score", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "1", ",", "n_labels", ")", ")", ",", "average", "=", "\"micro\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.individual_f1_score_": [[12, 15], ["sklearn.metrics.f1_score", "max", "list", "range"], "function", ["None"], ["", "def", "individual_f1_score_", "(", "labels", ",", "preds", ",", "n_labels", "=", "None", ")", ":", "\n", "    ", "n_labels", "=", "max", "(", "labels", ")", "+", "1", "if", "n_labels", "is", "None", "else", "n_labels", "\n", "return", "f1_score", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "0", ",", "n_labels", ")", ")", ",", "average", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.precision_recall_fscore_": [[17, 21], ["sklearn.metrics.precision_recall_fscore_support", "max", "list", "range"], "function", ["None"], ["", "def", "precision_recall_fscore_", "(", "labels", ",", "preds", ",", "n_labels", ":", "int", "=", "None", ")", ":", "\n", "    ", "n_labels", "=", "max", "(", "labels", ")", "+", "1", "if", "n_labels", "is", "None", "else", "n_labels", "\n", "p", ",", "r", ",", "f", ",", "_", "=", "precision_recall_fscore_support", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "1", ",", "n_labels", ")", ")", ",", "average", "=", "\"micro\"", ")", "\n", "return", "p", ",", "r", ",", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.apply_threshold": [[23, 32], ["output.copy", "output.copy.argmax"], "function", ["None"], ["", "def", "apply_threshold", "(", "output", ",", "threshold", "=", "0.0", ",", "ignore_negative_prediction", "=", "True", ",", "negative_label_id", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"Applies a threshold to determine whether is a relation or not\"\"\"", "\n", "output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n", "        ", "output_", "[", ":", ",", "negative_label_id", "]", "=", "0.0", "\n", "", "activations", "=", "(", "output_", ">=", "threshold", ")", ".", "sum", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "output_", "[", "activations", "==", "0", ",", "negative_label_id", "]", "=", "1.00", "\n", "\n", "return", "output_", ".", "argmax", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.apply_individual_threshold": [[34, 45], ["output.copy", "enumerate", "output.copy.argmax"], "function", ["None"], ["", "def", "apply_individual_threshold", "(", "output", ",", "thresholds", ",", "ignore_negative_prediction", "=", "True", ")", ":", "\n", "    ", "output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n", "        ", "output_", "[", ":", ",", "0", "]", "=", "0.0", "\n", "", "for", "i", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "if", "not", "i", ":", "\n", "            ", "continue", "\n", "", "activations", "=", "output_", "[", ":", ",", "i", "]", "<", "threshold", "\n", "output_", "[", "activations", ",", "i", "]", "=", "0.0", "\n", "\n", "", "return", "output_", ".", "argmax", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.find_optimal_threshold": [[47, 66], ["numpy.linspace", "numpy.argmax", "apply_threshold_fn", "values.append", "metric"], "function", ["None"], ["", "def", "find_optimal_threshold", "(", "\n", "labels", ",", "\n", "output", ",", "\n", "granularity", "=", "1000", ",", "\n", "metric", "=", "f1_score_", ",", "\n", "n_labels", "=", "None", ",", "\n", "negative_label_id", ":", "int", "=", "0", ",", "\n", "apply_threshold_fn", ":", "Callable", "=", "apply_threshold", ",", "\n", ")", ":", "\n", "    ", "thresholds", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "granularity", ")", "\n", "values", "=", "[", "]", "\n", "for", "t", "in", "thresholds", ":", "\n", "        ", "preds", "=", "apply_threshold_fn", "(", "output", ",", "threshold", "=", "t", ",", "negative_label_id", "=", "negative_label_id", ")", "\n", "values", ".", "append", "(", "metric", "(", "labels", ",", "preds", ",", "n_labels", "=", "n_labels", ")", ")", "\n", "\n", "", "best_metric_id", "=", "np", ".", "argmax", "(", "values", ")", "\n", "best_threshold", "=", "thresholds", "[", "best_metric_id", "]", "\n", "\n", "return", "best_threshold", ",", "values", "[", "best_metric_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.find_optimal_individual_threshold": [[68, 93], ["numpy.linspace", "numpy.argmax", "utils.apply_individual_threshold", "values.append", "range", "metric", "indv_metric", "utils.apply_individual_threshold", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.apply_individual_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.apply_individual_threshold"], ["", "def", "find_optimal_individual_threshold", "(", "\n", "labels", ",", "\n", "output", ",", "\n", "granularity", "=", "1000", ",", "\n", "indv_metric", "=", "individual_f1_score_", ",", "\n", "metric", "=", "f1_score_", ",", "\n", "n_labels", "=", "None", ",", "\n", "default", "=", "0.9", ",", "\n", ")", ":", "\n", "    ", "thresholds", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "granularity", ")", "\n", "values", "=", "[", "]", "\n", "for", "t", "in", "thresholds", ":", "\n", "        ", "preds", "=", "apply_individual_threshold", "(", "output", ",", "thresholds", "=", "[", "t", "]", "*", "output", ".", "shape", "[", "1", "]", ")", "\n", "values", ".", "append", "(", "indv_metric", "(", "labels", ",", "preds", ",", "n_labels", "=", "n_labels", ")", ")", "\n", "\n", "", "best_metric_id", "=", "np", ".", "argmax", "(", "values", ",", "0", ")", "\n", "best_threshold", "=", "thresholds", "[", "best_metric_id", "]", "\n", "\n", "# Fill the thresholds of unseen arguments with default=.5", "\n", "if", "n_labels", "is", "not", "None", ":", "\n", "        ", "for", "i", "in", "range", "(", "n_labels", ")", ":", "\n", "            ", "if", "i", "not", "in", "np", ".", "unique", "(", "labels", ")", ":", "\n", "                ", "best_threshold", "[", "i", "]", "=", "default", "\n", "\n", "", "", "", "return", "best_threshold", ",", "metric", "(", "labels", ",", "apply_individual_threshold", "(", "output", ",", "thresholds", "=", "best_threshold", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.apply_multi_label_threshold": [[95, 97], ["enumerate"], "function", ["None"], ["", "def", "apply_multi_label_threshold", "(", "output", ",", "threshold", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "[", "[", "i", "for", "i", ",", "coef", "in", "enumerate", "(", "row", ")", "if", "coef", ">=", "threshold", "]", "for", "row", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.utils.multi_label_metrics": [[99, 111], ["zip", "sum", "len", "len"], "function", ["None"], ["", "def", "multi_label_metrics", "(", "y_true", ":", "List", "[", "int", "]", ",", "y_pred", ":", "List", "[", "int", "]", ",", "**", "kwargs", ")", ":", "\n", "    ", "tp", ",", "total_t", ",", "total_p", "=", "0", ",", "0", ",", "0", "\n", "for", "y_t", ",", "y_p", "in", "zip", "(", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "tp", "+=", "sum", "(", "[", "p", "in", "y_t", "for", "p", "in", "y_p", "]", ")", "\n", "total_t", "+=", "len", "(", "y_t", ")", "\n", "total_p", "+=", "len", "(", "y_p", ")", "\n", "\n", "", "precision", "=", "tp", "/", "total_p", "if", "total_p", ">", "0", "else", "0.0", "\n", "recall", "=", "tp", "/", "total_t", "if", "total_t", ">", "0", "else", "0.0", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "if", "precision", "+", "recall", ">", "0", "else", "0.0", "\n", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.evaluation.main": [[66, 153], ["os.makedirs", "task_class.from_config", "hasattr", "hasattr", "open", "types.SimpleNamespace", "hasattr", "hasattr", "dataset_class", "dataset_class", "a2t.base.EntailmentClassifier", "a2t.base.EntailmentClassifier.clear_gpu_memory", "torch.cuda.empty_cache", "a2t.base.EntailmentClassifier.", "os.makedirs", "numpy.save", "numpy.save", "task_class.from_config.compute_metrics", "a2t.base.EntailmentClassifier.", "os.makedirs", "numpy.save", "numpy.save", "task_class.from_config.compute_metrics", "json.load", "vars", "open", "json.dump", "open", "json.dump", "vars", "vars"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.from_config", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.a2t.base.Classifier.clear_gpu_memory", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.BinaryTask.compute_metrics", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.BinaryTask.compute_metrics"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "with", "open", "(", "args", ".", "config", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "config", "=", "SimpleNamespace", "(", "**", "json", ".", "load", "(", "f", ")", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "f\"experiments/{config.name}\"", ",", "exist_ok", "=", "True", ")", "\n", "\n", "task_class", ",", "_", "=", "PREDEFINED_TASKS", "[", "config", ".", "task_name", "]", "\n", "task", "=", "task_class", ".", "from_config", "(", "args", ".", "config", ")", "# (**vars(config))", "\n", "\n", "dataset_class", "=", "PREDEFINED_DATASETS", "[", "config", ".", "dataset", "]", "\n", "\n", "assert", "hasattr", "(", "config", ",", "\"dev_path\"", ")", "or", "hasattr", "(", "config", ",", "\"test_path\"", ")", ",", "\"At least a test or dev path must be provided.\"", "\n", "\n", "# Run dev evaluation", "\n", "if", "hasattr", "(", "config", ",", "\"dev_path\"", ")", ":", "\n", "        ", "dev_dataset", "=", "dataset_class", "(", "config", ".", "dev_path", ",", "task", ".", "labels", ")", "\n", "", "else", ":", "\n", "        ", "dev_dataset", "=", "None", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"test_path\"", ")", ":", "\n", "        ", "test_dataset", "=", "dataset_class", "(", "config", ".", "test_path", ",", "task", ".", "labels", ")", "\n", "", "else", ":", "\n", "        ", "test_dataset", "=", "None", "\n", "\n", "", "results", "=", "{", "}", "\n", "for", "pretrained_model", "in", "config", ".", "nli_models", ":", "\n", "\n", "        ", "nlp", "=", "EntailmentClassifier", "(", "pretrained_model", ",", "**", "vars", "(", "config", ")", ")", "\n", "\n", "results", "[", "pretrained_model", "]", "=", "{", "}", "\n", "\n", "if", "dev_dataset", ":", "\n", "            ", "_", ",", "output", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "dev_dataset", ",", "negative_threshold", "=", "0.0", ",", "return_raw_output", "=", "True", ",", "**", "vars", "(", "config", ")", ")", "\n", "\n", "dev_labels", "=", "dev_dataset", ".", "labels", "\n", "\n", "# Save the output", "\n", "os", ".", "makedirs", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/dev\"", ",", "\n", "exist_ok", "=", "True", ",", "\n", ")", "\n", "np", ".", "save", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/dev/output.npy\"", ",", "\n", "output", ",", "\n", ")", "\n", "np", ".", "save", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/dev/labels.npy\"", ",", "\n", "dev_labels", ",", "\n", ")", "\n", "\n", "# If dev data then optimize the threshold on it", "\n", "dev_results", "=", "task", ".", "compute_metrics", "(", "dev_labels", ",", "output", ",", "threshold", "=", "\"optimize\"", ")", "\n", "results", "[", "pretrained_model", "]", "[", "\"dev\"", "]", "=", "dev_results", "\n", "\n", "with", "open", "(", "f\"experiments/{config.name}/results.json\"", ",", "\"wt\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "if", "test_dataset", ":", "\n", "            ", "_", ",", "output", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "test_dataset", ",", "negative_threshold", "=", "0.0", ",", "return_raw_output", "=", "True", ",", "**", "vars", "(", "config", ")", ")", "\n", "\n", "test_labels", "=", "test_dataset", ".", "labels", "\n", "\n", "# Save the output", "\n", "os", ".", "makedirs", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/test\"", ",", "\n", "exist_ok", "=", "True", ",", "\n", ")", "\n", "np", ".", "save", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/test/output.npy\"", ",", "\n", "output", ",", "\n", ")", "\n", "np", ".", "save", "(", "\n", "f\"experiments/{config.name}/{pretrained_model}/test/labels.npy\"", ",", "\n", "test_labels", ",", "\n", ")", "\n", "\n", "optimal_threshold", "=", "0.5", "if", "not", "dev_dataset", "else", "dev_results", "[", "\"optimal_threshold\"", "]", "\n", "test_results", "=", "task", ".", "compute_metrics", "(", "test_labels", ",", "output", ",", "threshold", "=", "optimal_threshold", ")", "\n", "results", "[", "pretrained_model", "]", "[", "\"test\"", "]", "=", "test_results", "\n", "\n", "with", "open", "(", "f\"experiments/{config.name}/results.json\"", ",", "\"wt\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "nlp", ".", "clear_gpu_memory", "(", ")", "\n", "del", "nlp", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.TopicClassifier.__init__": [[14, 35], ["object.__init__", "torch.device", "base.TopicClassifier.model.to", "base.TopicClassifier.model.eval", "open", "base.TopicClassifier._initialize", "base.TopicClassifier._initialize", "torch.cuda.is_available", "base.TopicClassifier.model.half", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._initialize", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._initialize"], ["_use_tqdm", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "_use_tqdm", "=", "False", "\n", "\n", "", "from", "transformers", "import", "AutoConfig", ",", "AutoTokenizer", ",", "AutoModelForSequenceClassification", "\n", "\n", "from", ".", "tasks", "import", "Features", ",", "Task", "\n", "\n", "try", ":", "\n", "    ", "import", "transformers", "\n", "\n", "transformers", ".", "logging", ".", "set_verbosity_error", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "    ", "pass", "\n", "\n", "\n", "", "def", "np_softmax", "(", "x", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "e", "=", "np", ".", "exp", "(", "x", ")", "\n", "return", "e", "/", "np", ".", "sum", "(", "e", ",", "axis", "=", "dim", ",", "keepdims", "=", "True", ")", "\n", "\n", "\n", "", "def", "np_sigmoid", "(", "x", ",", "dim", "=", "-", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.TopicClassifier._initialize": [[36, 38], ["None"], "methods", ["None"], ["    ", "return", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "x", ")", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.TopicClassifier.__call__": [[39, 41], ["None"], "methods", ["None"], ["", "class", "Classifier", "(", "object", ")", ":", "\n", "    ", "\"\"\"Abstact classifier class.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax": [[8, 11], ["numpy.exp", "numpy.sum"], "function", ["None"], ["import", "numpy", "as", "np", "\n", "import", "torch", "\n", "\n", "try", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli._NLITopicClassifier.__init__": [[15, 41], ["a2t.base.Classifier.__init__", "numpy.vectorize"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "use_cuda", "=", "True", ",", "\n", "query_phrase", "=", "\"The domain of the sentence is about\"", ",", "\n", "entailment_position", "=", "2", ",", "\n", "half", "=", "False", ",", "\n", "verbose", "=", "True", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels", ",", "\n", "pretrained_model", "=", "pretrained_model", ",", "\n", "use_cuda", "=", "use_cuda", ",", "\n", "verbose", "=", "verbose", ",", "\n", "half", "=", "half", ",", "\n", ")", "\n", "self", ".", "query_phrase", "=", "query_phrase", "\n", "self", ".", "ent_pos", "=", "entailment_position", "\n", "\n", "def", "idx2topic", "(", "idx", ")", ":", "\n", "            ", "return", "self", ".", "labels", "[", "idx", "]", "\n", "\n", "", "self", ".", "idx2topic", "=", "np", ".", "vectorize", "(", "idx2topic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli._NLITopicClassifier._initialize": [[42, 45], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained"], "methods", ["None"], ["", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli._NLITopicClassifier._run_batch": [[46, 54], ["torch.no_grad", "mnli._NLITopicClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "[].view", "output.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "torch.tensor", "len", "output.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "mnli._NLITopicClassifier.model", "output.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["None"], ["", "def", "_run_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch", ",", "padding", "=", "True", ")", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", "[", "\"input_ids\"", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "output", "=", "self", ".", "model", "(", "input_ids", ")", "[", "0", "]", "[", ":", ",", "self", ".", "ent_pos", "]", ".", "view", "(", "input_ids", ".", "shape", "[", "0", "]", "//", "len", "(", "self", ".", "labels", ")", ",", "-", "1", ")", "\n", "output", "=", "output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli._NLITopicClassifier.__call__": [[55, 76], ["tqdm.tqdm.tqdm", "numpy.vstack", "isinstance", "enumerate", "batch.extend", "len", "mnli._NLITopicClassifier._run_batch", "numpy.vstack.append", "len", "mnli._NLITopicClassifier._run_batch", "numpy.vstack.append"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch"], ["", "def", "__call__", "(", "self", ",", "contexts", ":", "List", "[", "str", "]", ",", "batch_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "contexts", ",", "list", ")", ":", "\n", "            ", "contexts", "=", "[", "contexts", "]", "\n", "\n", "", "batch", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "context", "in", "tqdm", "(", "enumerate", "(", "contexts", ")", ",", "total", "=", "len", "(", "contexts", ")", ")", ":", "\n", "            ", "sentences", "=", "[", "f\"{context} {self.tokenizer.sep_token} {self.query_phrase} {topic}.\"", "for", "topic", "in", "self", ".", "labels", "]", "\n", "batch", ".", "extend", "(", "sentences", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "batch_size", "==", "0", ":", "\n", "                ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "batch", "=", "[", "]", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli._NLITopicClassifier.predict": [[77, 101], ["mnli._NLITopicClassifier.", "mnli._NLITopicClassifier.idx2topic", "numpy.stack().tolist", "topics.tolist.tolist.tolist", "numpy.argsort", "numpy.stack", "int", "float", "float", "numpy.sort"], "methods", ["None"], ["", "def", "predict", "(", "\n", "self", ",", "\n", "contexts", ":", "List", "[", "str", "]", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "return_labels", ":", "bool", "=", "True", ",", "\n", "return_confidences", ":", "bool", "=", "False", ",", "\n", "topk", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "output", "=", "self", "(", "contexts", ",", "batch_size", ")", "\n", "topics", "=", "np", ".", "argsort", "(", "output", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "[", ":", ",", ":", "topk", "]", "\n", "if", "return_labels", ":", "\n", "            ", "topics", "=", "self", ".", "idx2topic", "(", "topics", ")", "\n", "", "if", "return_confidences", ":", "\n", "            ", "topics", "=", "np", ".", "stack", "(", "(", "topics", ",", "np", ".", "sort", "(", "output", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "[", ":", ",", ":", "topk", "]", ")", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "topics", "=", "[", "\n", "[", "(", "int", "(", "label", ")", ",", "float", "(", "conf", ")", ")", "if", "not", "return_labels", "else", "(", "label", ",", "float", "(", "conf", ")", ")", "for", "label", ",", "conf", "in", "row", "]", "\n", "for", "row", "in", "topics", "\n", "]", "\n", "", "else", ":", "\n", "            ", "topics", "=", "topics", ".", "tolist", "(", ")", "\n", "", "if", "topk", "==", "1", ":", "\n", "            ", "topics", "=", "[", "row", "[", "0", "]", "for", "row", "in", "topics", "]", "\n", "\n", "", "return", "topics", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli.NLITopicClassifier.__init__": [[132, 140], ["mnli._NLITopicClassifier.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", "NLITopicClassifier", ",", "self", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "pretrained_model", "=", "pretrained_model", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli.NLITopicClassifier.__call__": [[141, 146], ["mnli._NLITopicClassifier.__call__", "a2t.base.np_softmax"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__call__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax"], ["", "def", "__call__", "(", "self", ",", "contexts", ":", "List", "[", "str", "]", ",", "batch_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "outputs", "=", "super", "(", ")", ".", "__call__", "(", "contexts", "=", "contexts", ",", "batch_size", "=", "batch_size", ")", "\n", "outputs", "=", "np_softmax", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli.NLITopicClassifierWithMappingHead.__init__": [[149, 170], ["list", "collections.defaultdict", "topic_mapping.items", "mnli._NLITopicClassifier.__init__", "numpy.vectorize", "topic_mapping.keys", "mnli.NLITopicClassifierWithMappingHead.mapping[].append", "enumerate"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "topic_mapping", ":", "Dict", "[", "str", ",", "str", "]", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "new_topics", "=", "list", "(", "topic_mapping", ".", "keys", "(", ")", ")", "\n", "self", ".", "target_topics", "=", "labels", "\n", "self", ".", "new_topics2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "new_topics", ")", "}", "\n", "self", ".", "mapping", "=", "defaultdict", "(", "list", ")", "\n", "for", "key", ",", "value", "in", "topic_mapping", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "mapping", "[", "value", "]", ".", "append", "(", "self", ".", "new_topics2id", "[", "key", "]", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "self", ".", "new_topics", ",", "*", "args", ",", "pretrained_model", "=", "pretrained_model", ",", "**", "kwargs", ")", "\n", "\n", "def", "idx2topic", "(", "idx", ")", ":", "\n", "            ", "return", "self", ".", "target_topics", "[", "idx", "]", "\n", "\n", "", "self", ".", "idx2topic", "=", "np", ".", "vectorize", "(", "idx2topic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mnli.NLITopicClassifierWithMappingHead.__call__": [[171, 177], ["mnli._NLITopicClassifier.__call__", "numpy.hstack", "a2t.base.np_softmax", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__call__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax"], ["", "def", "__call__", "(", "self", ",", "contexts", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "outputs", "=", "super", "(", ")", ".", "__call__", "(", "contexts", ",", "batch_size", ")", "\n", "outputs", "=", "np", ".", "hstack", "(", "[", "np", ".", "max", "(", "outputs", "[", ":", ",", "self", ".", "mapping", "[", "topic", "]", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "for", "topic", "in", "self", ".", "target_topics", "]", ")", "\n", "outputs", "=", "np_softmax", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.babeldomains.BabelDomainsClassifier.__init__": [[136, 144], ["NLITopicClassifierWithMappingHead.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BabelDomainsClassifier", ",", "self", ")", ".", "__init__", "(", "\n", "pretrained_model", "=", "\"roberta-large-mnli\"", ",", "\n", "labels", "=", "BABELDOMAINS_TOPICS", ",", "\n", "topic_mapping", "=", "BABELDOMAINS_TOPIC_MAPPING", ",", "\n", "query_phrase", "=", "\"The domain of the sentence is about\"", ",", "\n", "entailment_position", "=", "2", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mlm.MLMTopicClassifier.__init__": [[14, 34], ["a2t.base.Classifier.__init__", "torch.tensor().to", "len", "mlm.MLMTopicClassifier.tokenizer.encode", "torch.tensor", "mlm.MLMTopicClassifier.tokenizer.encode"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large\"", ",", "\n", "use_cuda", "=", "True", ",", "\n", "half", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels", ",", "\n", "pretrained_model", ",", "\n", "use_cuda", "=", "use_cuda", ",", "\n", "half", "=", "half", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "self", ".", "topics2mask", "=", "{", "topic", ":", "len", "(", "self", ".", "tokenizer", ".", "encode", "(", "topic", ",", "add_special_tokens", "=", "False", ")", ")", "for", "topic", "in", "labels", "}", "\n", "self", ".", "topics2id", "=", "torch", ".", "tensor", "(", "[", "self", ".", "tokenizer", ".", "encode", "(", "topic", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "for", "topic", "in", "labels", "]", ")", ".", "to", "(", "\n", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mlm.MLMTopicClassifier._initialize": [[36, 39], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelWithLMHead.from_pretrained"], "methods", ["None"], ["", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mlm.MLMTopicClassifier._run_batch": [[40, 56], ["torch.no_grad", "mlm.MLMTopicClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "torch.tensor().to", "outputs.view.view.view", "torch.arange().to", "torch.softmax().detach().cpu().numpy", "mlm.MLMTopicClassifier.model", "torch.tensor", "torch.tensor", "torch.arange", "torch.softmax().detach().cpu", "len", "len", "[].item", "torch.softmax().detach", "range", "len", "torch.softmax"], "methods", ["None"], ["", "def", "_run_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch", ",", "padding", "=", "True", ")", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", "[", "\"input_ids\"", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "masked_index", "=", "torch", ".", "tensor", "(", "\n", "[", "(", "input_ids", "[", "i", "]", "==", "self", ".", "tokenizer", ".", "mask_token_id", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "[", "0", "]", ".", "item", "(", ")", "for", "i", "in", "range", "(", "len", "(", "batch", ")", ")", "]", "\n", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "new_shape", "=", "(", "len", "(", "batch", ")", "//", "len", "(", "self", ".", "labels", ")", ",", "-", "1", ")", "+", "outputs", ".", "shape", "[", "-", "2", ":", "]", "\n", "outputs", "=", "outputs", ".", "view", "(", "new_shape", ")", "\n", "ind_1", "=", "torch", ".", "arange", "(", "outputs", ".", "shape", "[", "1", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "outputs", "=", "outputs", "[", ":", ",", "ind_1", ",", "masked_index", ",", "self", ".", "topics2id", "]", "\n", "output", "=", "torch", ".", "softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.mlm.MLMTopicClassifier.__call__": [[57, 84], ["tqdm.tqdm.tqdm", "numpy.vstack", "isinstance", "enumerate", "batch.extend", "len", "mlm.MLMTopicClassifier._run_batch", "numpy.vstack.append", "len", "mlm.MLMTopicClassifier._run_batch", "numpy.vstack.append", "context.replace"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch"], ["", "def", "__call__", "(", "self", ",", "contexts", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "contexts", ",", "list", ")", ":", "\n", "            ", "contexts", "=", "[", "contexts", "]", "\n", "# Use just batch_size 1", "\n", "", "batch_size", "=", "1", "\n", "\n", "batch", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "context", "in", "tqdm", "(", "enumerate", "(", "contexts", ")", ",", "total", "=", "len", "(", "contexts", ")", ")", ":", "\n", "            ", "sentences", "=", "[", "\n", "f\"Context: {context.replace(':', ' ')} Topic: {' '.join([self.tokenizer.mask_token] * self.topics2mask[topic])} \"", "\n", "for", "topic", "in", "self", ".", "labels", "\n", "]", "\n", "\n", "batch", ".", "extend", "(", "sentences", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "batch_size", "==", "0", ":", "\n", "                ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "batch", "=", "[", "]", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.EarlyStopping.__init__": [[40, 51], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "self", ",", "patience", "=", "3", ",", "delta", "=", "0.0", ",", "save_checkpoint_fn", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "delta", "=", "delta", "\n", "self", ".", "save_checkpoint_fn", "=", "save_checkpoint_fn", "\n", "\n", "self", ".", "best_loss", "=", "np", ".", "inf", "\n", "self", ".", "best_epoch", "=", "-", "1", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "epoch", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.EarlyStopping.__call__": [[52, 66], ["finetune_classifier.EarlyStopping.save_checkpoint_fn"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "val_loss", ":", "float", ",", "*", "args", ",", "**", "kwargs", ")", "->", "bool", ":", "\n", "        ", "self", ".", "epoch", "+=", "1", "\n", "diff", "=", "(", "self", ".", "best_loss", "+", "self", ".", "delta", ")", "-", "val_loss", "\n", "if", "diff", ">", "0", ":", "\n", "            ", "self", ".", "steps", "=", "self", ".", "patience", "\n", "if", "diff", ">", "self", ".", "delta", ":", "\n", "                ", "self", ".", "best_epoch", "=", "self", ".", "epoch", "\n", "self", ".", "best_loss", "=", "val_loss", "\n", "if", "self", ".", "save_checkpoint_fn", ":", "\n", "                    ", "self", ".", "save_checkpoint_fn", "(", "*", "args", ",", "val_loss", "=", "self", ".", "best_loss", ",", "**", "kwargs", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "steps", "-=", "1", "\n", "\n", "", "return", "self", ".", "steps", "<=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.EarlyStopping.get_best_epoch": [[67, 69], ["None"], "methods", ["None"], ["", "def", "get_best_epoch", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "best_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.parse_args": [[71, 82], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "\"finetune_classifier\"", ",", "\n", "usage", "=", "\"finetune_classifier train_data eval_data --config config.json\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--config\"", ",", "type", "=", "str", ",", "dest", "=", "\"config\"", ",", "help", "=", "\"Training configuration\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.train": [[84, 267], ["os.makedirs", "transformers.AutoTokenizer.from_pretrained", "AutoTokenizer.from_pretrained.save_pretrained", "transformers.AutoConfig.from_pretrained", "len", "transformers.AutoModelForSequenceClassification.from_pretrained", "AutoTokenizer.from_pretrained.", "AutoTokenizer.from_pretrained.", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.optim.AdamW", "AutoModelForSequenceClassification.from_pretrained.cuda", "finetune_classifier.EarlyStopping", "range", "open", "json.load", "open", "gzip.open", "open", "gzip.open", "str", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "list", "finetune_classifier.train.get_parameters"], "function", ["None"], ["", "def", "train", "(", "opt", ")", ":", "\n", "\n", "# Load the configuration", "\n", "    ", "with", "open", "(", "opt", ".", "config", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "config", "[", "\"output_path\"", "]", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Load the topics/labels", "\n", "with", "open", "(", "config", "[", "\"topics\"", "]", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "topics", "=", "[", "topic", ".", "rstrip", "(", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "topic", "in", "f", "]", "\n", "topic2id", "=", "{", "topic", ":", "i", "for", "i", ",", "topic", "in", "enumerate", "(", "topics", ")", "}", "\n", "\n", "# Load the sinset-->gloss mapping", "\n", "", "glosses", "=", "{", "}", "\n", "with", "gzip", ".", "open", "(", "config", "[", "\"glosses\"", "]", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "row", "=", "line", ".", "split", "(", ")", "\n", "idx", ",", "gloss", "=", "row", "[", "0", "]", ",", "\" \"", ".", "join", "(", "row", "[", "1", ":", "]", ")", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "glosses", "[", "idx", "]", "=", "gloss", "\n", "\n", "# Load train and eval data", "\n", "", "", "train_data", ",", "train_labels", ",", "eval_data", ",", "eval_labels", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "config", "[", "\"eval_data\"", "]", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "idx", ",", "label", ",", "_", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "eval_data", ".", "append", "(", "idx", ")", "\n", "eval_labels", ".", "append", "(", "topic2id", "[", "label", "]", ")", "\n", "\n", "", "", "with", "gzip", ".", "open", "(", "config", "[", "\"train_data\"", "]", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "row", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "row", "[", "0", "]", "in", "glosses", "and", "float", "(", "row", "[", "-", "1", "]", ")", ">", "config", "[", "\"minimum_confidence\"", "]", "and", "row", "[", "0", "]", "not", "in", "eval_data", ":", "\n", "                ", "train_data", ".", "append", "(", "row", "[", "0", "]", ")", "\n", "train_labels", ".", "append", "(", "topic2id", "[", "row", "[", "1", "]", "]", ")", "\n", "\n", "# Convert train and eval data to glosses", "\n", "", "", "", "train_glosses", "=", "[", "glosses", "[", "instance", "]", "for", "instance", "in", "train_data", "]", "\n", "eval_glosses", "=", "[", "glosses", "[", "instance", "]", "for", "instance", "in", "eval_data", "]", "\n", "\n", "# Define the model and tokenizer", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "config", "[", "\"pretrained_model\"", "]", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "config", "[", "\"output_path\"", "]", ")", "\n", "cfg", "=", "AutoConfig", ".", "from_pretrained", "(", "config", "[", "\"pretrained_model\"", "]", ")", "\n", "cfg", ".", "num_labels", "=", "len", "(", "topics", ")", "\n", "cfg", ".", "label2id", "=", "topic2id", "\n", "cfg", ".", "id2label", "=", "{", "str", "(", "idx", ")", ":", "label", "for", "label", ",", "idx", "in", "topic2id", ".", "items", "(", ")", "}", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "config", "[", "\"pretrained_model\"", "]", ",", "config", "=", "cfg", ")", "\n", "\n", "# Prepare data for training", "\n", "train_dataset", "=", "tokenizer", "(", "\n", "train_glosses", ",", "\n", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "config", "[", "\"max_length\"", "]", ",", "\n", ")", "\n", "eval_dataset", "=", "tokenizer", "(", "\n", "eval_glosses", ",", "\n", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "config", "[", "\"max_length\"", "]", ",", "\n", ")", "\n", "\n", "train_dataset", "=", "TensorDataset", "(", "\n", "torch", ".", "tensor", "(", "train_dataset", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "train_dataset", "[", "\"attention_mask\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "train_labels", ")", ",", "\n", ")", "\n", "eval_dataset", "=", "TensorDataset", "(", "\n", "torch", ".", "tensor", "(", "eval_dataset", "[", "\"input_ids\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "eval_dataset", "[", "\"attention_mask\"", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "eval_labels", ")", ",", "\n", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "config", "[", "\"batch_size\"", "]", ",", "shuffle", "=", "True", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "batch_size", "=", "config", "[", "\"eval_batch_size\"", "]", ")", "\n", "\n", "def", "get_parameters", "(", "model", ",", "freeze", "=", "False", ")", ":", "\n", "        ", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "if", "freeze", ":", "\n", "            ", "for", "n", ",", "p", "in", "param_optimizer", ":", "\n", "                ", "if", "\"classifier\"", "not", "in", "n", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.01", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "", "optimizer", "=", "AdamW", "(", "get_parameters", "(", "model", ",", "config", "[", "\"freeze\"", "]", ")", ",", "lr", "=", "config", "[", "\"learning_rate\"", "]", ")", "\n", "\n", "model", ".", "cuda", "(", ")", "\n", "if", "config", "[", "\"half\"", "]", ":", "\n", "        ", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "\"O2\"", ",", "keep_batchnorm_fp32", "=", "True", ")", "\n", "\n", "", "def", "save_checkpoint_fn", "(", "model", ",", "output_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "model", ".", "save_pretrained", "(", "output_path", ")", "\n", "\n", "", "config", "[", "\"training_log\"", "]", "=", "{", "}", "\n", "\n", "early_stopping", "=", "EarlyStopping", "(", "patience", "=", "config", "[", "\"patience\"", "]", ",", "save_checkpoint_fn", "=", "save_checkpoint_fn", ")", "\n", "for", "epoch", "in", "range", "(", "config", "[", "\"epochs\"", "]", ")", ":", "\n", "        ", "config", "[", "\"training_log\"", "]", "[", "f\"epoch_{epoch}\"", "]", "=", "{", "}", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", ",", "accuracy", "=", "0.0", ",", "0.0", "\n", "correct", ",", "total", "=", "0", ",", "0", "\n", "progress", "=", "tqdm", "(", "\n", "enumerate", "(", "train_dataloader", ")", ",", "\n", "desc", "=", "f\"Epoch: {epoch} - Loss: {total_loss} - Accuracy: {accuracy}\"", ",", "\n", "total", "=", "len", "(", "train_dataset", ")", "//", "config", "[", "\"batch_size\"", "]", ",", "\n", ")", "\n", "for", "i", ",", "batch", "in", "progress", ":", "\n", "# Batch to cuda", "\n", "            ", "input_ids", ",", "attention_mask", ",", "labels", "=", "batch", "\n", "\n", "loss", ",", "logits", "=", "model", "(", "\n", "input_ids", "=", "input_ids", ".", "cuda", "(", ")", ",", "\n", "attention_mask", "=", "attention_mask", ".", "cuda", "(", ")", ",", "\n", "labels", "=", "labels", ".", "cuda", "(", ")", ",", "\n", ")", "\n", "\n", "if", "config", "[", "\"half\"", "]", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scale_loss", ":", "\n", "                    ", "scale_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "sum", "(", "np", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "-", "1", ")", "==", "labels", ".", "numpy", "(", ")", ")", "\n", "total", "+=", "input_ids", ".", "shape", "[", "0", "]", "\n", "accuracy", "=", "correct", "/", "total", "\n", "\n", "progress", ".", "set_description", "(", "f\"Epoch: {epoch} - Loss: {total_loss/(i+1):.3f} - Accuracy: {accuracy:.3f}\"", ")", "\n", "\n", "", "config", "[", "\"training_log\"", "]", "[", "f\"epoch_{epoch}\"", "]", "[", "\"train_loss\"", "]", "=", "total_loss", "/", "(", "i", "+", "1", ")", "\n", "config", "[", "\"training_log\"", "]", "[", "f\"epoch_{epoch}\"", "]", "[", "\"train_accuracy\"", "]", "=", "correct", "/", "total", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "total_loss", ",", "accuracy", "=", "0.0", ",", "0.0", "\n", "correct", ",", "total", "=", "0", ",", "0", "\n", "progress", "=", "tqdm", "(", "\n", "enumerate", "(", "eval_dataloader", ")", ",", "\n", "desc", "=", "f\"Epoch: {epoch} - Loss: {total_loss} - Accuracy: {accuracy}\"", ",", "\n", "total", "=", "len", "(", "eval_dataset", ")", "//", "config", "[", "\"eval_batch_size\"", "]", ",", "\n", ")", "\n", "for", "i", ",", "batch", "in", "progress", ":", "\n", "# Batch to cuda", "\n", "                ", "input_ids", ",", "attention_mask", ",", "labels", "=", "batch", "\n", "\n", "loss", ",", "logits", "=", "model", "(", "\n", "input_ids", "=", "input_ids", ".", "cuda", "(", ")", ",", "\n", "attention_mask", "=", "attention_mask", ".", "cuda", "(", ")", ",", "\n", "labels", "=", "labels", ".", "cuda", "(", ")", ",", "\n", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "sum", "(", "np", ".", "argmax", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "-", "1", ")", "==", "labels", ".", "numpy", "(", ")", ")", "\n", "total", "+=", "input_ids", ".", "shape", "[", "0", "]", "\n", "accuracy", "=", "correct", "/", "total", "\n", "\n", "progress", ".", "set_description", "(", "f\"Epoch: {epoch} - Loss: {total_loss/(i+1):.3f} - Accuracy: {accuracy:.3f}\"", ")", "\n", "\n", "", "", "config", "[", "\"training_log\"", "]", "[", "f\"epoch_{epoch}\"", "]", "[", "\"eval_loss\"", "]", "=", "total_loss", "/", "(", "i", "+", "1", ")", "\n", "config", "[", "\"training_log\"", "]", "[", "f\"epoch_{epoch}\"", "]", "[", "\"eval_accuracy\"", "]", "=", "correct", "/", "total", "\n", "\n", "if", "early_stopping", "(", "total_loss", "/", "(", "i", "+", "1", ")", ",", "model", ",", "output_path", "=", "config", "[", "\"output_path\"", "]", ")", ":", "\n", "            ", "break", "\n", "\n", "# Save the new config file", "\n", "", "", "with", "open", "(", "opt", ".", "config", ",", "\"wt\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "config", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.run_evaluation.top_k_accuracy": [[24, 27], ["sum", "len", "numpy.argsort", "zip"], "function", ["None"], ["def", "top_k_accuracy", "(", "output", ",", "labels", ",", "k", "=", "5", ")", ":", "\n", "    ", "preds", "=", "np", ".", "argsort", "(", "output", ")", "[", ":", ",", ":", ":", "-", "1", "]", "[", ":", ",", ":", "k", "]", "\n", "return", "sum", "(", "l", "in", "p", "for", "l", ",", "p", "in", "zip", "(", "labels", ",", "preds", ")", ")", "/", "len", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.wndomains.WNDomainsClassifier.__init__": [[226, 234], ["NLITopicClassifierWithMappingHead.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "WNDomainsClassifier", ",", "self", ")", ".", "__init__", "(", "\n", "pretrained_model", "=", "\"roberta-large-mnli\"", ",", "\n", "labels", "=", "WNDOMAINS_TOPICS", ",", "\n", "topic_mapping", "=", "WNDOMAINS_TOPIC_MAPPING", ",", "\n", "query_phrase", "=", "\"The domain of the sentence is about\"", ",", "\n", "entailment_position", "=", "2", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.nsp.NSPTopicClassifier.__init__": [[14, 35], ["a2t.base.Classifier.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "pretrained_model", ":", "str", "=", "\"bert-large-uncased\"", ",", "\n", "use_cuda", "=", "True", ",", "\n", "query_phrase", "=", "\"Topic or domain about\"", ",", "\n", "positive_position", "=", "1", ",", "\n", "half", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "labels", ",", "\n", "pretrained_model", ",", "\n", "use_cuda", "=", "use_cuda", ",", "\n", "half", "=", "half", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "self", ".", "query_phrase", "=", "query_phrase", "\n", "self", ".", "cls_pos", "=", "positive_position", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.nsp.NSPTopicClassifier._initialize": [[36, 39], ["transformers.AutoTokenizer.from_pretrained", "transformers.BertForNextSentencePrediction.from_pretrained"], "methods", ["None"], ["", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ",", "use_fast", "=", "True", ")", "\n", "self", ".", "model", "=", "BertForNextSentencePrediction", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.nsp.NSPTopicClassifier._run_batch": [[40, 48], ["torch.no_grad", "nsp.NSPTopicClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "[].view", "torch.softmax().detach().cpu().numpy", "torch.tensor", "len", "len", "torch.softmax().detach().cpu", "nsp.NSPTopicClassifier.model", "torch.softmax().detach", "torch.softmax"], "methods", ["None"], ["", "def", "_run_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch", ",", "padding", "=", "True", ")", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", "[", "\"input_ids\"", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "output", "=", "self", ".", "model", "(", "input_ids", ")", "[", "0", "]", "[", ":", ",", "self", ".", "cls_pos", "]", ".", "view", "(", "len", "(", "batch", ")", "//", "len", "(", "self", ".", "labels", ")", ",", "-", "1", ")", "\n", "output", "=", "torch", ".", "softmax", "(", "output", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.nsp.NSPTopicClassifier.__call__": [[49, 70], ["tqdm.tqdm.tqdm", "numpy.vstack", "isinstance", "enumerate", "batch.extend", "len", "nsp.NSPTopicClassifier._run_batch", "numpy.vstack.append", "len", "nsp.NSPTopicClassifier._run_batch", "numpy.vstack.append"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch"], ["", "def", "__call__", "(", "self", ",", "contexts", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "contexts", ",", "list", ")", ":", "\n", "            ", "contexts", "=", "[", "contexts", "]", "\n", "\n", "", "batch", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "context", "in", "tqdm", "(", "enumerate", "(", "contexts", ")", ",", "total", "=", "len", "(", "contexts", ")", ")", ":", "\n", "            ", "sentences", "=", "[", "f'{context} {self.tokenizer.sep_token} {self.query_phrase} \"{topic}\".'", "for", "topic", "in", "self", ".", "labels", "]", "\n", "batch", ".", "extend", "(", "sentences", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "batch_size", "==", "0", ":", "\n", "                ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "batch", "=", "[", "]", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier.__init__": [[29, 79], ["a2t.base.Classifier.__init__", "len", "numpy.vectorize", "len", "valid_conditions.items", "enumerate", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["pretrained_model", "=", "pretrained_model", ",", "\n", "use_cuda", "=", "use_cuda", ",", "\n", "verbose", "=", "verbose", ",", "\n", "half", "=", "half", ",", "\n", ")", "\n", "self", ".", "query_phrase", "=", "query_phrase", "\n", "self", ".", "ent_pos", "=", "entailment_position", "\n", "\n", "def", "idx2topic", "(", "idx", ")", ":", "\n", "            ", "return", "self", ".", "labels", "[", "idx", "]", "\n", "\n", "", "self", ".", "idx2topic", "=", "np", ".", "vectorize", "(", "idx2topic", ")", "\n", "\n", "", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "\n", "", "def", "_run_batch", "(", "self", ",", "batch", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_ids", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "batch", ",", "padding", "=", "True", ")", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", "[", "\"input_ids\"", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "output", "=", "self", ".", "model", "(", "input_ids", ")", "[", "0", "]", "[", ":", ",", "self", ".", "ent_pos", "]", ".", "view", "(", "input_ids", ".", "shape", "[", "0", "]", "//", "len", "(", "self", ".", "labels", ")", ",", "-", "1", ")", "\n", "output", "=", "output", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "output", "\n", "\n", "", "def", "__call__", "(", "self", ",", "contexts", ":", "List", "[", "str", "]", ",", "batch_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "contexts", ",", "list", ")", ":", "\n", "            ", "contexts", "=", "[", "contexts", "]", "\n", "\n", "", "batch", ",", "outputs", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "context", "in", "tqdm", "(", "enumerate", "(", "contexts", ")", ",", "total", "=", "len", "(", "contexts", ")", ")", ":", "\n", "            ", "sentences", "=", "[", "f\"{context} {self.tokenizer.sep_token} {self.query_phrase} {topic}.\"", "for", "topic", "in", "self", ".", "labels", "]", "\n", "batch", ".", "extend", "(", "sentences", ")", "\n", "\n", "if", "(", "i", "+", "1", ")", "%", "batch_size", "==", "0", ":", "\n", "                ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "batch", "=", "[", "]", "\n", "\n", "", "", "if", "len", "(", "batch", ")", ">", "0", ":", "\n", "            ", "output", "=", "self", ".", "_run_batch", "(", "batch", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n", "", "def", "predict", "(", "\n", "self", ",", "\n", "contexts", ":", "List", "[", "str", "]", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._initialize": [[80, 89], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "transformers.AutoConfig.from_pretrained", "mnli._NLIRelationClassifier.config.label2id.get", "mnli._NLIRelationClassifier.config.label2id.get", "ValueError", "int"], "methods", ["None"], ["batch_size", ":", "int", "=", "1", ",", "\n", "return_labels", ":", "bool", "=", "True", ",", "\n", "return_confidences", ":", "bool", "=", "False", ",", "\n", "topk", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "output", "=", "self", "(", "contexts", ",", "batch_size", ")", "\n", "topics", "=", "np", ".", "argsort", "(", "output", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "[", ":", ",", ":", "topk", "]", "\n", "if", "return_labels", ":", "\n", "            ", "topics", "=", "self", ".", "idx2topic", "(", "topics", ")", "\n", "", "if", "return_confidences", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._run_batch": [[90, 102], ["torch.no_grad", "mnli._NLIRelationClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "[].detach().cpu().numpy", "output[].reshape", "torch.tensor", "[].detach().cpu", "numpy.exp", "numpy.exp().sum", "len", "[].detach", "numpy.exp", "mnli._NLIRelationClassifier.model"], "methods", ["None"], ["            ", "topics", "=", "np", ".", "stack", "(", "(", "topics", ",", "np", ".", "sort", "(", "output", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "[", ":", ",", ":", "topk", "]", ")", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "topics", "=", "[", "\n", "[", "(", "int", "(", "label", ")", ",", "float", "(", "conf", ")", ")", "if", "not", "return_labels", "else", "(", "label", ",", "float", "(", "conf", ")", ")", "for", "label", ",", "conf", "in", "row", "]", "\n", "for", "row", "in", "topics", "\n", "]", "\n", "", "else", ":", "\n", "            ", "topics", "=", "topics", ".", "tolist", "(", ")", "\n", "", "if", "topk", "==", "1", ":", "\n", "            ", "topics", "=", "[", "row", "[", "0", "]", "for", "row", "in", "topics", "]", "\n", "\n", "", "return", "topics", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier.__call__": [[103, 132], ["tqdm.tqdm.tqdm", "numpy.vstack", "isinstance", "enumerate", "batch.extend", "len", "mnli._NLIRelationClassifier._run_batch", "numpy.vstack.append", "len", "mnli._NLIRelationClassifier._run_batch", "numpy.vstack.append", "label_template.format"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch"], ["", "", "class", "NLITopicClassifier", "(", "_NLITopicClassifier", ")", ":", "\n", "    ", "\"\"\"NLITopicClassifier\n\n    Zero-Shot topic classifier based on a Natural Language Inference pretrained Transformer.\n\n    Use:\n\n    ```python\n    >>> from a2t.topic_classification import NLITopicClassifier\n\n    >>> topics = ['politics', 'culture', 'economy', 'biology', 'legal', 'medicine', 'business']\n    >>> context = \"hospital: a health facility where patients receive treatment.\"\n\n    >>> clf = NLITopicClassifier(topics)\n\n    >>> predictions = clf(context)[0]\n    >>> print(sorted(list(zip(predictions, topics)), reverse=True))\n\n    [(0.77885467, 'medicine'),\n     (0.08395168, 'biology'),\n     (0.040319894, 'business'),\n     (0.027866213, 'economy'),\n     (0.02357693, 'politics'),\n     (0.023382403, 'legal'),\n     (0.02204825, 'culture')]\n\n    ```\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._apply_negative_threshold": [[133, 140], ["numpy.logical_or"], "methods", ["None"], ["self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", "NLITopicClassifier", ",", "self", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "pretrained_model", "=", "pretrained_model", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._apply_valid_conditions": [[141, 149], ["numpy.stack", "mnli._NLIRelationClassifier.valid_conditions.get", "numpy.zeros"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "contexts", ":", "List", "[", "str", "]", ",", "batch_size", ":", "int", "=", "1", ")", ":", "\n", "        ", "outputs", "=", "super", "(", ")", ".", "__call__", "(", "contexts", "=", "contexts", ",", "batch_size", "=", "batch_size", ")", "\n", "outputs", "=", "np_softmax", "(", "outputs", ")", "\n", "\n", "return", "outputs", "\n", "\n", "\n", "", "", "class", "NLITopicClassifierWithMappingHead", "(", "_NLITopicClassifier", ")", ":", "\n", "    ", "def", "__init__", "(", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier.predict": [[150, 174], ["mnli._NLIRelationClassifier.", "mnli._NLIRelationClassifier.idx2label", "numpy.stack().tolist", "topics.tolist.tolist.tolist", "numpy.argsort", "numpy.stack", "int", "float", "float", "numpy.sort"], "methods", ["None"], ["self", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "topic_mapping", ":", "Dict", "[", "str", ",", "str", "]", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "new_topics", "=", "list", "(", "topic_mapping", ".", "keys", "(", ")", ")", "\n", "self", ".", "target_topics", "=", "labels", "\n", "self", ".", "new_topics2id", "=", "{", "t", ":", "i", "for", "i", ",", "t", "in", "enumerate", "(", "self", ".", "new_topics", ")", "}", "\n", "self", ".", "mapping", "=", "defaultdict", "(", "list", ")", "\n", "for", "key", ",", "value", "in", "topic_mapping", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "mapping", "[", "value", "]", ".", "append", "(", "self", ".", "new_topics2id", "[", "key", "]", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "self", ".", "new_topics", ",", "*", "args", ",", "pretrained_model", "=", "pretrained_model", ",", "**", "kwargs", ")", "\n", "\n", "def", "idx2topic", "(", "idx", ")", ":", "\n", "            ", "return", "self", ".", "target_topics", "[", "idx", "]", "\n", "\n", "", "self", ".", "idx2topic", "=", "np", ".", "vectorize", "(", "idx2topic", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "contexts", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "outputs", "=", "super", "(", ")", ".", "__call__", "(", "contexts", ",", "batch_size", ")", "\n", "outputs", "=", "np", ".", "hstack", "(", "[", "np", ".", "max", "(", "outputs", "[", ":", ",", "self", ".", "mapping", "[", "topic", "]", "]", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "for", "topic", "in", "self", ".", "target_topics", "]", ")", "\n", "outputs", "=", "np_softmax", "(", "outputs", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._initialize": [[184, 196], ["transformers.AutoTokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "transformers.AutoConfig.from_pretrained", "mnli._GenerativeNLIRelationClassifier._get_entailment_neutral_contradiction_token_id", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._get_entailment_neutral_contradiction_token_id"], ["\n", "", "with", "open", "(", "sys", ".", "argv", "[", "1", "]", ",", "\"rt\"", ")", "as", "f", ":", "\n", "        ", "topics", "=", "[", "topic", ".", "rstrip", "(", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "for", "topic", "in", "f", "]", "\n", "\n", "", "input_stream", "=", "open", "(", "sys", ".", "argv", "[", "2", "]", ",", "\"rt\"", ")", "if", "len", "(", "sys", ".", "argv", ")", "==", "3", "else", "sys", ".", "stdin", "\n", "\n", "clf", "=", "NLITopicClassifier", "(", "labels", "=", "topics", ",", "pretrained_model", "=", "\"roberta-large-mnli\"", ")", "\n", "\n", "for", "line", "in", "input_stream", ":", "\n", "        ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "output_probs", "=", "clf", "(", "line", ")", "[", "0", "]", "\n", "topic_dist", "=", "sorted", "(", "list", "(", "zip", "(", "output_probs", ",", "topics", ")", ")", ",", "reverse", "=", "True", ")", "\n", "print", "(", "line", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._run_batch": [[197, 212], ["torch.no_grad", "mnli._GenerativeNLIRelationClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "mnli._GenerativeNLIRelationClassifier.tokenizer.batch_encode_plus", "torch.tensor().to", "[].detach().cpu().numpy", "mnli._GenerativeNLIRelationClassifier._vocab_to_class_logits", "output[].reshape", "torch.tensor", "len", "torch.tensor", "[].detach().cpu", "numpy.exp", "numpy.exp().sum", "len", "[].detach", "numpy.exp", "mnli._GenerativeNLIRelationClassifier.model"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._vocab_to_class_logits"], ["pprint", "(", "topic_dist", ")", "\n", "print", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._get_entailment_neutral_contradiction_token_id": [[213, 224], ["mnli._GenerativeNLIRelationClassifier.tokenizer"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._GenerativeNLIRelationClassifier._vocab_to_class_logits": [[226, 237], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifier.__init__": [[240, 248], ["mnli._NLIRelationClassifier.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifier.__call__": [[249, 260], ["mnli._NLIRelationClassifier.__call__", "mnli.NLIRelationClassifier._apply_negative_threshold", "a2t.base.np_softmax"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__call__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._apply_negative_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__init__": [[263, 313], ["collections.defaultdict", "template_mapping.items", "list", "collections.defaultdict", "template_mapping.items", "mnli._NLIRelationClassifier.__init__", "numpy.vectorize", "mnli.NLIRelationClassifierWithMappingHead.template_mapping_reverse.keys", "mnli.NLIRelationClassifierWithMappingHead.mapping[].extend", "len", "valid_conditions.items", "mnli.NLIRelationClassifierWithMappingHead.template_mapping_reverse[].append", "enumerate", "enumerate", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__call__": [[314, 332], ["mnli._NLIRelationClassifier.__call__", "numpy.hstack", "mnli.NLIRelationClassifierWithMappingHead._apply_negative_threshold", "a2t.base.np_softmax", "mnli.NLIRelationClassifierWithMappingHead._apply_valid_conditions", "numpy.max", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__call__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._apply_negative_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.base.np_softmax", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier._apply_valid_conditions"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.tacred.TACREDClassifier.__init__": [[304, 313], ["kwargs.pop", "a2t.legacy.relation_classification.mnli.NLIRelationClassifierWithMappingHead.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "pretrained_model", "=", "kwargs", ".", "pop", "(", "\"pretrained_model\"", ",", "\"microsoft/deberta-v2-xlarge-mnli\"", ")", "\n", "super", "(", "TACREDClassifier", ",", "self", ")", ".", "__init__", "(", "\n", "pretrained_model", "=", "pretrained_model", ",", "\n", "labels", "=", "TACRED_LABELS", ",", "\n", "template_mapping", "=", "TACRED_LABEL_TEMPLATES", ",", "\n", "valid_conditions", "=", "TACRED_VALID_CONDITIONS", ",", "\n", "entailment_position", "=", "2", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_evaluation.top_k_accuracy": [[18, 21], ["sum", "numpy.argsort", "zip"], "function", ["None"], ["\"nsp\"", ":", "NSPTopicClassifier", ",", "\n", "\"mlm\"", ":", "MLMTopicClassifier", ",", "\n", "\"mnli-mapping\"", ":", "NLITopicClassifierWithMappingHead", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_glue.DataTrainingArguments.__post_init__": [[130, 147], ["run_glue.DataTrainingArguments.task_name.lower", "task_to_keys.keys", "ValueError", "ValueError", "run_glue.DataTrainingArguments.train_file.split", "run_glue.DataTrainingArguments.validation_file.split", "task_to_keys.keys"], "methods", ["None"], ["\"value if set.\"", "\n", "}", ",", "\n", ")", "\n", "train_file", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"A csv or a json file containing the training data.\"", "}", ",", "\n", ")", "\n", "validation_file", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"A csv or a json file containing the validation data.\"", "}", ",", "\n", ")", "\n", "test_file", ":", "Optional", "[", "str", "]", "=", "field", "(", "\n", "default", "=", "None", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"A csv or a json file containing the test data.\"", "}", ",", "\n", ")", "\n", "\n", "def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "task_name", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_glue.main": [[187, 539], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "min", "datasets.load_dataset.map", "transformers.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "data_files.keys", "data_args.train_file.endswith", "logger.warn", "AutoTokenizer.from_pretrained.", "random.sample", "datasets.load_metric", "transformers.Trainer.train", "min", "transformers.Trainer.save_model", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "transformers.Trainer.save_state", "logger.info", "zip", "logger.info", "zip", "len", "ValueError", "transformers.trainer_utils.is_main_process", "logger.info", "datasets.load_dataset", "datasets.load_dataset", "len", "datasets[].unique", "datasets[].unique.sort", "bool", "k.lower", "list", "list", "logger.warn", "ValueError", "train_dataset.select.select", "ValueError", "eval_dataset.select.select", "ValueError", "test_dataset.select.select", "range", "logger.info", "isinstance", "numpy.squeeze", "numpy.argmax", "datasets.load_metric.compute", "transformers.DataCollatorWithPadding", "os.path.isdir", "len", "len", "tasks.append", "eval_datasets.append", "transformers.Trainer.evaluate", "min", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "tasks.append", "test_datasets.append", "test_dataset.select.remove_columns_", "os.path.join", "transformers.Trainer.is_world_process_zero", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "ValueError", "len", "transformers.PretrainedConfig", "AutoModelForSequenceClassification.from_pretrained.config.label2id.items", "sorted", "sorted", "int", "range", "range", "range", "len", "len", "numpy.mean().item", "len", "len", "transformers.Trainer.predict", "numpy.squeeze", "numpy.argmax", "os.listdir", "bool", "data_args.train_file.split", "data_args.test_file.split", "label_name_to_id.keys", "range", "enumerate", "open", "logger.info", "writer.write", "enumerate", "list", "list", "numpy.mean", "transformers.AutoConfig.from_pretrained", "sorted", "sorted", "list", "writer.write", "writer.write", "label_name_to_id.keys", "metric.compute.values"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.topic_classification.finetune_classifier.train", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.mnli._NLIRelationClassifier.predict"], [")", "\n", "use_fast_tokenizer", ":", "bool", "=", "field", "(", "\n", "default", "=", "True", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"Whether to use one of the fast tokenizer (backed by the tokenizers library) or not.\"", "}", ",", "\n", ")", "\n", "model_revision", ":", "str", "=", "field", "(", "\n", "default", "=", "\"main\"", ",", "\n", "metadata", "=", "{", "\"help\"", ":", "\"The specific model version to use (can be a branch name, tag name or commit id).\"", "}", ",", "\n", ")", "\n", "use_auth_token", ":", "bool", "=", "field", "(", "\n", "default", "=", "False", ",", "\n", "metadata", "=", "{", "\n", "\"help\"", ":", "\"Will use the token generated when running `transformers-cli login` (necessary to use this script \"", "\n", "\"with private models).\"", "\n", "}", ",", "\n", ")", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "\n", "log_level", "=", "training_args", ".", "get_process_log_level", "(", ")", "\n", "logger", ".", "setLevel", "(", "log_level", ")", "\n", "datasets", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity", "(", "log_level", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "training_args", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "", "", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or specify a GLUE benchmark task (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use as labels the column called 'label' and as pair of sentences the", "\n", "# sentences in columns called 'sentence1' and 'sentence2' if such column exists or the first two columns not named", "\n", "# label if at least two columns are provided.", "\n", "#", "\n", "# If the CSVs/JSONs contain only one non-label column, the script does single sentence classification on this", "\n", "# single column. You can easily tweak this behavior (see below)", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\"glue\"", ",", "data_args", ".", "task_name", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "elif", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "raw_datasets", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from your local files.", "\n", "# CSV/JSON training and evaluation files are needed.", "\n", "        ", "data_files", "=", "{", "\n", "\"train\"", ":", "data_args", ".", "train_file", ",", "\n", "\"validation\"", ":", "data_args", ".", "validation_file", ",", "\n", "}", "\n", "\n", "# Get the test dataset: you can provide your own CSV/JSON test file (see below)", "\n", "# when you use `do_predict` without specifying a GLUE benchmark task.", "\n", "if", "training_args", ".", "do_predict", ":", "\n", "            ", "if", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "                ", "train_extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "test_extension", "=", "data_args", ".", "test_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "(", "\n", "test_extension", "==", "train_extension", "\n", ")", ",", "\"`test_file` should have the same extension (csv or json) as `train_file`.\"", "\n", "data_files", "[", "\"test\"", "]", "=", "data_args", ".", "test_file", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Need either a GLUE task or a test file for `do_predict`.\"", ")", "\n", "\n", "", "", "for", "key", "in", "data_files", ".", "keys", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"load a local file for {key}: {data_files[key]}\"", ")", "\n", "\n", "", "if", "data_args", ".", "train_file", ".", "endswith", "(", "\".csv\"", ")", ":", "\n", "# Loading a dataset from local csv files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\"csv\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "# Loading a dataset from local json files", "\n", "            ", "raw_datasets", "=", "load_dataset", "(", "\"json\"", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "model_args", ".", "cache_dir", ")", "\n", "# See more about loading any type of standard or custom dataset at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Labels", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "is_regression", "=", "data_args", ".", "task_name", "==", "\"stsb\"", "\n", "if", "not", "is_regression", ":", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "names", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "", "else", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "", "else", ":", "\n", "# Trying to have good defaults here, don't hesitate to tweak to your needs.", "\n", "        ", "is_regression", "=", "raw_datasets", "[", "\"train\"", "]", ".", "features", "[", "\"label\"", "]", ".", "dtype", "in", "[", "\n", "\"float32\"", ",", "\n", "\"float64\"", ",", "\n", "]", "\n", "if", "is_regression", ":", "\n", "            ", "num_labels", "=", "1", "\n", "", "else", ":", "\n", "# A useful fast method:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.unique", "\n", "            ", "label_list", "=", "raw_datasets", "[", "\"train\"", "]", ".", "unique", "(", "\"label\"", ")", "\n", "label_list", ".", "sort", "(", ")", "# Let's sort it for determinism", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "data_args", ".", "task_name", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Preprocessing the raw_datasets", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "sentence1_key", ",", "sentence2_key", "=", "task_to_keys", "[", "data_args", ".", "task_name", "]", "\n", "", "else", ":", "\n", "# Again, we try to have some nice defaults but don't hesitate to tweak to your use case.", "\n", "        ", "non_label_column_names", "=", "[", "name", "for", "name", "in", "raw_datasets", "[", "\"train\"", "]", ".", "column_names", "if", "name", "!=", "\"label\"", "]", "\n", "if", "\"sentence1\"", "in", "non_label_column_names", "and", "\"sentence2\"", "in", "non_label_column_names", ":", "\n", "            ", "sentence1_key", ",", "sentence2_key", "=", "\"sentence1\"", ",", "\"sentence2\"", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "non_label_column_names", ")", ">=", "2", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "                ", "sentence1_key", ",", "sentence2_key", "=", "non_label_column_names", "[", "0", "]", ",", "None", "\n", "\n", "# Padding strategy", "\n", "", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "# We will pad later, dynamically at batch creation, to the max sequence length in each batch", "\n", "        ", "padding", "=", "False", "\n", "\n", "# Some models have set the order of the labels to use, so let's make sure we do use it.", "\n", "", "label_to_id", "=", "None", "\n", "if", "(", "\n", "model", ".", "config", ".", "label2id", "!=", "PretrainedConfig", "(", "num_labels", "=", "num_labels", ")", ".", "label2id", "\n", "and", "data_args", ".", "task_name", "is", "not", "None", "\n", "and", "not", "is_regression", "\n", ")", ":", "\n", "# Some have all caps in their config, some don't.", "\n", "        ", "label_name_to_id", "=", "{", "k", ".", "lower", "(", ")", ":", "v", "for", "k", ",", "v", "in", "model", ".", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "if", "list", "(", "sorted", "(", "label_name_to_id", ".", "keys", "(", ")", ")", ")", "==", "list", "(", "sorted", "(", "label_list", ")", ")", ":", "\n", "            ", "label_to_id", "=", "{", "i", ":", "int", "(", "label_name_to_id", "[", "label_list", "[", "i", "]", "]", ")", "for", "i", "in", "range", "(", "num_labels", ")", "}", "\n", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Your model seems to have been trained with labels, but they don't match the dataset: \"", ",", "\n", "f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"", "\n", "\"\\nIgnoring the model labels as a result.\"", ",", "\n", ")", "\n", "", "", "elif", "data_args", ".", "task_name", "is", "None", "and", "not", "is_regression", ":", "\n", "        ", "label_to_id", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "", "if", "label_to_id", "is", "not", "None", ":", "\n", "        ", "model", ".", "config", ".", "label2id", "=", "label_to_id", "\n", "model", ".", "config", ".", "id2label", "=", "{", "id", ":", "label", "for", "label", ",", "id", "in", "config", ".", "label2id", ".", "items", "(", ")", "}", "\n", "\n", "", "if", "data_args", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({data_args.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "max_seq_length", "=", "min", "(", "data_args", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "examples", "[", "sentence1_key", "]", ",", ")", "if", "sentence2_key", "is", "None", "else", "(", "examples", "[", "sentence1_key", "]", ",", "examples", "[", "sentence2_key", "]", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "# Map labels to IDs (not necessary for GLUE tasks)", "\n", "if", "label_to_id", "is", "not", "None", "and", "\"label\"", "in", "examples", ":", "\n", "            ", "result", "[", "\"label\"", "]", "=", "[", "(", "label_to_id", "[", "l", "]", "if", "l", "!=", "-", "1", "else", "-", "1", ")", "for", "l", "in", "examples", "[", "\"label\"", "]", "]", "\n", "", "return", "result", "\n", "\n", "", "with", "training_args", ".", "main_process_first", "(", "desc", "=", "\"dataset map pre-processing\"", ")", ":", "\n", "        ", "raw_datasets", "=", "raw_datasets", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "desc", "=", "\"Running tokenizer on dataset\"", ",", "\n", ")", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "\"train\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_train requires a train dataset\"", ")", "\n", "", "train_dataset", "=", "raw_datasets", "[", "\"train\"", "]", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "if", "\"validation\"", "not", "in", "raw_datasets", "and", "\"validation_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_eval requires a validation dataset\"", ")", "\n", "", "eval_dataset", "=", "raw_datasets", "[", "\"validation_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"validation\"", "]", "\n", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_eval_samples", ")", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", "or", "data_args", ".", "task_name", "is", "not", "None", "or", "data_args", ".", "test_file", "is", "not", "None", ":", "\n", "        ", "if", "\"test\"", "not", "in", "raw_datasets", "and", "\"test_matched\"", "not", "in", "raw_datasets", ":", "\n", "            ", "raise", "ValueError", "(", "\"--do_predict requires a test dataset\"", ")", "\n", "", "predict_dataset", "=", "raw_datasets", "[", "\"test_matched\"", "if", "data_args", ".", "task_name", "==", "\"mnli\"", "else", "\"test\"", "]", "\n", "if", "data_args", ".", "max_predict_samples", "is", "not", "None", ":", "\n", "            ", "predict_dataset", "=", "predict_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_predict_samples", ")", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {train_dataset[index]}.\"", ")", "\n", "\n", "# Get the metric function", "\n", "", "", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"glue\"", ",", "data_args", ".", "task_name", ")", "\n", "", "else", ":", "\n", "        ", "metric", "=", "load_metric", "(", "\"accuracy\"", ")", "\n", "\n", "# You can define your custom compute_metrics function. It takes an `EvalPrediction` object (a namedtuple with a", "\n", "# predictions and label_ids field) and has to return a dictionary string to float.", "\n", "", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "if", "data_args", ".", "task_name", "is", "not", "None", ":", "\n", "            ", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "preds", ",", "references", "=", "p", ".", "label_ids", ")", "\n", "if", "len", "(", "result", ")", ">", "1", ":", "\n", "                ", "result", "[", "\"combined_score\"", "]", "=", "np", ".", "mean", "(", "list", "(", "result", ".", "values", "(", ")", ")", ")", ".", "item", "(", ")", "\n", "", "return", "result", "\n", "", "elif", "is_regression", ":", "\n", "            ", "return", "{", "\"mse\"", ":", "(", "(", "preds", "-", "p", ".", "label_ids", ")", "**", "2", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "\"accuracy\"", ":", "(", "preds", "==", "p", ".", "label_ids", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "training_args", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "if", "training_args", ".", "resume_from_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "training_args", ".", "resume_from_checkpoint", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "checkpoint", "=", "last_checkpoint", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "max_train_samples", "=", "data_args", ".", "max_train_samples", "if", "data_args", ".", "max_train_samples", "is", "not", "None", "else", "len", "(", "train_dataset", ")", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "min", "(", "max_train_samples", ",", "len", "(", "train_dataset", ")", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "tasks", "=", "[", "data_args", ".", "task_name", "]", "\n", "eval_datasets", "=", "[", "eval_dataset", "]", "\n", "if", "data_args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "tasks", ".", "append", "(", "\"mnli-mm\"", ")", "\n", "eval_datasets", ".", "append", "(", "raw_datasets", "[", "\"validation_mismatched\"", "]", ")", "\n", "\n", "", "for", "eval_dataset", ",", "task", "in", "zip", "(", "eval_datasets", ",", "tasks", ")", ":", "\n", "            ", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "eval_dataset", ")", "\n", "\n", "max_eval_samples", "=", "data_args", ".", "max_eval_samples", "if", "data_args", ".", "max_eval_samples", "is", "not", "None", "else", "len", "(", "eval_dataset", ")", "\n", "metrics", "[", "\"eval_samples\"", "]", "=", "min", "(", "max_eval_samples", ",", "len", "(", "eval_dataset", ")", ")", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_glue._mp_fn": [[541, 544], ["run_glue.main"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.run_glue.main"], ["predict_datasets", "=", "[", "predict_dataset", "]", "\n", "if", "data_args", ".", "task_name", "==", "\"mnli\"", ":", "\n", "            ", "tasks", ".", "append", "(", "\"mnli-mm\"", ")", "\n", "predict_datasets", ".", "append", "(", "raw_datasets", "[", "\"test_mismatched\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.f1_score_": [[5, 7], ["sklearn.metrics.f1_score", "list", "range"], "function", ["None"], ["\n", "\n", "def", "f1_score_", "(", "labels", ",", "preds", ",", "n_labels", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.precision_recall_fscore_": [[9, 12], ["sklearn.metrics.precision_recall_fscore_support", "list", "range"], "function", ["None"], ["return", "f1_score", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "1", ",", "n_labels", ")", ")", ",", "average", "=", "\"micro\"", ")", "\n", "\n", "\n", "", "def", "individual_f1_score_", "(", "labels", ",", "preds", ",", "n_labels", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold": [[14, 23], ["output.copy", "output.copy.argmax"], "function", ["None"], ["return", "f1_score", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "0", ",", "n_labels", ")", ")", ",", "average", "=", "None", ")", "\n", "\n", "\n", "", "def", "precision_recall_fscore_", "(", "labels", ",", "preds", ",", "n_labels", ":", "int", "=", "None", ")", ":", "\n", "    ", "n_labels", "=", "max", "(", "labels", ")", "+", "1", "if", "n_labels", "is", "None", "else", "n_labels", "\n", "p", ",", "r", ",", "f", ",", "_", "=", "precision_recall_fscore_support", "(", "labels", ",", "preds", ",", "labels", "=", "list", "(", "range", "(", "1", ",", "n_labels", ")", ")", ",", "average", "=", "\"micro\"", ")", "\n", "return", "p", ",", "r", ",", "f", "\n", "\n", "\n", "", "def", "apply_threshold", "(", "output", ",", "threshold", "=", "0.0", ",", "ignore_negative_prediction", "=", "True", ",", "negative_label_id", ":", "int", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold": [[25, 36], ["numpy.linspace", "numpy.argmax", "utils.apply_threshold", "values.append", "metric"], "function", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold"], ["output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n", "        ", "output_", "[", ":", ",", "negative_label_id", "]", "=", "0.0", "\n", "", "activations", "=", "(", "output_", ">=", "threshold", ")", ".", "sum", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "output_", "[", "activations", "==", "0", ",", "negative_label_id", "]", "=", "1.00", "\n", "\n", "return", "output_", ".", "argmax", "(", "-", "1", ")", "\n", "\n", "\n", "", "def", "apply_individual_threshold", "(", "output", ",", "thresholds", ",", "ignore_negative_prediction", "=", "True", ")", ":", "\n", "    ", "output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.__post_init__": [[63, 110], ["base.Task._assert_minimal_constraints", "base.Task._assert_constraints", "len", "collections.defaultdict", "base.Task.templates.items", "list", "collections.defaultdict", "base.Task.templates.items", "numpy.vectorize", "base.Task.template2label.keys", "base.Task.label2templateid[].extend", "numpy.zeros", "base.Task.valid_conditions.items", "enumerate", "base.Task.template2label[].append", "enumerate", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task._assert_minimal_constraints", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.BinaryTask._assert_constraints"], ["if", "self", ".", "use_cuda", "and", "self", ".", "half", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "half", "(", ")", "\n", "\n", "", "", "def", "_initialize", "(", "self", ",", "pretrained_model", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "def", "__call__", "(", "self", ",", "context", ",", "batch_size", "=", "1", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "def", "clear_gpu_memory", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "cpu", "(", ")", "\n", "del", "self", ".", "model", "\n", "gc", ".", "collect", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "\n", "", "", "class", "EntailmentClassifier", "(", "Classifier", ")", ":", "\n", "    ", "\"\"\"General purpose Entailment based classifier.\n\n    This class contains the code for entailment-based zero-shot classification inference. It is pretended to be\n    task and data independent.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "pretrained_model", ":", "str", "=", "\"roberta-large-mnli\"", ",", "\n", "use_cuda", ":", "bool", "=", "True", ",", "\n", "half", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", "use_tqdm", ":", "bool", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pretrained_model (str, optional): The name or path of the pretrained model. Defaults to \"roberta-large-mnli\".\n            use_cuda (bool, optional): Use the GPU if possible. Defaults to True.\n            half (bool, optional): Use half precision if possible. Defaults to False.\n            verbose (bool, optional): Output log information. Defaults to True.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "None", ",", "pretrained_model", ",", "use_cuda", ",", "half", ",", "verbose", ")", "\n", "self", ".", "use_tqdm", "=", "use_tqdm", "and", "_use_tqdm", "\n", "\n", "", "def", "_initialize", "(", "self", ",", "pretrained_model", ":", "str", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "pretrained_model", ")", "\n", "self", ".", "ent_pos", "=", "self", ".", "config", ".", "label2id", ".", "get", "(", "\"ENTAILMENT\"", ",", "self", ".", "config", ".", "label2id", ".", "get", "(", "\"entailment\"", ",", "None", ")", ")", "\n", "if", "self", ".", "ent_pos", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.__repr__": [[111, 121], ["base.Task.labels.__repr__", "len", "str", "str", "len", "base.Task.labels[].__repr__().replace", "base.Task.labels[].__repr__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.__repr__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.__repr__"], ["            ", "raise", "ValueError", "(", "\"The model config must contain ENTAILMENT label in the label2id dict.\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ent_pos", "=", "int", "(", "self", ".", "ent_pos", ")", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "apply_threshold", "(", "\n", "output", ":", "np", ".", "ndarray", ",", "\n", "threshold", ":", "float", "=", "0.0", ",", "\n", "ignore_negative_prediction", ":", "bool", "=", "True", ",", "\n", "application_type", ":", "str", "=", "\"prediction\"", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task._assert_constraints": [[127, 129], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task._assert_minimal_constraints": [[130, 169], ["list", "all", "all", "len", "len", "base.Task.templates.keys", "list", "len", "warnings.warn", "base.Task.valid_conditions.keys", "warnings.warn", "var.strip().strip", "base.Task.templates.values", "re.findall", "base.Task.templates.values", "var.strip"], "methods", ["None"], ["\n", "output_", "=", "output", ".", "copy", "(", ")", "\n", "if", "ignore_negative_prediction", ":", "\n", "            ", "output_", "[", ":", ",", "0", "]", "=", "0.0", "\n", "", "if", "application_type", "==", "\"prediction\"", ":", "\n", "            ", "activations", "=", "(", "output_", ">=", "threshold", ")", ".", "sum", "(", "-", "1", ")", ".", "astype", "(", "int", ")", "\n", "output_", "[", "activations", "==", "0", ",", "0", "]", "=", "1.00", "\n", "", "elif", "application_type", "==", "\"mask\"", ":", "\n", "            ", "activations", "=", "output_", "<", "threshold", "\n", "output_", "[", "activations", "]", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"application_type argument must be \"prediction\" or \"mask\".\"\"\"", ")", "\n", "\n", "", "return", "output_", "\n", "\n", "", "def", "__call__", "(", "\n", "self", ",", "\n", "task", ":", "Task", ",", "\n", "features", ":", "List", "[", "Features", "]", ",", "\n", "negative_threshold", ":", "float", "=", "0.5", ",", "\n", "topk", ":", "int", "=", "1", ",", "\n", "return_labels", ":", "bool", "=", "False", ",", "\n", "return_confidences", ":", "bool", "=", "False", ",", "\n", "ignore_negative_prediction", ":", "bool", "=", "False", ",", "\n", "return_raw_output", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", "->", "List", ":", "\n", "        "]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class": [[171, 184], ["isinstance", "base.IncorrectFeatureTypeError", "type"], "methods", ["None"], ["\n", "task", ".", "assert_features_class", "(", "features", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "iterator", "=", "features", "if", "not", "self", ".", "use_tqdm", "else", "tqdm", "(", "features", ",", "total", "=", "len", "(", "features", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "feature", "in", "iterator", ":", "\n", "                ", "sentence_pairs", "=", "task", ".", "generate_premise_hypotheses_pairs", "(", "[", "feature", "]", ",", "self", ".", "tokenizer", ".", "sep_token", ")", "\n", "data", "=", "self", ".", "tokenizer", "(", "sentence_pairs", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ")", ".", "input_ids", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs": [[186, 205], ["isinstance", "template.format"], "methods", ["None"], ["output", "=", "self", ".", "model", "(", "data", ")", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "", "outputs", "=", "np", ".", "vstack", "(", "outputs", ")", "\n", "\n", "if", "task", ".", "multi_label", ":", "\n", "            ", "outputs", "=", "np", ".", "exp", "(", "outputs", ")", "/", "np", ".", "exp", "(", "outputs", ")", ".", "sum", "(", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "", "outputs", "=", "outputs", "[", "...", ",", "self", ".", "ent_pos", "]", ".", "reshape", "(", "len", "(", "features", ")", ",", "-", "1", ")", "\n", "\n", "preds", "=", "task", ".", "reverse_to_labels", "(", "outputs", ")", "\n", "if", "not", "task", ".", "multi_label", ":", "\n", "            ", "preds", "=", "np_softmax", "(", "preds", ")", "\n", "\n", "", "preds", "=", "task", ".", "apply_valid_conditions", "(", "features", ",", "preds", ")", "\n", "\n", "apply_threshold", "=", "task", ".", "multi_label", "and", "negative_threshold", ">", "0", "\n", "if", "apply_threshold", ":", "\n", "            ", "preds", "=", "self", ".", "apply_threshold", "(", "\n", "preds", ",", "threshold", "=", "negative_threshold", ",", "ignore_negative_prediction", "=", "ignore_negative_prediction", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.reverse_to_labels": [[206, 226], ["numpy.hstack", "collate_fn", "numpy.zeros"], "methods", ["None"], ["\n", "", "predictions", "=", "np", ".", "argsort", "(", "preds", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "if", "topk", ">", "0", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", ",", ":", "topk", "]", "\n", "", "if", "return_labels", ":", "\n", "            ", "predictions", "=", "task", ".", "idx2label", "(", "predictions", ")", "\n", "", "if", "return_confidences", ":", "\n", "            ", "confidences", "=", "np", ".", "sort", "(", "preds", ",", "-", "1", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "if", "topk", ">", "0", ":", "\n", "                ", "confidences", "=", "confidences", "[", ":", ",", ":", "topk", "]", "\n", "\n", "", "predictions", "=", "np", ".", "stack", "(", "(", "predictions", ",", "confidences", ")", ",", "-", "1", ")", ".", "tolist", "(", ")", "\n", "predictions", "=", "[", "\n", "[", "(", "int", "(", "label", ")", ",", "float", "(", "conf", ")", ")", "if", "not", "return_labels", "else", "(", "label", ",", "float", "(", "conf", ")", ")", "for", "label", ",", "conf", "in", "row", "]", "\n", "for", "row", "in", "predictions", "\n", "]", "\n", "", "else", ":", "\n", "            ", "predictions", "=", "predictions", ".", "tolist", "(", ")", "\n", "", "if", "topk", "==", "1", ":", "\n", "            ", "predictions", "=", "[", "row", "[", "0", "]", "for", "row", "in", "predictions", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.apply_valid_conditions": [[227, 244], ["numpy.stack", "numpy.logical_or", "base.Task._valid_conditions.get", "numpy.zeros"], "methods", ["None"], ["", "if", "return_raw_output", ":", "\n", "            ", "return", "(", "predictions", ",", "preds", ")", "\n", "", "else", ":", "\n", "            ", "return", "predictions", "\n", "\n", "\n", "", "", "", "__pdoc__", "=", "{", "\"EntailmentClassifier.__call__\"", ":", "True", "}", "\n", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.compute_metrics": [[245, 269], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.from_config": [[270, 295], ["cls", "open", "json.load", "config[].split", "__import__", "set", "set", "getattr", "inspect.signature().parameters.keys", "dataclasses.fields", "inspect.signature"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.to_config": [[296, 310], ["os.makedirs", "os.path.dirname", "open", "json.dump", "vars().items", "vars"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.ZeroaryTask._assert_constraints": [[336, 339], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.ZeroaryTask.compute_metrics": [[340, 356], ["warnings.warn", "sklearn.metrics.accuracy_score", "output.argmax"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.UnaryTask._assert_constraints": [[384, 387], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.UnaryTask.compute_metrics": [[388, 436], ["ValueError", "a2t.utils.find_optimal_threshold", "sklearn.metrics.accuracy_score", "a2t.utils.apply_threshold", "list", "output.copy", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "isinstance", "output.argmax", "output_pos[].argmax", "set", "set", "range", "len"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.BinaryTask._assert_constraints": [[465, 468], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.BinaryTask.compute_metrics": [[469, 518], ["ValueError", "a2t.utils.find_optimal_threshold", "sklearn.metrics.accuracy_score", "a2t.utils.apply_threshold", "list", "output.copy", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "isinstance", "output.argmax", "output_pos[].argmax", "set", "set", "range", "len"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.find_optimal_threshold", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.relation_classification.utils.apply_threshold"], []], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.tuple_classification.RelationClassificationTask.__init__": [[15, 54], ["base.BinaryTask.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "# *args,", "\n", "required_variables", ":", "List", "[", "str", "]", "=", "[", "\"X\"", ",", "\"Y\"", "]", ",", "\n", "additional_variables", ":", "List", "[", "str", "]", "=", "[", "\"inst_type\"", "]", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "valid_conditions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "features_class", ":", "type", "=", "RelationClassificationFeatures", ",", "\n", "multi_label", ":", "bool", "=", "True", ",", "\n", "negative_label_id", ":", "int", "=", "0", ",", "\n", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of a RelationClassificationTask task.\n\n        Args:\n            name (str): A name for the task that may be used for to differentiate task when saving.\n            labels (List[str]): The labels for the task.\n            required_variables (List[str], optional): The variables required to perform the task and must be implemented by the `RelationClassificationFeatures` class. Defaults to `[\"X\", \"Y\"]`.\n            additional_variables (List[str], optional): The variables not required to perform the task and must be implemented by the `RelationClassificationFeatures` class. Defaults to [\"inst_type\"].\n            templates (Dict[str, List[str]], optional): The templates/verbalizations for the task. Defaults to None.\n            valid_conditions (Dict[str, List[str]], optional): The valid conditions or constraints for the task. Defaults to None.\n            features_class (type, optional): The `Features` class related to the task. Defaults to RelationClassificationFeatures.\n            multi_label (bool, optional): Whether the task must be treated as multi-label or not. Defaults to True.\n            negative_label_id (int, optional): The index of the negative label or -1 if no negative label exist. A negative label is for example the class `Other` on NER, that means that the specific token is not a named entity. Defaults to 0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "# *args,", "\n", "name", "=", "name", ",", "\n", "required_variables", "=", "required_variables", ",", "\n", "additional_variables", "=", "additional_variables", ",", "\n", "labels", "=", "labels", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "valid_conditions", ",", "\n", "features_class", "=", "features_class", ",", "\n", "multi_label", "=", "multi_label", ",", "\n", "negative_label_id", "=", "negative_label_id", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.tuple_classification.EventArgumentClassificationTask.__init__": [[70, 107], ["base.BinaryTask.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "required_variables", ":", "List", "[", "str", "]", "=", "[", "\"trg\"", ",", "\"arg\"", "]", ",", "\n", "additional_variables", ":", "List", "[", "str", "]", "=", "[", "\"inst_type\"", ",", "\"trg_type\"", ",", "\"trg_subtype\"", "]", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "valid_conditions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "features_class", ":", "type", "=", "EventArgumentClassificationFeatures", ",", "\n", "multi_label", ":", "bool", "=", "True", ",", "\n", "negative_label_id", ":", "int", "=", "0", ",", "\n", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of a RelationClassificationTask task.\n\n        Args:\n            name (str): A name for the task that may be used for to differentiate task when saving.\n            labels (List[str]): The labels for the task.\n            required_variables (List[str], optional): The variables required to perform the task and must be implemented by the `EventArgumentClassificationFeatures` class. Defaults to `[\"trg\", \"arg\"]`.\n            additional_variables (List[str], optional): The variables not required to perform the task and must be implemented by the `EventArgumentClassificationFeatures` class. Defaults to [\"inst_type\", \"trg_type\", \"trg_subtype\"].\n            templates (Dict[str, List[str]], optional): The templates/verbalizations for the task. Defaults to None.\n            valid_conditions (Dict[str, List[str]], optional): The valid conditions or constraints for the task. Defaults to None.\n            features_class (type, optional): The `Features` class related to the task. Defaults to EventArgumentClassificationFeatures.\n            multi_label (bool, optional): Whether the task must be treated as multi-label or not. Defaults to True.\n            negative_label_id (int, optional): The index of the negative label or -1 if no negative label exist. A negative label is for example the class `Other` on NER, that means that the specific token is not a named entity. Defaults to 0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "name", "=", "name", ",", "\n", "required_variables", "=", "required_variables", ",", "\n", "additional_variables", "=", "additional_variables", ",", "\n", "labels", "=", "labels", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "valid_conditions", ",", "\n", "features_class", "=", "features_class", ",", "\n", "multi_label", "=", "multi_label", ",", "\n", "negative_label_id", "=", "negative_label_id", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.tuple_classification.TACREDRelationClassificationTask.__init__": [[121, 144], ["tuple_classification.RelationClassificationTask.__init__", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "labels", ":", "List", "[", "str", "]", ",", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "valid_conditions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of the TACRED RelationClassification task\n\n        Args:\n            labels (List[str]): The labels for the task.\n            templates (Dict[str, List[str]]): The templates/verbalizations for the task.\n            valid_conditions (Dict[str, List[str]]): The valid conditions or constraints for the task.\n        \"\"\"", "\n", "for", "key", "in", "[", "\"name\"", ",", "\"required_variables\"", ",", "\"additional_variables\"", ",", "\"features_class\"", ",", "\"multi_label\"", ",", "\"negative_label_id\"", "]", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "\"TACRED Relation Classification task\"", ",", "\n", "labels", "=", "labels", ",", "\n", "required_variables", "=", "[", "\"subj\"", ",", "\"obj\"", "]", ",", "\n", "additional_variables", "=", "[", "\"inst_type\"", "]", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "valid_conditions", ",", "\n", "features_class", "=", "TACREDFeatures", ",", "\n", "multi_label", "=", "True", ",", "\n", "negative_label_id", "=", "0", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.span_classification.NamedEntityClassificationTask.__init__": [[16, 75], ["base.UnaryTask.__init__", "text_classification.IncorrectHypothesisTemplateError", "hypothesis_template.replace", "enumerate"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "*", "args", ",", "\n", "required_variables", ":", "List", "[", "str", "]", "=", "[", "\"X\"", "]", ",", "\n", "additional_variables", ":", "List", "[", "str", "]", "=", "[", "\"inst_type\"", "]", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "valid_conditions", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "hypothesis_template", ":", "str", "=", "\"{X} is a {label}.\"", ",", "\n", "features_class", ":", "type", "=", "NamedEntityClassificationFeatures", ",", "\n", "multi_label", ":", "bool", "=", "True", ",", "\n", "negative_label_id", ":", "int", "=", "0", ",", "\n", "**", "kwargs", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of a NamedEntityClassificationTask task.\n\n        Args:\n            name (str): A name for the task that may be used for to differentiate task when saving.\n            labels (List[str]): The labels for the task.\n            required_variables (List[str], optional): The variables required to perform the task and must be implemented by the `NamedEntityClassificationFeatures` class. Defaults to `[\"X\", \"Y\"]`.\n            additional_variables (List[str], optional): The variables not required to perform the task and must be implemented by the `NamedEntityClassificationFeatures` class. Defaults to [\"inst_type\"].\n            templates (Dict[str, List[str]], optional): The templates/verbalizations for the task. Defaults to None.\n            valid_conditions (Dict[str, List[str]], optional): The valid conditions or constraints for the task. Defaults to None.\n            hypothesis_template (str, optional): A meta template to generate hypothesis templates, if `templates` is None,\n                then the templates will be the combinations of the `hypothesis_template` and the `labels`. It must contain the\n                '{label}' placeholder. Defaults to \"{X} is a {label}.\".\n            features_class (type, optional): The `Features` class related to the task. Defaults to NamedEntityClassificationFeatures.\n            multi_label (bool, optional): Whether the task must be treated as multi-label or not. Defaults to True.\n            negative_label_id (int, optional): The index of the negative label or -1 if no negative label exist. A negative label is for example the class `Other` on NER, that means that the specific token is not a named entity. Defaults to 0.\n\n        Raises:\n            IncorrectHypothesisTemplateError: Raised when the `hypotesis_template` argument does not contain the '{label}' placeholder.\n        \"\"\"", "\n", "\n", "if", "not", "templates", ":", "\n", "            ", "if", "\"{label}\"", "not", "in", "hypothesis_template", ":", "\n", "                ", "raise", "IncorrectHypothesisTemplateError", "(", "\n", "\"The hypothesis_template argument must contain the '{label}' placeholder.\"", "\n", ")", "\n", "\n", "", "templates", "=", "{", "\n", "label", ":", "[", "hypothesis_template", ".", "replace", "(", "\"{label}\"", ",", "label", ")", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "\n", "if", "i", "!=", "negative_label_id", "\n", "}", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "name", "=", "name", ",", "\n", "required_variables", "=", "required_variables", ",", "\n", "additional_variables", "=", "additional_variables", ",", "\n", "labels", "=", "labels", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "valid_conditions", ",", "\n", "features_class", "=", "features_class", ",", "\n", "multi_label", "=", "multi_label", ",", "\n", "negative_label_id", "=", "negative_label_id", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.text_classification.TextClassificationTask.__init__": [[24, 67], ["base.ZeroaryTask.__init__", "text_classification.IncorrectHypothesisTemplateError", "hypothesis_template.format"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", "=", "None", ",", "\n", "labels", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "hypothesis_template", ":", "str", "=", "\"It was {label}.\"", ",", "\n", "features_class", ":", "type", "=", "TextClassificationFeatures", ",", "\n", "multi_label", ":", "bool", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"_summary_\n\n        Args:\n            name (str, optional): A name for the task that may be used for to differentiate task when saving. Defaults to None.\n            labels (List[str], optional): The labels for the task. Defaults to empty list.\n            templates (Dict[str, List[str]], optional): The templates/verbalizations for the task. Defaults to None.\n            hypothesis_template (str, optional): A meta template to generate hypothesis templates, if `templates` is None,\n                then the templates will be the combinations of the `hypothesis_template` and the `labels`. It must contain the\n                '{label}' placeholder. Defaults to \"The domain of the sentence is about {label}.\".\n            features_class (type, optional): The `Features` class related to the task. Defaults to TextClassificationFeatures.\n            multi_label (bool, optional): Whether the task must be treated as multi-label or not. Defaults to False.\n\n        Raises:\n            IncorrectHypothesisTemplateError: Raised when the `hypotesis_template` argument does not contain the '{label}' placeholder.\n        \"\"\"", "\n", "if", "not", "templates", ":", "\n", "\n", "            ", "if", "\"{label}\"", "not", "in", "hypothesis_template", ":", "\n", "                ", "raise", "IncorrectHypothesisTemplateError", "(", "\n", "\"The hypothesis_template argument must contain the '{label}' placeholder.\"", "\n", ")", "\n", "", "templates", "=", "{", "label", ":", "[", "hypothesis_template", ".", "format", "(", "label", "=", "label", ")", "]", "for", "label", "in", "labels", "}", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "name", "=", "name", ",", "\n", "required_variables", "=", "[", "]", ",", "\n", "additional_variables", "=", "[", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "None", ",", "\n", "features_class", "=", "features_class", ",", "\n", "multi_label", "=", "multi_label", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.text_classification.TopicClassificationTask.__init__": [[80, 133], ["base.ZeroaryTask.__init__", "text_classification.IncorrectHypothesisTemplateError", "hypothesis_template.format", "hypothesis_template.format", "split_labels_fn"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "name", ":", "str", "=", "None", ",", "\n", "labels", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "templates", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "hypothesis_template", ":", "str", "=", "\"The domain of the sentence is about {label}.\"", ",", "\n", "features_class", ":", "type", "=", "TopicClassificationFeatures", ",", "\n", "preprocess_labels", ":", "bool", "=", "False", ",", "\n", "preprocess_fn", ":", "Callable", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"Initialization of a TopicClassification task.\n\n        Args:\n            name (str, optional): A name for the task that may be used for to differentiate task when saving. Defaults to None.\n            labels (List[str]): The labels for the task. Defaults to empty list.\n            templates (Dict[str, List[str]], optional): The templates/verbalizations for the task. Defaults to None.\n            hypothesis_template (str, optional): A meta template to generate hypothesis templates, if `templates` is None,\n                then the templates will be the combinations of the `hypothesis_template` and the `labels`. It must contain the\n                '{label}' placeholder. Defaults to \"The domain of the sentence is about {label}.\".\n            features_class (type, optional): The `Features` class related to the task. Defaults to TopicClassificationFeatures.\n            preprocess_labels (bool, optional): Whether to split the topic labels. Defaults to True.\n            preprocess_fn (Callable, optional): The function that is applied if `split_labels` is True. If None then\n                `TopicClassificationTask._split_labels_fn` is applied. Defaults to None.\n\n        Raises:\n            IncorrectHypothesisTemplateError: Raised when the `hypotesis_template` argument does not contain the '{label}' placeholder.\n        \"\"\"", "\n", "if", "not", "templates", ":", "\n", "\n", "            ", "if", "\"{label}\"", "not", "in", "hypothesis_template", ":", "\n", "                ", "raise", "IncorrectHypothesisTemplateError", "(", "\n", "\"The hypothesis_template argument must contain the '{label}' placeholder.\"", "\n", ")", "\n", "\n", "", "if", "preprocess_labels", ":", "\n", "                ", "split_labels_fn", "=", "preprocess_fn", "if", "preprocess_fn", "is", "not", "None", "else", "self", ".", "_split_and_extend_labels_fn", "\n", "templates", "=", "{", "\n", "label", ":", "[", "hypothesis_template", ".", "format", "(", "label", "=", "partial_label", ")", "for", "partial_label", "in", "split_labels_fn", "(", "label", ")", "]", "\n", "for", "label", "in", "labels", "\n", "}", "\n", "", "else", ":", "\n", "                ", "templates", "=", "{", "label", ":", "[", "hypothesis_template", ".", "format", "(", "label", "=", "label", ")", "]", "for", "label", "in", "labels", "}", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "\n", "name", "=", "name", ",", "\n", "required_variables", "=", "[", "]", ",", "\n", "additional_variables", "=", "[", "]", ",", "\n", "labels", "=", "labels", ",", "\n", "templates", "=", "templates", ",", "\n", "valid_conditions", "=", "None", ",", "\n", "features_class", "=", "features_class", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.text_classification.TopicClassificationTask._split_labels_fn": [[135, 144], ["list", "partial_label.strip().capitalize", "set", "label.split", "partial_label.split", "len", "partial_label.strip", "partial_label.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_split_labels_fn", "(", "label", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "labels", "=", "[", "\n", "partial_label", ".", "strip", "(", ")", ".", "capitalize", "(", ")", "\n", "for", "partial_label", "in", "label", ".", "split", "(", "\",\"", ")", "\n", "for", "partial_label", "in", "partial_label", ".", "split", "(", "\"and\"", ")", "\n", "if", "len", "(", "partial_label", ".", "strip", "(", ")", ")", "\n", "]", "\n", "return", "list", "(", "set", "(", "labels", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.text_classification.TopicClassificationTask._split_and_extend_labels_fn": [[145, 154], ["list", "set", "partial_label.strip().capitalize", "label.split", "partial_label.split", "len", "partial_label.strip", "partial_label.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_split_and_extend_labels_fn", "(", "label", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "labels", "=", "[", "label", "]", "+", "[", "\n", "partial_label", ".", "strip", "(", ")", ".", "capitalize", "(", ")", "\n", "for", "partial_label", "in", "label", ".", "split", "(", "\",\"", ")", "\n", "for", "partial_label", "in", "partial_label", ".", "split", "(", "\"and\"", ")", "\n", "if", "len", "(", "partial_label", ".", "strip", "(", ")", ")", "\n", "]", "\n", "return", "list", "(", "set", "(", "labels", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestTasks.test_assert_minimal_constraints": [[27, 64], ["test_tasks.TestTasks.assertRaises", "test_tasks.TestTasks.assertWarns", "test_tasks.TestTasks.assertWarns", "test_tasks.TestTasks.assertRaises", "DummyTask", "test_tasks.TestTasks.assertRaises", "DummyTask", "test_tasks.TestTasks.assertRaises", "test_tasks.TestTasks.assertRaises"], "methods", ["None"], ["    ", "def", "test_assert_minimal_constraints", "(", "self", ")", ":", "\n", "\n", "# Check number of labels greater than 0", "\n", "        ", "self", ".", "assertRaises", "(", "AssertionError", ",", "Task", ")", "\n", "\n", "# Check templates keys", "\n", "self", ".", "assertWarns", "(", "UserWarning", ",", "ZeroaryTask", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"B\"", ":", "[", "]", "}", ")", "\n", "\n", "# Check valid conditions keys", "\n", "self", ".", "assertWarns", "(", "UserWarning", ",", "ZeroaryTask", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "]", "}", ",", "valid_conditions", "=", "{", "\"B\"", ":", "[", "]", "}", ")", "\n", "\n", "# Check negative label id to be smaller than the number of labels", "\n", "self", ".", "assertRaises", "(", "AssertionError", ",", "Task", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "]", "}", ",", "negative_label_id", "=", "1", ")", "\n", "\n", "# Check required and additional variables", "\n", "@", "dataclass", "\n", "class", "DummyFeatures", "(", "Features", ")", ":", "\n", "            ", "X", ":", "str", "=", "None", "\n", "\n", "", "class", "DummyTask", "(", "Task", ")", ":", "\n", "            ", "def", "_assert_constraints", "(", "self", ")", ":", "\n", "                ", "pass", "\n", "\n", "", "", "_", "=", "DummyTask", "(", "required_variables", "=", "[", "\"X\"", "]", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "]", "}", ",", "features_class", "=", "DummyFeatures", ")", "\n", "\n", "self", ".", "assertRaises", "(", "AssertionError", ",", "DummyTask", ",", "required_variables", "=", "[", "\"X\"", "]", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "]", "}", ")", "\n", "\n", "_", "=", "DummyTask", "(", "\n", "required_variables", "=", "[", "\"X\"", "]", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "\"{X} is a Potato.\"", "]", "}", ",", "features_class", "=", "DummyFeatures", "\n", ")", "\n", "\n", "self", ".", "assertRaises", "(", "\n", "AssertionError", ",", "DummyTask", ",", "required_variables", "=", "[", "\"X\"", "]", ",", "labels", "=", "[", "\"O\"", "]", ",", "templates", "=", "{", "\"O\"", ":", "[", "\"{Y} is a Potato.\"", "]", "}", "\n", ")", "\n", "\n", "# Abstract class should not be instantiated", "\n", "self", ".", "assertRaises", "(", "NotImplementedError", ",", "Task", ",", "labels", "=", "[", "\"O\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestTasks.test_assert_constraints": [[65, 80], ["a2t.tasks.base.ZeroaryTask", "a2t.tasks.base.UnaryTask", "a2t.tasks.base.BinaryTask"], "methods", ["None"], ["", "def", "test_assert_constraints", "(", "self", ")", ":", "\n", "        ", "_", "=", "ZeroaryTask", "(", "labels", "=", "[", "\"O\"", "]", ")", "\n", "\n", "@", "dataclass", "\n", "class", "UnaryFeatures", "(", "Features", ")", ":", "\n", "            ", "X", ":", "str", "=", "None", "\n", "\n", "", "_", "=", "UnaryTask", "(", "labels", "=", "[", "\"O\"", "]", ",", "required_variables", "=", "[", "\"X\"", "]", ",", "features_class", "=", "UnaryFeatures", ")", "\n", "\n", "@", "dataclass", "\n", "class", "BinaryFeatures", "(", "Features", ")", ":", "\n", "            ", "X", ":", "str", "=", "None", "\n", "Y", ":", "str", "=", "None", "\n", "\n", "", "_", "=", "BinaryTask", "(", "labels", "=", "[", "\"O\"", "]", ",", "required_variables", "=", "[", "\"X\"", ",", "\"Y\"", "]", ",", "features_class", "=", "BinaryFeatures", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestTasks.test_assert_feature_type": [[81, 106], ["a2t.tasks.base.UnaryTask", "a2t.tasks.base.BinaryTask", "a2t.tasks.base.UnaryTask.assert_features_class", "a2t.tasks.base.BinaryTask.assert_features_class", "test_tasks.TestTasks.assertRaises", "test_tasks.TestTasks.assertRaises", "UnaryFeatures", "BinaryFeatures", "range", "range", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class"], ["", "def", "test_assert_feature_type", "(", "self", ")", ":", "\n", "        ", "@", "dataclass", "\n", "class", "UnaryFeatures", "(", "Features", ")", ":", "\n", "            ", "X", ":", "str", "=", "None", "\n", "\n", "", "unary_task", "=", "UnaryTask", "(", "labels", "=", "[", "\"O\"", "]", ",", "required_variables", "=", "[", "\"X\"", "]", ",", "features_class", "=", "UnaryFeatures", ")", "\n", "\n", "unary_features", "=", "[", "UnaryFeatures", "(", "context", "=", "\"\"", ",", "label", "=", "\"\"", ",", "X", "=", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "\n", "@", "dataclass", "\n", "class", "BinaryFeatures", "(", "Features", ")", ":", "\n", "            ", "X", ":", "str", "=", "None", "\n", "Y", ":", "str", "=", "None", "\n", "\n", "", "binary_task", "=", "BinaryTask", "(", "labels", "=", "[", "\"O\"", "]", ",", "required_variables", "=", "[", "\"X\"", ",", "\"Y\"", "]", ",", "features_class", "=", "BinaryFeatures", ")", "\n", "\n", "binary_features", "=", "[", "BinaryFeatures", "(", "context", "=", "\"\"", ",", "label", "=", "\"\"", ",", "X", "=", "str", "(", "i", ")", ",", "Y", "=", "str", "(", "i", "+", "10", ")", ")", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "\n", "# Correct", "\n", "unary_task", ".", "assert_features_class", "(", "unary_features", ")", "\n", "binary_task", ".", "assert_features_class", "(", "binary_features", ")", "\n", "\n", "# Incorrect", "\n", "self", ".", "assertRaises", "(", "IncorrectFeatureTypeError", ",", "unary_task", ".", "assert_features_class", ",", "binary_features", ")", "\n", "self", ".", "assertRaises", "(", "IncorrectFeatureTypeError", ",", "binary_task", ".", "assert_features_class", ",", "unary_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestTasks.test_save_and_load": [[107, 123], ["a2t.tasks.base.ZeroaryTask", "test_tasks.TestTasks.assertEqual", "tempfile.TemporaryDirectory", "a2t.tasks.base.ZeroaryTask.to_config", "a2t.tasks.base.ZeroaryTask.from_config", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.to_config", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.from_config"], ["", "def", "test_save_and_load", "(", "self", ")", ":", "\n", "        ", "task", "=", "ZeroaryTask", "(", "\n", "\"Topic Classification task.\"", ",", "\n", "labels", "=", "[", "\"Medicine\"", ",", "\"Sports\"", ",", "\"Politics\"", "]", ",", "\n", "templates", "=", "{", "\n", "\"Medicine\"", ":", "[", "\"Topic about health.\"", ",", "\"Topic about medicine.\"", "]", ",", "\n", "\"Sports\"", ":", "[", "\"Topic about footbal.\"", ",", "\"Topic about sports.\"", "]", ",", "\n", "\"Politics\"", ":", "[", "\"Topic about corruption.\"", ",", "\"Topic about politics.\"", "]", ",", "\n", "}", ",", "\n", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "task", ".", "to_config", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"task.config.json\"", ")", ")", "\n", "task2", "=", "ZeroaryTask", ".", "from_config", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"task.config.json\"", ")", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "task", ",", "task2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestTopicClassification.test_hypothesis_generation": [[126, 153], ["a2t.tasks.text_classification.TopicClassificationTask", "a2t.tasks.text_classification.TopicClassificationTask.generate_premise_hypotheses_pairs", "test_tasks.TestTopicClassification.assertTrue", "test_tasks.TestTopicClassification.assertTrue", "test_tasks.TestTopicClassification.assertRaises", "a2t.tasks.text_classification.TopicClassificationFeatures", "hypothesis_template.format", "all", "len", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs"], ["    ", "def", "test_hypothesis_generation", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"Culture\"", ",", "\"Health\"", ",", "\"Army\"", "]", "\n", "\n", "features", "=", "[", "\n", "TopicClassificationFeatures", "(", "context", "=", "\"hospital: a health facility where patients receive treatment.\"", ",", "label", "=", "\"Health\"", ")", "\n", "]", "\n", "\n", "hypothesis_template", "=", "\"The domain of the sentence is {label}.\"", "\n", "\n", "task", "=", "TopicClassificationTask", "(", "\"Test Topic task\"", ",", "labels", "=", "labels", ",", "hypothesis_template", "=", "hypothesis_template", ")", "\n", "\n", "premise_hypothesis_pairs", "=", "task", ".", "generate_premise_hypotheses_pairs", "(", "features", ")", "\n", "hypotheses", "=", "[", "hypothesis_template", ".", "format", "(", "label", "=", "label", ")", "for", "label", "in", "labels", "]", "\n", "\n", "self", ".", "assertTrue", "(", "len", "(", "premise_hypothesis_pairs", ")", "==", "len", "(", "hypotheses", ")", ",", "\"The amount of hypothesis generated is not correct.\"", ")", "\n", "\n", "self", ".", "assertTrue", "(", "\n", "all", "(", "correct", "in", "generated", "for", "correct", ",", "generated", "in", "zip", "(", "hypotheses", ",", "premise_hypothesis_pairs", ")", ")", ",", "\n", "\"The generated hypothesis does not match the correct ones.\"", ",", "\n", ")", "\n", "\n", "self", ".", "assertRaises", "(", "\n", "IncorrectHypothesisTemplateError", ",", "\n", "TopicClassificationTask", ",", "\n", "\"Test Topic task\"", ",", "\n", "labels", "=", "labels", ",", "\n", "hypothesis_template", "=", "\"This template does not contain a label placeholder.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestNamedEntityClassificationTask.test_hypothesis_generation": [[157, 182], ["a2t.tasks.span_classification.NamedEntityClassificationTask", "test_tasks.TestNamedEntityClassificationTask.assertEqual", "a2t.tasks.span_classification.NamedEntityClassificationFeatures", "a2t.tasks.span_classification.NamedEntityClassificationFeatures", "a2t.tasks.span_classification.NamedEntityClassificationTask.generate_premise_hypotheses_pairs"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs"], ["    ", "def", "test_hypothesis_generation", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"O\"", ",", "\"Person\"", ",", "\"Location\"", ",", "\"Organization\"", "]", "\n", "\n", "valid_conditions", "=", "{", "\"Person\"", ":", "[", "\"*\"", "]", ",", "\"Location\"", ":", "[", "\"NNP\"", "]", ",", "\"Organization\"", ":", "[", "\"NNP\"", "]", "}", "\n", "\n", "task", "=", "NamedEntityClassificationTask", "(", "\"Dummy NER task\"", ",", "labels", "=", "labels", ",", "valid_conditions", "=", "valid_conditions", ")", "\n", "\n", "features", "=", "[", "\n", "NamedEntityClassificationFeatures", "(", "\n", "context", "=", "\"Peter won an award in London.\"", ",", "label", "=", "\"Person\"", ",", "inst_type", "=", "\"NNP\"", ",", "X", "=", "\"Peter\"", "\n", ")", ",", "\n", "NamedEntityClassificationFeatures", "(", "\n", "context", "=", "\"Peter won an award in London.\"", ",", "label", "=", "\"Location\"", ",", "inst_type", "=", "\"NNP\"", ",", "X", "=", "\"London\"", "\n", ")", ",", "\n", "]", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "task", ".", "generate_premise_hypotheses_pairs", "(", "features", ")", ",", "\n", "[", "\n", "\"Peter won an award in London. </s> Peter is a Person.\"", ",", "\n", "\"Peter won an award in London. </s> Peter is a Location.\"", ",", "\n", "\"Peter won an award in London. </s> Peter is a Organization.\"", ",", "\n", "\"Peter won an award in London. </s> London is a Person.\"", ",", "\n", "\"Peter won an award in London. </s> London is a Location.\"", ",", "\n", "\"Peter won an award in London. </s> London is a Organization.\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestNamedEntityClassificationTask.test_inference": [[185, 206], ["a2t.tasks.span_classification.NamedEntityClassificationTask", "a2t.base.EntailmentClassifier", "a2t.base.EntailmentClassifier.", "test_tasks.TestNamedEntityClassificationTask.assertEqual", "a2t.tasks.span_classification.NamedEntityClassificationFeatures", "a2t.tasks.span_classification.NamedEntityClassificationFeatures"], "methods", ["None"], ["", "def", "test_inference", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"O\"", ",", "\"Person\"", ",", "\"Location\"", ",", "\"Organization\"", "]", "\n", "\n", "valid_conditions", "=", "{", "\"Person\"", ":", "[", "\"NNP\"", "]", ",", "\"Location\"", ":", "[", "\"NNP\"", "]", ",", "\"Organization\"", ":", "[", "\"NNP\"", "]", "}", "\n", "\n", "task", "=", "NamedEntityClassificationTask", "(", "\"Dummy NER task\"", ",", "labels", "=", "labels", ",", "valid_conditions", "=", "valid_conditions", ")", "\n", "\n", "features", "=", "[", "\n", "NamedEntityClassificationFeatures", "(", "\n", "context", "=", "\"Peter won an award in London.\"", ",", "label", "=", "\"Person\"", ",", "inst_type", "=", "\"NNP\"", ",", "X", "=", "\"Peter\"", "\n", ")", ",", "\n", "NamedEntityClassificationFeatures", "(", "\n", "context", "=", "\"Peter won an award in London.\"", ",", "label", "=", "\"Location\"", ",", "inst_type", "=", "\"NNP\"", ",", "X", "=", "\"London\"", "\n", ")", ",", "\n", "]", "\n", "\n", "nlp", "=", "EntailmentClassifier", "(", "use_cuda", "=", "False", ",", "use_tqdm", "=", "False", ")", "\n", "\n", "preds", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "features", ",", "negative_threshold", "=", "0.5", ",", "return_labels", "=", "True", ",", "topk", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "preds", ",", "[", "feature", ".", "label", "for", "feature", "in", "features", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestRelationClassificationTask.test_hypothesis_generation": [[209, 259], ["a2t.tasks.tuple_classification.RelationClassificationTask", "test_tasks.TestRelationClassificationTask.assertEqual", "a2t.tasks.tuple_classification.RelationClassificationFeatures", "a2t.tasks.tuple_classification.RelationClassificationFeatures", "a2t.tasks.tuple_classification.RelationClassificationFeatures", "a2t.tasks.tuple_classification.RelationClassificationTask.generate_premise_hypotheses_pairs"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs"], ["    ", "def", "test_hypothesis_generation", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"no_relation\"", ",", "\"per:city_of_death\"", ",", "\"org:founded_by\"", "]", "\n", "\n", "templates", "=", "{", "\n", "\"per:city_of_death\"", ":", "[", "\"{X} died in {Y}.\"", "]", ",", "\n", "\"org:founded_by\"", ":", "[", "\"{X} was founded by {Y}.\"", ",", "\"{Y} founded {X}.\"", "]", ",", "\n", "}", "\n", "\n", "valid_conditions", "=", "{", "\"per:city_of_death\"", ":", "[", "\"PERSON:CITY\"", ",", "\"PERSON:LOCATION\"", "]", ",", "\"org:founded_by\"", ":", "[", "\"ORGANIZATION:PERSON\"", "]", "}", "\n", "\n", "task", "=", "RelationClassificationTask", "(", "\n", "\"Dummy RE task\"", ",", "labels", "=", "labels", ",", "templates", "=", "templates", ",", "valid_conditions", "=", "valid_conditions", "\n", ")", "\n", "\n", "features", "=", "[", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"Billy Mays\"", ",", "\n", "Y", "=", "\"Tampa\"", ",", "\n", "inst_type", "=", "\"PERSON:CITY\"", ",", "\n", "context", "=", "\"Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday\"", ",", "\n", "label", "=", "\"per:city_of_death\"", ",", "\n", ")", ",", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"Old Lane Partners\"", ",", "\n", "Y", "=", "\"Pandit\"", ",", "\n", "inst_type", "=", "\"ORGANIZATION:PERSON\"", ",", "\n", "context", "=", "\"Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners.\"", ",", "\n", "label", "=", "\"org:founded_by\"", ",", "\n", ")", ",", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"He\"", ",", "\n", "Y", "=", "\"University of Maryland in College Park\"", ",", "\n", "inst_type", "=", "\"PERSON:ORGANIZATION\"", ",", "\n", "context", "=", "\"He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park.\"", ",", "\n", "label", "=", "\"no_relation\"", ",", "\n", ")", ",", "\n", "]", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "task", ".", "generate_premise_hypotheses_pairs", "(", "features", ")", ",", "\n", "[", "\n", "\"Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday </s> Billy Mays died in Tampa.\"", ",", "\n", "\"Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday </s> Billy Mays was founded by Tampa.\"", ",", "\n", "\"Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday </s> Tampa founded Billy Mays.\"", ",", "\n", "\"Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners. </s> Old Lane Partners died in Pandit.\"", ",", "\n", "\"Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners. </s> Old Lane Partners was founded by Pandit.\"", ",", "\n", "\"Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners. </s> Pandit founded Old Lane Partners.\"", ",", "\n", "\"He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park. </s> He died in University of Maryland in College Park.\"", ",", "\n", "\"He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park. </s> He was founded by University of Maryland in College Park.\"", ",", "\n", "\"He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park. </s> University of Maryland in College Park founded He.\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestRelationClassificationTask.test_inference": [[262, 305], ["a2t.tasks.tuple_classification.RelationClassificationTask", "a2t.base.EntailmentClassifier", "a2t.base.EntailmentClassifier.", "test_tasks.TestRelationClassificationTask.assertEqual", "a2t.tasks.tuple_classification.RelationClassificationFeatures", "a2t.tasks.tuple_classification.RelationClassificationFeatures", "a2t.tasks.tuple_classification.RelationClassificationFeatures"], "methods", ["None"], ["", "def", "test_inference", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"no_relation\"", ",", "\"per:city_of_death\"", ",", "\"org:founded_by\"", "]", "\n", "\n", "templates", "=", "{", "\n", "\"per:city_of_death\"", ":", "[", "\"{X} died in {Y}.\"", "]", ",", "\n", "\"org:founded_by\"", ":", "[", "\"{X} was founded by {Y}.\"", ",", "\"{Y} founded {X}.\"", "]", ",", "\n", "}", "\n", "\n", "valid_conditions", "=", "{", "\"per:city_of_death\"", ":", "[", "\"PERSON:CITY\"", ",", "\"PERSON:LOCATION\"", "]", ",", "\"org:founded_by\"", ":", "[", "\"ORGANIZATION:PERSON\"", "]", "}", "\n", "\n", "task", "=", "RelationClassificationTask", "(", "\n", "\"Dummy RE task\"", ",", "labels", "=", "labels", ",", "templates", "=", "templates", ",", "valid_conditions", "=", "valid_conditions", "\n", ")", "\n", "\n", "features", "=", "[", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"Billy Mays\"", ",", "\n", "Y", "=", "\"Tampa\"", ",", "\n", "inst_type", "=", "\"PERSON:CITY\"", ",", "\n", "context", "=", "\"Billy Mays, the bearded, boisterous pitchman who, as the undisputed king of TV yell and sell, became an unlikely pop culture icon, died at his home in Tampa, Fla, on Sunday\"", ",", "\n", "label", "=", "\"per:city_of_death\"", ",", "\n", ")", ",", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"Old Lane Partners\"", ",", "\n", "Y", "=", "\"Pandit\"", ",", "\n", "inst_type", "=", "\"ORGANIZATION:PERSON\"", ",", "\n", "context", "=", "\"Pandit worked at the brokerage Morgan Stanley for about 11 years until 2005, when he and some Morgan Stanley colleagues quit and later founded the hedge fund Old Lane Partners.\"", ",", "\n", "label", "=", "\"org:founded_by\"", ",", "\n", ")", ",", "\n", "RelationClassificationFeatures", "(", "\n", "X", "=", "\"He\"", ",", "\n", "Y", "=", "\"University of Maryland in College Park\"", ",", "\n", "inst_type", "=", "\"PERSON:ORGANIZATION\"", ",", "\n", "context", "=", "\"He received an undergraduate degree from Morgan State University in 1950 and applied for admission to graduate school at the University of Maryland in College Park.\"", ",", "\n", "label", "=", "\"no_relation\"", ",", "\n", ")", ",", "\n", "]", "\n", "\n", "nlp", "=", "EntailmentClassifier", "(", "use_cuda", "=", "False", ",", "use_tqdm", "=", "False", ")", "\n", "\n", "preds", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "features", ",", "negative_threshold", "=", "0.5", ",", "return_labels", "=", "True", ",", "topk", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "preds", ",", "[", "feature", ".", "label", "for", "feature", "in", "features", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestEventArgumentClassificationTask.test_hypothesis_generation": [[308, 359], ["a2t.tasks.tuple_classification.EventArgumentClassificationTask", "test_tasks.TestEventArgumentClassificationTask.assertEqual", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationTask.generate_premise_hypotheses_pairs"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.generate_premise_hypotheses_pairs"], ["    ", "def", "test_hypothesis_generation", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"no_relation\"", ",", "\"VictimArg\"", ",", "\"PlaceArg\"", ",", "\"TimeArg\"", "]", "\n", "\n", "valid_conditions", "=", "{", "\"VictimArg\"", ":", "[", "\"Life.Die:PER\"", "]", ",", "\"PlaceArg\"", ":", "[", "\"*:LOC\"", ",", "\"*:GPE\"", "]", ",", "\"TimeArg\"", ":", "[", "\"*:DATE\"", "]", "}", "\n", "\n", "templates", "=", "{", "\n", "\"VictimArg\"", ":", "[", "\"{arg} was {trg}.\"", "]", ",", "\n", "\"PlaceArg\"", ":", "[", "\"{trg} occurred in {arg}.\"", "]", ",", "\n", "\"TimeArg\"", ":", "[", "\"{trg} occurred on {arg}.\"", "]", ",", "\n", "}", "\n", "\n", "task", "=", "EventArgumentClassificationTask", "(", "\n", "\"Dummy EAE task\"", ",", "labels", "=", "labels", ",", "templates", "=", "templates", ",", "valid_conditions", "=", "valid_conditions", "\n", ")", "\n", "\n", "features", "=", "[", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"John Smith\"", ",", "\n", "label", "=", "\"VictimArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:PER\"", ",", "\n", ")", ",", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"Florida\"", ",", "\n", "label", "=", "\"PlaceArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:GPE\"", ",", "\n", ")", ",", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"Sunday\"", ",", "\n", "label", "=", "\"TimeArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:DATE\"", ",", "\n", ")", ",", "\n", "]", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "task", ".", "generate_premise_hypotheses_pairs", "(", "features", ")", ",", "\n", "[", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> John Smith was died.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred in John Smith.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred on John Smith.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> Florida was died.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred in Florida.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred on Florida.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> Sunday was died.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred in Sunday.\"", ",", "\n", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday </s> died occurred on Sunday.\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_tasks.TestEventArgumentClassificationTask.test_inference": [[362, 410], ["a2t.tasks.tuple_classification.EventArgumentClassificationTask", "a2t.base.EntailmentClassifier", "a2t.base.EntailmentClassifier.", "test_tasks.TestEventArgumentClassificationTask.assertEqual", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures"], "methods", ["None"], ["", "def", "test_inference", "(", "self", ")", ":", "\n", "        ", "labels", "=", "[", "\"no_relation\"", ",", "\"VictimArg\"", ",", "\"PlaceArg\"", ",", "\"TimeArg\"", "]", "\n", "\n", "valid_conditions", "=", "{", "\n", "\"VictimArg\"", ":", "[", "\"Life.Die:PER\"", "]", ",", "\n", "\"PlaceArg\"", ":", "[", "\"Life.Die:LOC\"", ",", "\"Life.Die:GPE\"", "]", ",", "\n", "\"TimeArg\"", ":", "[", "\"Life.Die:DATE\"", "]", ",", "\n", "}", "\n", "\n", "templates", "=", "{", "\n", "\"VictimArg\"", ":", "[", "\"{arg} was {trg}.\"", "]", ",", "\n", "\"PlaceArg\"", ":", "[", "\"{trg} occurred in {arg}.\"", "]", ",", "\n", "\"TimeArg\"", ":", "[", "\"{trg} occurred on {arg}.\"", "]", ",", "\n", "}", "\n", "\n", "task", "=", "EventArgumentClassificationTask", "(", "\n", "\"Dummy EAE task\"", ",", "labels", "=", "labels", ",", "templates", "=", "templates", ",", "valid_conditions", "=", "valid_conditions", "\n", ")", "\n", "\n", "features", "=", "[", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"John Smith\"", ",", "\n", "label", "=", "\"VictimArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:PER\"", ",", "\n", ")", ",", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"Florida\"", ",", "\n", "label", "=", "\"PlaceArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:GPE\"", ",", "\n", ")", ",", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "\"John Smith, an executive at XYZ Co., died in Florida on Sunday\"", ",", "\n", "trg", "=", "\"died\"", ",", "\n", "arg", "=", "\"Sunday\"", ",", "\n", "label", "=", "\"TimeArg\"", ",", "\n", "inst_type", "=", "\"Life.Die:DATE\"", ",", "\n", ")", ",", "\n", "]", "\n", "\n", "nlp", "=", "EntailmentClassifier", "(", "use_cuda", "=", "False", ",", "use_tqdm", "=", "False", ")", "\n", "\n", "preds", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "features", ",", "negative_threshold", "=", "0.5", ",", "return_labels", "=", "True", ",", "topk", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "preds", ",", "[", "feature", ".", "label", "for", "feature", "in", "features", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_data.TestTACREDRelationClassificationDataset.test_data_loader": [[19, 80], ["unittest.skipIf", "a2t.data.TACREDRelationClassificationDataset", "test_data.TestTACREDRelationClassificationDataset.assertTrue", "test_data.TestTACREDRelationClassificationDataset.assertTrue", "a2t.tasks.tuple_classification.TACREDRelationClassificationTask", "a2t.tasks.tuple_classification.TACREDRelationClassificationTask.assert_features_class", "isinstance", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class"], ["    ", "@", "unittest", ".", "skipIf", "(", "not", "os", ".", "path", ".", "exists", "(", "\"data/tacred/dev.json\"", ")", ",", "\"No TACRED data available at data/tacred/\"", ")", "\n", "def", "test_data_loader", "(", "self", ")", ":", "\n", "\n", "        ", "TACRED_LABELS", "=", "[", "\n", "\"no_relation\"", ",", "\n", "\"org:alternate_names\"", ",", "\n", "\"org:city_of_headquarters\"", ",", "\n", "\"org:country_of_headquarters\"", ",", "\n", "\"org:dissolved\"", ",", "\n", "\"org:founded\"", ",", "\n", "\"org:founded_by\"", ",", "\n", "\"org:member_of\"", ",", "\n", "\"org:members\"", ",", "\n", "\"org:number_of_employees/members\"", ",", "\n", "\"org:parents\"", ",", "\n", "\"org:political/religious_affiliation\"", ",", "\n", "\"org:shareholders\"", ",", "\n", "\"org:stateorprovince_of_headquarters\"", ",", "\n", "\"org:subsidiaries\"", ",", "\n", "\"org:top_members/employees\"", ",", "\n", "\"org:website\"", ",", "\n", "\"per:age\"", ",", "\n", "\"per:alternate_names\"", ",", "\n", "\"per:cause_of_death\"", ",", "\n", "\"per:charges\"", ",", "\n", "\"per:children\"", ",", "\n", "\"per:cities_of_residence\"", ",", "\n", "\"per:city_of_birth\"", ",", "\n", "\"per:city_of_death\"", ",", "\n", "\"per:countries_of_residence\"", ",", "\n", "\"per:country_of_birth\"", ",", "\n", "\"per:country_of_death\"", ",", "\n", "\"per:date_of_birth\"", ",", "\n", "\"per:date_of_death\"", ",", "\n", "\"per:employee_of\"", ",", "\n", "\"per:origin\"", ",", "\n", "\"per:other_family\"", ",", "\n", "\"per:parents\"", ",", "\n", "\"per:religion\"", ",", "\n", "\"per:schools_attended\"", ",", "\n", "\"per:siblings\"", ",", "\n", "\"per:spouse\"", ",", "\n", "\"per:stateorprovince_of_birth\"", ",", "\n", "\"per:stateorprovince_of_death\"", ",", "\n", "\"per:stateorprovinces_of_residence\"", ",", "\n", "\"per:title\"", ",", "\n", "]", "\n", "\n", "# Test class creation without errors", "\n", "dataset", "=", "TACREDRelationClassificationDataset", "(", "\"data/tacred/dev.json\"", ",", "labels", "=", "TACRED_LABELS", ")", "\n", "\n", "# Test instance class is the correct", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "dataset", "[", "0", "]", ",", "TACREDFeatures", ")", ")", "\n", "\n", "# Test that instances are loaded correctly", "\n", "self", ".", "assertTrue", "(", "dataset", "[", "0", "]", ".", "label", "==", "\"per:title\"", ")", "\n", "\n", "# Test that above is true for all the instances", "\n", "task", "=", "TACREDRelationClassificationTask", "(", "TACRED_LABELS", ",", "{", "\"per:title\"", ":", "[", "\"{subj} is also known as {obj}\"", "]", "}", ",", "None", ")", "\n", "\n", "task", ".", "assert_features_class", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_data.TestWikiEventsDatasets.test_data_loader": [[85, 105], ["unittest.skipIf", "a2t.data.WikiEventsArgumentClassificationDataset", "test_data.TestWikiEventsDatasets.assertTrue", "test_data.TestWikiEventsDatasets.assertTrue", "a2t.tasks.tuple_classification.EventArgumentClassificationTask", "a2t.tasks.tuple_classification.EventArgumentClassificationTask.assert_features_class", "isinstance", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class"], ["@", "unittest", ".", "skipIf", "(", "not", "os", ".", "path", ".", "exists", "(", "\"data/wikievents/dev.jsonl\"", ")", ",", "\"No WikiEvents data available at data/wikievents/\"", ")", "\n", "def", "test_data_loader", "(", "self", ")", ":", "\n", "\n", "        ", "WikiEvents_LABELS", "=", "[", "\"Victim\"", ",", "\"no_relation\"", "]", "\n", "\n", "# Test class creation without errors", "\n", "dataset", "=", "WikiEventsArgumentClassificationDataset", "(", "\"data/wikievents/dev.jsonl\"", ",", "labels", "=", "WikiEvents_LABELS", ")", "\n", "\n", "# Test instance class is the correct", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "dataset", "[", "0", "]", ",", "EventArgumentClassificationFeatures", ")", ")", "\n", "\n", "# Test that instances are loaded correctly", "\n", "self", ".", "assertTrue", "(", "dataset", "[", "0", "]", ".", "label", "==", "\"Victim\"", ")", "\n", "\n", "# Test that above is true for all the instances", "\n", "task", "=", "EventArgumentClassificationTask", "(", "\n", "\"WikiEvents EAE\"", ",", "labels", "=", "WikiEvents_LABELS", ",", "templates", "=", "{", "\"Victim\"", ":", "[", "\"{arg} is a victim.\"", "]", "}", "\n", ")", "\n", "\n", "task", ".", "assert_features_class", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_data.TestACEDatasets.test_data_loader": [[110, 130], ["unittest.skipIf", "a2t.data.ACEArgumentClassificationDataset", "test_data.TestACEDatasets.assertTrue", "test_data.TestACEDatasets.assertTrue", "a2t.tasks.tuple_classification.EventArgumentClassificationTask", "a2t.tasks.tuple_classification.EventArgumentClassificationTask.assert_features_class", "isinstance", "os.path.exists"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tasks.base.Task.assert_features_class"], ["@", "unittest", ".", "skipIf", "(", "not", "os", ".", "path", ".", "exists", "(", "\"data/ace/dev.oneie.json\"", ")", ",", "\"No WikiEvents data available at data/ace/\"", ")", "\n", "def", "test_data_loader", "(", "self", ")", ":", "\n", "\n", "        ", "ACE_LABELS", "=", "[", "\"Artifact\"", ",", "\"no_relation\"", "]", "\n", "\n", "# Test class creation without errors", "\n", "dataset", "=", "ACEArgumentClassificationDataset", "(", "\"data/ace/dev.oneie.json\"", ",", "labels", "=", "ACE_LABELS", ")", "\n", "\n", "# Test instance class is the correct", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "dataset", "[", "0", "]", ",", "EventArgumentClassificationFeatures", ")", ")", "\n", "\n", "# Test that instances are loaded correctly", "\n", "self", ".", "assertTrue", "(", "dataset", "[", "0", "]", ".", "label", "==", "\"Artifact\"", ")", "\n", "\n", "# Test that above is true for all the instances", "\n", "task", "=", "EventArgumentClassificationTask", "(", "\n", "\"WikiEvents EAE\"", ",", "labels", "=", "ACE_LABELS", ",", "templates", "=", "{", "\"Artifact\"", ":", "[", "\"{arg} is an artifact.\"", "]", "}", "\n", ")", "\n", "\n", "task", ".", "assert_features_class", "(", "dataset", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.tests.test_inference.TestEntailmentModel.test_load_model": [[12, 34], ["a2t.tasks.text_classification.TopicClassificationTask", "a2t.base.EntailmentClassifier", "a2t.base.EntailmentClassifier.", "zip", "a2t.tasks.text_classification.TopicClassificationFeatures", "test_inference.TestEntailmentModel.assertEqual", "test_inference.TestEntailmentModel.assertAlmostEqual"], "methods", ["None"], ["    ", "def", "test_load_model", "(", "self", ")", ":", "\n", "\n", "# Create a task", "\n", "        ", "task", "=", "TopicClassificationTask", "(", "\n", "\"DummyTopic task\"", ",", "labels", "=", "[", "\"politics\"", ",", "\"culture\"", ",", "\"economy\"", ",", "\"biology\"", ",", "\"legal\"", ",", "\"medicine\"", ",", "\"business\"", "]", "\n", ")", "\n", "\n", "features", "=", "[", "\n", "TopicClassificationFeatures", "(", "\n", "context", "=", "\"hospital: a health facility where patients receive treatment.\"", ",", "label", "=", "\"medicine\"", "\n", ")", "\n", "]", "\n", "\n", "nlp", "=", "EntailmentClassifier", "(", "use_tqdm", "=", "False", ")", "\n", "\n", "preds", "=", "nlp", "(", "task", "=", "task", ",", "features", "=", "features", ",", "negative_threshold", "=", "0.0", ",", "return_confidences", "=", "True", ",", "return_labels", "=", "True", ",", "topk", "=", "3", ")", "\n", "\n", "for", "(", "pred_label", ",", "pred_prob", ")", ",", "(", "gold_label", ",", "gold_prob", ")", "in", "zip", "(", "\n", "preds", "[", "0", "]", ",", "[", "(", "\"medicine\"", ",", "0.8547821", ")", ",", "(", "\"biology\"", ",", "0.036895804", ")", ",", "(", "\"business\"", ",", "0.032091234", ")", "]", "\n", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "pred_label", ",", "gold_label", ")", "\n", "self", ".", "assertAlmostEqual", "(", "pred_prob", ",", "gold_prob", ",", "places", "=", "2", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.base.Dataset.__init__": [[12, 21], ["list.__init__", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["    ", "from", "tqdm", "import", "tqdm", "\n", "\n", "_use_tqdm", "=", "True", "\n", "", "except", "ImportError", ":", "\n", "    ", "_use_tqdm", "=", "False", "\n", "\n", "", "from", "transformers", "import", "AutoConfig", ",", "AutoTokenizer", ",", "AutoModelForSequenceClassification", "\n", "\n", "from", ".", "tasks", "import", "Features", ",", "Task", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.base.Dataset.labels": [[22, 28], ["hasattr", "numpy.asarray"], "methods", ["None"], ["try", ":", "\n", "    ", "import", "transformers", "\n", "\n", "transformers", ".", "logging", ".", "set_verbosity_error", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.babeldomains.BabelDomainsTopicClassificationDataset.__init__": [[13, 25], ["base.Dataset.__init__", "open", "line.strip().split", "babeldomains.BabelDomainsTopicClassificationDataset.append", "a2t.tasks.text_classification.TopicClassificationFeatures", "line.strip"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["\"Farming\"", ",", "\n", "\"Food and drink\"", ",", "\n", "\"Games and video games\"", ",", "\n", "\"Geography and places\"", ",", "\n", "\"Geology and geophysics\"", ",", "\n", "\"Health and medicine\"", ",", "\n", "\"Heraldry, honors, and vexillology\"", ",", "\n", "\"History\"", ",", "\n", "\"Language and linguistics\"", ",", "\n", "\"Law and crime\"", ",", "\n", "\"Literature and theatre\"", ",", "\n", "\"Mathematics\"", ",", "\n", "\"Media\"", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.tacred.TACREDRelationClassificationDataset.__init__": [[14, 43], ["base.Dataset.__init__", "open", "enumerate", "json.load", "tacred.TACREDRelationClassificationDataset.append", "a2t.tasks.tuple_classification.TACREDFeatures"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["\"org:dissolved\"", ",", "\n", "\"org:founded\"", ",", "\n", "\"org:founded_by\"", ",", "\n", "\"org:member_of\"", ",", "\n", "\"org:members\"", ",", "\n", "\"org:number_of_employees/members\"", ",", "\n", "\"org:parents\"", ",", "\n", "\"org:political/religious_affiliation\"", ",", "\n", "\"org:shareholders\"", ",", "\n", "\"org:stateorprovince_of_headquarters\"", ",", "\n", "\"org:subsidiaries\"", ",", "\n", "\"org:top_members/employees\"", ",", "\n", "\"org:website\"", ",", "\n", "\"per:age\"", ",", "\n", "\"per:alternate_names\"", ",", "\n", "\"per:cause_of_death\"", ",", "\n", "\"per:charges\"", ",", "\n", "\"per:children\"", ",", "\n", "\"per:cities_of_residence\"", ",", "\n", "\"per:city_of_birth\"", ",", "\n", "\"per:city_of_death\"", ",", "\n", "\"per:countries_of_residence\"", ",", "\n", "\"per:country_of_birth\"", ",", "\n", "\"per:country_of_death\"", ",", "\n", "\"per:date_of_birth\"", ",", "\n", "\"per:date_of_death\"", ",", "\n", "\"per:employee_of\"", ",", "\n", "\"per:origin\"", ",", "\n", "\"per:other_family\"", ",", "\n", "\"per:parents\"", ",", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset.__init__": [[17, 20], ["base.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "self", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_nlp", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._sent_tokenize": [[21, 29], ["spacy.load", "wikievents._WikiEventsDataset._nlp"], "methods", ["None"], ["", "def", "_sent_tokenize", "(", "self", ",", "text", ",", "start_pos", ")", ":", "\n", "        ", "if", "not", "self", ".", "_nlp", ":", "\n", "            ", "import", "spacy", "\n", "\n", "self", ".", "_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n", "", "for", "sent", "in", "self", ".", "_nlp", "(", "text", ")", ".", "sents", ":", "\n", "            ", "yield", "[", "sent", "[", "0", "]", ".", "idx", "+", "start_pos", ",", "sent", ".", "text", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._find_subsentence": [[30, 34], ["next", "sentences.copy", "enumerate", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_find_subsentence", "(", "offset", ",", "sentences", ")", ":", "\n", "        ", "sentences_", "=", "sentences", ".", "copy", "(", ")", "+", "[", "(", "sentences", "[", "-", "1", "]", "[", "0", "]", "+", "len", "(", "sentences", "[", "-", "1", "]", "[", "1", "]", ")", "+", "1", ",", "\"\"", ")", "]", "\n", "return", "next", "(", "(", "i", "-", "1", "for", "i", ",", "(", "idx", ",", "_", ")", "in", "enumerate", "(", "sentences_", ")", "if", "offset", "<", "idx", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._load": [[35, 132], ["open", "tqdm.tqdm.tqdm", "json.loads", "collections.defaultdict", "enumerate", "entities.values", "enumerate", "list", "enumerate", "wikievents._WikiEventsDataset._find_subsentence", "copy.deepcopy", "sentence[].find", "[].append", "wikievents._WikiEventsDataset._find_subsentence", "copy.deepcopy", "sentence[].find", "[].append", "enumerate", "wikievents._WikiEventsDataset._sent_tokenize", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._find_subsentence", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._find_subsentence", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents._WikiEventsDataset._sent_tokenize"], ["", "def", "_load", "(", "self", ",", "input_path", ":", "str", ")", "->", "Iterable", "[", "dict", "]", ":", "\n", "        ", "\"\"\"A function that loads and converts the WikiEvents dataset into sentence level.\"\"\"", "\n", "with", "open", "(", "input_path", ",", "\"rt\"", ")", "as", "data_f", ":", "\n", "            ", "for", "data_line", "in", "tqdm", "(", "data_f", ")", ":", "\n", "                ", "instance", "=", "json", ".", "loads", "(", "data_line", ")", "\n", "\n", "entities", "=", "{", "entity", "[", "\"id\"", "]", ":", "entity", "for", "entity", "in", "instance", "[", "\"entity_mentions\"", "]", "}", "\n", "tokens", "=", "[", "token", "for", "sentence", "in", "instance", "[", "\"sentences\"", "]", "for", "token", "in", "sentence", "[", "0", "]", "]", "\n", "\n", "sub_sentence_information", "=", "defaultdict", "(", "dict", ")", "\n", "all_sub_sentences", "=", "[", "list", "(", "self", ".", "_sent_tokenize", "(", "text", ",", "tokens", "[", "0", "]", "[", "1", "]", ")", ")", "for", "tokens", ",", "text", "in", "instance", "[", "\"sentences\"", "]", "]", "\n", "\n", "for", "i", ",", "sentences", "in", "enumerate", "(", "all_sub_sentences", ")", ":", "\n", "                    ", "for", "j", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                        ", "sub_sentence_information", "[", "f\"{i}-{j}\"", "]", "[", "\"text\"", "]", "=", "sent", "[", "-", "1", "]", "\n", "\n", "", "", "for", "value", "in", "entities", ".", "values", "(", ")", ":", "\n", "                    ", "sent_idx", "=", "value", "[", "\"sent_idx\"", "]", "\n", "sub_sent_idx", "=", "self", ".", "_find_subsentence", "(", "tokens", "[", "value", "[", "\"start\"", "]", "]", "[", "1", "]", ",", "all_sub_sentences", "[", "sent_idx", "]", ")", "\n", "\n", "sentence", "=", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"text\"", "]", "\n", "\n", "new_value", "=", "deepcopy", "(", "value", ")", "\n", "new_value", "[", "\"start\"", "]", "=", "tokens", "[", "value", "[", "\"start\"", "]", "]", "[", "1", "]", "-", "all_sub_sentences", "[", "sent_idx", "]", "[", "sub_sent_idx", "]", "[", "0", "]", "\n", "# Fix start if needed", "\n", "_shift", "=", "sentence", "[", "new_value", "[", "\"start\"", "]", ":", "]", ".", "find", "(", "new_value", "[", "\"text\"", "]", ")", "\n", "if", "_shift", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "elif", "_shift", ">", "0", ":", "\n", "                        ", "new_value", "[", "\"start\"", "]", "+=", "_shift", "\n", "\n", "# new_value[\"end\"] = tokens[value[\"end\"] - 1][-1] - all_sub_sentences[sent_idx][sub_sent_idx][0]", "\n", "", "new_value", "[", "\"end\"", "]", "=", "new_value", "[", "\"start\"", "]", "+", "len", "(", "new_value", "[", "\"text\"", "]", ")", "\n", "\n", "assert", "(", "\n", "sentence", "[", "new_value", "[", "\"start\"", "]", ":", "new_value", "[", "\"end\"", "]", "]", "==", "new_value", "[", "\"text\"", "]", "\n", ")", ",", "f\"{sentence[new_value['start']:new_value['end']]}|{new_value['text']}\"", "\n", "\n", "if", "\"entity_mentions\"", "not", "in", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", ":", "\n", "                        ", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"entity_mentions\"", "]", "=", "[", "]", "\n", "\n", "", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"entity_mentions\"", "]", ".", "append", "(", "new_value", ")", "\n", "\n", "", "for", "event", "in", "instance", "[", "\"event_mentions\"", "]", ":", "\n", "                    ", "sent_idx", "=", "event", "[", "\"trigger\"", "]", "[", "\"sent_idx\"", "]", "\n", "sub_sent_idx", "=", "self", ".", "_find_subsentence", "(", "tokens", "[", "event", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "]", "[", "1", "]", ",", "all_sub_sentences", "[", "sent_idx", "]", ")", "\n", "\n", "sentence", "=", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"text\"", "]", "\n", "\n", "new_value", "=", "deepcopy", "(", "event", ")", "\n", "new_value", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "=", "(", "\n", "tokens", "[", "event", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "]", "[", "1", "]", "-", "all_sub_sentences", "[", "sent_idx", "]", "[", "sub_sent_idx", "]", "[", "0", "]", "\n", ")", "\n", "# Fix start if needed", "\n", "_shift", "=", "sentence", "[", "new_value", "[", "\"trigger\"", "]", "[", "\"start\"", "]", ":", "]", ".", "find", "(", "new_value", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ")", "\n", "if", "_shift", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "elif", "_shift", ">", "0", ":", "\n", "                        ", "new_value", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "+=", "_shift", "\n", "# new_value[\"trigger\"][\"end\"] = (", "\n", "#     tokens[event[\"trigger\"][\"end\"] - 1][-1] - all_sub_sentences[sent_idx][sub_sent_idx][0]", "\n", "# )", "\n", "", "new_value", "[", "\"trigger\"", "]", "[", "\"end\"", "]", "=", "new_value", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "+", "len", "(", "new_value", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ")", "\n", "\n", "sent_entities", "=", "(", "\n", "{", "ent", "[", "\"id\"", "]", "for", "ent", "in", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"entity_mentions\"", "]", "}", "\n", "if", "\"entity_mentions\"", "in", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "\n", "else", "{", "}", "\n", ")", "\n", "\n", "for", "argument", "in", "new_value", "[", "\"arguments\"", "]", ":", "\n", "                        ", "if", "not", "argument", "[", "\"entity_id\"", "]", "in", "sent_entities", ":", "\n", "                            ", "argument", "[", "\"role\"", "]", "=", "f\"[OOR]_{argument['role']}\"", "\n", "\n", "", "", "assert", "(", "\n", "sentence", "[", "new_value", "[", "\"trigger\"", "]", "[", "\"start\"", "]", ":", "new_value", "[", "\"trigger\"", "]", "[", "\"end\"", "]", "]", "==", "new_value", "[", "\"trigger\"", "]", "[", "\"text\"", "]", "\n", ")", ",", "f\"{sentence[new_value['trigger']['start']:new_value['trigger']['end']]}|{new_value['trigger']['text']}\"", "\n", "\n", "if", "\"event_mentions\"", "not", "in", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", ":", "\n", "                        ", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"event_mentions\"", "]", "=", "[", "]", "\n", "\n", "", "sub_sentence_information", "[", "f\"{sent_idx}-{sub_sent_idx}\"", "]", "[", "\"event_mentions\"", "]", ".", "append", "(", "new_value", ")", "\n", "\n", "", "for", "i", ",", "sentences", "in", "enumerate", "(", "all_sub_sentences", ")", ":", "\n", "                    ", "for", "j", ",", "_", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                        ", "info", "=", "sub_sentence_information", "[", "f\"{i}-{j}\"", "]", "\n", "info", "[", "\"doc_id\"", "]", "=", "f\"{instance['doc_id']}_{i}_{j}\"", "\n", "\n", "if", "\"entity_mentions\"", "not", "in", "info", "and", "\"event_mentions\"", "not", "in", "info", "and", "len", "(", "info", "[", "\"text\"", "]", ")", "<=", "25", ":", "\n", "                            ", "continue", "\n", "\n", "", "if", "\"entity_mentions\"", "not", "in", "info", ":", "\n", "                            ", "info", "[", "\"entity_mentions\"", "]", "=", "[", "]", "\n", "", "if", "\"event_mentions\"", "not", "in", "info", ":", "\n", "                            ", "info", "[", "\"event_mentions\"", "]", "=", "[", "]", "\n", "\n", "", "yield", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents.WikiEventsEventClassificationDataset.__init__": [[135, 149], ["wikievents._WikiEventsDataset.__init__", "wikievents.WikiEventsEventClassificationDataset._load", "wikievents.WikiEventsEventClassificationDataset.append", "a2t.tasks.text_classification.TextClassificationFeatures", "event[].split"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load"], ["    ", "def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts WikiEvents data files into a list of `a2t.tasks.TextClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "            ", "self", ".", "append", "(", "\n", "TextClassificationFeatures", "(", "\n", "context", "=", "instance", "[", "\"text\"", "]", ",", "\n", "label", "=", "[", "\".\"", ".", "join", "(", "event", "[", "\"event_type\"", "]", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "for", "event", "in", "instance", "[", "\"event_mentions\"", "]", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents.WikiEventsEntityClassificationDataset.__init__": [[154, 187], ["wikievents._WikiEventsDataset.__init__", "wikievents.WikiEventsEntityClassificationDataset._load", "spacy.load", "copy.deepcopy", "sorted", "sorted", "wikievents.WikiEventsEntityClassificationDataset.append", "a2t.tasks.span_classification.NamedEntityClassificationFeatures", "wikievents.WikiEventsEntityClassificationDataset._nlp"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load"], ["    ", "def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts WikiEvents data files into a list of `a2t.tasks.NamedEntityClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "not", "self", ".", "_nlp", ":", "\n", "            ", "import", "spacy", "\n", "\n", "self", ".", "_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n", "", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "            ", "text", "=", "deepcopy", "(", "instance", "[", "\"text\"", "]", ")", "\n", "chunks", "=", "sorted", "(", "[", "[", "chunk", ".", "start_char", ",", "chunk", ".", "end_char", ",", "chunk", ".", "text", ",", "None", "]", "for", "chunk", "in", "self", ".", "_nlp", "(", "text", ")", ".", "noun_chunks", "]", ")", "\n", "for", "entity", "in", "sorted", "(", "instance", "[", "\"entity_mentions\"", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"start\"", "]", ")", ":", "\n", "                ", "for", "chunk", "in", "chunks", ":", "\n", "# If entity is inside the chunk", "\n", "                    ", "if", "entity", "[", "\"start\"", "]", ">=", "chunk", "[", "0", "]", "and", "entity", "[", "\"end\"", "]", "<=", "chunk", "[", "1", "]", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "# Chunk is inside the entity", "\n", "", "elif", "chunk", "[", "0", "]", ">=", "entity", "[", "\"start\"", "]", "and", "chunk", "[", "1", "]", "<=", "entity", "[", "\"end\"", "]", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "# The head of the entity matches the head of the chunk", "\n", "", "elif", "chunk", "[", "1", "]", "==", "entity", "[", "\"end\"", "]", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "", "for", "chunk", "in", "chunks", ":", "\n", "                ", "self", ".", "append", "(", "NamedEntityClassificationFeatures", "(", "context", "=", "text", ",", "label", "=", "chunk", "[", "-", "1", "]", "if", "chunk", "[", "-", "1", "]", "else", "\"O\"", ",", "X", "=", "chunk", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.wikievents.WikiEventsArgumentClassificationDataset.__init__": [[190, 253], ["wikievents._WikiEventsDataset.__init__", "wikievents.WikiEventsArgumentClassificationDataset._load", "event[].replace().split", "wikievents.WikiEventsArgumentClassificationDataset.append", "entities.remove", "wikievents.WikiEventsArgumentClassificationDataset.append", "event[].replace", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load"], ["    ", "def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "mark_trigger", ":", "bool", "=", "True", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts WikiEvents data files into a list of `a2t.tasks.EventArgumentClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "\n", "            ", "id2ent", "=", "{", "ent", "[", "\"id\"", "]", ":", "ent", "for", "ent", "in", "instance", "[", "\"entity_mentions\"", "]", "}", "\n", "for", "event", "in", "instance", "[", "\"event_mentions\"", "]", ":", "\n", "                ", "event_type", "=", "event", "[", "\"event_type\"", "]", ".", "replace", "(", "\":\"", ",", "\".\"", ")", ".", "split", "(", "\".\"", ")", "# [:-1]", "\n", "trigger_type", "=", "event_type", "[", "0", "]", "\n", "trigger_subtype", "=", "event_type", "[", "-", "2", "]", "\n", "event_type", "=", "\".\"", ".", "join", "(", "event_type", ")", "\n", "\n", "entities", "=", "{", "ent", "[", "\"id\"", "]", "for", "ent", "in", "instance", "[", "\"entity_mentions\"", "]", "}", "\n", "\n", "context", "=", "instance", "[", "\"text\"", "]", "[", ":", "]", "\n", "if", "mark_trigger", ":", "\n", "                    ", "context", "=", "(", "\n", "context", "[", ":", "event", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "]", "\n", "+", "\"[[\"", "\n", "+", "event", "[", "\"trigger\"", "]", "[", "\"text\"", "]", "\n", "+", "\"]]\"", "\n", "+", "context", "[", "event", "[", "\"trigger\"", "]", "[", "\"end\"", "]", ":", "]", "\n", ")", "\n", "\n", "", "for", "argument", "in", "event", "[", "\"arguments\"", "]", ":", "\n", "                    ", "if", "argument", "[", "\"entity_id\"", "]", "not", "in", "entities", ":", "\n", "                        ", "continue", "\n", "\n", "", "self", ".", "append", "(", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "context", ",", "\n", "trg", "=", "event", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ",", "\n", "trg_type", "=", "trigger_type", ",", "\n", "trg_subtype", "=", "trigger_subtype", ",", "\n", "inst_type", "=", "f\"{event_type}:{id2ent[argument['entity_id']]['entity_type']}\"", ",", "\n", "arg", "=", "id2ent", "[", "argument", "[", "\"entity_id\"", "]", "]", "[", "\"text\"", "]", ",", "\n", "label", "=", "argument", "[", "\"role\"", "]", "if", "not", "\"OOR\"", "in", "argument", "[", "\"role\"", "]", "else", "\"OOR\"", ",", "\n", ")", "\n", ")", "\n", "self", "[", "-", "1", "]", ".", "docid", "=", "instance", "[", "\"doc_id\"", "]", "\n", "\n", "entities", ".", "remove", "(", "argument", "[", "\"entity_id\"", "]", ")", "\n", "\n", "# Generate negative examples", "\n", "", "for", "entity", "in", "entities", ":", "\n", "                    ", "self", ".", "append", "(", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "context", ",", "\n", "trg", "=", "event", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ",", "\n", "trg_type", "=", "trigger_type", ",", "\n", "trg_subtype", "=", "trigger_subtype", ",", "\n", "inst_type", "=", "f\"{event_type}:{id2ent[entity]['entity_type']}\"", ",", "\n", "arg", "=", "id2ent", "[", "entity", "]", "[", "\"text\"", "]", ",", "\n", "label", "=", "\"no_relation\"", ",", "\n", ")", "\n", ")", "\n", "self", "[", "-", "1", "]", ".", "docid", "=", "instance", "[", "\"doc_id\"", "]", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset.__init__": [[19, 22], ["base.Dataset.__init__"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__"], ["def", "__init__", "(", "self", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "_nlp", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load": [[23, 27], ["open", "json.loads", "line.strip"], "methods", ["None"], ["", "def", "_load", "(", "self", ",", "input_path", ":", "str", ")", "->", "Iterable", "[", "dict", "]", ":", "\n", "        ", "with", "open", "(", "input_path", ",", "\"rt\"", ")", "as", "data_f", ":", "\n", "            ", "for", "line", "in", "data_f", ":", "\n", "                ", "yield", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._convert_token_ids_to_char_ids": [[28, 37], ["len", "char_ids.append"], "methods", ["None"], ["", "", "", "def", "_convert_token_ids_to_char_ids", "(", "self", ",", "instance", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "tokens", "=", "instance", "[", "\"tokens\"", "]", "\n", "prev", "=", "0", "\n", "char_ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "l", "=", "len", "(", "token", ")", "\n", "char_ids", ".", "append", "(", "(", "prev", ",", "prev", "+", "l", ")", ")", "\n", "prev", "+=", "l", "+", "1", "\n", "", "return", "{", "**", "instance", ",", "\"char_ids\"", ":", "char_ids", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEEventClassificationDataset.__init__": [[40, 53], ["ace._ACEDataset.__init__", "ace.ACEEventClassificationDataset._load", "ace.ACEEventClassificationDataset.append", "a2t.tasks.text_classification.TextClassificationFeatures"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load"], ["    ", "def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts ACE data files into a list of `a2t.tasks.TextClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "input_path", ",", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "            ", "self", ".", "append", "(", "\n", "TextClassificationFeatures", "(", "\n", "context", "=", "instance", "[", "\"sentence\"", "]", ",", "label", "=", "[", "event", "[", "\"event_type\"", "]", "for", "event", "in", "instance", "[", "\"event_mentions\"", "]", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEEntityClassificationDataset.__init__": [[58, 96], ["ace._ACEDataset.__init__", "ace.ACEEntityClassificationDataset._load", "spacy.load", "ace.ACEEntityClassificationDataset._convert_token_ids_to_char_ids", "copy.deepcopy", "sorted", "sorted", "ace.ACEEntityClassificationDataset.append", "a2t.tasks.span_classification.NamedEntityClassificationFeatures", "ace.ACEEntityClassificationDataset._nlp"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._convert_token_ids_to_char_ids"], ["    ", "def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts ACE data files into a list of `a2t.tasks.NamedEntityClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "not", "self", ".", "_nlp", ":", "\n", "            ", "import", "spacy", "\n", "\n", "self", ".", "_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "\n", "", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "            ", "instance", "=", "self", ".", "_convert_token_ids_to_char_ids", "(", "instance", ")", "\n", "\n", "text", "=", "deepcopy", "(", "instance", "[", "\"sentence\"", "]", ")", "\n", "chunks", "=", "sorted", "(", "[", "[", "chunk", ".", "start_char", ",", "chunk", ".", "end_char", ",", "chunk", ".", "text", ",", "None", "]", "for", "chunk", "in", "self", ".", "_nlp", "(", "text", ")", ".", "noun_chunks", "]", ")", "\n", "for", "entity", "in", "sorted", "(", "instance", "[", "\"entity_mentions\"", "]", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"start\"", "]", ")", ":", "\n", "                ", "start", "=", "instance", "[", "\"char_ids\"", "]", "[", "entity", "[", "\"start\"", "]", "]", "[", "0", "]", "\n", "end", "=", "instance", "[", "\"char_ids\"", "]", "[", "entity", "[", "\"end\"", "]", "-", "1", "]", "[", "1", "]", "\n", "\n", "for", "chunk", "in", "chunks", ":", "\n", "# If entity is inside the chunk", "\n", "                    ", "if", "start", ">=", "chunk", "[", "0", "]", "and", "end", "<=", "chunk", "[", "1", "]", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "# Chunk is inside the entity", "\n", "", "elif", "chunk", "[", "0", "]", ">=", "start", "and", "chunk", "[", "1", "]", "<=", "entity", "[", "\"end\"", "]", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "# The head of the entity matches the head of the chunk", "\n", "", "elif", "chunk", "[", "1", "]", "==", "end", ":", "\n", "                        ", "chunk", "[", "-", "1", "]", "=", "entity", "[", "\"entity_type\"", "]", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "", "for", "chunk", "in", "chunks", ":", "\n", "                ", "self", ".", "append", "(", "NamedEntityClassificationFeatures", "(", "context", "=", "text", ",", "label", "=", "chunk", "[", "-", "1", "]", "if", "chunk", "[", "-", "1", "]", "else", "\"O\"", ",", "X", "=", "chunk", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__": [[107, 170], ["ace._ACEDataset.__init__", "ace.ACEArgumentClassificationDataset._load", "event[].replace().split", "ace.ACEArgumentClassificationDataset.label_mapping.get", "ace.ACEArgumentClassificationDataset.append", "entities.remove", "ace.ACEArgumentClassificationDataset.append", "event[].replace", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures", "a2t.tasks.tuple_classification.EventArgumentClassificationFeatures"], "methods", ["home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace.ACEArgumentClassificationDataset.__init__", "home.repos.pwc.inspect_result.osainz59_Ask2Transformers.data.ace._ACEDataset._load"], ["def", "__init__", "(", "self", ",", "input_path", ":", "str", ",", "labels", ":", "List", "[", "str", "]", ",", "*", "args", ",", "mark_trigger", ":", "bool", "=", "True", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"This class converts ACE data files into a list of `a2t.tasks.EventArgumentClassificationFeatures`.\n\n        Args:\n            input_path (str): The path to the input file.\n            labels (List[str]): The possible label set of the dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "labels", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "instance", "in", "self", ".", "_load", "(", "input_path", ")", ":", "\n", "            ", "tokens", "=", "instance", "[", "\"tokens\"", "]", "\n", "id2ent", "=", "{", "ent", "[", "\"id\"", "]", ":", "ent", "for", "ent", "in", "instance", "[", "\"entity_mentions\"", "]", "}", "\n", "for", "event", "in", "instance", "[", "\"event_mentions\"", "]", ":", "\n", "                ", "event_type", "=", "event", "[", "\"event_type\"", "]", ".", "replace", "(", "\":\"", ",", "\".\"", ")", ".", "split", "(", "\".\"", ")", "# [:-1]", "\n", "trigger_type", ",", "trigger_subtype", "=", "event_type", "\n", "event_type", "=", "\".\"", ".", "join", "(", "event_type", ")", "\n", "\n", "entities", "=", "{", "ent", "[", "\"id\"", "]", "for", "ent", "in", "instance", "[", "\"entity_mentions\"", "]", "}", "\n", "\n", "if", "mark_trigger", ":", "\n", "                    ", "context", "=", "\" \"", ".", "join", "(", "\n", "tokens", "[", ":", "event", "[", "\"trigger\"", "]", "[", "\"start\"", "]", "]", "\n", "+", "[", "\"[[\"", "]", "\n", "+", "tokens", "[", "event", "[", "\"trigger\"", "]", "[", "\"start\"", "]", ":", "event", "[", "\"trigger\"", "]", "[", "\"end\"", "]", "]", "\n", "+", "[", "\"]]\"", "]", "\n", "+", "tokens", "[", "event", "[", "\"trigger\"", "]", "[", "\"end\"", "]", ":", "]", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "context", "=", "\" \"", ".", "join", "(", "tokens", ")", "\n", "\n", "", "for", "argument", "in", "event", "[", "\"arguments\"", "]", ":", "\n", "# Apply label mapping to sattisfy guidelines constraints", "\n", "                    ", "role", "=", "self", ".", "label_mapping", ".", "get", "(", "f'{event[\"event_type\"]}|{argument[\"role\"]}'", ",", "argument", "[", "\"role\"", "]", ")", "\n", "\n", "# Skip annotation errors", "\n", "if", "argument", "[", "\"entity_id\"", "]", "not", "in", "entities", ":", "\n", "                        ", "continue", "\n", "\n", "", "self", ".", "append", "(", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "context", ",", "\n", "trg", "=", "event", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ",", "\n", "trg_type", "=", "trigger_type", ",", "\n", "trg_subtype", "=", "trigger_subtype", ",", "\n", "inst_type", "=", "f\"{event_type}:{id2ent[argument['entity_id']]['entity_type']}\"", ",", "\n", "arg", "=", "id2ent", "[", "argument", "[", "\"entity_id\"", "]", "]", "[", "\"text\"", "]", ",", "\n", "label", "=", "role", ",", "\n", ")", "\n", ")", "\n", "\n", "entities", ".", "remove", "(", "argument", "[", "\"entity_id\"", "]", ")", "\n", "\n", "# Generate negative examples", "\n", "", "for", "entity", "in", "entities", ":", "\n", "                    ", "self", ".", "append", "(", "\n", "EventArgumentClassificationFeatures", "(", "\n", "context", "=", "context", ",", "\n", "trg", "=", "event", "[", "\"trigger\"", "]", "[", "\"text\"", "]", ",", "\n", "trg_type", "=", "trigger_type", ",", "\n", "trg_subtype", "=", "trigger_subtype", ",", "\n", "inst_type", "=", "f\"{event_type}:{id2ent[entity]['entity_type']}\"", ",", "\n", "arg", "=", "id2ent", "[", "entity", "]", "[", "\"text\"", "]", ",", "\n", "label", "=", "\"no_relation\"", ",", "\n", ")", "\n"]]}