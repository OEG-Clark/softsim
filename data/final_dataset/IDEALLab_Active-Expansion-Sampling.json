{"home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.one_circle": [[12, 20], ["numpy.array", "numpy.min", "numpy.random.binomial", "sklearn.metrics.pairwise.pairwise_distances"], "function", ["None"], ["def", "one_circle", "(", "D", ",", "p", "=", "0", ",", "s", "=", "0", ")", ":", "\n", "\n", "    ", "landmark", "=", "np", ".", "array", "(", "[", "[", "2", ",", "0", "]", "]", ")", "\n", "threshold", "=", "1.5", "\n", "L", "=", "(", "np", ".", "min", "(", "pairwise_distances", "(", "D", ",", "landmark", ")", ",", "axis", "=", "1", ")", "<", "threshold", ")", "\n", "L", "=", "L", "*", "2", "-", "1", "\n", "L", "*=", "(", "-", "1", ")", "**", "np", ".", "random", ".", "binomial", "(", "1", ",", "p", ",", "D", ".", "shape", "[", "0", "]", ")", "# add noise", "\n", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.two_circles": [[21, 30], ["numpy.array", "numpy.min", "numpy.random.binomial", "sklearn.metrics.pairwise.pairwise_distances"], "function", ["None"], ["", "def", "two_circles", "(", "D", ",", "p", "=", "0", ",", "s", "=", "0", ")", ":", "\n", "\n", "    ", "landmark", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "\n", "[", "3", ",", "0", "]", "]", ")", "\n", "threshold", "=", "1.", "\n", "L", "=", "(", "np", ".", "min", "(", "pairwise_distances", "(", "D", ",", "landmark", ")", ",", "axis", "=", "1", ")", "<", "threshold", ")", "\n", "L", "=", "L", "*", "2", "-", "1", "\n", "L", "*=", "(", "-", "1", ")", "**", "np", ".", "random", ".", "binomial", "(", "1", ",", "p", ",", "D", ".", "shape", "[", "0", "]", ")", "# add noise", "\n", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.branin": [[31, 44], ["numpy.logical_and", "numpy.logical_and", "numpy.logical_and", "numpy.random.normal", "numpy.logical_and", "numpy.random.binomial", "numpy.cos"], "function", ["None"], ["", "def", "branin", "(", "D", ",", "p", "=", "0", ",", "s", "=", "0", ",", "sigma", "=", "1.0", ")", ":", "\n", "\n", "    ", "x1", "=", "D", "[", ":", ",", "0", "]", "\n", "x2", "=", "D", "[", ":", ",", "1", "]", "\n", "g", "=", "(", "x2", "-", "5.1", "*", "x1", "**", "2", "/", "4", "/", "np", ".", "pi", "**", "2", "+", "5", "/", "np", ".", "pi", "*", "x1", "-", "6", ")", "**", "2", "+", "10", "*", "(", "1", "-", "1", "/", "8", "/", "np", ".", "pi", ")", "*", "np", ".", "cos", "(", "x1", ")", "+", "10", "# branin", "\n", "g", "+=", "s", "*", "np", ".", "random", ".", "normal", "(", "0", ",", "sigma", "**", "2", ",", "D", ".", "shape", "[", "0", "]", ")", "# add Gaussian noise", "\n", "y1", "=", "g", "<=", "8", "\n", "y2", "=", "np", ".", "logical_and", "(", "x1", ">", "-", "9", ",", "x1", "<", "14", ")", "\n", "y3", "=", "np", ".", "logical_and", "(", "x2", ">", "-", "7", ",", "x2", "<", "17", ")", "\n", "y", "=", "np", ".", "logical_and", "(", "np", ".", "logical_and", "(", "y1", ",", "y2", ")", ",", "y3", ")", "\n", "y", "=", "y", "*", "2", "-", "1", "\n", "y", "*=", "(", "-", "1", ")", "**", "np", ".", "random", ".", "binomial", "(", "1", ",", "p", ",", "D", ".", "shape", "[", "0", "]", ")", "# add Bernoulli noise", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.hosaki": [[45, 54], ["numpy.exp", "numpy.random.normal", "numpy.random.binomial", "numpy.logical_and"], "function", ["None"], ["", "def", "hosaki", "(", "D", ",", "p", "=", "0", ",", "s", "=", "0", ",", "sigma", "=", "1.0", ")", ":", "\n", "\n", "    ", "x1", "=", "D", "[", ":", ",", "0", "]", "\n", "x2", "=", "D", "[", ":", ",", "1", "]", "\n", "g", "=", "(", "1.", "-", "8.", "*", "x1", "+", "7.", "*", "x1", "**", "2.", "-", "7.", "/", "3", "*", "x1", "**", "3", "+", "x1", "**", "4", "/", "4.", ")", "*", "x2", "**", "2", "*", "np", ".", "exp", "(", "-", "x2", ")", "\n", "g", "+=", "s", "*", "np", ".", "random", ".", "normal", "(", "0", ",", "sigma", "**", "2", ",", "D", ".", "shape", "[", "0", "]", ")", "# add Gaussian noise", "\n", "y", "=", "np", ".", "logical_and", "(", "g", "<=", "-", "1.", ",", "x2", ">", "0", ")", "*", "2", "-", "1", "\n", "y", "*=", "(", "-", "1", ")", "**", "np", ".", "random", ".", "binomial", "(", "1", ",", "p", ",", "D", ".", "shape", "[", "0", "]", ")", "# add Bernoulli noise", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.beam": [[55, 74], ["numpy.logical_and.reduce"], "function", ["None"], ["", "def", "beam", "(", "D", ",", "p", "=", "0", ",", "s", "=", "0", ",", "sigma", "=", "1.0", ")", ":", "\n", "\n", "    ", "b", "=", "D", "[", ":", ",", "0", "]", "\n", "h", "=", "D", "[", ":", ",", "1", "]", "\n", "It", "=", "(", "b", "**", "3", "*", "h", "+", "b", "*", "h", "**", "3", ")", "/", "12", "\n", "Iz", "=", "b", "**", "3", "*", "h", "/", "12", "\n", "Iy", "=", "b", "*", "h", "**", "3", "/", "12", "\n", "y0", "=", "b", "*", "h", "<=", "0.0025", "# cross sectional area", "\n", "y1", "=", "5", "*", ".5", "**", "3", "/", "(", "3", "*", "216620", "*", "Iy", ")", "<=", "5", "# maximum tip deflection", "\n", "y2", "=", "6", "*", "5", "*", ".5", "/", "(", "b", "*", "h", "**", "2", ")", "<=", "240000", "# bending stress", "\n", "y3", "=", "3", "*", "5", "/", "(", "2", "*", "b", "*", "h", ")", "<=", "120000", "# shear stress", "\n", "y4", "=", "h", "/", "b", "<=", "10", "# aspect ratio", "\n", "y5", "=", "b", "/", "h", "<=", "10", "\n", "y6", "=", "4", "/", ".5", "**", "2", "*", "(", "86.65", "*", "It", "*", "216.62", "*", "Iz", "/", "(", "1", "-", ".27", "**", "2", ")", ")", "**", ".5", ">=", "2", "*", "5", "/", "1e6", "# failue force of buckling", "\n", "y7", "=", "b", ">", "0", "\n", "y8", "=", "h", ">", "0", "\n", "y", "=", "np", ".", "logical_and", ".", "reduce", "(", "(", "y0", ",", "y1", ",", "y2", ",", "y3", ",", "y4", ",", "y5", ",", "y6", ",", "y7", ",", "y8", ")", ")", "\n", "y", "=", "y", "*", "2", "-", "1", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.functions.two_spheres": [[75, 84], ["numpy.zeros", "numpy.min", "numpy.random.binomial", "sklearn.metrics.pairwise.pairwise_distances"], "function", ["None"], ["", "def", "two_spheres", "(", "D", ",", "p", "=", "0", ")", ":", "\n", "\n", "    ", "landmark", "=", "np", ".", "zeros", "(", "(", "2", ",", "D", ".", "shape", "[", "1", "]", ")", ")", "\n", "landmark", "[", "1", ",", "0", "]", "+=", "3.0", "\n", "threshold", "=", "1.", "\n", "L", "=", "np", ".", "min", "(", "pairwise_distances", "(", "D", ",", "landmark", ")", ",", "axis", "=", "1", ")", "<", "threshold", "\n", "L", "=", "L", "*", "2", "-", "1", "\n", "L", "*=", "(", "-", "1", ")", "**", "np", ".", "random", ".", "binomial", "(", "1", ",", "p", ",", "D", ".", "shape", "[", "0", "]", ")", "# add noise", "\n", "return", "L", "", "", ""]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc._BGPCL.fit": [[40, 122], ["sklearn.utils.check_random_state", "sklearn.preprocessing.LabelEncoder", "sklearn.preprocessing.LabelEncoder.fit_transform", "gpc._BGPCL.kernel_", "gpc._BGPCL._posterior_mode", "sklearn.base.clone", "numpy.copy", "ValueError", "list", "gpc._BGPCL.log_marginal_likelihood", "sklearn.gaussian_process.kernels.ConstantKernel", "sklearn.gaussian_process.kernels.RBF", "gpc._BGPCL._constrained_optimization", "range", "map", "numpy.min", "gpc._BGPCL.log_marginal_likelihood", "numpy.isfinite().all", "ValueError", "numpy.exp", "optima.append", "operator.itemgetter", "gpc._BGPCL.log_marginal_likelihood", "gpc._BGPCL.rng.uniform", "gpc._BGPCL._constrained_optimization", "numpy.argmin", "numpy.isfinite"], "methods", ["home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier._posterior_mode", "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.log_marginal_likelihood", "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.log_marginal_likelihood", "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.log_marginal_likelihood"], ["    ", "def", "fit", "(", "self", ",", "X", ",", "y", ")", ":", "\n", "        ", "\"\"\"Fit Gaussian process classification model\n\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n            Training data\n\n        y : array-like, shape = (n_samples,)\n            Target values, must be binary\n\n        Returns\n        -------\n        self : returns an instance of self.\n        \"\"\"", "\n", "if", "self", ".", "kernel", "is", "None", ":", "# Use an RBF kernel as default", "\n", "            ", "self", ".", "kernel_", "=", "C", "(", "1.0", ",", "constant_value_bounds", "=", "\"fixed\"", ")", "*", "RBF", "(", "1.0", ",", "length_scale_bounds", "=", "\"fixed\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "kernel_", "=", "clone", "(", "self", ".", "kernel", ")", "\n", "\n", "", "self", ".", "rng", "=", "check_random_state", "(", "self", ".", "random_state", ")", "\n", "\n", "self", ".", "X_train_", "=", "np", ".", "copy", "(", "X", ")", "if", "self", ".", "copy_X_train", "else", "X", "\n", "\n", "# Encode class labels and check that it is a binary classification", "\n", "# problem", "\n", "label_encoder", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "y_train_", "=", "label_encoder", ".", "fit_transform", "(", "y", ")", "\n", "self", ".", "classes_", "=", "label_encoder", ".", "classes_", "\n", "if", "self", ".", "classes_", ".", "size", ">", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"%s supports only binary classification. \"", "\n", "\"y contains classes %s\"", "\n", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "classes_", ")", ")", "\n", "\n", "", "if", "self", ".", "optimizer", "is", "not", "None", "and", "self", ".", "kernel_", ".", "n_dims", ">", "0", ":", "\n", "# Choose hyperparameters based on maximizing the log-marginal", "\n", "# likelihood (potentially starting from several initial values)", "\n", "            ", "def", "obj_func", "(", "theta", ",", "eval_gradient", "=", "True", ")", ":", "\n", "                ", "if", "eval_gradient", ":", "\n", "                    ", "lml", ",", "grad", "=", "self", ".", "log_marginal_likelihood", "(", "\n", "theta", ",", "eval_gradient", "=", "True", ")", "\n", "return", "-", "lml", ",", "-", "grad", "\n", "", "else", ":", "\n", "                    ", "return", "-", "self", ".", "log_marginal_likelihood", "(", "theta", ")", "\n", "\n", "# First optimize starting from theta specified in kernel", "\n", "", "", "optima", "=", "[", "self", ".", "_constrained_optimization", "(", "obj_func", ",", "\n", "self", ".", "kernel_", ".", "theta", ",", "\n", "self", ".", "kernel_", ".", "bounds", ")", "]", "\n", "\n", "# Additional runs are performed from log-uniform chosen initial", "\n", "# theta", "\n", "if", "self", ".", "n_restarts_optimizer", ">", "0", ":", "\n", "                ", "if", "not", "np", ".", "isfinite", "(", "self", ".", "kernel_", ".", "bounds", ")", ".", "all", "(", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Multiple optimizer restarts (n_restarts_optimizer>0) \"", "\n", "\"requires that all bounds are finite.\"", ")", "\n", "", "bounds", "=", "self", ".", "kernel_", ".", "bounds", "\n", "for", "iteration", "in", "range", "(", "self", ".", "n_restarts_optimizer", ")", ":", "\n", "                    ", "theta_initial", "=", "np", ".", "exp", "(", "self", ".", "rng", ".", "uniform", "(", "bounds", "[", ":", ",", "0", "]", ",", "\n", "bounds", "[", ":", ",", "1", "]", ")", ")", "\n", "optima", ".", "append", "(", "\n", "self", ".", "_constrained_optimization", "(", "obj_func", ",", "theta_initial", ",", "\n", "bounds", ")", ")", "\n", "# Select result from run with minimal (negative) log-marginal", "\n", "# likelihood", "\n", "", "", "lml_values", "=", "list", "(", "map", "(", "itemgetter", "(", "1", ")", ",", "optima", ")", ")", "\n", "self", ".", "kernel_", ".", "theta", "=", "optima", "[", "np", ".", "argmin", "(", "lml_values", ")", "]", "[", "0", "]", "\n", "self", ".", "log_marginal_likelihood_value_", "=", "-", "np", ".", "min", "(", "lml_values", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "log_marginal_likelihood_value_", "=", "self", ".", "log_marginal_likelihood", "(", "self", ".", "kernel_", ".", "theta", ")", "\n", "\n", "# Precompute quantities required for predictions which are independent", "\n", "# of actual query points", "\n", "", "K", "=", "self", ".", "kernel_", "(", "self", ".", "X_train_", ")", "\n", "\n", "_", ",", "(", "self", ".", "pi_", ",", "self", ".", "W_sr_", ",", "self", ".", "L_", ",", "_", ",", "_", ")", "=", "self", ".", "_posterior_mode", "(", "K", ",", "return_temporaries", "=", "True", ")", "\n", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.predict_proba": [[126, 166], ["sklearn.utils.validation.check_is_fitted", "gpc.GPClassifier.kernel_", "gpc.GPClassifier.T.dot", "scipy.linalg.solve", "gpc.GPClassifier.kernel_.diag", "numpy.einsum", "numpy.vstack", "numpy.sqrt", "scipy.special.erf", "numpy.sqrt", "COEFS.sum", "numpy.sqrt"], "methods", ["None"], ["    ", "def", "predict_proba", "(", "self", ",", "X", ",", "get_var", "=", "False", ")", ":", "\n", "        ", "\"\"\"Return probability estimates for the test vector X.\n        Parameters\n        ----------\n        X : array-like, shape = (n_samples, n_features)\n        Returns\n        -------\n        C : array-like, shape = (n_samples, n_classes)\n            Returns the probability of the samples for each class in\n            the model. The columns correspond to the classes in sorted\n            order, as they appear in the attribute ``classes_``.\n        \"\"\"", "\n", "check_is_fitted", "(", "self", ",", "[", "\"X_train_\"", ",", "\"y_train_\"", ",", "\"pi_\"", ",", "\"W_sr_\"", ",", "\"L_\"", "]", ")", "\n", "\n", "# Based on Algorithm 3.2 of GPML", "\n", "K_star", "=", "self", ".", "kernel_", "(", "self", ".", "X_train_", ",", "X", ")", "# K_star =k(x_star)", "\n", "f_star", "=", "K_star", ".", "T", ".", "dot", "(", "self", ".", "y_train_", "-", "self", ".", "pi_", ")", "# Line 4", "\n", "v", "=", "solve", "(", "self", ".", "L_", ",", "self", ".", "W_sr_", "[", ":", ",", "np", ".", "newaxis", "]", "*", "K_star", ")", "# Line 5", "\n", "\n", "# Line 6 (compute np.diag(v.T.dot(v)) via einsum)", "\n", "var_f_star", "=", "self", ".", "kernel_", ".", "diag", "(", "X", ")", "-", "np", ".", "einsum", "(", "\"ij,ij->j\"", ",", "v", ",", "v", ")", "\n", "\n", "if", "get_var", ":", "\n", "            ", "return", "f_star", ",", "var_f_star", "\n", "\n", "# Line 7:", "\n", "# Approximate \\int log(z) * N(z | f_star, var_f_star)", "\n", "# Approximation is due to Williams & Barber, \"Bayesian Classification", "\n", "# with Gaussian Processes\", Appendix A: Approximate the logistic", "\n", "# sigmoid by a linear combination of 5 error functions.", "\n", "# For information on how this integral can be computed see", "\n", "# blitiri.blogspot.de/2012/11/gaussian-integral-of-error-function.html", "\n", "", "alpha", "=", "1", "/", "(", "2", "*", "var_f_star", ")", "\n", "gamma", "=", "LAMBDAS", "*", "f_star", "\n", "integrals", "=", "np", ".", "sqrt", "(", "np", ".", "pi", "/", "alpha", ")", "*", "erf", "(", "gamma", "*", "np", ".", "sqrt", "(", "alpha", "/", "(", "alpha", "+", "LAMBDAS", "**", "2", ")", ")", ")", "/", "(", "2", "*", "np", ".", "sqrt", "(", "var_f_star", "*", "2", "*", "np", ".", "pi", ")", ")", "\n", "pi_star", "=", "(", "COEFS", "*", "integrals", ")", ".", "sum", "(", "axis", "=", "0", ")", "+", ".5", "*", "COEFS", ".", "sum", "(", ")", "\n", "\n", "return", "np", ".", "vstack", "(", "(", "1", "-", "pi_star", ",", "pi_star", ")", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.log_marginal_likelihood": [[167, 233], ["gpc.GPClassifier.kernel_.clone_with_theta", "gpc.GPClassifier._posterior_mode", "numpy.empty", "scipy.linalg.solve", "range", "gpc.GPClassifier.", "gpc.GPClassifier.", "scipy.linalg.cho_solve", "scipy.linalg.solve.dot", "ValueError", "numpy.diag", "gpc.GPClassifier.dot", "s_2.T.dot", "numpy.diag", "numpy.einsum", "a.T.dot().dot", "R.T.ravel().dot", "R.dot", "scipy.linalg.solve.ravel", "a.T.dot", "R.T.ravel"], "methods", ["home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier._posterior_mode"], ["", "def", "log_marginal_likelihood", "(", "self", ",", "theta", "=", "None", ",", "eval_gradient", "=", "False", ")", ":", "\n", "        ", "\"\"\"Returns log-marginal likelihood of theta for training data.\n\n        Parameters\n        ----------\n        theta : array-like, shape = (n_kernel_params,) or None\n            Kernel hyperparameters for which the log-marginal likelihood is\n            evaluated. If None, the precomputed log_marginal_likelihood\n            of ``self.kernel_.theta`` is returned.\n\n        eval_gradient : bool, default: False\n            If True, the gradient of the log-marginal likelihood with respect\n            to the kernel hyperparameters at position theta is returned\n            additionally. If True, theta must not be None.\n\n        Returns\n        -------\n        log_likelihood : float\n            Log-marginal likelihood of theta for training data.\n\n        log_likelihood_gradient : array, shape = (n_kernel_params,), optional\n            Gradient of the log-marginal likelihood with respect to the kernel\n            hyperparameters at position theta.\n            Only returned when eval_gradient is True.\n        \"\"\"", "\n", "if", "theta", "is", "None", ":", "\n", "            ", "if", "eval_gradient", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Gradient can only be evaluated for theta!=None\"", ")", "\n", "", "return", "self", ".", "log_marginal_likelihood_value_", "\n", "\n", "", "kernel", "=", "self", ".", "kernel_", ".", "clone_with_theta", "(", "theta", ")", "\n", "\n", "if", "eval_gradient", ":", "\n", "            ", "K", ",", "K_gradient", "=", "kernel", "(", "self", ".", "X_train_", ",", "eval_gradient", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "K", "=", "kernel", "(", "self", ".", "X_train_", ")", "\n", "\n", "# Compute log-marginal-likelihood Z and also store some temporaries", "\n", "# which can be reused for computing Z's gradient", "\n", "", "Z", ",", "(", "pi", ",", "W_sr", ",", "L", ",", "b", ",", "a", ")", "=", "self", ".", "_posterior_mode", "(", "K", ",", "return_temporaries", "=", "True", ")", "\n", "\n", "if", "not", "eval_gradient", ":", "\n", "            ", "return", "Z", "\n", "\n", "# Compute gradient based on Algorithm 5.1 of GPML", "\n", "", "d_Z", "=", "np", ".", "empty", "(", "theta", ".", "shape", "[", "0", "]", ")", "\n", "# XXX: Get rid of the np.diag() in the next line", "\n", "R", "=", "W_sr", "[", ":", ",", "np", ".", "newaxis", "]", "*", "cho_solve", "(", "(", "L", ",", "True", ")", ",", "np", ".", "diag", "(", "W_sr", ")", ")", "# Line 7", "\n", "C", "=", "solve", "(", "L", ",", "W_sr", "[", ":", ",", "np", ".", "newaxis", "]", "*", "K", ")", "# Line 8", "\n", "# Line 9: (use einsum to compute np.diag(C.T.dot(C))))", "\n", "s_2", "=", "-", "0.5", "*", "(", "np", ".", "diag", "(", "K", ")", "-", "np", ".", "einsum", "(", "'ij, ij -> j'", ",", "C", ",", "C", ")", ")", "*", "(", "pi", "*", "(", "1", "-", "pi", ")", "*", "(", "1", "-", "2", "*", "pi", ")", ")", "# third derivative", "\n", "\n", "for", "j", "in", "range", "(", "d_Z", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "C", "=", "K_gradient", "[", ":", ",", ":", ",", "j", "]", "# Line 11", "\n", "# Line 12: (R.T.ravel().dot(C.ravel()) = np.trace(R.dot(C)))", "\n", "s_1", "=", ".5", "*", "a", ".", "T", ".", "dot", "(", "C", ")", ".", "dot", "(", "a", ")", "-", ".5", "*", "R", ".", "T", ".", "ravel", "(", ")", ".", "dot", "(", "C", ".", "ravel", "(", ")", ")", "\n", "\n", "b", "=", "C", ".", "dot", "(", "self", ".", "y_train_", "-", "pi", ")", "# Line 13", "\n", "s_3", "=", "b", "-", "K", ".", "dot", "(", "R", ".", "dot", "(", "b", ")", ")", "# Line 14", "\n", "\n", "d_Z", "[", "j", "]", "=", "s_1", "+", "s_2", ".", "T", ".", "dot", "(", "s_3", ")", "# Line 15", "\n", "\n", "", "return", "Z", ",", "d_Z", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier._posterior_mode": [[234, 286], ["range", "hasattr", "numpy.zeros_like", "numpy.sqrt", "scipy.linalg.cholesky", "K.dot", "numpy.eye", "numpy.log().sum", "numpy.exp", "scipy.linalg.cho_solve", "numpy.log().sum", "W_sr_K.dot", "a.T.dot", "numpy.log", "numpy.log", "numpy.diag", "numpy.exp"], "methods", ["None"], ["", "def", "_posterior_mode", "(", "self", ",", "K", ",", "return_temporaries", "=", "False", ")", ":", "\n", "        ", "\"\"\"Mode-finding for binary Laplace GPC and fixed kernel.\n\n        This approximates the posterior of the latent function values for given\n        inputs and target observations with a Gaussian approximation and uses\n        Newton's iteration to find the mode of this approximation.\n        \"\"\"", "\n", "# Based on Algorithm 3.1 of GPML", "\n", "\n", "# If warm_start are enabled, we reuse the last solution for the", "\n", "# posterior mode as initialization; otherwise, we initialize with 0", "\n", "if", "self", ".", "warm_start", "and", "hasattr", "(", "self", ",", "\"f_cached\"", ")", "and", "self", ".", "f_cached", ".", "shape", "==", "self", ".", "y_train_", ".", "shape", ":", "\n", "            ", "f", "=", "self", ".", "f_cached", "\n", "", "else", ":", "\n", "            ", "f", "=", "np", ".", "zeros_like", "(", "self", ".", "y_train_", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "# Use Newton's iteration method to find mode of Laplace approximation", "\n", "", "log_marginal_likelihood", "=", "-", "np", ".", "inf", "\n", "for", "_", "in", "range", "(", "self", ".", "max_iter_predict", ")", ":", "\n", "# Line 4", "\n", "            ", "pi", "=", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "f", ")", ")", "\n", "W", "=", "pi", "*", "(", "1", "-", "pi", ")", "\n", "# Line 5", "\n", "W_sr", "=", "np", ".", "sqrt", "(", "W", ")", "\n", "W_sr_K", "=", "W_sr", "[", ":", ",", "np", ".", "newaxis", "]", "*", "K", "\n", "B", "=", "np", ".", "eye", "(", "W", ".", "shape", "[", "0", "]", ")", "+", "W_sr_K", "*", "W_sr", "\n", "L", "=", "cholesky", "(", "B", ",", "lower", "=", "True", ")", "\n", "# Line 6", "\n", "b", "=", "W", "*", "f", "+", "(", "self", ".", "y_train_", "-", "pi", ")", "\n", "# Line 7", "\n", "a", "=", "b", "-", "W_sr", "*", "cho_solve", "(", "(", "L", ",", "True", ")", ",", "W_sr_K", ".", "dot", "(", "b", ")", ")", "\n", "# Line 8", "\n", "f", "=", "K", ".", "dot", "(", "a", ")", "\n", "\n", "# Line 10: Compute log marginal likelihood in loop and use as", "\n", "#          convergence criterion", "\n", "lml", "=", "-", "0.5", "*", "a", ".", "T", ".", "dot", "(", "f", ")", "-", "np", ".", "log", "(", "1", "+", "np", ".", "exp", "(", "-", "(", "self", ".", "y_train_", "*", "2", "-", "1", ")", "*", "f", ")", ")", ".", "sum", "(", ")", "-", "np", ".", "log", "(", "np", ".", "diag", "(", "L", ")", ")", ".", "sum", "(", ")", "\n", "# Check if we have converged (log marginal likelihood does", "\n", "# not decrease)", "\n", "# XXX: more complex convergence criterion", "\n", "if", "lml", "-", "log_marginal_likelihood", "<", "1e-10", ":", "\n", "                ", "break", "\n", "", "log_marginal_likelihood", "=", "lml", "\n", "\n", "", "self", ".", "f_cached", "=", "f", "# Remember solution for later warm-starts", "\n", "if", "return_temporaries", ":", "\n", "            ", "return", "log_marginal_likelihood", ",", "(", "pi", ",", "W_sr", ",", "L", ",", "b", ",", "a", ")", "\n", "", "else", ":", "\n", "            ", "return", "log_marginal_likelihood", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.predict_real": [[287, 294], ["numpy.array", "gpc.GPClassifier.predict_proba", "len", "numpy.shape", "numpy.vstack"], "methods", ["home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.predict_proba"], ["", "", "def", "predict_real", "(", "self", ",", "feature", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "feature", "=", "np", ".", "array", "(", "feature", ")", "\n", "dvalue", "=", "self", ".", "predict_proba", "(", "feature", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "if", "len", "(", "np", ".", "shape", "(", "dvalue", ")", ")", "==", "1", ":", "# n_classes == 2", "\n", "            ", "return", "np", ".", "vstack", "(", "(", "-", "dvalue", ",", "dvalue", ")", ")", ".", "T", "\n", "", "else", ":", "\n", "            ", "return", "dvalue", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.predict_mean_var": [[295, 298], ["numpy.array", "gpc.GPClassifier.predict_proba"], "methods", ["home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.predict_proba"], ["", "", "def", "predict_mean_var", "(", "self", ",", "feature", ",", "K_star", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "feature", "=", "np", ".", "array", "(", "feature", ")", "\n", "return", "self", ".", "predict_proba", "(", "feature", ",", "get_var", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.IDEALLab_Active-Expansion-Sampling.None.gpc.GPClassifier.get_mu_nu": [[299, 305], ["numpy.sign().reshape", "numpy.sign().reshape.T.dot", "scipy.linalg.solve", "numpy.einsum", "numpy.sign"], "methods", ["None"], ["", "def", "get_mu_nu", "(", "self", ")", ":", "\n", "        ", "s0", "=", "np", ".", "sign", "(", "self", ".", "y_train_", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "mu", "=", "s0", ".", "T", ".", "dot", "(", "self", ".", "y_train_", "-", "self", ".", "pi_", ")", "\n", "v", "=", "solve", "(", "self", ".", "L_", ",", "self", ".", "W_sr_", "[", ":", ",", "np", ".", "newaxis", "]", "*", "s0", ")", "\n", "nu", "=", "np", ".", "einsum", "(", "\"ij,ij->j\"", ",", "v", ",", "v", ")", "\n", "return", "mu", "[", "0", "]", ",", "nu", "[", "0", "]", "\n", "\n"]]}