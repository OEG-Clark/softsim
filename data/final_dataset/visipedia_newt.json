{"home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_newt_task": [[8, 43], ["open", "json.load", "open", "json.load", "len", "os.path.join", "train_image_fps.append", "train_labels.append", "os.path.join", "test_image_fps.append", "test_labels.append", "os.path.join", "os.path.join", "len", "len"], "function", ["None"], ["def", "load_newt_task", "(", "task_dir", ")", ":", "\n", "    ", "\"\"\" Load a NeWT binary task\n    \"\"\"", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "task_dir", ",", "\"train.json\"", ")", ")", "as", "f", ":", "\n", "        ", "train_dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "task_dir", ",", "\"test.json\"", ")", ")", "as", "f", ":", "\n", "        ", "test_dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "image_id_to_fp", "=", "{", "image", "[", "'id'", "]", ":", "image", "[", "'filename'", "]", "for", "image", "in", "train_dataset", "[", "'images'", "]", "+", "test_dataset", "[", "'images'", "]", "}", "\n", "assert", "len", "(", "image_id_to_fp", ")", "==", "len", "(", "train_dataset", "[", "'images'", "]", ")", "+", "len", "(", "test_dataset", "[", "'images'", "]", ")", ",", "\"overlapping images in %s ?\"", "%", "task_dir", "\n", "\n", "train_image_fps", "=", "[", "]", "\n", "train_labels", "=", "[", "]", "\n", "for", "anno", "in", "train_dataset", "[", "'annotations'", "]", ":", "\n", "\n", "        ", "image_fp", "=", "os", ".", "path", ".", "join", "(", "task_dir", ",", "image_id_to_fp", "[", "anno", "[", "'image_id'", "]", "]", ")", "\n", "image_label", "=", "anno", "[", "'category_id'", "]", "\n", "assert", "image_label", "in", "[", "0", ",", "1", "]", ",", "\"unexpected category id, assumed binary?\"", "\n", "\n", "train_image_fps", ".", "append", "(", "image_fp", ")", "\n", "train_labels", ".", "append", "(", "image_label", ")", "\n", "\n", "", "test_image_fps", "=", "[", "]", "\n", "test_labels", "=", "[", "]", "\n", "for", "anno", "in", "test_dataset", "[", "'annotations'", "]", ":", "\n", "\n", "        ", "image_fp", "=", "os", ".", "path", ".", "join", "(", "task_dir", ",", "image_id_to_fp", "[", "anno", "[", "'image_id'", "]", "]", ")", "\n", "image_label", "=", "anno", "[", "'category_id'", "]", "\n", "assert", "image_label", "in", "[", "0", ",", "1", "]", ",", "\"unexpected category id, assumed binary?\"", "\n", "\n", "test_image_fps", ".", "append", "(", "image_fp", ")", "\n", "test_labels", ".", "append", "(", "image_label", ")", "\n", "\n", "", "return", "train_image_fps", ",", "train_labels", ",", "test_image_fps", ",", "test_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_cub": [[44, 75], ["pandas.read_csv", "[].values.astype", "numpy.unique", "pandas.read_csv", "pandas.read_csv", "[].values.astype", "range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "pd.read_csv.set_index().loc[].reset_index", "train_paths.append", "train_classes.append", "test_paths.append", "test_classes.append", "pd.read_csv.set_index().loc[].reset_index", "[].values.astype.set_index().loc[].reset_index", "pd.read_csv.set_index", "pd.read_csv.set_index", "[].values.astype.set_index"], "function", ["None"], ["", "def", "load_cub", "(", "dataset_path", ",", "label_file_name", "=", "'image_class_labels.txt'", ")", ":", "\n", "    ", "\"\"\" Load the CUB 200 dataset\n    \"\"\"", "\n", "\n", "# load data", "\n", "data", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "label_file_name", ")", ",", "sep", "=", "' '", ",", "names", "=", "[", "'id'", ",", "'class_label'", "]", ")", "\n", "ids", "=", "data", "[", "'id'", "]", ".", "values", "\n", "labels", "=", "data", ".", "set_index", "(", "'id'", ")", ".", "loc", "[", "ids", "]", ".", "reset_index", "(", "inplace", "=", "False", ")", "[", "'class_label'", "]", ".", "values", ".", "astype", "(", "np", ".", "int", ")", "\n", "_", ",", "labels", "=", "np", ".", "unique", "(", "labels", ",", "return_inverse", "=", "True", ")", "\n", "\n", "files", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'images.txt'", ")", ",", "sep", "=", "' '", ",", "names", "=", "[", "'id'", ",", "'file'", "]", ")", "\n", "files", "=", "files", ".", "set_index", "(", "'id'", ")", ".", "loc", "[", "ids", "]", ".", "reset_index", "(", "inplace", "=", "False", ")", "[", "'file'", "]", ".", "values", "\n", "files", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'images'", ",", "ff", ")", "for", "ff", "in", "files", "]", "\n", "\n", "is_train", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'train_test_split.txt'", ")", ",", "sep", "=", "' '", ",", "names", "=", "[", "'id'", ",", "'is_train'", "]", ")", "\n", "is_train", "=", "is_train", ".", "set_index", "(", "'id'", ")", ".", "loc", "[", "ids", "]", ".", "reset_index", "(", "inplace", "=", "False", ")", "[", "'is_train'", "]", ".", "values", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "train_paths", "=", "[", "]", "\n", "train_classes", "=", "[", "]", "\n", "test_paths", "=", "[", "]", "\n", "test_classes", "=", "[", "]", "\n", "\n", "for", "ii", "in", "range", "(", "len", "(", "files", ")", ")", ":", "\n", "        ", "if", "is_train", "[", "ii", "]", "==", "1", ":", "\n", "            ", "train_paths", ".", "append", "(", "files", "[", "ii", "]", ")", "\n", "train_classes", ".", "append", "(", "labels", "[", "ii", "]", ")", "\n", "", "else", ":", "\n", "            ", "test_paths", ".", "append", "(", "files", "[", "ii", "]", ")", "\n", "test_classes", ".", "append", "(", "labels", "[", "ii", "]", ")", "\n", "\n", "", "", "return", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_oxford_flowers": [[77, 90], ["classes[].tolist", "classes[].tolist", "os.path.join", "os.path.join", "scipy.io.loadmat", "scipy.io.loadmat", "scipy.io.loadmat", "os.path.join", "os.path.join", "str().zfill", "str().zfill", "os.path.join", "str", "str"], "function", ["None"], ["", "def", "load_oxford_flowers", "(", "dataset_path", ")", ":", "\n", "\n", "    ", "classes", "=", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'imagelabels.mat'", ")", ")", "[", "'labels'", "]", "[", "0", ",", ":", "]", "-", "1", "\n", "train_ids", "=", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'setid.mat'", ")", ")", "[", "'trnid'", "]", "[", "0", ",", ":", "]", "\n", "test_ids", "=", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'setid.mat'", ")", ")", "[", "'tstid'", "]", "[", "0", ",", ":", "]", "\n", "train_paths", "=", "[", "'image_'", "+", "str", "(", "jj", ")", ".", "zfill", "(", "5", ")", "+", "'.jpg'", "for", "jj", "in", "train_ids", "]", "\n", "test_paths", "=", "[", "'image_'", "+", "str", "(", "jj", ")", ".", "zfill", "(", "5", ")", "+", "'.jpg'", "for", "jj", "in", "test_ids", "]", "\n", "train_paths", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'jpg'", ",", "jj", ")", "for", "jj", "in", "train_paths", "]", "\n", "test_paths", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'jpg'", ",", "jj", ")", "for", "jj", "in", "test_paths", "]", "\n", "train_classes", "=", "classes", "[", "train_ids", "-", "1", "]", ".", "tolist", "(", ")", "\n", "test_classes", "=", "classes", "[", "test_ids", "-", "1", "]", ".", "tolist", "(", ")", "\n", "\n", "return", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_stanford_dogs": [[92, 102], ["os.path.join", "os.path.join", "scipy.io.loadmat", "scipy.io.loadmat", "os.path.join", "os.path.join", "scipy.io.loadmat", "scipy.io.loadmat", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "load_stanford_dogs", "(", "dataset_path", ")", ":", "\n", "\n", "    ", "train_paths", "=", "[", "jj", "[", "0", "]", "[", "0", "]", "for", "jj", "in", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'train_list.mat'", ")", ")", "[", "'file_list'", "]", "]", "\n", "test_paths", "=", "[", "jj", "[", "0", "]", "[", "0", "]", "for", "jj", "in", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'test_list.mat'", ")", ")", "[", "'file_list'", "]", "]", "\n", "train_paths", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'Images'", ",", "jj", ")", "for", "jj", "in", "train_paths", "]", "\n", "test_paths", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'Images'", ",", "jj", ")", "for", "jj", "in", "test_paths", "]", "\n", "train_classes", "=", "(", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'train_list.mat'", ")", ")", "[", "'labels'", "]", "[", ":", ",", "0", "]", "-", "1", ")", ".", "tolist", "(", ")", "\n", "test_classes", "=", "(", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'test_list.mat'", ")", ")", "[", "'labels'", "]", "[", ":", ",", "0", "]", "-", "1", ")", ".", "tolist", "(", ")", "\n", "\n", "return", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_stanford_cars": [[103, 125], ["range", "str", "os.path.join", "int", "len", "scipy.io.loadmat", "int", "test_paths.append", "test_classes.append", "train_paths.append", "train_classes.append", "os.path.join"], "function", ["None"], ["", "def", "load_stanford_cars", "(", "dataset_path", ")", ":", "\n", "\n", "    ", "anns", "=", "loadmat", "(", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "'cars_annos.mat'", ")", ")", "[", "'annotations'", "]", "[", "0", "]", "\n", "im_paths", "=", "[", "str", "(", "aa", "[", "0", "]", "[", "0", "]", ")", "for", "aa", "in", "anns", "]", "\n", "im_paths", "=", "[", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "aa", ")", "for", "aa", "in", "im_paths", "]", "\n", "classes", "=", "[", "int", "(", "aa", "[", "5", "]", "[", "0", "]", "[", "0", "]", ")", "-", "1", "for", "aa", "in", "anns", "]", "\n", "is_test", "=", "[", "int", "(", "aa", "[", "6", "]", "[", "0", "]", "[", "0", "]", ")", "for", "aa", "in", "anns", "]", "\n", "\n", "train_paths", "=", "[", "]", "\n", "train_classes", "=", "[", "]", "\n", "test_paths", "=", "[", "]", "\n", "test_classes", "=", "[", "]", "\n", "\n", "for", "ii", "in", "range", "(", "len", "(", "im_paths", ")", ")", ":", "\n", "        ", "if", "is_test", "[", "ii", "]", "==", "1", ":", "\n", "            ", "test_paths", ".", "append", "(", "im_paths", "[", "ii", "]", ")", "\n", "test_classes", ".", "append", "(", "classes", "[", "ii", "]", ")", "\n", "", "else", ":", "\n", "            ", "train_paths", ".", "append", "(", "im_paths", "[", "ii", "]", ")", "\n", "train_classes", ".", "append", "(", "classes", "[", "ii", "]", ")", "\n", "\n", "", "", "return", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_dataset": [[127, 143], ["dataset_utils.load_cub", "dataset_utils.load_cub", "dataset_utils.load_cub", "dataset_utils.load_oxford_flowers", "dataset_utils.load_stanford_dogs", "dataset_utils.load_stanford_cars", "ValueError"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_cub", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_cub", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_cub", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_oxford_flowers", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_stanford_dogs", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_stanford_cars"], ["", "def", "load_dataset", "(", "dataset_name", ",", "dataset_path", ")", ":", "\n", "\n", "    ", "if", "dataset_name", "==", "'CUB'", ":", "\n", "        ", "return", "load_cub", "(", "dataset_path", ")", "\n", "", "elif", "dataset_name", "==", "'CUBExpert'", ":", "\n", "        ", "return", "load_cub", "(", "dataset_path", ",", "label_file_name", "=", "'image_class_labels_expert.txt'", ")", "\n", "", "elif", "dataset_name", "==", "'NABirds'", ":", "\n", "        ", "return", "load_cub", "(", "dataset_path", ")", "\n", "", "elif", "dataset_name", "==", "'OxfordFlowers'", ":", "\n", "        ", "return", "load_oxford_flowers", "(", "dataset_path", ")", "\n", "", "elif", "dataset_name", "==", "'StandfordDogs'", ":", "\n", "        ", "return", "load_stanford_dogs", "(", "dataset_path", ")", "\n", "", "elif", "dataset_name", "==", "'StandfordCars'", ":", "\n", "        ", "return", "load_stanford_cars", "(", "dataset_path", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown dataset name: %s\"", "%", "dataset_name", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.plot_utils.task_stem_plot": [[6, 74], ["matplotlib.pyplot.figure", "matplotlib.pyplot.title", "range", "result_df.iterrows", "matplotlib.pyplot.xticks", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "result_df.iterrows", "matplotlib.pyplot.legend", "numpy.linspace", "matplotlib.pyplot.axvspan", "matplotlib.pyplot.plot", "matplotlib.pyplot.stem", "matplotlib.pyplot.setp", "matplotlib.pyplot.setp", "matplotlib.pyplot.setp", "matplotlib.pyplot.setp", "matplotlib.pyplot.gca", "range", "legend_names.append", "custom_lines.append", "numpy.arange", "plt.gca.text", "matplotlib.lines.Line2D", "numpy.arange", "min", "max", "min", "max"], "function", ["None"], ["def", "task_stem_plot", "(", "\n", "result_df", ",", "\n", "task_labels", ",", "\n", "task_space", "=", "2", ",", "\n", "task_offset", "=", "3", ",", "\n", "title", "=", "'Average Group Performance'", ",", "\n", "xlabel", "=", "'tasks'", ",", "\n", "ylabel", "=", "'$\\Delta$ ACC'", ",", "\n", "figsize", "=", "(", "10", ",", "5", ")", ",", "\n", "rotate_x_tick_labels", "=", "True", ",", "\n", "task_baseline_scores", "=", "None", ",", "\n", "task_baseline_scores_x_offset", "=", "-", ".3", ",", "\n", "task_baseline_scores_y_pos", "=", "-", ".2", "\n", ")", ":", "\n", "    ", "\"\"\" Make a stem plot with results\n    \"\"\"", "\n", "\n", "num_methods", "=", "result_df", ".", "shape", "[", "0", "]", "\n", "num_tasks", "=", "result_df", ".", "iloc", "[", "0", "]", "[", "'scores'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "\n", "\n", "offsets", "=", "np", ".", "linspace", "(", "0", ",", "task_space", ",", "num_methods", ")", "-", "task_space", "/", "2.", "\n", "\n", "for", "j", "in", "range", "(", "num_tasks", ")", ":", "\n", "        ", "plt", ".", "axvspan", "(", "j", "*", "task_offset", "+", "min", "(", "offsets", ")", "-", "0.2", ",", "j", "*", "task_offset", "+", "max", "(", "offsets", ")", "+", "0.2", ",", "facecolor", "=", "'#dfe1df'", ",", "alpha", "=", "1.", ")", "\n", "plt", ".", "plot", "(", "[", "j", "*", "task_offset", "+", "min", "(", "offsets", ")", "-", "0.2", ",", "j", "*", "task_offset", "+", "max", "(", "offsets", ")", "+", "0.2", "]", ",", "[", "0", ",", "0", "]", ",", "color", "=", "'#777B7E'", ",", "linestyle", "=", "'-'", ")", "\n", "\n", "", "i", "=", "0", "\n", "for", "_", ",", "mtd", "in", "result_df", ".", "iterrows", "(", ")", ":", "\n", "\n", "        ", "ys", "=", "mtd", "[", "'scores'", "]", "\n", "c", "=", "mtd", "[", "'color'", "]", "\n", "s", "=", "offsets", "[", "i", "]", "\n", "ls", "=", "mtd", "[", "'line_style'", "]", "\n", "mf", "=", "mtd", "[", "'marker_format'", "]", "\n", "x", "=", "np", ".", "arange", "(", "num_tasks", ")", "*", "task_offset", "+", "s", "\n", "#plt.stem(x, ys, '%s%s' % (c, ls), markerfmt='%s%s' % (c, mf), use_line_collection=True, basefmt=\" \")", "\n", "markerline", ",", "stemlines", ",", "baseline", "=", "plt", ".", "stem", "(", "x", ",", "ys", ",", "use_line_collection", "=", "True", ",", "basefmt", "=", "\" \"", ")", "\n", "plt", ".", "setp", "(", "stemlines", ",", "'color'", ",", "mtd", "[", "'color'", "]", ")", "\n", "plt", ".", "setp", "(", "stemlines", ",", "'linestyle'", ",", "mtd", "[", "'line_style'", "]", ")", "\n", "plt", ".", "setp", "(", "markerline", ",", "'color'", ",", "mtd", "[", "'color'", "]", ")", "\n", "plt", ".", "setp", "(", "markerline", ",", "'marker'", ",", "mtd", "[", "'marker_format'", "]", ")", "\n", "\n", "i", "+=", "1", "\n", "\n", "", "xticks", "=", "task_labels", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "num_tasks", ")", "*", "task_offset", ",", "xticks", ",", "rotation", "=", "'vertical'", "if", "rotate_x_tick_labels", "else", "None", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ")", "\n", "\n", "# Print baseline performance on figure", "\n", "if", "task_baseline_scores", "is", "not", "None", ":", "\n", "        ", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "for", "j", "in", "range", "(", "num_tasks", ")", ":", "\n", "            ", "ax", ".", "text", "(", "j", "*", "task_offset", "+", "task_baseline_scores_x_offset", ",", "task_baseline_scores_y_pos", ",", "\"%0.2f\"", "%", "(", "task_baseline_scores", "[", "j", "]", ",", ")", ")", "\n", "\n", "# Legend", "\n", "", "", "legend_names", "=", "[", "]", "\n", "custom_lines", "=", "[", "]", "\n", "\n", "for", "i", ",", "mtd", "in", "result_df", ".", "iterrows", "(", ")", ":", "\n", "        ", "legend_names", ".", "append", "(", "mtd", "[", "'display_name'", "]", ")", "\n", "custom_lines", ".", "append", "(", "Line2D", "(", "[", "0", "]", ",", "[", "0", "]", ",", "marker", "=", "mtd", "[", "'marker_format'", "]", ",", "markersize", "=", "8", ",", "linestyle", "=", "mtd", "[", "'line_style'", "]", ",", "linewidth", "=", "1", ",", "color", "=", "mtd", "[", "'color'", "]", ")", ")", "\n", "\n", "", "plt", ".", "legend", "(", "custom_lines", ",", "legend_names", ",", "loc", "=", "'center left'", ",", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.evaluate_linear_models.evalute_features": [[15, 38], ["tqdm.tqdm", "tqdm.tqdm.close", "features_df.iterrows", "tqdm.tqdm.set_description", "evaluator_fn", "task_results.append"], "function", ["None"], ["def", "evalute_features", "(", "features_df", ",", "evaluator_fn", ")", ":", "\n", "\n", "    ", "task_results", "=", "[", "]", "\n", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "features_df", ".", "iterrows", "(", ")", ")", "\n", "for", "i", ",", "row", "in", "pbar", ":", "\n", "\n", "        ", "dataset_name", "=", "row", "[", "'name'", "]", "\n", "pbar", ".", "set_description", "(", "\"Evaluating %s\"", "%", "dataset_name", ")", "\n", "\n", "X_train", "=", "row", "[", "'X_train'", "]", "\n", "X_test", "=", "row", "[", "'X_test'", "]", "\n", "y_train", "=", "row", "[", "'y_train'", "]", "\n", "y_test", "=", "row", "[", "'y_test'", "]", "\n", "\n", "results", "=", "evaluator_fn", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ")", "\n", "\n", "results", "[", "'name'", "]", "=", "dataset_name", "\n", "\n", "task_results", ".", "append", "(", "results", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "return", "task_results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.evaluate_linear_models.analyze_features": [[40, 79], ["print", "time.time", "os.path.join", "os.path.join", "pandas.read_pickle", "evaluate_linear_models.evalute_features", "pandas.DataFrame", "pd.DataFrame.to_pickle", "time.time", "divmod", "divmod", "print", "print", "os.path.exists", "print", "os.path.exists", "print", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.evaluate_linear_models.evalute_features"], ["", "def", "analyze_features", "(", "feature_dir", ",", "results_dir", ",", "evaluator_fn", ",", "overwrite", "=", "False", ")", ":", "\n", "\n", "    ", "for", "model_spec", "in", "configs", ".", "model_specs", ":", "\n", "\n", "        ", "model_name", "=", "model_spec", "[", "'name'", "]", "\n", "print", "(", "\"Evaluating features from %s\"", "%", "model_name", ")", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "\n", "results_fp", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "model_name", "+", "\".pkl\"", ")", "\n", "\n", "# Have we already run evaluation?", "\n", "if", "os", ".", "path", ".", "exists", "(", "results_fp", ")", "and", "not", "overwrite", ":", "\n", "            ", "print", "(", "\"Found existing results file for model %s at %s\"", "%", "(", "model_name", ",", "results_fp", ")", ")", "\n", "continue", "\n", "\n", "# Make sure the features exists for this model", "\n", "", "feature_fp", "=", "os", ".", "path", ".", "join", "(", "feature_dir", ",", "model_name", "+", "\".pkl\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "feature_fp", ")", ":", "\n", "            ", "print", "(", "\"WARNING: did not find features for model %s at location %s\"", "%", "(", "model_name", ",", "feature_fp", ")", ")", "\n", "continue", "\n", "\n", "# Load in the features extracted by this model", "\n", "", "feature_df", "=", "pd", ".", "read_pickle", "(", "feature_fp", ")", "\n", "\n", "# Evaluate the features", "\n", "results", "=", "evalute_features", "(", "feature_df", ",", "evaluator_fn", ")", "\n", "\n", "# Save off the results", "\n", "results_df", "=", "pd", ".", "DataFrame", "(", "results", ")", "\n", "results_df", "[", "'model_name'", "]", "=", "model_name", "\n", "results_df", ".", "to_pickle", "(", "results_fp", ")", "\n", "\n", "# Print the total time the experiment took", "\n", "et", "=", "time", ".", "time", "(", ")", "\n", "total_time", "=", "et", "-", "st", "\n", "hours", ",", "remainder", "=", "divmod", "(", "total_time", ",", "3600", ")", "\n", "minutes", ",", "seconds", "=", "divmod", "(", "remainder", ",", "60", ")", "\n", "print", "(", "'Evaluation Time: {:02}:{:02}:{:02}'", ".", "format", "(", "int", "(", "hours", ")", ",", "int", "(", "minutes", ")", ",", "int", "(", "seconds", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.evaluate_linear_models.parse_args": [[83, 127], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train and evaluate linear models.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--feature_dir'", ",", "dest", "=", "'feature_dir'", ",", "\n", "help", "=", "'Path to the directory containing extracted features.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "dest", "=", "'result_dir'", ",", "\n", "help", "=", "'Path to the directory to store results.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "dest", "=", "'model'", ",", "\n", "help", "=", "'Model type'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'logreg'", ",", "'sgd'", ",", "'linearsvc'", "]", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--overwrite'", ",", "dest", "=", "'overwrite'", ",", "\n", "help", "=", "'Overwrite existing saved features.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max_iter'", ",", "dest", "=", "'max_iter'", ",", "\n", "help", "=", "'Maximum number of iterations taken for the solvers to converge.'", ",", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "default", "=", "100", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--standardize'", ",", "dest", "=", "'standardize'", ",", "\n", "help", "=", "'Standardize features by removing the mean and scaling to unit variance.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--normalize'", ",", "dest", "=", "'normalize'", ",", "\n", "help", "=", "'Scale feature vectors individually to unit norm.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--grid_search'", ",", "dest", "=", "'grid_search'", ",", "\n", "help", "=", "'Search for optimal regularization terms.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dual'", ",", "dest", "=", "'dual'", ",", "\n", "help", "=", "'Use the dual formulation of the SVM (only relevant for `model = linearsvc`)'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parsed_args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "parsed_args", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_extract_features.extract_fg_features": [[18, 59], ["pt_resnet_feature_extractor.load_feature_extractor", "tqdm.tqdm", "tqdm.tqdm.close", "datasets.items", "tqdm.tqdm.set_description", "dataset_utils.load_dataset", "pt_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "pt_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "numpy.array", "numpy.array", "task_results.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.load_feature_extractor", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_dataset", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch"], ["def", "extract_fg_features", "(", "\n", "model_spec", ",", "\n", "datasets", ",", "\n", "feature_extractor_batch_size", "=", "32", ",", "\n", "device", "=", "'cuda'", ")", ":", "\n", "\n", "    ", "feature_extractor", "=", "pt_resnet_feature_extractor", ".", "load_feature_extractor", "(", "model_spec", ",", "device", ")", "\n", "\n", "task_results", "=", "[", "]", "\n", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "datasets", ".", "items", "(", ")", ")", "\n", "for", "dataset_name", ",", "dataset_dir", "in", "pbar", ":", "\n", "\n", "        ", "pbar", ".", "set_description", "(", "\"Processing %s\"", "%", "dataset_name", ")", "\n", "\n", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "=", "dataset_utils", ".", "load_dataset", "(", "dataset_name", ",", "dataset_dir", ")", "\n", "\n", "X_train", "=", "feature_extractor", ".", "extract_features_batch", "(", "train_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "len", "(", "train_paths", ")", ",", "\"Feature extractor did not extract features for all train images?\"", "\n", "y_train", "=", "np", ".", "array", "(", "train_classes", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "y_train", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of train examples and the number of train labels\"", "\n", "\n", "X_test", "=", "feature_extractor", ".", "extract_features_batch", "(", "test_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "len", "(", "test_paths", ")", ",", "\"Feature extractor did not extract features for all test images?\"", "\n", "y_test", "=", "np", ".", "array", "(", "test_classes", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "y_test", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of test examples and the number of test labels\"", "\n", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "'name'", "]", "=", "dataset_name", "\n", "results", "[", "'X_train'", "]", "=", "X_train", "\n", "results", "[", "'X_test'", "]", "=", "X_test", "\n", "results", "[", "'y_train'", "]", "=", "y_train", "\n", "results", "[", "'y_test'", "]", "=", "y_test", "\n", "results", "[", "'train_paths'", "]", "=", "np", ".", "array", "(", "train_paths", ",", "dtype", "=", "object", ")", "\n", "results", "[", "'test_paths'", "]", "=", "np", ".", "array", "(", "test_paths", ",", "dtype", "=", "object", ")", "\n", "\n", "task_results", ".", "append", "(", "results", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "return", "task_results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_extract_features.extract_newt_features": [[60, 104], ["pt_resnet_feature_extractor.load_feature_extractor", "glob.glob", "tqdm.tqdm", "tqdm.tqdm.close", "os.path.join", "os.path.basename", "tqdm.tqdm.set_description", "dataset_utils.load_newt_task", "pt_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "pt_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "numpy.array", "numpy.array", "task_results.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.load_feature_extractor", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_newt_task", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch"], ["", "def", "extract_newt_features", "(", "\n", "model_spec", ",", "\n", "newt_dataset_dir", ",", "\n", "feature_extractor_batch_size", "=", "32", ",", "\n", "device", "=", "'cuda'", ")", ":", "\n", "\n", "    ", "feature_extractor", "=", "pt_resnet_feature_extractor", ".", "load_feature_extractor", "(", "model_spec", ",", "device", ")", "\n", "\n", "newt_task_dirs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "newt_dataset_dir", ",", "\"*\"", ")", ")", "\n", "\n", "task_results", "=", "[", "]", "\n", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "newt_task_dirs", ")", "\n", "for", "newt_task_dir", "in", "pbar", ":", "\n", "\n", "        ", "task_name", "=", "os", ".", "path", ".", "basename", "(", "newt_task_dir", ")", "\n", "pbar", ".", "set_description", "(", "\"Processing %s\"", "%", "task_name", ")", "\n", "\n", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "=", "dataset_utils", ".", "load_newt_task", "(", "newt_task_dir", ")", "\n", "\n", "X_train", "=", "feature_extractor", ".", "extract_features_batch", "(", "train_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "len", "(", "train_paths", ")", ",", "\"Feature extractor did not extract features for all train images?\"", "\n", "y_train", "=", "np", ".", "array", "(", "train_classes", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "y_train", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of train examples and the number of train labels\"", "\n", "\n", "X_test", "=", "feature_extractor", ".", "extract_features_batch", "(", "test_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "len", "(", "test_paths", ")", ",", "\"Feature extractor did not extract features for all test images?\"", "\n", "y_test", "=", "np", ".", "array", "(", "test_classes", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "y_test", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of test examples and the number of test labels\"", "\n", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "'name'", "]", "=", "task_name", "\n", "results", "[", "'X_train'", "]", "=", "X_train", "\n", "results", "[", "'X_test'", "]", "=", "X_test", "\n", "results", "[", "'y_train'", "]", "=", "y_train", "\n", "results", "[", "'y_test'", "]", "=", "y_test", "\n", "results", "[", "'train_paths'", "]", "=", "np", ".", "array", "(", "train_paths", ",", "dtype", "=", "object", ")", "\n", "results", "[", "'test_paths'", "]", "=", "np", ".", "array", "(", "test_paths", ",", "dtype", "=", "object", ")", "\n", "\n", "task_results", ".", "append", "(", "results", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "return", "task_results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_extract_features.run_pt_feature_extractor": [[106, 167], ["torch.device", "torch.cuda.is_available", "print", "time.time", "time.time", "divmod", "divmod", "print", "print", "print", "os.path.join", "print", "print", "os.path.join", "print", "pt_extract_features.extract_newt_features", "pandas.DataFrame", "pd.DataFrame.to_pickle", "print", "pt_extract_features.extract_fg_features", "pandas.DataFrame", "pd.DataFrame.to_pickle", "print", "int", "int", "int", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_newt_features", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_fg_features"], ["", "def", "run_pt_feature_extractor", "(", "newt_dataset_dir", ",", "fg_datasets", ",", "newt_features_dir", ",", "fg_features_dir", ",", "feature_extractor_batch_size", "=", "64", ",", "overwrite", "=", "False", ")", ":", "\n", "    ", "\"\"\" Run the experiments from the paper for the pytorch models.\n    \"\"\"", "\n", "\n", "batch_size", "=", "feature_extractor_batch_size", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "for", "model_spec", "in", "configs", ".", "model_specs", ":", "\n", "\n", "        ", "if", "model_spec", "[", "'format'", "]", "==", "configs", ".", "PYTORCH", ":", "\n", "\n", "\n", "            ", "print", "(", "\"Current feature extractor: %s\"", "%", "model_spec", "[", "'display_name'", "]", ")", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "newt_dataset_dir", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"Extracting features across NeWT tasks\"", ")", "\n", "newt_features_fp", "=", "os", ".", "path", ".", "join", "(", "newt_features_dir", ",", "\"%s.pkl\"", "%", "model_spec", "[", "'name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "newt_features_fp", ")", "or", "overwrite", ":", "\n", "\n", "                    ", "newt_features", "=", "extract_newt_features", "(", "\n", "model_spec", ",", "\n", "newt_dataset_dir", ",", "\n", "feature_extractor_batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "newt_features_df", "=", "pd", ".", "DataFrame", "(", "newt_features", ")", "\n", "newt_features_df", "[", "'model_name'", "]", "=", "model_spec", "[", "'name'", "]", "\n", "newt_features_df", ".", "to_pickle", "(", "newt_features_fp", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Found existing features for NeWT tasks\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"Skipping NeWT tasks\"", ")", "\n", "\n", "\n", "", "if", "fg_datasets", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"Extracting features across FG datasets\"", ")", "\n", "fg_features_fp", "=", "os", ".", "path", ".", "join", "(", "fg_features_dir", ",", "\"%s.pkl\"", "%", "model_spec", "[", "'name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fg_features_fp", ")", "or", "overwrite", ":", "\n", "\n", "                    ", "fg_features", "=", "extract_fg_features", "(", "\n", "model_spec", ",", "\n", "fg_datasets", ",", "\n", "feature_extractor_batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "fg_features_df", "=", "pd", ".", "DataFrame", "(", "fg_features", ")", "\n", "fg_features_df", "[", "'model_name'", "]", "=", "model_spec", "[", "'name'", "]", "\n", "fg_features_df", ".", "to_pickle", "(", "fg_features_fp", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Found existing features for FG Datasets\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"Skipping FG datasets\"", ")", "\n", "\n", "# Print the total time the experiment took", "\n", "", "et", "=", "time", ".", "time", "(", ")", "\n", "total_time", "=", "et", "-", "st", "\n", "hours", ",", "remainder", "=", "divmod", "(", "total_time", ",", "3600", ")", "\n", "minutes", ",", "seconds", "=", "divmod", "(", "remainder", ",", "60", ")", "\n", "print", "(", "'Feature Extraction Time: {:02}:{:02}:{:02}'", ".", "format", "(", "int", "(", "hours", ")", ",", "int", "(", "minutes", ")", ",", "int", "(", "seconds", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_extract_features.parse_args": [[170, 193], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract features using pytorch models.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--newt_feature_dir'", ",", "dest", "=", "'newt_feature_dir'", ",", "\n", "help", "=", "'Path to the directory to store the newt features.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fg_feature_dir'", ",", "dest", "=", "'fg_feature_dir'", ",", "\n", "help", "=", "'Path to the directory to store FG dataset features.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "dest", "=", "'batch_size'", ",", "\n", "help", "=", "'Feature extractor batch size.'", ",", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "default", "=", "64", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--overwrite'", ",", "dest", "=", "'overwrite'", ",", "\n", "help", "=", "'Overwrite existing saved features.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parsed_args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "parsed_args", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_fg_features": [[17, 58], ["tf_resnet_feature_extractor.load_feature_extractor", "tqdm.tqdm", "tqdm.tqdm.close", "datasets.items", "tqdm.tqdm.set_description", "dataset_utils.load_dataset", "tf_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "tf_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "numpy.array", "numpy.array", "task_results.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.load_feature_extractor", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_dataset", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch"], ["def", "extract_fg_features", "(", "\n", "model_spec", ",", "\n", "datasets", ",", "\n", "feature_extractor_batch_size", "=", "32", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "feature_extractor", "=", "tf_resnet_feature_extractor", ".", "load_feature_extractor", "(", "model_spec", ",", "device", ")", "\n", "\n", "task_results", "=", "[", "]", "\n", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "datasets", ".", "items", "(", ")", ")", "\n", "for", "dataset_name", ",", "dataset_dir", "in", "pbar", ":", "\n", "\n", "        ", "pbar", ".", "set_description", "(", "\"Processing %s\"", "%", "dataset_name", ")", "\n", "\n", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "=", "dataset_utils", ".", "load_dataset", "(", "dataset_name", ",", "dataset_dir", ")", "\n", "\n", "X_train", "=", "feature_extractor", ".", "extract_features_batch", "(", "train_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ",", "use_pbar", "=", "True", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "len", "(", "train_paths", ")", ",", "\"Feature extractor did not extract features for all train images?\"", "\n", "y_train", "=", "np", ".", "array", "(", "train_classes", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "y_train", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of train examples and the number of train labels\"", "\n", "\n", "X_test", "=", "feature_extractor", ".", "extract_features_batch", "(", "test_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ",", "use_pbar", "=", "True", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "len", "(", "test_paths", ")", ",", "\"Feature extractor did not extract features for all test images?\"", "\n", "y_test", "=", "np", ".", "array", "(", "test_classes", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "y_test", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of test examples and the number of test labels\"", "\n", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "'name'", "]", "=", "dataset_name", "\n", "results", "[", "'X_train'", "]", "=", "X_train", "\n", "results", "[", "'X_test'", "]", "=", "X_test", "\n", "results", "[", "'y_train'", "]", "=", "y_train", "\n", "results", "[", "'y_test'", "]", "=", "y_test", "\n", "results", "[", "'train_paths'", "]", "=", "np", ".", "array", "(", "train_paths", ",", "dtype", "=", "object", ")", "\n", "results", "[", "'test_paths'", "]", "=", "np", ".", "array", "(", "test_paths", ",", "dtype", "=", "object", ")", "\n", "\n", "task_results", ".", "append", "(", "results", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "return", "task_results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_newt_features": [[61, 106], ["tf_resnet_feature_extractor.load_feature_extractor", "glob.glob", "tqdm.tqdm", "tqdm.tqdm.close", "os.path.join", "os.path.basename", "tqdm.tqdm.set_description", "dataset_utils.load_newt_task", "tf_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "tf_resnet_feature_extractor.load_feature_extractor.extract_features_batch", "numpy.array", "numpy.array", "numpy.array", "task_results.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.load_feature_extractor", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.dataset_utils.load_newt_task", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch"], ["", "def", "extract_newt_features", "(", "\n", "model_spec", ",", "\n", "newt_dataset_dir", ",", "\n", "feature_extractor_batch_size", "=", "32", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "    ", "feature_extractor", "=", "tf_resnet_feature_extractor", ".", "load_feature_extractor", "(", "model_spec", ",", "device", ")", "\n", "\n", "newt_task_dirs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "newt_dataset_dir", ",", "\"*\"", ")", ")", "\n", "\n", "task_results", "=", "[", "]", "\n", "\n", "pbar", "=", "tqdm", ".", "tqdm", "(", "newt_task_dirs", ")", "\n", "for", "newt_task_dir", "in", "pbar", ":", "\n", "\n", "        ", "task_name", "=", "os", ".", "path", ".", "basename", "(", "newt_task_dir", ")", "\n", "pbar", ".", "set_description", "(", "\"Processing %s\"", "%", "task_name", ")", "\n", "\n", "train_paths", ",", "train_classes", ",", "test_paths", ",", "test_classes", "=", "dataset_utils", ".", "load_newt_task", "(", "newt_task_dir", ")", "\n", "\n", "X_train", "=", "feature_extractor", ".", "extract_features_batch", "(", "train_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ",", "use_pbar", "=", "True", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "len", "(", "train_paths", ")", ",", "\"Feature extractor did not extract features for all train images?\"", "\n", "y_train", "=", "np", ".", "array", "(", "train_classes", ")", "\n", "assert", "X_train", ".", "shape", "[", "0", "]", "==", "y_train", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of train examples and the number of train labels\"", "\n", "\n", "X_test", "=", "feature_extractor", ".", "extract_features_batch", "(", "test_paths", ",", "batch_size", "=", "feature_extractor_batch_size", ",", "use_pbar", "=", "True", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "len", "(", "test_paths", ")", ",", "\"Feature extractor did not extract features for all test images?\"", "\n", "y_test", "=", "np", ".", "array", "(", "test_classes", ")", "\n", "assert", "X_test", ".", "shape", "[", "0", "]", "==", "y_test", ".", "shape", "[", "0", "]", ",", "\"Mismatch between the number of test examples and the number of test labels\"", "\n", "\n", "\n", "results", "=", "{", "}", "\n", "\n", "results", "[", "'name'", "]", "=", "task_name", "\n", "results", "[", "'X_train'", "]", "=", "X_train", "\n", "results", "[", "'X_test'", "]", "=", "X_test", "\n", "results", "[", "'y_train'", "]", "=", "y_train", "\n", "results", "[", "'y_test'", "]", "=", "y_test", "\n", "results", "[", "'train_paths'", "]", "=", "np", ".", "array", "(", "train_paths", ",", "dtype", "=", "object", ")", "\n", "results", "[", "'test_paths'", "]", "=", "np", ".", "array", "(", "test_paths", ",", "dtype", "=", "object", ")", "\n", "\n", "task_results", ".", "append", "(", "results", ")", "\n", "", "pbar", ".", "close", "(", ")", "\n", "\n", "return", "task_results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.run_tf_feature_extractor": [[109, 175], ["print", "time.time", "time.time", "divmod", "divmod", "print", "print", "print", "os.path.join", "print", "print", "os.path.join", "print", "tf_extract_features.extract_newt_features", "pandas.DataFrame", "pd.DataFrame.to_pickle", "print", "tf_extract_features.extract_fg_features", "pandas.DataFrame", "pd.DataFrame.to_pickle", "print", "int", "int", "int", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_newt_features", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.extract_fg_features"], ["", "def", "run_tf_feature_extractor", "(", "newt_dataset_dir", ",", "fg_datasets", ",", "newt_features_dir", ",", "fg_features_dir", ",", "feature_extractor_batch_size", "=", "64", ",", "overwrite", "=", "False", ",", "x4_batch_size", "=", "16", ")", ":", "\n", "    ", "\"\"\" Run the experiments from the paper for the tensorflow models.\n    \"\"\"", "\n", "\n", "for", "model_spec", "in", "configs", ".", "model_specs", ":", "\n", "\n", "        ", "if", "model_spec", "[", "'format'", "]", "==", "configs", ".", "TENSORFLOW", ":", "\n", "\n", "            ", "print", "(", "\"Current feature extractor: %s\"", "%", "model_spec", "[", "'display_name'", "]", ")", "\n", "st", "=", "time", ".", "time", "(", ")", "\n", "\n", "# The resnet50x4 models often don't fit in a \"standard\" gpu", "\n", "if", "model_spec", "[", "'backbone'", "]", "==", "configs", ".", "RESNET50_X4", ":", "\n", "                ", "device", "=", "'/device:CPU:0'", "\n", "batch_size", "=", "x4_batch_size", "\n", "", "else", ":", "\n", "                ", "device", "=", "None", "\n", "batch_size", "=", "feature_extractor_batch_size", "\n", "\n", "", "if", "newt_dataset_dir", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"Extracting features across NeWT tasks\"", ")", "\n", "\n", "newt_features_fp", "=", "os", ".", "path", ".", "join", "(", "newt_features_dir", ",", "\"%s.pkl\"", "%", "model_spec", "[", "'name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "newt_features_fp", ")", "or", "overwrite", ":", "\n", "\n", "                    ", "newt_features", "=", "extract_newt_features", "(", "\n", "model_spec", ",", "\n", "newt_dataset_dir", ",", "\n", "feature_extractor_batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "newt_features_df", "=", "pd", ".", "DataFrame", "(", "newt_features", ")", "\n", "newt_features_df", "[", "'model_name'", "]", "=", "model_spec", "[", "'name'", "]", "\n", "newt_features_df", ".", "to_pickle", "(", "newt_features_fp", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Found existing features for NeWT tasks\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"Skipping NeWT tasks\"", ")", "\n", "\n", "\n", "", "if", "fg_datasets", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"Extracting features across FG datasets\"", ")", "\n", "fg_features_fp", "=", "os", ".", "path", ".", "join", "(", "fg_features_dir", ",", "\"%s.pkl\"", "%", "model_spec", "[", "'name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fg_features_fp", ")", "or", "overwrite", ":", "\n", "\n", "                    ", "fg_features", "=", "extract_fg_features", "(", "\n", "model_spec", ",", "\n", "fg_datasets", ",", "\n", "feature_extractor_batch_size", "=", "batch_size", ",", "\n", "device", "=", "device", "\n", ")", "\n", "fg_features_df", "=", "pd", ".", "DataFrame", "(", "fg_features", ")", "\n", "fg_features_df", "[", "'model_name'", "]", "=", "model_spec", "[", "'name'", "]", "\n", "fg_features_df", ".", "to_pickle", "(", "fg_features_fp", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"Found existing features for FG Datasets\"", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"Skipping FG datasets\"", ")", "\n", "\n", "# Print the total time the experiment took", "\n", "", "et", "=", "time", ".", "time", "(", ")", "\n", "total_time", "=", "et", "-", "st", "\n", "hours", ",", "remainder", "=", "divmod", "(", "total_time", ",", "3600", ")", "\n", "minutes", ",", "seconds", "=", "divmod", "(", "remainder", ",", "60", ")", "\n", "print", "(", "'Feature Extraction Time: {:02}:{:02}:{:02}'", ".", "format", "(", "int", "(", "hours", ")", ",", "int", "(", "minutes", ")", ",", "int", "(", "seconds", ")", ")", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_extract_features.parse_args": [[178, 205], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract features using tensorflow models.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--newt_feature_dir'", ",", "dest", "=", "'newt_feature_dir'", ",", "\n", "help", "=", "'Path to the directory to store the newt features.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fg_feature_dir'", ",", "dest", "=", "'fg_feature_dir'", ",", "\n", "help", "=", "'Path to the directory to store FG dataset features.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "dest", "=", "'batch_size'", ",", "\n", "help", "=", "'Feature extractor batch size.'", ",", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "default", "=", "64", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--overwrite'", ",", "dest", "=", "'overwrite'", ",", "\n", "help", "=", "'Overwrite existing saved features.'", ",", "\n", "required", "=", "False", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--x4_batch_size'", ",", "dest", "=", "'x4_batch_size'", ",", "\n", "help", "=", "'Feature extractor batch size for the ResNet x4 models.'", ",", "type", "=", "int", ",", "\n", "required", "=", "False", ",", "default", "=", "16", ")", "\n", "\n", "parsed_args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "parsed_args", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.create_fg_plots": [[25, 212], ["pandas.DataFrame", "pd.concat.pivot", "pd.concat.pivot", "pandas.DataFrame", "plot_utils.task_stem_plot", "os.path.join", "matplotlib.pyplot.savefig", "len", "len", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.concat", "next", "exp_results.append", "open", "os.path.exists", "print", "contextlib.redirect_stdout", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "next", "enumerate", "print", "ys.append", "ry.append", "numpy.mean", "ValueError"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.plot_utils.task_stem_plot"], ["def", "create_fg_plots", "(", "fg_results_dir", ",", "output_dir", ")", ":", "\n", "\n", "    ", "fg_results_df", "=", "pd", ".", "DataFrame", "(", "None", ",", "columns", "=", "[", "'model_name'", ",", "'name'", ",", "'acc'", "]", ")", "\n", "\n", "for", "model_spec", "in", "configs", ".", "model_specs", ":", "\n", "\n", "        ", "model_name", "=", "model_spec", "[", "'name'", "]", "\n", "results_fp", "=", "os", ".", "path", ".", "join", "(", "fg_results_dir", ",", "model_name", "+", "\".pkl\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "results_fp", ")", ":", "\n", "            ", "print", "(", "\"WARNING: did not find results for model %s at %s\"", "%", "(", "model_name", ",", "results_fp", ")", ")", "\n", "continue", "\n", "\n", "", "results_df", "=", "pd", ".", "read_pickle", "(", "results_fp", ")", "\n", "\n", "fg_results_df", "=", "pd", ".", "concat", "(", "[", "fg_results_df", ",", "results_df", "]", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# models are the rows", "\n", "", "fg_model_results_df", "=", "fg_results_df", ".", "pivot", "(", "index", "=", "'model_name'", ",", "columns", "=", "'name'", ",", "values", "=", "'acc'", ")", "\n", "fg_model_results_df", "=", "fg_model_results_df", ".", "loc", "[", "[", "model_spec", "[", "'name'", "]", "for", "model_spec", "in", "configs", ".", "model_specs", "]", "]", "\n", "fg_model_results_df", "=", "fg_model_results_df", "[", "[", "'OxfordFlowers'", ",", "'CUB'", ",", "'CUBExpert'", ",", "'NABirds'", ",", "'StandfordDogs'", ",", "'StandfordCars'", "]", "]", "\n", "\n", "# datasets are the rows", "\n", "fg_dataset_results_df", "=", "fg_results_df", ".", "pivot", "(", "index", "=", "'name'", ",", "columns", "=", "'model_name'", ",", "values", "=", "'acc'", ")", "\n", "fg_dataset_results_df", "=", "fg_dataset_results_df", ".", "loc", "[", "[", "'OxfordFlowers'", ",", "'CUB'", ",", "'CUBExpert'", ",", "'NABirds'", ",", "'StandfordDogs'", ",", "'StandfordCars'", "]", "]", "\n", "fg_dataset_results_df", "=", "fg_dataset_results_df", "[", "[", "model_spec", "[", "'name'", "]", "for", "model_spec", "in", "configs", ".", "model_specs", "]", "]", "\n", "\n", "#####################", "\n", "# Stem plot for FG tasks", "\n", "datasets", "=", "[", "'OxfordFlowers'", ",", "'CUB'", ",", "'CUBExpert'", ",", "'NABirds'", ",", "'StandfordDogs'", ",", "'StandfordCars'", "]", "\n", "\n", "result_names", "=", "[", "\n", "'imagenet_simclr'", ",", "\n", "'imagenet_simclr_x4'", ",", "\n", "'imagenet_simclr_v2'", ",", "\n", "'imagenet_swav'", ",", "\n", "'imagenet_moco_v2'", ",", "\n", "'inat2021_supervised'", ",", "\n", "'inat2021_mini_supervised'", ",", "\n", "'inat2018_supervised'", ",", "\n", "'inat2021_simclr'", ",", "\n", "'inat2021_mini_simclr'", ",", "\n", "'inat2021_mini_simclr_x4'", ",", "\n", "'inat2021_mini_simclr_v2'", ",", "\n", "'inat2021_mini_swav'", ",", "\n", "'inat2021_mini_moco_v2'", "\n", "]", "\n", "\n", "baseline_scores", "=", "fg_model_results_df", ".", "loc", "[", "'imagenet_supervised'", "]", "[", "datasets", "]", ".", "values", "\n", "exp_results", "=", "[", "]", "\n", "for", "model_name", "in", "result_names", ":", "\n", "\n", "        ", "model_spec", "=", "next", "(", "model_spec", "for", "model_spec", "in", "configs", ".", "model_specs", "if", "model_spec", "[", "'name'", "]", "==", "model_name", ")", "\n", "\n", "if", "model_spec", "[", "'name'", "]", "==", "'imagenet_supervised'", ":", "\n", "            ", "continue", "\n", "\n", "", "task_scores", "=", "fg_model_results_df", ".", "loc", "[", "model_spec", "[", "'name'", "]", "]", "[", "datasets", "]", ".", "values", "-", "baseline_scores", "\n", "\n", "r", "=", "{", "\n", "'name'", ":", "model_spec", "[", "'name'", "]", ",", "\n", "'scores'", ":", "task_scores", ",", "\n", "'color'", ":", "model_spec", "[", "'color'", "]", ",", "\n", "'display_name'", ":", "model_spec", "[", "'display_name'", "]", ",", "\n", "}", "\n", "\n", "if", "model_spec", "[", "'name'", "]", "==", "'random'", ":", "\n", "            ", "r", "[", "'line_style'", "]", "=", "':'", "\n", "", "elif", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "SUPERVISED", ":", "\n", "            ", "r", "[", "'line_style'", "]", "=", "'-'", "\n", "", "else", ":", "\n", "            ", "r", "[", "'line_style'", "]", "=", "'--'", "\n", "\n", "", "if", "model_spec", "[", "'name'", "]", "==", "'random'", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'>'", "\n", "", "elif", "model_spec", "[", "'training_dataset'", "]", "==", "configs", ".", "IMAGENET", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'^'", "\n", "", "elif", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "SUPERVISED", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'o'", "\n", "", "elif", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "SIMCLR", "or", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "SIMCLR_V2", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'*'", "\n", "", "elif", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "MOCO_V2", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'*'", "\n", "", "elif", "model_spec", "[", "'train_objective'", "]", "==", "configs", ".", "SWAV", ":", "\n", "            ", "r", "[", "'marker_format'", "]", "=", "'*'", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown train objective: %s\"", "%", "model_spec", "[", "'train_objective'", "]", ")", "\n", "\n", "", "exp_results", ".", "append", "(", "r", ")", "\n", "\n", "\n", "", "result_df", "=", "pd", ".", "DataFrame", "(", "exp_results", ")", "\n", "\n", "task_labels", "=", "[", "'Flowers102'", ",", "'CUB'", ",", "'CUBExpert'", ",", "'NABirds'", ",", "'StanfordDogs'", ",", "'StanfordCars'", "]", "\n", "\n", "plot_utils", ".", "task_stem_plot", "(", "\n", "result_df", ",", "\n", "task_labels", ",", "\n", "task_space", "=", "4", ",", "\n", "task_offset", "=", "5", ",", "\n", "title", "=", "'Change in Mean Accuracy from Imagenet Supervised Features'", ",", "\n", "xlabel", "=", "''", ",", "\n", "ylabel", "=", "'$\\Delta$ ACC'", ",", "\n", "figsize", "=", "(", "15", ",", "5", ")", ",", "\n", "rotate_x_tick_labels", "=", "False", ",", "\n", "task_baseline_scores", "=", "baseline_scores", ",", "\n", "task_baseline_scores_x_offset", "=", "-", ".5", ",", "\n", "task_baseline_scores_y_pos", "=", "-", ".55", "\n", ")", "\n", "\n", "output_fp", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"fg_stem_plot.pdf\"", ")", "\n", "plt", ".", "savefig", "(", "output_fp", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n", "##############", "\n", "# Latex Table of results", "\n", "\n", "result_names", "=", "[", "\n", "'imagenet_supervised'", ",", "\n", "'imagenet_simclr'", ",", "\n", "'imagenet_simclr_x4'", ",", "\n", "'imagenet_simclr_v2'", ",", "\n", "'imagenet_swav'", ",", "\n", "'imagenet_moco_v2'", ",", "\n", "'inat2021_supervised'", ",", "\n", "'inat2021_supervised_from_scratch'", ",", "\n", "'inat2021_mini_supervised'", ",", "\n", "'inat2021_mini_supervised_from_scratch'", ",", "\n", "'inat2018_supervised'", ",", "\n", "'inat2021_simclr'", ",", "\n", "'inat2021_mini_simclr'", ",", "\n", "'inat2021_mini_simclr_x4'", ",", "\n", "'inat2021_mini_simclr_v2'", ",", "\n", "'inat2021_mini_swav'", ",", "\n", "'inat2021_mini_moco_v2'", "\n", "]", "\n", "\n", "\n", "num_cols", "=", "len", "(", "datasets", ")", "\n", "num_rows", "=", "len", "(", "result_names", ")", "\n", "\n", "table_fp", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"fg_latex_table.txt\"", ")", "\n", "\n", "with", "open", "(", "table_fp", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "with", "redirect_stdout", "(", "f", ")", ":", "\n", "            ", "print", "(", "\"\\\\begin{table*}[t]\"", ")", "\n", "print", "(", "\"\\\\small\"", ")", "\n", "print", "(", "\"\\\\centering\"", ")", "\n", "print", "(", "\"\\\\begin{tabular}{|l | l | %s |}\"", "%", "(", "\" \"", ".", "join", "(", "[", "\"c\"", "]", "*", "(", "num_cols", "+", "1", ")", ")", ")", ")", "\n", "print", "(", "\"\\\\hline\"", ")", "\n", "\n", "header", "=", "[", "\"Source Dataset\"", ",", "\"Train Loss\"", "]", "+", "datasets", "+", "[", "\"Mean ACC\"", "]", "\n", "print", "(", "\"  &  \\t\"", ".", "join", "(", "header", ")", "+", "\"\\\\\\\\\"", ")", "\n", "print", "(", "\"\\hline\\hline\"", ")", "\n", "\n", "for", "model_name", "in", "result_names", ":", "\n", "\n", "                ", "model_spec", "=", "next", "(", "model_spec", "for", "model_spec", "in", "configs", ".", "model_specs", "if", "model_spec", "[", "'name'", "]", "==", "model_name", ")", "\n", "\n", "model_scores", "=", "fg_model_results_df", ".", "loc", "[", "model_spec", "[", "'name'", "]", "]", "\n", "\n", "ys", "=", "[", "]", "\n", "ry", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "datasets", ")", ":", "\n", "\n", "                    ", "v", "=", "model_scores", "[", "label", "]", "\n", "ys", ".", "append", "(", "\n", "\"%0.3f\"", "%", "v", "\n", ")", "\n", "ry", ".", "append", "(", "v", ")", "\n", "\n", "\n", "", "td", "=", "model_spec", "[", "'training_dataset'", "]", "if", "model_spec", "[", "'training_dataset'", "]", "is", "not", "None", "else", "\"\"", "\n", "to", "=", "model_spec", "[", "'train_objective'", "]", "\n", "if", "model_spec", "[", "'backbone'", "]", "==", "configs", ".", "RESNET50_X4", ":", "\n", "                    ", "to", "+=", "\" x4\"", "\n", "", "if", "model_spec", "[", "'pretrained_weights'", "]", "is", "not", "None", ":", "\n", "                    ", "to", "+=", "\" (from %s)\"", "%", "model_spec", "[", "'pretrained_weights'", "]", "\n", "\n", "", "row", "=", "[", "td", ",", "to", "]", "+", "ys", "+", "[", "\"%0.3f\"", "%", "np", ".", "mean", "(", "ry", ")", "]", "\n", "\n", "print", "(", "\"  &  \\t\"", ".", "join", "(", "row", ")", "+", "\" \\\\\\\\\"", ")", "\n", "\n", "", "print", "(", "\"\\\\hline\"", ")", "\n", "print", "(", "\"\\\\end{tabular}\"", ")", "\n", "print", "(", "\"\\\\caption{}\"", ")", "\n", "print", "(", "\"\\\\label{table:}\"", ")", "\n", "print", "(", "\"\\\\end{table*}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.parse_args": [[215, 230], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.make_fg_plots.parse_args"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Create the stem plot figure and latex table of results for the FG datasets.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--result_dir'", ",", "dest", "=", "'result_dir'", ",", "\n", "help", "=", "'Path to the directory containing the FG results.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "dest", "=", "'output_dir'", ",", "\n", "help", "=", "'Path to the directory to save figures and tables.'", ",", "type", "=", "str", ",", "\n", "required", "=", "True", ")", "\n", "\n", "parsed_args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "parsed_args", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer": [[25, 27], ["tensorflow.python.keras.regularizers.l2"], "function", ["None"], ["def", "_gen_l2_regularizer", "(", "use_l2_regularizer", "=", "True", ",", "l2_weight_decay", "=", "1e-4", ")", ":", "\n", "    ", "return", "regularizers", ".", "l2", "(", "l2_weight_decay", ")", "if", "use_l2_regularizer", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.fixed_padding": [[28, 52], ["tensorflow.pad", "tensorflow.pad"], "function", ["None"], ["", "def", "fixed_padding", "(", "inputs", ",", "kernel_size", ",", "data_format", "=", "'channels_last'", ")", ":", "\n", "    ", "\"\"\"Pads the input along the spatial dimensions independently of input size.\n    Args:\n        inputs: `Tensor` of size `[batch, channels, height, width]` or\n            `[batch, height, width, channels]` depending on `data_format`.\n        kernel_size: `int` kernel size to be used for `conv2d` or max_pool2d`\n            operations. Should be a positive integer.\n        data_format: `str` either \"channels_first\" for `[batch, channels, height,\n            width]` or \"channels_last for `[batch, height, width, channels]`.\n    Returns:\n        A padded `Tensor` of the same `data_format` with size either intact\n        (if `kernel_size == 1`) or padded (if `kernel_size > 1`).\n    \"\"\"", "\n", "pad_total", "=", "kernel_size", "-", "1", "\n", "pad_beg", "=", "pad_total", "//", "2", "\n", "pad_end", "=", "pad_total", "-", "pad_beg", "\n", "if", "data_format", "==", "'channels_first'", ":", "\n", "        ", "padded_inputs", "=", "tf", ".", "pad", "(", "inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "\n", "[", "pad_beg", ",", "pad_end", "]", ",", "[", "pad_beg", ",", "pad_end", "]", "]", ")", "\n", "", "else", ":", "\n", "        ", "padded_inputs", "=", "tf", ".", "pad", "(", "inputs", ",", "[", "[", "0", ",", "0", "]", ",", "[", "pad_beg", ",", "pad_end", "]", ",", "\n", "[", "pad_beg", ",", "pad_end", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "\n", "", "return", "padded_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block": [[54, 146], ["layers.add", "tensorflow.python.keras.backend.image_data_format", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "str", "str", "tf_resnet._gen_l2_regularizer", "tf_resnet._gen_l2_regularizer", "tf_resnet._gen_l2_regularizer"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer"], ["", "def", "identity_block", "(", "input_tensor", ",", "\n", "kernel_size", ",", "\n", "filters", ",", "\n", "stage", ",", "\n", "block", ",", "\n", "use_l2_regularizer", "=", "True", ",", "\n", "batch_norm_decay", "=", "0.9", ",", "\n", "batch_norm_epsilon", "=", "1e-5", ",", "\n", "batch_norm_trainable", "=", "True", ")", ":", "\n", "    ", "\"\"\"The identity block is the block that has no conv layer at shortcut.\n    Args:\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n        use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n        batch_norm_decay: Moment of batch norm layers.\n        batch_norm_epsilon: Epsilon of batch borm layers.\n    Returns:\n        Output tensor for the block.\n    \"\"\"", "\n", "filters1", ",", "filters2", ",", "filters3", "=", "filters", "\n", "if", "backend", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "        ", "bn_axis", "=", "3", "\n", "", "else", ":", "\n", "        ", "bn_axis", "=", "1", "\n", "", "conv_name_base", "=", "'res'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "bn_name_base", "=", "'bn'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "\n", "# Kernel: 1", "\n", "# Strides: 1", "\n", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters1", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2a'", ")", "(", "\n", "input_tensor", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2a'", ")", "(", "\n", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "# Kernel: 3", "\n", "# Strides: 1", "\n", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters2", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "'same'", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2b'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2b'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "# Kernel: 1", "\n", "# Strides: 1", "\n", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2c'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2c'", ")", "(", "x", ")", "\n", "\n", "x", "=", "layers", ".", "add", "(", "[", "x", ",", "input_tensor", "]", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.conv_block": [[148, 269], ["layers.add", "tensorflow.python.keras.backend.image_data_format", "layers.Conv2D", "layers.BatchNormalization", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "tf_resnet.fixed_padding", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "str", "str", "tf_resnet._gen_l2_regularizer", "tf_resnet._gen_l2_regularizer", "tensorflow.python.keras.backend.image_data_format", "tf_resnet._gen_l2_regularizer", "tf_resnet._gen_l2_regularizer"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.fixed_padding", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer"], ["", "def", "conv_block", "(", "input_tensor", ",", "\n", "kernel_size", ",", "\n", "filters", ",", "\n", "stage", ",", "\n", "block", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "use_l2_regularizer", "=", "True", ",", "\n", "batch_norm_decay", "=", "0.9", ",", "\n", "batch_norm_epsilon", "=", "1e-5", ",", "\n", "batch_norm_trainable", "=", "True", ")", ":", "\n", "    ", "\"\"\"A block that has a conv layer at shortcut.\n    Note that from stage 3,\n    the second conv layer at main path is with strides=(2, 2)\n    And the shortcut should have strides=(2, 2) as well\n    Args:\n        input_tensor: input tensor\n        kernel_size: default 3, the kernel size of middle conv layer at main path\n        filters: list of integers, the filters of 3 conv layer at main path\n        stage: integer, current stage label, used for generating layer names\n        block: 'a','b'..., current block label, used for generating layer names\n        strides: Strides for the second conv layer in the block.\n        use_l2_regularizer: whether to use L2 regularizer on Conv layer.\n        batch_norm_decay: Moment of batch norm layers.\n        batch_norm_epsilon: Epsilon of batch borm layers.\n    Returns:\n        Output tensor for the block.\n    \"\"\"", "\n", "filters1", ",", "filters2", ",", "filters3", "=", "filters", "\n", "if", "backend", ".", "image_data_format", "(", ")", "==", "'channels_last'", ":", "\n", "        ", "bn_axis", "=", "3", "\n", "", "else", ":", "\n", "        ", "bn_axis", "=", "1", "\n", "", "conv_name_base", "=", "'res'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "bn_name_base", "=", "'bn'", "+", "str", "(", "stage", ")", "+", "block", "+", "'_branch'", "\n", "\n", "\n", "# Kernel: 1", "\n", "# Stride: Dynamic", "\n", "\n", "shortcut", "=", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "strides", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'1'", ")", "(", "input_tensor", ")", "\n", "shortcut", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'1'", ")", "(", "shortcut", ")", "\n", "\n", "\n", "# Kernel: 1", "\n", "# Stride: 1", "\n", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters1", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2a'", ")", "(", "input_tensor", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2a'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "# Kernel: 3", "\n", "# Strides: Dynamic", "\n", "\n", "if", "strides", "[", "0", "]", ">", "1", ":", "\n", "        ", "x", "=", "fixed_padding", "(", "x", ",", "kernel_size", ",", "data_format", "=", "backend", ".", "image_data_format", "(", ")", ")", "\n", "padding", "=", "'valid'", "\n", "", "else", ":", "\n", "        ", "padding", "=", "'same'", "\n", "\n", "", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters2", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "strides", "=", "strides", ",", "\n", "padding", "=", "padding", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2b'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2b'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "\n", "# Kernel: 1", "\n", "# Stride: 1", "\n", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "filters3", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "conv_name_base", "+", "'2c'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "bn_name_base", "+", "'2c'", ")", "(", "x", ")", "\n", "\n", "x", "=", "layers", ".", "add", "(", "[", "x", ",", "shortcut", "]", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50": [[273, 384], ["dict", "tf_resnet.fixed_padding", "tf_resnet.conv_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.conv_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.conv_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tf_resnet.conv_block", "tf_resnet.identity_block", "tf_resnet.identity_block", "tensorflow.python.keras.models.Model", "layers.Input", "tensorflow.python.keras.backend.image_data_format", "tensorflow.python.keras.backend.image_data_format", "layers.Conv2D", "layers.BatchNormalization", "layers.Activation", "layers.MaxPooling2D", "layers.GlobalAveragePooling2D", "models.Model.load_weights", "tensorflow.keras.backend.is_keras_tensor", "layers.Input", "layers.Permute", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "layers.Dense", "layers.Activation", "tf_resnet._gen_l2_regularizer", "tensorflow.python.keras.initializers.RandomNormal", "tf_resnet._gen_l2_regularizer", "tf_resnet._gen_l2_regularizer"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.fixed_padding", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.conv_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.conv_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.conv_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.conv_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.identity_block", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet._gen_l2_regularizer"], ["", "def", "resnet50", "(", "\n", "include_top", "=", "True", ",", "\n", "weights", "=", "'imagenet'", ",", "\n", "input_tensor", "=", "None", ",", "\n", "input_shape", "=", "None", ",", "\n", "pooling", "=", "None", ",", "\n", "classes", "=", "1000", ",", "\n", "batch_size", "=", "None", ",", "\n", "use_l2_regularizer", "=", "True", ",", "\n", "rescale_inputs", "=", "False", ",", "\n", "batch_norm_decay", "=", "0.9", ",", "\n", "batch_norm_epsilon", "=", "1e-5", ",", "\n", "batch_norm_trainable", "=", "True", ",", "\n", "width_multiplier", "=", "1", ")", ":", "\n", "    ", "\"\"\"Instantiates the ResNet50 architecture.\n    Args:\n        num_classes: `int` number of classes for image classification.\n        batch_size: Size of the batches for each step.\n        use_l2_regularizer: whether to use L2 regularizer on Conv/Dense layer.\n        rescale_inputs: whether to rescale inputs from 0 to 1.\n        batch_norm_decay: Moment of batch norm layers.\n        batch_norm_epsilon: Epsilon of batch borm layers.\n    Returns:\n        A Keras model instance.\n    \"\"\"", "\n", "\n", "if", "input_tensor", "is", "None", ":", "\n", "        ", "img_input", "=", "layers", ".", "Input", "(", "shape", "=", "input_shape", ",", "batch_size", "=", "batch_size", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "tf", ".", "keras", ".", "backend", ".", "is_keras_tensor", "(", "input_tensor", ")", ":", "\n", "            ", "img_input", "=", "layers", ".", "Input", "(", "tensor", "=", "input_tensor", ",", "shape", "=", "input_shape", ")", "\n", "", "else", ":", "\n", "            ", "img_input", "=", "input_tensor", "\n", "\n", "", "", "x", "=", "img_input", "\n", "\n", "if", "backend", ".", "image_data_format", "(", ")", "==", "'channels_first'", ":", "\n", "        ", "x", "=", "layers", ".", "Permute", "(", "(", "3", ",", "1", ",", "2", ")", ")", "(", "x", ")", "\n", "bn_axis", "=", "1", "\n", "", "else", ":", "# channels_last", "\n", "        ", "bn_axis", "=", "3", "\n", "\n", "", "block_config", "=", "dict", "(", "\n", "use_l2_regularizer", "=", "use_l2_regularizer", ",", "\n", "batch_norm_decay", "=", "batch_norm_decay", ",", "\n", "batch_norm_epsilon", "=", "batch_norm_epsilon", ",", "\n", "batch_norm_trainable", "=", "batch_norm_trainable", ")", "\n", "\n", "#x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(x)", "\n", "x", "=", "fixed_padding", "(", "x", ",", "7", ",", "backend", ".", "image_data_format", "(", ")", ")", "\n", "x", "=", "layers", ".", "Conv2D", "(", "\n", "64", "*", "width_multiplier", ",", "\n", "kernel_size", "=", "(", "7", ",", "7", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "\n", "padding", "=", "'valid'", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "'he_normal'", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "'conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "BatchNormalization", "(", "\n", "axis", "=", "bn_axis", ",", "\n", "momentum", "=", "batch_norm_decay", ",", "\n", "epsilon", "=", "batch_norm_epsilon", ",", "\n", "trainable", "=", "batch_norm_trainable", ",", "\n", "name", "=", "'bn_conv1'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "Activation", "(", "'relu'", ")", "(", "x", ")", "\n", "x", "=", "layers", ".", "MaxPooling2D", "(", "(", "3", ",", "3", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ")", "(", "x", ")", "\n", "\n", "x", "=", "conv_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "64", ",", "64", ",", "256", "]", ")", "*", "width_multiplier", ",", "stage", "=", "2", ",", "block", "=", "'a'", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "64", ",", "64", ",", "256", "]", ")", "*", "width_multiplier", ",", "stage", "=", "2", ",", "block", "=", "'b'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "64", ",", "64", ",", "256", "]", ")", "*", "width_multiplier", ",", "stage", "=", "2", ",", "block", "=", "'c'", ",", "**", "block_config", ")", "\n", "\n", "x", "=", "conv_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "128", ",", "128", ",", "512", "]", ")", "*", "width_multiplier", ",", "stage", "=", "3", ",", "block", "=", "'a'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "128", ",", "128", ",", "512", "]", ")", "*", "width_multiplier", ",", "stage", "=", "3", ",", "block", "=", "'b'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "128", ",", "128", ",", "512", "]", ")", "*", "width_multiplier", ",", "stage", "=", "3", ",", "block", "=", "'c'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "128", ",", "128", ",", "512", "]", ")", "*", "width_multiplier", ",", "stage", "=", "3", ",", "block", "=", "'d'", ",", "**", "block_config", ")", "\n", "\n", "x", "=", "conv_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'a'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'b'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'c'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'d'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'e'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "256", ",", "256", ",", "1024", "]", ")", "*", "width_multiplier", ",", "stage", "=", "4", ",", "block", "=", "'f'", ",", "**", "block_config", ")", "\n", "\n", "x", "=", "conv_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "512", ",", "512", ",", "2048", "]", ")", "*", "width_multiplier", ",", "stage", "=", "5", ",", "block", "=", "'a'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "512", ",", "512", ",", "2048", "]", ")", "*", "width_multiplier", ",", "stage", "=", "5", ",", "block", "=", "'b'", ",", "**", "block_config", ")", "\n", "x", "=", "identity_block", "(", "x", ",", "3", ",", "np", ".", "array", "(", "[", "512", ",", "512", ",", "2048", "]", ")", "*", "width_multiplier", ",", "stage", "=", "5", ",", "block", "=", "'c'", ",", "**", "block_config", ")", "\n", "\n", "x", "=", "layers", ".", "GlobalAveragePooling2D", "(", ")", "(", "x", ")", "\n", "\n", "if", "include_top", ":", "\n", "        ", "x", "=", "layers", ".", "Dense", "(", "\n", "classes", ",", "\n", "kernel_initializer", "=", "initializers", ".", "RandomNormal", "(", "stddev", "=", "0.01", ")", ",", "\n", "kernel_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "bias_regularizer", "=", "_gen_l2_regularizer", "(", "use_l2_regularizer", ")", ",", "\n", "name", "=", "'fc1000'", ")", "(", "\n", "x", ")", "\n", "\n", "# A softmax that is followed by the model loss must be done cannot be done", "\n", "# in float16 due to numeric issues. So we pass dtype=float32.", "\n", "x", "=", "layers", ".", "Activation", "(", "'softmax'", ",", "dtype", "=", "'float32'", ")", "(", "x", ")", "\n", "\n", "\n", "# Create model.", "\n", "", "model", "=", "models", ".", "Model", "(", "img_input", ",", "x", ",", "name", "=", "'resnet50'", ")", "\n", "\n", "if", "weights", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_weights", "(", "weights", ")", "\n", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.__init__": [[12, 24], ["os.path.exists", "tf_resnet_feature_extractor.TFResNet50FeatureExtractor.build_model"], "methods", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.build_model"], ["    ", "def", "__init__", "(", "self", ",", "input_height", "=", "224", ",", "input_width", "=", "224", ",", "weights", "=", "None", ",", "width_multiplier", "=", "1", ",", "center_crop", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "input_height", "=", "input_height", "\n", "self", ".", "input_width", "=", "input_width", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "width_multiplier", "=", "width_multiplier", "\n", "self", ".", "center_crop", "=", "center_crop", "\n", "self", ".", "device", "=", "device", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "self", ".", "weights", ")", "\n", "\n", "self", ".", "build_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.build_model": [[25, 35], ["tf_resnet.resnet50"], "methods", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "\n", "        ", "backbone", "=", "resnet50", "(", "\n", "include_top", "=", "False", ",", "\n", "weights", "=", "self", ".", "weights", ",", "\n", "input_shape", "=", "(", "self", ".", "input_height", ",", "self", ".", "input_width", ",", "3", ")", ",", "\n", "width_multiplier", "=", "self", ".", "width_multiplier", "\n", ")", "\n", "\n", "self", ".", "model", "=", "backbone", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.preprocess": [[36, 52], ["tensorflow.io.read_file", "tensorflow.io.decode_image", "tensorflow.image.convert_image_dtype", "tensorflow.reshape", "tensorflow.clip_by_value", "tensorflow.keras.preprocessing.image.smart_resize", "tensorflow.image.resize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "image_fp", ")", ":", "\n", "\n", "        ", "contents", "=", "tf", ".", "io", ".", "read_file", "(", "image_fp", ")", "\n", "image", "=", "tf", ".", "io", ".", "decode_image", "(", "contents", ",", "channels", "=", "3", ",", "dtype", "=", "tf", ".", "dtypes", ".", "uint8", ",", "expand_animations", "=", "False", ")", "\n", "\n", "# Convert the image to [0, 1]", "\n", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "if", "self", ".", "center_crop", ":", "\n", "            ", "image", "=", "tf", ".", "keras", ".", "preprocessing", ".", "image", ".", "smart_resize", "(", "image", ",", "[", "self", ".", "input_height", ",", "self", ".", "input_width", "]", ",", "interpolation", "=", "'bilinear'", ")", "\n", "", "else", ":", "\n", "            ", "image", "=", "tf", ".", "image", ".", "resize", "(", "image", ",", "[", "self", ".", "input_height", ",", "self", ".", "input_width", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ",", "antialias", "=", "True", ")", "\n", "", "image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "self", ".", "input_height", ",", "self", ".", "input_width", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.", ",", "1.", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.extract_features": [[53, 61], ["tf_resnet_feature_extractor.TFResNet50FeatureExtractor.preprocess", "tf_resnet_feature_extractor.TFResNet50FeatureExtractor.model", "features[].numpy", "tensorflow.expand_dims"], "methods", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.preprocess"], ["", "def", "extract_features", "(", "self", ",", "image_fp", ")", ":", "\n", "        ", "\"\"\" Load the image and extract features.\n        \"\"\"", "\n", "\n", "processed_image", "=", "self", ".", "preprocess", "(", "image_fp", ")", "\n", "features", "=", "self", ".", "model", "(", "tf", ".", "expand_dims", "(", "processed_image", ",", "0", ")", ",", "training", "=", "False", ")", "\n", "\n", "return", "features", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.TFResNet50FeatureExtractor.extract_features_batch": [[62, 87], ["iter", "numpy.empty", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "dataset.batch.batch.map", "dataset.batch.batch.batch", "tqdm.tqdm", "tensorflow.device", "len", "tf_resnet_feature_extractor.TFResNet50FeatureExtractor.model", "tf_resnet_feature_extractor.TFResNet50FeatureExtractor.numpy"], "methods", ["None"], ["", "def", "extract_features_batch", "(", "self", ",", "image_fp_list", ",", "batch_size", "=", "32", ",", "use_pbar", "=", "False", ")", ":", "\n", "\n", "        ", "with", "tf", ".", "device", "(", "\"CPU:0\"", ")", ":", "\n", "            ", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "image_fp_list", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "self", ".", "preprocess", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "dataset", "=", "dataset", ".", "batch", "(", "batch_size", ",", "drop_remainder", "=", "False", ")", "\n", "\n", "", "dataset_iter", "=", "iter", "(", "dataset", ")", "\n", "\n", "features", "=", "np", ".", "empty", "(", "[", "len", "(", "image_fp_list", ")", ",", "self", ".", "model", ".", "output", ".", "shape", "[", "1", "]", "]", ")", "\n", "feature_index", "=", "0", "\n", "\n", "if", "use_pbar", ":", "\n", "            ", "dataset_iter", "=", "tqdm", ".", "tqdm", "(", "dataset_iter", ",", "leave", "=", "False", ")", "\n", "\n", "", "with", "tf", ".", "device", "(", "self", ".", "device", ")", ":", "\n", "\n", "            ", "for", "batch", "in", "dataset_iter", ":", "\n", "\n", "                ", "batch_features", "=", "self", ".", "model", "(", "batch", ",", "training", "=", "False", ")", "\n", "num_in_batch", "=", "batch", ".", "shape", "[", "0", "]", "\n", "features", "[", "feature_index", ":", "feature_index", "+", "num_in_batch", "]", "=", "batch_features", ".", "numpy", "(", ")", "\n", "feature_index", "+=", "num_in_batch", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet_feature_extractor.load_feature_extractor": [[88, 120], ["tf_resnet_feature_extractor.TFResNet50FeatureExtractor", "tensorflow.device", "tf_resnet_feature_extractor.TFResNet50FeatureExtractor"], "function", ["None"], ["", "", "def", "load_feature_extractor", "(", "model_spec", ",", "device", "=", "None", ",", "input_height", "=", "224", ",", "input_width", "=", "224", ",", "center_crop", "=", "True", ")", ":", "\n", "    ", "\"\"\" The tensorflow resnet50 models have all been standardized. So we simply load the specified weights into the resnet50 model.\n    \"\"\"", "\n", "\n", "assert", "model_spec", "[", "'backbone'", "]", "in", "[", "configs", ".", "RESNET50", ",", "configs", ".", "RESNET50_X4", "]", ",", "\"Unsupported tensorflow feature extractor: %s\"", "%", "model_spec", "[", "'backbone'", "]", "\n", "\n", "model_weights_fp", "=", "model_spec", "[", "'weights'", "]", "\n", "\n", "width_multiplier", "=", "1", "\n", "if", "model_spec", "[", "'backbone'", "]", "==", "configs", ".", "RESNET50_X4", ":", "\n", "        ", "width_multiplier", "=", "4", "\n", "\n", "", "if", "device", "is", "not", "None", ":", "\n", "        ", "with", "tf", ".", "device", "(", "device", ")", ":", "\n", "            ", "feature_extractor", "=", "TFResNet50FeatureExtractor", "(", "\n", "input_height", "=", "input_height", ",", "\n", "input_width", "=", "input_width", ",", "\n", "weights", "=", "model_weights_fp", ",", "\n", "width_multiplier", "=", "width_multiplier", ",", "\n", "center_crop", "=", "center_crop", ",", "\n", "device", "=", "device", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "feature_extractor", "=", "TFResNet50FeatureExtractor", "(", "\n", "input_height", "=", "input_height", ",", "\n", "input_width", "=", "input_width", ",", "\n", "weights", "=", "model_weights_fp", ",", "\n", "width_multiplier", "=", "width_multiplier", ",", "\n", "center_crop", "=", "center_crop", ",", "\n", ")", "\n", "\n", "", "return", "feature_extractor", "", "", ""]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.linear_evaluation.logreg": [[10, 58], ["sklearn.linear_model.LogisticRegression", "sklearn.model_selection.GridSearchCV.fit", "sklearn.model_selection.GridSearchCV.predict", "sklearn.preprocessing.StandardScaler().fit", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "sklearn.model_selection.GridSearchCV", "sklearn.metrics.accuracy_score", "sklearn.model_selection.PredefinedSplit", "sklearn.preprocessing.StandardScaler"], "function", ["None"], ["def", "logreg", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "max_iter", "=", "1000", ",", "grid_search", "=", "False", ",", "predefined_val_indices", "=", "None", ",", "standardize", "=", "False", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "if", "standardize", ":", "\n", "        ", "scaler", "=", "sklearn", ".", "preprocessing", ".", "StandardScaler", "(", ")", ".", "fit", "(", "X_train", ")", "\n", "X_train", "=", "scaler", ".", "transform", "(", "X_train", ")", "\n", "X_test", "=", "scaler", ".", "transform", "(", "X_test", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "X_train", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_train", ",", "norm", "=", "'l2'", ")", "\n", "X_test", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_test", ",", "norm", "=", "'l2'", ")", "\n", "\n", "", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "'l2'", ",", "\n", "dual", "=", "False", ",", "\n", "tol", "=", "1e-4", ",", "\n", "C", "=", "1.0", ",", "\n", "fit_intercept", "=", "True", ",", "\n", "class_weight", "=", "None", ",", "\n", "solver", "=", "'lbfgs'", ",", "\n", "max_iter", "=", "max_iter", ",", "\n", "multi_class", "=", "'multinomial'", ",", "\n", "warm_start", "=", "True", ",", "# GVH: GridSearch does NOT use this.", "\n", "n_jobs", "=", "-", "1", "\n", ")", "\n", "\n", "if", "grid_search", ":", "\n", "\n", "        ", "C_values", "=", "[", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1", ",", "1.", ",", "10.", ",", "100.", ",", "1000.", "]", "\n", "parameters", "=", "{", "'C'", ":", "C_values", "}", "\n", "\n", "if", "predefined_val_indices", "is", "not", "None", ":", "\n", "            ", "cv", "=", "PredefinedSplit", "(", "test_fold", "=", "predefined_val_indices", ")", "\n", "", "else", ":", "\n", "            ", "cv", "=", "3", "\n", "", "clf", "=", "GridSearchCV", "(", "clf", ",", "parameters", ",", "n_jobs", "=", "-", "1", ",", "cv", "=", "cv", ",", "refit", "=", "True", ")", "\n", "\n", "", "clf", "=", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "y_pred", "=", "clf", ".", "predict", "(", "X_test", ")", "\n", "\n", "results", "=", "{", "\n", "'acc'", ":", "accuracy_score", "(", "y_test", ",", "y_pred", ")", ",", "\n", "}", "\n", "\n", "if", "grid_search", ":", "\n", "        ", "results", "[", "'best_param'", "]", "=", "clf", ".", "best_params_", "[", "'C'", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.linear_evaluation.linearsvc": [[61, 106], ["sklearn.svm.LinearSVC", "sklearn.model_selection.GridSearchCV.fit", "sklearn.model_selection.GridSearchCV.predict", "sklearn.preprocessing.StandardScaler().fit", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "sklearn.model_selection.GridSearchCV", "sklearn.metrics.accuracy_score", "sklearn.model_selection.PredefinedSplit", "sklearn.preprocessing.StandardScaler"], "function", ["None"], ["", "def", "linearsvc", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "max_iter", "=", "1000", ",", "grid_search", "=", "False", ",", "predefined_val_indices", "=", "None", ",", "standardize", "=", "False", ",", "normalize", "=", "True", ",", "dual", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    \"\"\"", "\n", "\n", "if", "standardize", ":", "\n", "        ", "scaler", "=", "sklearn", ".", "preprocessing", ".", "StandardScaler", "(", ")", ".", "fit", "(", "X_train", ")", "\n", "X_train", "=", "scaler", ".", "transform", "(", "X_train", ")", "\n", "X_test", "=", "scaler", ".", "transform", "(", "X_test", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "X_train", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_train", ",", "norm", "=", "'l2'", ")", "\n", "X_test", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_test", ",", "norm", "=", "'l2'", ")", "\n", "\n", "", "clf", "=", "LinearSVC", "(", "\n", "random_state", "=", "0", ",", "\n", "tol", "=", "1e-5", ",", "\n", "C", "=", "1.", ",", "\n", "dual", "=", "dual", ",", "\n", "class_weight", "=", "None", ",", "\n", "max_iter", "=", "max_iter", "\n", ")", "\n", "\n", "if", "grid_search", ":", "\n", "\n", "        ", "C_values", "=", "[", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1", ",", "1.", ",", "10.", ",", "100.", ",", "1000.", "]", "\n", "parameters", "=", "{", "'C'", ":", "C_values", "}", "\n", "\n", "if", "predefined_val_indices", "is", "not", "None", ":", "\n", "            ", "cv", "=", "PredefinedSplit", "(", "test_fold", "=", "predefined_val_indices", ")", "\n", "", "else", ":", "\n", "            ", "cv", "=", "3", "\n", "", "clf", "=", "GridSearchCV", "(", "clf", ",", "parameters", ",", "n_jobs", "=", "-", "1", ",", "cv", "=", "cv", ",", "refit", "=", "True", ")", "\n", "\n", "", "clf", "=", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "y_pred", "=", "clf", ".", "predict", "(", "X_test", ")", "\n", "\n", "results", "=", "{", "\n", "'acc'", ":", "accuracy_score", "(", "y_test", ",", "y_pred", ")", "\n", "}", "\n", "\n", "if", "grid_search", ":", "\n", "        ", "results", "[", "'best_param'", "]", "=", "clf", ".", "best_params_", "[", "'C'", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.linear_evaluation.sgd": [[109, 159], ["sklearn.linear_model.SGDClassifier", "sklearn.model_selection.GridSearchCV.fit", "sklearn.model_selection.GridSearchCV.predict", "sklearn.preprocessing.StandardScaler().fit", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.StandardScaler().fit.transform", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "sklearn.model_selection.GridSearchCV", "sklearn.metrics.accuracy_score", "sklearn.model_selection.PredefinedSplit", "sklearn.preprocessing.StandardScaler"], "function", ["None"], ["", "def", "sgd", "(", "X_train", ",", "y_train", ",", "X_test", ",", "y_test", ",", "max_iter", "=", "1000", ",", "loss_type", "=", "'hinge'", ",", "grid_search", "=", "False", ",", "predefined_val_indices", "=", "None", ",", "standardize", "=", "False", ",", "normalize", "=", "True", ")", ":", "\n", "\n", "    ", "if", "standardize", ":", "\n", "        ", "scaler", "=", "sklearn", ".", "preprocessing", ".", "StandardScaler", "(", ")", ".", "fit", "(", "X_train", ")", "\n", "X_train", "=", "scaler", ".", "transform", "(", "X_train", ")", "\n", "X_test", "=", "scaler", ".", "transform", "(", "X_test", ")", "\n", "\n", "", "if", "normalize", ":", "\n", "        ", "X_train", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_train", ",", "norm", "=", "'l2'", ")", "\n", "X_test", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "X_test", ",", "norm", "=", "'l2'", ")", "\n", "\n", "\n", "", "clf", "=", "SGDClassifier", "(", "\n", "loss", "=", "loss_type", ",", "\n", "penalty", "=", "'l2'", ",", "\n", "alpha", "=", "0.0001", ",", "\n", "fit_intercept", "=", "True", ",", "\n", "max_iter", "=", "max_iter", ",", "\n", "tol", "=", "1e-5", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_state", "=", "0", ",", "\n", "n_jobs", "=", "-", "1", ",", "\n", "learning_rate", "=", "'optimal'", ",", "\n", "class_weight", "=", "None", ",", "\n", "warm_start", "=", "True", "\n", ")", "\n", "\n", "if", "grid_search", ":", "\n", "\n", "        ", "alpha_values", "=", "[", "0.000001", ",", "0.00001", ",", "0.0001", ",", "0.001", ",", "0.01", ",", "0.1", ",", "1.", ",", "10.", "]", "\n", "parameters", "=", "{", "'alpha'", ":", "alpha_values", "}", "\n", "\n", "if", "predefined_val_indices", "is", "not", "None", ":", "\n", "            ", "cv", "=", "PredefinedSplit", "(", "test_fold", "=", "predefined_val_indices", ")", "\n", "", "else", ":", "\n", "            ", "cv", "=", "3", "\n", "", "clf", "=", "GridSearchCV", "(", "clf", ",", "parameters", ",", "n_jobs", "=", "-", "1", ",", "cv", "=", "cv", ",", "refit", "=", "True", ")", "\n", "\n", "", "clf", "=", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "y_pred", "=", "clf", ".", "predict", "(", "X_test", ")", "\n", "\n", "results", "=", "{", "\n", "'acc'", ":", "accuracy_score", "(", "y_test", ",", "y_pred", ")", "\n", "}", "\n", "\n", "if", "grid_search", ":", "\n", "        ", "results", "[", "'best_param'", "]", "=", "clf", ".", "best_params_", "[", "'alpha'", "]", "\n", "\n", "", "return", "results", "", "", ""]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.list_loader.__init__": [[17, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "im_paths", ",", "transform", "=", "None", ")", ":", "\n", "# im_paths is a list", "\n", "        ", "self", ".", "im_paths", "=", "im_paths", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.list_loader.__len__": [[22, 24], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "im_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.list_loader.__getitem__": [[25, 31], ["pt_resnet_feature_extractor.loader", "pt_resnet_feature_extractor.list_loader.transform"], "methods", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.loader"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "im_paths", "[", "index", "]", "\n", "sample", "=", "loader", "(", "path", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "", "return", "sample", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.__init__": [[36, 47], ["torchvision.transforms.Compose", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "device", ",", "im_size", "=", "256", ",", "im_size_crop", "=", "224", ",", "feature_shape", "=", "2048", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "feature_shape", "=", "feature_shape", "\n", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "im_size", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "im_size_crop", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.PTResNet50FeatureExtractor.extract_features_batch": [[49, 82], ["torch.utils.data.DataLoader", "numpy.empty", "numpy.hstack", "numpy.all", "pt_resnet_feature_extractor.list_loader", "torch.no_grad", "enumerate", "len", "images.to.to.to", "pt_resnet_feature_extractor.PTResNet50FeatureExtractor.model", "op.squeeze().squeeze.squeeze().squeeze.squeeze().squeeze", "op.squeeze().squeeze.squeeze().squeeze.cpu().data.numpy", "numpy.hstack.append", "numpy.arange", "indices.cpu().data.numpy", "op.squeeze().squeeze.squeeze().squeeze.squeeze", "op.squeeze().squeeze.squeeze().squeeze.cpu", "indices.cpu"], "methods", ["None"], ["", "def", "extract_features_batch", "(", "self", ",", "image_fp_list", ",", "batch_size", "=", "32", ",", "num_workers", "=", "6", ")", ":", "\n", "\n", "        ", "pin_mem", "=", "True", "\n", "if", "self", ".", "device", "==", "'cpu'", ":", "\n", "            ", "pin_mem", "=", "False", "\n", "\n", "", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "list_loader", "(", "image_fp_list", ",", "transform", "=", "self", ".", "transform", ")", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "pin_memory", "=", "pin_mem", ")", "\n", "\n", "\n", "features", "=", "np", ".", "empty", "(", "[", "len", "(", "image_fp_list", ")", ",", "self", ".", "feature_shape", "]", ")", "\n", "feature_index", "=", "0", "\n", "ids", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "ii", ",", "(", "images", ",", "indices", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "                ", "images", "=", "images", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "op", "=", "self", ".", "model", "(", "images", ")", "\n", "op", "=", "op", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", "\n", "feats", "=", "op", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "num_in_batch", "=", "feats", ".", "shape", "[", "0", "]", "\n", "\n", "features", "[", "feature_index", ":", "feature_index", "+", "num_in_batch", "]", "=", "feats", "\n", "ids", ".", "append", "(", "indices", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "feature_index", "+=", "num_in_batch", "\n", "\n", "# double check that the image order is as expected i.e. sequential", "\n", "", "", "ids", "=", "np", ".", "hstack", "(", "ids", ")", "\n", "assert", "np", ".", "all", "(", "ids", "==", "np", ".", "arange", "(", "ids", ".", "shape", "[", "0", "]", ")", ")", ",", "\"The image features were extracted out of order\"", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.loader": [[8, 13], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visipedia_newt.benchmark.pt_resnet_feature_extractor.load_feature_extractor": [[84, 213], ["torch.nn.Sequential", "models.resnet50.to", "models.resnet50.eval", "pt_resnet_feature_extractor.PTResNet50FeatureExtractor", "torchvision.models.resnet50", "torch.nn.Identity", "torch.load", "list", "models.resnet50.load_state_dict", "k.replace", "torch.load.keys", "torchvision.models.resnet50", "torch.nn.Identity", "torch.load", "list", "models.resnet50.load_state_dict", "torch.load.items", "torch.load.keys", "torchvision.models.resnet50", "list", "k.startswith", "torchvision.models.resnet50", "models.resnet50.children", "k.startswith", "torchvision.models.resnet50", "torch.nn.Linear", "torch.load", "models.resnet50.load_state_dict", "torchvision.models.resnet50", "torch.nn.Linear", "torch.load", "models.resnet50.load_state_dict", "torchvision.models.resnet50", "torch.nn.Linear", "torch.load", "models.resnet50.load_state_dict", "len", "torchvision.models.resnet50", "torch.nn.Linear", "torch.load", "models.resnet50.load_state_dict", "k.replace", "torchvision.models.resnet50", "torch.nn.Linear", "torch.load", "models.resnet50.load_state_dict", "checkpoint[].items", "torchvision.models.resnet50", "torch.nn.Identity", "torch.load", "list", "models.resnet50.load_state_dict", "torch.load.keys", "torchvision.models.resnet50", "torch.nn.Identity", "torch.load", "list", "models.resnet50.load_state_dict", "ValueError", "k.startswith", "k.replace", "torch.load.keys", "k.startswith", "state_dict[].items", "len"], "function", ["home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50", "home.repos.pwc.inspect_result.visipedia_newt.benchmark.tf_resnet.resnet50"], ["", "", "def", "load_feature_extractor", "(", "model_spec", ",", "device", ")", ":", "\n", "    ", "\"\"\" The pytorch models have not been standardized, so we need to do some custom surgery for different checkpoint files.\n\n    For ImageNet MOCOv2 you need to download the pretrained model from here:\n    https://dl.fbaipublicfiles.com/moco/moco_checkpoints/moco_v2_800ep/moco_v2_800ep_pretrain.pth.tar\n    rename: imagenet_moco_v2_800ep_pretrain.pth.tar\n    For ImageNet SWAV download:\n    https://dl.fbaipublicfiles.com/deepcluster/swav_800ep_pretrain.pth.tar\n    rename: imagenet_swav_800ep_pretrain.pth.tar\n    \"\"\"", "\n", "\n", "model_type", "=", "model_spec", "[", "'name'", "]", "\n", "model_weights_fp", "=", "model_spec", "[", "'weights'", "]", "\n", "\n", "if", "model_type", "==", "'imagenet_swav'", ":", "\n", "# or could load from hub model", "\n", "# model = torch.hub.load('facebookresearch/swav', 'resnet50')", "\n", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "state_dict", "=", "{", "k", ".", "replace", "(", "\"module.\"", ",", "\"\"", ")", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "'projection'", "in", "k", "or", "'prototypes'", "in", "k", ":", "\n", "                ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'imagenet_moco_v2'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "# rename moco pre-trained keys", "\n", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# retain only encoder_q up to before the embedding layer", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.encoder_q'", ")", "and", "not", "k", ".", "startswith", "(", "'module.encoder_q.fc'", ")", ":", "\n", "# remove prefix", "\n", "                ", "state_dict", "[", "k", "[", "len", "(", "\"module.encoder_q.\"", ")", ":", "]", "]", "=", "state_dict", "[", "k", "]", "\n", "# delete renamed or unused k", "\n", "", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'imagenet_supervised'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'random'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2018_supervised'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "# This model was actually trained with 10000 classes for the fc layer", "\n", "# but only 8142 (the number in inat2018) were actually updated", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "10000", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_mini_supervised'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "10000", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_supervised'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "10000", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_mini_supervised_from_scratch'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "10000", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict", "=", "{", "k", ".", "replace", "(", "\"module.\"", ",", "\"\"", ")", ":", "v", "for", "k", ",", "v", "in", "checkpoint", "[", "'state_dict'", "]", ".", "items", "(", ")", "}", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_supervised_from_scratch'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "10000", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_mini_moco_v2'", ":", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "# rename moco pre-trained keys", "\n", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# retain only encoder_q up to before the embedding layer", "\n", "            ", "if", "k", ".", "startswith", "(", "'module.encoder_q'", ")", "and", "not", "k", ".", "startswith", "(", "'module.encoder_q.fc'", ")", ":", "\n", "# remove prefix", "\n", "                ", "state_dict", "[", "k", "[", "len", "(", "\"module.encoder_q.\"", ")", ":", "]", "]", "=", "state_dict", "[", "k", "]", "\n", "# delete renamed or unused k", "\n", "", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "elif", "model_type", "==", "'inat2021_mini_swav'", "or", "model_type", "==", "'inat2021_mini_swav_1k'", ":", "\n", "# or could load from hub model", "\n", "# model = torch.hub.load('facebookresearch/swav', 'resnet50')", "\n", "\n", "        ", "model", "=", "models", ".", "resnet50", "(", "pretrained", "=", "False", ")", "\n", "model", ".", "fc", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_weights_fp", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "state_dict", "=", "{", "k", ".", "replace", "(", "\"module.\"", ",", "\"\"", ")", ":", "v", "for", "k", ",", "v", "in", "state_dict", "[", "'state_dict'", "]", ".", "items", "(", ")", "}", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "'projection'", "in", "k", "or", "'prototypes'", "in", "k", ":", "\n", "                ", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown pytorch model: %s\"", "%", "model_type", ")", "\n", "\n", "\n", "# remove the final fully connected layer so the model only operates with post average pool features", "\n", "", "model", "=", "torch", ".", "nn", ".", "Sequential", "(", "*", "(", "list", "(", "model", ".", "children", "(", ")", ")", "[", ":", "-", "1", "]", ")", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "feature_extractor", "=", "PTResNet50FeatureExtractor", "(", "model", ",", "device", ")", "\n", "\n", "return", "feature_extractor", "", "", ""]]}