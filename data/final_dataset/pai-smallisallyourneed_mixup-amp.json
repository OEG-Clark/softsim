{"home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.InputExample.__init__": [[463, 468], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.InputFeatures.__init__": [[473, 478], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_id", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_id", "=", "label_id", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.InputFeatures.__getitem__": [[479, 482], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "[", "self", ".", "input_ids", ",", "self", ".", "input_mask", ",", "\n", "self", ".", "segment_ids", ",", "self", ".", "label_id", "]", "[", "item", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.DatasetProcessor.get_train_examples": [[485, 487], ["None"], "methods", ["None"], ["    ", "def", "get_train_examples", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.DatasetProcessor.get_dev_examples": [[488, 490], ["None"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.DatasetProcessor.get_test_examples": [[491, 493], ["None"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.DatasetProcessor.get_labels": [[494, 496], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST1_Processor.__init__": [[501, 514], ["print", "data_loader.SST1_Processor._create_examples", "data_loader.csv_reader", "data_loader.csv_reader", "data_loader.SST1_Processor.get_train_examples", "data_loader.SST1_Processor.get_test_examples", "open", "zip", "y.append", "x.append"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_test_examples"], ["def", "__init__", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "train_file", "=", "\"./data/SST1/train.tsv\"", "\n", "test_file", "=", "\"./data/SST1/test.tsv\"", "\n", "print", "(", "\"processing train_file{},test_file\"", ".", "format", "(", "train_file", ",", "test_file", ")", ")", "\n", "self", ".", "_train_set", ",", "self", ".", "_test_set", "=", "csv_reader", "(", "train_file", ")", ",", "csv_reader", "(", "test_file", ")", "\n", "self", ".", "train_examples", ",", "self", ".", "test_examples", "=", "self", ".", "get_train_examples", "(", ")", ",", "self", ".", "get_test_examples", "(", ")", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/SST1/stsa.fine.phrases.train\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "y", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "x", ".", "append", "(", "line", "[", "2", ":", "]", ")", "\n", "", "", "self", ".", "train_examples_extra", "=", "self", ".", "_create_examples", "(", "zip", "(", "x", ",", "y", ")", ",", "\"train\"", ")", "\n", "self", ".", "train_examples", "=", "self", ".", "train_examples", "+", "self", ".", "train_examples_extra", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST1_Processor.get_train_examples": [[515, 520], ["data_loader.SST1_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_train_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_train_set", ",", "\"train\"", ")", "\n", "print", "(", "'getting train examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST1_Processor.get_test_examples": [[521, 526], ["data_loader.SST1_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_test_set", ",", "\"test\"", ")", "\n", "print", "(", "'getting test examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST1_Processor.get_labels": [[527, 533], ["set", "sorted", "set.add", "list"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "example", "in", "self", ".", "train_examples", ":", "\n", "            ", "label_set", ".", "add", "(", "example", ".", "label", ")", "\n", "", "return", "sorted", "(", "list", "(", "label_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST1_Processor._create_examples": [[534, 546], ["enumerate", "examples.append", "data_loader.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "dataset", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "data", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "guid", ",", "\n", "text_a", "=", "data", "[", "0", "]", ",", "\n", "label", "=", "data", "[", "1", "]", "\n", ")", ")", "\n", "# return examples", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST2_Processor.__init__": [[551, 565], ["data_loader.SST2_Processor._create_examples", "print", "open", "zip", "data_loader.csv_reader", "data_loader.csv_reader", "data_loader.SST2_Processor.get_train_examples", "data_loader.SST2_Processor.get_test_examples", "y.append", "x.append"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_test_examples"], ["def", "__init__", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "train_file", "=", "\"./data/SST2/train.tsv\"", "\n", "test_file", "=", "\"./data/SST2/test.tsv\"", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/SST2/stsa.binary.phrases.train\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "y", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "x", ".", "append", "(", "line", "[", "2", ":", "]", ")", "\n", "", "", "self", ".", "train_examples_extra", "=", "self", ".", "_create_examples", "(", "zip", "(", "x", ",", "y", ")", ",", "\"train\"", ")", "\n", "print", "(", "\"processing train_file{},test_file\"", ".", "format", "(", "train_file", ",", "test_file", ")", ")", "\n", "self", ".", "_train_set", ",", "self", ".", "_test_set", "=", "csv_reader", "(", "train_file", ")", ",", "csv_reader", "(", "test_file", ")", "\n", "\n", "self", ".", "train_examples", ",", "self", ".", "test_examples", "=", "self", ".", "get_train_examples", "(", ")", ",", "self", ".", "get_test_examples", "(", ")", "\n", "self", ".", "train_examples", "=", "self", ".", "train_examples", "+", "self", ".", "train_examples_extra", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST2_Processor.get_train_examples": [[566, 571], ["data_loader.SST2_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_train_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_train_set", ",", "\"train\"", ")", "\n", "print", "(", "'getting train examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST2_Processor.get_test_examples": [[572, 577], ["data_loader.SST2_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_test_set", ",", "\"test\"", ")", "\n", "print", "(", "'getting test examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST2_Processor.get_labels": [[578, 584], ["set", "sorted", "set.add", "list"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "example", "in", "self", ".", "train_examples", ":", "\n", "            ", "label_set", ".", "add", "(", "example", ".", "label", ")", "\n", "", "return", "sorted", "(", "list", "(", "label_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SST2_Processor._create_examples": [[585, 597], ["enumerate", "examples.append", "data_loader.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "dataset", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "data", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "guid", ",", "\n", "text_a", "=", "data", "[", "0", "]", ",", "\n", "label", "=", "data", "[", "1", "]", "\n", ")", ")", "\n", "# return examples", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.__init__": [[602, 608], ["print", "data_loader.csv_reader", "data_loader.csv_reader", "data_loader.TREC_Processor.get_train_examples", "data_loader.TREC_Processor.get_test_examples"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_test_examples"], ["def", "__init__", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "train_file", "=", "\"./data/TREC/train.tsv\"", "\n", "test_file", "=", "\"./data/TREC/test.tsv\"", "\n", "print", "(", "\"processing train_file{},test_file,{}\"", ".", "format", "(", "train_file", ",", "test_file", ")", ")", "\n", "self", ".", "_train_set", ",", "self", ".", "_test_set", "=", "csv_reader", "(", "train_file", ")", ",", "csv_reader", "(", "test_file", ")", "\n", "self", ".", "train_examples", ",", "self", ".", "test_examples", "=", "self", ".", "get_train_examples", "(", ")", ",", "self", ".", "get_test_examples", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_train_examples": [[609, 614], ["data_loader.TREC_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_train_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_train_set", ",", "\"train\"", ")", "\n", "print", "(", "'getting train examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_test_examples": [[615, 620], ["data_loader.TREC_Processor._create_examples", "print", "len"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "get_test_examples", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_test_set", ",", "\"test\"", ")", "\n", "print", "(", "'getting test examples,len = '", ",", "len", "(", "examples", ")", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor.get_labels": [[621, 627], ["set", "sorted", "set.add", "list"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "example", "in", "self", ".", "train_examples", ":", "\n", "            ", "label_set", ".", "add", "(", "example", ".", "label", ")", "\n", "", "return", "sorted", "(", "list", "(", "label_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.TREC_Processor._create_examples": [[628, 640], ["enumerate", "examples.append", "data_loader.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "dataset", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "data", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "guid", ",", "\n", "text_a", "=", "data", "[", "0", "]", ",", "\n", "label", "=", "data", "[", "1", "]", "\n", ")", ")", "\n", "# return examples", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SUBJ_Processor.__init__": [[645, 650], ["print", "data_loader.csv_reader", "data_loader.SUBJ_Processor.get_train_examples"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples"], ["def", "__init__", "(", "self", ",", "cv", ")", ":", "\n", "        ", "all_file", "=", "\"./data/SUBJ/data_all.tsv\"", "\n", "print", "(", "\"processing all_file{}\"", ".", "format", "(", "all_file", ")", ")", "\n", "self", ".", "_all_set", "=", "csv_reader", "(", "all_file", ")", "\n", "self", ".", "train_examples", ",", "self", ".", "test_examples", "=", "self", ".", "get_train_examples", "(", "cv", "=", "cv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SUBJ_Processor._read_examples": [[651, 654], ["data_loader.SUBJ_Processor._create_examples"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "_read_examples", "(", "self", ")", ":", "\n", "        ", "examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_all_set", ",", "\"all\"", ")", "\n", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SUBJ_Processor.get_train_examples": [[655, 670], ["data_loader.SUBJ_Processor._read_examples", "list", "numpy.random.shuffle", "enumerate", "range", "len", "test_example.append", "train_example.append"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._read_examples"], ["", "def", "get_train_examples", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_read_examples", "(", ")", "\n", "idx", "=", "list", "(", "range", "(", "len", "(", "examples", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "test_index", "=", "cv", "\n", "test_example", "=", "[", "]", "\n", "train_example", "=", "[", "]", "\n", "for", "i", ",", "id_", "in", "enumerate", "(", "idx", ")", ":", "\n", "            ", "index", "=", "i", "%", "10", "\n", "if", "index", "==", "test_index", ":", "\n", "                ", "test_example", ".", "append", "(", "examples", "[", "id_", "]", ")", "\n", "", "else", ":", "\n", "                ", "train_example", ".", "append", "(", "examples", "[", "id_", "]", ")", "\n", "", "", "return", "train_example", ",", "test_example", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SUBJ_Processor.get_labels": [[671, 677], ["set", "sorted", "set.add", "list"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "example", "in", "self", ".", "train_examples", ":", "\n", "            ", "label_set", ".", "add", "(", "example", ".", "label", ")", "\n", "", "return", "sorted", "(", "list", "(", "label_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.SUBJ_Processor._create_examples": [[678, 689], ["enumerate", "examples.append", "data_loader.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "dataset", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "data", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "guid", ",", "\n", "text_a", "=", "data", "[", "0", "]", ",", "\n", "label", "=", "data", "[", "1", "]", "\n", ")", ")", "\n", "", "return", "examples", "\n", "# return shuffle_data(examples)", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.__init__": [[695, 701], ["print", "data_loader.MR_Processor.get_train_examples", "data_loader.csv_reader", "data_loader.csv_reader"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader"], ["def", "__init__", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "pos_file", "=", "\"./data/MR/rt-polarity.pos\"", "\n", "neg_file", "=", "\"./data/MR/rt-polarity.neg\"", "\n", "print", "(", "\"processing pos_file:{},neg_file:{}\"", ".", "format", "(", "pos_file", ",", "neg_file", ")", ")", "\n", "self", ".", "_pos_set", ",", "self", ".", "_neg_set", "=", "csv_reader", "(", "pos_file", ")", ",", "csv_reader", "(", "neg_file", ")", "\n", "self", ".", "train_examples", ",", "self", ".", "test_examples", "=", "self", ".", "get_train_examples", "(", "cv", "=", "cv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._read_examples": [[702, 719], ["data_loader.MR_Processor._create_examples", "data_loader.MR_Processor._create_examples", "examples.append", "examples.append", "data_loader.InputExample", "data_loader.InputExample"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples"], ["", "def", "_read_examples", "(", "self", ")", ":", "\n", "        ", "pos_examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_pos_set", ",", "\"pos\"", ")", "\n", "neg_examples", "=", "self", ".", "_create_examples", "(", "self", ".", "_neg_set", ",", "\"neg\"", ")", "\n", "examples", "=", "[", "]", "\n", "for", "ex", "in", "pos_examples", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "ex", ".", "guid", ",", "\n", "text_a", "=", "ex", ".", "text_a", ",", "\n", "label", "=", "1", "\n", ")", ")", "\n", "", "for", "ex", "in", "neg_examples", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "ex", ".", "guid", ",", "\n", "text_a", "=", "ex", ".", "text_a", ",", "\n", "label", "=", "0", "\n", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_train_examples": [[720, 735], ["data_loader.MR_Processor._read_examples", "list", "numpy.random.shuffle", "enumerate", "range", "len", "test_example.append", "train_example.append"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._read_examples"], ["", "def", "get_train_examples", "(", "self", ",", "cv", "=", "0", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "examples", "=", "self", ".", "_read_examples", "(", ")", "\n", "idx", "=", "list", "(", "range", "(", "len", "(", "examples", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "test_index", "=", "cv", "\n", "test_example", "=", "[", "]", "\n", "train_example", "=", "[", "]", "\n", "for", "i", ",", "id_", "in", "enumerate", "(", "idx", ")", ":", "\n", "            ", "index", "=", "i", "%", "10", "\n", "if", "index", "==", "test_index", ":", "\n", "                ", "test_example", ".", "append", "(", "examples", "[", "id_", "]", ")", "\n", "", "else", ":", "\n", "                ", "train_example", ".", "append", "(", "examples", "[", "id_", "]", ")", "\n", "", "", "return", "train_example", ",", "test_example", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor.get_labels": [[736, 742], ["set", "sorted", "set.add", "list"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "label_set", "=", "set", "(", ")", "\n", "for", "example", "in", "self", ".", "train_examples", ":", "\n", "            ", "label_set", ".", "add", "(", "example", ".", "label", ")", "\n", "", "return", "sorted", "(", "list", "(", "label_set", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.MR_Processor._create_examples": [[743, 753], ["enumerate", "examples.append", "data_loader.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "dataset", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "data", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "\n", "guid", "=", "guid", ",", "\n", "text_a", "=", "data", "[", "0", "]", ",", "\n", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.load_glove_txt": [[12, 21], ["sum", "open", "tqdm.tqdm", "line.strip().split", "open", "line.strip"], "function", ["None"], ["def", "load_glove_txt", "(", "file_path", "=", "\"glove.840B.300d.txt\"", ")", ":", "\n", "    ", "results", "=", "{", "}", "\n", "num_file", "=", "sum", "(", "[", "1", "for", "i", "in", "open", "(", "file_path", ",", "\"r\"", ",", "encoding", "=", "'utf8'", ")", "]", ")", "\n", "with", "open", "(", "file_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "tqdm", ".", "tqdm", "(", "infile", ",", "total", "=", "num_file", ")", ":", "\n", "            ", "data", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "data", "[", "0", "]", "\n", "results", "[", "word", "]", "=", "1", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.clean_str": [[23, 45], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub.strip().split", "re.sub.strip"], "function", ["None"], ["", "def", "clean_str", "(", "string", ")", ":", "\n", "# string = re.sub(\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)", "\n", "    ", "string", "=", "re", ".", "sub", "(", "\"\\'s\"", ",", "\" \\'s\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\\'ve\"", ",", "\" \\'ve\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"n\\'t\"", ",", "\" n\\'t\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\\'re\"", ",", "\" \\'re\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\\'d\"", ",", "\" \\'d\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"\\'ll\"", ",", "\" \\'ll\"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "'\"'", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"'\"", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "\"`\"", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"\\\\\"", ",", "\" \"", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "r\"[\\[\\]<>/&#\\^$%{}\u2018\\.\u2026*]\"", ",", "\" \"", ",", "string", ")", "\n", "# string = re.sub(\",\", \" , \", string)", "\n", "# string = re.sub(\"!\", \" ! \", string)", "\n", "# string = re.sub(\"\\(\", \" \\( \", string)", "\n", "# string = re.sub(\"\\)\", \" \\) \", string)", "\n", "# string = re.sub(\"\\?\", \" \\? \", string)", "\n", "# string = re.sub(\"\\\\\\?\", \"?\", string)", "\n", "# string = re.sub(\"\\s{2,}\", \" \", string)", "\n", "# string = re.sub(\"-\", ' ', string)", "\n", "return", "string", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.shuffle_data": [[47, 56], ["list", "numpy.random.shuffle", "range", "new_x.append", "new_y.append", "len"], "function", ["None"], ["", "def", "shuffle_data", "(", "x", ",", "y", ")", ":", "\n", "    ", "idx", "=", "list", "(", "range", "(", "len", "(", "x", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "new_x", "=", "[", "]", "\n", "new_y", "=", "[", "]", "\n", "for", "id_", "in", "idx", ":", "\n", "        ", "new_x", ".", "append", "(", "x", "[", "id_", "]", ")", "\n", "new_y", ".", "append", "(", "y", "[", "id_", "]", ")", "\n", "", "return", "new_x", ",", "new_y", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.read_TREC": [[58, 94], ["data_loader.read_TREC.read"], "function", ["None"], ["", "def", "read_TREC", "(", "cv", "=", "None", ",", "scale_rate", "=", "1", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "\n", "def", "read", "(", "mode", ")", ":", "\n", "        ", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/TREC/\"", "+", "mode", "+", "\".tsv\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "None", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "x", ".", "append", "(", "clean_str", "(", "line", "[", "0", "]", ")", ")", "\n", "y", ".", "append", "(", "line", "[", "1", "]", ")", "\n", "\n", "", "", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "label2data", "=", "{", "}", "\n", "for", "x_", ",", "y_", "in", "zip", "(", "x", ",", "y", ")", ":", "\n", "                ", "if", "y_", "not", "in", "label2data", ":", "\n", "                    ", "label2data", "[", "y_", "]", "=", "[", "x_", "]", "\n", "", "else", ":", "\n", "                    ", "label2data", "[", "y_", "]", ".", "append", "(", "x_", ")", "\n", "", "", "new_train_x", "=", "[", "]", "\n", "new_train_y", "=", "[", "]", "\n", "for", "y_", "in", "label2data", ".", "keys", "(", ")", ":", "\n", "                ", "train_idx", "=", "max", "(", "int", "(", "len", "(", "label2data", "[", "y_", "]", ")", "*", "scale_rate", ")", ",", "1", ")", "\n", "for", "x_", "in", "label2data", "[", "y_", "]", "[", ":", "train_idx", "]", ":", "\n", "                    ", "new_train_x", ".", "append", "(", "x_", ")", "\n", "new_train_y", ".", "append", "(", "y_", ")", "\n", "", "", "x", ",", "y", "=", "shuffle_data", "(", "new_train_x", ",", "new_train_y", ")", "\n", "\n", "data", "[", "\"train_x\"", "]", ",", "data", "[", "\"train_y\"", "]", "=", "x", ",", "y", "\n", "\n", "", "else", ":", "\n", "            ", "data", "[", "\"test_x\"", "]", ",", "data", "[", "\"test_y\"", "]", "=", "x", ",", "y", "\n", "\n", "", "", "read", "(", "\"train\"", ")", "\n", "read", "(", "\"test\"", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.read_SST1": [[96, 134], ["data_loader.read_TREC.read"], "function", ["None"], ["", "def", "read_SST1", "(", "cv", "=", "None", ",", "scale_rate", "=", "1", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "\n", "def", "read", "(", "mode", ")", ":", "\n", "        ", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/SST1/\"", "+", "mode", "+", "\".tsv\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "None", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "y", ".", "append", "(", "line", "[", "1", "]", ")", "\n", "x", ".", "append", "(", "clean_str", "(", "line", "[", "0", "]", ")", ")", "\n", "# x.append(line[0])", "\n", "", "", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "with", "open", "(", "\"data/SST1/stsa.fine.phrases.train\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "y", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "x", ".", "append", "(", "clean_str", "(", "line", "[", "2", ":", "]", ")", ")", "\n", "", "", "label2data", "=", "{", "}", "\n", "for", "x_", ",", "y_", "in", "zip", "(", "x", ",", "y", ")", ":", "\n", "                ", "if", "y_", "not", "in", "label2data", ":", "\n", "                    ", "label2data", "[", "y_", "]", "=", "[", "x_", "]", "\n", "", "else", ":", "\n", "                    ", "label2data", "[", "y_", "]", ".", "append", "(", "x_", ")", "\n", "", "", "new_train_x", "=", "[", "]", "\n", "new_train_y", "=", "[", "]", "\n", "for", "y_", "in", "label2data", ".", "keys", "(", ")", ":", "\n", "                ", "train_idx", "=", "max", "(", "int", "(", "len", "(", "label2data", "[", "y_", "]", ")", "*", "scale_rate", ")", ",", "1", ")", "\n", "for", "x_", "in", "label2data", "[", "y_", "]", "[", ":", "train_idx", "]", ":", "\n", "                    ", "new_train_x", ".", "append", "(", "x_", ")", "\n", "new_train_y", ".", "append", "(", "y_", ")", "\n", "\n", "", "", "x", ",", "y", "=", "shuffle_data", "(", "new_train_x", ",", "new_train_y", ")", "\n", "data", "[", "\"train_x\"", "]", ",", "data", "[", "\"train_y\"", "]", "=", "x", ",", "y", "\n", "", "else", ":", "\n", "            ", "data", "[", "\"test_x\"", "]", ",", "data", "[", "\"test_y\"", "]", "=", "x", ",", "y", "\n", "\n", "", "", "read", "(", "\"train\"", ")", "\n", "read", "(", "\"test\"", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.read_SST2": [[136, 174], ["data_loader.read_TREC.read"], "function", ["None"], ["", "def", "read_SST2", "(", "cv", "=", "None", ",", "scale_rate", "=", "1", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "\n", "def", "read", "(", "mode", ")", ":", "\n", "        ", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/SST2/\"", "+", "mode", "+", "\".tsv\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "None", ")", "\n", "for", "line", "in", "reader", ":", "\n", "                ", "y", ".", "append", "(", "line", "[", "1", "]", ")", "\n", "x", ".", "append", "(", "clean_str", "(", "line", "[", "0", "]", ")", ")", "\n", "# x.append(line[0])", "\n", "", "", "if", "mode", "==", "\"train\"", ":", "\n", "            ", "with", "open", "(", "\"data/SST2/stsa.binary.phrases.train\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "y", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "x", ".", "append", "(", "clean_str", "(", "line", "[", "2", ":", "]", ")", ")", "\n", "", "", "label2data", "=", "{", "}", "\n", "for", "x_", ",", "y_", "in", "zip", "(", "x", ",", "y", ")", ":", "\n", "                ", "if", "y_", "not", "in", "label2data", ":", "\n", "                    ", "label2data", "[", "y_", "]", "=", "[", "x_", "]", "\n", "", "else", ":", "\n", "                    ", "label2data", "[", "y_", "]", ".", "append", "(", "x_", ")", "\n", "", "", "new_train_x", "=", "[", "]", "\n", "new_train_y", "=", "[", "]", "\n", "for", "y_", "in", "label2data", ".", "keys", "(", ")", ":", "\n", "                ", "train_idx", "=", "max", "(", "int", "(", "len", "(", "label2data", "[", "y_", "]", ")", "*", "scale_rate", ")", ",", "1", ")", "\n", "for", "x_", "in", "label2data", "[", "y_", "]", "[", ":", "train_idx", "]", ":", "\n", "                    ", "new_train_x", ".", "append", "(", "x_", ")", "\n", "new_train_y", ".", "append", "(", "y_", ")", "\n", "", "", "x", ",", "y", "=", "shuffle_data", "(", "new_train_x", ",", "new_train_y", ")", "\n", "\n", "data", "[", "\"train_x\"", "]", ",", "data", "[", "\"train_y\"", "]", "=", "x", ",", "y", "\n", "", "else", ":", "\n", "            ", "data", "[", "\"test_x\"", "]", ",", "data", "[", "\"test_y\"", "]", "=", "x", ",", "y", "\n", "\n", "", "", "read", "(", "\"train\"", ")", "\n", "read", "(", "\"test\"", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.read_SUBJ": [[176, 219], ["list", "numpy.random.shuffle", "enumerate", "zip", "label2data.keys", "data_loader.shuffle_data", "open", "range", "max", "x.append", "y.append", "len", "test_x.append", "test_y.append", "train_x.append", "train_y.append", "label2data[].append", "int", "new_train_x.append", "new_train_y.append", "data_loader.clean_str", "len"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.shuffle_data", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.clean_str"], ["", "def", "read_SUBJ", "(", "cv", "=", "0", ",", "scale_rate", "=", "1", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/SUBJ/subj.all\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ",", "errors", "=", "'ignore'", ")", "as", "f", ":", "\n", "# reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "x", ".", "append", "(", "clean_str", "(", "line", "[", "2", ":", "]", ")", ")", "\n", "# x.append(line[0])", "\n", "y", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "", "", "idx", "=", "list", "(", "range", "(", "len", "(", "x", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "test_index", "=", "cv", "# 0-9", "\n", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "\n", "test_x", "=", "[", "]", "\n", "test_y", "=", "[", "]", "\n", "for", "i", ",", "id_", "in", "enumerate", "(", "idx", ")", ":", "\n", "        ", "index", "=", "i", "%", "10", "\n", "if", "index", "==", "test_index", ":", "\n", "            ", "test_x", ".", "append", "(", "x", "[", "id_", "]", ")", "\n", "test_y", ".", "append", "(", "y", "[", "id_", "]", ")", "\n", "", "else", ":", "\n", "            ", "train_x", ".", "append", "(", "x", "[", "id_", "]", ")", "\n", "train_y", ".", "append", "(", "y", "[", "id_", "]", ")", "\n", "\n", "", "", "label2data", "=", "{", "}", "\n", "for", "x_", ",", "y_", "in", "zip", "(", "train_x", ",", "train_y", ")", ":", "\n", "        ", "if", "y_", "not", "in", "label2data", ":", "\n", "            ", "label2data", "[", "y_", "]", "=", "[", "x_", "]", "\n", "", "else", ":", "\n", "            ", "label2data", "[", "y_", "]", ".", "append", "(", "x_", ")", "\n", "", "", "new_train_x", "=", "[", "]", "\n", "new_train_y", "=", "[", "]", "\n", "for", "y_", "in", "label2data", ".", "keys", "(", ")", ":", "\n", "        ", "train_idx", "=", "max", "(", "int", "(", "len", "(", "label2data", "[", "y_", "]", ")", "*", "scale_rate", ")", ",", "1", ")", "\n", "for", "x_", "in", "label2data", "[", "y_", "]", "[", ":", "train_idx", "]", ":", "\n", "            ", "new_train_x", ".", "append", "(", "x_", ")", "\n", "new_train_y", ".", "append", "(", "y_", ")", "\n", "", "", "train_x", ",", "train_y", "=", "shuffle_data", "(", "new_train_x", ",", "new_train_y", ")", "\n", "data", "[", "\"train_x\"", "]", ",", "data", "[", "\"train_y\"", "]", "=", "train_x", ",", "train_y", "\n", "data", "[", "\"test_x\"", "]", ",", "data", "[", "\"test_y\"", "]", "=", "test_x", ",", "test_y", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.read_MR": [[221, 272], ["list", "numpy.random.shuffle", "enumerate", "zip", "label2data.keys", "data_loader.shuffle_data", "open", "open", "range", "max", "x.append", "y.append", "x.append", "y.append", "len", "test_x.append", "test_y.append", "train_x.append", "train_y.append", "label2data[].append", "int", "new_train_x.append", "new_train_y.append", "data_loader.clean_str", "data_loader.clean_str", "len"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.shuffle_data", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.clean_str", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.clean_str"], ["", "def", "read_MR", "(", "cv", "=", "0", ",", "scale_rate", "=", "1", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "\"data/MR/rt-polarity.pos\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", "[", "-", "1", "]", "==", "\"\\n\"", ":", "\n", "                ", "line", "=", "line", "[", ":", "-", "1", "]", "\n", "", "x", ".", "append", "(", "clean_str", "(", "line", ")", ")", "\n", "y", ".", "append", "(", "1", ")", "\n", "", "", "with", "open", "(", "\"data/MR/rt-polarity.neg\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", "[", "-", "1", "]", "==", "\"\\n\"", ":", "\n", "                ", "line", "=", "line", "[", ":", "-", "1", "]", "\n", "", "x", ".", "append", "(", "clean_str", "(", "line", ")", ")", "\n", "y", ".", "append", "(", "0", ")", "\n", "\n", "", "", "idx", "=", "list", "(", "range", "(", "len", "(", "x", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "test_index", "=", "cv", "# 0-9", "\n", "# dev_index = (cv+1)%10", "\n", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "test_x", "=", "[", "]", "\n", "test_y", "=", "[", "]", "\n", "for", "i", ",", "id_", "in", "enumerate", "(", "idx", ")", ":", "\n", "        ", "index", "=", "i", "%", "10", "\n", "if", "index", "==", "test_index", ":", "\n", "            ", "test_x", ".", "append", "(", "x", "[", "id_", "]", ")", "\n", "test_y", ".", "append", "(", "y", "[", "id_", "]", ")", "\n", "", "else", ":", "\n", "            ", "train_x", ".", "append", "(", "x", "[", "id_", "]", ")", "\n", "train_y", ".", "append", "(", "y", "[", "id_", "]", ")", "\n", "\n", "", "", "label2data", "=", "{", "}", "\n", "for", "x_", ",", "y_", "in", "zip", "(", "train_x", ",", "train_y", ")", ":", "\n", "        ", "if", "y_", "not", "in", "label2data", ":", "\n", "            ", "label2data", "[", "y_", "]", "=", "[", "x_", "]", "\n", "", "else", ":", "\n", "            ", "label2data", "[", "y_", "]", ".", "append", "(", "x_", ")", "\n", "", "", "new_train_x", "=", "[", "]", "\n", "new_train_y", "=", "[", "]", "\n", "for", "y_", "in", "label2data", ".", "keys", "(", ")", ":", "\n", "        ", "train_idx", "=", "max", "(", "int", "(", "len", "(", "label2data", "[", "y_", "]", ")", "*", "scale_rate", ")", ",", "1", ")", "\n", "for", "x_", "in", "label2data", "[", "y_", "]", "[", ":", "train_idx", "]", ":", "\n", "            ", "new_train_x", ".", "append", "(", "x_", ")", "\n", "new_train_y", ".", "append", "(", "y_", ")", "\n", "\n", "", "", "train_x", ",", "train_y", "=", "shuffle_data", "(", "new_train_x", ",", "new_train_y", ")", "\n", "data", "[", "\"train_x\"", "]", ",", "data", "[", "\"train_y\"", "]", "=", "train_x", ",", "train_y", "\n", "data", "[", "\"test_x\"", "]", ",", "data", "[", "\"test_y\"", "]", "=", "test_x", ",", "test_y", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.refind_sent": [[274, 290], ["new_sent.append", "word.split", "new_sent.append", "word.split", "new_sent.append", "word.lower", "new_sent.append", "word.lower"], "function", ["None"], ["", "def", "refind_sent", "(", "sent", ",", "g_dict", ")", ":", "\n", "    ", "new_sent", "=", "[", "]", "\n", "for", "word", "in", "sent", ":", "\n", "        ", "if", "word", "in", "g_dict", ":", "\n", "            ", "new_sent", ".", "append", "(", "word", ")", "\n", "", "elif", "'-'", "in", "word", ":", "\n", "            ", "for", "wd", "in", "word", ".", "split", "(", "'-'", ")", ":", "\n", "                ", "new_sent", ".", "append", "(", "wd", ")", "\n", "", "", "elif", "'\\/'", "in", "word", ":", "\n", "            ", "for", "wd", "in", "word", ".", "split", "(", "'\\/'", ")", ":", "\n", "                ", "new_sent", ".", "append", "(", "wd", ")", "\n", "", "", "elif", "word", ".", "lower", "(", ")", "in", "g_dict", ":", "\n", "            ", "new_sent", ".", "append", "(", "word", ".", "lower", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "", "", "return", "new_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.preprocess_data": [[292, 307], ["torch.LongTensor", "torch.LongTensor", "sent_tmp.append", "torch.LongTensor.append", "data[].index", "len", "len", "sent_tmp.append", "len"], "function", ["None"], ["", "def", "preprocess_data", "(", "data", ",", "VOCAB_SIZE", ",", "MAX_SENT_LEN", ",", "dtype", "=", "'train'", ")", ":", "\n", "    ", "x", "=", "[", "]", "\n", "for", "sent", "in", "data", "[", "dtype", "+", "\"_x\"", "]", ":", "\n", "        ", "sent_tmp", "=", "[", "data", "[", "'word_to_idx'", "]", "[", "\"<BOS>\"", "]", "]", "\n", "for", "word", "in", "sent", ":", "\n", "            ", "if", "len", "(", "sent_tmp", ")", "<", "MAX_SENT_LEN", "-", "1", ":", "\n", "                ", "sent_tmp", ".", "append", "(", "data", "[", "'word_to_idx'", "]", "[", "word", "]", ")", "\n", "", "", "sent_tmp", ".", "append", "(", "data", "[", "'word_to_idx'", "]", "[", "\"<EOS>\"", "]", ")", "\n", "if", "len", "(", "sent_tmp", ")", "<", "MAX_SENT_LEN", ":", "\n", "            ", "sent_tmp", "+=", "[", "VOCAB_SIZE", "+", "1", "]", "*", "(", "MAX_SENT_LEN", "-", "len", "(", "sent_tmp", ")", ")", "\n", "", "x", ".", "append", "(", "sent_tmp", ")", "\n", "", "y", "=", "[", "data", "[", "\"classes\"", "]", ".", "index", "(", "c", ")", "for", "c", "in", "data", "[", "dtype", "+", "\"_y\"", "]", "]", "\n", "x", "=", "torch", ".", "LongTensor", "(", "x", ")", "\n", "y", "=", "torch", ".", "LongTensor", "(", "y", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.load_dataset": [[309, 349], ["data_loader.load_glove_txt", "range", "range", "sorted", "sorted", "len", "len", "data_loader.preprocess_data", "torch.utils.data.TensorDataset", "data_loader.preprocess_data", "torch.utils.data.TensorDataset", "transformers.tokenization_bert.BertTokenizer", "sorted", "len", "len", "data_loader._make_data_loader", "data_loader._make_data_loader", "getattr", "len", "data_loader.refind_sent", "len", "data_loader.refind_sent", "list", "list", "hasattr", "max", "getattr", "list", "hasattr", "setattr", "set", "set", "enumerate", "enumerate", "set", "len", "max", "len", "example.text_a.split"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.load_glove_txt", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.preprocess_data", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.preprocess_data", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._make_data_loader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._make_data_loader", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.refind_sent", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.refind_sent"], ["", "def", "load_dataset", "(", "options", ")", ":", "\n", "    ", "mod", "=", "sys", ".", "modules", "[", "__name__", "]", "\n", "if", "options", ".", "classifier", "!=", "'BERT'", ":", "\n", "        ", "data", "=", "getattr", "(", "mod", ",", "f\"read_{options.dataset}\"", ")", "(", "cv", "=", "options", ".", "cv", ",", "scale_rate", "=", "options", ".", "scale_rate", ")", "\n", "g_dict", "=", "load_glove_txt", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "'train_x'", "]", ")", ")", ":", "\n", "            ", "data", "[", "'train_x'", "]", "[", "i", "]", "=", "refind_sent", "(", "data", "[", "'train_x'", "]", "[", "i", "]", ",", "g_dict", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "data", "[", "'test_x'", "]", ")", ")", ":", "\n", "            ", "data", "[", "'test_x'", "]", "[", "i", "]", "=", "refind_sent", "(", "data", "[", "'test_x'", "]", "[", "i", "]", ",", "g_dict", ")", "\n", "", "data", "[", "\"vocab\"", "]", "=", "sorted", "(", "\n", "list", "(", "set", "(", "[", "w", "for", "sent", "in", "data", "[", "\"train_x\"", "]", "+", "data", "[", "\"test_x\"", "]", "for", "w", "in", "sent", "]", "+", "[", "\"<BOS>\"", ",", "\"<EOS>\"", "]", ")", ")", ")", "\n", "data", "[", "\"classes\"", "]", "=", "sorted", "(", "list", "(", "set", "(", "data", "[", "\"train_y\"", "]", ")", ")", ")", "\n", "data", "[", "\"word_to_idx\"", "]", "=", "{", "w", ":", "i", "for", "i", ",", "w", "in", "enumerate", "(", "data", "[", "\"vocab\"", "]", ")", "}", "\n", "data", "[", "\"idx_to_word\"", "]", "=", "{", "i", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "data", "[", "\"vocab\"", "]", ")", "}", "\n", "options", ".", "VOCAB_SIZE", "=", "len", "(", "data", "[", "\"vocab\"", "]", ")", "\n", "if", "not", "hasattr", "(", "options", ",", "'MAX_SENT_LEN'", ")", ":", "\n", "            ", "options", ".", "MAX_SENT_LEN", "=", "max", "(", "[", "len", "(", "sent", ")", "for", "sent", "in", "data", "[", "\"train_x\"", "]", "+", "data", "[", "\"test_x\"", "]", "]", ")", "\n", "", "options", ".", "CLASS_SIZE", "=", "len", "(", "data", "[", "\"classes\"", "]", ")", "\n", "train_x", ",", "train_y", "=", "preprocess_data", "(", "data", ",", "options", ".", "VOCAB_SIZE", ",", "options", ".", "MAX_SENT_LEN", ",", "'train'", ")", "\n", "train_set", "=", "TensorDataset", "(", "train_x", ",", "train_y", ")", "\n", "test_x", ",", "test_y", "=", "preprocess_data", "(", "data", ",", "options", ".", "VOCAB_SIZE", ",", "options", ".", "MAX_SENT_LEN", ",", "'test'", ")", "\n", "test_set", "=", "TensorDataset", "(", "test_x", ",", "test_y", ")", "\n", "return", "train_set", ",", "test_set", ",", "data", "\n", "", "else", ":", "\n", "        ", "data", "=", "{", "}", "\n", "dset", "=", "getattr", "(", "mod", ",", "f\"{options.dataset}_Processor\"", ")", "(", "cv", "=", "options", ".", "cv", ")", "\n", "train_examples", "=", "dset", ".", "train_examples", "\n", "test_examples", "=", "dset", ".", "test_examples", "\n", "data", "[", "'tokenizer'", "]", "=", "BertTokenizer", "(", "vocab_file", "=", "'./bert-base-uncased/vocab.txt'", "\n", ",", "do_basic_tokenize", "=", "True", ")", "\n", "data", "[", "\"classes\"", "]", "=", "sorted", "(", "list", "(", "set", "(", "[", "z", ".", "label", "for", "z", "in", "train_examples", "]", ")", ")", ")", "\n", "options", ".", "CLASS_SIZE", "=", "len", "(", "data", "[", "\"classes\"", "]", ")", "\n", "options", ".", "VOCAB_SIZE", "=", "len", "(", "data", "[", "'tokenizer'", "]", ".", "vocab", ")", "\n", "if", "not", "hasattr", "(", "options", ",", "'MAX_SENT_LEN'", ")", ":", "\n", "            ", "setattr", "(", "options", ",", "'MAX_SENT_LEN'", ",", "\n", "max", "(", "[", "len", "(", "example", ".", "text_a", ".", "split", "(", "' '", ")", ")", "for", "example", "in", "train_examples", "+", "test_examples", "]", ")", "+", "2", ")", "\n", "# print(\"max\",max([len(example.text_a.split(' ')) for example in train_examples + test_examples]))", "\n", "", "train_set", "=", "_make_data_loader", "(", "train_examples", ",", "data", "[", "\"classes\"", "]", ",", "data", "[", "'tokenizer'", "]", ",", "options", ".", "MAX_SENT_LEN", ")", "\n", "test_set", "=", "_make_data_loader", "(", "test_examples", ",", "data", "[", "\"classes\"", "]", ",", "data", "[", "'tokenizer'", "]", ",", "options", ".", "MAX_SENT_LEN", ")", "\n", "return", "train_set", ",", "test_set", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._make_data_loader": [[351, 372], ["data_loader._convert_examples_to_features", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.arange", "torch.utils.data.TensorDataset", "len"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._convert_examples_to_features"], ["", "", "def", "_make_data_loader", "(", "examples", ",", "label_list", ",", "tokenizer", ",", "MAX_SEQ_LENGTH", ")", ":", "\n", "    ", "all_features", "=", "_convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_seq_length", "=", "MAX_SEQ_LENGTH", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "output_mode", "=", "'classification'", ")", "\n", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "input_ids", "for", "f", "in", "all_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "input_mask", "for", "f", "in", "all_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "segment_ids", "for", "f", "in", "all_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "\n", "[", "f", ".", "label_id", "for", "f", "in", "all_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_ids", "=", "torch", ".", "arange", "(", "len", "(", "examples", ")", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ",", "all_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._convert_examples_to_features": [[374, 433], ["enumerate", "tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "tokenizer.tokenize", "data_loader._truncate_seq_pair", "len", "len", "len", "len", "len", "data_loader.InputFeatures", "len", "len", "float", "KeyError", "len"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._truncate_seq_pair"], ["", "def", "_convert_examples_to_features", "(", "examples", ",", "label_list", ",", "max_seq_length", ",", "\n", "tokenizer", ",", "output_mode", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens_a", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_a", ")", "\n", "\n", "tokens_b", "=", "None", "\n", "if", "example", ".", "text_b", ":", "\n", "            ", "tokens_b", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "text_b", ")", "\n", "# Modifies `tokens_a` and `tokens_b` in place so that the total", "\n", "# length is less than the specified length.", "\n", "# Account for [CLS], [SEP], [SEP] with \"- 3\"", "\n", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_seq_length", "-", "3", ")", "\n", "", "else", ":", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "            ", "if", "len", "(", "tokens_a", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens_a", "=", "tokens_a", "[", ":", "(", "max_seq_length", "-", "2", ")", "]", "\n", "\n", "", "", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens_a", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "tokens_b", ":", "\n", "            ", "tokens", "+=", "tokens_b", "+", "[", "\"[SEP]\"", "]", "\n", "segment_ids", "+=", "[", "1", "]", "*", "(", "len", "(", "tokens_b", ")", "+", "1", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "input_mask", "+=", "padding", "\n", "segment_ids", "+=", "padding", "\n", "# print(len(input_ids),len(input_mask),len(segment_ids),max_seq_length)", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label_id", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label_id", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_id", "=", "label_id", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader._truncate_seq_pair": [[435, 451], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["", "def", "_truncate_seq_pair", "(", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal", "\n", "# percent of tokens from each, since if one sequence is very short then each", "\n", "# token that's truncated likely contains more information than a longer", "\n", "# sequence.", "\n", "while", "True", ":", "\n", "        ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "            ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "            ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "            ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.csv_reader": [[453, 458], ["print", "open", "csv.reader"], "function", ["None"], ["", "", "", "def", "csv_reader", "(", "filename", ")", ":", "\n", "    ", "print", "(", "'read file:'", ",", "filename", ")", "\n", "f", "=", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "\n", "reader", "=", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "None", ")", "\n", "return", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.SoftEmbedding.__init__": [[20, 26], ["torch.Module.__init__", "torch.Module.__init__", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "nn", ".", "Module", ".", "__init__", "(", "self", ")", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_embeddings", ",", "embedding_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.SoftEmbedding.forward": [[27, 41], ["torch.zeros().scatter_.view().mm().view", "torch.zeros().scatter_.view().mm().view", "torch.zeros().scatter_.view().mm().view", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "len", "ids.unsqueeze", "torch.zeros().scatter_.view().mm", "torch.zeros().scatter_.view().mm", "torch.zeros().scatter_.view().mm", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().scatter_.view", "torch.zeros().scatter_.view", "torch.zeros().scatter_.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "ids_or_probs", ",", "use_probs", "=", "False", ")", ":", "\n", "        ", "if", "not", "use_probs", ":", "\n", "            ", "ids", "=", "ids_or_probs", "\n", "assert", "len", "(", "ids", ".", "shape", ")", "==", "2", "\n", "probs", "=", "torch", ".", "zeros", "(", "\n", "ids", ".", "shape", "[", "0", "]", ",", "ids", ".", "shape", "[", "1", "]", ",", "self", ".", "num_embeddings", ",", "\n", "device", "=", "ids_or_probs", ".", "device", ")", ".", "scatter_", "(", "2", ",", "ids", ".", "unsqueeze", "(", "2", ")", ",", "1.", ")", "\n", "", "else", ":", "\n", "            ", "probs", "=", "ids_or_probs", "\n", "\n", "", "embedding", "=", "probs", ".", "view", "(", "-", "1", ",", "self", ".", "num_embeddings", ")", ".", "mm", "(", "self", ".", "weight", ")", ".", "view", "(", "probs", ".", "shape", "[", "0", "]", ",", "probs", ".", "shape", "[", "1", "]", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertEmbeddings.__init__": [[47, 60], ["torch.Module.__init__", "model.SoftEmbedding", "model.SoftEmbedding", "model.SoftEmbedding", "transformers.modeling_bert.BertLayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "SoftEmbedding", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "SoftEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "SoftEmbedding", "(", "\n", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertEmbeddings.forward": [[61, 82], ["input_ids_or_probs.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "model.BertEmbeddings.word_embeddings", "model.BertEmbeddings.position_embeddings", "model.BertEmbeddings.token_type_embeddings", "model.BertEmbeddings.LayerNorm", "model.BertEmbeddings.dropout", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids_or_probs", ",", "token_type_ids", "=", "None", ",", "\n", "use_input_probs", "=", "False", ")", ":", "\n", "        ", "seq_length", "=", "input_ids_or_probs", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "\n", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids_or_probs", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_ids_or_probs", ".", "shape", "[", ":", "2", "]", ")", "\n", "assert", "token_type_ids", "is", "not", "None", "\n", "# if token_type_ids is None:", "\n", "#     token_type_ids = torch.zeros_like(input_ids)", "\n", "\n", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids_or_probs", ",", "use_probs", "=", "use_input_probs", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.__init__": [[85, 91], ["transformers.BertPreTrainedModel.__init__", "model.BertEmbeddings", "transformers.modeling_bert.BertEncoder", "transformers.modeling_bert.BertPooler", "model.BertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.forward": [[92, 124], ["attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "model.BertModel.embeddings", "model.BertModel.encoder", "model.BertModel.pooler", "attention_mask.unsqueeze", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "next", "model.BertModel.parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids_or_probs", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "use_input_probs", "=", "False", ")", ":", "\n", "        ", "assert", "attention_mask", "is", "not", "None", "\n", "# if attention_mask is None:", "\n", "#     attention_mask = torch.ones_like(input_ids)", "\n", "# if token_type_ids is None:", "\n", "#     token_type_ids = torch.zeros_like(input_ids)", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids_or_probs", ",", "token_type_ids", ",", "use_input_probs", ")", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "extended_attention_mask", ",", "\n", "head_mask", "=", "torch", ".", "Tensor", "(", "[", "1", "]", "*", "self", ".", "config", ".", "num_attention_heads", ")", ".", "long", "(", ")", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.get_token_embeddings": [[125, 131], ["model.BertModel.embeddings"], "methods", ["None"], ["", "def", "get_token_embeddings", "(", "self", ",", "input_ids_or_probs", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "use_input_probs", "=", "False", ")", ":", "\n", "        ", "assert", "attention_mask", "is", "not", "None", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids_or_probs", ",", "token_type_ids", ",", "use_input_probs", ")", "\n", "return", "embedding_output", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.get_sent_embedding": [[132, 144], ["attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "model.BertModel.encoder", "model.BertModel.pooler", "attention_mask.unsqueeze", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "next", "model.BertModel.parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "get_sent_embedding", "(", "self", ",", "token_embeddings", ",", "attention_mask", "=", "None", ")", ":", "\n", "        ", "assert", "attention_mask", "is", "not", "None", "\n", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "\n", "token_embeddings", ",", "extended_attention_mask", ",", "\n", "head_mask", "=", "torch", ".", "Tensor", "(", "[", "1", "]", "*", "self", ".", "config", ".", "num_attention_heads", ")", ".", "long", "(", ")", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertForSequenceClassification.__init__": [[147, 154], ["transformers.BertPreTrainedModel.__init__", "model.BertModel", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "model.BertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "kwargs", "[", "'CLASS_SIZE'", "]", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "kwargs", "[", "'CLASS_SIZE'", "]", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertForSequenceClassification.forward": [[155, 181], ["numpy.random.permutation", "model.BertForSequenceClassification.bert.get_token_embeddings", "model.BertForSequenceClassification.bert.get_sent_embedding", "model.BertForSequenceClassification.classifier", "model.BertForSequenceClassification.bert", "model.BertForSequenceClassification.dropout", "model.BertForSequenceClassification.classifier", "input_ids_or_probs.size", "random.randint", "numpy.random.beta", "model.mixup_process", "model.mixup_process"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.get_token_embeddings", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.BertModel.get_sent_embedding", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process"], ["", "def", "forward", "(", "self", ",", "input_ids_or_probs", ",", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "use_input_probs", "=", "False", ",", "target", "=", "None", ",", "mixup_hidden", "=", "False", ",", "layer_mix", "=", "None", ",", "lam", "=", "None", ",", "indices", "=", "None", ")", ":", "\n", "        ", "if", "indices", "==", "None", ":", "\n", "            ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "input_ids_or_probs", ".", "size", "(", "0", ")", ")", "\n", "", "if", "mixup_hidden", ":", "\n", "            ", "if", "layer_mix", "==", "None", ":", "\n", "                ", "layer_mix", "=", "random", ".", "randint", "(", "0", ",", "2", ")", "# random mixup in different layers", "\n", "", "if", "lam", "==", "None", ":", "\n", "                ", "lam", "=", "np", ".", "random", ".", "beta", "(", "1", ",", "1", ")", "# random lam if not set", "\n", "", "x", "=", "self", ".", "bert", ".", "get_token_embeddings", "(", "input_ids_or_probs", ",", "token_type_ids", ",", "attention_mask", ")", "\n", "if", "layer_mix", "==", "0", ":", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ",", "indices", "=", "indices", ")", "\n", "", "x", "=", "self", ".", "bert", ".", "get_sent_embedding", "(", "x", ",", "attention_mask", ")", "\n", "if", "layer_mix", "==", "1", ":", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ",", "ndices", "=", "indices", ")", "\n", "#x = self.dropout(x)", "\n", "", "logits", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "logits", ",", "target", ",", "indices", "\n", "\n", "", "else", ":", "\n", "            ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "\n", "input_ids_or_probs", ",", "token_type_ids", ",", "attention_mask", ",", "use_input_probs", "=", "use_input_probs", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.CNN.__init__": [[187, 216], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Linear", "torch.Linear", "torch.Linear", "model.CNN.init", "torch.Dropout", "torch.Dropout", "torch.Dropout", "len", "len", "model.CNN.embedding.weight.data.copy_", "len", "model.CNN.conv.append", "sum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.CNN.init"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "MODEL", "=", "kwargs", "[", "\"MODEL\"", "]", "\n", "self", ".", "BATCH_SIZE", "=", "kwargs", "[", "\"BATCH_SIZE\"", "]", "\n", "self", ".", "MAX_SENT_LEN", "=", "kwargs", "[", "\"MAX_SENT_LEN\"", "]", "\n", "self", ".", "WORD_DIM", "=", "kwargs", "[", "\"WORD_DIM\"", "]", "\n", "self", ".", "VOCAB_SIZE", "=", "kwargs", "[", "\"VOCAB_SIZE\"", "]", "\n", "self", ".", "CLASS_SIZE", "=", "kwargs", "[", "\"CLASS_SIZE\"", "]", "\n", "self", ".", "FILTERS", "=", "kwargs", "[", "\"FILTERS\"", "]", "\n", "self", ".", "FILTER_NUM", "=", "kwargs", "[", "\"FILTER_NUM\"", "]", "\n", "self", ".", "DROPOUT_PROB", "=", "kwargs", "[", "\"DROPOUT_PROB\"", "]", "\n", "self", ".", "IN_CHANNEL", "=", "1", "\n", "if", "self", ".", "DROPOUT_PROB", ">", "0", "and", "self", ".", "DROPOUT_PROB", "<", "1", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "DROPOUT_PROB", ")", "\n", "", "assert", "(", "len", "(", "self", ".", "FILTERS", ")", "==", "len", "(", "self", ".", "FILTER_NUM", ")", ")", "\n", "\n", "# one for UNK and one for zero padding", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "VOCAB_SIZE", "+", "2", ",", "self", ".", "WORD_DIM", ",", "padding_idx", "=", "self", ".", "VOCAB_SIZE", "+", "1", ")", "\n", "if", "self", ".", "MODEL", "==", "\"static\"", "or", "self", ".", "MODEL", "==", "\"non-static\"", "or", "self", ".", "MODEL", "==", "\"multichannel\"", ":", "\n", "            ", "self", ".", "WV_MATRIX", "=", "kwargs", "[", "\"WV_MATRIX\"", "]", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "WV_MATRIX", ")", ")", "\n", "if", "self", ".", "MODEL", "==", "\"static\"", ":", "\n", "                ", "self", ".", "embedding", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "FILTERS", ")", ")", ":", "\n", "            ", "self", ".", "conv", ".", "append", "(", "nn", ".", "Conv1d", "(", "self", ".", "IN_CHANNEL", ",", "self", ".", "FILTER_NUM", "[", "i", "]", ",", "self", ".", "WORD_DIM", "*", "self", ".", "FILTERS", "[", "i", "]", ",", "stride", "=", "self", ".", "WORD_DIM", ")", ")", "\n", "", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "sum", "(", "self", ".", "FILTER_NUM", ")", ",", "self", ".", "CLASS_SIZE", ")", "\n", "self", ".", "init", "(", ")", "\n", "# self.beta = torch.distributions.beta.Beta(torch.tensor([kwargs['ALPHA_A']]), torch.tensor([kwargs['ALPHA_B']]))", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.CNN.init": [[218, 222], ["model.CNN.named_parameters", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "init", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "weight", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'conv'", "in", "name", "and", "'weight'", "in", "name", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "weight", ",", "gain", "=", "2", ")", "\n", "#todo fc\u521d\u59cb\u5316\uff0c\u5b9e\u9a8c", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.CNN.forward": [[226, 269], ["model.CNN.long", "model.CNN.embedding().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.CNN.fc", "model.CNN.embedding().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.CNN.fc", "numpy.random.permutation", "random.randint", "numpy.random.beta", "model.mixup_process", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "model.mixup_process", "model.CNN.dropout", "model.mixup_process", "torch.max_pool1d().view", "torch.max_pool1d().view", "torch.max_pool1d().view", "model.CNN.dropout", "model.CNN.size", "model.CNN.embedding", "range", "model.CNN.embedding", "range", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "len", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "len", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process"], ["", "", "", "def", "forward", "(", "self", ",", "x", ",", "target", "=", "None", ",", "mixup_hidden", "=", "False", ",", "layer_mix", "=", "None", ",", "lam", "=", "None", ",", "indices", "=", "None", ")", ":", "\n", "# target is one_hot vector", "\n", "        ", "x", "=", "x", ".", "long", "(", ")", "# make sure the input type is long", "\n", "\n", "if", "mixup_hidden", ":", "# if we make mixup in hidden state", "\n", "            ", "if", "indices", "==", "None", ":", "\n", "                ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "x", ".", "size", "(", "0", ")", ")", "\n", "", "if", "layer_mix", "==", "None", ":", "\n", "                ", "layer_mix", "=", "random", ".", "randint", "(", "0", ",", "2", ")", "# random mixup in different layers", "\n", "", "if", "lam", "==", "None", ":", "\n", "                ", "lam", "=", "np", ".", "random", ".", "beta", "(", "1", ",", "1", ")", "# random lam if not set", "\n", "# layer#0", "\n", "", "x", "=", "self", ".", "embedding", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "self", ".", "MAX_SENT_LEN", ")", "\n", "if", "layer_mix", "==", "0", ":", "# word", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ",", "indices", "=", "indices", ")", "\n", "# layer#1", "\n", "", "conv_results", "=", "[", "\n", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "conv", "[", "i", "]", "(", "x", ")", ")", ",", "self", ".", "MAX_SENT_LEN", "-", "self", ".", "FILTERS", "[", "i", "]", "+", "1", ")", "\n", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "FILTERS", ")", ")", "]", "\n", "x", "=", "torch", ".", "cat", "(", "conv_results", ",", "1", ")", "\n", "if", "layer_mix", "==", "1", ":", "# sentence", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ",", "indices", "=", "indices", ")", "\n", "# layer#2", "\n", "", "if", "self", ".", "DROPOUT_PROB", ">", "0", "and", "self", ".", "DROPOUT_PROB", "<", "1", ":", "\n", "                ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "if", "layer_mix", "==", "2", ":", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ")", "\n", "", "return", "x", ",", "target", ",", "indices", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "x", "=", "self", ".", "embedding", "(", "x", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "WORD_DIM", "*", "self", ".", "MAX_SENT_LEN", ")", "\n", "conv_results", "=", "[", "\n", "F", ".", "max_pool1d", "(", "F", ".", "relu", "(", "self", ".", "conv", "[", "i", "]", "(", "x", ")", ")", ",", "self", ".", "MAX_SENT_LEN", "-", "self", ".", "FILTERS", "[", "i", "]", "+", "1", ")", "\n", ".", "view", "(", "-", "1", ",", "self", ".", "FILTER_NUM", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "FILTERS", ")", ")", "]", "\n", "x", "=", "torch", ".", "cat", "(", "conv_results", ",", "1", ")", "\n", "if", "self", ".", "DROPOUT_PROB", ">", "0", "and", "self", ".", "DROPOUT_PROB", "<", "1", ":", "\n", "                ", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__": [[272, 296], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "model.RNN.embedding.weight.data.copy_", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "MODEL", "=", "kwargs", "[", "\"MODEL\"", "]", "\n", "self", ".", "BATCH_SIZE", "=", "kwargs", "[", "\"BATCH_SIZE\"", "]", "\n", "self", ".", "MAX_SENT_LEN", "=", "kwargs", "[", "\"MAX_SENT_LEN\"", "]", "\n", "self", ".", "WORD_DIM", "=", "kwargs", "[", "\"WORD_DIM\"", "]", "\n", "self", ".", "VOCAB_SIZE", "=", "kwargs", "[", "\"VOCAB_SIZE\"", "]", "\n", "self", ".", "CLASS_SIZE", "=", "kwargs", "[", "\"CLASS_SIZE\"", "]", "\n", "self", ".", "HIDDEN_SIZE", "=", "kwargs", "[", "\"HIDDEN_SIZE\"", "]", "\n", "self", ".", "DROPOUT_PROB", "=", "kwargs", "[", "\"DROPOUT_PROB\"", "]", "\n", "if", "self", ".", "DROPOUT_PROB", "<", "0", "or", "self", ".", "DROPOUT_PROB", ">", "1", ":", "\n", "            ", "self", ".", "DROPOUT_PROB", "=", "0", "\n", "\n", "", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "VOCAB_SIZE", "+", "2", ",", "self", ".", "WORD_DIM", ",", "padding_idx", "=", "self", ".", "VOCAB_SIZE", "+", "1", ")", "\n", "self", ".", "WV_MATRIX", "=", "kwargs", "[", "\"WV_MATRIX\"", "]", "\n", "self", ".", "embedding", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "self", ".", "WV_MATRIX", ")", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "WORD_DIM", ",", "self", ".", "HIDDEN_SIZE", ",", "2", ",", "\n", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "dropout", "=", "self", ".", "DROPOUT_PROB", ")", "\n", "self", ".", "tanh1", "=", "nn", ".", "Tanh", "(", ")", "\n", "# self.u = nn.Parameter(torch.Tensor(config.hidden_size * 2, config.hidden_size * 2))", "\n", "self", ".", "w", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "HIDDEN_SIZE", "*", "2", ")", ")", "\n", "self", ".", "tanh2", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "HIDDEN_SIZE", "*", "2", ",", "self", ".", "CLASS_SIZE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.RNN.forward": [[298, 334], ["model.RNN.embedding", "model.RNN.lstm", "model.RNN.tanh1", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.relu", "torch.relu", "torch.relu", "model.RNN.fc1", "model.RNN.lstm", "model.RNN.tanh1", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.relu", "torch.relu", "torch.relu", "model.RNN.fc1", "numpy.random.permutation", "random.randint", "numpy.random.beta", "model.mixup_process", "model.mixup_process", "model.RNN.size", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", "=", "None", ",", "mixup_hidden", "=", "False", ",", "layer_mix", "=", "None", ",", "lam", "=", "None", ",", "indices", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "embedding", "(", "x", ")", "# [batch_size, seq_len, embeding]=[128, 32, 300]", "\n", "\n", "if", "mixup_hidden", ":", "\n", "            ", "if", "indices", "==", "None", ":", "\n", "                ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "x", ".", "size", "(", "0", ")", ")", "\n", "", "if", "layer_mix", "==", "None", ":", "\n", "                ", "layer_mix", "=", "random", ".", "randint", "(", "0", ",", "2", ")", "# random mixup in different layers", "\n", "", "if", "lam", "==", "None", ":", "\n", "                ", "lam", "=", "np", ".", "random", ".", "beta", "(", "1", ",", "1", ")", "# random lam if not set", "\n", "# layer#0", "\n", "", "if", "layer_mix", "==", "0", ":", "# word", "\n", "                ", "x", ",", "target", ",", "indices", "=", "mixup_process", "(", "x", ",", "target", ",", "lam", ",", "indices", "=", "indices", ")", "\n", "", "H", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "# [batch_size, seq_len, hidden_size * num_direction]=[128, 32, 256]", "\n", "\n", "M", "=", "self", ".", "tanh1", "(", "H", ")", "# [128, 32, 256]", "\n", "# M = torch.tanh(torch.matmul(H, self.u))", "\n", "alpha", "=", "F", ".", "softmax", "(", "torch", ".", "matmul", "(", "M", ",", "self", ".", "w", ")", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# [128, 32, 1]", "\n", "out", "=", "H", "*", "alpha", "# [128, 32, 256]", "\n", "out", "=", "torch", ".", "sum", "(", "out", ",", "1", ")", "# [128, 256]", "\n", "if", "layer_mix", "==", "1", ":", "# sentence", "\n", "                ", "out", ",", "target", ",", "indices", "=", "mixup_process", "(", "out", ",", "target", ",", "lam", ",", "indices", "=", "indices", ")", "\n", "", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "fc1", "(", "out", ")", "\n", "return", "out", ",", "target", ",", "indices", "\n", "", "else", ":", "\n", "            ", "H", ",", "_", "=", "self", ".", "lstm", "(", "x", ")", "# [batch_size, seq_len, hidden_size * num_direction]=[128, 32, 256]", "\n", "\n", "M", "=", "self", ".", "tanh1", "(", "H", ")", "# [128, 32, 256]", "\n", "# M = torch.tanh(torch.matmul(H, self.u))", "\n", "alpha", "=", "F", ".", "softmax", "(", "torch", ".", "matmul", "(", "M", ",", "self", ".", "w", ")", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "# [128, 32, 1]", "\n", "out", "=", "H", "*", "alpha", "# [128, 32, 256]", "\n", "out", "=", "torch", ".", "sum", "(", "out", ",", "1", ")", "# [128, 256]", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "fc1", "(", "out", ")", "\n", "", "return", "out", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.model.mixup_process": [[9, 18], ["lam.clone().detach", "numpy.random.permutation", "out.size", "lam.clone"], "function", ["None"], ["def", "mixup_process", "(", "out", ",", "target_reweighted", ",", "lam", ",", "indices", "=", "None", ")", ":", "\n", "    ", "if", "indices", "is", "None", ":", "\n", "        ", "indices", "=", "np", ".", "random", ".", "permutation", "(", "out", ".", "size", "(", "0", ")", ")", "\n", "", "out", "=", "(", "out", ".", "T", "*", "lam", ")", ".", "T", "+", "(", "out", "[", "indices", "]", ".", "T", "*", "(", "1", "-", "lam", ")", ")", ".", "T", "\n", "target_shuffled_onehot", "=", "target_reweighted", "[", "indices", "]", "\n", "lam2", "=", "lam", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "target_reweighted", "=", "(", "target_reweighted", ".", "T", "*", "lam2", ")", ".", "T", "+", "(", "target_shuffled_onehot", ".", "T", "*", "(", "1", "-", "lam2", ")", ")", ".", "T", "\n", "#print(out,target_reweighted)", "\n", "return", "out", ",", "target_reweighted", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.log_name": [[20, 29], ["os.path.exists", "os.makedirs", "str"], "function", ["None"], ["def", "log_name", "(", "params", ")", ":", "\n", "    ", "file_name", "=", "\"train_log/\"", "+", "params", "[", "'DATASET'", "]", "+", "\"/\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_name", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "file_name", ")", "\n", "", "for", "key", "in", "KEYS", ":", "\n", "        ", "if", "key", "in", "params", ":", "\n", "            ", "file_name", "+=", "key", "+", "\"_\"", "+", "str", "(", "params", "[", "key", "]", ")", "+", "\"_\"", "\n", "", "", "path", "=", "file_name", "+", "\".log\"", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.set_seed": [[32, 37], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed", "random.seed"], "function", ["None"], ["", "def", "set_seed", "(", "seed", "=", "7", ")", ":", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "# cpu", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "# gpu", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "# numpy", "\n", "random", ".", "seed", "(", "seed", ")", "# random and transforms", "\n", "# torch.backends.cudnn.deterministic=True # cudnn", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.train": [[40, 157], ["torch.BCELoss().to", "torch.Softmax().to", "torch.CrossEntropyLoss().to", "list", "torch.Adam", "torch.utils.data.DataLoader", "logger.info", "filter", "torch.BCELoss", "torch.Softmax", "torch.CrossEntropyLoss", "model.parameters", "model.train", "numpy.random.beta", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "bce_loss.item", "optim.Adam.zero_grad", "bce_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "optim.Adam.step", "model.eval", "run_main.test", "logger.info", "batch_x.to.to", "label_ids.to.to", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "torch.nn.functional.one_hot", "nn.Softmax().to.", "nn.CrossEntropyLoss().to.", "torch.FloatTensor().to.requires_grad_", "nn.Softmax().to.", "nn.BCELoss().to.sum", "torch.mean", "torch.mean", "torch.mean", "torch.nn.functional.one_hot.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "model", "model", "model", "model", "torch.mean().backward", "torch.mean().backward", "torch.mean().backward", "nn.Softmax().to.", "nn.BCELoss().to.", "bce_loss.sum", "loss_delta.index_select", "loss_delta_recorder.append", "torch.cat().std", "torch.cat().std", "torch.cat().std", "torch.cat().mean", "torch.cat().mean", "torch.cat().mean", "weight.clone().detach.clone().detach", "nn.BCELoss().to.", "torch.FloatTensor().to.clone().detach", "model", "model", "mask_.view", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.mean", "torch.mean", "torch.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "weight.clone().detach.clone", "torch.FloatTensor().to.clone"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.train", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.test"], ["", "def", "train", "(", "model", ",", "train_set", ",", "test_set", ",", "params", ",", "logger", ")", ":", "\n", "    ", "bce_loss", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "parameters", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "parameters", ",", "lr", "=", "params", "[", "\"LEARNING_RATE\"", "]", ",", "weight_decay", "=", "params", "[", "\"L2\"", "]", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "params", "[", "\"BATCH_SIZE\"", "]", ",", "shuffle", "=", "True", ")", "\n", "max_test_acc", "=", "0", "\n", "cur_batch", "=", "0", "\n", "cur_epoch", "=", "0", "\n", "train_loss", "=", "0", "\n", "test_loss", "=", "0", "\n", "go_flag", "=", "True", "\n", "\n", "gamma", "=", "params", "[", "\"GAMMA\"", "]", "\n", "adv_type", "=", "params", "[", "\"ADV_TYPE\"", "]", "\n", "adv_flag", "=", "params", "[", "\"ADV_FLAG\"", "]", "\n", "loss_delta_recorder", "=", "[", "]", "\n", "while", "go_flag", ":", "\n", "        ", "cur_epoch", "+=", "1", "\n", "for", "batch", "in", "train_loader", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "cur_batch", "+=", "1", "\n", "if", "cur_batch", "==", "params", "[", "'TRAIN_BATCH'", "]", ":", "\n", "                ", "go_flag", "=", "False", "\n", "break", "\n", "", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "                ", "batch_x", ",", "batch_y", "=", "batch", "\n", "batch_x", "=", "batch_x", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "batch_y", "=", "batch_y", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "one_hot_batch_y", "=", "torch", ".", "nn", ".", "functional", ".", "one_hot", "(", "batch_y", ",", "params", "[", "\"CLASS_SIZE\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "_", "=", "batch", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "batch_y", "=", "label_ids", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "one_hot_batch_y", "=", "torch", ".", "nn", ".", "functional", ".", "one_hot", "(", "batch_y", ",", "params", "[", "\"CLASS_SIZE\"", "]", ")", "\n", "\n", "# argmax lam loss", "\n", "", "lam", "=", "np", ".", "random", ".", "beta", "(", "params", "[", "'ALPHA'", "]", ",", "params", "[", "'ALPHA'", "]", ",", "one_hot_batch_y", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "# lam = np.fmax(lam,1-lam)", "\n", "lam", "=", "torch", ".", "FloatTensor", "(", "lam", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "if", "adv_type", "==", "0", ":", "\n", "                ", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "                    ", "pred", "=", "model", "(", "batch_x", ")", "\n", "", "else", ":", "\n", "                    ", "pred", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ")", "\n", "", "pred", "=", "softmax", "(", "pred", ")", "\n", "loss", "=", "criterion", "(", "pred", ",", "batch_y", ")", "\n", "", "if", "adv_type", "==", "1", ":", "\n", "                ", "lam", ".", "requires_grad_", "(", ")", "\n", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "                    ", "mixed_x", ",", "mixed_y", ",", "indices", "=", "model", "(", "batch_x", ",", "target", "=", "one_hot_batch_y", ",", "mixup_hidden", "=", "params", "[", "'MIX_HIDDEN'", "]", ",", "\n", "layer_mix", "=", "params", "[", "'LAYER_MIX'", "]", ",", "lam", "=", "lam", ")", "\n", "", "else", ":", "\n", "                    ", "mixed_x", ",", "mixed_y", ",", "indices", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "target", "=", "one_hot_batch_y", ",", "\n", "mixup_hidden", "=", "True", ",", "\n", "layer_mix", "=", "params", "[", "'LAYER_MIX'", "]", ",", "lam", "=", "lam", ")", "\n", "", "pred", "=", "softmax", "(", "mixed_x", ")", "\n", "loss", "=", "bce_loss", "(", "pred", ",", "mixed_y", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "if", "adv_flag", ":", "\n", "# get gradient for lambda", "\n", "                    ", "torch", ".", "mean", "(", "loss", ")", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "loss_pre", "=", "loss", "\n", "lgrad", "=", "lam", ".", "grad", "\n", "lam", "=", "lam", ".", "clone", "(", ")", ".", "detach", "(", ")", "+", "gamma", "*", "lgrad", "\n", "# renew the interpolated input and label", "\n", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "                        ", "mixed_x_", ",", "mixed_y_", ",", "_", "=", "model", "(", "batch_x", ",", "target", "=", "one_hot_batch_y", ",", "mixup_hidden", "=", "params", "[", "'MIX_HIDDEN'", "]", ",", "\n", "layer_mix", "=", "params", "[", "'LAYER_MIX'", "]", ",", "lam", "=", "lam", ",", "indices", "=", "indices", ")", "\n", "", "else", ":", "\n", "                        ", "mixed_x_", ",", "mixed_y_", ",", "_", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "target", "=", "one_hot_batch_y", ",", "\n", "mixup_hidden", "=", "True", ",", "\n", "layer_mix", "=", "params", "[", "'LAYER_MIX'", "]", ",", "lam", "=", "lam", ",", "indices", "=", "indices", ")", "\n", "", "pred", "=", "softmax", "(", "mixed_x_", ")", "\n", "loss", "=", "bce_loss", "(", "pred", ",", "mixed_y", ")", "\n", "loss_cur", "=", "loss", ".", "sum", "(", "dim", "=", "1", ")", "\n", "# get the loss delta, record the position that loss delta greater than zero", "\n", "loss_delta", "=", "loss_cur", "-", "loss_pre", "\n", "mask_", "=", "(", "loss_delta", ">", "0", ")", ".", "nonzero", "(", ")", "\n", "# record all the loss delta that greater than zero, and get the mean and std", "\n", "positive_loss_delta", "=", "loss_delta", ".", "index_select", "(", "0", ",", "mask_", ".", "view", "(", "-", "1", ")", ")", "\n", "loss_delta_recorder", ".", "append", "(", "positive_loss_delta", ")", "\n", "cur_delta_std", "=", "torch", ".", "cat", "(", "loss_delta_recorder", "[", "-", "params", "[", "'MOVING_AVG'", "]", ":", "]", ")", ".", "std", "(", ")", "\n", "cur_delta_mean", "=", "torch", ".", "cat", "(", "loss_delta_recorder", "[", "-", "params", "[", "'MOVING_AVG'", "]", ":", "]", ")", ".", "mean", "(", ")", "\n", "# generate a masker to mask the loss delta >0", "\n", "positive_mask", "=", "(", "loss_delta", ">", "cur_delta_mean", ")", ".", "float", "(", ")", "\n", "# to re-weight the samples that loss delta is greater than zero, the weight is calculated by the normalized  the loss delta", "\n", "weight", "=", "torch", ".", "ones_like", "(", "loss_pre", ")", "+", "(", "loss_delta", "-", "cur_delta_mean", ")", "/", "cur_delta_std", "*", "positive_mask", "\n", "weight", "=", "weight", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mask_", "=", "(", "loss_delta", ">", "0", ")", ".", "float", "(", ")", "\n", "# calculate the final loss", "\n", "# if the loss delta is greater than zero, use the loss after adv", "\n", "# if the loss delta is lower than zero, use the loss before adv", "\n", "# re-weight the loss by the normalized loss delta", "\n", "loss", "=", "weight", "*", "(", "loss_cur", "*", "mask_", "+", "loss_pre", "*", "(", "1", "-", "mask_", ")", ")", "\n", "# print(\"{:.4f}-{:.4f} rate: {:.2f}%\".format(loss_pre.item(),loss_cur.item(),100*count/cur_batch))", "\n", "\n", "", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "parameters", ",", "max_norm", "=", "params", "[", "\"NORM_LIMIT\"", "]", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "test_acc", ",", "test_loss_", "=", "test", "(", "model", ",", "test_set", ",", "params", ")", "\n", "test_loss", "+=", "test_loss_", "\n", "\n", "if", "test_acc", ">", "max_test_acc", ":", "\n", "                ", "max_test_acc", "=", "test_acc", "\n", "", "logger", ".", "info", "(", "\n", "\"{} batch {:6d}\\ttrain_loss {:.4f}\\ttest_loss {:.4f}\\ttest_acc {:.4f}\\tmax_acc {:.4f}\"", ".", "format", "(", "\n", "params", "[", "'DATASET'", "]", ",", "cur_batch", ",", "train_loss", "/", "cur_batch", ",", "test_loss", "/", "cur_batch", ",", "test_acc", ",", "\n", "max_test_acc", ")", ")", "\n", "", "", "logger", ".", "info", "(", "\"max test acc: {:.4f}\"", ".", "format", "(", "max_test_acc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.test": [[159, 194], ["torch.utils.data.DataLoader", "torch.CrossEntropyLoss().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "y_list.data.numpy.data.numpy", "pred_list.cpu().data.numpy.cpu().data.numpy", "y_list.data.numpy.append", "nn.CrossEntropyLoss().to.", "criterion.item", "torch.argmax", "torch.argmax", "torch.argmax", "pred_list.cpu().data.numpy.append", "sum", "len", "torch.CrossEntropyLoss", "batch_x.to.to", "label_ids.to.to", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to", "model", "model", "model.to", "pred_list.cpu().data.numpy.cpu", "zip"], "function", ["None"], ["", "def", "test", "(", "model", ",", "data_set", ",", "params", ")", ":", "\n", "    ", "data_loader", "=", "DataLoader", "(", "data_set", ",", "batch_size", "=", "params", "[", "'BATCH_SIZE'", "]", ",", "shuffle", "=", "False", ",", "drop_last", "=", "False", ")", "\n", "y_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "test_loss", "=", "0", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "batch_count", "=", "0", "\n", "for", "batch", "in", "data_loader", ":", "\n", "        ", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "            ", "batch_x", ",", "batch_y", "=", "batch", "\n", "batch_x", "=", "batch_x", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "batch_y", "=", "batch_y", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "_", "=", "batch", "\n", "input_ids", "=", "input_ids", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "batch_y", "=", "label_ids", ".", "to", "(", "\"cpu\"", ")", "\n", "", "y_list", ".", "append", "(", "batch_y", ")", "\n", "if", "params", "[", "'CLASSIFIER'", "]", "!=", "\"BERT\"", ":", "\n", "            ", "pred", "=", "model", "(", "batch_x", ",", "mixup_hidden", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "pred", "=", "model", "(", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "mixup_hidden", "=", "False", ")", "\n", "", "loss", "=", "criterion", "(", "pred", ".", "to", "(", "'cpu'", ")", ",", "batch_y", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "pred", "=", "torch", ".", "argmax", "(", "pred", ",", "axis", "=", "1", ")", "\n", "pred_list", ".", "append", "(", "pred", ")", "\n", "batch_count", "+=", "1", "\n", "", "y_list", "=", "torch", ".", "cat", "(", "y_list", ",", "dim", "=", "0", ")", "\n", "pred_list", "=", "torch", ".", "cat", "(", "pred_list", ",", "dim", "=", "0", ")", "\n", "y_list", "=", "y_list", ".", "data", ".", "numpy", "(", ")", "\n", "pred_list", "=", "pred_list", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "acc", "=", "sum", "(", "[", "1", "if", "p", "==", "y", "else", "0", "for", "p", ",", "y", "in", "zip", "(", "pred_list", ",", "y_list", ")", "]", ")", "/", "len", "(", "pred_list", ")", "\n", "return", "acc", ",", "test_loss", "/", "batch_count", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.load_glove_txt": [[196, 206], ["sum", "open", "tqdm.tqdm", "line.strip().split", "numpy.array", "open", "line.strip"], "function", ["None"], ["", "def", "load_glove_txt", "(", "file_path", "=", "\"glove.6B.300d.txt\"", ")", ":", "\n", "    ", "results", "=", "{", "}", "\n", "num_file", "=", "sum", "(", "[", "1", "for", "i", "in", "open", "(", "file_path", ",", "\"r\"", ",", "encoding", "=", "'utf8'", ")", "]", ")", "\n", "with", "open", "(", "file_path", ",", "'r'", ",", "encoding", "=", "'utf8'", ")", "as", "infile", ":", "\n", "        ", "for", "line", "in", "tqdm", ".", "tqdm", "(", "infile", ",", "total", "=", "num_file", ")", ":", "\n", "            ", "data", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "word", "=", "data", "[", "0", "]", "\n", "vec", "=", "np", ".", "array", "(", "data", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "results", "[", "word", "]", "=", "vec", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.main": [[208, 338], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "logging.getLogger", "logging.getLogger.setLevel", "argparse.ArgumentParser.parse_args", "run_main.set_seed", "data_loader.load_dataset", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.Formatter", "logging.FileHandler.setFormatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.getLogger.addHandler", "logging.getLogger.addHandler", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.removeHandler", "logging.getLogger.removeHandler", "torch.device", "torch.device", "torch.device", "run_main.log_name", "logging.getLogger.info", "logging.getLogger.info", "range", "np.array.append", "np.array.append", "numpy.array", "model.CNN().to", "logging.getLogger.info", "run_main.train", "logging.getLogger.info", "run_main.load_glove_txt", "len", "numpy.random.uniform().astype", "numpy.zeros().astype", "model.RNN().to", "np.array.append", "np.array.append", "model.CNN", "model.BertForSequenceClassification.from_pretrained().to", "numpy.random.uniform().astype", "numpy.random.uniform", "numpy.zeros", "model.RNN", "model.BertForSequenceClassification.from_pretrained", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.set_seed", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.data_loader.load_dataset", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.log_name", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.train", "home.repos.pwc.inspect_result.pai-smallisallyourneed_mixup-amp.None.run_main.load_glove_txt"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"-----[CNN-classifier]-----\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "default", "=", "\"train\"", ",", "help", "=", "\"train: train (with test) a model / test: test saved models\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model\"", ",", "default", "=", "\"non-static\"", ",", "\n", "help", "=", "\"available models: rand, static, non-static, multichannel\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_model\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "\"whether saving model or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--early_stopping\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "\"whether to apply early stopping\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "2e-4", ",", "type", "=", "float", ",", "help", "=", "\"learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "default", "=", "123", ",", "type", "=", "int", ",", "help", "=", "\"seed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mixup\"", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "\"0: no mixup, 1: mixup, 2: our mixup\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cv\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"cv: 0-9  |  none\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--device\"", ",", "default", "=", "\"cpu\"", ",", "type", "=", "str", ",", "help", "=", "\"the device to be used\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "default", "=", "\"1\"", ",", "type", "=", "float", ",", "help", "=", "\"the alpha\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--norm_limit\"", ",", "default", "=", "10", ",", "type", "=", "float", ",", "help", "=", "\"the norm limit\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--moving_avg\"", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "\"the norm limit\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "default", "=", "50", ",", "type", "=", "int", ",", "help", "=", "\"batch size\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dropout\"", ",", "default", "=", "\"-1\"", ",", "type", "=", "float", ",", "help", "=", "\"dropout ratio, between 0 and 1.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch\"", ",", "default", "=", "8000", ",", "type", "=", "int", ",", "help", "=", "\"number of max batch\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--l2\"", ",", "default", "=", "0", ",", "type", "=", "float", ",", "help", "=", "\"l2\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mix_hidden\"", ",", "default", "=", "True", ",", "action", "=", "'store_true'", ",", "help", "=", "\"whether mixup hidden statues or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--layer_mix\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"the layer to perform mixup\uff0c 1 word\uff0c 2 sentence\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"TREC\"", ",", "help", "=", "\"available datasets: TREC ,SST1, SST2, SUBJ, MR\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_flag\"", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "\"using adv or not\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv_type\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"0: no mixup or 1:mixup\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--scale_rate\"", ",", "default", "=", "1.", ",", "type", "=", "float", ",", "help", "=", "\"scale rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "default", "=", "0.002", ",", "type", "=", "float", ",", "help", "=", "\"gamma\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sent_len\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"max_length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--classifier\"", ",", "default", "=", "\"BERT\"", ",", "type", "=", "str", ",", "help", "=", "\"CNN,RNN,BERT\"", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "setLevel", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "options", "=", "parser", ".", "parse_args", "(", ")", "\n", "# if options.classifier != \"BERT\":", "\n", "#     if options.dataset in ['SUBJ', 'MR']:", "\n", "#         filename = \"{}-{}.pkl\".format(options.dataset, options.cv)", "\n", "#     else:", "\n", "#         filename = \"{}-{}.pkl\".format(options.dataset, 0)", "\n", "#     with open(filename, 'rb') as f:", "\n", "#         train_set, test_set, wv_matrix, params_tmp = pickle.load(f)", "\n", "# else:", "\n", "#     if options.dataset in ['SUBJ', 'MR']:", "\n", "#         filename = \"{}-{}-{}.pkl\".format(options.classifier, options.dataset, options.cv)", "\n", "#     else:", "\n", "#         filename = \"{}-{}-{}.pkl\".format(options.classifier, options.dataset, 0)", "\n", "#     with open(filename, 'rb') as f:", "\n", "#         train_set, test_set, params_tmp = pickle.load(f)", "\n", "\n", "set_seed", "(", "options", ".", "seed", ")", "\n", "word_vectors", "=", "None", "\n", "if", "options", ".", "max_sent_len", ">", "0", ":", "\n", "        ", "options", ".", "MAX_SENT_LEN", "=", "options", ".", "max_sent_len", "\n", "", "train_set", ",", "test_set", ",", "data", "=", "load_dataset", "(", "options", ")", "\n", "params", "=", "{", "\n", "\"MODEL\"", ":", "options", ".", "model", ",", "\n", "\"DATASET\"", ":", "options", ".", "dataset", ",", "\n", "\"SAVE_MODEL\"", ":", "options", ".", "save_model", ",", "\n", "\"EARLY_STOPPING\"", ":", "options", ".", "early_stopping", ",", "\n", "\"TRAIN_BATCH\"", ":", "options", ".", "train_batch", ",", "\n", "\"LEARNING_RATE\"", ":", "options", ".", "learning_rate", ",", "\n", "\"MAX_SENT_LEN\"", ":", "options", ".", "MAX_SENT_LEN", ",", "\n", "\"BATCH_SIZE\"", ":", "options", ".", "batch_size", ",", "\n", "\"WORD_DIM\"", ":", "300", ",", "\n", "\"HIDDEN_SIZE\"", ":", "512", ",", "\n", "\"VOCAB_SIZE\"", ":", "options", ".", "VOCAB_SIZE", ",", "\n", "\"CLASS_SIZE\"", ":", "options", ".", "CLASS_SIZE", ",", "\n", "\"FILTERS\"", ":", "[", "3", ",", "4", ",", "5", "]", ",", "\n", "\"FILTER_NUM\"", ":", "[", "100", ",", "100", ",", "100", "]", ",", "\n", "\"DROPOUT_PROB\"", ":", "options", ".", "dropout", ",", "\n", "\"NORM_LIMIT\"", ":", "options", ".", "norm_limit", ",", "\n", "\"MIXUP\"", ":", "options", ".", "mixup", ",", "\n", "\"MIX_HIDDEN\"", ":", "options", ".", "mix_hidden", ",", "\n", "\"LAYER_MIX\"", ":", "options", ".", "layer_mix", ",", "\n", "\"CV\"", ":", "options", ".", "cv", ",", "\n", "\"L2\"", ":", "options", ".", "l2", ",", "\n", "\"CLASSIFIER\"", ":", "options", ".", "classifier", ",", "\n", "\"ALPHA\"", ":", "options", ".", "alpha", ",", "\n", "\"SEED\"", ":", "options", ".", "seed", ",", "\n", "\"ADV_TYPE\"", ":", "options", ".", "adv_type", ",", "\n", "\"ADV_FLAG\"", ":", "options", ".", "adv_flag", ",", "\n", "\"GAMMA\"", ":", "options", ".", "gamma", ",", "\n", "\"SCALE_RATE\"", ":", "options", ".", "scale_rate", ",", "\n", "\"DEVICE\"", ":", "torch", ".", "device", "(", "options", ".", "device", ")", ",", "\n", "\"MOVING_AVG\"", ":", "options", ".", "moving_avg", "\n", "}", "\n", "handler", "=", "logging", ".", "FileHandler", "(", "log_name", "(", "params", ")", ")", "\n", "handler", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(name)s - %(levelname)s - %(message)s'", ")", "\n", "handler", ".", "setFormatter", "(", "formatter", ")", "\n", "console", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "logger", ".", "addHandler", "(", "handler", ")", "\n", "logger", ".", "addHandler", "(", "console", ")", "\n", "\n", "logger", ".", "info", "(", "\"=\"", "*", "20", "+", "\"INFORMATION\"", "+", "\"=\"", "*", "20", ")", "\n", "for", "key", "in", "params", ":", "\n", "        ", "logger", ".", "info", "(", "[", "key", ",", "params", "[", "key", "]", "]", ")", "\n", "", "logger", ".", "info", "(", "\"=\"", "*", "20", "+", "\"INFORMATION\"", "+", "\"=\"", "*", "20", ")", "\n", "\n", "if", "params", "[", "\"MODEL\"", "]", "==", "\"non-static\"", "and", "params", "[", "'CLASSIFIER'", "]", "!=", "'BERT'", ":", "\n", "# load word2vec", "\n", "        ", "logger", ".", "info", "(", "\"loading Glove...\"", ")", "\n", "if", "word_vectors", "==", "None", ":", "\n", "            ", "word_vectors", "=", "load_glove_txt", "(", "file_path", "=", "\"glove.840B.300d.txt\"", ")", "\n", "", "wv_matrix", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data", "[", "\"vocab\"", "]", ")", ")", ":", "\n", "            ", "word", "=", "data", "[", "\"idx_to_word\"", "]", "[", "i", "]", "\n", "if", "word", "in", "word_vectors", ":", "\n", "                ", "wv_matrix", ".", "append", "(", "word_vectors", "[", "word", "]", ")", "\n", "", "else", ":", "\n", "# print(word)", "\n", "                ", "wv_matrix", ".", "append", "(", "np", ".", "random", ".", "uniform", "(", "-", "0.01", ",", "0.01", ",", "params", "[", "'WORD_DIM'", "]", ")", ".", "astype", "(", "\"float32\"", ")", ")", "\n", "# one for UNK and one for zero padding", "\n", "", "", "wv_matrix", ".", "append", "(", "np", ".", "random", ".", "uniform", "(", "-", "0.01", ",", "0.01", ",", "params", "[", "'WORD_DIM'", "]", ")", ".", "astype", "(", "\"float32\"", ")", ")", "\n", "wv_matrix", ".", "append", "(", "np", ".", "zeros", "(", "params", "[", "'WORD_DIM'", "]", ")", ".", "astype", "(", "\"float32\"", ")", ")", "\n", "wv_matrix", "=", "np", ".", "array", "(", "wv_matrix", ")", "\n", "params", "[", "\"WV_MATRIX\"", "]", "=", "wv_matrix", "\n", "", "if", "params", "[", "'CLASSIFIER'", "]", "==", "\"CNN\"", ":", "\n", "        ", "model", "=", "CNN", "(", "**", "params", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "", "elif", "params", "[", "'CLASSIFIER'", "]", "==", "\"RNN\"", ":", "\n", "        ", "model", "=", "RNN", "(", "**", "params", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "", "elif", "params", "[", "'CLASSIFIER'", "]", "==", "\"BERT\"", ":", "\n", "        ", "model", "=", "BertForSequenceClassification", ".", "from_pretrained", "(", "'./bert-base-uncased'", ",", "**", "params", ")", ".", "to", "(", "params", "[", "'DEVICE'", "]", ")", "\n", "", "if", "options", ".", "mode", "==", "\"train\"", ":", "\n", "        ", "logger", ".", "info", "(", "\"=\"", "*", "20", "+", "\"TRAINING STARTED\"", "+", "\"=\"", "*", "20", ")", "\n", "train", "(", "model", ",", "train_set", ",", "test_set", ",", "params", ",", "logger", ")", "\n", "logger", ".", "info", "(", "\"=\"", "*", "20", "+", "\"TRAINING FINISHED\"", "+", "\"=\"", "*", "20", ")", "\n", "", "logger", ".", "removeHandler", "(", "handler", ")", "\n", "logger", ".", "removeHandler", "(", "console", ")", "\n", "\n"]]}