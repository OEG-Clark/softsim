{"home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.sequential_cifar_mnist_compression.train_test": [[81, 141], ["torch.reshape", "torch.reshape", "x_flat.permute.permute", "range", "loss_fun", "torch.sum().type().detach().cpu().numpy", "torch.sum().type().detach().cpu().numpy", "loss_fun.detach().cpu().numpy", "optimizer.zero_grad", "cell.train", "cell.eval", "cell", "cell.get_wavelet_loss", "cell.get_wavelet_loss.detach().cpu().numpy", "loss_full.backward", "optimizer.step", "print", "list", "x_flat[].type", "torch.sum().type().detach().cpu", "torch.sum().type().detach().cpu", "loss_fun.detach().cpu", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "cell.get_wavelet_loss.detach().cpu", "cell.parameters", "torch.sum().type().detach", "torch.sum().type().detach", "loss_fun.detach", "cell.get_wavelet_loss.detach", "torch.sum().type", "torch.sum().type", "torch.sum", "torch.sum", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.backward"], ["def", "train_test", "(", "x", ",", "y", ",", "iteration_no", ",", "e_no", ",", "train", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Run the network.\n        x: image tensors, [batch_size, 1, 28, 28]\n        y: ground truth, [batch_size]\n        iteration_no: iteration count\n        e_no: epoch count\n        train: if true turn on gradient descent.\n\n    Returns:\n        cpu_loss: loss on the current batch\n        sum_correct: The total of correctly identified digits.\n    \"\"\"", "\n", "# reshape into batch, time, channel", "\n", "x_shape", "=", "x", ".", "shape", "\n", "x_flat", "=", "torch", ".", "reshape", "(", "x", ",", "list", "(", "x_shape", "[", ":", "2", "]", ")", "+", "[", "-", "1", "]", ")", "\n", "x_flat", "=", "x_flat", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "if", "train", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "cell", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "cell", ".", "eval", "(", ")", "\n", "\n", "", "time_steps", "=", "x_flat", ".", "shape", "[", "1", "]", "\n", "# run the RNN", "\n", "hc", "=", "None", "\n", "for", "t", "in", "range", "(", "time_steps", ")", ":", "\n", "# batch_major format [b,t,d]", "\n", "        ", "yc", ",", "hc", "=", "cell", "(", "x_flat", "[", ":", ",", "t", ",", ":", "]", ".", "type", "(", "torch", ".", "float32", ")", ",", "hc", ")", "\n", "\n", "# only the last output is interesting", "\n", "", "loss", "=", "loss_fun", "(", "yc", ",", "y", ")", "\n", "sum_correct", "=", "torch", ".", "sum", "(", "torch", ".", "max", "(", "yc", ",", "dim", "=", "-", "1", ")", "[", "1", "]", "==", "y", ")", ".", "type", "(", "torch", ".", "float32", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "acc", "=", "sum_correct", "/", "(", "args", ".", "batch_size", "*", "1.0", ")", "\n", "\n", "cpu_loss", "=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# compute gradients", "\n", "if", "args", ".", "cell", "==", "'WaveletGRU'", ":", "\n", "        ", "loss_wave", "=", "cell", ".", "get_wavelet_loss", "(", ")", "\n", "loss_full", "=", "loss", "+", "loss_wave", "\n", "loss_wave_cpu", "=", "loss_wave", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "        ", "loss_wave_cpu", "=", "0", "\n", "loss_full", "=", "loss", "\n", "\n", "", "if", "train", ":", "\n", "        ", "loss_full", ".", "backward", "(", ")", "\n", "\n", "# clip gradients.", "\n", "if", "args", ".", "clip", ">", "0", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "cell", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "\n", "# apply gradients", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "", "if", "iteration_no", "%", "50", "==", "0", ":", "\n", "        ", "print", "(", "'e'", ",", "e_no", ",", "'step'", ",", "iteration_no", ",", "\n", "'loss'", ",", "cpu_loss", ",", "'acc'", ",", "acc", ",", "'wl'", ",", "\n", "loss_wave_cpu", ",", "'train'", ",", "train", ")", "\n", "", "return", "cpu_loss", ",", "sum_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.sequential_cifar_mnist_compression.test": [[143, 162], ["print", "print", "numpy.mean", "torch.no_grad", "torch.no_grad", "sequential_cifar_mnist_compression.train_test", "test_loss_lst.append", "test_x.cuda", "test_y.cuda"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.sequential_cifar_mnist_compression.train_test"], ["", "def", "test", "(", ")", ":", "\n", "    ", "test_loss_lst", "=", "[", "]", "\n", "test_acc_lst", "=", "[", "]", "\n", "test_it", "=", "0", "\n", "test_true_total", "=", "0", "\n", "test_elements_total", "=", "0", "\n", "for", "test_x", ",", "test_y", "in", "test_loader", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "test_loss", ",", "test_sum_correct", "=", "train_test", "(", "test_x", ".", "cuda", "(", ")", ",", "test_y", ".", "cuda", "(", ")", ",", "\n", "test_it", ",", "-", "1", ",", "train", "=", "False", ")", "\n", "test_it", "+=", "1", "\n", "test_true_total", "+=", "test_sum_correct", "\n", "test_elements_total", "+=", "test_y", ".", "shape", "[", "0", "]", "\n", "test_loss_lst", ".", "append", "(", "test_loss", ")", "\n", "", "", "print", "(", "'test_true_total'", ",", "test_true_total", ",", "\n", "'test_elements_total'", ",", "test_elements_total", ")", "\n", "test_acc", "=", "test_true_total", "/", "(", "test_elements_total", "*", "1.0", ")", "\n", "print", "(", "'test loss mean'", ",", "np", ".", "mean", "(", "test_loss_lst", ")", ",", "'test acc'", ",", "test_acc", ",", "'pt'", ",", "pt", ")", "\n", "return", "test_acc", ",", "test_loss_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.Net.__init__": [[23, 46], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "src.fastfood.fastfood.FastFoodLayer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "src.wavelet_learning.wavelet_linear.WaveletLayer", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["    ", "def", "__init__", "(", "self", ",", "compression", ",", "wavelet", "=", "None", ",", "wave_dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "20", ",", "5", ",", "1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "20", ",", "64", ",", "5", ",", "1", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout2d", "(", "0.25", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout2d", "(", "0.5", ")", "\n", "self", ".", "wavelet", "=", "wavelet", "\n", "self", ".", "do_dropout", "=", "True", "\n", "if", "compression", "==", "'None'", ":", "\n", "            ", "self", ".", "fc1", "=", "torch", ".", "nn", ".", "Linear", "(", "4", "*", "4", "*", "64", ",", "500", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "500", ",", "10", ")", "\n", "", "elif", "compression", "==", "'Fastfood'", ":", "\n", "            ", "assert", "wavelet", "is", "None", "\n", "self", ".", "fc1", "=", "FastFoodLayer", "(", "1024", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "1024", ",", "10", ")", "\n", "self", ".", "do_dropout", "=", "False", "\n", "", "elif", "compression", "==", "'Wavelet'", ":", "\n", "            ", "assert", "wavelet", "is", "not", "None", ",", "'initial wavelet must be set.'", "\n", "self", ".", "fc1", "=", "WaveletLayer", "(", "init_wavelet", "=", "wavelet", ",", "scales", "=", "6", ",", "depth", "=", "1024", ",", "p_drop", "=", "wave_dropout", ")", "\n", "self", ".", "fc2", "=", "torch", ".", "nn", ".", "Linear", "(", "1024", ",", "10", ")", "\n", "self", ".", "do_dropout", "=", "False", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Compression type Unknown.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.Net.forward": [[47, 63], ["mnist_CNN_compression.Net.conv1", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "mnist_CNN_compression.Net.conv2", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "mnist_CNN_compression.Net.fc1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "mnist_CNN_compression.Net.fc2", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "mnist_CNN_compression.Net.dropout1", "mnist_CNN_compression.Net.dropout2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "# x = F.relu(x)", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "2", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "2", ")", "\n", "if", "self", ".", "do_dropout", ":", "\n", "            ", "x", "=", "self", ".", "dropout1", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "if", "self", ".", "do_dropout", ":", "\n", "            ", "x", "=", "self", ".", "dropout2", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.Net.wavelet_loss": [[64, 71], ["mnist_CNN_compression.Net.fc1.wavelet.alias_cancellation_loss", "mnist_CNN_compression.Net.fc1.wavelet.perfect_reconstruction_loss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.alias_cancellation_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.perfect_reconstruction_loss"], ["", "def", "wavelet_loss", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "wavelet", "is", "None", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.0", ")", ",", "torch", ".", "tensor", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "acl", ",", "_", ",", "_", "=", "self", ".", "fc1", ".", "wavelet", ".", "alias_cancellation_loss", "(", ")", "\n", "prl", ",", "_", ",", "_", "=", "self", ".", "fc1", ".", "wavelet", ".", "perfect_reconstruction_loss", "(", ")", "\n", "return", "acl", ",", "prl", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.train": [[73, 93], ["model.train", "enumerate", "optimizer.zero_grad", "model", "torch.nll_loss", "loss.backward", "optimizer.step", "data.to", "target.to", "model.wavelet_loss", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "print", "len", "F.nll_loss.item", "torch.tensor.item", "len", "len"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.backward", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.Net.wavelet_loss"], ["", "", "", "def", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "nll_loss", "=", "F", ".", "nll_loss", "(", "output", ",", "target", ")", "\n", "if", "args", ".", "compression", "==", "'Wavelet'", ":", "\n", "            ", "acl", ",", "prl", "=", "model", ".", "wavelet_loss", "(", ")", "\n", "wvl", "=", "acl", "+", "prl", "\n", "loss", "=", "nll_loss", "+", "wvl", "*", "args", ".", "wave_loss_weight", "\n", "", "else", ":", "\n", "            ", "wvl", "=", "torch", ".", "tensor", "(", "0.0", ")", "\n", "loss", "=", "nll_loss", "\n", "", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "batch_idx", "%", "args", ".", "log_interval", "==", "0", ":", "\n", "            ", "print", "(", "'Train Epoch: {} [{}/{} ({:.0f}%)], Loss: {:.6f}, wvl-Loss: {:.6f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", "*", "len", "(", "data", ")", ",", "len", "(", "train_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "batch_idx", "/", "len", "(", "train_loader", ")", ",", "nll_loss", ".", "item", "(", ")", ",", "wvl", ".", "item", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.test": [[95, 120], ["model.eval", "len", "model.wavelet_loss", "print", "test_writer.add_scalar", "test_writer.add_scalar", "test_writer.add_scalar", "test_writer.add_scalar", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "torch.nll_loss().item", "model.argmax", "output.argmax.eq().sum().item", "len", "len", "len", "data.to", "target.to", "len", "torch.nll_loss", "output.argmax.eq().sum", "output.argmax.eq", "target.view_as"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.Net.wavelet_loss"], ["", "", "", "def", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ",", "test_writer", ",", "epoch", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "test_loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "test_loss", "+=", "F", ".", "nll_loss", "(", "output", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "test_loss", "/=", "len", "(", "test_loader", ".", "dataset", ")", "\n", "acl", ",", "prl", "=", "model", ".", "wavelet_loss", "(", ")", "\n", "wvl_loss", "=", "acl", "+", "prl", "\n", "\n", "print", "(", "'\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "len", "(", "test_loader", ".", "dataset", ")", ",", "\n", "100.", "*", "correct", "/", "len", "(", "test_loader", ".", "dataset", ")", ")", ")", "\n", "\n", "test_writer", ".", "add_scalar", "(", "'test_correct'", ",", "correct", ",", "epoch", ")", "\n", "test_writer", ".", "add_scalar", "(", "'test_loss'", ",", "test_loss", ",", "epoch", ")", "\n", "test_writer", ".", "add_scalar", "(", "'test_acc'", ",", "100.", "*", "correct", "/", "len", "(", "test_loader", ".", "dataset", ")", ",", "epoch", ")", "\n", "test_writer", ".", "add_scalar", "(", "'wvl_loss'", ",", "wvl_loss", ",", "epoch", ")", "\n", "return", "wvl_loss", ",", "100.", "*", "correct", "/", "len", "(", "test_loader", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.main": [[122, 225], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torch.device", "torch.device", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "Net().to", "print", "torch.Adadelta", "torch.utils.tensorboard.writer.SummaryWriter", "torch.optim.lr_scheduler.StepLR", "mnist_CNN_compression.test", "test_wvl_lst.append", "test_acc_lst.append", "range", "print", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "collections.namedtuple", "collections.namedtuple.", "src.util.compute_parameter_total", "Net().to.parameters", "test_wvl_loss.item", "mnist_CNN_compression.train", "mnist_CNN_compression.test", "test_wvl_lst.append", "test_acc_lst.append", "torch.optim.lr_scheduler.StepLR.step", "torch.save", "torch.save", "torch.save", "torch.save", "src.util.compute_parameter_total", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.show", "mnist_CNN_compression.Net", "test_wvl_loss.item", "Net().to.state_dict", "Net().to.fc1.wavelet.dec_lo.detach().cpu().numpy", "Net().to.fc1.wavelet.dec_hi.detach().cpu().numpy", "Net().to.fc1.wavelet.rec_lo.detach().cpu().numpy", "Net().to.fc1.wavelet.rec_hi.detach().cpu().numpy", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "numpy.random.uniform", "Net().to.fc1.wavelet.dec_lo.detach().cpu", "Net().to.fc1.wavelet.dec_hi.detach().cpu", "Net().to.fc1.wavelet.rec_lo.detach().cpu", "Net().to.fc1.wavelet.rec_hi.detach().cpu", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "Net().to.fc1.wavelet.dec_lo.detach", "Net().to.fc1.wavelet.dec_hi.detach", "Net().to.fc1.wavelet.rec_lo.detach", "Net().to.fc1.wavelet.rec_hi.detach"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.test", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.src.util.compute_parameter_total", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.mnist_CNN_compression.test", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.src.util.compute_parameter_total"], ["", "def", "main", "(", ")", ":", "\n", "# Training settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch Network compression on MNIST'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch-size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for training (default: 64)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test-batch-size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "14", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'number of epochs to train (default: 14)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "metavar", "=", "'LR'", ",", "\n", "help", "=", "'learning rate (default: 1.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "metavar", "=", "'M'", ",", "\n", "help", "=", "'Learning rate step gamma (default: 0.7)'", ")", "\n", "parser", ".", "add_argument", "(", "'--no-cuda'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'disables CUDA training'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "metavar", "=", "'S'", ",", "\n", "help", "=", "'random seed (default: 1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--log-interval'", ",", "type", "=", "int", ",", "default", "=", "250", ",", "metavar", "=", "'N'", ",", "\n", "help", "=", "'how many batches to wait before logging training status'", ")", "\n", "parser", ".", "add_argument", "(", "'--save-model'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'For Saving the current Model'", ")", "\n", "parser", ".", "add_argument", "(", "'--compression'", ",", "type", "=", "str", ",", "default", "=", "'Wavelet'", ",", "\n", "help", "=", "'Choose the compression mode, None, Wavelet, Fastfood'", ")", "\n", "parser", ".", "add_argument", "(", "'--wave_loss_weight'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'Weight term of the wavelet loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--wave_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Wavelet layer dropout probability.'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "use_cuda", "=", "not", "args", ".", "no_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "use_cuda", "else", "\"cpu\"", ")", "\n", "\n", "kwargs", "=", "{", "'num_workers'", ":", "1", ",", "'pin_memory'", ":", "True", "}", "if", "use_cuda", "else", "{", "}", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "'../data'", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "MNIST", "(", "'../data'", ",", "train", "=", "False", ",", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "if", "args", ".", "compression", "==", "'Wavelet'", ":", "\n", "        ", "CustomWavelet", "=", "collections", ".", "namedtuple", "(", "'Wavelet'", ",", "[", "'dec_lo'", ",", "'dec_hi'", ",", "\n", "'rec_lo'", ",", "'rec_hi'", ",", "'name'", "]", ")", "\n", "# init_wavelet = CustomWavelet(", "\n", "#     dec_lo=[0, 0, 0.7071067811865476, 0.7071067811865476, 0, 0],", "\n", "#     dec_hi=[0, 0, -0.7071067811865476, 0.7071067811865476, 0, 0],", "\n", "#     rec_lo=[0, 0, 0.7071067811865476, 0.7071067811865476, 0, 0],", "\n", "#     rec_hi=[0, 0, 0.7071067811865476, -0.7071067811865476, 0, 0],", "\n", "#     name='customHaar')", "\n", "\n", "# random init", "\n", "init_wavelet", "=", "CustomWavelet", "(", "\n", "dec_lo", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "6", ")", ")", ",", "\n", "dec_hi", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "6", ")", ")", ",", "\n", "rec_lo", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "6", ")", ")", ",", "\n", "rec_hi", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "size", "=", "(", "6", ")", ")", ",", "\n", "name", "=", "'customHaar'", ")", "\n", "# init_wavelet = pywt.Wavelet('db6')", "\n", "", "else", ":", "\n", "        ", "init_wavelet", "=", "None", "\n", "\n", "", "model", "=", "Net", "(", "compression", "=", "args", ".", "compression", ",", "wavelet", "=", "init_wavelet", ",", "wave_dropout", "=", "args", ".", "wave_dropout", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "'Parameter total:'", ",", "compute_parameter_total", "(", "model", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adadelta", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ")", "\n", "writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "1", ",", "gamma", "=", "args", ".", "gamma", ")", "\n", "test_wvl_lst", "=", "[", "]", "\n", "test_acc_lst", "=", "[", "]", "\n", "test_wvl_loss", ",", "test_acc", "=", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ",", "writer", ",", "0", ")", "\n", "test_wvl_lst", ".", "append", "(", "test_wvl_loss", ".", "item", "(", ")", ")", "\n", "test_acc_lst", ".", "append", "(", "test_acc", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test_wvl_loss", ",", "test_acc", "=", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ",", "writer", ",", "epoch", ")", "\n", "test_wvl_lst", ".", "append", "(", "test_wvl_loss", ".", "item", "(", ")", ")", "\n", "test_acc_lst", ".", "append", "(", "test_acc", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "if", "args", ".", "save_model", ":", "\n", "        ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "\"mnist_cnn.pt\"", ")", "\n", "\n", "", "print", "(", "'Parameter total:'", ",", "compute_parameter_total", "(", "model", ")", ")", "\n", "\n", "if", "args", ".", "compression", "==", "'Wavelet'", ":", "\n", "        ", "plt", ".", "plot", "(", "model", ".", "fc1", ".", "wavelet", ".", "dec_lo", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "'-*'", ")", "\n", "plt", ".", "plot", "(", "model", ".", "fc1", ".", "wavelet", ".", "dec_hi", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "'-*'", ")", "\n", "plt", ".", "plot", "(", "model", ".", "fc1", ".", "wavelet", ".", "rec_lo", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "'-*'", ")", "\n", "plt", ".", "plot", "(", "model", ".", "fc1", ".", "wavelet", ".", "rec_hi", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "'-*'", ")", "\n", "plt", ".", "legend", "(", "[", "'H_0'", ",", "'H_1'", ",", "'F_0'", ",", "'F_1'", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", "print", "(", "'done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.EmbeddingRnnWrapper.__init__": [[92, 98], ["super().__init__", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cell", ",", "input_size", ",", "out_size", ")", ":", "\n", "        ", "super", "(", "EmbeddingRnnWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "out_size", "=", "out_size", "\n", "self", ".", "cell", "=", "cell", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "out_size", ",", "input_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.EmbeddingRnnWrapper.forward": [[99, 102], ["penn_RNN_compression.EmbeddingRnnWrapper.encoder", "penn_RNN_compression.EmbeddingRnnWrapper.cell"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "h", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder", "(", "x", ")", "\n", "return", "self", ".", "cell", "(", "emb", ",", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.EmbeddingRnnWrapper.get_wavelet_loss": [[103, 105], ["penn_RNN_compression.EmbeddingRnnWrapper.cell.get_wavelet_loss"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss"], ["", "def", "get_wavelet_loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cell", ".", "get_wavelet_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.run_rnn": [[119, 129], ["range", "torch.stack", "torch.stack", "cell", "y_cell_lst.append"], "function", ["None"], ["def", "run_rnn", "(", "cell", ",", "input", ")", ":", "\n", "    ", "y_cell_lst", "=", "[", "]", "\n", "h", "=", "None", "\n", "for", "t", "in", "range", "(", "input", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "# batch_major format [b,t,d]", "\n", "        ", "y", ",", "h", "=", "cell", "(", "input", "[", ":", ",", "t", "]", ",", "h", ")", "\n", "y_cell_lst", ".", "append", "(", "y", ")", "\n", "\n", "", "y", "=", "torch", ".", "stack", "(", "y_cell_lst", ",", "1", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.evaluate": [[131, 160], ["model.eval", "source.size", "torch.no_grad", "torch.no_grad", "enumerate", "range", "src.penn_treebank.char_utils.get_batch", "penn_RNN_compression.run_rnn", "output[].contiguous().view", "target[].contiguous().view", "criterion", "output[].contiguous().view.size", "torch.sum", "torch.sum", "output[].contiguous().view.size", "total_loss.item", "acc_sum.item", "output[].contiguous", "target[].contiguous", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.get_batch", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.run_rnn"], ["", "def", "evaluate", "(", "source", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "count", "=", "0", "\n", "acc_sum", "=", "0", "\n", "source_len", "=", "source", ".", "size", "(", "1", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", ",", "i", "in", "enumerate", "(", "range", "(", "0", ",", "source_len", "-", "1", ",", "args", ".", "validseqlen", ")", ")", ":", "\n", "            ", "if", "i", "+", "args", ".", "seq_len", "-", "args", ".", "validseqlen", ">=", "source_len", ":", "\n", "                ", "continue", "\n", "", "inp", ",", "target", "=", "get_batch", "(", "source", ",", "i", ",", "args", ")", "\n", "\n", "# output = model(inp)", "\n", "output", "=", "run_rnn", "(", "model", ",", "inp", ")", "\n", "\n", "eff_history", "=", "args", ".", "seq_len", "-", "args", ".", "validseqlen", "\n", "final_output", "=", "output", "[", ":", ",", "eff_history", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_characters", ")", "\n", "final_target", "=", "target", "[", ":", ",", "eff_history", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss", "=", "criterion", "(", "final_output", ",", "final_target", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "data", "*", "final_output", ".", "size", "(", "0", ")", "\n", "count", "+=", "final_output", ".", "size", "(", "0", ")", "\n", "\n", "# compute accuracy.", "\n", "acc_sum", "+=", "torch", ".", "sum", "(", "(", "torch", ".", "max", "(", "final_output", ",", "-", "1", ")", "[", "1", "]", "==", "final_target", ")", ".", "type", "(", "torch", ".", "float32", ")", ")", "\n", "\n", "", "val_loss", "=", "total_loss", ".", "item", "(", ")", "/", "count", "*", "1.0", "\n", "val_acc", "=", "acc_sum", ".", "item", "(", ")", "/", "count", "*", "1.0", "\n", "return", "val_loss", ",", "val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train": [[162, 215], ["model.train", "time.time", "source.size", "enumerate", "range", "src.penn_treebank.char_utils.get_batch", "optimizer.zero_grad", "penn_RNN_compression.run_rnn", "output[].contiguous().view", "target[].contiguous().view", "criterion", "loss.backward", "optimizer.step", "criterion.item", "torch.tensor.item", "model.get_wavelet_loss", "torch.tensor", "torch.tensor", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "losses.append", "wvl_losses.append", "print", "time.time", "len", "sum", "len", "output[].contiguous", "target[].contiguous", "model.parameters", "time.time", "sum", "int", "math.log"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.get_batch", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.run_rnn", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.backward", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss"], ["", "", "def", "train", "(", "epoch", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "total_wvl_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "losses", "=", "[", "]", "\n", "wvl_losses", "=", "[", "]", "\n", "source", "=", "train_data", "\n", "source_len", "=", "source", ".", "size", "(", "1", ")", "\n", "for", "batch_idx", ",", "i", "in", "enumerate", "(", "range", "(", "0", ",", "source_len", "-", "1", ",", "args", ".", "validseqlen", ")", ")", ":", "\n", "        ", "if", "i", "+", "args", ".", "seq_len", "-", "args", ".", "validseqlen", ">=", "source_len", ":", "\n", "            ", "continue", "\n", "", "inp", ",", "target", "=", "get_batch", "(", "source", ",", "i", ",", "args", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# output = model(inp)", "\n", "output", "=", "run_rnn", "(", "model", ",", "inp", ")", "\n", "\n", "eff_history", "=", "args", ".", "seq_len", "-", "args", ".", "validseqlen", "\n", "final_output", "=", "output", "[", ":", ",", "eff_history", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_characters", ")", "\n", "final_target", "=", "target", "[", ":", ",", "eff_history", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "criterion_loss", "=", "criterion", "(", "final_output", ",", "final_target", ")", "\n", "\n", "if", "args", ".", "cell", "==", "'WaveletGRU'", ":", "\n", "            ", "loss_wave", "=", "model", ".", "get_wavelet_loss", "(", ")", "\n", "loss", "=", "criterion_loss", "+", "loss_wave", "*", "args", ".", "wavelet_weight", "\n", "# print(loss_wave.item())", "\n", "", "else", ":", "\n", "            ", "loss_wave", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "loss", "=", "criterion_loss", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "args", ".", "clip", ">", "0", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "total_loss", "+=", "criterion_loss", ".", "item", "(", ")", "\n", "total_wvl_loss", "+=", "loss_wave", ".", "item", "(", ")", "\n", "\n", "if", "batch_idx", "%", "args", ".", "log_interval", "==", "0", "and", "batch_idx", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", "/", "args", ".", "log_interval", "\n", "cur_wvl_loss", "=", "total_wvl_loss", "/", "args", ".", "log_interval", "\n", "losses", ".", "append", "(", "cur_loss", ")", "\n", "wvl_losses", ".", "append", "(", "cur_wvl_loss", ")", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.5f} | ms/batch {:5.2f} | '", "\n", "'loss {:5.3f} | bpc {:5.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch_idx", ",", "int", "(", "(", "source_len", "-", "0.5", ")", "/", "args", ".", "validseqlen", ")", ",", "lr", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "return", "sum", "(", "losses", ")", "*", "1.0", "/", "len", "(", "losses", ")", ",", "sum", "(", "wvl_losses", ")", "/", "len", "(", "wvl_losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.main": [[217, 255], ["print", "range", "penn_RNN_compression.evaluate", "print", "print", "print", "print", "penn_RNN_compression.train", "print", "penn_RNN_compression.evaluate", "print", "print", "penn_RNN_compression.evaluate", "print", "print", "print", "all_losses.append", "max", "math.log", "math.log", "math.log", "math.log"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.evaluate", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.evaluate", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "lr", "\n", "print", "(", "\"Training for %d epochs...\"", "%", "args", ".", "epochs", ")", "\n", "all_losses", "=", "[", "]", "\n", "best_vloss", "=", "1e7", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "        ", "loss", ",", "wvl_loss", "=", "train", "(", "epoch", ")", "\n", "print", "(", "'| epoch {:3d} | loss {:5.3f} | bpc {:8.3f} | wvl-loss {:8.6f}'", ".", "format", "(", "\n", "epoch", ",", "loss", ",", "loss", "/", "math", ".", "log", "(", "2", ")", ",", "wvl_loss", ")", ")", "\n", "vloss", ",", "vacc", "=", "evaluate", "(", "val_data", ")", "\n", "print", "(", "'-'", "*", "89", ")", "\n", "print", "(", "'| End of epoch {:3d} | valid loss {:5.3f} | valid bpc {:8.3f}| valid acc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "vloss", ",", "vloss", "/", "math", ".", "log", "(", "2", ")", ",", "vacc", ")", ")", "\n", "\n", "test_loss", ",", "test_acc", "=", "evaluate", "(", "test_data", ")", "\n", "print", "(", "'='", "*", "89", ")", "\n", "print", "(", "'| End of epoch {:3d} | test loss {:5.3f} | test bpc {:8.3f}  | test acc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "test_loss", ",", "test_loss", "/", "math", ".", "log", "(", "2", ")", ",", "test_acc", ")", ")", "\n", "print", "(", "'='", "*", "89", ")", "\n", "\n", "if", "epoch", ">", "5", "and", "vloss", ">", "max", "(", "all_losses", "[", "-", "3", ":", "]", ")", ":", "\n", "            ", "lr", "=", "lr", "/", "2.", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "", "all_losses", ".", "append", "(", "vloss", ")", "\n", "\n", "# if vloss < best_vloss:", "\n", "#     print(\"Saving...\")", "\n", "#     save(model)", "\n", "#     best_vloss = vloss", "\n", "\n", "# Run on test data.", "\n", "", "test_loss", ",", "test_acc", "=", "evaluate", "(", "test_data", ")", "\n", "print", "(", "'='", "*", "89", ")", "\n", "print", "(", "'| End of training | test loss {:5.3f} | test bpc {:8.3f}'", ".", "format", "(", "\n", "test_loss", ",", "test_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "print", "(", "'='", "*", "89", ")", "\n", "print", "(", "'parameter total'", ",", "parameter_total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.adding_memory_RNN_compression.train_test_loop": [[19, 74], ["range", "loss_fun.detach().cpu().numpy", "optimizer.zero_grad", "cell.train", "cell.eval", "cell", "y_cell_lst.append", "numpy.prod().astype", "torch.stack", "loss_fun", "torch.sum().type().detach().cpu().numpy", "in_y_gt.type", "loss_fun", "torch.sum().type().detach().cpu().numpy", "cell.get_wavelet_loss", "cell.get_wavelet_loss.detach().cpu().numpy", "loss_full.backward", "optimizer.step", "print", "in_x[].type", "torch.max", "loss_fun.detach().cpu", "numpy.prod", "torch.sum().type().detach().cpu", "torch.sum().type().detach().cpu", "cell.get_wavelet_loss.detach().cpu", "loss_fun.detach", "torch.sum().type().detach", "torch.sum().type().detach", "cell.get_wavelet_loss.detach", "torch.sum().type", "torch.sum().type", "torch.sum", "torch.sum", "torch.abs"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.None.penn_RNN_compression.train", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.backward"], ["def", "train_test_loop", "(", "args", ",", "in_x", ",", "in_y_gt", ",", "iteration_no", ",", "cell", ",", "loss_fun", ",", "\n", "train", "=", "False", ",", "optimizer", "=", "None", ",", "\n", "baseline", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run the network on the adding or copy memory problems.\n    train: if true turns backpropagation on.\n    \"\"\"", "\n", "if", "train", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "cell", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "        ", "cell", ".", "eval", "(", ")", "\n", "\n", "", "time_steps", "=", "in_x", ".", "shape", "[", "1", "]", "\n", "# run the RNN", "\n", "y_cell_lst", "=", "[", "]", "\n", "h", "=", "None", "\n", "for", "t", "in", "range", "(", "time_steps", ")", ":", "\n", "# batch_major format [b,t,d]", "\n", "        ", "y", ",", "h", "=", "cell", "(", "in_x", "[", ":", ",", "t", ",", ":", "]", ".", "type", "(", "torch", ".", "float32", ")", ",", "h", ")", "\n", "y_cell_lst", ".", "append", "(", "y", ")", "\n", "\n", "", "if", "args", ".", "problem", "==", "'memory'", ":", "\n", "        ", "el", "=", "np", ".", "prod", "(", "in_y_gt", "[", ":", ",", "-", "10", ":", "]", ".", "shape", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "y_tensor", "=", "torch", ".", "stack", "(", "y_cell_lst", ",", "dim", "=", "-", "1", ")", "\n", "loss", "=", "loss_fun", "(", "y_tensor", ",", "in_y_gt", ")", "\n", "mem_res", "=", "torch", ".", "max", "(", "y_tensor", "[", ":", ",", ":", ",", "-", "10", ":", "]", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "acc_sum", "=", "torch", ".", "sum", "(", "mem_res", "==", "in_y_gt", "[", ":", ",", "-", "10", ":", "]", ")", ".", "type", "(", "torch", ".", "float32", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "acc", "=", "acc_sum", "/", "(", "el", "*", "1.0", ")", "\n", "", "else", ":", "\n", "# only the last output is interesting", "\n", "        ", "el", "=", "in_y_gt", ".", "shape", "[", "0", "]", "\n", "train_y_gt", "=", "in_y_gt", ".", "type", "(", "torch", ".", "float32", ")", "\n", "loss", "=", "loss_fun", "(", "y", ",", "train_y_gt", ")", "\n", "acc_sum", "=", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "y", "-", "train_y_gt", ")", "<", "0.05", ")", ".", "type", "(", "torch", ".", "float32", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "acc", "=", "acc_sum", "/", "(", "el", "*", "1.0", ")", "\n", "\n", "", "cpu_loss", "=", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# compute gradients", "\n", "if", "args", ".", "cell", "==", "'WaveletGRU'", ":", "\n", "        ", "loss_wave", "=", "cell", ".", "get_wavelet_loss", "(", ")", "\n", "loss_full", "=", "loss", "+", "loss_wave", "\n", "loss_wave_cpu", "=", "loss_wave", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "        ", "loss_wave_cpu", "=", "0", "\n", "loss_full", "=", "loss", "\n", "\n", "", "if", "train", ":", "\n", "        ", "loss_full", ".", "backward", "(", ")", "\n", "# apply gradients", "\n", "optimizer", ".", "step", "(", ")", "\n", "", "if", "iteration_no", "%", "50", "==", "0", ":", "\n", "        ", "print", "(", "'step'", ",", "iteration_no", ",", "'loss'", ",", "cpu_loss", ",", "'baseline:'", ",", "baseline", ",", "'acc'", ",", "acc", ",", "'wl'", ",", "\n", "loss_wave_cpu", ",", "'train'", ",", "train", ")", "\n", "", "return", "cpu_loss", ",", "acc_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.src.util.compute_parameter_total": [[7, 14], ["net.parameters", "print", "numpy.prod"], "function", ["None"], ["def", "compute_parameter_total", "(", "net", ")", ":", "\n", "    ", "total", "=", "0", "\n", "for", "p", "in", "net", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "p", ".", "requires_grad", ":", "\n", "            ", "print", "(", "p", ".", "shape", ")", "\n", "total", "+=", "np", ".", "prod", "(", "p", ".", "shape", ")", "\n", "", "", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.src.util.pd_to_string": [[16, 36], ["pd_var.copy.copy", "list", "pd_var.copy.keys", "type", "type", "type", "str"], "function", ["None"], ["", "def", "pd_to_string", "(", "pd_var", ")", "->", "str", ":", "\n", "    ", "'''\n    Convert a parameter dict to string\n    :param pd_var: The Parameter dictionary\n    :return: A string containg what was in the dict.\n    '''", "\n", "pd_var", "=", "pd_var", ".", "copy", "(", ")", "\n", "pd_var_str", "=", "''", "\n", "for", "key", "in", "list", "(", "pd_var", ".", "keys", "(", ")", ")", ":", "\n", "        ", "if", "type", "(", "pd_var", "[", "key", "]", ")", "is", "str", ":", "\n", "            ", "pd_var_str", "+=", "'_'", "+", "key", "+", "pd_var", "[", "key", "]", "\n", "", "elif", "type", "(", "pd_var", "[", "key", "]", ")", "is", "bool", ":", "\n", "            ", "pd_var_str", "+=", "'_'", "+", "key", "\n", "", "elif", "type", "(", "pd_var", "[", "key", "]", ")", "is", "pywt", ".", "Wavelet", ":", "\n", "            ", "pd_var_str", "+=", "'_'", "+", "pd_var", "[", "key", "]", ".", "name", "\n", "", "elif", "key", "==", "'init_wavelet'", ":", "\n", "            ", "pd_var_str", "+=", "'_'", "+", "pd_var", "[", "key", "]", ".", "name", "\n", "", "else", ":", "\n", "            ", "pd_var_str", "+=", "'_'", "+", "key", "+", "str", "(", "pd_var", "[", "key", "]", ")", "\n", "", "", "return", "pd_var_str", "\n", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.adding_memory.generate_data_adding": [[9, 37], ["numpy.asarray", "numpy.asarray", "numpy.asarray", "int", "range", "numpy.reshape", "numpy.zeros", "numpy.random.uniform", "numpy.random.randint", "int", "torch.from_numpy().permute", "torch.from_numpy", "int", "torch.from_numpy"], "function", ["None"], ["def", "generate_data_adding", "(", "time_steps", ",", "n_data", ")", ":", "\n", "    ", "\"\"\"\n    Generate data for the adding problem.\n    Source: https://github.com/amarshah/complex_RNN/blob/master/adding_problem.py\n    Params:\n        time_steps: The number of time steps we would like to consider.\n        n_data: the number of sequences we would like to consider.\n    returns:\n        x: [n_data, time_steps, 2] input array.\n        y: [n_data, 1] output array.\n    \"\"\"", "\n", "x", "=", "np", ".", "asarray", "(", "np", ".", "zeros", "(", "(", "time_steps", ",", "int", "(", "n_data", ")", ",", "2", ")", ")", ",", "\n", "dtype", "=", "np", ".", "float", ")", "\n", "# this should be low=-1!? According to hochreiter et al?!", "\n", "x", "[", ":", ",", ":", ",", "0", "]", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.", ",", "\n", "high", "=", "1.", ",", "\n", "size", "=", "(", "time_steps", ",", "n_data", ")", ")", ",", "\n", "dtype", "=", "np", ".", "float", ")", "\n", "inds", "=", "np", ".", "asarray", "(", "np", ".", "random", ".", "randint", "(", "time_steps", "/", "2", ",", "size", "=", "(", "n_data", ",", "2", ")", ")", ")", "\n", "inds", "[", ":", ",", "1", "]", "+=", "int", "(", "time_steps", "/", "2", ")", "\n", "\n", "for", "i", "in", "range", "(", "int", "(", "n_data", ")", ")", ":", "\n", "        ", "x", "[", "inds", "[", "i", ",", "0", "]", ",", "i", ",", "1", "]", "=", "1.0", "\n", "x", "[", "inds", "[", "i", ",", "1", "]", ",", "i", ",", "1", "]", "=", "1.0", "\n", "\n", "", "y", "=", "(", "x", "[", ":", ",", ":", ",", "0", "]", "*", "x", "[", ":", ",", ":", ",", "1", "]", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "y", "=", "np", ".", "reshape", "(", "y", ",", "(", "n_data", ",", "1", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ".", "permute", "(", "[", "1", ",", "0", ",", "2", "]", ")", ",", "torch", ".", "from_numpy", "(", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.adding_memory.generate_data_memory": [[39, 49], ["numpy.random.randint", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.concatenate().astype", "numpy.concatenate().astype", "numpy.ones", "torch.from_numpy", "torch.from_numpy", "numpy.concatenate", "numpy.concatenate"], "function", ["None"], ["", "def", "generate_data_memory", "(", "time_steps", ",", "n_data", ",", "n_sequence", "=", "10", ")", ":", "\n", "    ", "seq", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "high", "=", "9", ",", "size", "=", "(", "n_data", ",", "n_sequence", ")", ")", "\n", "zeros1", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "time_steps", "-", "1", ")", ")", "\n", "zeros2", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "time_steps", ")", ")", "\n", "marker", "=", "9", "*", "np", ".", "ones", "(", "(", "n_data", ",", "1", ")", ")", "\n", "zeros3", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "n_sequence", ")", ")", "\n", "\n", "x", "=", "np", ".", "concatenate", "(", "(", "seq", ",", "zeros1", ",", "marker", ",", "zeros3", ")", ",", "axis", "=", "1", ")", ".", "astype", "(", "'int32'", ")", "\n", "y", "=", "np", ".", "concatenate", "(", "(", "zeros3", ",", "zeros2", ",", "seq", ")", ",", "axis", "=", "1", ")", ".", "astype", "(", "'int32'", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ",", "torch", ".", "from_numpy", "(", "y", ")", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.cells.GRUCell.__init__": [[11, 29], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "out_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_input_size", "=", "input_size", "\n", "self", ".", "_hidden_size", "=", "hidden_size", "\n", "\n", "# update gate weights.", "\n", "self", ".", "Whz", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wxz", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ")", "\n", "\n", "# reset gate weights.", "\n", "self", ".", "Whr", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wxr", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ")", "\n", "\n", "# state candidate mapping", "\n", "self", ".", "Whh", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "Wxh", "=", "torch", ".", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "W_proj", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_size", ",", "out_size", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.cells.GRUCell.forward": [[30, 39], ["torch.sigmoid", "torch.sigmoid", "torch.tanh", "cells.GRUCell.W_proj", "torch.zeros", "x.size", "cells.GRUCell.Whz", "cells.GRUCell.Wxz", "cells.GRUCell.Whr", "cells.GRUCell.Wxr", "cells.GRUCell.Whh", "cells.GRUCell.Wxh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "h", "=", "None", ")", ":", "\n", "        ", "if", "h", "is", "None", ":", "\n", "            ", "h", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "_hidden_size", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "", "z", "=", "torch", ".", "sigmoid", "(", "self", ".", "Whz", "(", "h", ")", "+", "self", ".", "Wxz", "(", "x", ")", ")", "\n", "r", "=", "torch", ".", "sigmoid", "(", "self", ".", "Whr", "(", "h", ")", "+", "self", ".", "Wxr", "(", "x", ")", ")", "\n", "hc", "=", "torch", ".", "tanh", "(", "self", ".", "Whh", "(", "r", "*", "h", ")", "+", "self", ".", "Wxh", "(", "x", ")", ")", "\n", "hn", "=", "(", "1", "-", "z", ")", "*", "h", "+", "z", "*", "hc", "\n", "y", "=", "self", ".", "W_proj", "(", "hn", ")", "\n", "return", "y", ",", "hn", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.cells.WaveletGRU.__init__": [[44, 79], ["pywt.Wavelet", "cells.GRUCell.__init__", "print", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "src.wavelet_learning.wavelet_linear.WaveletLayer", "print", "src.wavelet_learning.wavelet_linear.WaveletLayer", "src.wavelet_learning.wavelet_linear.WaveletLayer", "src.wavelet_learning.wavelet_linear.WaveletLayer"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "out_size", ",", "init_wavelet", "=", "pywt", ".", "Wavelet", "(", "'db6'", ")", ",", "mode", "=", "'full'", ",", "\n", "p_drop", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "out_size", ")", "\n", "self", ".", "init_wavelet", "=", "init_wavelet", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "drop_prob", "=", "p_drop", "\n", "scales", "=", "4", "\n", "\n", "if", "mode", "==", "'gates'", ":", "\n", "            ", "print", "(", "'gates compression'", ")", "\n", "self", ".", "Whz", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whr", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "elif", "mode", "==", "'reset'", ":", "\n", "            ", "print", "(", "'reset compression'", ")", "\n", "self", ".", "Whr", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "elif", "mode", "==", "'update'", ":", "\n", "            ", "print", "(", "'update compression'", ")", "\n", "self", ".", "Whz", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "elif", "mode", "==", "'state'", ":", "\n", "            ", "print", "(", "'state compression'", ")", "\n", "self", ".", "Whh", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "elif", "mode", "==", "'state_reset'", ":", "\n", "            ", "print", "(", "'state+reset gate compression'", ")", "\n", "self", ".", "Whh", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whr", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "elif", "mode", "==", "'state_update'", ":", "\n", "            ", "print", "(", "'state+update gate compression'", ")", "\n", "self", ".", "Whh", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whz", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'full compression'", ")", "\n", "self", ".", "Whz", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whr", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whh", "=", "WaveletLayer", "(", "hidden_size", ",", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "print", "(", "'Creating a Wavelet GRU, do not forget to add the wavelet-loss.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.cells.WaveletGRU.get_wavelet_loss": [[80, 95], ["cells.WaveletGRU.Whz.get_wavelet_loss", "cells.WaveletGRU.Whr.get_wavelet_loss", "cells.WaveletGRU.Whh.get_wavelet_loss", "cells.WaveletGRU.Whr.get_wavelet_loss", "cells.WaveletGRU.Whz.get_wavelet_loss", "cells.WaveletGRU.Whh.get_wavelet_loss", "cells.WaveletGRU.Whr.get_wavelet_loss", "cells.WaveletGRU.Whh.get_wavelet_loss", "cells.WaveletGRU.Whz.get_wavelet_loss", "cells.WaveletGRU.Whr.get_wavelet_loss", "cells.WaveletGRU.Whh.get_wavelet_loss", "cells.WaveletGRU.Whz.get_wavelet_loss"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss"], ["", "def", "get_wavelet_loss", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'gates'", ":", "\n", "            ", "return", "self", ".", "Whz", ".", "get_wavelet_loss", "(", ")", "+", "self", ".", "Whr", ".", "get_wavelet_loss", "(", ")", "\n", "", "elif", "self", ".", "mode", "==", "'state'", ":", "\n", "            ", "return", "self", ".", "Whh", ".", "get_wavelet_loss", "(", ")", "\n", "", "elif", "self", ".", "mode", "==", "'reset'", ":", "\n", "            ", "return", "self", ".", "Whr", ".", "get_wavelet_loss", "(", ")", "\n", "", "elif", "self", ".", "mode", "==", "'update'", ":", "\n", "            ", "return", "self", ".", "Whz", ".", "get_wavelet_loss", "(", ")", "\n", "", "elif", "self", ".", "mode", "==", "'state_reset'", ":", "\n", "            ", "return", "self", ".", "Whh", ".", "get_wavelet_loss", "(", ")", "+", "self", ".", "Whr", ".", "get_wavelet_loss", "(", ")", "\n", "", "elif", "self", ".", "mode", "==", "'state_update'", ":", "\n", "            ", "return", "self", ".", "Whh", ".", "get_wavelet_loss", "(", ")", "+", "self", ".", "Whz", ".", "get_wavelet_loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "Whh", ".", "get_wavelet_loss", "(", ")", "+", "self", ".", "Whz", ".", "get_wavelet_loss", "(", ")", "+", "self", ".", "Whr", ".", "get_wavelet_loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.cells.FastFoodGRU.__init__": [[100, 106], ["cells.GRUCell.__init__", "src.fastfood.fastfood.FastFoodLayer", "src.fastfood.fastfood.FastFoodLayer", "src.fastfood.fastfood.FastFoodLayer"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "out_size", ",", "p_drop", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "out_size", ")", "\n", "self", ".", "drop_prob", "=", "p_drop", "\n", "self", ".", "Whz", "=", "FastFoodLayer", "(", "hidden_size", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whr", "=", "FastFoodLayer", "(", "hidden_size", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "self", ".", "Whh", "=", "FastFoodLayer", "(", "hidden_size", ",", "p_drop", "=", "self", ".", "drop_prob", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.MackeyGenerator.__init__": [[72, 80], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "tmax", ",", "delta_t", ",", "block_size", "=", "None", ",", "\n", "restore_and_plot", "=", "False", ",", "cuda", "=", "True", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "tmax", "=", "tmax", "\n", "self", ".", "delta_t", "=", "delta_t", "\n", "self", ".", "block_size", "=", "block_size", "\n", "self", ".", "restore_and_plot", "=", "restore_and_plot", "\n", "self", ".", "cuda", "=", "cuda", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.MackeyGenerator.__call__": [[81, 93], ["mackey_glass.generate_mackey", "torch.unsqueeze", "mackey_glass.blockify", "blockify.cuda"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.generate_mackey", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.blockify"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "data_nd", "=", "generate_mackey", "(", "tmax", "=", "self", ".", "tmax", ",", "delta_t", "=", "self", ".", "delta_t", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "rnd", "=", "not", "self", ".", "restore_and_plot", ")", "\n", "data_nd", "=", "torch", ".", "unsqueeze", "(", "data_nd", ",", "-", "1", ")", "\n", "if", "self", ".", "block_size", ":", "\n", "            ", "data_nd", "=", "blockify", "(", "data_nd", ",", "self", ".", "block_size", ")", "\n", "# print('data_nd_shape', data_nd.shape)", "\n", "", "if", "self", ".", "cuda", ":", "\n", "            ", "return", "data_nd", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "data_nd", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.generate_mackey": [[5, 38], ["int", "torch.ones", "torch.stack", "range", "int", "torch.empty().uniform_", "torch.unsqueeze", "torch.cat", "torch.empty", "torch.pow", "mackey_glass.generate_mackey.mackey"], "function", ["None"], ["def", "generate_mackey", "(", "batch_size", "=", "100", ",", "tmax", "=", "200", ",", "delta_t", "=", "1", ",", "rnd", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Generate synthetic training data using the Mackey system\n    of equations (http://www.scholarpedia.org/article/Mackey-Glass_equation):\n    dx/dt = beta*(x'/(1+x'))\n    The system is simulated using a forward euler scheme\n    (https://en.wikipedia.org/wiki/Euler_method).\n\n    Returns:\n        spikes: A Tensor of shape [batch_size, time, 1],\n    \"\"\"", "\n", "steps", "=", "int", "(", "tmax", "/", "delta_t", ")", "+", "200", "\n", "\n", "# multi-dimensional data.", "\n", "def", "mackey", "(", "x", ",", "tau", ",", "gamma", "=", "0.1", ",", "beta", "=", "0.2", ",", "n", "=", "10", ")", ":", "\n", "        ", "return", "beta", "*", "x", "[", ":", ",", "-", "tau", "]", "/", "(", "1", "+", "torch", ".", "pow", "(", "x", "[", ":", ",", "-", "tau", "]", ",", "n", ")", ")", "-", "gamma", "*", "x", "[", ":", ",", "-", "1", "]", "\n", "\n", "", "tau", "=", "int", "(", "17", "*", "(", "1", "/", "delta_t", ")", ")", "\n", "x0", "=", "torch", ".", "ones", "(", "[", "tau", "]", ")", "\n", "x0", "=", "torch", ".", "stack", "(", "batch_size", "*", "[", "x0", "]", ",", "dim", "=", "0", ")", "\n", "if", "rnd", ":", "\n", "# print('Mackey initial state is random.')", "\n", "        ", "x0", "+=", "torch", ".", "empty", "(", "x0", ".", "shape", ")", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "", "else", ":", "\n", "        ", "x0", "+=", "[", "-", "0.01", ",", "0.02", "]", "\n", "\n", "", "x", "=", "x0", "\n", "# forward_euler", "\n", "for", "_", "in", "range", "(", "steps", ")", ":", "\n", "        ", "res", "=", "torch", ".", "unsqueeze", "(", "x", "[", ":", ",", "-", "1", "]", "+", "delta_t", "*", "mackey", "(", "x", ",", "tau", ")", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "res", "]", ",", "-", "1", ")", "\n", "", "discard", "=", "200", "+", "tau", "\n", "return", "x", "[", ":", ",", "discard", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.mackey_glass.blockify": [[40, 55], ["range", "torch.cat().transpose", "torch.mean", "block_signal.append", "torch.ones", "torch.cat"], "function", ["None"], ["", "def", "blockify", "(", "data", ",", "block_length", ")", ":", "\n", "    ", "'''\n        Blockify the input data series by replacing\n        blocks in the output with its mean.\n    '''", "\n", "batch_size", "=", "data", ".", "shape", "[", "0", "]", "\n", "steps", "=", "data", ".", "shape", "[", "-", "1", "]", "//", "block_length", "\n", "block_signal", "=", "[", "]", "\n", "for", "block_no", "in", "range", "(", "steps", ")", ":", "\n", "        ", "start", "=", "block_no", "*", "block_length", "\n", "stop", "=", "(", "block_no", "+", "1", ")", "*", "block_length", "\n", "block_mean", "=", "torch", ".", "mean", "(", "data", "[", ":", ",", "start", ":", "stop", "]", ",", "dim", "=", "-", "1", ")", "\n", "block", "=", "block_mean", "*", "torch", ".", "ones", "(", "[", "batch_size", ",", "block_length", "]", ")", "\n", "block_signal", ".", "append", "(", "block", ")", "\n", "", "return", "torch", ".", "cat", "(", "block_signal", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.Chomp1d.__init__": [[13, 16], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["    ", "def", "__init__", "(", "self", ",", "chomp_size", ")", ":", "\n", "        ", "super", "(", "Chomp1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chomp_size", "=", "chomp_size", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.Chomp1d.forward": [[17, 19], ["x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", ":", ",", ":", ",", ":", "-", "self", ".", "chomp_size", "]", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TemporalBlock.__init__": [[22, 41], ["torch.nn.Module.__init__", "torch.nn.utils.weight_norm", "model.Chomp1d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.utils.weight_norm", "model.Chomp1d", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Sequential", "torch.nn.ReLU", "model.TemporalBlock.init_weights", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TCN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "n_inputs", ",", "n_outputs", ",", "kernel_size", ",", "stride", ",", "dilation", ",", "padding", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "TemporalBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "weight_norm", "(", "nn", ".", "Conv1d", "(", "n_inputs", ",", "n_outputs", ",", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ")", ")", "\n", "self", ".", "chomp1", "=", "Chomp1d", "(", "padding", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "conv2", "=", "weight_norm", "(", "nn", ".", "Conv1d", "(", "n_outputs", ",", "n_outputs", ",", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ")", ")", "\n", "self", ".", "chomp2", "=", "Chomp1d", "(", "padding", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "self", ".", "conv1", ",", "self", ".", "chomp1", ",", "self", ".", "relu1", ",", "self", ".", "dropout1", ",", "\n", "self", ".", "conv2", ",", "self", ".", "chomp2", ",", "self", ".", "relu2", ",", "self", ".", "dropout2", ")", "\n", "self", ".", "downsample", "=", "nn", ".", "Conv1d", "(", "n_inputs", ",", "n_outputs", ",", "1", ")", "if", "n_inputs", "!=", "n_outputs", "else", "None", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TemporalBlock.init_weights": [[42, 47], ["model.TemporalBlock.conv1.weight.data.normal_", "model.TemporalBlock.conv2.weight.data.normal_", "model.TemporalBlock.downsample.weight.data.normal_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "self", ".", "conv1", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "self", ".", "conv2", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "self", ".", "downsample", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TemporalBlock.forward": [[48, 52], ["model.TemporalBlock.net", "model.TemporalBlock.relu", "model.TemporalBlock.downsample"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "net", "(", "x", ")", "\n", "res", "=", "x", "if", "self", ".", "downsample", "is", "None", "else", "self", ".", "downsample", "(", "x", ")", "\n", "return", "self", ".", "relu", "(", "out", "+", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TemporalConvNet.__init__": [[55, 67], ["torch.nn.Module.__init__", "len", "range", "torch.nn.Sequential", "model.TemporalBlock"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_inputs", ",", "num_channels", ",", "kernel_size", "=", "2", ",", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "TemporalConvNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "[", "]", "\n", "num_levels", "=", "len", "(", "num_channels", ")", "\n", "for", "i", "in", "range", "(", "num_levels", ")", ":", "\n", "            ", "dilation_size", "=", "2", "**", "i", "\n", "in_channels", "=", "num_inputs", "if", "i", "==", "0", "else", "num_channels", "[", "i", "-", "1", "]", "\n", "out_channels", "=", "num_channels", "[", "i", "]", "\n", "layers", "+=", "[", "TemporalBlock", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "dilation", "=", "dilation_size", ",", "\n", "padding", "=", "(", "kernel_size", "-", "1", ")", "*", "dilation_size", ",", "dropout", "=", "dropout", ")", "]", "\n", "\n", "", "self", ".", "network", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TemporalConvNet.forward": [[68, 70], ["model.TemporalConvNet.network"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "network", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TCN.__init__": [[73, 81], ["torch.nn.Module.__init__", "torch.nn.Embedding", "model.TemporalConvNet", "torch.nn.Linear", "torch.nn.Dropout", "model.TCN.init_weights"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TCN.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "output_size", ",", "num_channels", ",", "kernel_size", "=", "2", ",", "dropout", "=", "0.2", ",", "emb_dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "TCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "output_size", ",", "input_size", ")", "\n", "self", ".", "tcn", "=", "TemporalConvNet", "(", "input_size", ",", "num_channels", ",", "kernel_size", "=", "kernel_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ")", "\n", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "emb_dropout", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TCN.init_weights": [[82, 87], ["model.TCN.encoder.weight.data.uniform_", "model.TCN.decoder.bias.data.fill_", "model.TCN.decoder.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.model.TCN.forward": [[88, 94], ["model.TCN.drop", "model.TCN.tcn", "model.TCN.decoder", "model.TCN.contiguous", "model.TCN.encoder", "model.TCN.transpose", "model.TCN.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# input has dimension (N, L_in), and emb has dimension (N, L_in, C_in)", "\n", "        ", "emb", "=", "self", ".", "drop", "(", "self", ".", "encoder", "(", "x", ")", ")", "\n", "y", "=", "self", ".", "tcn", "(", "emb", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "o", "=", "self", ".", "decoder", "(", "y", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "return", "o", ".", "contiguous", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.sequential_mnist.data_generator": [[8, 40], ["torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["def", "data_generator", "(", "root", ",", "batch_size", ")", ":", "\n", "    ", "if", "\"cifar\"", "in", "root", ":", "\n", "        ", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "\n", "train_set", "=", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_set", "=", "datasets", ".", "CIFAR10", "(", "root", "=", "'./data'", ",", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "2", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_set", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "2", ")", "\n", "classes", "=", "(", "'plane'", ",", "'car'", ",", "'bird'", ",", "'cat'", ",", "\n", "'deer'", ",", "'dog'", ",", "'frog'", ",", "'horse'", ",", "'ship'", ",", "'truck'", ")", "\n", "", "else", ":", "\n", "        ", "train_set", "=", "datasets", ".", "MNIST", "(", "root", "=", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", "\n", "test_set", "=", "datasets", ".", "MNIST", "(", "root", "=", "root", ",", "train", "=", "False", ",", "download", "=", "True", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "]", ")", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_set", ",", "batch_size", "=", "batch_size", ")", "\n", "", "return", "train_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.RNN_compression.sequential_mnist.count_parameters": [[42, 44], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.__init__": [[12, 34], ["super().__init__", "learn_wave.Wave1D.__init__.to_tensor"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_wavelet", ",", "scales", "=", "1", ",", "\n", "mode", "=", "'zero'", ",", "fixed", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "def", "to_tensor", "(", "filt_lst", ":", "list", ")", ":", "\n", "                ", "tensor", "=", "torch", ".", "tensor", "(", "np", ".", "array", "(", "filt_lst", ")", ".", "ravel", "(", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ")", "\n", "return", "torch", ".", "nn", ".", "Parameter", "(", "tensor", ",", "requires_grad", "=", "not", "fixed", ")", "\n", "\n", "# self.init_wavelet = init_wavelet", "\n", "", "self", ".", "dec_lo", "=", "to_tensor", "(", "init_wavelet", ".", "dec_lo", ")", "\n", "self", ".", "dec_hi", "=", "to_tensor", "(", "init_wavelet", ".", "dec_hi", ")", "\n", "self", ".", "rec_lo", "=", "to_tensor", "(", "init_wavelet", ".", "rec_lo", ")", "\n", "self", ".", "rec_hi", "=", "to_tensor", "(", "init_wavelet", ".", "rec_hi", ")", "\n", "\n", "# all filter shapes must be the same.", "\n", "assert", "self", ".", "dec_lo", ".", "shape", "==", "self", ".", "dec_hi", ".", "shape", ",", "'filters must have the same sizes'", "\n", "assert", "self", ".", "rec_lo", ".", "shape", "==", "self", ".", "rec_hi", ".", "shape", ",", "'filters must have the same sizes'", "\n", "assert", "self", ".", "dec_lo", ".", "shape", "==", "self", ".", "rec_lo", ".", "shape", ",", "'filters must have the same sizes'", "\n", "\n", "self", ".", "scales", "=", "scales", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.coeff_len": [[35, 37], ["pywt.dwt_coeff_len"], "methods", ["None"], ["", "def", "coeff_len", "(", "self", ",", "input_length", ")", ":", "\n", "            ", "return", "pywt", ".", "dwt_coeff_len", "(", "input_length", ",", "self", ".", "dec_lo", ".", "shape", "[", "0", "]", ",", "self", ".", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.check_sym": [[38, 48], ["range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_sym", "(", "in_filter", ")", "->", "bool", ":", "\n", "# 1d in_filterer arrays.", "\n", "        ", "assert", "len", "(", "in_filter", ".", "shape", ")", "==", "1", "\n", "length", "=", "in_filter", ".", "shape", "[", "0", "]", "\n", "sym", "=", "True", "\n", "for", "i", "in", "range", "(", "length", "//", "2", ")", ":", "\n", "            ", "if", "in_filter", "[", "i", "]", "!=", "in_filter", "[", "length", "-", "1", "]", ":", "\n", "                ", "sym", "=", "False", "\n", "", "", "return", "sym", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.check_anti_sym": [[49, 58], ["range", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "check_anti_sym", "(", "in_filter", ")", "->", "bool", ":", "\n", "        ", "assert", "len", "(", "in_filter", ".", "shape", ")", "==", "1", "\n", "length", "=", "in_filter", ".", "shape", "[", "0", "]", "\n", "anti_sym", "=", "True", "\n", "for", "i", "in", "range", "(", "length", "//", "2", ")", ":", "\n", "            ", "if", "in_filter", "[", "i", "]", "!=", "-", "in_filter", "[", "length", "-", "1", "]", ":", "\n", "                ", "anti_sym", "=", "False", "\n", "", "", "return", "anti_sym", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.alias_cancellation_loss": [[59, 77], ["torch.tensor", "torch.tensor", "torch.sum", "torch.tensor", "torch.sum", "torch.pow", "torch.pow", "range", "range"], "methods", ["None"], ["", "def", "alias_cancellation_loss", "(", "self", ")", "->", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "'''\n        Strang+Nguyen 105: F0(z) = H1(-z); F1(z) = -H0(-z)\n        Alternating sign convention from 0 to N see strang overview on the back of the cover.\n        '''", "\n", "m1", "=", "torch", ".", "tensor", "(", "[", "-", "1", "]", ",", "device", "=", "self", ".", "dec_hi", ".", "device", ",", "dtype", "=", "self", ".", "dec_hi", ".", "dtype", ")", "\n", "length", "=", "self", ".", "rec_lo", ".", "shape", "[", "0", "]", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "torch", ".", "pow", "(", "m1", ",", "n", ")", "for", "n", "in", "range", "(", "length", ")", "]", "[", ":", ":", "-", "1", "]", ",", "\n", "device", "=", "self", ".", "dec_hi", ".", "device", ",", "dtype", "=", "self", ".", "dec_hi", ".", "dtype", ")", "\n", "err1", "=", "self", ".", "rec_lo", "-", "mask", "*", "self", ".", "dec_hi", "\n", "err1s", "=", "torch", ".", "sum", "(", "err1", "*", "err1", ")", "\n", "\n", "length", "=", "self", ".", "rec_hi", ".", "shape", "[", "0", "]", "\n", "mask", "=", "torch", ".", "tensor", "(", "[", "torch", ".", "pow", "(", "m1", ",", "n", ")", "for", "n", "in", "range", "(", "length", ")", "]", "[", ":", ":", "-", "1", "]", ",", "\n", "device", "=", "self", ".", "dec_lo", ".", "device", ",", "dtype", "=", "self", ".", "dec_lo", ".", "dtype", ")", "\n", "err2", "=", "self", ".", "rec_hi", "-", "m1", "*", "mask", "*", "self", ".", "dec_lo", "\n", "err2s", "=", "torch", ".", "sum", "(", "err2", "*", "err2", ")", "\n", "return", "err1s", "+", "err2s", ",", "err1", ",", "err2", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.perfect_reconstruction_loss": [[78, 113], ["torch.nn.functional.conv1d", "torch.nn.functional.conv1d", "torch.zeros", "learn_wave.Wave1D.dec_lo.unsqueeze().unsqueeze", "torch.flip().unsqueeze().unsqueeze", "learn_wave.Wave1D.dec_hi.unsqueeze().unsqueeze", "torch.flip().unsqueeze().unsqueeze", "torch.sum", "learn_wave.Wave1D.dec_lo.unsqueeze", "torch.flip().unsqueeze", "learn_wave.Wave1D.dec_hi.unsqueeze", "torch.flip().unsqueeze", "torch.flip", "torch.flip"], "methods", ["None"], ["", "def", "perfect_reconstruction_loss", "(", "self", ")", "->", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "'''\n        Strang 107:\n        Assuming alias cancellation holds:\n        P(z) = F(z)H(z)\n        Product filter P(z) + P(-z) = 2.\n        However since alias cancellation is implemented as soft constraint:\n        P_0 + P_1 = 2\n\n        Somehow numpy and torch implement convolution differently.\n        For some reason the machine learning people call cross-correlation convolution.\n        https://discuss.pytorch.org/t/numpy-convolve-and-conv1d-in-pytorch/12172\n        Therefore for true convolution one element needs to be flipped.\n        '''", "\n", "# polynomial multiplication is convolution, compute p(z):", "\n", "pad", "=", "self", ".", "dec_lo", ".", "shape", "[", "0", "]", "-", "1", "\n", "p_lo", "=", "torch", ".", "nn", ".", "functional", ".", "conv1d", "(", "\n", "self", ".", "dec_lo", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "torch", ".", "flip", "(", "self", ".", "rec_lo", ",", "[", "-", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "padding", "=", "pad", ")", "\n", "\n", "pad", "=", "self", ".", "dec_hi", ".", "shape", "[", "0", "]", "-", "1", "\n", "p_hi", "=", "torch", ".", "nn", ".", "functional", ".", "conv1d", "(", "\n", "self", ".", "dec_hi", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "torch", ".", "flip", "(", "self", ".", "rec_hi", ",", "[", "-", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "padding", "=", "pad", ")", "\n", "\n", "p_test", "=", "p_lo", "+", "p_hi", "\n", "two_at_power_zero", "=", "torch", ".", "zeros", "(", "p_test", ".", "shape", ",", "device", "=", "p_test", ".", "device", ",", "\n", "dtype", "=", "p_test", ".", "dtype", ")", "\n", "# numpy comparison for debugging.", "\n", "# np.convolve(self.init_wavelet.filter_bank[0], self.init_wavelet.filter_bank[2])", "\n", "# np.convolve(self.init_wavelet.filter_bank[1], self.init_wavelet.filter_bank[3])", "\n", "two_at_power_zero", "[", "...", ",", "p_test", ".", "shape", "[", "-", "1", "]", "//", "2", "]", "=", "2", "\n", "return", "torch", ".", "sum", "(", "(", "p_test", "-", "two_at_power_zero", ")", "*", "(", "p_test", "-", "two_at_power_zero", ")", ")", ",", "p_test", ",", "two_at_power_zero", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.compute_coeff_no": [[114, 125], ["range", "lengths.append", "lengths.append", "pywt.dwt_coeff_len"], "methods", ["None"], ["", "def", "compute_coeff_no", "(", "self", ",", "init_length", ")", ":", "\n", "        ", "\"\"\"\n        Compute the number of resulting wavelet coefficients.\n        @param init_length: length of the input signal vector.\n        \"\"\"", "\n", "lengths", "=", "[", "init_length", "]", "\n", "for", "J", "in", "range", "(", "self", ".", "scales", ")", ":", "\n", "            ", "lengths", ".", "append", "(", "pywt", ".", "dwt_coeff_len", "(", "\n", "lengths", "[", "-", "1", "]", ",", "self", ".", "dec_lo", ".", "shape", "[", "-", "1", "]", ",", "self", ".", "mode", ")", ")", "\n", "", "lengths", ".", "append", "(", "lengths", "[", "-", "1", "]", ")", "\n", "return", "lengths", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.analysis": [[126, 145], ["torch.flip", "torch.flip", "range", "yh.append", "src.wavelet_learning.lowlevel.afb1d", "torch.split", "yh.append"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d"], ["", "def", "analysis", "(", "self", ",", "x", ",", "mode", "=", "'zero'", ")", ":", "\n", "        ", "\"\"\" Computes the forward fwt\n        Args:\n            x (torch.tensor): 4-d input tensor\n            mode (str, optional): Padding type. Defaults to 'zero'.\n        Returns:\n            list: The wavelet coefficients.\n        \"\"\"", "\n", "yh", "=", "[", "]", "\n", "lo", "=", "x", "\n", "# flip filters", "\n", "flip_dec_lo", "=", "torch", ".", "flip", "(", "self", ".", "dec_lo", ",", "[", "-", "1", "]", ")", "\n", "flip_dec_hi", "=", "torch", ".", "flip", "(", "self", ".", "dec_hi", ",", "[", "-", "1", "]", ")", "\n", "for", "s", "in", "range", "(", "self", ".", "scales", ")", ":", "\n", "            ", "lohi", "=", "afb1d", "(", "lo", ",", "flip_dec_lo", ",", "flip_dec_hi", ",", "mode", "=", "self", ".", "mode", ",", "dim", "=", "-", "1", ")", "\n", "lo", ",", "hi", "=", "torch", ".", "split", "(", "lohi", ",", "split_size_or_sections", "=", "[", "1", ",", "1", "]", ",", "dim", "=", "1", ")", "\n", "yh", ".", "append", "(", "hi", ")", "\n", "", "yh", ".", "append", "(", "lo", ")", "\n", "return", "yh", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.reconstruction": [[146, 158], ["src.wavelet_learning.lowlevel.sfb1d"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d"], ["", "def", "reconstruction", "(", "self", ",", "X", ")", ":", "\n", "        ", "X_inv", "=", "X", "[", ":", ":", "-", "1", "]", "\n", "lo", "=", "X_inv", "[", "0", "]", "\n", "\n", "for", "hi", "in", "X_inv", "[", "1", ":", "]", ":", "\n", "# 'Unpad' added dimensions", "\n", "            ", "if", "lo", ".", "shape", "[", "-", "2", "]", ">", "hi", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "lo", "=", "lo", "[", "...", ",", ":", "-", "1", ",", ":", "]", "\n", "", "if", "lo", ".", "shape", "[", "-", "1", "]", ">", "hi", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "lo", "=", "lo", "[", "...", ",", ":", "-", "1", "]", "\n", "", "lo", "=", "sfb1d", "(", "lo", ",", "hi", ",", "self", ".", "rec_lo", ",", "self", ".", "rec_hi", ",", "mode", "=", "self", ".", "mode", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "lo", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.add_wavelet_summary": [[159, 186], ["matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "tensorboard_writer.add_figure", "matplotlib.close", "learn_wave.Wave1D.alias_cancellation_loss", "learn_wave.Wave1D.perfect_reconstruction_loss", "tensorboard_writer.add_scalar", "tensorboard_writer.add_scalar", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "tensorboard_writer.add_figure", "matplotlib.close", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "tensorboard_writer.add_figure", "matplotlib.close", "learn_wave.Wave1D.dec_lo.detach().cpu().numpy", "learn_wave.Wave1D.dec_hi.detach().cpu().numpy", "learn_wave.Wave1D.rec_lo.detach().cpu().numpy", "learn_wave.Wave1D.rec_hi.detach().cpu().numpy", "prl.detach().cpu().numpy", "acl.detach().cpu().numpy", "err1.detach().cpu().numpy", "err2.detach().cpu().numpy", "p_test.squeeze().detach().cpu().numpy", "numpy.abs", "learn_wave.Wave1D.dec_lo.detach().cpu", "learn_wave.Wave1D.dec_hi.detach().cpu", "learn_wave.Wave1D.rec_lo.detach().cpu", "learn_wave.Wave1D.rec_hi.detach().cpu", "prl.detach().cpu", "acl.detach().cpu", "err1.detach().cpu", "err2.detach().cpu", "p_test.squeeze().detach().cpu", "learn_wave.Wave1D.dec_lo.detach", "learn_wave.Wave1D.dec_hi.detach", "learn_wave.Wave1D.rec_lo.detach", "learn_wave.Wave1D.rec_hi.detach", "prl.detach", "acl.detach", "err1.detach", "err2.detach", "p_test.squeeze().detach", "p_test.squeeze"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.alias_cancellation_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.perfect_reconstruction_loss"], ["", "def", "add_wavelet_summary", "(", "self", ",", "name", ",", "tensorboard_writer", ",", "step", ")", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "self", ".", "dec_lo", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "plot", "(", "self", ".", "dec_hi", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "plot", "(", "self", ".", "rec_lo", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "plot", "(", "self", ".", "rec_hi", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "legend", "(", "[", "'dec_lo,'", ",", "'dec_hi'", ",", "'rec_lo'", ",", "'rec_hi'", "]", ")", "\n", "tensorboard_writer", ".", "add_figure", "(", "name", "+", "'/wavelet/filters'", ",", "fig", ",", "step", ",", "close", "=", "True", ")", "\n", "plt", ".", "close", "(", ")", "\n", "acl", ",", "err1", ",", "err2", "=", "self", ".", "alias_cancellation_loss", "(", ")", "\n", "prl", ",", "p_test", ",", "two_at_power_zero", "=", "self", ".", "perfect_reconstruction_loss", "(", ")", "\n", "tensorboard_writer", ".", "add_scalar", "(", "name", "+", "'/wavelet/prl'", ",", "prl", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "step", ")", "\n", "tensorboard_writer", ".", "add_scalar", "(", "name", "+", "'/wavelet/acl'", ",", "acl", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "step", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "err1", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "plot", "(", "err2", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "legend", "(", "[", "'e1,'", ",", "'e2'", "]", ")", "\n", "tensorboard_writer", ".", "add_figure", "(", "name", "+", "'/wavelet/filters-acl'", ",", "fig", ",", "step", ",", "close", "=", "True", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "p_test", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "plot", "(", "np", ".", "abs", "(", "(", "p_test", "-", "two_at_power_zero", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "plt", ".", "legend", "(", "[", "'p_test,'", ",", "'err'", "]", ")", "\n", "tensorboard_writer", ".", "add_figure", "(", "name", "+", "'/wavelet/filters-prl'", ",", "fig", ",", "step", ",", "close", "=", "True", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.__init__": [[16, 38], ["super().__init__", "print", "src.wavelet_learning.learn_wave.Wave1D", "range", "wavelet_linear.WaveletLayer.coefficient_len_lst.append", "numpy.sum", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.random.permutation", "torch.nn.parameter.Parameter", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "wavelet_linear.WaveletLayer.coefficient_len_lst.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.eye", "torch.from_numpy", "wavelet_linear.WaveletLayer.wavelet.coeff_len", "numpy.ones", "numpy.ones", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.coeff_len"], ["def", "__init__", "(", "self", ",", "depth", ",", "init_wavelet", ",", "scales", ",", "p_drop", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "print", "(", "'wavelet dropout:'", ",", "p_drop", ")", "\n", "self", ".", "scales", "=", "scales", "\n", "self", ".", "wavelet", "=", "Wave1D", "(", "init_wavelet", "=", "init_wavelet", ",", "scales", "=", "scales", ")", "\n", "self", ".", "coefficient_len_lst", "=", "[", "depth", "]", "\n", "for", "_", "in", "range", "(", "scales", ")", ":", "\n", "            ", "self", ".", "coefficient_len_lst", ".", "append", "(", "self", ".", "wavelet", ".", "coeff_len", "(", "self", ".", "coefficient_len_lst", "[", "-", "1", "]", ")", ")", "\n", "", "self", ".", "coefficient_len_lst", "=", "self", ".", "coefficient_len_lst", "[", "1", ":", "]", "\n", "self", ".", "coefficient_len_lst", ".", "append", "(", "self", ".", "coefficient_len_lst", "[", "-", "1", "]", ")", "\n", "\n", "wave_depth", "=", "np", ".", "sum", "(", "self", ".", "coefficient_len_lst", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "diag_vec_s", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "depth", ",", "np", ".", "float32", ")", ")", ")", "\n", "self", ".", "diag_vec_g", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "wave_depth", ",", "np", ".", "float32", ")", ")", ")", "\n", "self", ".", "diag_vec_b", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "np", ".", "ones", "(", "depth", ",", "np", ".", "float32", ")", ")", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "eye", "(", "wave_depth", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "self", ".", "perm", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "perm", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "self", ".", "drop_s", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "self", ".", "drop_g", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "self", ".", "drop_b", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.mul_s": [[39, 41], ["torch.mm", "wavelet_linear.WaveletLayer.drop_s", "torch.diag"], "methods", ["None"], ["", "def", "mul_s", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_s", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.mul_g": [[42, 44], ["torch.mm", "wavelet_linear.WaveletLayer.drop_g", "torch.diag"], "methods", ["None"], ["", "def", "mul_g", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_g", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_g", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.mul_b": [[45, 47], ["torch.mm", "wavelet_linear.WaveletLayer.drop_b", "torch.diag"], "methods", ["None"], ["", "def", "mul_b", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_b", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_b", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.mul_p": [[48, 50], ["torch.mm"], "methods", ["None"], ["", "def", "mul_p", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "perm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.wavelet_analysis": [[51, 63], ["wavelet_linear.WaveletLayer.wavelet.analysis", "torch.cat", "x.unsqueeze().unsqueeze", "c.squeeze().squeeze", "x.unsqueeze", "c.squeeze"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.analysis"], ["", "def", "wavelet_analysis", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Compute a 1d-analysis transform.\n        Args:\n            x (torch.tensor): 2d input tensor\n        Returns:\n            [torch.tensor]: 2d output tensor.\n        \"\"\"", "\n", "c_lst", "=", "self", ".", "wavelet", ".", "analysis", "(", "x", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "shape_lst", "=", "[", "c_el", ".", "shape", "[", "-", "1", "]", "for", "c_el", "in", "c_lst", "]", "\n", "c_tensor", "=", "torch", ".", "cat", "(", "[", "c", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", "for", "c", "in", "c_lst", "]", ",", "-", "1", ")", "\n", "assert", "shape_lst", "==", "self", ".", "coefficient_len_lst", ",", "'Wavelet shape assumptions false. This is a bug.'", "\n", "return", "c_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.wavelet_reconstruction": [[64, 80], ["range", "wavelet_linear.WaveletLayer.wavelet.reconstruction", "wavelet_linear.WaveletLayer.squeeze().squeeze", "coeff_lst.append", "x[].unsqueeze().unsqueeze", "wavelet_linear.WaveletLayer.squeeze", "x[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.reconstruction"], ["", "def", "wavelet_reconstruction", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Reconstruction from a tensor input.\n        Args:\n            x (torch.tensor): Analysis coefficient tensor.\n        Returns:\n            torch.tensor: Input reconstruction.\n        \"\"\"", "\n", "coeff_lst", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "s", "in", "range", "(", "self", ".", "scales", "+", "1", ")", ":", "\n", "            ", "stop", "=", "start", "+", "self", ".", "coefficient_len_lst", "[", "s", "]", "\n", "coeff_lst", ".", "append", "(", "x", "[", "...", ",", "start", ":", "stop", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "start", "=", "self", ".", "coefficient_len_lst", "[", "s", "]", "\n", "# turn into list", "\n", "", "y", "=", "self", ".", "wavelet", ".", "reconstruction", "(", "coeff_lst", ")", "\n", "return", "y", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.forward": [[81, 97], ["wavelet_linear.WaveletLayer.mul_b", "wavelet_linear.WaveletLayer.wavelet_analysis", "wavelet_linear.WaveletLayer.mul_p", "wavelet_linear.WaveletLayer.mul_g", "wavelet_linear.WaveletLayer.wavelet_reconstruction", "wavelet_linear.WaveletLayer.mul_s"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_b", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.wavelet_analysis", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_p", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_g", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.wavelet_reconstruction", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_s"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Evaluate the wavelet layer.\n        Args:\n            x (torch.tensor): The layer input.\n        Returns:\n            torch.tensor: Layer output.\n        \"\"\"", "\n", "# test = self.wavelet_analysis(x)", "\n", "step1", "=", "self", ".", "mul_b", "(", "x", ")", "\n", "step2", "=", "self", ".", "wavelet_analysis", "(", "step1", ")", "\n", "step3", "=", "self", ".", "mul_p", "(", "step2", ")", "\n", "step4", "=", "self", ".", "mul_g", "(", "step3", ")", "\n", "step5", "=", "self", ".", "wavelet_reconstruction", "(", "step4", ")", "\n", "step6", "=", "self", ".", "mul_s", "(", "step5", ")", "\n", "\n", "return", "step6", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.extra_repr": [[98, 100], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'depth={}'", ".", "format", "(", "self", ".", "depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.wavelet_linear.WaveletLayer.get_wavelet_loss": [[101, 111], ["wavelet_linear.WaveletLayer.wavelet.perfect_reconstruction_loss", "wavelet_linear.WaveletLayer.wavelet.alias_cancellation_loss"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.perfect_reconstruction_loss", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.learn_wave.Wave1D.alias_cancellation_loss"], ["", "def", "get_wavelet_loss", "(", "self", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\" Returns the wavelet loss for the wavelet in the layer.\n            This value must be added to the cost for the wavelet learning to\n            work.\n        Returns:\n            torch.tensor: The wavelet loss scalar.\n        \"\"\"", "\n", "prl", ",", "_", ",", "_", "=", "self", ".", "wavelet", ".", "perfect_reconstruction_loss", "(", ")", "\n", "acl", ",", "_", ",", "_", "=", "self", ".", "wavelet", ".", "alias_cancellation_loss", "(", ")", "\n", "return", "prl", "+", "acl", "\n", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.DWTForward.__init__": [[22, 45], ["torch.Module.__init__", "isinstance", "isinstance", "pywt.Wavelet.prep_filt_afb2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "pywt.Wavelet", "len", "len"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d"], ["def", "__init__", "(", "self", ",", "J", "=", "1", ",", "wave", "=", "'db1'", ",", "mode", "=", "'zero'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "wave", ",", "str", ")", ":", "\n", "            ", "wave", "=", "pywt", ".", "Wavelet", "(", "wave", ")", "\n", "", "if", "isinstance", "(", "wave", ",", "pywt", ".", "Wavelet", ")", ":", "\n", "            ", "h0_col", ",", "h1_col", "=", "wave", ".", "dec_lo", ",", "wave", ".", "dec_hi", "\n", "h0_row", ",", "h1_row", "=", "h0_col", ",", "h1_col", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "wave", ")", "==", "2", ":", "\n", "                ", "h0_col", ",", "h1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "h0_row", ",", "h1_row", "=", "h0_col", ",", "h1_col", "\n", "", "elif", "len", "(", "wave", ")", "==", "4", ":", "\n", "                ", "h0_col", ",", "h1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "h0_row", ",", "h1_row", "=", "wave", "[", "2", "]", ",", "wave", "[", "3", "]", "\n", "\n", "# Prepare the filters", "\n", "", "", "filts", "=", "lowlevel", ".", "prep_filt_afb2d", "(", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", ")", "\n", "self", ".", "h0_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "0", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h1_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h0_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "2", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h1_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "3", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "J", "=", "J", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.DWTForward.forward": [[46, 77], ["wave.mode_to_int", "range", "wave.AFB2D.apply", "yh.append"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mode_to_int"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Forward pass of the DWT.\n\n        Args:\n            x (tensor): Input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n\n        Returns:\n            (yl, yh)\n                tuple of lowpass (yl) and bandpass (yh)\n                coefficients. yh is a list of length J with the first entry\n                being the finest scale coefficients. yl has shape\n                :math:`(N, C_{in}, H_{in}', W_{in}')` and yh has shape\n                :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. The new\n                dimension in yh iterates over the LH, HL and HH coefficients.\n\n        Note:\n            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n            downsampled shapes of the DWT pyramid.\n        \"\"\"", "\n", "yh", "=", "[", "]", "\n", "ll", "=", "x", "\n", "mode", "=", "lowlevel", ".", "mode_to_int", "(", "self", ".", "mode", ")", "\n", "\n", "# Do a multilevel transform", "\n", "for", "j", "in", "range", "(", "self", ".", "J", ")", ":", "\n", "# Do 1 level of the transform", "\n", "            ", "ll", ",", "high", "=", "lowlevel", ".", "AFB2D", ".", "apply", "(", "\n", "ll", ",", "self", ".", "h0_col", ",", "self", ".", "h1_col", ",", "self", ".", "h0_row", ",", "self", ".", "h1_row", ",", "mode", ")", "\n", "yh", ".", "append", "(", "high", ")", "\n", "\n", "", "return", "ll", ",", "yh", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.DWTInverse.__init__": [[87, 108], ["torch.Module.__init__", "isinstance", "isinstance", "pywt.Wavelet.prep_filt_sfb2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "pywt.Wavelet", "len", "len"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d"], ["def", "__init__", "(", "self", ",", "wave", "=", "'db1'", ",", "mode", "=", "'zero'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "wave", ",", "str", ")", ":", "\n", "            ", "wave", "=", "pywt", ".", "Wavelet", "(", "wave", ")", "\n", "", "if", "isinstance", "(", "wave", ",", "pywt", ".", "Wavelet", ")", ":", "\n", "            ", "g0_col", ",", "g1_col", "=", "wave", ".", "rec_lo", ",", "wave", ".", "rec_hi", "\n", "g0_row", ",", "g1_row", "=", "g0_col", ",", "g1_col", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "wave", ")", "==", "2", ":", "\n", "                ", "g0_col", ",", "g1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "g0_row", ",", "g1_row", "=", "g0_col", ",", "g1_col", "\n", "", "elif", "len", "(", "wave", ")", "==", "4", ":", "\n", "                ", "g0_col", ",", "g1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "g0_row", ",", "g1_row", "=", "wave", "[", "2", "]", ",", "wave", "[", "3", "]", "\n", "# Prepare the filters", "\n", "", "", "filts", "=", "lowlevel", ".", "prep_filt_sfb2d", "(", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", ")", "\n", "self", ".", "g0_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "0", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g1_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g0_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "2", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g1_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "3", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.DWTInverse.forward": [[109, 147], ["wave.mode_to_int", "wave.SFB2D.apply", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mode_to_int"], ["", "def", "forward", "(", "self", ",", "coeffs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            coeffs (yl, yh): tuple of lowpass and bandpass coefficients, where:\n              yl is a lowpass tensor of shape :math:`(N, C_{in}, H_{in}',\n              W_{in}')` and yh is a list of bandpass tensors of shape\n              :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. I.e. should match\n              the format returned by DWTForward\n\n        Returns:\n            Reconstructed input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n\n        Note:\n            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n            downsampled shapes of the DWT pyramid.\n\n        Note:\n            Can have None for any of the highpass scales and will treat the\n            values as zeros (not in an efficient way though).\n        \"\"\"", "\n", "yl", ",", "yh", "=", "coeffs", "\n", "ll", "=", "yl", "\n", "mode", "=", "lowlevel", ".", "mode_to_int", "(", "self", ".", "mode", ")", "\n", "\n", "# Do a multilevel inverse transform", "\n", "for", "h", "in", "yh", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "h", "is", "None", ":", "\n", "                ", "h", "=", "torch", ".", "zeros", "(", "ll", ".", "shape", "[", "0", "]", ",", "ll", ".", "shape", "[", "1", "]", ",", "3", ",", "ll", ".", "shape", "[", "-", "2", "]", ",", "\n", "ll", ".", "shape", "[", "-", "1", "]", ",", "device", "=", "ll", ".", "device", ")", "\n", "\n", "# 'Unpad' added dimensions", "\n", "", "if", "ll", ".", "shape", "[", "-", "2", "]", ">", "h", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "ll", "=", "ll", "[", "...", ",", ":", "-", "1", ",", ":", "]", "\n", "", "if", "ll", ".", "shape", "[", "-", "1", "]", ">", "h", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "ll", "=", "ll", "[", "...", ",", ":", "-", "1", "]", "\n", "", "ll", "=", "lowlevel", ".", "SFB2D", ".", "apply", "(", "\n", "ll", ",", "h", ",", "self", ".", "g0_col", ",", "self", ".", "g1_col", ",", "self", ".", "g0_row", ",", "self", ".", "g1_row", ",", "mode", ")", "\n", "", "return", "ll", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.SWTForward.__init__": [[163, 187], ["torch.Module.__init__", "isinstance", "isinstance", "pywt.Wavelet.prep_filt_afb2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "pywt.Wavelet", "len", "len"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d"], ["def", "__init__", "(", "self", ",", "J", "=", "1", ",", "wave", "=", "'db1'", ",", "mode", "=", "'periodization'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "wave", ",", "str", ")", ":", "\n", "            ", "wave", "=", "pywt", ".", "Wavelet", "(", "wave", ")", "\n", "", "if", "isinstance", "(", "wave", ",", "pywt", ".", "Wavelet", ")", ":", "\n", "            ", "h0_col", ",", "h1_col", "=", "wave", ".", "dec_lo", ",", "wave", ".", "dec_hi", "\n", "h0_row", ",", "h1_row", "=", "h0_col", ",", "h1_col", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "wave", ")", "==", "2", ":", "\n", "                ", "h0_col", ",", "h1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "h0_row", ",", "h1_row", "=", "h0_col", ",", "h1_col", "\n", "", "elif", "len", "(", "wave", ")", "==", "4", ":", "\n", "                ", "h0_col", ",", "h1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "h0_row", ",", "h1_row", "=", "wave", "[", "2", "]", ",", "wave", "[", "3", "]", "\n", "\n", "# Prepare the filters", "\n", "", "", "filts", "=", "lowlevel", ".", "prep_filt_afb2d", "(", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", ")", "\n", "self", ".", "h0_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "0", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h1_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h0_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "2", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "h1_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "3", "]", ",", "requires_grad", "=", "False", ")", "\n", "\n", "self", ".", "J", "=", "J", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.transform2d.SWTForward.forward": [[188, 211], ["range", "wave.afb2d_atrous", "coeffs.append"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb2d_atrous"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Forward pass of the SWT.\n\n        Args:\n            x (tensor): Input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n\n        Returns:\n            List of coefficients for each scale. Each coefficient has\n            shape :math:`(N, C_{in}, 4, H_{in}, W_{in})` where the extra\n            dimension stores the 4 subbands for each scale. The ordering in\n            these 4 coefficients is: (A, H, V, D) or (ll, lh, hl, hh).\n        \"\"\"", "\n", "ll", "=", "x", "\n", "coeffs", "=", "[", "]", "\n", "# Do a multilevel transform", "\n", "filts", "=", "(", "self", ".", "h0_col", ",", "self", ".", "h1_col", ",", "self", ".", "h0_row", ",", "self", ".", "h1_row", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "J", ")", ":", "\n", "# Do 1 level of the transform", "\n", "            ", "y", "=", "lowlevel", ".", "afb2d_atrous", "(", "ll", ",", "filts", ",", "self", ".", "mode", ",", "2", "**", "j", ")", "\n", "coeffs", ".", "append", "(", "y", ")", "\n", "ll", "=", "y", "[", ":", ",", ":", ",", "0", "]", "\n", "\n", "", "return", "coeffs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.SWTInverse.__init__": [[133, 160], ["nn.Module.__init__", "isinstance", "isinstance", "pywt.Wavelet", "lowlevel.prep_filt_sfb2d", "nn.Parameter", "nn.Parameter", "nn.Parameter", "nn.Parameter", "lowlevel.prep_filt_sfb2d_nonsep", "nn.Parameter", "len", "len"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d_nonsep"], ["def", "__init__", "(", "self", ",", "wave", "=", "'db1'", ",", "mode", "=", "'zero'", ",", "separable", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "wave", ",", "str", ")", ":", "\n", "            ", "wave", "=", "pywt", ".", "Wavelet", "(", "wave", ")", "\n", "", "if", "isinstance", "(", "wave", ",", "pywt", ".", "Wavelet", ")", ":", "\n", "            ", "g0_col", ",", "g1_col", "=", "wave", ".", "rec_lo", ",", "wave", ".", "rec_hi", "\n", "g0_row", ",", "g1_row", "=", "g0_col", ",", "g1_col", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "wave", ")", "==", "2", ":", "\n", "                ", "g0_col", ",", "g1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "g0_row", ",", "g1_row", "=", "g0_col", ",", "g1_col", "\n", "", "elif", "len", "(", "wave", ")", "==", "4", ":", "\n", "                ", "g0_col", ",", "g1_col", "=", "wave", "[", "0", "]", ",", "wave", "[", "1", "]", "\n", "g0_row", ",", "g1_row", "=", "wave", "[", "2", "]", ",", "wave", "[", "3", "]", "\n", "# Prepare the filters", "\n", "", "", "if", "separable", ":", "\n", "            ", "filts", "=", "lowlevel", ".", "prep_filt_sfb2d", "(", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", ")", "\n", "self", ".", "g0_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "0", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g1_col", "=", "nn", ".", "Parameter", "(", "filts", "[", "1", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g0_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "2", "]", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "g1_row", "=", "nn", ".", "Parameter", "(", "filts", "[", "3", "]", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "filts", "=", "lowlevel", ".", "prep_filt_sfb2d_nonsep", "(", "\n", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", ")", "\n", "self", ".", "h", "=", "nn", ".", "Parameter", "(", "filts", ",", "requires_grad", "=", "False", ")", "\n", "", "self", ".", "mode", "=", "mode", "\n", "self", ".", "separable", "=", "separable", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.SWTInverse.forward": [[161, 205], ["torch.zeros", "torch.unbind", "lowlevel.sfb2d", "torch.cat", "lowlevel.sfb2d_nonsep"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb2d_nonsep"], ["", "def", "forward", "(", "self", ",", "coeffs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            coeffs (yl, yh): tuple of lowpass and bandpass coefficients, where:\n              yl is a lowpass tensor of shape :math:`(N, C_{in}, H_{in}',\n              W_{in}')` and yh is a list of bandpass tensors of shape\n              :math:`list(N, C_{in}, 3, H_{in}'', W_{in}'')`. I.e. should match\n              the format returned by DWTForward\n\n        Returns:\n            Reconstructed input of shape :math:`(N, C_{in}, H_{in}, W_{in})`\n\n        Note:\n            :math:`H_{in}', W_{in}', H_{in}'', W_{in}''` denote the correctly\n            downsampled shapes of the DWT pyramid.\n\n        Note:\n            Can have None for any of the highpass scales and will treat the\n            values as zeros (not in an efficient way though).\n        \"\"\"", "\n", "yl", ",", "yh", "=", "coeffs", "\n", "ll", "=", "yl", "\n", "\n", "# Do a multilevel inverse transform", "\n", "for", "h", "in", "yh", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "h", "is", "None", ":", "\n", "                ", "h", "=", "torch", ".", "zeros", "(", "ll", ".", "shape", "[", "0", "]", ",", "ll", ".", "shape", "[", "1", "]", ",", "3", ",", "ll", ".", "shape", "[", "-", "2", "]", ",", "\n", "ll", ".", "shape", "[", "-", "1", "]", ",", "device", "=", "ll", ".", "device", ")", "\n", "\n", "# 'Unpad' added dimensions", "\n", "", "if", "ll", ".", "shape", "[", "-", "2", "]", ">", "h", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "ll", "=", "ll", "[", "...", ",", ":", "-", "1", ",", ":", "]", "\n", "", "if", "ll", ".", "shape", "[", "-", "1", "]", ">", "h", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "ll", "=", "ll", "[", "...", ",", ":", "-", "1", "]", "\n", "\n", "# Do the synthesis filter banks", "\n", "", "if", "self", ".", "separable", ":", "\n", "                ", "lh", ",", "hl", ",", "hh", "=", "torch", ".", "unbind", "(", "h", ",", "dim", "=", "2", ")", "\n", "filts", "=", "(", "self", ".", "g0_col", ",", "self", ".", "g1_col", ",", "self", ".", "g0_row", ",", "self", ".", "g1_row", ")", "\n", "ll", "=", "lowlevel", ".", "sfb2d", "(", "ll", ",", "lh", ",", "hl", ",", "hh", ",", "filts", ",", "mode", "=", "self", ".", "mode", ")", "\n", "", "else", ":", "\n", "                ", "c", "=", "torch", ".", "cat", "(", "(", "ll", "[", ":", ",", ":", ",", "None", "]", ",", "h", ")", ",", "dim", "=", "2", ")", "\n", "ll", "=", "lowlevel", ".", "sfb2d_nonsep", "(", "c", ",", "self", ".", "h", ",", "mode", "=", "self", ".", "mode", ")", "\n", "", "", "return", "ll", "\n", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.sfb1d_atrous": [[2, 77], ["g0.reshape.numel", "torch.cat", "torch.cat", "mypad", "mypad", "isinstance", "torch.tensor", "isinstance", "torch.tensor", "tuple", "g0.reshape.reshape", "tuple", "g1.reshape.reshape", "F.conv_transpose2d", "F.conv_transpose2d", "np.copy", "np.copy", "np.array().ravel", "np.array().ravel", "np.array", "np.array"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad"], ["def", "sfb1d_atrous", "(", "lo", ",", "hi", ",", "g0", ",", "g1", ",", "mode", "=", "'periodization'", ",", "dim", "=", "-", "1", ",", "dilation", "=", "1", ",", "\n", "pad1", "=", "None", ",", "pad", "=", "None", ")", ":", "\n", "    ", "\"\"\" 1D synthesis filter bank of an image tensor with no upsampling. Used for\n    the stationary wavelet transform.\n    \"\"\"", "\n", "C", "=", "lo", ".", "shape", "[", "1", "]", "\n", "d", "=", "dim", "%", "4", "\n", "# If g0, g1 are not tensors, make them. If they are, then assume that they", "\n", "# are in the right order", "\n", "if", "not", "isinstance", "(", "g0", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "g0", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "g0", ")", ".", "ravel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "lo", ".", "device", ")", "\n", "", "if", "not", "isinstance", "(", "g1", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "g1", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "g1", ")", ".", "ravel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "lo", ".", "device", ")", "\n", "", "L", "=", "g0", ".", "numel", "(", ")", "\n", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "shape", "[", "d", "]", "=", "L", "\n", "# If g aren't in the right shape, make them so", "\n", "if", "g0", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "g0", "=", "g0", ".", "reshape", "(", "*", "shape", ")", "\n", "", "if", "g1", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "g1", "=", "g1", ".", "reshape", "(", "*", "shape", ")", "\n", "", "g0", "=", "torch", ".", "cat", "(", "[", "g0", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "g1", "=", "torch", ".", "cat", "(", "[", "g1", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "\n", "# Calculate the padding size.", "\n", "# With dilation, zeros are inserted between the filter taps but not after.", "\n", "# that means a filter that is [a b c d] becomes [a 0 b 0 c 0 d].", "\n", "centre", "=", "L", "/", "2", "\n", "fsz", "=", "(", "L", "-", "1", ")", "*", "dilation", "+", "1", "\n", "newcentre", "=", "fsz", "/", "2", "\n", "before", "=", "newcentre", "-", "dilation", "*", "centre", "\n", "\n", "# When conv_transpose2d is done, a filter with k taps expands an input with", "\n", "# N samples to be N + k - 1 samples. The 'padding' is really the opposite of", "\n", "# that, and is how many samples on the edges you want to cut out.", "\n", "# In addition to this, we want the input to be extended before convolving.", "\n", "# This means the final output size without the padding option will be", "\n", "#   N + k - 1 + k - 1", "\n", "# The final thing to worry about is making sure that the output is centred.", "\n", "short_offset", "=", "dilation", "-", "1", "\n", "centre_offset", "=", "fsz", "%", "2", "\n", "a", "=", "fsz", "//", "2", "\n", "b", "=", "fsz", "//", "2", "+", "(", "fsz", "+", "1", ")", "%", "2", "\n", "#  a = 0", "\n", "#  b = 0", "\n", "pad", "=", "(", "0", ",", "0", ",", "a", ",", "b", ")", "if", "d", "==", "2", "else", "(", "a", ",", "b", ",", "0", ",", "0", ")", "\n", "lo", "=", "mypad", "(", "lo", ",", "pad", "=", "pad", ",", "mode", "=", "mode", ")", "\n", "hi", "=", "mypad", "(", "hi", ",", "pad", "=", "pad", ",", "mode", "=", "mode", ")", "\n", "unpad", "=", "(", "fsz", "-", "1", ",", "0", ")", "if", "d", "==", "2", "else", "(", "0", ",", "fsz", "-", "1", ")", "\n", "unpad", "=", "(", "0", ",", "0", ")", "\n", "y", "=", "F", ".", "conv_transpose2d", "(", "lo", ",", "g0", ",", "padding", "=", "unpad", ",", "groups", "=", "C", ",", "dilation", "=", "dilation", ")", "+", "F", ".", "conv_transpose2d", "(", "hi", ",", "g1", ",", "padding", "=", "unpad", ",", "groups", "=", "C", ",", "dilation", "=", "dilation", ")", "\n", "#  pad = (L-1, 0) if d == 2 else (0, L-1)", "\n", "#  y = F.conv_transpose2d(lo, g0, padding=pad, groups=C, dilation=dilation) + \\", "\n", "#  F.conv_transpose2d(hi, g1, padding=pad, groups=C, dilation=dilation)", "\n", "#", "\n", "#", "\n", "# Calculate the pad size", "\n", "#  L2 = (L * dilation)//2", "\n", "#  #  pad = (0, 0, L2, L2+dilation) if d == 2 else (L2, L2+dilation, 0, 0)", "\n", "#  a = dilation*2", "\n", "#  b = dilation*(L-2)", "\n", "#  if pad1 is None:", "\n", "#  pad1 = (0, 0, a, b) if d == 2 else (a, b, 0, 0)", "\n", "#  print(pad1)", "\n", "#  lo = mypad(lo, pad=pad1, mode=mode)", "\n", "#  hi = mypad(hi, pad=pad1, mode=mode)", "\n", "#  if pad is None:", "\n", "#  p = (a + b + (L - 1)*dilation)//2", "\n", "#  pad = (p, 0) if d == 2 else (0, p)", "\n", "#  print(pad)", "\n", "\n", "return", "y", "/", "(", "2", "*", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.sfb2d_atrous": [[79, 124], ["swt_inverse.sfb1d_atrous", "swt_inverse.sfb1d_atrous", "swt_inverse.sfb1d_atrous", "len", "isinstance", "prep_filt_sfb2d", "g0.transpose", "g1.transpose", "len", "ValueError", "prep_filt_sfb2d"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.sfb1d_atrous", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.sfb1d_atrous", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.swt_inverse.sfb1d_atrous", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d"], ["", "def", "sfb2d_atrous", "(", "ll", ",", "lh", ",", "hl", ",", "hh", ",", "filts", ",", "mode", "=", "'zero'", ")", ":", "\n", "    ", "\"\"\" Does a single level 2d wavelet reconstruction of wavelet coefficients.\n    Does separate row and column filtering by two calls to\n    :py:func:`pytorch_wavelets.dwt.lowlevel.sfb1d`\n\n    Inputs:\n        ll (torch.Tensor): lowpass coefficients\n        lh (torch.Tensor): horizontal coefficients\n        hl (torch.Tensor): vertical coefficients\n        hh (torch.Tensor): diagonal coefficients\n        filts (list of ndarray or torch.Tensor): If a list of tensors has been\n            given, this function assumes they are in the right form (the form\n            returned by\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d`).\n            Otherwise, this function will prepare the filters to be of the right\n            form by calling\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d`.\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n    \"\"\"", "\n", "tensorize", "=", "[", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "for", "x", "in", "filts", "]", "\n", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "        ", "g0", ",", "g1", "=", "filts", "\n", "if", "True", "in", "tensorize", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "prep_filt_sfb2d", "(", "g0", ",", "g1", ")", "\n", "", "else", ":", "\n", "            ", "g0_col", "=", "g0", "\n", "g0_row", "=", "g0", ".", "transpose", "(", "2", ",", "3", ")", "\n", "g1_col", "=", "g1", "\n", "g1_row", "=", "g1", ".", "transpose", "(", "2", ",", "3", ")", "\n", "", "", "elif", "len", "(", "filts", ")", "==", "4", ":", "\n", "        ", "if", "True", "in", "tensorize", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "prep_filt_sfb2d", "(", "*", "filts", ")", "\n", "", "else", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "filts", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown form for input filts\"", ")", "\n", "\n", "", "lo", "=", "sfb1d_atrous", "(", "ll", ",", "lh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "hi", "=", "sfb1d_atrous", "(", "hl", ",", "hh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "y", "=", "sfb1d_atrous", "(", "lo", ",", "hi", ",", "g0_row", ",", "g1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.AFB2D.forward": [[344, 357], ["ctx.save_for_backward", "lowlevel.int_to_mode", "lowlevel.afb1d", "lowlevel.afb1d", "y.reshape.reshape.reshape", "y[].contiguous", "y[].contiguous"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.int_to_mode", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "h0_row", ",", "h1_row", ",", "h0_col", ",", "h1_col", ",", "mode", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "h0_row", ",", "h1_row", ",", "h0_col", ",", "h1_col", ")", "\n", "ctx", ".", "shape", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "mode", "=", "int_to_mode", "(", "mode", ")", "\n", "ctx", ".", "mode", "=", "mode", "\n", "lohi", "=", "afb1d", "(", "x", ",", "h0_row", ",", "h1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "y", "=", "afb1d", "(", "lohi", ",", "h0_col", ",", "h1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "s", "=", "y", ".", "shape", "\n", "y", "=", "y", ".", "reshape", "(", "s", "[", "0", "]", ",", "-", "1", ",", "4", ",", "s", "[", "-", "2", "]", ",", "s", "[", "-", "1", "]", ")", "\n", "low", "=", "y", "[", ":", ",", ":", ",", "0", "]", ".", "contiguous", "(", ")", "\n", "highs", "=", "y", "[", ":", ",", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "return", "low", ",", "highs", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.AFB2D.backward": [[358, 375], ["torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "lowlevel.sfb1d", "lowlevel.sfb1d", "lowlevel.sfb1d"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "low", ",", "highs", ")", ":", "\n", "        ", "dx", "=", "None", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "            ", "mode", "=", "ctx", ".", "mode", "\n", "h0_row", ",", "h1_row", ",", "h0_col", ",", "h1_col", "=", "ctx", ".", "saved_tensors", "\n", "lh", ",", "hl", ",", "hh", "=", "torch", ".", "unbind", "(", "highs", ",", "dim", "=", "2", ")", "\n", "lo", "=", "sfb1d", "(", "low", ",", "lh", ",", "h0_col", ",", "h1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "hi", "=", "sfb1d", "(", "hl", ",", "hh", ",", "h0_col", ",", "h1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "dx", "=", "sfb1d", "(", "lo", ",", "hi", ",", "h0_row", ",", "h1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "if", "dx", ".", "shape", "[", "-", "2", "]", ">", "ctx", ".", "shape", "[", "-", "2", "]", "and", "dx", ".", "shape", "[", "-", "1", "]", ">", "ctx", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "dx", "=", "dx", "[", ":", ",", ":", ",", ":", "ctx", ".", "shape", "[", "-", "2", "]", ",", ":", "ctx", ".", "shape", "[", "-", "1", "]", "]", "\n", "", "elif", "dx", ".", "shape", "[", "-", "2", "]", ">", "ctx", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "dx", "=", "dx", "[", ":", ",", ":", ",", ":", "ctx", ".", "shape", "[", "-", "2", "]", "]", "\n", "", "elif", "dx", ".", "shape", "[", "-", "1", "]", ">", "ctx", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "dx", "=", "dx", "[", ":", ",", ":", ",", ":", ",", ":", "ctx", ".", "shape", "[", "-", "1", "]", "]", "\n", "", "", "return", "dx", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.forward": [[620, 631], ["lowlevel.int_to_mode", "ctx.save_for_backward", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "lowlevel.sfb1d", "lowlevel.sfb1d", "lowlevel.sfb1d"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.int_to_mode", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "low", ",", "highs", ",", "g0_row", ",", "g1_row", ",", "g0_col", ",", "g1_col", ",", "mode", ")", ":", "\n", "        ", "mode", "=", "int_to_mode", "(", "mode", ")", "\n", "ctx", ".", "mode", "=", "mode", "\n", "ctx", ".", "save_for_backward", "(", "g0_row", ",", "g1_row", ",", "g0_col", ",", "g1_col", ")", "\n", "\n", "lh", ",", "hl", ",", "hh", "=", "torch", ".", "unbind", "(", "highs", ",", "dim", "=", "2", ")", "\n", "lo", "=", "sfb1d", "(", "low", ",", "lh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "hi", "=", "sfb1d", "(", "hl", ",", "hh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "y", "=", "sfb1d", "(", "lo", ",", "hi", ",", "g0_row", ",", "g1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.SFB2D.backward": [[632, 645], ["lowlevel.afb1d", "lowlevel.afb1d", "dx.reshape.reshape.reshape", "dx[].contiguous", "dx[].contiguous"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "dy", ")", ":", "\n", "        ", "dx", "=", "None", "\n", "if", "ctx", ".", "needs_input_grad", "[", "0", "]", ":", "\n", "            ", "mode", "=", "ctx", ".", "mode", "\n", "g0_row", ",", "g1_row", ",", "g0_col", ",", "g1_col", "=", "ctx", ".", "saved_tensors", "\n", "dx", "=", "afb1d", "(", "dy", ",", "g0_row", ",", "g1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "dx", "=", "afb1d", "(", "dx", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "s", "=", "dx", ".", "shape", "\n", "dx", "=", "dx", ".", "reshape", "(", "s", "[", "0", "]", ",", "-", "1", ",", "4", ",", "s", "[", "-", "2", "]", ",", "s", "[", "-", "1", "]", ")", "\n", "dlow", "=", "dx", "[", ":", ",", ":", ",", "0", "]", ".", "contiguous", "(", ")", "\n", "dhigh", "=", "dx", "[", ":", ",", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "", "return", "dlow", ",", "dhigh", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll": [[15, 32], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "function", ["None"], ["def", "roll", "(", "x", ",", "n", ",", "dim", ",", "make_even", "=", "False", ")", ":", "\n", "    ", "if", "n", "<", "0", ":", "\n", "        ", "n", "=", "x", ".", "shape", "[", "dim", "]", "+", "n", "\n", "\n", "", "if", "make_even", "and", "x", ".", "shape", "[", "dim", "]", "%", "2", "==", "1", ":", "\n", "        ", "end", "=", "1", "\n", "", "else", ":", "\n", "        ", "end", "=", "0", "\n", "\n", "", "if", "dim", "==", "0", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x", "[", "-", "n", ":", "]", ",", "x", "[", ":", "-", "n", "+", "end", "]", ")", ",", "dim", "=", "0", ")", "\n", "", "elif", "dim", "==", "1", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x", "[", ":", ",", "-", "n", ":", "]", ",", "x", "[", ":", ",", ":", "-", "n", "+", "end", "]", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "dim", "==", "2", "or", "dim", "==", "-", "2", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x", "[", ":", ",", ":", ",", "-", "n", ":", "]", ",", "x", "[", ":", ",", ":", ",", ":", "-", "n", "+", "end", "]", ")", ",", "dim", "=", "2", ")", "\n", "", "elif", "dim", "==", "3", "or", "dim", "==", "-", "1", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x", "[", ":", ",", ":", ",", ":", ",", "-", "n", ":", "]", ",", "x", "[", ":", ",", ":", ",", ":", ",", ":", "-", "n", "+", "end", "]", ")", ",", "dim", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad": [[34, 97], ["src.wavelet_learning.utils.reflect", "numpy.arange", "src.wavelet_learning.utils.reflect", "src.wavelet_learning.utils.reflect", "src.wavelet_learning.utils.reflect", "numpy.outer", "numpy.outer", "numpy.arange", "numpy.pad", "torch.pad", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.ones", "numpy.ones", "numpy.arange", "numpy.pad", "numpy.arange", "numpy.pad", "numpy.arange", "numpy.pad", "numpy.outer", "numpy.outer", "torch.pad", "ValueError", "numpy.ones", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect"], ["", "", "def", "mypad", "(", "x", ",", "pad", ",", "mode", "=", "'constant'", ",", "value", "=", "0", ")", ":", "\n", "    ", "\"\"\" Function to do numpy like padding on tensors. Only works for 2-D\n    padding.\n\n    Inputs:\n        x (tensor): tensor to pad\n        pad (tuple): tuple of (left, right, top, bottom) pad sizes\n        mode (str): 'symmetric', 'wrap', 'constant, 'reflect', 'replicate', or\n            'zero'. The padding technique.\n    \"\"\"", "\n", "if", "mode", "==", "'symmetric'", ":", "\n", "# Vertical only", "\n", "        ", "if", "pad", "[", "0", "]", "==", "0", "and", "pad", "[", "1", "]", "==", "0", ":", "\n", "            ", "m1", ",", "m2", "=", "pad", "[", "2", "]", ",", "pad", "[", "3", "]", "\n", "l", "=", "x", ".", "shape", "[", "-", "2", "]", "\n", "xe", "=", "reflect", "(", "np", ".", "arange", "(", "-", "m1", ",", "l", "+", "m2", ",", "dtype", "=", "'int32'", ")", ",", "-", "0.5", ",", "l", "-", "0.5", ")", "\n", "return", "x", "[", ":", ",", ":", ",", "xe", "]", "\n", "# horizontal only", "\n", "", "elif", "pad", "[", "2", "]", "==", "0", "and", "pad", "[", "3", "]", "==", "0", ":", "\n", "            ", "m1", ",", "m2", "=", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", "\n", "l", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "xe", "=", "reflect", "(", "np", ".", "arange", "(", "-", "m1", ",", "l", "+", "m2", ",", "dtype", "=", "'int32'", ")", ",", "-", "0.5", ",", "l", "-", "0.5", ")", "\n", "return", "x", "[", ":", ",", ":", ",", ":", ",", "xe", "]", "\n", "# Both", "\n", "", "else", ":", "\n", "            ", "m1", ",", "m2", "=", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", "\n", "l1", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "xe_row", "=", "reflect", "(", "\n", "np", ".", "arange", "(", "-", "m1", ",", "l1", "+", "m2", ",", "dtype", "=", "'int32'", ")", ",", "-", "0.5", ",", "l1", "-", "0.5", ")", "\n", "m1", ",", "m2", "=", "pad", "[", "2", "]", ",", "pad", "[", "3", "]", "\n", "l2", "=", "x", ".", "shape", "[", "-", "2", "]", "\n", "xe_col", "=", "reflect", "(", "\n", "np", ".", "arange", "(", "-", "m1", ",", "l2", "+", "m2", ",", "dtype", "=", "'int32'", ")", ",", "-", "0.5", ",", "l2", "-", "0.5", ")", "\n", "i", "=", "np", ".", "outer", "(", "xe_col", ",", "np", ".", "ones", "(", "xe_row", ".", "shape", "[", "0", "]", ")", ")", "\n", "j", "=", "np", ".", "outer", "(", "np", ".", "ones", "(", "xe_col", ".", "shape", "[", "0", "]", ")", ",", "xe_row", ")", "\n", "return", "x", "[", ":", ",", ":", ",", "i", ",", "j", "]", "\n", "", "", "elif", "mode", "==", "'periodic'", ":", "\n", "# Vertical only", "\n", "        ", "if", "pad", "[", "0", "]", "==", "0", "and", "pad", "[", "1", "]", "==", "0", ":", "\n", "            ", "xe", "=", "np", ".", "arange", "(", "x", ".", "shape", "[", "-", "2", "]", ")", "\n", "xe", "=", "np", ".", "pad", "(", "xe", ",", "(", "pad", "[", "2", "]", ",", "pad", "[", "3", "]", ")", ",", "mode", "=", "'wrap'", ")", "\n", "return", "x", "[", ":", ",", ":", ",", "xe", "]", "\n", "# Horizontal only", "\n", "", "elif", "pad", "[", "2", "]", "==", "0", "and", "pad", "[", "3", "]", "==", "0", ":", "\n", "            ", "xe", "=", "np", ".", "arange", "(", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "xe", "=", "np", ".", "pad", "(", "xe", ",", "(", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ")", ",", "mode", "=", "'wrap'", ")", "\n", "return", "x", "[", ":", ",", ":", ",", ":", ",", "xe", "]", "\n", "# Both", "\n", "", "else", ":", "\n", "            ", "xe_col", "=", "np", ".", "arange", "(", "x", ".", "shape", "[", "-", "2", "]", ")", "\n", "xe_col", "=", "np", ".", "pad", "(", "xe_col", ",", "(", "pad", "[", "2", "]", ",", "pad", "[", "3", "]", ")", ",", "mode", "=", "'wrap'", ")", "\n", "xe_row", "=", "np", ".", "arange", "(", "x", ".", "shape", "[", "-", "1", "]", ")", "\n", "xe_row", "=", "np", ".", "pad", "(", "xe_row", ",", "(", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ")", ",", "mode", "=", "'wrap'", ")", "\n", "i", "=", "np", ".", "outer", "(", "xe_col", ",", "np", ".", "ones", "(", "xe_row", ".", "shape", "[", "0", "]", ")", ")", "\n", "j", "=", "np", ".", "outer", "(", "np", ".", "ones", "(", "xe_col", ".", "shape", "[", "0", "]", ")", ",", "xe_row", ")", "\n", "return", "x", "[", ":", ",", ":", ",", "i", ",", "j", "]", "\n", "\n", "", "", "elif", "mode", "==", "'constant'", "or", "mode", "==", "'reflect'", "or", "mode", "==", "'replicate'", ":", "\n", "        ", "return", "F", ".", "pad", "(", "x", ",", "pad", ",", "mode", ",", "value", ")", "\n", "", "elif", "mode", "==", "'zero'", ":", "\n", "        ", "return", "F", ".", "pad", "(", "x", ",", "pad", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d": [[99, 182], ["h0.reshape.numel", "torch.cat", "torch.cat", "isinstance", "torch.tensor", "torch.tensor", "isinstance", "torch.tensor", "torch.tensor", "tuple", "h0.reshape.reshape", "tuple", "h1.reshape.reshape", "lowlevel.roll", "torch.conv2d", "pywt.dwt_coeff_len", "numpy.copy", "numpy.copy", "torch.conv2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.pad", "lowlevel.mypad", "torch.conv2d", "ValueError", "numpy.array().ravel", "numpy.array().ravel", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad"], ["", "", "def", "afb1d", "(", "x", ",", "h0", ",", "h1", ",", "mode", "=", "'zero'", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" 1D analysis filter bank (along one dimension only) of an image\n\n    Inputs:\n        x (tensor): 4D input with the last two dimensions the spatial input\n        h0 (tensor): 4D input for the lowpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        h1 (tensor): 4D input for the highpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        mode (str): padding method\n        dim (int) - dimension of filtering. d=2 is for a vertical filter (called\n            column filtering but filters across the rows). d=3 is for a\n            horizontal filter, (called row filtering but filters across the\n            columns).\n\n    Returns:\n        lohi: lowpass and highpass subbands concatenated along the channel\n            dimension\n    \"\"\"", "\n", "C", "=", "x", ".", "shape", "[", "1", "]", "\n", "# Convert the dim to positive", "\n", "d", "=", "dim", "%", "4", "\n", "s", "=", "(", "2", ",", "1", ")", "if", "d", "==", "2", "else", "(", "1", ",", "2", ")", "\n", "N", "=", "x", ".", "shape", "[", "d", "]", "\n", "# If h0, h1 are not tensors, make them. If they are, then assume that they", "\n", "# are in the right order", "\n", "if", "not", "isinstance", "(", "h0", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "h0", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "h0", ")", ".", "ravel", "(", ")", "[", ":", ":", "-", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "x", ".", "device", ")", "\n", "", "if", "not", "isinstance", "(", "h1", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "h1", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "h1", ")", ".", "ravel", "(", ")", "[", ":", ":", "-", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "x", ".", "device", ")", "\n", "", "L", "=", "h0", ".", "numel", "(", ")", "\n", "L2", "=", "L", "//", "2", "\n", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "shape", "[", "d", "]", "=", "L", "\n", "# If h aren't in the right shape, make them so", "\n", "if", "h0", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "h0", "=", "h0", ".", "reshape", "(", "*", "shape", ")", "\n", "", "if", "h1", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "h1", "=", "h1", ".", "reshape", "(", "*", "shape", ")", "\n", "", "h", "=", "torch", ".", "cat", "(", "[", "h0", ",", "h1", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "\n", "if", "mode", "==", "'per'", "or", "mode", "==", "'periodization'", ":", "\n", "        ", "if", "x", ".", "shape", "[", "dim", "]", "%", "2", "==", "1", ":", "\n", "            ", "if", "d", "==", "2", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x", "[", ":", ",", ":", ",", "-", "1", ":", "]", ")", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x", "[", ":", ",", ":", ",", ":", ",", "-", "1", ":", "]", ")", ",", "dim", "=", "3", ")", "\n", "", "N", "+=", "1", "\n", "", "x", "=", "roll", "(", "x", ",", "-", "L2", ",", "dim", "=", "d", ")", "\n", "pad", "=", "(", "L", "-", "1", ",", "0", ")", "if", "d", "==", "2", "else", "(", "0", ",", "L", "-", "1", ")", "\n", "lohi", "=", "F", ".", "conv2d", "(", "x", ",", "h", ",", "padding", "=", "pad", ",", "stride", "=", "s", ",", "groups", "=", "C", ")", "\n", "N2", "=", "N", "//", "2", "\n", "if", "d", "==", "2", ":", "\n", "            ", "lohi", "[", ":", ",", ":", ",", ":", "L2", "]", "=", "lohi", "[", ":", ",", ":", ",", ":", "L2", "]", "+", "lohi", "[", ":", ",", ":", ",", "N2", ":", "N2", "+", "L2", "]", "\n", "lohi", "=", "lohi", "[", ":", ",", ":", ",", ":", "N2", "]", "\n", "", "else", ":", "\n", "            ", "lohi", "[", ":", ",", ":", ",", ":", ",", ":", "L2", "]", "=", "lohi", "[", ":", ",", ":", ",", ":", ",", ":", "L2", "]", "+", "lohi", "[", ":", ",", ":", ",", ":", ",", "N2", ":", "N2", "+", "L2", "]", "\n", "lohi", "=", "lohi", "[", ":", ",", ":", ",", ":", ",", ":", "N2", "]", "\n", "", "", "else", ":", "\n", "# Calculate the pad size", "\n", "        ", "outsize", "=", "pywt", ".", "dwt_coeff_len", "(", "N", ",", "L", ",", "mode", "=", "mode", ")", "\n", "p", "=", "2", "*", "(", "outsize", "-", "1", ")", "-", "N", "+", "L", "\n", "if", "mode", "==", "'zero'", ":", "\n", "# Sadly, pytorch only allows for same padding before and after, if", "\n", "# we need to do more padding after for odd length signals, have to", "\n", "# prepad", "\n", "            ", "if", "p", "%", "2", "==", "1", ":", "\n", "                ", "pad", "=", "(", "0", ",", "0", ",", "0", ",", "1", ")", "if", "d", "==", "2", "else", "(", "0", ",", "1", ",", "0", ",", "0", ")", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "pad", ")", "\n", "", "pad", "=", "(", "p", "//", "2", ",", "0", ")", "if", "d", "==", "2", "else", "(", "0", ",", "p", "//", "2", ")", "\n", "# Calculate the high and lowpass", "\n", "# ipdb.set_trace()", "\n", "lohi", "=", "F", ".", "conv2d", "(", "x", ",", "h", ",", "padding", "=", "pad", ",", "stride", "=", "s", ",", "groups", "=", "C", ")", "\n", "", "elif", "mode", "==", "'symmetric'", "or", "mode", "==", "'reflect'", "or", "mode", "==", "'periodic'", ":", "\n", "            ", "pad", "=", "(", "0", ",", "0", ",", "p", "//", "2", ",", "(", "p", "+", "1", ")", "//", "2", ")", "if", "d", "==", "2", "else", "(", "p", "//", "2", ",", "(", "p", "+", "1", ")", "//", "2", ",", "0", ",", "0", ")", "\n", "x", "=", "mypad", "(", "x", ",", "pad", "=", "pad", ",", "mode", "=", "mode", ")", "\n", "lohi", "=", "F", ".", "conv2d", "(", "x", ",", "h", ",", "stride", "=", "s", ",", "groups", "=", "C", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "", "return", "lohi", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d_atrous": [[184, 233], ["h0.reshape.numel", "torch.cat", "torch.cat", "lowlevel.mypad", "torch.conv2d", "isinstance", "torch.tensor", "torch.tensor", "isinstance", "torch.tensor", "torch.tensor", "tuple", "h0.reshape.reshape", "tuple", "h1.reshape.reshape", "numpy.copy", "numpy.copy", "numpy.array().ravel", "numpy.array().ravel", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad"], ["", "def", "afb1d_atrous", "(", "x", ",", "h0", ",", "h1", ",", "mode", "=", "'periodic'", ",", "dim", "=", "-", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\" 1D analysis filter bank (along one dimension only) of an image without\n    downsampling. Does the a trous algorithm.\n\n    Inputs:\n        x (tensor): 4D input with the last two dimensions the spatial input\n        h0 (tensor): 4D input for the lowpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        h1 (tensor): 4D input for the highpass filter. Should have shape (1, 1,\n            h, 1) or (1, 1, 1, w)\n        mode (str): padding method\n        dim (int) - dimension of filtering. d=2 is for a vertical filter (called\n            column filtering but filters across the rows). d=3 is for a\n            horizontal filter, (called row filtering but filters across the\n            columns).\n        dilation (int): dilation factor. Should be a power of 2.\n\n    Returns:\n        lohi: lowpass and highpass subbands concatenated along the channel\n            dimension\n    \"\"\"", "\n", "C", "=", "x", ".", "shape", "[", "1", "]", "\n", "# Convert the dim to positive", "\n", "d", "=", "dim", "%", "4", "\n", "# If h0, h1 are not tensors, make them. If they are, then assume that they", "\n", "# are in the right order", "\n", "if", "not", "isinstance", "(", "h0", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "h0", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "h0", ")", ".", "ravel", "(", ")", "[", ":", ":", "-", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "x", ".", "device", ")", "\n", "", "if", "not", "isinstance", "(", "h1", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "h1", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "h1", ")", ".", "ravel", "(", ")", "[", ":", ":", "-", "1", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "x", ".", "device", ")", "\n", "", "L", "=", "h0", ".", "numel", "(", ")", "\n", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "shape", "[", "d", "]", "=", "L", "\n", "# If h aren't in the right shape, make them so", "\n", "if", "h0", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "h0", "=", "h0", ".", "reshape", "(", "*", "shape", ")", "\n", "", "if", "h1", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "h1", "=", "h1", ".", "reshape", "(", "*", "shape", ")", "\n", "", "h", "=", "torch", ".", "cat", "(", "[", "h0", ",", "h1", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "\n", "# Calculate the pad size", "\n", "L2", "=", "(", "L", "*", "dilation", ")", "//", "2", "\n", "pad", "=", "(", "0", ",", "0", ",", "L2", "-", "dilation", ",", "L2", ")", "if", "d", "==", "2", "else", "(", "L2", "-", "dilation", ",", "L2", ",", "0", ",", "0", ")", "\n", "x", "=", "mypad", "(", "x", ",", "pad", "=", "pad", ",", "mode", "=", "mode", ")", "\n", "lohi", "=", "F", ".", "conv2d", "(", "x", ",", "h", ",", "groups", "=", "C", ",", "dilation", "=", "dilation", ")", "\n", "\n", "return", "lohi", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d": [[235, 281], ["g0.reshape.numel", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "torch.tensor", "torch.tensor", "isinstance", "torch.tensor", "torch.tensor", "tuple", "g0.reshape.reshape", "tuple", "g1.reshape.reshape", "lowlevel.roll", "numpy.copy", "numpy.copy", "torch.conv_transpose2d", "torch.conv_transpose2d", "ValueError", "numpy.array().ravel", "numpy.array().ravel", "torch.conv_transpose2d", "torch.conv_transpose2d", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll"], ["", "def", "sfb1d", "(", "lo", ",", "hi", ",", "g0", ",", "g1", ",", "mode", "=", "'zero'", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" 1D synthesis filter bank of an image tensor\n    \"\"\"", "\n", "C", "=", "lo", ".", "shape", "[", "1", "]", "\n", "d", "=", "dim", "%", "4", "\n", "# If g0, g1 are not tensors, make them. If they are, then assume that they", "\n", "# are in the right order", "\n", "if", "not", "isinstance", "(", "g0", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "g0", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "g0", ")", ".", "ravel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "lo", ".", "device", ")", "\n", "", "if", "not", "isinstance", "(", "g1", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "g1", "=", "torch", ".", "tensor", "(", "np", ".", "copy", "(", "np", ".", "array", "(", "g1", ")", ".", "ravel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "lo", ".", "device", ")", "\n", "", "L", "=", "g0", ".", "numel", "(", ")", "\n", "shape", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", "\n", "shape", "[", "d", "]", "=", "L", "\n", "N", "=", "2", "*", "lo", ".", "shape", "[", "d", "]", "\n", "# If g aren't in the right shape, make them so", "\n", "if", "g0", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "g0", "=", "g0", ".", "reshape", "(", "*", "shape", ")", "\n", "", "if", "g1", ".", "shape", "!=", "tuple", "(", "shape", ")", ":", "\n", "        ", "g1", "=", "g1", ".", "reshape", "(", "*", "shape", ")", "\n", "\n", "", "s", "=", "(", "2", ",", "1", ")", "if", "d", "==", "2", "else", "(", "1", ",", "2", ")", "\n", "g0", "=", "torch", ".", "cat", "(", "[", "g0", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "g1", "=", "torch", ".", "cat", "(", "[", "g1", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "if", "mode", "==", "'per'", "or", "mode", "==", "'periodization'", ":", "\n", "        ", "y", "=", "F", ".", "conv_transpose2d", "(", "lo", ",", "g0", ",", "stride", "=", "s", ",", "groups", "=", "C", ")", "+", "F", ".", "conv_transpose2d", "(", "hi", ",", "g1", ",", "stride", "=", "s", ",", "groups", "=", "C", ")", "\n", "if", "d", "==", "2", ":", "\n", "            ", "y", "[", ":", ",", ":", ",", ":", "L", "-", "2", "]", "=", "y", "[", ":", ",", ":", ",", ":", "L", "-", "2", "]", "+", "y", "[", ":", ",", ":", ",", "N", ":", "N", "+", "L", "-", "2", "]", "\n", "y", "=", "y", "[", ":", ",", ":", ",", ":", "N", "]", "\n", "", "else", ":", "\n", "            ", "y", "[", ":", ",", ":", ",", ":", ",", ":", "L", "-", "2", "]", "=", "y", "[", ":", ",", ":", ",", ":", ",", ":", "L", "-", "2", "]", "+", "y", "[", ":", ",", ":", ",", ":", ",", "N", ":", "N", "+", "L", "-", "2", "]", "\n", "y", "=", "y", "[", ":", ",", ":", ",", ":", ",", ":", "N", "]", "\n", "", "y", "=", "roll", "(", "y", ",", "1", "-", "L", "//", "2", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "if", "mode", "==", "'zero'", "or", "mode", "==", "'symmetric'", "or", "mode", "==", "'reflect'", "or", "mode", "==", "'periodic'", ":", "\n", "            ", "pad", "=", "(", "L", "-", "2", ",", "0", ")", "if", "d", "==", "2", "else", "(", "0", ",", "L", "-", "2", ")", "\n", "y", "=", "F", ".", "conv_transpose2d", "(", "lo", ",", "g0", ",", "stride", "=", "s", ",", "padding", "=", "pad", ",", "groups", "=", "C", ")", "+", "F", ".", "conv_transpose2d", "(", "hi", ",", "g1", ",", "stride", "=", "s", ",", "padding", "=", "pad", ",", "groups", "=", "C", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mode_to_int": [[283, 300], ["ValueError"], "function", ["None"], ["", "def", "mode_to_int", "(", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "'zero'", ":", "\n", "        ", "return", "0", "\n", "", "elif", "mode", "==", "'symmetric'", ":", "\n", "        ", "return", "1", "\n", "", "elif", "mode", "==", "'per'", "or", "mode", "==", "'periodization'", ":", "\n", "        ", "return", "2", "\n", "", "elif", "mode", "==", "'constant'", ":", "\n", "        ", "return", "3", "\n", "", "elif", "mode", "==", "'reflect'", ":", "\n", "        ", "return", "4", "\n", "", "elif", "mode", "==", "'replicate'", ":", "\n", "        ", "return", "5", "\n", "", "elif", "mode", "==", "'periodic'", ":", "\n", "        ", "return", "6", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.int_to_mode": [[302, 319], ["ValueError"], "function", ["None"], ["", "", "def", "int_to_mode", "(", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "0", ":", "\n", "        ", "return", "'zero'", "\n", "", "elif", "mode", "==", "1", ":", "\n", "        ", "return", "'symmetric'", "\n", "", "elif", "mode", "==", "2", ":", "\n", "        ", "return", "'periodization'", "\n", "", "elif", "mode", "==", "3", ":", "\n", "        ", "return", "'constant'", "\n", "", "elif", "mode", "==", "4", ":", "\n", "        ", "return", "'reflect'", "\n", "", "elif", "mode", "==", "5", ":", "\n", "        ", "return", "'replicate'", "\n", "", "elif", "mode", "==", "6", ":", "\n", "        ", "return", "'periodic'", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb2d": [[377, 423], ["lowlevel.afb1d", "lowlevel.afb1d", "len", "isinstance", "lowlevel.prep_filt_afb2d", "h0.transpose", "h1.transpose", "len", "ValueError", "lowlevel.prep_filt_afb2d"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d"], ["", "", "def", "afb2d", "(", "x", ",", "filts", ",", "mode", "=", "'zero'", ")", ":", "\n", "    ", "\"\"\" Does a single level 2d wavelet decomposition of an input. Does separate\n    row and column filtering by two calls to\n    :py:func:`pytorch_wavelets.dwt.lowlevel.afb1d`\n\n    Inputs:\n        x (torch.Tensor): Input to decompose\n        filts (list of ndarray or torch.Tensor): If a list of tensors has been\n            given, this function assumes they are in the right form (the form\n            returned by\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_afb2d`).\n            Otherwise, this function will prepare the filters to be of the right\n            form by calling\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_afb2d`.\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n\n    Returns:\n        y: Tensor of shape (N, C*4, H, W)\n    \"\"\"", "\n", "tensorize", "=", "[", "not", "isinstance", "(", "f", ",", "torch", ".", "Tensor", ")", "for", "f", "in", "filts", "]", "\n", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "        ", "h0", ",", "h1", "=", "filts", "\n", "if", "True", "in", "tensorize", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "prep_filt_afb2d", "(", "\n", "h0", ",", "h1", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "h0_col", "=", "h0", "\n", "h0_row", "=", "h0", ".", "transpose", "(", "2", ",", "3", ")", "\n", "h1_col", "=", "h1", "\n", "h1_row", "=", "h1", ".", "transpose", "(", "2", ",", "3", ")", "\n", "", "", "elif", "len", "(", "filts", ")", "==", "4", ":", "\n", "        ", "if", "True", "in", "tensorize", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "prep_filt_afb2d", "(", "\n", "*", "filts", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "filts", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown form for input filts\"", ")", "\n", "\n", "", "lohi", "=", "afb1d", "(", "x", ",", "h0_row", ",", "h1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "y", "=", "afb1d", "(", "lohi", ",", "h0_col", ",", "h1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb2d_atrous": [[425, 472], ["lowlevel.afb1d_atrous", "lowlevel.afb1d_atrous", "len", "isinstance", "lowlevel.prep_filt_afb2d", "h0.transpose", "h1.transpose", "len", "ValueError", "lowlevel.prep_filt_afb2d"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d_atrous", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb1d_atrous", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d"], ["", "def", "afb2d_atrous", "(", "x", ",", "filts", ",", "mode", "=", "'periodization'", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\" Does a single level 2d wavelet decomposition of an input. Does separate\n    row and column filtering by two calls to\n    :py:func:`pytorch_wavelets.dwt.lowlevel.afb1d`\n\n    Inputs:\n        x (torch.Tensor): Input to decompose\n        filts (list of ndarray or torch.Tensor): If a list of tensors has been\n            given, this function assumes they are in the right form (the form\n            returned by\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_afb2d`).\n            Otherwise, this function will prepare the filters to be of the right\n            form by calling\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_afb2d`.\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n        dilation (int): dilation factor for the filters. Should be 2**level\n\n    Returns:\n        y: Tensor of shape (N, C, 4, H, W)\n    \"\"\"", "\n", "tensorize", "=", "[", "not", "isinstance", "(", "f", ",", "torch", ".", "Tensor", ")", "for", "f", "in", "filts", "]", "\n", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "        ", "h0", ",", "h1", "=", "filts", "\n", "if", "True", "in", "tensorize", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "prep_filt_afb2d", "(", "\n", "h0", ",", "h1", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "h0_col", "=", "h0", "\n", "h0_row", "=", "h0", ".", "transpose", "(", "2", ",", "3", ")", "\n", "h1_col", "=", "h1", "\n", "h1_row", "=", "h1", ".", "transpose", "(", "2", ",", "3", ")", "\n", "", "", "elif", "len", "(", "filts", ")", "==", "4", ":", "\n", "        ", "if", "True", "in", "tensorize", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "prep_filt_afb2d", "(", "\n", "*", "filts", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "=", "filts", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown form for input filts\"", ")", "\n", "\n", "", "lohi", "=", "afb1d_atrous", "(", "x", ",", "h0_row", ",", "h1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ",", "dilation", "=", "dilation", ")", "\n", "y", "=", "afb1d_atrous", "(", "lohi", ",", "h0_col", ",", "h1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ",", "dilation", "=", "dilation", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.afb2d_nonsep": [[474, 548], ["isinstance", "torch.cat", "torch.cat", "lowlevel.roll", "torch.conv2d", "len", "lowlevel.prep_filt_afb2d_nonsep", "lowlevel.prep_filt_afb2d_nonsep", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lowlevel.roll", "pywt.dwt_coeff_len", "pywt.dwt_coeff_len", "ValueError", "torch.conv2d", "torch.pad", "lowlevel.mypad", "torch.conv2d", "torch.pad", "torch.pad"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d_nonsep", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d_nonsep", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.mypad"], ["", "def", "afb2d_nonsep", "(", "x", ",", "filts", ",", "mode", "=", "'zero'", ")", ":", "\n", "    ", "\"\"\" Does a 1 level 2d wavelet decomposition of an input. Doesn't do separate\n    row and column filtering.\n\n    Inputs:\n        x (torch.Tensor): Input to decompose\n        filts (list or torch.Tensor): If a list is given, should be the low and\n            highpass filter banks. If a tensor is given, it should be of the\n            form created by\n            :py:func:`pytorch_wavelets.dwt.lowlevel.prep_filt_afb2d_nonsep`\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n\n    Returns:\n        y: Tensor of shape (N, C, 4, H, W)\n    \"\"\"", "\n", "C", "=", "x", ".", "shape", "[", "1", "]", "\n", "Ny", "=", "x", ".", "shape", "[", "2", "]", "\n", "Nx", "=", "x", ".", "shape", "[", "3", "]", "\n", "\n", "# Check the filter inputs", "\n", "if", "isinstance", "(", "filts", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "            ", "filts", "=", "prep_filt_afb2d_nonsep", "(", "filts", "[", "0", "]", ",", "filts", "[", "1", "]", ",", "device", "=", "x", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "filts", "=", "prep_filt_afb2d_nonsep", "(", "\n", "filts", "[", "0", "]", ",", "filts", "[", "1", "]", ",", "filts", "[", "2", "]", ",", "filts", "[", "3", "]", ",", "device", "=", "x", ".", "device", ")", "\n", "", "", "f", "=", "torch", ".", "cat", "(", "[", "filts", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "Ly", "=", "f", ".", "shape", "[", "2", "]", "\n", "Lx", "=", "f", ".", "shape", "[", "3", "]", "\n", "\n", "if", "mode", "==", "'periodization'", "or", "mode", "==", "'per'", ":", "\n", "        ", "if", "x", ".", "shape", "[", "2", "]", "%", "2", "==", "1", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x", "[", ":", ",", ":", ",", "-", "1", ":", "]", ")", ",", "dim", "=", "2", ")", "\n", "Ny", "+=", "1", "\n", "", "if", "x", ".", "shape", "[", "3", "]", "%", "2", "==", "1", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x", "[", ":", ",", ":", ",", ":", ",", "-", "1", ":", "]", ")", ",", "dim", "=", "3", ")", "\n", "Nx", "+=", "1", "\n", "", "pad", "=", "(", "Ly", "-", "1", ",", "Lx", "-", "1", ")", "\n", "stride", "=", "(", "2", ",", "2", ")", "\n", "x", "=", "roll", "(", "roll", "(", "x", ",", "-", "Ly", "//", "2", ",", "dim", "=", "2", ")", ",", "-", "Lx", "//", "2", ",", "dim", "=", "3", ")", "\n", "y", "=", "F", ".", "conv2d", "(", "x", ",", "f", ",", "padding", "=", "pad", ",", "stride", "=", "stride", ",", "groups", "=", "C", ")", "\n", "y", "[", ":", ",", ":", ",", ":", "Ly", "//", "2", "]", "+=", "y", "[", ":", ",", ":", ",", "Ny", "//", "2", ":", "Ny", "//", "2", "+", "Ly", "//", "2", "]", "\n", "y", "[", ":", ",", ":", ",", ":", ",", ":", "Lx", "//", "2", "]", "+=", "y", "[", ":", ",", ":", ",", ":", ",", "Nx", "//", "2", ":", "Nx", "//", "2", "+", "Lx", "//", "2", "]", "\n", "y", "=", "y", "[", ":", ",", ":", ",", ":", "Ny", "//", "2", ",", ":", "Nx", "//", "2", "]", "\n", "", "elif", "mode", "==", "'zero'", "or", "mode", "==", "'symmetric'", "or", "mode", "==", "'reflect'", ":", "\n", "# Calculate the pad size", "\n", "        ", "out1", "=", "pywt", ".", "dwt_coeff_len", "(", "Ny", ",", "Ly", ",", "mode", "=", "mode", ")", "\n", "out2", "=", "pywt", ".", "dwt_coeff_len", "(", "Nx", ",", "Lx", ",", "mode", "=", "mode", ")", "\n", "p1", "=", "2", "*", "(", "out1", "-", "1", ")", "-", "Ny", "+", "Ly", "\n", "p2", "=", "2", "*", "(", "out2", "-", "1", ")", "-", "Nx", "+", "Lx", "\n", "if", "mode", "==", "'zero'", ":", "\n", "# Sadly, pytorch only allows for same padding before and after, if", "\n", "# we need to do more padding after for odd length signals, have to", "\n", "# prepad", "\n", "            ", "if", "p1", "%", "2", "==", "1", "and", "p2", "%", "2", "==", "1", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "1", ",", "0", ",", "1", ")", ")", "\n", "", "elif", "p1", "%", "2", "==", "1", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "0", ",", "0", ",", "1", ")", ")", "\n", "", "elif", "p2", "%", "2", "==", "1", ":", "\n", "                ", "x", "=", "F", ".", "pad", "(", "x", ",", "(", "0", ",", "1", ",", "0", ",", "0", ")", ")", "\n", "# Calculate the high and lowpass", "\n", "", "y", "=", "F", ".", "conv2d", "(", "\n", "x", ",", "f", ",", "padding", "=", "(", "p1", "//", "2", ",", "p2", "//", "2", ")", ",", "stride", "=", "2", ",", "groups", "=", "C", ")", "\n", "", "elif", "mode", "==", "'symmetric'", "or", "mode", "==", "'reflect'", "or", "mode", "==", "'periodic'", ":", "\n", "            ", "pad", "=", "(", "p2", "//", "2", ",", "(", "p2", "+", "1", ")", "//", "2", ",", "p1", "//", "2", ",", "(", "p1", "+", "1", ")", "//", "2", ")", "\n", "x", "=", "mypad", "(", "x", ",", "pad", "=", "pad", ",", "mode", "=", "mode", ")", "\n", "y", "=", "F", ".", "conv2d", "(", "x", ",", "f", ",", "stride", "=", "2", ",", "groups", "=", "C", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb2d": [[550, 595], ["lowlevel.sfb1d", "lowlevel.sfb1d", "lowlevel.sfb1d", "len", "isinstance", "lowlevel.prep_filt_sfb2d", "g0.transpose", "g1.transpose", "len", "ValueError", "lowlevel.prep_filt_sfb2d"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb1d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d"], ["", "def", "sfb2d", "(", "ll", ",", "lh", ",", "hl", ",", "hh", ",", "filts", ",", "mode", "=", "'zero'", ")", ":", "\n", "    ", "\"\"\" Does a single level 2d wavelet reconstruction of wavelet coefficients.\n    Does separate row and column filtering by two calls to\n    :py:func:`pytorch_wavelets.dwt.lowlevel.sfb1d`\n\n    Inputs:\n        ll (torch.Tensor): lowpass coefficients\n        lh (torch.Tensor): horizontal coefficients\n        hl (torch.Tensor): vertical coefficients\n        hh (torch.Tensor): diagonal coefficients\n        filts (list of ndarray or torch.Tensor): If a list of tensors has been\n            given, this function assumes they are in the right form (the form\n            returned by\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d`).\n            Otherwise, this function will prepare the filters to be of the right\n            form by calling\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d`.\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n    \"\"\"", "\n", "tensorize", "=", "[", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "for", "x", "in", "filts", "]", "\n", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "        ", "g0", ",", "g1", "=", "filts", "\n", "if", "True", "in", "tensorize", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "prep_filt_sfb2d", "(", "g0", ",", "g1", ")", "\n", "", "else", ":", "\n", "            ", "g0_col", "=", "g0", "\n", "g0_row", "=", "g0", ".", "transpose", "(", "2", ",", "3", ")", "\n", "g1_col", "=", "g1", "\n", "g1_row", "=", "g1", ".", "transpose", "(", "2", ",", "3", ")", "\n", "", "", "elif", "len", "(", "filts", ")", "==", "4", ":", "\n", "        ", "if", "True", "in", "tensorize", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "prep_filt_sfb2d", "(", "*", "filts", ")", "\n", "", "else", ":", "\n", "            ", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "=", "filts", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown form for input filts\"", ")", "\n", "\n", "", "lo", "=", "sfb1d", "(", "ll", ",", "lh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "hi", "=", "sfb1d", "(", "hl", ",", "hh", ",", "g0_col", ",", "g1_col", ",", "mode", "=", "mode", ",", "dim", "=", "2", ")", "\n", "y", "=", "sfb1d", "(", "lo", ",", "hi", ",", "g0_row", ",", "g1_row", ",", "mode", "=", "mode", ",", "dim", "=", "3", ")", "\n", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.sfb2d_nonsep": [[647, 700], ["isinstance", "torch.cat", "torch.cat", "coeffs.reshape", "F.conv_transpose2d.contiguous", "torch.conv_transpose2d", "lowlevel.roll", "len", "lowlevel.prep_filt_sfb2d_nonsep", "lowlevel.roll", "torch.conv_transpose2d", "ValueError", "len", "lowlevel.prep_filt_sfb2d_nonsep", "ValueError"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d_nonsep", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.roll", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d_nonsep"], ["", "", "def", "sfb2d_nonsep", "(", "coeffs", ",", "filts", ",", "mode", "=", "'zero'", ")", ":", "\n", "    ", "\"\"\" Does a single level 2d wavelet reconstruction of wavelet coefficients.\n    Does not do separable filtering.\n\n    Inputs:\n        coeffs (torch.Tensor): tensor of coefficients of shape (N, C, 4, H, W)\n            where the third dimension indexes across the (ll, lh, hl, hh) bands.\n        filts (list of ndarray or torch.Tensor): If a list of tensors has been\n            given, this function assumes they are in the right form (the form\n            returned by\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d_nonsep`).\n            Otherwise, this function will prepare the filters to be of the right\n            form by calling\n            :py:func:`~pytorch_wavelets.dwt.lowlevel.prep_filt_sfb2d_nonsep`.\n        mode (str): 'zero', 'symmetric', 'reflect' or 'periodization'. Which\n            padding to use. If periodization, the output size will be half the\n            input size.  Otherwise, the output size will be slightly larger than\n            half.\n    \"\"\"", "\n", "C", "=", "coeffs", ".", "shape", "[", "1", "]", "\n", "Ny", "=", "coeffs", ".", "shape", "[", "-", "2", "]", "\n", "Nx", "=", "coeffs", ".", "shape", "[", "-", "1", "]", "\n", "\n", "# Check the filter inputs - should be in the form of a torch tensor, but if", "\n", "# not, tensorize it here.", "\n", "if", "isinstance", "(", "filts", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "if", "len", "(", "filts", ")", "==", "2", ":", "\n", "            ", "filts", "=", "prep_filt_sfb2d_nonsep", "(", "filts", "[", "0", "]", ",", "filts", "[", "1", "]", ",", "\n", "device", "=", "coeffs", ".", "device", ")", "\n", "", "elif", "len", "(", "filts", ")", "==", "4", ":", "\n", "            ", "filts", "=", "prep_filt_sfb2d_nonsep", "(", "\n", "filts", "[", "0", "]", ",", "filts", "[", "1", "]", ",", "filts", "[", "2", "]", ",", "filts", "[", "3", "]", ",", "device", "=", "coeffs", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unkown form for input filts\"", ")", "\n", "", "", "f", "=", "torch", ".", "cat", "(", "[", "filts", "]", "*", "C", ",", "dim", "=", "0", ")", "\n", "Ly", "=", "f", ".", "shape", "[", "2", "]", "\n", "Lx", "=", "f", ".", "shape", "[", "3", "]", "\n", "\n", "x", "=", "coeffs", ".", "reshape", "(", "coeffs", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "coeffs", ".", "shape", "[", "-", "2", "]", ",", "coeffs", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "mode", "==", "'periodization'", "or", "mode", "==", "'per'", ":", "\n", "        ", "ll", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "f", ",", "groups", "=", "C", ",", "stride", "=", "2", ")", "\n", "ll", "[", ":", ",", ":", ",", ":", "Ly", "-", "2", "]", "+=", "ll", "[", ":", ",", ":", ",", "2", "*", "Ny", ":", "2", "*", "Ny", "+", "Ly", "-", "2", "]", "\n", "ll", "[", ":", ",", ":", ",", ":", ",", ":", "Lx", "-", "2", "]", "+=", "ll", "[", ":", ",", ":", ",", ":", ",", "2", "*", "Nx", ":", "2", "*", "Nx", "+", "Lx", "-", "2", "]", "\n", "ll", "=", "ll", "[", ":", ",", ":", ",", ":", "2", "*", "Ny", ",", ":", "2", "*", "Nx", "]", "\n", "ll", "=", "roll", "(", "roll", "(", "ll", ",", "1", "-", "Ly", "//", "2", ",", "dim", "=", "2", ")", ",", "1", "-", "Lx", "//", "2", ",", "dim", "=", "3", ")", "\n", "", "elif", "mode", "==", "'symmetric'", "or", "mode", "==", "'zero'", "or", "mode", "==", "'reflect'", "or", "mode", "==", "'periodic'", ":", "\n", "        ", "pad", "=", "(", "Ly", "-", "2", ",", "Lx", "-", "2", ")", "\n", "ll", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "f", ",", "padding", "=", "pad", ",", "groups", "=", "C", ",", "stride", "=", "2", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unkown pad type: {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "return", "ll", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d_nonsep": [[702, 735], ["numpy.array().ravel", "numpy.array().ravel", "numpy.outer", "numpy.outer", "numpy.outer", "numpy.outer", "numpy.stack", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "torch.get_default_dtype", "torch.get_default_dtype"], "function", ["None"], ["", "def", "prep_filt_afb2d_nonsep", "(", "h0_col", ",", "h1_col", ",", "h0_row", "=", "None", ",", "h1_row", "=", "None", ",", "\n", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Prepares the filters to be of the right form for the afb2d_nonsep function.\n    In particular, makes 2d point spread functions, and mirror images them in\n    preparation to do torch.conv2d.\n\n    Inputs:\n        h0_col (array-like): low pass column filter bank\n        h1_col (array-like): high pass column filter bank\n        h0_row (array-like): low pass row filter bank. If none, will assume the\n            same as column filter\n        h1_row (array-like): high pass row filter bank. If none, will assume the\n            same as column filter\n        device: which device to put the tensors on to\n\n    Returns:\n        filts: (4, 1, h, w) tensor ready to get the four subbands\n    \"\"\"", "\n", "h0_col", "=", "np", ".", "array", "(", "h0_col", ")", ".", "ravel", "(", ")", "\n", "h1_col", "=", "np", ".", "array", "(", "h1_col", ")", ".", "ravel", "(", ")", "\n", "if", "h0_row", "is", "None", ":", "\n", "        ", "h0_row", "=", "h0_col", "\n", "", "if", "h1_row", "is", "None", ":", "\n", "        ", "h1_row", "=", "h1_col", "\n", "", "ll", "=", "np", ".", "outer", "(", "h0_col", ",", "h0_row", ")", "\n", "lh", "=", "np", ".", "outer", "(", "h1_col", ",", "h0_row", ")", "\n", "hl", "=", "np", ".", "outer", "(", "h0_col", ",", "h1_row", ")", "\n", "hh", "=", "np", ".", "outer", "(", "h1_col", ",", "h1_row", ")", "\n", "filts", "=", "np", ".", "stack", "(", "[", "ll", "[", "None", ",", ":", ":", "-", "1", ",", ":", ":", "-", "1", "]", ",", "lh", "[", "None", ",", ":", ":", "-", "1", ",", ":", ":", "-", "1", "]", ",", "\n", "hl", "[", "None", ",", ":", ":", "-", "1", ",", ":", ":", "-", "1", "]", ",", "hh", "[", "None", ",", ":", ":", "-", "1", ",", ":", ":", "-", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "filts", "=", "torch", ".", "tensor", "(", "filts", ",", "dtype", "=", "torch", ".", "get_default_dtype", "(", ")", ",", "device", "=", "device", ")", "\n", "return", "filts", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d_nonsep": [[737, 769], ["numpy.array().ravel", "numpy.array().ravel", "numpy.outer", "numpy.outer", "numpy.outer", "numpy.outer", "numpy.stack", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "torch.get_default_dtype", "torch.get_default_dtype"], "function", ["None"], ["", "def", "prep_filt_sfb2d_nonsep", "(", "g0_col", ",", "g1_col", ",", "g0_row", "=", "None", ",", "g1_row", "=", "None", ",", "\n", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Prepares the filters to be of the right form for the sfb2d_nonsep function.\n    In particular, makes 2d point spread functions. Does not mirror image them\n    as sfb2d_nonsep uses conv2d_transpose which acts like normal convolution.\n\n    Inputs:\n        g0_col (array-like): low pass column filter bank\n        g1_col (array-like): high pass column filter bank\n        g0_row (array-like): low pass row filter bank. If none, will assume the\n            same as column filter\n        g1_row (array-like): high pass row filter bank. If none, will assume the\n            same as column filter\n        device: which device to put the tensors on to\n\n    Returns:\n        filts: (4, 1, h, w) tensor ready to combine the four subbands\n    \"\"\"", "\n", "g0_col", "=", "np", ".", "array", "(", "g0_col", ")", ".", "ravel", "(", ")", "\n", "g1_col", "=", "np", ".", "array", "(", "g1_col", ")", ".", "ravel", "(", ")", "\n", "if", "g0_row", "is", "None", ":", "\n", "        ", "g0_row", "=", "g0_col", "\n", "", "if", "g1_row", "is", "None", ":", "\n", "        ", "g1_row", "=", "g1_col", "\n", "", "ll", "=", "np", ".", "outer", "(", "g0_col", ",", "g0_row", ")", "\n", "lh", "=", "np", ".", "outer", "(", "g1_col", ",", "g0_row", ")", "\n", "hl", "=", "np", ".", "outer", "(", "g0_col", ",", "g1_row", ")", "\n", "hh", "=", "np", ".", "outer", "(", "g1_col", ",", "g1_row", ")", "\n", "filts", "=", "np", ".", "stack", "(", "[", "ll", "[", "None", "]", ",", "lh", "[", "None", "]", ",", "hl", "[", "None", "]", ",", "hh", "[", "None", "]", "]", ",", "axis", "=", "0", ")", "\n", "filts", "=", "torch", ".", "tensor", "(", "filts", ",", "dtype", "=", "torch", ".", "get_default_dtype", "(", ")", ",", "device", "=", "device", ")", "\n", "return", "filts", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_sfb2d": [[771, 806], ["numpy.array().ravel", "numpy.array().ravel", "torch.get_default_dtype", "torch.get_default_dtype", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "numpy.array", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "prep_filt_sfb2d", "(", "g0_col", ",", "g1_col", ",", "g0_row", "=", "None", ",", "g1_row", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Prepares the filters to be of the right form for the sfb2d function.  In\n    particular, makes the tensors the right shape. It does not mirror image them\n    as as sfb2d uses conv2d_transpose which acts like normal convolution.\n\n    Inputs:\n        g0_col (array-like): low pass column filter bank\n        g1_col (array-like): high pass column filter bank\n        g0_row (array-like): low pass row filter bank. If none, will assume the\n            same as column filter\n        g1_row (array-like): high pass row filter bank. If none, will assume the\n            same as column filter\n        device: which device to put the tensors on to\n\n    Returns:\n        (g0_col, g1_col, g0_row, g1_row)\n    \"\"\"", "\n", "g0_col", "=", "np", ".", "array", "(", "g0_col", ")", ".", "ravel", "(", ")", "\n", "g1_col", "=", "np", ".", "array", "(", "g1_col", ")", ".", "ravel", "(", ")", "\n", "t", "=", "torch", ".", "get_default_dtype", "(", ")", "\n", "if", "g0_row", "is", "None", ":", "\n", "        ", "g0_row", "=", "g0_col", "\n", "", "if", "g1_row", "is", "None", ":", "\n", "        ", "g1_row", "=", "g1_col", "\n", "", "g0_col", "=", "torch", ".", "tensor", "(", "g0_col", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", "\n", "g1_col", "=", "torch", ".", "tensor", "(", "g1_col", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", "\n", "g0_row", "=", "torch", ".", "tensor", "(", "g0_row", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "g1_row", "=", "torch", ".", "tensor", "(", "g1_row", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "\n", "return", "g0_col", ",", "g1_col", ",", "g0_row", ",", "g1_row", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.lowlevel.prep_filt_afb2d": [[808, 847], ["numpy.array().ravel", "numpy.array().ravel", "torch.get_default_dtype", "torch.get_default_dtype", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "torch.tensor().reshape", "numpy.array().ravel", "numpy.array().ravel", "numpy.array", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "prep_filt_afb2d", "(", "h0_col", ",", "h1_col", ",", "h0_row", "=", "None", ",", "h1_row", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Prepares the filters to be of the right form for the afb2d function.  In\n    particular, makes the tensors the right shape. It takes mirror images of\n    them as as afb2d uses conv2d which acts like normal correlation.\n\n    Inputs:\n        h0_col (array-like): low pass column filter bank\n        h1_col (array-like): high pass column filter bank\n        h0_row (array-like): low pass row filter bank. If none, will assume the\n            same as column filter\n        h1_row (array-like): high pass row filter bank. If none, will assume the\n            same as column filter\n        device: which device to put the tensors on to\n\n    Returns:\n        (h0_col, h1_col, h0_row, h1_row)\n    \"\"\"", "\n", "h0_col", "=", "np", ".", "array", "(", "h0_col", "[", ":", ":", "-", "1", "]", ")", ".", "ravel", "(", ")", "\n", "h1_col", "=", "np", ".", "array", "(", "h1_col", "[", ":", ":", "-", "1", "]", ")", ".", "ravel", "(", ")", "\n", "t", "=", "torch", ".", "get_default_dtype", "(", ")", "\n", "if", "h0_row", "is", "None", ":", "\n", "        ", "h0_row", "=", "h0_col", "\n", "", "else", ":", "\n", "        ", "h0_row", "=", "np", ".", "array", "(", "h0_row", "[", ":", ":", "-", "1", "]", ")", ".", "ravel", "(", ")", "\n", "", "if", "h1_row", "is", "None", ":", "\n", "        ", "h1_row", "=", "h1_col", "\n", "", "else", ":", "\n", "        ", "h1_row", "=", "np", ".", "array", "(", "h1_row", "[", ":", ":", "-", "1", "]", ")", ".", "ravel", "(", ")", "\n", "", "h0_col", "=", "torch", ".", "tensor", "(", "h0_col", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", "\n", "h1_col", "=", "torch", ".", "tensor", "(", "h1_col", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ")", "\n", "h0_row", "=", "torch", ".", "tensor", "(", "h0_row", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "h1_row", "=", "torch", ".", "tensor", "(", "h1_row", ",", "device", "=", "device", ",", "\n", "dtype", "=", "t", ")", ".", "reshape", "(", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "\n", "return", "h0_col", ",", "h1_col", ",", "h0_row", ",", "h1_row", "\n", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.unpack": [[7, 41], ["backend.lower.lower"], "function", ["None"], ["def", "unpack", "(", "pyramid", ",", "backend", "=", "'numpy'", ")", ":", "\n", "    ", "\"\"\" Unpacks a pyramid give back the constituent parts.\n\n    :param pyramid: The Pyramid of DTCWT transforms you wish to unpack\n    :param str backend: A string from 'numpy', 'opencl', or 'tf' indicating\n        which attributes you want to unpack from the pyramid.\n\n    :returns: returns a generator which can be unpacked into the Yl, Yh and\n        Yscale components of the pyramid. The generator will only return 2\n        values if the pyramid was created with the include_scale parameter set\n        to false.\n\n    .. note::\n\n        You can still unpack a tf or opencl pyramid as if it were created by a\n        numpy. In this case it will return a numpy array, rather than the\n        backend specific array type.\n    \"\"\"", "\n", "backend", "=", "backend", ".", "lower", "(", ")", "\n", "if", "backend", "==", "'numpy'", ":", "\n", "        ", "yield", "pyramid", ".", "lowpass", "\n", "yield", "pyramid", ".", "highpasses", "\n", "if", "pyramid", ".", "scales", "is", "not", "None", ":", "\n", "            ", "yield", "pyramid", ".", "scales", "\n", "", "", "elif", "backend", "==", "'opencl'", ":", "\n", "        ", "yield", "pyramid", ".", "cl_lowpass", "\n", "yield", "pyramid", ".", "cl_highpasses", "\n", "if", "pyramid", ".", "cl_scales", "is", "not", "None", ":", "\n", "            ", "yield", "pyramid", ".", "cl_scales", "\n", "", "", "elif", "backend", "==", "'tf'", ":", "\n", "        ", "yield", "pyramid", ".", "lowpass_op", "\n", "yield", "pyramid", ".", "highpasses_ops", "\n", "if", "pyramid", ".", "scales_ops", "is", "not", "None", ":", "\n", "            ", "yield", "pyramid", ".", "scales_ops", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.drawedge": [[43, 73], ["numpy.array", "numpy.maximum", "numpy.arange", "numpy.ones", "numpy.ones", "numpy.array", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.minimum", "numpy.array", "numpy.cos", "numpy.sin", "numpy.maximum"], "function", ["None"], ["", "", "", "def", "drawedge", "(", "theta", ",", "r", ",", "w", ",", "N", ")", ":", "\n", "    ", "\"\"\"Generate an image of size N * N pels, of an edge going from 0 to 1 in\n    height at theta degrees to the horizontal (top of image = 1 if angle = 0).\n    r is a two-element vector, it is a coordinate in ij coords through which the\n    step should pass.\n    The shape of the intensity step is half a raised cosine w pels wide (w>=1).\n\n    T. E . Gale's enhancement to drawedge() for MATLAB, transliterated\n    to Python by S. C. Forshaw, Nov. 2013. \"\"\"", "\n", "\n", "# convert theta from degrees to radians", "\n", "thetar", "=", "np", ".", "array", "(", "theta", "*", "np", ".", "pi", "/", "180", ")", "\n", "\n", "# Calculate image centre from given width", "\n", "imCentre", "=", "(", "np", ".", "array", "(", "[", "N", ",", "N", "]", ")", ".", "T", "-", "1", ")", "/", "2", "+", "1", "\n", "\n", "# Calculate values to subtract from the plane", "\n", "r", "=", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "thetar", ")", ",", "np", ".", "sin", "(", "thetar", ")", "]", ")", "*", "(", "-", "1", ")", "*", "(", "r", "-", "imCentre", ")", "\n", "\n", "# check width of raised cosine section", "\n", "w", "=", "np", ".", "maximum", "(", "1", ",", "w", ")", "\n", "\n", "ramp", "=", "np", ".", "arange", "(", "0", ",", "N", ")", "-", "(", "N", "+", "1", ")", "/", "2", "\n", "hgrad", "=", "np", ".", "sin", "(", "thetar", ")", "*", "(", "-", "1", ")", "*", "np", ".", "ones", "(", "[", "N", ",", "1", "]", ")", "\n", "vgrad", "=", "np", ".", "cos", "(", "thetar", ")", "*", "(", "-", "1", ")", "*", "np", ".", "ones", "(", "[", "1", ",", "N", "]", ")", "\n", "plane", "=", "(", "(", "hgrad", "*", "ramp", ")", "-", "r", "[", "0", "]", ")", "+", "(", "(", "ramp", "*", "vgrad", ")", ".", "T", "-", "r", "[", "1", "]", ")", "\n", "x", "=", "0.5", "+", "0.5", "*", "np", ".", "sin", "(", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "\n", "plane", "*", "(", "np", ".", "pi", "/", "w", ")", ",", "np", ".", "pi", "/", "(", "-", "2", ")", ")", ",", "np", ".", "pi", "/", "2", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.drawcirc": [[75, 99], ["numpy.maximum", "numpy.ones", "numpy.ones", "numpy.sin", "numpy.minimum", "numpy.arange", "numpy.maximum", "numpy.arange", "numpy.exp", "numpy.exp", "numpy.array"], "function", ["None"], ["", "def", "drawcirc", "(", "r", ",", "w", ",", "du", ",", "dv", ",", "N", ")", ":", "\n", "    ", "\"\"\" Generate an image of size N*N pels, containing a circle\n    radius r pels and centred at du,dv relative\n    to the centre of the image.  The edge of the circle is a cosine shaped\n    edge of width w (from 10 to 90% points).\n\n    Python implementation by S. C. Forshaw, November 2013.\"\"\"", "\n", "\n", "# check value of w to avoid dividing by zero", "\n", "w", "=", "np", ".", "maximum", "(", "w", ",", "1", ")", "\n", "\n", "# x plane", "\n", "x", "=", "np", ".", "ones", "(", "[", "N", ",", "1", "]", ")", "*", "(", "(", "np", ".", "arange", "(", "0", ",", "N", ",", "1", ",", "dtype", "=", "'float'", ")", "-", "\n", "(", "N", "+", "1", ")", "/", "2", "-", "dv", ")", "/", "r", ")", "\n", "\n", "# y vector", "\n", "y", "=", "(", "(", "(", "np", ".", "arange", "(", "0", ",", "N", ",", "1", ",", "dtype", "=", "'float'", ")", "-", "(", "N", "+", "1", ")", "/", "2", "-", "du", ")", "/", "r", ")", "*", "\n", "np", ".", "ones", "(", "[", "1", ",", "N", "]", ")", ")", ".", "T", "\n", "\n", "# Final circle image plane", "\n", "p", "=", "0.5", "+", "0.5", "*", "np", ".", "sin", "(", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "(", "\n", "np", ".", "exp", "(", "np", ".", "array", "(", "[", "-", "0.5", "]", ")", "*", "(", "x", "**", "2", "+", "y", "**", "2", ")", ")", ".", "T", "-", "np", ".", "exp", "(", "(", "-", "0.5", ")", ")", ")", "*", "(", "r", "*", "3", "/", "w", ")", ",", "# noqa", "\n", "np", ".", "pi", "/", "(", "-", "2", ")", ")", ",", "np", ".", "pi", "/", "2", ")", ")", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.asfarray": [[101, 109], ["numpy.asanyarray", "numpy.asfarray"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.asfarray"], ["", "def", "asfarray", "(", "X", ")", ":", "\n", "    ", "\"\"\"Similar to :py:func:`numpy.asfarray` except that this function tries to\n    preserve the original datatype of X if it is already a floating point type\n    and will pass floating point arrays through directly without copying.\n\n    \"\"\"", "\n", "X", "=", "np", ".", "asanyarray", "(", "X", ")", "\n", "return", "np", ".", "asfarray", "(", "X", ",", "dtype", "=", "X", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.appropriate_complex_type_for": [[111, 130], ["utils.asfarray", "numpy.issubsctype", "numpy.issubsctype", "numpy.issubsctype", "numpy.issubsctype"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.asfarray"], ["", "def", "appropriate_complex_type_for", "(", "X", ")", ":", "\n", "    ", "\"\"\"Return an appropriate complex data type depending on the type of X. If X\n    is already complex, return that, if it is floating point return a complex\n    type of the appropriate size and if it is integer, choose an complex\n    floating point type depending on the result of :py:func:`numpy.asfarray`.\n\n    \"\"\"", "\n", "X", "=", "asfarray", "(", "X", ")", "\n", "\n", "if", "np", ".", "issubsctype", "(", "X", ".", "dtype", ",", "np", ".", "complex64", ")", "or", "np", ".", "issubsctype", "(", "X", ".", "dtype", ",", "np", ".", "complex128", ")", ":", "\n", "        ", "return", "X", ".", "dtype", "\n", "", "elif", "np", ".", "issubsctype", "(", "X", ".", "dtype", ",", "np", ".", "float32", ")", ":", "\n", "        ", "return", "np", ".", "complex64", "\n", "", "elif", "np", ".", "issubsctype", "(", "X", ".", "dtype", ",", "np", ".", "float64", ")", ":", "\n", "        ", "return", "np", ".", "complex128", "\n", "\n", "# God knows, err on the side of caution", "\n", "", "return", "np", ".", "complex128", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.as_column_vector": [[132, 141], ["numpy.atleast_2d"], "function", ["None"], ["", "def", "as_column_vector", "(", "v", ")", ":", "\n", "    ", "\"\"\"Return *v* as a column vector with shape (N,1).\n\n    \"\"\"", "\n", "v", "=", "np", ".", "atleast_2d", "(", "v", ")", "\n", "if", "v", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "        ", "return", "v", ".", "T", "\n", "", "else", ":", "\n", "        ", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect": [[143, 161], ["numpy.asanyarray", "numpy.fmod", "numpy.where", "numpy.array", "numpy.where"], "function", ["None"], ["", "", "def", "reflect", "(", "x", ",", "minx", ",", "maxx", ")", ":", "\n", "    ", "\"\"\"Reflect the values in matrix *x* about the scalar values *minx* and\n    *maxx*.  Hence a vector *x* containing a long linearly increasing series is\n    converted into a waveform which ramps linearly up and down between *minx*\n    and *maxx*.  If *x* contains integers and *minx* and *maxx* are (integers +\n    0.5), the ramps will have repeated max and min samples.\n\n    .. codeauthor:: Rich Wareham <rjw57@cantab.net>, Aug 2013\n    .. codeauthor:: Nick Kingsbury, Cambridge University, January 1999.\n\n    \"\"\"", "\n", "x", "=", "np", ".", "asanyarray", "(", "x", ")", "\n", "rng", "=", "maxx", "-", "minx", "\n", "rng_by_2", "=", "2", "*", "rng", "\n", "mod", "=", "np", ".", "fmod", "(", "x", "-", "minx", ",", "rng_by_2", ")", "\n", "normed_mod", "=", "np", ".", "where", "(", "mod", "<", "0", ",", "mod", "+", "rng_by_2", ",", "mod", ")", "\n", "out", "=", "np", ".", "where", "(", "normed_mod", ">=", "rng", ",", "rng_by_2", "-", "normed_mod", ",", "normed_mod", ")", "+", "minx", "\n", "return", "np", ".", "array", "(", "out", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.symm_pad_1d": [[163, 172], ["utils.reflect", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.reflect"], ["", "def", "symm_pad_1d", "(", "l", ",", "m", ")", ":", "\n", "    ", "\"\"\" Creates indices for symmetric padding. Works for 1-D.\n\n    Inptus:\n        l (int): size of input\n        m (int): size of filter\n    \"\"\"", "\n", "xe", "=", "reflect", "(", "np", ".", "arange", "(", "-", "m", ",", "l", "+", "m", ",", "dtype", "=", "'int32'", ")", ",", "-", "0.5", ",", "l", "-", "0.5", ")", "\n", "return", "xe", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.memoize": [[176, 185], ["functools.wraps", "obj"], "function", ["None"], ["", "def", "memoize", "(", "obj", ")", ":", "\n", "    ", "cache", "=", "obj", ".", "cache", "=", "{", "}", "\n", "\n", "@", "functools", ".", "wraps", "(", "obj", ")", "\n", "def", "memoizer", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "args", "not", "in", "cache", ":", "\n", "            ", "cache", "[", "args", "]", "=", "obj", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "cache", "[", "args", "]", "\n", "", "return", "memoizer", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.stacked_2d_matrix_vector_prod": [[187, 200], ["numpy.einsum"], "function", ["None"], ["", "def", "stacked_2d_matrix_vector_prod", "(", "mats", ",", "vecs", ")", ":", "\n", "    ", "\"\"\"\n    Interpret *mats* and *vecs* as arrays of 2D matrices and vectors. I.e.\n    *mats* has shape PxQxNxM and *vecs* has shape PxQxM. The result\n    is a PxQxN array equivalent to:\n\n    .. code::\n\n        result[i,j,:] = mats[i,j,:,:].dot(vecs[i,j,:])\n\n    for all valid row and column indices *i* and *j*.\n    \"\"\"", "\n", "return", "np", ".", "einsum", "(", "'...ij,...j->...i'", ",", "mats", ",", "vecs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.stacked_2d_vector_matrix_prod": [[202, 218], ["numpy.array", "stacked_2d_matrix_matrix_prod().reshape", "utils.stacked_2d_matrix_matrix_prod", "vecs.reshape"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.stacked_2d_matrix_matrix_prod"], ["", "def", "stacked_2d_vector_matrix_prod", "(", "vecs", ",", "mats", ")", ":", "\n", "    ", "\"\"\"\n    Interpret *mats* and *vecs* as arrays of 2D matrices and vectors. I.e.\n    *mats* has shape PxQxNxM and *vecs* has shape PxQxN. The result\n    is a PxQxM array equivalent to:\n\n    .. code::\n\n        result[i,j,:] = mats[i,j,:,:].T.dot(vecs[i,j,:])\n\n    for all valid row and column indices *i* and *j*.\n    \"\"\"", "\n", "vecshape", "=", "np", ".", "array", "(", "vecs", ".", "shape", "+", "(", "1", ",", ")", ")", "\n", "vecshape", "[", "-", "1", ":", "-", "3", ":", "-", "1", "]", "=", "vecshape", "[", "-", "2", ":", "]", "\n", "outshape", "=", "mats", ".", "shape", "[", ":", "-", "2", "]", "+", "(", "mats", ".", "shape", "[", "-", "1", "]", ",", ")", "\n", "return", "stacked_2d_matrix_matrix_prod", "(", "vecs", ".", "reshape", "(", "vecshape", ")", ",", "mats", ")", ".", "reshape", "(", "outshape", ")", "# noqa", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.wavelet_learning.utils.stacked_2d_matrix_matrix_prod": [[220, 233], ["numpy.einsum"], "function", ["None"], ["", "def", "stacked_2d_matrix_matrix_prod", "(", "mats1", ",", "mats2", ")", ":", "\n", "    ", "\"\"\"\n    Interpret *mats1* and *mats2* as arrays of 2D matrices. I.e.\n    *mats1* has shape PxQxNxM and *mats2* has shape PxQxMxR. The result\n    is a PxQxNxR array equivalent to:\n\n    .. code::\n\n        result[i,j,:,:] = mats1[i,j,:,:].dot(mats2[i,j,:,:])\n\n    for all valid row and column indices *i* and *j*.\n    \"\"\"", "\n", "return", "np", ".", "einsum", "(", "'...ij,...jk->...ik'", ",", "mats1", ",", "mats2", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fwht.matmul_wht": [[7, 23], ["torch.nn.functional.linear", "torch.from_numpy", "scipy.linalg.hadamard().astype", "h_mat.cuda.cuda", "scipy.linalg.hadamard"], "function", ["None"], ["def", "matmul_wht", "(", "x", ",", "h_mat", "=", "None", ",", "inverse", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Welsh-Hadamard transform by matrix multiplication.\n    @ param x: The sequence to be transformed [batchsize, seq_len].\n    @ param inverse: If true computes the inverse transform.\n    \"\"\"", "\n", "n", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "h_mat", "is", "None", ":", "\n", "        ", "h_mat", "=", "torch", ".", "from_numpy", "(", "hadamard", "(", "n", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "if", "x", ".", "device", ".", "type", "==", "'cuda'", ":", "\n", "            ", "h_mat", "=", "h_mat", ".", "cuda", "(", ")", "\n", "", "", "y", "=", "torch", ".", "nn", ".", "functional", ".", "linear", "(", "x", ",", "h_mat", ",", "bias", "=", "None", ")", "\n", "if", "not", "inverse", ":", "\n", "        ", "y", "=", "y", "/", "n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fwht.fwht": [[25, 70], ["y.clone.clone", "range", "torch.zeros", "range", "AssertionError", "int", "int", "torch.zeros.clone", "numpy.power", "range", "numpy.log2"], "function", ["None"], ["", "def", "fwht", "(", "x", ",", "inverse", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Matlab inspired fast welsh-hadamard transform.\n    :param inverse: If true the ifwht is computed.\n    :param x: The tensor to be transformed\n    :return: The welsh hadamard coefficients.\n    \"\"\"", "\n", "\n", "x", "=", "x", ".", "clone", "(", ")", "\n", "\n", "n", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "if", "n", "<", "2", ":", "\n", "        ", "return", "x", "\n", "\n", "", "if", "n", "%", "2", "!=", "0", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Input feature dimension must be a power of two.\"", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "0", ",", "n", ",", "2", ")", ":", "\n", "        ", "x", "[", "...", ",", "i", "]", "=", "x", "[", "...", ",", "i", "]", "+", "x", "[", "...", ",", "i", "+", "1", "]", "\n", "x", "[", "...", ",", "i", "+", "1", "]", "=", "x", "[", "...", ",", "i", "]", "-", "2", "*", "x", "[", "...", ",", "i", "+", "1", "]", "\n", "\n", "", "l", "=", "1", "\n", "y", "=", "torch", ".", "zeros", "(", "x", ".", "shape", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "for", "nStage", "in", "range", "(", "2", ",", "int", "(", "np", ".", "log2", "(", "n", ")", "+", "1", ")", ")", ":", "# np.log2(n) = number of stages in the flow diagram", "\n", "# calculate coefficients for the ith stage specified by nStage", "\n", "        ", "m", "=", "int", "(", "np", ".", "power", "(", "2", ",", "l", ")", ")", "\n", "jb", "=", "0", "\n", "k", "=", "0", "\n", "while", "k", "<", "n", ":", "\n", "# print('jb, jb+m, k, n, m', jb, jb+m, k, n, m)", "\n", "            ", "for", "j", "in", "range", "(", "jb", ",", "jb", "+", "m", ",", "2", ")", ":", "\n", "                ", "y", "[", "...", ",", "k", "]", "=", "x", "[", "...", ",", "j", "]", "+", "x", "[", "...", ",", "j", "+", "m", "]", "\n", "y", "[", "...", ",", "k", "+", "1", "]", "=", "x", "[", "...", ",", "j", "]", "-", "x", "[", "...", ",", "j", "+", "m", "]", "\n", "y", "[", "...", ",", "k", "+", "2", "]", "=", "x", "[", "...", ",", "j", "+", "1", "]", "-", "x", "[", "...", ",", "j", "+", "1", "+", "m", "]", "\n", "y", "[", "...", ",", "k", "+", "3", "]", "=", "x", "[", "...", ",", "j", "+", "1", "]", "+", "x", "[", "...", ",", "j", "+", "1", "+", "m", "]", "\n", "k", "=", "k", "+", "4", "\n", "", "jb", "=", "jb", "+", "2", "*", "m", "\n", "\n", "# store coefficients in x at the end of each stage", "\n", "", "x", "=", "y", ".", "clone", "(", ")", "\n", "l", "=", "l", "+", "1", "\n", "# perform scaling of coefficients", "\n", "", "if", "not", "inverse", ":", "\n", "         ", "y", "=", "x", "/", "n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fwht.walsh_hadamard_transform": [[72, 108], ["seq_in.clone", "len", "AssertionError", "range", "range", "len"], "function", ["None"], ["", "def", "walsh_hadamard_transform", "(", "seq_in", ",", "inverse", "=", "False", ",", "scale", "=", "True", ")", ":", "\n", "    ", "\"\"\"Utility function for the Walsh Hadamard Transform,\n       produces Hadamard ordered coefficients.\n       Based on: https://docs.sympy.org/latest/_modules/sympy/discrete/transforms.html#fwht\"\"\"", "\n", "assert", "seq_in", ".", "dtype", "==", "torch", ".", "float32", ",", "'float tensor input required.'", "\n", "\n", "a", "=", "seq_in", ".", "clone", "(", ")", "\n", "\n", "if", "inverse", "and", "scale", ":", "\n", "        ", "a", "*=", "len", "(", "a", ")", "\n", "\n", "", "n", "=", "a", ".", "shape", "[", "-", "1", "]", "\n", "if", "n", "<", "2", ":", "\n", "        ", "return", "a", "\n", "\n", "", "if", "n", "%", "2", "!=", "0", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Input feature dimension must be a power of two.\"", ")", "\n", "\n", "# zero padding", "\n", "# a += [S.Zero]*(n - len(a))", "\n", "", "h", "=", "2", "\n", "while", "h", "<=", "n", ":", "\n", "        ", "hf", ",", "ut", "=", "h", "//", "2", ",", "n", "//", "h", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "h", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "hf", ")", ":", "\n", "                ", "u", ",", "v", "=", "a", "[", "...", ",", "i", "+", "j", "]", ",", "a", "[", "...", ",", "i", "+", "j", "+", "hf", "]", "\n", "a", "[", "...", ",", "i", "+", "j", "]", ",", "a", "[", "...", ",", "i", "+", "j", "+", "hf", "]", "=", "u", "+", "v", ",", "u", "-", "v", "\n", "", "", "h", "*=", "2", "\n", "\n", "", "if", "inverse", ":", "\n", "        ", "a", "=", "a", "/", "n", "\n", "", "else", ":", "\n", "# scale if desired", "\n", "        ", "if", "scale", ":", "\n", "            ", "a", "=", "a", "/", "(", "len", "(", "a", ")", "*", "1.0", ")", "\n", "", "", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.__init__": [[23, 37], ["super().__init__", "print", "numpy.ones", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.random.permutation", "torch.nn.parameter.Parameter", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.parameter.Parameter", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.eye", "torch.from_numpy", "torch.from_numpy", "scipy.linalg.hadamard().astype", "scipy.linalg.hadamard"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__"], ["def", "__init__", "(", "self", ",", "depth", ",", "p_drop", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "print", "(", "'fastfood dropout:'", ",", "p_drop", ")", "\n", "ones", "=", "np", ".", "ones", "(", "depth", ",", "np", ".", "float32", ")", "\n", "self", ".", "diag_vec_s", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "ones", ")", ")", "\n", "self", ".", "diag_vec_g", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "ones", ")", ")", "\n", "self", ".", "diag_vec_b", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "ones", ")", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "eye", "(", "depth", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "self", ".", "perm", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "perm", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "drop_s", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "self", ".", "drop_g", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "self", ".", "drop_b", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "p_drop", ")", "\n", "self", ".", "h_mat", "=", "Parameter", "(", "torch", ".", "from_numpy", "(", "hadamard", "(", "depth", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_s": [[38, 40], ["torch.mm", "fastfood.FastFoodLayer.drop_s", "torch.diag"], "methods", ["None"], ["", "def", "mul_s", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_s", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_s", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_g": [[41, 43], ["torch.mm", "fastfood.FastFoodLayer.drop_g", "torch.diag"], "methods", ["None"], ["", "def", "mul_g", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_g", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_g", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_b": [[44, 46], ["torch.mm", "fastfood.FastFoodLayer.drop_b", "torch.diag"], "methods", ["None"], ["", "def", "mul_b", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "drop_b", "(", "torch", ".", "diag", "(", "self", ".", "diag_vec_b", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_p": [[47, 49], ["torch.mm"], "methods", ["None"], ["", "def", "mul_p", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "mm", "(", "x", ",", "self", ".", "perm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.forward": [[50, 54], ["fastfood.FastFoodLayer.mul_s", "src.fastfood.fwht.matmul_wht", "fastfood.FastFoodLayer.mul_g", "fastfood.FastFoodLayer.mul_p", "src.fastfood.fwht.matmul_wht", "fastfood.FastFoodLayer.mul_b"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_s", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fwht.matmul_wht", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_g", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_p", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fwht.matmul_wht", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.mul_b"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "mul_s", "(", "wht", "(", "self", ".", "mul_g", "(", "self", ".", "mul_p", "(", "wht", "(", "self", ".", "mul_b", "(", "x", ")", ",", "\n", "h_mat", "=", "self", ".", "h_mat", ")", ")", ")", ",", "\n", "h_mat", "=", "self", ".", "h_mat", ",", "inverse", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.FastFoodLayer.extra_repr": [[55, 57], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'depth={}'", ".", "format", "(", "self", ".", "depth", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.fastfood.fastfood.diag_mul": [[12, 14], ["torch.mm", "torch.diag"], "function", ["None"], ["def", "diag_mul", "(", "vector", ",", "mat", ")", ":", "\n", "    ", "return", "torch", ".", "mm", "(", "torch", ".", "diag", "(", "vector", ")", ",", "mat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.__init__": [[40, 44], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "char2idx", "=", "{", "}", "\n", "self", ".", "idx2char", "=", "[", "]", "\n", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.add_word": [[45, 47], ["None"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "char", ")", ":", "\n", "        ", "self", ".", "counter", "[", "char", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.prep_dict": [[48, 53], ["char_utils.Dictionary.idx2char.append", "len"], "methods", ["None"], ["", "def", "prep_dict", "(", "self", ")", ":", "\n", "        ", "for", "char", "in", "self", ".", "counter", ":", "\n", "            ", "if", "char", "not", "in", "self", ".", "char2idx", ":", "\n", "                ", "self", ".", "idx2char", ".", "append", "(", "char", ")", "\n", "self", ".", "char2idx", "[", "char", "]", "=", "len", "(", "self", ".", "idx2char", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.__len__": [[54, 56], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2char", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Corpus.__init__": [[59, 64], ["char_utils.Dictionary", "char_utils.Corpus.dict.prep_dict", "char_utils.Corpus.dict.add_word"], "methods", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.prep_dict", "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.Dictionary.add_word"], ["    ", "def", "__init__", "(", "self", ",", "string", ")", ":", "\n", "        ", "self", ".", "dict", "=", "Dictionary", "(", ")", "\n", "for", "c", "in", "string", ":", "\n", "            ", "self", ".", "dict", ".", "add_word", "(", "c", ")", "\n", "", "self", ".", "dict", ".", "prep_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.data_generator": [[13, 32], ["len", "len", "len", "char_utils.Corpus", "getattr"], "function", ["None"], ["def", "data_generator", "(", "args", ")", ":", "\n", "    ", "file", ",", "testfile", ",", "valfile", "=", "getattr", "(", "observations", ",", "args", ".", "dataset", ")", "(", "'../data_sets/penn_treebank/data'", ")", "\n", "file_len", "=", "len", "(", "file", ")", "\n", "valfile_len", "=", "len", "(", "valfile", ")", "\n", "testfile_len", "=", "len", "(", "testfile", ")", "\n", "corpus", "=", "Corpus", "(", "file", "+", "\" \"", "+", "valfile", "+", "\" \"", "+", "testfile", ")", "\n", "\n", "#############################################################", "\n", "# Use the following if you want to pickle the loaded data", "\n", "#", "\n", "# pickle_name = \"{0}.corpus\".format(args.dataset)", "\n", "# if os.path.exists(pickle_name):", "\n", "#     corpus = pickle.load(open(pickle_name, 'rb'))", "\n", "# else:", "\n", "#     corpus = Corpus(file + \" \" + valfile + \" \" + testfile)", "\n", "#     pickle.dump(corpus, open(pickle_name, 'wb'))", "\n", "#############################################################", "\n", "\n", "return", "file", ",", "file_len", ",", "valfile", ",", "valfile_len", ",", "testfile", ",", "testfile_len", ",", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.read_file": [[34, 37], ["unidecode.unidecode", "open().read", "len", "open"], "function", ["None"], ["", "def", "read_file", "(", "filename", ")", ":", "\n", "    ", "file", "=", "unidecode", ".", "unidecode", "(", "open", "(", "filename", ")", ".", "read", "(", ")", ")", "\n", "return", "file", ",", "len", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.char_tensor": [[66, 71], ["torch.zeros().long", "range", "len", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.zeros", "len", "torch.autograd.Variable"], "function", ["None"], ["", "", "def", "char_tensor", "(", "corpus", ",", "string", ")", ":", "\n", "    ", "tensor", "=", "torch", ".", "zeros", "(", "len", "(", "string", ")", ")", ".", "long", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "string", ")", ")", ":", "\n", "        ", "tensor", "[", "i", "]", "=", "corpus", ".", "dict", ".", "char2idx", "[", "string", "[", "i", "]", "]", "\n", "", "return", "Variable", "(", "tensor", ")", ".", "cuda", "(", ")", "if", "cuda", "else", "Variable", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.batchify": [[73, 84], ["data.cuda.narrow", "data.cuda.view", "data.cuda.size", "data.cuda.cuda"], "function", ["None"], ["", "def", "batchify", "(", "data", ",", "batch_size", ",", "args", ")", ":", "\n", "    ", "\"\"\"The output should have size [L x batch_size], where L could be a long sequence length\"\"\"", "\n", "# Work out how cleanly we can divide the dataset into batch_size parts (i.e. continuous seqs).", "\n", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "batch_size", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "batch_size", ")", "\n", "# Evenly divide the data across the batch_size batches.", "\n", "data", "=", "data", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.get_batch": [[86, 92], ["min", "source[].contiguous", "source[].contiguous", "source.size"], "function", ["None"], ["", "def", "get_batch", "(", "source", ",", "start_index", ",", "args", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "args", ".", "seq_len", ",", "source", ".", "size", "(", "1", ")", "-", "1", "-", "start_index", ")", "\n", "end_index", "=", "start_index", "+", "seq_len", "\n", "inp", "=", "source", "[", ":", ",", "start_index", ":", "end_index", "]", ".", "contiguous", "(", ")", "\n", "target", "=", "source", "[", ":", ",", "start_index", "+", "1", ":", "end_index", "+", "1", "]", ".", "contiguous", "(", ")", "# The successors of the inp.", "\n", "return", "inp", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save": [[94, 98], ["torch.save", "print"], "function", ["home.repos.pwc.inspect_result.v0lta_wavelet-network-compression.penn_treebank.char_utils.save"], ["", "def", "save", "(", "model", ")", ":", "\n", "    ", "save_filename", "=", "'model.pt'", "\n", "torch", ".", "save", "(", "model", ",", "save_filename", ")", "\n", "print", "(", "'Saved as %s'", "%", "save_filename", ")", "\n", "\n"]]}