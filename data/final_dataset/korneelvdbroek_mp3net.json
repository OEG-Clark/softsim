{"home.repos.pwc.inspect_result.korneelvdbroek_mp3net.None.launcher.setup_tpu": [[23, 36], ["tensorflow.config.experimental_connect_to_cluster", "tensorflow.tpu.experimental.initialize_tpu_system", "tensorflow.distribute.experimental.TPUStrategy", "tensorflow.distribute.cluster_resolver.TPUClusterResolver", "print", "tf.distribute.cluster_resolver.TPUClusterResolver.cluster_spec().as_dict", "BaseException", "tf.distribute.cluster_resolver.TPUClusterResolver.cluster_spec"], "function", ["None"], ["def", "setup_tpu", "(", ")", ":", "\n", "  ", "try", ":", "\n", "    ", "tpu", "=", "tf", ".", "distribute", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", ")", "# TPU detection", "\n", "tpu_ip", "=", "tpu", ".", "cluster_spec", "(", ")", ".", "as_dict", "(", ")", "[", "'worker'", "]", "\n", "print", "(", "'Running on TPU '", ",", "tpu_ip", ")", "\n", "", "except", "ValueError", ":", "\n", "    ", "raise", "BaseException", "(", "\n", "'ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!'", ")", "\n", "\n", "", "tf", ".", "config", ".", "experimental_connect_to_cluster", "(", "tpu", ")", "\n", "tpu_topology", "=", "tf", ".", "tpu", ".", "experimental", ".", "initialize_tpu_system", "(", "tpu", ")", "# prints info to screen", "\n", "tpu_strategy", "=", "tf", ".", "distribute", ".", "experimental", ".", "TPUStrategy", "(", "tpu", ")", "\n", "return", "tpu_strategy", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.None.launcher.get_training_dir": [[38, 69], ["print", "print", "utils.gspath.join", "utils.gspath.join", "print", "utils.gspath.is_dir", "ValueError", "input", "datetime.datetime.utcnow().strftime", "utils.gspath.is_dir", "utils.gspath.mkdir", "print", "input.lower", "datetime.datetime.utcnow"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_dir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_dir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.mkdir"], ["", "def", "get_training_dir", "(", "args", ",", "confirm", "=", "True", ")", ":", "\n", "  ", "print", "(", "\"Determining training directory...\"", ")", "\n", "\n", "# figure out the training directory", "\n", "training_dir", "=", "None", "\n", "if", "args", ".", "training_sub_dir", "is", "not", "None", ":", "\n", "# user specified a tag to use", "\n", "    ", "training_dir", "=", "gspath", ".", "join", "(", "args", ".", "training_base_dir", ",", "args", ".", "training_sub_dir", ")", "\n", "\n", "if", "not", "gspath", ".", "is_dir", "(", "training_dir", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Training directory {} does not exist... exiting\"", ".", "format", "(", "training_dir", ")", ")", "\n", "\n", "", "if", "confirm", ":", "\n", "      ", "answer", "=", "input", "(", "\"Do you want to reuse the training directory {}? \"", ".", "format", "(", "training_dir", ")", ")", "\n", "if", "answer", ".", "lower", "(", ")", "[", "0", "]", "==", "\"y\"", ":", "\n", "        ", "print", "(", "\"Ok, re-using directory {}\"", ".", "format", "(", "training_dir", ")", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "training_sub_dir", "=", "None", "\n", "\n", "", "", "", "if", "args", ".", "training_sub_dir", "is", "None", ":", "\n", "# creating new training directory", "\n", "    ", "args", ".", "training_sub_dir", "=", "\"train_{0}\"", ".", "format", "(", "datetime", ".", "datetime", ".", "utcnow", "(", ")", ".", "strftime", "(", "\"%Y%m%d%H%M%S\"", ")", ")", "\n", "training_dir", "=", "gspath", ".", "join", "(", "args", ".", "training_base_dir", ",", "args", ".", "training_sub_dir", ")", "\n", "print", "(", "\"Training in new directory {}\"", ".", "format", "(", "training_dir", ")", ")", "\n", "\n", "# Make training dir", "\n", "if", "not", "gspath", ".", "is_dir", "(", "training_dir", ")", ":", "\n", "      ", "gspath", ".", "mkdir", "(", "training_dir", ")", "\n", "\n", "", "", "print", "(", "f\"  Training directory is {training_dir}\"", ")", "\n", "return", "training_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.None.launcher.execute": [[71, 127], ["model.progressivetrainer.ProgressiveTrainer", "print", "Exception", "tensorflow.distribute.OneDeviceStrategy", "print", "tensorflow.distribute.OneDeviceStrategy", "print", "print", "print", "subprocess.Popen", "print", "utils.gspath.join", "print", "utils.gspath.write", "model.progressivetrainer.ProgressiveTrainer.progressive_training", "subprocess.call", "model.progressivetrainer.ProgressiveTrainer.evaluation_loop", "datetime.datetime.utcnow().strftime", "model.progressivetrainer.ProgressiveTrainer.inference_loop", "NotImplementedError", "str", "str", "sorted", "datetime.datetime.utcnow", "str", "vars().items", "vars"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.progressive_training", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.call", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.evaluation_loop", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.inference_loop"], ["", "def", "execute", "(", "args", ",", "strategy", "=", "None", ")", ":", "\n", "# set up device strategy", "\n", "  ", "if", "args", ".", "runtime_tpu", ":", "\n", "# rely on the externally defined tpu_strategy", "\n", "    ", "if", "strategy", "is", "None", ":", "\n", "      ", "raise", "Exception", "(", "\"Strategy should be defined for TPU run\"", ")", "\n", "", "print", "(", "\"Running on TPU\"", ")", "\n", "", "elif", "args", ".", "mode", "==", "'eval'", ":", "\n", "# # make only CPU visible for evaluation loop (otherwise it tries to grab the cuda already in use)", "\n", "# physical_devices = tf.config.list_physical_devices('CPU')", "\n", "# tf.config.set_visible_devices(physical_devices)", "\n", "# device = \"/cpu:0\"", "\n", "\n", "    ", "device", "=", "\"/gpu:0\"", "\n", "strategy", "=", "tf", ".", "distribute", ".", "OneDeviceStrategy", "(", "device", ")", "\n", "print", "(", "\"Running on {}\"", ".", "format", "(", "device", ")", ")", "\n", "", "else", ":", "\n", "    ", "device", "=", "\"/gpu:0\"", "\n", "strategy", "=", "tf", ".", "distribute", ".", "OneDeviceStrategy", "(", "device", ")", "\n", "print", "(", "\"Running on {}\"", ".", "format", "(", "device", ")", ")", "\n", "\n", "", "model_trainer", "=", "ProgressiveTrainer", "(", "strategy", ",", "args", ")", "\n", "\n", "# start tensorboard", "\n", "tensorboard_process", "=", "None", "\n", "try", ":", "\n", "    ", "if", "args", ".", "runtime_launch_tensorboard", ":", "\n", "      ", "print", "(", "\"Launching tensorboard...\"", ")", "\n", "exec_str", "=", "\"tensorboard --logdir={0}\"", ".", "format", "(", "args", ".", "training_dir", ")", "\n", "print", "(", "'  '", "+", "exec_str", ")", "\n", "tensorboard_process", "=", "subprocess", ".", "Popen", "(", "exec_str", ")", "\n", "print", "(", "f'  PID = {tensorboard_process.pid}'", ")", "\n", "\n", "# decode running mode", "\n", "", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "# Save args", "\n", "      ", "filepath", "=", "gspath", ".", "join", "(", "args", ".", "training_dir", ",", "'args_{0}.txt'", ".", "format", "(", "datetime", ".", "datetime", ".", "utcnow", "(", ")", ".", "strftime", "(", "\"%Y%m%d%H%M%S\"", ")", ")", ")", "\n", "data_str", "=", "'\\n'", ".", "join", "(", "[", "str", "(", "k", ")", "+", "','", "+", "str", "(", "v", ")", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "args", ")", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", ")", "\n", "print", "(", "'Writing arguments to {}'", ".", "format", "(", "filepath", ")", ")", "\n", "gspath", ".", "write", "(", "filepath", ",", "data_str", ")", "\n", "\n", "model_trainer", ".", "progressive_training", "(", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'eval'", ":", "\n", "      ", "model_trainer", ".", "evaluation_loop", "(", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'infer'", ":", "\n", "      ", "model_trainer", ".", "inference_loop", "(", ")", "\n", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "", "finally", ":", "\n", "    ", "if", "tensorboard_process", "is", "not", "None", ":", "\n", "# kill tensorboard", "\n", "      ", "subprocess", ".", "call", "(", "[", "'taskkill'", ",", "'/F'", ",", "'/T'", ",", "'/PID'", ",", "str", "(", "tensorboard_process", ".", "pid", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.preprocessing.dataprep.audio2tfrecord": [[11, 72], ["model.audiorepresentation.AudioRepresentation", "tensorflow.data.Dataset.from_tensor_slices", "dataset.map.map", "dataset.map.map", "dataset.map.map", "dataset.map.map", "tensorflow.data.experimental.TFRecordWriter", "tf.data.experimental.TFRecordWriter.write", "tensorflow.py_function", "tensorflow.assert_equal", "tf.expand_dims.set_shape", "tensorflow.truncatediv", "tensorflow.expand_dims", "model.audiorepresentation.AudioRepresentation.t_to_repr", "audio_representation.t_to_repr.set_shape", "model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl", "tensorflow.stack", "utils.load_audio", "tensorflow.shape", "_filepath.numpy().decode", "tensorflow.shape", "_filepath.numpy", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.t_to_repr", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.load_audio"], ["def", "audio2tfrecord", "(", "audio_file_paths", ",", "output_filename", ",", "model", ")", ":", "\n", "  ", "\"\"\"Pre-process audio files to tensors and write to output_filename\n\n  :param audio_file_paths:         list of file paths of the input files\n  :param output_filename:          output file name\n  :param model:                    representation model to convert audio signal to audio representation.\n  :return:                         nothing\n  \"\"\"", "\n", "audio_representation", "=", "AudioRepresentation", "(", "model", ".", "sample_rate", ",", "model", ".", "freq_n", "[", "-", "1", "]", ",", "compute_dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Create dataset of filepaths", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "audio_file_paths", ")", "\n", "\n", "# STEP 1. filepath to read in raw audio data", "\n", "def", "_decode_audio_shaped", "(", "filepath", ")", ":", "\n", "    ", "_decode_audio_closure", "=", "lambda", "_filepath", ":", "audio_utils", ".", "load_audio", "(", "_filepath", ".", "numpy", "(", ")", ".", "decode", "(", "'utf-8'", ")", ",", "\n", "sample_rate", "=", "model", ".", "sample_rate", ",", "\n", "mono", "=", "(", "model", ".", "channels_n", "[", "-", "1", "]", "==", "1", ")", ")", "\n", "audio", "=", "tf", ".", "py_function", "(", "_decode_audio_closure", ",", "[", "filepath", "]", ",", "tf", ".", "float32", ")", "\n", "return", "audio", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "_decode_audio_shaped", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "# STEP 2. convert audio fragments to spectrograms", "\n", "@", "tf", ".", "function", "\n", "def", "wav_to_spectrogram", "(", "wav_data", ")", ":", "\n", "# [samples_n, channels_n]", "\n", "    ", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "wav_data", ")", "[", "1", "]", ",", "model", ".", "channels_n", "[", "-", "1", "]", ",", "\n", "f\"Audio data has {tf.shape(wav_data)[1]} channels, but needs to have {model.channels_n[-1]} for the model\"", ")", "\n", "wav_data", ".", "set_shape", "(", "[", "None", ",", "model", ".", "channels_n", "[", "-", "1", "]", "]", ")", "\n", "\n", "# truncate audio (only a tiny bit)", "\n", "samples_n", "=", "tf", ".", "shape", "(", "wav_data", ")", "[", "0", "]", "\n", "last_block", "=", "tf", ".", "truncatediv", "(", "samples_n", ",", "model", ".", "freq_n", "[", "-", "1", "]", ")", "\n", "wav_data", "=", "wav_data", "[", ":", "last_block", "*", "model", ".", "freq_n", "[", "-", "1", "]", ",", ":", "]", "\n", "\n", "wav_data", "=", "tf", ".", "expand_dims", "(", "wav_data", ",", "axis", "=", "0", ")", "# add batch dimension (t_to_repr expects it)", "\n", "mdct_norm", "=", "audio_representation", ".", "t_to_repr", "(", "wav_data", ")", "# -1..1", "\n", "# [batches_n=1, blocks_n, freqs_n, channels_n]", "\n", "return", "mdct_norm", "\n", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "wav_to_spectrogram", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "# STEP 3. add masking threshold", "\n", "def", "add_masking_intensity", "(", "mdct_norm", ")", ":", "\n", "    ", "mdct_norm", ".", "set_shape", "(", "[", "1", ",", "None", ",", "model", ".", "freq_n", "[", "-", "1", "]", ",", "model", ".", "channels_n", "[", "-", "1", "]", "]", ")", "\n", "\n", "# compute masking threshold amplitude --> determines standard deviation of noise to be added", "\n", "masking_threshold", "=", "audio_representation", ".", "psychoacoustic_masking_ampl", "(", "mdct_norm", ")", "\n", "\n", "# remove batch_n dimension again", "\n", "masking_threshold", "=", "masking_threshold", "[", "0", ",", ":", ",", ":", ",", ":", "]", "\n", "mdct_norm", "=", "mdct_norm", "[", "0", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "return", "tf", ".", "stack", "(", "[", "mdct_norm", ",", "masking_threshold", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "add_masking_intensity", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "# STEP4. convert to string & write to file", "\n", "dataset", "=", "dataset", ".", "map", "(", "tf", ".", "io", ".", "serialize_tensor", ")", "\n", "writer", "=", "tf", ".", "data", ".", "experimental", ".", "TFRecordWriter", "(", "output_filename", ",", "compression_type", "=", "\"GZIP\"", ")", "\n", "writer", ".", "write", "(", "dataset", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.tf_utils.summary": [[9, 82], ["print_fn", "print_fn", "tf_utils.summary.print_row"], "function", ["None"], ["def", "summary", "(", "model", ":", "tf", ".", "keras", ".", "Model", ",", "line_length", "=", "None", ",", "positions", "=", "None", ",", "print_fn", "=", "None", ",", "per_replica_batch", "=", "128", ")", ":", "\n", "  ", "\"\"\"Modified version of Model.summary() which only prints InputLayer and layers with weights\"\"\"", "\n", "if", "print_fn", "is", "None", ":", "\n", "    ", "print_fn", "=", "print", "\n", "\n", "# determine column positions", "\n", "", "line_length", "=", "line_length", "or", "120", "\n", "positions", "=", "positions", "or", "[", ".45", ",", ".65", ",", ".85", ",", "1.", "]", "\n", "if", "positions", "[", "-", "1", "]", "<=", "1", ":", "\n", "    ", "positions", "=", "[", "int", "(", "line_length", "*", "p", ")", "for", "p", "in", "positions", "]", "\n", "# header names for the different log elements", "\n", "", "compute_type", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "global_policy", "(", ")", ".", "compute_dtype", "\n", "\n", "to_display", "=", "[", "'Layer (type)'", ",", "'Output Shape'", ",", "f'MiB ({compute_type})'", ",", "'Param #'", "]", "\n", "formats", "=", "[", "'s'", ",", "'s'", ",", "'>11,.0f'", ",", "'>12,'", "]", "\n", "\n", "def", "print_row", "(", "fields", ",", "positions", ",", "formats", ")", ":", "\n", "    ", "line", "=", "''", "\n", "for", "i", ",", "(", "field", ",", "position", ",", "format", ")", "in", "enumerate", "(", "zip", "(", "fields", ",", "positions", ",", "formats", ")", ")", ":", "\n", "      ", "if", "i", ">", "0", ":", "\n", "        ", "line", "=", "line", "[", ":", "-", "1", "]", "+", "' '", "\n", "", "line", "+=", "f\"{field:{format}}\"", "\n", "line", "=", "line", "[", ":", "position", "]", "\n", "line", "+=", "' '", "*", "(", "position", "-", "len", "(", "line", ")", ")", "\n", "", "print_fn", "(", "line", ")", "\n", "\n", "", "print_fn", "(", "'Model: \"{}\"'", ".", "format", "(", "model", ".", "name", ")", ")", "\n", "print_fn", "(", "'_'", "*", "line_length", ")", "\n", "print_row", "(", "to_display", ",", "positions", ",", "[", "'s'", "]", "*", "4", ")", "\n", "print_fn", "(", "'='", "*", "line_length", ")", "\n", "\n", "def", "print_layer_summary", "(", "layer", ")", ":", "\n", "    ", "\"\"\"Prints a summary for a single layer.\n\n    Arguments:\n        layer: target layer.\n    \"\"\"", "\n", "try", ":", "\n", "      ", "output_shape", "=", "layer", ".", "output_shape", "\n", "", "except", "AttributeError", ":", "\n", "      ", "output_shape", "=", "'multiple'", "\n", "", "except", "RuntimeError", ":", "# output_shape unknown in Eager mode.", "\n", "      ", "output_shape", "=", "'?'", "\n", "", "name", "=", "layer", ".", "name", "\n", "cls_name", "=", "layer", ".", "__class__", ".", "__name__", "\n", "\n", "output_shape_temp", "=", "output_shape", "[", "0", "]", "if", "type", "(", "output_shape", ")", "is", "list", "else", "output_shape", "\n", "if", "len", "(", "output_shape_temp", ")", "==", "4", ":", "\n", "      ", "size", "=", "min", "(", "max", "(", "8", ",", "output_shape_temp", "[", "0", "]", ")", "*", "output_shape_temp", "[", "1", "]", "*", "output_shape_temp", "[", "2", "]", "*", "max", "(", "128", ",", "output_shape_temp", "[", "3", "]", ")", ",", "\n", "max", "(", "128", ",", "output_shape_temp", "[", "0", "]", ")", "*", "output_shape_temp", "[", "1", "]", "*", "output_shape_temp", "[", "2", "]", "*", "max", "(", "8", ",", "output_shape_temp", "[", "3", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "size", "=", "(", "output_shape_temp", "[", "0", "]", "if", "output_shape_temp", "[", "0", "]", "is", "not", "None", "else", "0", ")", "*", "np", ".", "prod", "(", "[", "x", "for", "x", "in", "output_shape_temp", "[", "1", ":", "]", "]", ",", "dtype", "=", "np", ".", "longlong", ")", "\n", "", "size", "*=", "tf", ".", "dtypes", ".", "as_dtype", "(", "compute_type", ")", ".", "size", "\n", "size", "/=", "2", "**", "20", "# to MiB", "\n", "\n", "fields", "=", "[", "name", "+", "' ('", "+", "cls_name", "+", "')'", ",", "str", "(", "output_shape", ")", ",", "size", ",", "layer", ".", "count_params", "(", ")", "]", "\n", "print_row", "(", "fields", ",", "positions", ",", "formats", ")", "\n", "\n", "", "for", "layer", "in", "model", ".", "layers", ":", "\n", "    ", "if", "isinstance", "(", "layer", ",", "tf", ".", "keras", ".", "layers", ".", "InputLayer", ")", "or", "layer", ".", "get_weights", "(", ")", ":", "\n", "      ", "print_layer_summary", "(", "layer", ")", "\n", "", "", "print_fn", "(", "'='", "*", "line_length", ")", "\n", "\n", "def", "count_params", "(", "variables", ")", ":", "\n", "    ", "return", "np", ".", "sum", "(", "[", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "dtype", "=", "np", ".", "int32", ")", "for", "v", "in", "variables", "]", ")", "\n", "\n", "", "trainable_count", "=", "count_params", "(", "model", ".", "trainable_weights", ")", "\n", "non_trainable_count", "=", "count_params", "(", "model", ".", "non_trainable_weights", ")", "\n", "\n", "print_fn", "(", "'Total params: {:,}'", ".", "format", "(", "int", "(", "trainable_count", "+", "non_trainable_count", ")", ")", ")", "\n", "print_fn", "(", "'Trainable params: {:,}'", ".", "format", "(", "trainable_count", ")", ")", "\n", "print_fn", "(", "'Non-trainable params: {:,}'", ".", "format", "(", "non_trainable_count", ")", ")", "\n", "print_fn", "(", "'_'", "*", "line_length", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs": [[22, 28], ["None"], "function", ["None"], ["def", "is_gs", "(", "filepath", ")", ":", "\n", "  ", "\"\"\"\n  :param filepath:  file path\n  :return:          True, if filepath is for Google Cloud Storage, otherwise False\n  \"\"\"", "\n", "return", "filepath", "[", "0", ":", "5", "]", "==", "\"gs://\"", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join": [[30, 37], ["gspath.is_gs", "os.path.join", "list"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join"], ["", "def", "join", "(", "path", ",", "*", "paths", ")", ":", "\n", "  ", "if", "is_gs", "(", "path", ")", ":", "\n", "# add '/' if needed", "\n", "    ", "sub_paths", "=", "[", "sub_path", "+", "(", "''", "if", "sub_path", "[", "-", "1", "]", "==", "'/'", "else", "'/'", ")", "for", "sub_path", "in", "[", "path", "]", "+", "list", "(", "paths", ")", "[", ":", "-", "1", "]", "]", "\n", "return", "''", ".", "join", "(", "sub_paths", ")", "+", "paths", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "    ", "return", "os", ".", "path", ".", "join", "(", "path", ",", "*", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.split": [[39, 49], ["gspath.is_gs", "gspath._split_gs_path", "os.path.isdir", "os.path.split"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._split_gs_path", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.split"], ["", "", "def", "split", "(", "filepath", ")", ":", "\n", "  ", "\"\"\"Split full path in (folder, filename) \"\"\"", "\n", "if", "is_gs", "(", "filepath", ")", ":", "\n", "    ", "bucket", ",", "folder", ",", "filename", "=", "_split_gs_path", "(", "filepath", ")", "\n", "return", "\"gs://\"", "+", "bucket", "+", "\"/\"", "+", "folder", "+", "'/'", ",", "filename", "\n", "", "else", ":", "\n", "    ", "if", "os", ".", "path", ".", "isdir", "(", "filepath", ")", ":", "\n", "      ", "return", "filepath", ",", "None", "\n", "", "else", ":", "\n", "      ", "return", "os", ".", "path", ".", "split", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.findall": [[51, 60], ["gspath.is_gs", "tensorflow.io.gfile.glob", "glob.glob"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs"], ["", "", "", "def", "findall", "(", "filepath_pattern", ")", ":", "\n", "  ", "\"\"\"Return list of all files which match the glob pattern\"\"\"", "\n", "if", "is_gs", "(", "filepath_pattern", ")", ":", "\n", "# regex_pattern = _glob_to_re(filepath_pattern)", "\n", "# bucket = _get_bucket(filepath_pattern)", "\n", "# return [blob for blob in _list_gs_objects(bucket) if re.search(regex_pattern, blob) is not None]", "\n", "    ", "return", "tf", ".", "io", ".", "gfile", ".", "glob", "(", "filepath_pattern", ")", "\n", "", "else", ":", "\n", "    ", "return", "glob", ".", "glob", "(", "filepath_pattern", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.mkdir": [[62, 67], ["gspath.is_gs", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.mkdir"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "  ", "\"\"\"Makes new dir\"\"\"", "\n", "if", "not", "is_gs", "(", "path", ")", ":", "\n", "    ", "return", "os", ".", "mkdir", "(", "path", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_dir": [[69, 75], ["gspath.is_gs", "tensorflow.io.gfile.isdir", "os.path.isdir"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs"], ["", "def", "is_dir", "(", "filepath", ")", ":", "\n", "  ", "\"\"\"Checks if this is a directory that exists\"\"\"", "\n", "if", "is_gs", "(", "filepath", ")", ":", "\n", "    ", "return", "tf", ".", "io", ".", "gfile", ".", "isdir", "(", "filepath", ")", "\n", "", "else", ":", "\n", "    ", "return", "os", ".", "path", ".", "isdir", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write": [[77, 86], ["gspath.is_gs", "gspath._split_gs_path", "gspath._upload_blob", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._split_gs_path", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._upload_blob", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write"], ["", "", "def", "write", "(", "filepath", ",", "data_str", ")", ":", "\n", "  ", "\"\"\"Write string to file\"\"\"", "\n", "if", "is_gs", "(", "filepath", ")", ":", "\n", "    ", "bucket", ",", "folder", ",", "filename", "=", "_split_gs_path", "(", "filepath", ")", "\n", "_upload_blob", "(", "bucket", ",", "folder", "+", "\"/\"", "+", "filename", ",", "data_str", ")", "\n", "", "else", ":", "\n", "    ", "with", "open", "(", "filepath", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "data_str", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._split_gs_path": [[88, 101], ["gspath.is_gs", "filepath_no_prefix.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_gs", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.split"], ["", "def", "_split_gs_path", "(", "filepath", ")", ":", "\n", "  ", "\"\"\"Breaks filepath into 1. gs:// 2. bucket 3. folder and 4. filename\n  \"\"\"", "\n", "assert", "is_gs", "(", "filepath", ")", ",", "\"{} is not a Google Cloud Storage path\"", ".", "format", "(", "filepath", ")", "\n", "\n", "filepath_no_prefix", "=", "filepath", "[", "5", ":", "]", "\n", "filepath_split", "=", "filepath_no_prefix", ".", "split", "(", "'/'", ")", "\n", "bucket", "=", "filepath_split", "[", "0", "]", "\n", "\n", "folder", "=", "'/'", ".", "join", "(", "filepath_split", "[", "1", ":", "-", "1", "]", ")", "if", "len", "(", "filepath_split", ")", ">", "2", "else", "''", "\n", "filename", "=", "filepath_split", "[", "-", "1", "]", "if", "len", "(", "filepath_split", ")", ">", "1", "and", "filepath_split", "[", "-", "1", "]", "!=", "''", "else", "None", "\n", "\n", "return", "bucket", ",", "folder", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._get_bucket": [[103, 106], ["gspath._split_gs_path"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._split_gs_path"], ["", "def", "_get_bucket", "(", "filepath", ")", ":", "\n", "  ", "bucket", ",", "_", ",", "_", "=", "_split_gs_path", "(", "filepath", ")", "\n", "return", "bucket", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath._upload_blob": [[108, 115], ["google.cloud.storage.Client", "storage.Client.get_bucket", "storage_client.get_bucket.blob", "bucket.blob.upload_from_string"], "function", ["None"], ["", "def", "_upload_blob", "(", "bucket_name", ",", "destination_blob_name", ",", "data_str", ")", ":", "\n", "  ", "\"\"\"Uploads a file to the bucket.\"\"\"", "\n", "storage_client", "=", "storage", ".", "Client", "(", ")", "\n", "bucket", "=", "storage_client", ".", "get_bucket", "(", "bucket_name", ")", "\n", "blob", "=", "bucket", ".", "blob", "(", "destination_blob_name", ")", "\n", "\n", "blob", ".", "upload_from_string", "(", "data_str", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.load_audio": [[16, 63], ["print", "tensorflow.io.gfile.GFile", "tf.io.gfile.GFile.read", "io.BytesIO", "soundfile.read", "librosa.resample", "numpy.reshape", "numpy.max", "numpy.swapaxes", "numpy.abs"], "function", ["None"], ["def", "load_audio", "(", "audio_file", ",", "sample_rate", "=", "None", ",", "mono", "=", "False", ",", "max_wav", "=", "0.999", ")", ":", "\n", "  ", "\"\"\"Loads and decodes audio file into 32-bit floating-point wav format\n\n  Args:\n    audio_file:            audio file\n    sample_rate:           if specified, re-samples decoded audio to this rate\n    max_wav:               normalizes audio signal, such that max_wav_value is the maximum wav value (default is 1.0)\n\n  Returns:                 normalized (-1..1) audio sample  [samples_n, channels_n] and\n                           output sample_rate\n  \"\"\"", "\n", "print", "(", "'reading <{}>...'", ".", "format", "(", "audio_file", ")", ")", "\n", "\n", "# allow download from gs://", "\n", "audio_file_gfile", "=", "tf", ".", "io", ".", "gfile", ".", "GFile", "(", "audio_file", ",", "mode", "=", "'rb'", ")", "\n", "audio_file_string", "=", "audio_file_gfile", ".", "read", "(", ")", "\n", "audio_file_stream", "=", "io", ".", "BytesIO", "(", "audio_file_string", ")", "\n", "\n", "data", ",", "input_sample_rate", "=", "soundfile", ".", "read", "(", "audio_file_stream", ",", "dtype", "=", "'float32'", ")", "\n", "# librosa needs shape = (nb_channels, nb_samples)", "\n", "data", "=", "data", ".", "T", "\n", "wav", "=", "librosa", ".", "resample", "(", "data", ",", "input_sample_rate", ",", "sample_rate", ")", "\n", "\n", "# old code:", "\n", "# wav, sample_rate = librosa.core.load(audio_file_stream, sr=sample_rate, mono=mono)", "\n", "\n", "if", "wav", ".", "ndim", "==", "2", ":", "\n", "    ", "wav", "=", "np", ".", "swapaxes", "(", "wav", ",", "0", ",", "1", ")", "\n", "\n", "", "assert", "wav", ".", "dtype", "==", "np", ".", "float32", "\n", "\n", "# At this point, wav is np.float32 either [nsamps,] or [nsamps, nch].", "\n", "# We want [samples_n, channels_n] to mimic 2D shape of spectral feats.", "\n", "if", "wav", ".", "ndim", "==", "1", ":", "\n", "    ", "nsamps", "=", "wav", ".", "shape", "[", "0", "]", "\n", "actual_channels", "=", "1", "\n", "", "else", ":", "\n", "    ", "nsamps", ",", "actual_channels", "=", "wav", ".", "shape", "\n", "", "wav", "=", "np", ".", "reshape", "(", "wav", ",", "[", "nsamps", ",", "actual_channels", "]", ")", "\n", "\n", "# normalization needed: librosa does not normalize properly!!!", "\n", "# note: keep balance between stereo channels!", "\n", "factor", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "wav", ")", ")", "\n", "if", "factor", ">", "0", ":", "\n", "    ", "wav", "=", "wav", "*", "max_wav", "/", "factor", "\n", "\n", "", "return", "wav", ",", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.save_audio": [[65, 80], ["numpy.clip", "out_format.lower", "scipy.write", "soundfile.write"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.write"], ["", "def", "save_audio", "(", "audio_filepath", ",", "wave_data", ",", "sample_rate", ",", "out_format", "=", "'wav'", ")", ":", "\n", "  ", "\"\"\"Write audio data to file. The audio data should be in 32-bit floating-point wav format.\n\n  :param audio_filepath:   filename to save the audio sample\n  :param wave_data:        normalized (-1..1) sample data [samples_n, channels_n]\n  :param sample_rate:      sample rate\n  :param out_format        output audio file format\n  :return:                 no return value\n  \"\"\"", "\n", "wave_data", "=", "np", ".", "clip", "(", "wave_data", ",", "-", "1.0", ",", "1.0", ")", "\n", "if", "out_format", ".", "lower", "(", ")", "==", "'wav'", ":", "\n", "    ", "wavfile", ".", "write", "(", "audio_filepath", ",", "sample_rate", ",", "wave_data", ")", "\n", "", "else", ":", "\n", "    ", "soundfile", ".", "write", "(", "audio_filepath", ",", "wave_data", ",", "sample_rate", ",", "out_format", ")", "\n", "", "return", "\n", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.tf_ops.reduce_mean_over_replica_group": [[8, 27], ["tensorflow.distribute.get_replica_context", "tf.distribute.get_replica_context.all_reduce", "tensorflow.cast"], "function", ["None"], ["@", "tf", ".", "function", "\n", "def", "reduce_mean_over_replica_group", "(", "x", ",", "device_group_size", ")", ":", "\n", "  ", "\"\"\"\n  Computes the mean over a group of replicas.\n  Should be executed in the non-default replica context (i.e. on a specific replica of a tf.distributed.Strategy)\n\n  :param x:                      A tensor\n  :param device_group_size:      number of other replicas over which to take the average\n  :return:                       tensor which is the average over device_group_size replicas which are in the same group\n\n  :raises InvalidArgumentError:  when total number of devices in the replica context is not a multiple of device_group_size\n  \"\"\"", "\n", "replica_context", "=", "tf", ".", "distribute", ".", "get_replica_context", "(", ")", "\n", "\n", "if", "replica_context", "is", "not", "None", ":", "\n", "    ", "x_ave", "=", "replica_context", ".", "all_reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "x", ")", "/", "tf", ".", "cast", "(", "device_group_size", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "return", "x_ave", "\n", "", "else", ":", "\n", "    ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.tf_ops.reduce_mean_over_replicas_tpu": [[29, 31], ["tensorflow.compat.v1.tpu.cross_replica_sum", "tensorflow.cast"], "function", ["None"], ["", "", "def", "reduce_mean_over_replicas_tpu", "(", "x", ",", "devices_n", ")", ":", "\n", "  ", "return", "tf", ".", "compat", ".", "v1", ".", "tpu", ".", "cross_replica_sum", "(", "x", ")", "/", "tf", ".", "cast", "(", "devices_n", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.__init__": [[28, 85], ["modeldriver.DistributedModelDriver.strategy.scope", "print", "print", "print", "print", "print", "print", "print", "print", "model_factory.build_model", "tensorflow.keras.optimizers.Adam", "tensorflow.keras.optimizers.Adam", "print", "tensorflow.train.Checkpoint", "utils.gspath.join", "tensorflow.train.CheckpointManager", "model.audiorepresentation.AudioRepresentation", "print", "tensorflow.keras.mixed_precision.experimental.Policy", "tensorflow.keras.mixed_precision.experimental.set_policy", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "tensorflow.keras.mixed_precision.experimental.global_policy", "tensorflow.keras.mixed_precision.experimental.global_policy", "datetime.datetime.utcnow", "datetime.datetime.utcnow", "datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.build_model", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join"], ["  ", "def", "__init__", "(", "self", ",", "strategy", ",", "model_factory", ":", "mp3net", ".", "MP3netFactory", ",", "stage", ",", "mode", ",", "summary_dir", ",", "args", ")", ":", "\n", "    ", "\"\"\"Model Driver owns the actual TranceModel object and takes care of running it on a distributed environment\n\n    :param strategy:\n    :param args:             user arguments\n    \"\"\"", "\n", "self", ".", "strategy", "=", "strategy", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "global_batch_size", "=", "self", ".", "args", ".", "batch_size", "\n", "\n", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "# use bfloat16 on tpu", "\n", "      ", "if", "self", ".", "args", ".", "runtime_tpu", ":", "\n", "# note: on GPUs we could use 'mixed_float32' but", "\n", "# then we would need to wrap the optimizers in LossScaleOptimizer! (not needed for bfloat32)", "\n", "        ", "policy", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "Policy", "(", "'mixed_bfloat16'", ")", "\n", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "set_policy", "(", "policy", ")", "\n", "\n", "", "print", "(", "f'Precision:'", ")", "\n", "print", "(", "f'  Compute dtype:  {tf.keras.mixed_precision.experimental.global_policy().compute_dtype}'", ")", "\n", "print", "(", "f'  Variable dtype: {tf.keras.mixed_precision.experimental.global_policy().variable_dtype}'", ")", "\n", "print", "(", ")", "\n", "print", "(", "f'Discriminator/Generator balance:'", ")", "\n", "print", "(", "f'  {self.args.n_discr} discriminator updates for each generator update'", ")", "\n", "print", "(", ")", "\n", "\n", "# build keras model", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Building model...\"", ")", "\n", "self", ".", "model", "=", "model_factory", ".", "build_model", "(", "stage", ",", "self", ".", "global_batch_size", ",", "mode", ")", "\n", "\n", "# set up optimizers", "\n", "#   https://towardsdatascience.com/adam-latest-trends-in-deep-learning-optimization-6be9a291375c", "\n", "# SpecGAN lr=1e-4, beta_1=0.5, beta_2=0.9  <=== works best", "\n", "# ProGAN  lr=1e-3, beta_1=0.1, beta_2=0.99", "\n", "# BigGAN  lr_G=1e-4 lr_D=4e-4 (for batch<1024), beta_1=0.0, beta_2=0.999", "\n", "# https://cs231n.github.io/neural-networks-3/", "\n", "self", ".", "discriminator_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "1e-4", ",", "beta_1", "=", "0.5", ",", "beta_2", "=", "0.9", ")", "\n", "self", ".", "generator_optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "1e-4", ",", "beta_1", "=", "0.5", ",", "beta_2", "=", "0.9", ")", "\n", "\n", "# set up checkpoint manager", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Setting up checkpoint manager...\"", ")", "\n", "self", ".", "checkpoint", "=", "tf", ".", "train", ".", "Checkpoint", "(", "generator_optimizer", "=", "self", ".", "generator_optimizer", ",", "\n", "discriminator_optimizer", "=", "self", ".", "discriminator_optimizer", ",", "\n", "generator", "=", "self", ".", "model", ".", "generator", ",", "\n", "discriminator", "=", "self", ".", "model", ".", "discriminator", ",", "\n", "song_counter", "=", "self", ".", "model", ".", "song_counter", ")", "# what to save", "\n", "self", ".", "checkpoint_dir", "=", "gspath", ".", "join", "(", "args", ".", "training_dir", ",", "\"stage-{}\"", ".", "format", "(", "self", ".", "model", ".", "stage", ")", ")", "\n", "self", ".", "checkpoint_manager", "=", "tf", ".", "train", ".", "CheckpointManager", "(", "self", ".", "checkpoint", ",", "self", ".", "checkpoint_dir", ",", "max_to_keep", "=", "5", ",", "\n", "checkpoint_name", "=", "\"stage-{}-ckpt\"", ".", "format", "(", "self", ".", "model", ".", "stage", ")", ")", "\n", "self", ".", "checkpoint_freq", "=", "args", ".", "train_checkpoint_freq", "\n", "\n", "# set up summary", "\n", "self", ".", "summary_audio_repr", "=", "AudioRepresentation", "(", "self", ".", "model", ".", "sample_rate", ",", "self", ".", "model", ".", "freq_n", ",", "compute_dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "summary_freq", "=", "args", ".", "summary_freq", "\n", "self", ".", "summary_dir", "=", "summary_dir", "\n", "self", ".", "summary_writer", "=", "None", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Summaries are written to {self.summary_dir}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.__del__": [[86, 90], ["modeldriver.DistributedModelDriver.summary_writer.close"], "methods", ["None"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "# make sure to close summary writer", "\n", "    ", "if", "self", ".", "summary_writer", "is", "not", "None", ":", "\n", "      ", "self", ".", "summary_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_latest_checkpoint": [[91, 101], ["modeldriver.DistributedModelDriver.strategy.scope", "tensorflow.train.latest_checkpoint", "modeldriver.DistributedModelDriver.checkpoint.restore().expect_partial", "print", "print", "modeldriver.DistributedModelDriver.checkpoint.restore", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow", "datetime.datetime.utcnow"], "methods", ["None"], ["", "", "def", "load_latest_checkpoint", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "# fetch latest checkpoint if any (and only complain if we find stuff in tf-graph which is not in checkpoint)", "\n", "      ", "latest_checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "self", ".", "checkpoint_dir", ")", "\n", "if", "latest_checkpoint", ":", "\n", "        ", "self", ".", "checkpoint", ".", "restore", "(", "latest_checkpoint", ")", ".", "expect_partial", "(", ")", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Restored from {latest_checkpoint}\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: No checkpoint found for stage {self.model.stage}: initializing from scratch in stage {self.model.stage}\"", ")", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_from_model_weights": [[102, 123], ["modeldriver.DistributedModelDriver.strategy.scope", "print", "new_model_layer.get_weights", "name_mapping", "print", "new_model_layer.set_weights", "print", "tensorflow.shape().numpy", "tensorflow.shape().numpy", "tensorflow.shape().numpy", "new_model_layer.get_weights", "new_model_layer.get_weights", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "load_from_model_weights", "(", "self", ",", "weights", ",", "name_mapping", ")", ":", "\n", "    ", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "print", "(", "\"Copying weights from previous stage {}\"", ".", "format", "(", "self", ".", "model", ".", "stage", ",", "self", ".", "model", ".", "stage", "-", "1", ")", ")", "\n", "# copy weights from earlier model", "\n", "old_g_weights", ",", "old_d_weights", "=", "weights", "\n", "old_weights", "=", "{", "**", "old_g_weights", ",", "**", "old_d_weights", "}", "# merge dicts", "\n", "\n", "for", "new_model_layer", "in", "self", ".", "model", ".", "generator", ".", "layers", "+", "self", ".", "model", ".", "discriminator", ".", "layers", ":", "\n", "        ", "if", "new_model_layer", ".", "get_weights", "(", ")", ":", "\n", "\n", "# translate new layer name to old layer name", "\n", "          ", "equivalent_old_model_layer_name", "=", "name_mapping", "(", "new_model_layer", ".", "name", ")", "\n", "\n", "# copy weights, if equivalent old layer", "\n", "if", "equivalent_old_model_layer_name", "in", "old_weights", ":", "\n", "            ", "print", "(", "\"  {0} {1} <-- old {2} {3}\"", ".", "format", "(", "new_model_layer", ".", "name", ",", "[", "tf", ".", "shape", "(", "g_weights", ")", ".", "numpy", "(", ")", "for", "g_weights", "in", "new_model_layer", ".", "get_weights", "(", ")", "]", ",", "\n", "equivalent_old_model_layer_name", ",", "[", "tf", ".", "shape", "(", "g_weights_old", ")", ".", "numpy", "(", ")", "for", "g_weights_old", "in", "old_weights", "[", "equivalent_old_model_layer_name", "]", "]", ")", ")", "\n", "new_model_layer", ".", "set_weights", "(", "old_weights", "[", "equivalent_old_model_layer_name", "]", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"  {0} {1} <-- new weights\"", ".", "format", "(", "new_model_layer", ".", "name", ",", "[", "tf", ".", "shape", "(", "g_weights", ")", ".", "numpy", "(", ")", "for", "g_weights", "in", "new_model_layer", ".", "get_weights", "(", ")", "]", ")", ")", "\n", "", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.print_model_summary": [[124, 140], ["modeldriver.DistributedModelDriver.strategy.scope", "print", "print", "print", "print", "print", "print", "print", "print", "modeldriver.DistributedModelDriver.model.summary", "modeldriver.DistributedModelDriver.discriminator_optimizer.iterations.numpy", "modeldriver.DistributedModelDriver.model.song_counter.numpy", "modeldriver.DistributedModelDriver.model.song_counter.numpy", "modeldriver.DistributedModelDriver.model.song_counter.numpy"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.summary"], ["", "def", "print_model_summary", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "print", "(", ")", "\n", "print", "(", "\"Already completed iterations in stage {0}  = {1:11,}\"", ".", "format", "(", "self", ".", "model", ".", "stage", ",", "\n", "self", ".", "discriminator_optimizer", ".", "iterations", ".", "numpy", "(", ")", ")", ")", "\n", "print", "(", "\"Total iterations to complete stage {0}     = {1:11,}\"", ".", "format", "(", "self", ".", "model", ".", "stage", ",", "\n", "self", ".", "discriminator_optimizer", ".", "iterations", "+", "(", "\n", "self", ".", "model", ".", "stage_total_songs", "-", "self", ".", "model", ".", "song_counter", ".", "numpy", "(", ")", ")", "/", "self", ".", "global_batch_size", ")", ")", "\n", "print", "(", "\"Remaining iterations to complete stage {0} = {1:11,.0f}\"", ".", "format", "(", "self", ".", "model", ".", "stage", ",", "(", "\n", "self", ".", "model", ".", "stage_total_songs", "-", "self", ".", "model", ".", "song_counter", ".", "numpy", "(", ")", ")", "/", "self", ".", "global_batch_size", ")", ")", "\n", "print", "(", ")", "\n", "print", "(", "f\"Total songs to listen to in stage {self.model.stage}      = {self.model.stage_total_songs:11,}\"", ")", "\n", "print", "(", "f\"Songs already listened to in stage {self.model.stage}     = {self.model.song_counter.numpy():11,.0f}\"", ")", "\n", "print", "(", ")", "\n", "\n", "self", ".", "model", ".", "summary", "(", "line_length", "=", "120", ")", "\n", "# self.model.generator.summary(line_length=180)", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.training_loop": [[146, 208], ["modeldriver.DistributedModelDriver.strategy.scope", "modeldriver.DistributedModelDriver.strategy.experimental_distribute_datasets_from_function", "tensorflow.cast", "modeldriver.DistributedModelDriver._weights_by_layer_name", "modeldriver.DistributedModelDriver._weights_by_layer_name", "model.dataloader.load_dataset", "tensorflow.greater_equal", "modeldriver.DistributedModelDriver.write_summary_gan", "modeldriver.DistributedModelDriver.train_step", "tensorflow.cast", "modeldriver.DistributedModelDriver.model.song_counter.assign_add", "print", "modeldriver.DistributedModelDriver.checkpoint_manager.save", "print", "print", "subprocess.Popen", "tensorflow.math.floormod", "tensorflow.math.floormod", "tensorflow.math.floormod", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow", "datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._weights_by_layer_name", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._weights_by_layer_name", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.dataloader.load_dataset", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.write_summary_gan", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.train_step"], ["", "", "def", "training_loop", "(", "self", ",", "input_filenames", ")", ":", "\n", "    ", "\"\"\"\n    :param input_filenames:  file paths of pre-processed audio files\n    :return:\n    \"\"\"", "\n", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "# get the training data", "\n", "      ", "def", "dataset_fn", "(", "distributed_context", ")", ":", "\n", "        ", "spectrogram_dataset", "=", "dataloader", ".", "load_dataset", "(", "\n", "distributed_context", ",", "\n", "input_filenames", ",", "\n", "global_batch_size", "=", "self", ".", "global_batch_size", ",", "\n", "slice_len", "=", "self", ".", "model", ".", "blocks_n", ",", "\n", "slice_hop", "=", "self", ".", "model", ".", "blocks_n", ",", "\n", "freq_n", "=", "self", ".", "model", ".", "freq_n", ",", "\n", "channels_n", "=", "self", ".", "model", ".", "channels_n", ",", "\n", "repeat", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "shuffle_buffer_size", "=", "self", ".", "args", ".", "data_shuffle_buffer_size", ",", "\n", "tpu", "=", "self", ".", "args", ".", "runtime_tpu", ")", "\n", "return", "spectrogram_dataset", "\n", "\n", "# now distribute the dataset over devices", "\n", "# note: The tf.data.Dataset returned by dataset_fn should have a per_replica_batch_size", "\n", "#   (see https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy)", "\n", "# experimental_distribute_datasets_from_function() returns a DataSet of PerReplica objects ;-)", "\n", "", "spectrogram_dataset_distr", "=", "self", ".", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", "\n", "\n", "# Main training loop runs on CPU!!!", "\n", "step", "=", "tf", ".", "cast", "(", "self", ".", "discriminator_optimizer", ".", "iterations", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "for", "reals_batch_per_replica", "in", "spectrogram_dataset_distr", ":", "\n", "# real_mdct_norm_batch is a PerReplica object with per replica a batch with the per_replica_batch_size", "\n", "\n", "        ", "if", "tf", ".", "math", ".", "floormod", "(", "step", ",", "self", ".", "summary_freq", ")", "==", "0", "and", "step", ">", "0", ":", "\n", "# write summary (not at same time as training, since it blows up the TPU...)", "\n", "          ", "self", ".", "write_summary_gan", "(", "reals_batch_per_replica", ",", "step", ")", "\n", "step", "+=", "1", "# so for next batch from dataset, it takes the train branch of this if statement", "\n", "", "else", ":", "\n", "# train", "\n", "          ", "step", "=", "self", ".", "train_step", "(", "reals_batch_per_replica", ")", "\n", "step", "=", "tf", ".", "cast", "(", "step", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "# song_counter is not a distributed variable, so update needs to happen on host (not on replicas!)", "\n", "self", ".", "model", ".", "song_counter", ".", "assign_add", "(", "self", ".", "global_batch_size", ")", "\n", "\n", "# save checkpoint", "\n", "", "if", "tf", ".", "math", ".", "floormod", "(", "step", ",", "self", ".", "checkpoint_freq", ")", "==", "0", "and", "step", ">", "0", ":", "\n", "          ", "print", "(", "f'{datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}: Step {step}, saving checkpoint'", ",", "end", "=", "''", ")", "\n", "checkpoint_save_path", "=", "self", ".", "checkpoint_manager", ".", "save", "(", ")", "\n", "print", "(", "f' at {checkpoint_save_path}... done'", ")", "\n", "\n", "# profile the TPU (needs to be run in Colab which has the TPU)", "\n", "", "if", "self", ".", "args", ".", "runtime_tpu", "and", "self", ".", "args", ".", "tpu_profiling", "and", "tf", ".", "math", ".", "floormod", "(", "step", ",", "51", ")", "==", "0", ":", "\n", "          ", "trace_duration_ms", "=", "6", "*", "1000", "# needs to be long enough to capture a few training steps", "\n", "trace_launch_s", "=", "10", "\n", "print", "(", "f'{datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}: Step {step}, launching trace in {trace_launch_s} seconds...'", ")", "\n", "subprocess", ".", "Popen", "(", "f\"sleep {trace_launch_s} && capture_tpu_profile --logdir={self.args.training_dir} --duration_ms={trace_duration_ms} --service_addr={os.environ['COLAB_TPU_ADDR']}\"", ",", "shell", "=", "True", ")", "\n", "\n", "# exit condition", "\n", "", "if", "tf", ".", "greater_equal", "(", "self", ".", "model", ".", "song_counter", ",", "self", ".", "model", ".", "stage_total_songs", ")", ":", "\n", "          ", "break", "\n", "\n", "", "", "", "return", "self", ".", "_weights_by_layer_name", "(", "self", ".", "model", ".", "generator", ")", ",", "self", ".", "_weights_by_layer_name", "(", "self", ".", "model", ".", "discriminator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.train_step": [[209, 224], ["modeldriver.DistributedModelDriver.strategy.run", "modeldriver.DistributedModelDriver.strategy.reduce"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "train_step", "(", "self", ",", "reals", ")", ":", "\n", "    ", "\"\"\"Crucial that this is a separate function with @tf.function\n       otherwise it won't run on a GPU. But not important for TPU\n    \"\"\"", "\n", "# launch the TPU monster", "\n", "# strategy.run() returns PerReplica objects (dict-like structures) either use:", "\n", "# 1. experimental_local_results to get result per worker in tuple, or", "\n", "# 2. self.strategy.reduce() to reduce over workers, or", "\n", "# 3. direct dict structure of PerReplica object (see self._merge_batch_over_replicas(...))", "\n", "step_per_replica", "=", "self", ".", "strategy", ".", "run", "(", "self", ".", "train_step_per_replica_gan", ",", "args", "=", "(", "reals", ",", ")", ")", "\n", "\n", "# reduce step_per_replica over the different replicas", "\n", "step", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "MEAN", ",", "step_per_replica", ",", "axis", "=", "None", ")", "\n", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.train_step_per_replica_gan": [[226, 256], ["modeldriver.DistributedModelDriver.model.audio_representation.add_noise", "tensorflow.random.normal", "tape.gradient", "modeldriver.DistributedModelDriver.discriminator_optimizer.apply_gradients", "tensorflow.cast", "tensorflow.GradientTape", "modeldriver.DistributedModelDriver.model.d_loss", "zip", "tensorflow.random.normal", "tape.gradient", "modeldriver.DistributedModelDriver.generator_optimizer.apply_gradients", "tensorflow.GradientTape", "modeldriver.DistributedModelDriver.model.g_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.d_loss", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.g_loss"], ["", "def", "train_step_per_replica_gan", "(", "self", ",", "reals_with_stddev", ")", ":", "\n", "    ", "reals", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "masking_threshold", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "real_noised", "=", "self", ".", "model", ".", "audio_representation", ".", "add_noise", "(", "reals", ",", "masking_threshold", ")", "\n", "\n", "per_replica_batch_size", "=", "reals", ".", "shape", "[", "0", "]", "\n", "\n", "# discriminator training", "\n", "z_vector", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "(", "per_replica_batch_size", ",", "self", ".", "model", ".", "latent_dim", ")", ")", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "      ", "d_loss_ave", "=", "self", ".", "model", ".", "d_loss", "(", "z_vector", ",", "real_noised", ",", "training", "=", "True", ")", "\n", "", "discriminator_gradients", "=", "tape", ".", "gradient", "(", "d_loss_ave", ",", "self", ".", "model", ".", "discriminator", ".", "trainable_variables", ")", "\n", "# When apply_gradients is called within a distribution strategy scope, its behavior is modified.", "\n", "# Specifically, before applying gradients on each parallel instance during synchronous training,", "\n", "# it performs a sum-over-all-replicas of the gradients.", "\n", "# see: https://www.tensorflow.org/guide/distributed_training", "\n", "self", ".", "discriminator_optimizer", ".", "apply_gradients", "(", "zip", "(", "discriminator_gradients", ",", "self", ".", "model", ".", "discriminator", ".", "trainable_variables", ")", ")", "\n", "\n", "step", "=", "tf", ".", "cast", "(", "self", ".", "discriminator_optimizer", ".", "iterations", ",", "tf", ".", "float32", ")", "\n", "\n", "# generator training", "\n", "# less often than discriminator: only a very good discr can get the generator to move in the right direction!", "\n", "if", "self", ".", "discriminator_optimizer", ".", "iterations", "%", "self", ".", "args", ".", "n_discr", "==", "0", ":", "\n", "      ", "z_vector", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "(", "per_replica_batch_size", ",", "self", ".", "model", ".", "latent_dim", ")", ")", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "        ", "g_loss_ave", "=", "self", ".", "model", ".", "g_loss", "(", "z_vector", ",", "training", "=", "True", ")", "\n", "", "generator_gradients", "=", "tape", ".", "gradient", "(", "g_loss_ave", ",", "self", ".", "model", ".", "generator", ".", "trainable_variables", ")", "\n", "self", ".", "generator_optimizer", ".", "apply_gradients", "(", "zip", "(", "generator_gradients", ",", "self", ".", "model", ".", "generator", ".", "trainable_variables", ")", ")", "\n", "\n", "", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.get_distributed_dataset": [[260, 287], ["modeldriver.DistributedModelDriver.strategy.scope", "iter", "model.dataloader.load_dataset", "modeldriver.DistributedModelDriver.strategy.experimental_distribute_datasets_from_function"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.dataloader.load_dataset"], ["", "def", "get_distributed_dataset", "(", "self", ",", "input_filenames", ")", ":", "\n", "    ", "\"\"\"\n    :param input_filenames:  file paths of pre-processed audio files\n    :return:\n    \"\"\"", "\n", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "# get the training data", "\n", "      ", "def", "dataset_fn", "(", "distributed_context", ")", ":", "\n", "        ", "spectrogram_dataset", "=", "dataloader", ".", "load_dataset", "(", "\n", "distributed_context", ",", "\n", "input_filenames", ",", "\n", "global_batch_size", "=", "self", ".", "global_batch_size", ",", "\n", "slice_len", "=", "self", ".", "model", ".", "blocks_n", ",", "\n", "slice_hop", "=", "self", ".", "model", ".", "blocks_n", ",", "\n", "freq_n", "=", "self", ".", "model", ".", "freq_n", ",", "\n", "channels_n", "=", "self", ".", "model", ".", "channels_n", ",", "\n", "repeat", "=", "True", ",", "\n", "shuffle", "=", "True", ",", "\n", "shuffle_buffer_size", "=", "self", ".", "args", ".", "data_shuffle_buffer_size", ",", "\n", "tpu", "=", "self", ".", "args", ".", "runtime_tpu", ")", "\n", "return", "spectrogram_dataset", "\n", "\n", "# now distribute the dataset over devices", "\n", "# note: The tf.data.Dataset returned by dataset_fn should have a per_replica_batch_size", "\n", "#   (see https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy)", "\n", "# experimental_distribute_datasets_from_function() returns a DataSet of PerReplica objects ;-)", "\n", "", "return", "iter", "(", "self", ".", "strategy", ".", "experimental_distribute_datasets_from_function", "(", "dataset_fn", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.evaluation_loop": [[288, 301], ["modeldriver.DistributedModelDriver.strategy.scope", "distributed_dataset_iterator.get_next", "tensorflow.cast", "print", "modeldriver.DistributedModelDriver.write_summary_gan", "datetime.datetime.utcnow().strftime", "modeldriver.DistributedModelDriver.numpy", "datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.write_summary_gan"], ["", "", "def", "evaluation_loop", "(", "self", ",", "distributed_dataset_iterator", ")", ":", "\n", "    ", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "# Main training loop runs on CPU!!!", "\n", "      ", "reals_batch_per_replica", "=", "distributed_dataset_iterator", ".", "get_next", "(", ")", "\n", "# real_mdct_norm_batch is a PerReplica object with per replica a batch with the per_replica_batch_size", "\n", "\n", "step", "=", "tf", ".", "cast", "(", "self", ".", "discriminator_optimizer", ".", "iterations", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "\n", "# write summary", "\n", "print", "(", "f'{datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}: Writing summary for iteration {step.numpy()}...'", ")", "\n", "step", "=", "self", ".", "write_summary_gan", "(", "reals_batch_per_replica", ",", "step", ")", "\n", "\n", "", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.write_summary_gan": [[302, 407], ["print", "modeldriver.DistributedModelDriver.eval_step_gan", "modeldriver.DistributedModelDriver._merge_batch_over_replicas", "modeldriver.DistributedModelDriver.model.audio_representation.add_noise", "tensorflow.argsort", "tensorflow.argsort", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "numpy.set_printoptions", "print", "print", "print", "print", "tensorflow.cast", "tensorflow.cast", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "modeldriver.DistributedModelDriver.summary_audio_repr.tonality", "modeldriver.DistributedModelDriver.summary_audio_repr.tonality", "modeldriver.DistributedModelDriver.summary_writer.add_scalars", "modeldriver.DistributedModelDriver.summary_writer.add_scalar", "range", "modeldriver.DistributedModelDriver.summary_writer.add_histogram", "modeldriver.DistributedModelDriver.summary_writer.add_histogram", "modeldriver.DistributedModelDriver.summary_writer.add_scalars", "print", "modeldriver.DistributedModelDriver.summary_writer.close", "tensorboardX.SummaryWriter", "print", "tensorflow.squeeze", "tensorflow.squeeze", "wdistance.numpy", "d_loss.numpy", "grad_penalty.numpy", "drift.numpy", "g_loss.numpy", "tensorflow.reshape().numpy", "modeldriver.DistributedModelDriver.model.drown().numpy", "tensorflow.reduce_mean().numpy", "modeldriver.DistributedModelDriver.summary_writer.add_images", "modeldriver.DistributedModelDriver.summary_writer.add_images", "modeldriver.DistributedModelDriver.summary_writer.add_images", "modeldriver.DistributedModelDriver.summary_writer.add_images", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_audio", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_audio", "range", "fake_scores.numpy", "real_scores.numpy", "tensorflow.math.floormod", "tensorflow.reduce_mean().numpy", "tensorflow.reduce_mean().numpy", "[].numpy", "[].numpy", "[].numpy", "[].numpy", "utils.gspath.mkdir", "modeldriver.DistributedModelDriver.summary_writer.add_audio", "modeldriver.DistributedModelDriver.summary_writer.add_audio", "tensorflow.reduce_min().numpy", "tensorflow.reduce_max().numpy", "tensorflow.reduce_min().numpy", "tensorflow.reduce_max().numpy", "datetime.datetime.utcnow().strftime", "tensorflow.reduce_min", "tensorflow.reshape", "modeldriver.DistributedModelDriver.model.drown", "tensorflow.reduce_mean", "utils.gspath.is_dir", "wav_fake[].numpy", "wav_real_noise[].numpy", "utils.save_audio", "utils.save_audio", "datetime.datetime.utcnow().strftime", "tensorflow.where", "modeldriver.DistributedModelDriver.model.fade_in", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "utils.gspath.join", "wav_fake[].numpy", "utils.gspath.join", "wav_real_noise[].numpy", "tensorflow.reduce_min", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.reduce_max", "datetime.datetime.utcnow", "tensorflow.abs", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_spectrogram", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_spectrogram", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_spectrogram", "modeldriver.DistributedModelDriver.summary_audio_repr.repr_to_spectrogram", "datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.eval_step_gan", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.tonality", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.tonality", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.mkdir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.drown", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_dir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.save_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.save_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.fade_in", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram"], ["", "def", "write_summary_gan", "(", "self", ",", "reals_batch_per_replica", ",", "step", ")", ":", "\n", "# make sure a summery_writer is open", "\n", "    ", "if", "self", ".", "summary_writer", "is", "not", "None", "and", "tf", ".", "math", ".", "floormod", "(", "step", ",", "5", "*", "self", ".", "summary_freq", ")", "==", "0", "and", "step", ">", "0", ":", "\n", "      ", "self", ".", "summary_writer", ".", "close", "(", ")", "\n", "self", ".", "summary_writer", "=", "None", "\n", "\n", "", "if", "self", ".", "summary_writer", "is", "None", ":", "\n", "      ", "self", ".", "summary_writer", "=", "SummaryWriter", "(", "self", ".", "summary_dir", ")", "\n", "print", "(", "f'{datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}: Opened new summary file... '", ")", "\n", "\n", "", "print", "(", "f'{datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S.%f\")}: Step {step}, writing summary... '", ",", "end", "=", "''", ")", "\n", "\n", "# compute 1 full batch on all replicas and track the metrics", "\n", "loss_tuple", ",", "metric_tuple", ",", "score_tuple", ",", "fakes_tuple", "=", "self", ".", "eval_step_gan", "(", "reals_batch_per_replica", ")", "\n", "\n", "# unpack", "\n", "g_loss", ",", "d_loss", "=", "loss_tuple", "\n", "wdistance", ",", "grad_penalty", ",", "drift", "=", "metric_tuple", "\n", "fake_scores", ",", "real_scores", "=", "score_tuple", "\n", "fakes_all", ",", "fakes_all_noised", "=", "fakes_tuple", "\n", "\n", "# make the reals here", "\n", "reals_with_stddev", "=", "self", ".", "_merge_batch_over_replicas", "(", "reals_batch_per_replica", ")", "\n", "\n", "reals", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "masking_threshold", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "reals_noised", "=", "self", ".", "model", ".", "audio_representation", ".", "add_noise", "(", "reals", ",", "masking_threshold", ")", "\n", "\n", "# find best, worst and mid scores (best first, ie. higher scores first)", "\n", "fakes_sorted_by_index", "=", "tf", ".", "argsort", "(", "tf", ".", "squeeze", "(", "fake_scores", ")", ",", "direction", "=", "'DESCENDING'", ")", "\n", "reals_sorted_by_index", "=", "tf", ".", "argsort", "(", "tf", ".", "squeeze", "(", "real_scores", ")", ",", "direction", "=", "'DESCENDING'", ")", "\n", "n", "=", "fakes_sorted_by_index", ".", "shape", "[", "0", "]", "\n", "\n", "fakes", "=", "tf", ".", "gather", "(", "fakes_all", ",", "[", "fakes_sorted_by_index", "[", "0", "]", ",", "fakes_sorted_by_index", "[", "n", "//", "2", "]", ",", "fakes_sorted_by_index", "[", "-", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "reals", "=", "tf", ".", "gather", "(", "reals", ",", "[", "reals_sorted_by_index", "[", "0", "]", ",", "reals_sorted_by_index", "[", "n", "//", "2", "]", ",", "reals_sorted_by_index", "[", "-", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "reals_noise", "=", "tf", ".", "gather", "(", "reals_noised", ",", "[", "reals_sorted_by_index", "[", "0", "]", ",", "reals_sorted_by_index", "[", "n", "//", "2", "]", ",", "reals_sorted_by_index", "[", "-", "1", "]", "]", ",", "axis", "=", "0", ")", "\n", "\n", "np", ".", "set_printoptions", "(", "edgeitems", "=", "10", ",", "linewidth", "=", "500", ")", "\n", "print", "(", ")", "\n", "print", "(", "f\"Fakes[0, :, :, 0]:\"", ")", "\n", "print", "(", "fakes", "[", "0", ",", ":", ",", ":", ",", "0", "]", ")", "\n", "print", "(", "f\"Minimum = {tf.reduce_min(tf.where(fakes == 0, 1., tf.abs(fakes)))}\"", ")", "\n", "\n", "fakes", "=", "tf", ".", "cast", "(", "fakes", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "reals_noise", "=", "tf", ".", "cast", "(", "reals_noise", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# write scalars...", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'10_W_distance'", ",", "wdistance", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'20_loss/D'", ",", "d_loss", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'20_loss/D_GP'", ",", "grad_penalty", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'20_loss/D_drift'", ",", "drift", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "'20_loss/G'", ",", "g_loss", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "\"50_progression/Fade-in\"", ",", "tf", ".", "reshape", "(", "self", ".", "model", ".", "fade_in", "(", ")", ",", "shape", "=", "[", "]", ")", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "\"50_progression/Drown\"", ",", "self", ".", "model", ".", "drown", "(", ")", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "\n", "fake_tonality", "=", "self", ".", "summary_audio_repr", ".", "tonality", "(", "fakes", ")", "\n", "real_tonality", "=", "self", ".", "summary_audio_repr", ".", "tonality", "(", "reals_noise", ")", "\n", "self", ".", "summary_writer", ".", "add_scalars", "(", "\"70_tonality/fakes\"", ",", "{", "'0_ave'", ":", "tf", ".", "reduce_mean", "(", "fake_tonality", ")", ".", "numpy", "(", ")", ",", "\n", "'1_best'", ":", "tf", ".", "reduce_mean", "(", "fake_tonality", "[", "0", ":", "1", ",", ":", ",", ":", ",", ":", "]", ")", ".", "numpy", "(", ")", "}", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_scalar", "(", "\"70_tonality/reals\"", ",", "tf", ".", "reduce_mean", "(", "real_tonality", ")", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "\n", "# spectrogram", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "# fake spectrograms", "\n", "      ", "self", ".", "summary_writer", ".", "add_images", "(", "f'10_fake/{i}'", ",", "\n", "self", ".", "summary_audio_repr", ".", "repr_to_spectrogram", "(", "fakes", ")", "[", "i", ",", ":", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "dataformats", "=", "'HWC'", ")", "\n", "self", ".", "summary_writer", ".", "add_images", "(", "f'11_fake_intensity/{i}'", ",", "\n", "self", ".", "summary_audio_repr", ".", "repr_to_spectrogram", "(", "fakes", ",", "intensity", "=", "True", ",", "cmap", "=", "cm", ".", "CMRmap", ")", "[", "i", ",", ":", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "dataformats", "=", "'HWC'", ")", "\n", "\n", "# real spectrograms", "\n", "self", ".", "summary_writer", ".", "add_images", "(", "f'20_real_noise/{i}'", ",", "\n", "self", ".", "summary_audio_repr", ".", "repr_to_spectrogram", "(", "reals_noise", ")", "[", "i", ",", ":", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "dataformats", "=", "'HWC'", ")", "\n", "self", ".", "summary_writer", ".", "add_images", "(", "f'21_real_noise_intensity/{i}'", ",", "\n", "self", ".", "summary_audio_repr", ".", "repr_to_spectrogram", "(", "reals_noise", ",", "intensity", "=", "True", ",", "cmap", "=", "cm", ".", "CMRmap", ")", "[", "i", ",", ":", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "dataformats", "=", "'HWC'", ")", "\n", "\n", "# audio (only if model is in final stage)", "\n", "", "if", "self", ".", "model", ".", "freq_n", "==", "self", ".", "model", ".", "audio_representation", ".", "freq_n", ":", "\n", "      ", "infer_dir", "=", "self", ".", "args", ".", "infer_dir", "\n", "if", "infer_dir", "is", "not", "None", "and", "not", "gspath", ".", "is_dir", "(", "infer_dir", ")", ":", "\n", "        ", "gspath", ".", "mkdir", "(", "infer_dir", ")", "\n", "\n", "", "wav_fake", "=", "self", ".", "summary_audio_repr", ".", "repr_to_audio", "(", "fakes", ")", "\n", "wav_real_noise", "=", "self", ".", "summary_audio_repr", ".", "repr_to_audio", "(", "reals_noise", ")", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "        ", "self", ".", "summary_writer", ".", "add_audio", "(", "f'1_fake/{i}'", ",", "wav_fake", "[", "i", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "sample_rate", "=", "self", ".", "model", ".", "sample_rate", ")", "\n", "self", ".", "summary_writer", ".", "add_audio", "(", "f'2_real_noise/{i}'", ",", "wav_real_noise", "[", "i", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ",", "sample_rate", "=", "self", ".", "model", ".", "sample_rate", ")", "\n", "\n", "if", "infer_dir", "is", "not", "None", ":", "\n", "          ", "audio_utils", ".", "save_audio", "(", "gspath", ".", "join", "(", "infer_dir", ",", "f'fake_sample{i}.wav'", ")", ",", "wav_fake", "[", "i", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "sample_rate", "=", "self", ".", "model", ".", "sample_rate", ",", "out_format", "=", "'wav'", ")", "\n", "audio_utils", ".", "save_audio", "(", "gspath", ".", "join", "(", "infer_dir", ",", "f'real_noise_sample{i}.wav'", ")", ",", "wav_real_noise", "[", "i", ",", ":", ",", ":", "]", ".", "numpy", "(", ")", ",", "sample_rate", "=", "self", ".", "model", ".", "sample_rate", ",", "out_format", "=", "'wav'", ")", "\n", "\n", "# histograms", "\n", "", "", "", "self", ".", "summary_writer", ".", "add_histogram", "(", "'1_fake'", ",", "fake_scores", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "self", ".", "summary_writer", ".", "add_histogram", "(", "'2_real'", ",", "real_scores", ".", "numpy", "(", ")", ",", "global_step", "=", "step", ")", "\n", "\n", "self", ".", "summary_writer", ".", "add_scalars", "(", "f\"11_score\"", ",", "{", "'0_fake_min'", ":", "tf", ".", "reduce_min", "(", "fake_scores", ")", ".", "numpy", "(", ")", ",", "\n", "'1_fake_max'", ":", "tf", ".", "reduce_max", "(", "fake_scores", ")", ".", "numpy", "(", ")", ",", "\n", "'2_real_min'", ":", "tf", ".", "reduce_min", "(", "real_scores", ")", ".", "numpy", "(", ")", ",", "\n", "'3_real_max'", ":", "tf", ".", "reduce_max", "(", "real_scores", ")", ".", "numpy", "(", ")", "}", ",", "global_step", "=", "step", ")", "\n", "\n", "print", "(", "f'done'", ")", "\n", "\n", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.eval_step_gan": [[408, 437], ["modeldriver.DistributedModelDriver.strategy.run", "modeldriver.DistributedModelDriver.strategy.reduce", "modeldriver.DistributedModelDriver.strategy.reduce", "modeldriver.DistributedModelDriver.strategy.reduce", "modeldriver.DistributedModelDriver.strategy.reduce", "modeldriver.DistributedModelDriver.strategy.reduce", "modeldriver.DistributedModelDriver._merge_batch_over_replicas", "modeldriver.DistributedModelDriver._merge_batch_over_replicas", "modeldriver.DistributedModelDriver._merge_batch_over_replicas", "modeldriver.DistributedModelDriver._merge_batch_over_replicas"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas"], ["", "@", "tf", ".", "function", "\n", "def", "eval_step_gan", "(", "self", ",", "reals_batch_per_replica", ")", ":", "\n", "# launch the TPU monster", "\n", "    ", "(", "loss_tuple_per_replica", ",", "metric_tuple_per_replica", ",", "score_tuple_per_replica", ",", "\n", "fakes_tuple_per_replica", ")", "=", "self", ".", "strategy", ".", "run", "(", "self", ".", "eval_step_per_replica_gan", ",", "args", "=", "(", "reals_batch_per_replica", ",", ")", ")", "\n", "\n", "# unpack", "\n", "g_loss_per_replica", ",", "d_loss_per_replica", "=", "loss_tuple_per_replica", "\n", "wdistance_per_replica", ",", "grad_penalty_per_replica", ",", "drift_ave_per_replica", "=", "metric_tuple_per_replica", "\n", "fake_scores_per_replica", ",", "real_scores_per_replica", "=", "score_tuple_per_replica", "\n", "per_replica_fakes", ",", "per_replica_fakes_noise", "=", "fakes_tuple_per_replica", "\n", "\n", "# **SUM** over each replica (is already normalized to get a mean -- just like the gradients in apply_gradients())", "\n", "g_loss", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "g_loss_per_replica", ",", "axis", "=", "None", ")", "\n", "d_loss", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "d_loss_per_replica", ",", "axis", "=", "None", ")", "\n", "\n", "wdistance", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "wdistance_per_replica", ",", "axis", "=", "None", ")", "\n", "grad_penalty", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "grad_penalty_per_replica", ",", "axis", "=", "None", ")", "\n", "drift", "=", "self", ".", "strategy", ".", "reduce", "(", "tf", ".", "distribute", ".", "ReduceOp", ".", "SUM", ",", "drift_ave_per_replica", ",", "axis", "=", "None", ")", "\n", "\n", "# re-package", "\n", "loss_tuple", "=", "(", "g_loss", ",", "d_loss", ")", "\n", "metric_tuple", "=", "(", "wdistance", ",", "grad_penalty", ",", "drift", ")", "\n", "score_tuple", "=", "(", "self", ".", "_merge_batch_over_replicas", "(", "fake_scores_per_replica", ")", ",", "\n", "self", ".", "_merge_batch_over_replicas", "(", "real_scores_per_replica", ")", ")", "\n", "fakes_tuple", "=", "(", "self", ".", "_merge_batch_over_replicas", "(", "per_replica_fakes", ")", ",", "\n", "self", ".", "_merge_batch_over_replicas", "(", "per_replica_fakes_noise", ")", ")", "\n", "\n", "return", "loss_tuple", ",", "metric_tuple", ",", "score_tuple", ",", "fakes_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.eval_step_per_replica_gan": [[439, 452], ["modeldriver.DistributedModelDriver.model.audio_representation.add_noise", "tensorflow.random.normal", "modeldriver.DistributedModelDriver.model.d_loss_verbose", "modeldriver.DistributedModelDriver.model.g_loss_verbose"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.d_loss_verbose", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.g_loss_verbose"], ["", "def", "eval_step_per_replica_gan", "(", "self", ",", "reals_with_stddev", ")", ":", "\n", "    ", "reals", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "masking_threshold", "=", "reals_with_stddev", "[", ":", ",", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "real_noised", "=", "self", ".", "model", ".", "audio_representation", ".", "add_noise", "(", "reals", ",", "masking_threshold", ")", "\n", "\n", "per_replica_batch_size", "=", "reals", ".", "shape", "[", "0", "]", "\n", "\n", "# compute", "\n", "z_vector", "=", "tf", ".", "random", ".", "normal", "(", "shape", "=", "(", "per_replica_batch_size", ",", "self", ".", "model", ".", "latent_dim", ")", ")", "\n", "d_loss_ave", ",", "metric_tuple", ",", "score_tuple", ",", "fakes_tuple", "=", "self", ".", "model", ".", "d_loss_verbose", "(", "z_vector", ",", "real_noised", ",", "training", "=", "False", ")", "\n", "g_loss_ave", "=", "self", ".", "model", ".", "g_loss_verbose", "(", "z_vector", ",", "training", "=", "False", ")", "\n", "\n", "return", "(", "g_loss_ave", ",", "d_loss_ave", ")", ",", "metric_tuple", ",", "score_tuple", ",", "fakes_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.inference_loop": [[456, 505], ["utils.gspath.join", "utils.gspath.is_dir", "utils.gspath.mkdir", "modeldriver.DistributedModelDriver.strategy.scope", "modeldriver.DistributedModelDriver.infer_step", "datetime.datetime.utcnow().strftime", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "imageio.imwrite", "utils.save_audio", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_audio", "os.path.join", "datetime.datetime.utcnow", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver.model.audio_representation.repr_to_spectrogram", "modeldriver.DistributedModelDriver._collate_probe_tensors", "modeldriver.DistributedModelDriver._collate_probe_tensors", "modeldriver.DistributedModelDriver._collate_probe_tensors", "modeldriver.DistributedModelDriver._collate_probe_tensors", "modeldriver.DistributedModelDriver._collate_probe_tensors", "modeldriver.DistributedModelDriver.model.blur_layer", "modeldriver.DistributedModelDriver.model.blur_layer", "modeldriver.DistributedModelDriver._collate_probe_tensors", "tensorflow.sqrt", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.is_dir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.mkdir", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.infer_step", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.audio_utils.save_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_audio", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors"], ["", "def", "inference_loop", "(", "self", ")", ":", "\n", "    ", "inference_dir", "=", "gspath", ".", "join", "(", "self", ".", "args", ".", "training_dir", ",", "\"infer\"", ")", "\n", "if", "not", "gspath", ".", "is_dir", "(", "inference_dir", ")", ":", "\n", "      ", "gspath", ".", "mkdir", "(", "inference_dir", ")", "\n", "\n", "", "with", "self", ".", "strategy", ".", "scope", "(", ")", ":", "\n", "      ", "_", ",", "l1", ",", "l2", ",", "l3", ",", "l4", ",", "_", "=", "self", ".", "infer_step", "(", ")", "\n", "\n", "timestamp", "=", "datetime", ".", "datetime", ".", "utcnow", "(", ")", ".", "strftime", "(", "\"%Y%m%d%H%M%S\"", ")", "\n", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_64x16_deep_strip_mean_of_squares_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "l1", "**", "2", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_64x16_deep_strip_ave_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "tf", ".", "reduce_mean", "(", "l1", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_64x16_deep_strip_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "l1", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_256x32_deep_strip_ave_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "tf", ".", "reduce_mean", "(", "l2", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_256x32_deep_strip_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "l2", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_256x32_blurred_output_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "model", ".", "blur_layer", "(", "l4", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_256x32_blurred_output.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "model", ".", "blur_layer", "(", "l4", ")", ",", "\n", "intensity", "=", "False", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "\n", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_1024x64_output_strip_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "self", ".", "_collate_probe_tensors", "(", "l3", ")", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_1024x64_output.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "l4", ",", "\n", "intensity", "=", "False", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "imageio", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_1024x64_output_intensity.png'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "self", ".", "model", ".", "audio_representation", ".", "repr_to_spectrogram", "(", "l4", ",", "\n", "intensity", "=", "True", ")", "[", "0", ",", ":", ",", ":", "]", ")", "\n", "\n", "wave_data", "=", "self", ".", "model", ".", "audio_representation", ".", "repr_to_audio", "(", "l4", ")", "[", "0", ",", ":", ",", ":", "]", "\n", "\n", "audio_utils", ".", "save_audio", "(", "os", ".", "path", ".", "join", "(", "inference_dir", ",", "'l{0}_audio.wav'", ".", "format", "(", "timestamp", ")", ")", ",", "\n", "wave_data", ",", "self", ".", "model", ".", "audio_representation", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._collate_probe_tensors": [[509, 516], ["print", "tensorflow.pad", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.reduce_max", "tensorflow.constant", "tensorflow.reshape", "tensorflow.abs", "tensorflow.reduce_max", "tensorflow.abs", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "", "def", "_collate_probe_tensors", "(", "self", ",", "probe_tensor", ")", ":", "\n", "    ", "print", "(", "f\"tensor.shape = {probe_tensor.shape}; max = {tf.reduce_max(tf.abs(probe_tensor))}\"", ")", "\n", "probe_tensor", "=", "probe_tensor", "/", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "probe_tensor", ")", ")", "\n", "padded", "=", "tf", ".", "pad", "(", "probe_tensor", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "2", ",", "2", "]", ",", "[", "2", ",", "2", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "mode", "=", "'CONSTANT'", ",", "constant_values", "=", ".5", ")", "\n", "transposed", "=", "tf", ".", "transpose", "(", "padded", ",", "perm", "=", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "probe", "=", "tf", ".", "expand_dims", "(", "tf", ".", "reshape", "(", "transposed", ",", "shape", "=", "[", "tf", ".", "shape", "(", "transposed", ")", "[", "0", "]", ",", "-", "1", ",", "tf", ".", "shape", "(", "transposed", ")", "[", "3", "]", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "probe", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.infer_step": [[517, 524], ["modeldriver.DistributedModelDriver.strategy.run"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "infer_step", "(", "self", ")", ":", "\n", "# only written for inference on GPU, not TPU", "\n", "    ", "fakes_and_probes_per_replica", "=", "self", ".", "strategy", ".", "run", "(", "self", ".", "infer_step_per_replica", ")", "\n", "\n", "# no self._merge_batch_over_replicas() necessary for TPU is applied", "\n", "return", "fakes_and_probes_per_replica", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.infer_step_per_replica": [[526, 536], ["tensorflow.random.truncated_normal", "modeldriver.DistributedModelDriver.model.generator", "modeldriver.DistributedModelDriver.model.audio_representation.psychoacoustic_masking_ampl", "modeldriver.DistributedModelDriver.model.audio_representation.add_noise"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise"], ["", "def", "infer_step_per_replica", "(", "self", ")", ":", "\n", "    ", "number_of_fakes", "=", "3", "\n", "\n", "# create fakes", "\n", "z_vector", "=", "tf", ".", "random", ".", "truncated_normal", "(", "shape", "=", "(", "number_of_fakes", ",", "self", ".", "model", ".", "latent_dim", ")", ")", "\n", "fakes_and_probes", "=", "self", ".", "model", ".", "generator", "(", "z_vector", ",", "training", "=", "False", ")", "\n", "fakes_masking_threshold", "=", "self", ".", "model", ".", "audio_representation", ".", "psychoacoustic_masking_ampl", "(", "fakes_and_probes", ")", "\n", "fakes_and_probes_noised", "=", "self", ".", "model", ".", "audio_representation", ".", "add_noise", "(", "fakes_and_probes", ",", "fakes_masking_threshold", ")", "\n", "\n", "return", "fakes_and_probes_noised", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._merge_batch_over_replicas": [[537, 550], ["tensorflow.reshape", "len", "tensorflow.stack", "per_replica_tensor.values[].shape.as_list", "per_replica_tensor.values[].shape.as_list"], "methods", ["None"], ["", "def", "_merge_batch_over_replicas", "(", "self", ",", "per_replica_tensor", ")", ":", "\n", "    ", "if", "self", ".", "strategy", ".", "num_replicas_in_sync", ">", "1", ":", "\n", "# per_replica_tensor is a PerReplica object (dict-like) of tensors (one tensor per replica),", "\n", "# so we stack them along the 0th dimension (batch) of the tensors itself", "\n", "      ", "if", "len", "(", "per_replica_tensor", ".", "values", "[", "0", "]", ".", "shape", ".", "as_list", "(", ")", ")", ">", "1", ":", "\n", "        ", "shape", "=", "[", "-", "1", "]", "+", "per_replica_tensor", ".", "values", "[", "0", "]", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "        ", "shape", "=", "[", "-", "1", "]", "\n", "", "tensor", "=", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "per_replica_tensor", ".", "values", ",", "axis", "=", "0", ")", ",", "shape", "=", "shape", ")", "\n", "# note can also be implemented with tf.distribute.Strategy.experimental_local_results()", "\n", "", "else", ":", "\n", "      ", "tensor", "=", "per_replica_tensor", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver._weights_by_layer_name": [[551, 553], ["layer.get_weights", "layer.get_weights"], "methods", ["None"], ["", "def", "_weights_by_layer_name", "(", "self", ",", "model", ")", ":", "\n", "    ", "return", "{", "layer", ".", "name", ":", "layer", ".", "get_weights", "(", ")", "for", "layer", "in", "model", ".", "layers", "if", "layer", ".", "get_weights", "(", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.__init__": [[15, 28], ["tensorflow.constant", "tensorflow.constant", "audiocodec.mdctransformer.MDCTransformer", "audiocodec.psychoacoustic.PsychoacousticModel"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "sample_rate", ",", "freq_n", ",", "compute_dtype", ")", ":", "\n", "# [batches_n, blocks_n, freqs_n, channels_n]", "\n", "# sample_rate = blocks_n x freqs_n", "\n", "\n", "    ", "self", ".", "sample_rate", "=", "tf", ".", "constant", "(", "sample_rate", ")", "\n", "self", ".", "freq_n", "=", "tf", ".", "constant", "(", "freq_n", ")", "\n", "\n", "# initialize MDCTransformer and PsychoacousticModel", "\n", "self", ".", "mdctransformer", "=", "MDCTransformer", "(", "freq_n", ",", "window_type", "=", "'vorbis'", ",", "\n", "compute_dtype", "=", "compute_dtype", ")", "\n", "# Note: Number of bark determines level of masking threshold!!! For freq_n = 256, bark_bands_n=24 is appropriate", "\n", "self", ".", "psychoacoustic", "=", "PsychoacousticModel", "(", "sample_rate", ",", "freq_n", ",", "bark_bands_n", "=", "24", ",", "alpha", "=", "0.6", ",", "\n", "compute_dtype", "=", "compute_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.t_to_repr": [[29, 42], ["tensorflow.assert_equal", "audiorepresentation.AudioRepresentation.mdctransformer.transform", "tensorflow.shape", "tensorflow.truncatemod"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "t_to_repr", "(", "self", ",", "wave", ")", ":", "\n", "    ", "\"\"\"Convert audio signal to representation for neural model\n\n    :param wave:         audio signal                    [batches_n, samples_n, channels_n]\n    :return              audio representation            [batches_n, blocks_n+1, freqs_n, channels_n]\n                         with samples_n = blocks_n * freq_n\n    \"\"\"", "\n", "samples_n", "=", "tf", ".", "shape", "(", "wave", ")", "[", "1", "]", "\n", "tf", ".", "assert_equal", "(", "tf", ".", "truncatemod", "(", "samples_n", ",", "self", ".", "freq_n", ")", ",", "0", ",", "\n", "f'Number of samples ({samples_n}) needs to be a multiple of {self.freq_n}'", ")", "\n", "\n", "return", "self", ".", "mdctransformer", ".", "transform", "(", "wave", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_t": [[43, 52], ["audiorepresentation.AudioRepresentation.mdctransformer.inverse_transform"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "repr_to_t", "(", "self", ",", "mdct_norm", ")", ":", "\n", "    ", "\"\"\"Convert representation to audio signal\n\n    :param mdct_norm:    audio representation            [batches_n, blocks_n, freqs_n, channels_n]\n    :return              audio signal                    [batches_n, samples_n, channels_n]\n                         with samples_n = (blocks_n+1) * freq_n\n    \"\"\"", "\n", "return", "self", ".", "mdctransformer", ".", "inverse_transform", "(", "mdct_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.tonality": [[53, 61], ["audiorepresentation.AudioRepresentation.psychoacoustic.tonality"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.tonality"], ["", "@", "tf", ".", "function", "\n", "def", "tonality", "(", "self", ",", "mdct_norm", ")", ":", "\n", "    ", "\"\"\"Computes the tonality of the audio signal defined by the representation\n\n    :param mdct_norm:           audio representation            [batches_n, blocks_n, freqs_n, channels_n]\n    :return:                    tonality per block              [batches_n, blocks_n, 1, channels_n]\n    \"\"\"", "\n", "return", "self", ".", "psychoacoustic", ".", "tonality", "(", "mdct_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl": [[62, 73], ["audiorepresentation.AudioRepresentation.psychoacoustic.tonality", "audiorepresentation.AudioRepresentation.psychoacoustic.global_masking_threshold"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.tonality"], ["", "@", "tf", ".", "function", "\n", "def", "psychoacoustic_masking_ampl", "(", "self", ",", "mdct_norm", ",", "drown", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Get hearing threshold for each pixel in the spectrogram\n\n    :param mdct_norm:           normalized mdct amplitudes      [batches_n, blocks_n, freqs_n, channels_n]\n    :param drown:               factor 0..1 to drown out audible sounds (0: no drowning, 1: fully drowned)\n    :return:                    masking amplitude (positive)    [batches_n, blocks_n, freqs_n, channels_n]\n    \"\"\"", "\n", "tonality_per_block", "=", "self", ".", "psychoacoustic", ".", "tonality", "(", "mdct_norm", ")", "\n", "total_threshold", "=", "self", ".", "psychoacoustic", ".", "global_masking_threshold", "(", "mdct_norm", ",", "tonality_per_block", ",", "drown", ")", "\n", "return", "total_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise": [[74, 90], ["audiorepresentation.AudioRepresentation.psychoacoustic.add_noise"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise"], ["", "@", "tf", ".", "function", "\n", "def", "add_noise", "(", "self", ",", "mdct_norm", ",", "masking_threshold", ")", ":", "\n", "    ", "\"\"\"\n    Adds inaudible noise to amplitudes, using the masking_threshold.\n    The noise added is calibrated at a 3-sigma deviation in both directions:\n      masking_threshold = 6*sigma\n    As such, there is a 0.2% probability that the noise added is bigger than the masking_threshold\n\n    :param mdct_norm:           mdct amplitudes (spectrum) for each filter [batches_n, blocks_n, filter_bands_n, channels_n]\n                                must be of compute_dtype\n    :param masking_threshold:   masking threshold in amplitude. Masking threshold is never negative\n                                output dtype is compute_dtype\n                                [batches_n, blocks_n, filter_bands_n, channels_n]\n    :return:                    mdct amplitudes with inaudible noise added [batches_n, blocks_n, filter_bands_n, channels_n]\n    \"\"\"", "\n", "return", "self", ".", "psychoacoustic", ".", "add_noise", "(", "mdct_norm", ",", "masking_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_filter": [[91, 116], ["tensorflow.where", "tensorflow.where", "tensorflow.abs", "audiorepresentation.AudioRepresentation.psychoacoustic_filter.f_attentuation"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "psychoacoustic_filter", "(", "self", ",", "mdct_norm", ",", "masking_threshold", ",", "max_gradient", "=", "10", ")", ":", "\n", "    ", "\"\"\"Apply lRElu filter to tab-representation\n\n    :param mdct_norm:           normalized mdct amplitudes      [batches_n, blocks_n, freqs_n, channels_n=1]\n    :param masking_threshold:   masking threshold in amplitude. Masking threshold is never negative\n                                output dtype is compute_dtype\n                                [batches_n, blocks_n, filter_bands_n, channels_n]\n    :param drown:               factor 0..1 to drown out audible sounds (0: no drowning, 1: fully drowned)\n    :param max_gradient:        maximum gradient filter will introduce\n    :return:                    normalized mdct amplitudes      [batches_n, blocks_n, freqs_n, channels_n=1]\n    \"\"\"", "\n", "# ReLU-filter", "\n", "def", "f_attentuation", "(", "x", ")", ":", "\n", "# function with", "\n", "#   f(0)  = 0.", "\n", "#   f(1)  = 1.", "\n", "#   f'(0) = max_gradient / (2**(max_gradient+1) - 2)  >~  0", "\n", "#   f'(1) = max_gradient / (1. - 1./2**max_gradient)  >~  max_gradient", "\n", "      ", "return", "(", "1.", "/", "(", "2.", "-", "x", ")", "**", "max_gradient", "-", "1.", "/", "2", "**", "max_gradient", ")", "/", "(", "1.", "-", "1.", "/", "2", "**", "max_gradient", ")", "\n", "", "x_abs", "=", "tf", ".", "abs", "(", "mdct_norm", ")", "/", "masking_threshold", "\n", "x_abs_safe", "=", "tf", ".", "where", "(", "x_abs", "<", "1.", ",", "x_abs", ",", "1.", ")", "\n", "mdct_norm_filtered", "=", "tf", ".", "where", "(", "x_abs", "<", "1.", ",", "f_attentuation", "(", "x_abs_safe", ")", "*", "mdct_norm", ",", "mdct_norm", ")", "\n", "\n", "return", "mdct_norm_filtered", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_spectrogram": [[117, 161], ["tensorflow.cast", "tensorflow.map_fn", "audiorepresentation.AudioRepresentation.psychoacoustic.amplitude_to_dB_norm", "audiorepresentation.AudioRepresentation.repr_to_spectrogram.normalized_dB_scale"], "methods", ["None"], ["", "def", "repr_to_spectrogram", "(", "self", ",", "mdct_norm", ",", "intensity", "=", "False", ",", "channel", "=", "0", ",", "cmap", "=", "None", ")", ":", "\n", "    ", "\"\"\"Make image of normalized mdct amplitudes\n\n    :param mdct_norm:           mdct amplitudes                   [batches_n, blocks_n, freqs_n, channels_n]\n    :param intensity:           shows amplitudes if False, intensities if True\n    :param channel:             select (stereo)-channel which needs to be displayed\n    :param cmap:                matplotlib colormap\n    :return:                    uint8 image with filter_band_n as height and #blocks as width\n                                shape = [batches_n, blocks_n, freqs_n, color_channels]\n                                where color_channels is 1 if cmap = None, otherwise it is 3 (RGB)\n    \"\"\"", "\n", "x", "=", "tf", ".", "cast", "(", "mdct_norm", "[", ":", ",", ":", ",", ":", ",", "channel", ":", "channel", "+", "1", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "def", "normalized_dB_scale", "(", "ampl", ",", "with_sign", "=", "True", ")", ":", "\n", "      ", "normalized_dB", "=", "self", ".", "psychoacoustic", ".", "amplitude_to_dB_norm", "(", "ampl", ")", "\n", "if", "with_sign", ":", "\n", "# range -1..1", "\n", "        ", "return", "tf", ".", "sign", "(", "ampl", ")", "*", "normalized_dB", "\n", "", "else", ":", "\n", "# range 0..1", "\n", "        ", "return", "normalized_dB", "\n", "\n", "# convert to 0..1 range", "\n", "", "", "if", "intensity", ":", "\n", "      ", "image", "=", "normalized_dB_scale", "(", "x", ",", "with_sign", "=", "False", ")", "\n", "", "else", ":", "\n", "      ", "image", "=", "(", "normalized_dB_scale", "(", "x", ",", "with_sign", "=", "True", ")", "+", "1.", ")", "/", "2.", "\n", "\n", "", "image", "=", "tf", ".", "map_fn", "(", "lambda", "im", ":", "tf", ".", "image", ".", "rot90", "(", "im", ")", ",", "image", ")", "\n", "\n", "# colorize with cmap", "\n", "if", "cmap", "is", "not", "None", ":", "\n", "# quantize", "\n", "      ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ",", "0", "]", "# remove the dummy channel direction (will be replace with rgb info from color map)", "\n", "image_index", "=", "tf", ".", "cast", "(", "tf", ".", "round", "(", "image", "*", "(", "cmap", ".", "N", "-", "1", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "# indices in [0, cmap.N-1]", "\n", "\n", "image_index", "=", "tf", ".", "clip_by_value", "(", "image_index", ",", "clip_value_min", "=", "0", ",", "clip_value_max", "=", "cmap", ".", "N", "-", "1", ")", "\n", "\n", "# gather", "\n", "color_map", "=", "matplotlib", ".", "cm", ".", "get_cmap", "(", "cmap", ")", "(", "np", ".", "arange", "(", "cmap", ".", "N", ")", ")", "# shape=[cmap.N, 3]", "\n", "colors", "=", "tf", ".", "constant", "(", "color_map", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "image", "=", "tf", ".", "gather", "(", "colors", ",", "image_index", ")", "# image[b, h, w, c] = color[image_index[b, h, w], c]", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_audio": [[162, 175], ["tensorflow.cast", "audiorepresentation.AudioRepresentation.repr_to_t", "tensorflow.clip_by_value"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.repr_to_t"], ["", "def", "repr_to_audio", "(", "self", ",", "mdct_norm", ")", ":", "\n", "    ", "\"\"\"Make audio of mdct amplitudes\n\n    :param mdct_norm:             mdct amplitudes                 [batches_n, blocks_n, freqs_n, channels_n]\n    :return:                      audio signal                    [batches_n, samples_n, channels_n]\n                                  with samples_n = (blocks_n+1) * freq_n\n    \"\"\"", "\n", "mdct_norm_ft32", "=", "tf", ".", "cast", "(", "mdct_norm", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "wave", "=", "self", ".", "repr_to_t", "(", "mdct_norm_ft32", ")", "\n", "\n", "wave", "=", "tf", ".", "clip_by_value", "(", "wave", ",", "clip_value_min", "=", "-", "1.", ",", "clip_value_max", "=", "1.", ")", "\n", "\n", "return", "wave", "\n", "", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.__init__": [[17, 32], ["model.mp3net.MP3netFactory", "print", "enumerate", "zip", "print"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "strategy", ",", "args", ")", ":", "\n", "    ", "\"\"\"Train specGAN\n\n    :param strategy:\n    :param args:             user arguments\n    \"\"\"", "\n", "self", ".", "strategy", "=", "strategy", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# set up model_factory", "\n", "self", ".", "model_factory", "=", "mp3net", ".", "MP3netFactory", "(", ")", "\n", "\n", "print", "(", "\"ProGAN training:\"", ")", "\n", "for", "stage", ",", "(", "blocks_n", ",", "freq_n", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "model_factory", ".", "blocks_n", ",", "self", ".", "model_factory", ".", "freq_n", ")", ")", ":", "\n", "      ", "print", "(", "\"  Stage {0}: {1:5d}x{2:5d}\"", ".", "format", "(", "stage", ",", "blocks_n", ",", "freq_n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.progressive_training": [[33, 73], ["progressivetrainer.ProgressiveTrainer._find_latest_stage", "range", "print", "print", "print", "print", "print", "print", "print", "print", "print", "utils.gspath.join", "model.modeldriver.DistributedModelDriver", "model.modeldriver.DistributedModelDriver.print_model_summary", "progressivetrainer.ProgressiveTrainer.find_data_files", "model.modeldriver.DistributedModelDriver.training_loop", "print", "model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "model.modeldriver.DistributedModelDriver.load_from_model_weights"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_stage", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.print_model_summary", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.find_data_files", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.training_loop", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_from_model_weights"], ["", "", "def", "progressive_training", "(", "self", ")", ":", "\n", "    ", "stage_start", "=", "self", ".", "_find_latest_stage", "(", ")", "\n", "if", "stage_start", "is", "not", "None", ":", "\n", "      ", "print", "(", "\"Restoring stage {} from checkpoint file\"", ".", "format", "(", "stage_start", ")", ")", "\n", "", "else", ":", "\n", "      ", "print", "(", "\"Starting anew from stage 0\"", ")", "\n", "stage_start", "=", "0", "\n", "\n", "", "model_weights", "=", "None", "\n", "for", "stage", "in", "range", "(", "stage_start", ",", "self", ".", "model_factory", ".", "stages", ")", ":", "\n", "      ", "print", "(", ")", "\n", "if", "self", ".", "model_factory", ".", "stage_total_songs", "[", "stage", "]", "==", "0", ":", "\n", "        ", "print", "(", "\"======= Empty stage {0} =======\"", ".", "format", "(", "stage", ")", ")", "\n", "", "else", ":", "\n", "        ", "blocks_n", "=", "self", ".", "model_factory", ".", "blocks_n", "[", "stage", "]", "\n", "freq_n", "=", "self", ".", "model_factory", ".", "freq_n", "[", "stage", "]", "\n", "print", "(", "\"======= Entering stage {0} =======\"", ".", "format", "(", "stage", ")", ")", "\n", "print", "(", "f'Stage {stage}:'", ")", "\n", "print", "(", "\"  * resolution            = {0:d} x {1:d}\"", ".", "format", "(", "blocks_n", ",", "freq_n", ")", ")", "\n", "print", "(", "\"  * total number of songs = {0:,}\"", ".", "format", "(", "self", ".", "model_factory", ".", "stage_total_songs", "[", "stage", "]", ")", ")", "\n", "print", "(", ")", "\n", "\n", "# set up summary writer (different writer for different stage, since different tensors etc)", "\n", "summary_dir", "=", "gspath", ".", "join", "(", "self", ".", "args", ".", "summary_dir", ",", "f\"stage-{stage}\"", ")", "\n", "\n", "# 2. start model driver", "\n", "model_driver", "=", "DistributedModelDriver", "(", "self", ".", "strategy", ",", "self", ".", "model_factory", ",", "stage", ",", "\n", "mode", "=", "'train'", ",", "summary_dir", "=", "summary_dir", ",", "args", "=", "self", ".", "args", ")", "\n", "if", "model_weights", "is", "None", ":", "\n", "          ", "model_driver", ".", "load_latest_checkpoint", "(", ")", "\n", "", "else", ":", "\n", "          ", "model_driver", ".", "load_from_model_weights", "(", "model_weights", ",", "self", ".", "model_factory", ".", "map_layer_names_for_model_growth", ")", "\n", "\n", "", "model_driver", ".", "print_model_summary", "(", ")", "\n", "\n", "# 3. run model", "\n", "data_files", "=", "self", ".", "find_data_files", "(", "stage", ",", "self", ".", "args", ".", "data_dir", ",", "self", ".", "model_factory", ")", "\n", "model_weights", "=", "model_driver", ".", "training_loop", "(", "data_files", ")", "\n", "\n", "print", "(", "\"======= Exiting stage {} =======\"", ".", "format", "(", "stage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.evaluation_loop": [[74, 116], ["progressivetrainer.ProgressiveTrainer._find_latest_checkpoint", "print", "print", "print", "utils.gspath.join", "model.modeldriver.DistributedModelDriver", "progressivetrainer.ProgressiveTrainer.find_data_files", "model.modeldriver.DistributedModelDriver.get_distributed_dataset", "max", "progressivetrainer.ProgressiveTrainer._find_latest_checkpoint", "time.sleep", "datetime.datetime.utcnow().strftime", "print", "print", "model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "model.modeldriver.DistributedModelDriver.evaluation_loop", "print", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow", "datetime.datetime.utcnow", "datetime.datetime.utcnow", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow().strftime", "datetime.datetime.utcnow", "datetime.datetime.utcnow", "datetime.datetime.utcnow"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_checkpoint", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.find_data_files", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.get_distributed_dataset", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_checkpoint", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.evaluation_loop"], ["", "", "", "def", "evaluation_loop", "(", "self", ")", ":", "\n", "    ", "current_stage", ",", "current_checkpoint_no", "=", "self", ".", "_find_latest_checkpoint", "(", ")", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Most recent is stage-{current_stage} and checkpoint-{current_checkpoint_no}...\"", ")", "\n", "\n", "# loop over different stages", "\n", "while", "True", ":", "\n", "      ", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Entering stage-{current_stage}...\"", ")", "\n", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Initializing model and data for stage-{current_stage}...\"", ")", "\n", "\n", "# set up summary writer (different writer for different stage, since different tensors etc)", "\n", "summary_dir", "=", "gspath", ".", "join", "(", "self", ".", "args", ".", "summary_dir", ",", "f\"stage-{current_stage}\"", ")", "\n", "\n", "model_driver", "=", "DistributedModelDriver", "(", "self", ".", "strategy", ",", "self", ".", "model_factory", ",", "current_stage", ",", "\n", "mode", "=", "'eval'", ",", "summary_dir", "=", "summary_dir", ",", "args", "=", "self", ".", "args", ")", "\n", "data_files", "=", "self", ".", "find_data_files", "(", "current_stage", ",", "self", ".", "args", ".", "data_dir", ",", "self", ".", "model_factory", ")", "\n", "dataset_iter", "=", "model_driver", ".", "get_distributed_dataset", "(", "data_files", ")", "\n", "\n", "current_checkpoint_no", "=", "max", "(", "0", ",", "current_checkpoint_no", "-", "1", ")", "\n", "\n", "# eternal evaluation loop of writing summaries for stage = current_stage", "\n", "while", "True", ":", "\n", "        ", "new_stage", ",", "new_checkpoint_no", "=", "self", ".", "_find_latest_checkpoint", "(", ")", "\n", "\n", "if", "new_stage", ">", "current_stage", ":", "\n", "          ", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: New stage found...\"", ")", "\n", "current_stage", "=", "new_stage", "\n", "current_checkpoint_no", "=", "new_checkpoint_no", "-", "1", "# minus 1 since it's still untreated!", "\n", "break", "\n", "\n", "", "if", "new_stage", ">", "current_stage", "or", "(", "new_stage", "==", "current_stage", "and", "new_checkpoint_no", ">", "current_checkpoint_no", ")", ":", "\n", "          ", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: New checkpoint found...\"", ")", "\n", "# wait a bit more, to make sure all checkpoint files are saved to disk", "\n", "\n", "model_driver", ".", "load_latest_checkpoint", "(", ")", "\n", "model_driver", ".", "evaluation_loop", "(", "dataset_iter", ")", "\n", "print", "(", "f\"{datetime.datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')}: Waiting for new checkpoint...\"", ")", "\n", "\n", "", "current_stage", "=", "new_stage", "\n", "current_checkpoint_no", "=", "new_checkpoint_no", "\n", "\n", "time", ".", "sleep", "(", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.inference_loop": [[117, 141], ["progressivetrainer.ProgressiveTrainer._find_latest_stage", "print", "print", "print", "print", "print", "model.modeldriver.DistributedModelDriver", "model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "model.modeldriver.DistributedModelDriver.print_model_summary", "model.modeldriver.DistributedModelDriver.inference_loop", "print", "print", "ValueError"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_stage", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.load_latest_checkpoint", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.modeldriver.DistributedModelDriver.print_model_summary", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.inference_loop"], ["", "", "", "def", "inference_loop", "(", "self", ")", ":", "\n", "    ", "stage", "=", "self", ".", "_find_latest_stage", "(", ")", "\n", "if", "stage", "is", "not", "None", ":", "\n", "      ", "print", "(", "\"Restoring stage {} from checkpoint file\"", ".", "format", "(", "stage", ")", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"No checkpoint file found\"", ")", "\n", "\n", "", "blocks_n", "=", "self", ".", "model_factory", ".", "blocks_n", "[", "stage", "]", "\n", "freq_n", "=", "self", ".", "model_factory", ".", "freq_n", "[", "stage", "]", "\n", "print", "(", "\"======= Entering stage {0} =======\"", ".", "format", "(", "stage", ")", ")", "\n", "print", "(", "f'Stage {stage}:'", ")", "\n", "print", "(", "\"  * resolution            = {0:d} x {1:d}\"", ".", "format", "(", "blocks_n", ",", "freq_n", ")", ")", "\n", "print", "(", "\"  * total number of songs = {0:,}\"", ".", "format", "(", "self", ".", "model_factory", ".", "stage_total_songs", "[", "stage", "]", ")", ")", "\n", "print", "(", ")", "\n", "\n", "# 1. start model driver", "\n", "model_driver", "=", "DistributedModelDriver", "(", "self", ".", "strategy", ",", "self", ".", "model_factory", ",", "stage", ",", "mode", "=", "'infer'", ",", "args", "=", "self", ".", "args", ")", "\n", "model_driver", ".", "load_latest_checkpoint", "(", ")", "\n", "model_driver", ".", "print_model_summary", "(", ")", "\n", "\n", "# 2. run model", "\n", "model_driver", ".", "inference_loop", "(", ")", "\n", "\n", "print", "(", "\"======= Exiting stage {} =======\"", ".", "format", "(", "stage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_stage": [[142, 152], ["utils.gspath.join", "utils.gspath.findall", "int", "max", "re.search().group", "re.search", "re.search"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.findall"], ["", "def", "_find_latest_stage", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    :return:  number of latest saved model stage, or None is no checkpoints in any stages were found\n    \"\"\"", "\n", "checkpoint_file_path", "=", "gspath", ".", "join", "(", "self", ".", "args", ".", "training_dir", ",", "\"stage-*\"", ",", "\"stage-*-ckpt-*.data*\"", ")", "\n", "checkpoint_files", "=", "gspath", ".", "findall", "(", "checkpoint_file_path", ")", "\n", "stages", "=", "[", "int", "(", "re", ".", "search", "(", "r'stage-(\\d+)-ckpt-\\d+\\.data'", ",", "checkpoint_file", ")", ".", "group", "(", "1", ")", ")", "for", "checkpoint_file", "in", "checkpoint_files", "\n", "if", "re", ".", "search", "(", "r'stage-(\\d+)-ckpt-\\d+\\.data'", ",", "checkpoint_file", ")", "is", "not", "None", "]", "\n", "\n", "return", "max", "(", "stages", ")", "if", "stages", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_checkpoint": [[153, 171], ["progressivetrainer.ProgressiveTrainer._find_latest_stage", "utils.gspath.join", "utils.gspath.findall", "max", "int", "re.search().group", "re.search", "re.search"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer._find_latest_stage", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.findall"], ["", "def", "_find_latest_checkpoint", "(", "self", ")", ":", "\n", "    ", "\"\"\"\n    :return: tuple (stage, checkpoint)\n             if no checkpoint in any stage is found, then (model_start_stage, 0) is returned\n    \"\"\"", "\n", "stage", "=", "self", ".", "_find_latest_stage", "(", ")", "\n", "if", "stage", "is", "not", "None", ":", "\n", "      ", "checkpoint_file_path", "=", "gspath", ".", "join", "(", "self", ".", "args", ".", "training_dir", ",", "f\"stage-{stage}\"", ",", "f\"stage-{stage}-ckpt-*.data*\"", ")", "\n", "checkpoint_files", "=", "gspath", ".", "findall", "(", "checkpoint_file_path", ")", "\n", "checkpoint_no", "=", "[", "int", "(", "re", ".", "search", "(", "r'stage-\\d+-ckpt-(\\d+)\\.data'", ",", "checkpoint_file", ")", ".", "group", "(", "1", ")", ")", "for", "checkpoint_file", "in", "checkpoint_files", "\n", "if", "re", ".", "search", "(", "r'stage-\\d+-ckpt-(\\d+)\\.data'", ",", "checkpoint_file", ")", "is", "not", "None", "]", "\n", "", "else", ":", "\n", "      ", "stage", "=", "0", "\n", "while", "self", ".", "model_factory", ".", "stage_total_songs", "[", "stage", "]", "==", "0", "and", "stage", "<", "self", ".", "model_factory", ".", "stages", ":", "\n", "        ", "stage", "+=", "1", "\n", "", "checkpoint_no", "=", "[", "0", "]", "\n", "\n", "", "return", "stage", ",", "max", "(", "checkpoint_no", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.progressivetrainer.ProgressiveTrainer.find_data_files": [[172, 188], ["utils.gspath.join", "print", "utils.gspath.findall", "len", "ValueError", "print", "len", "utils.gspath.split"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.join", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.findall", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.gspath.split"], ["", "@", "staticmethod", "\n", "def", "find_data_files", "(", "training_stage", ",", "data_dir", ",", "model_factory", ")", ":", "\n", "    ", "freq_n", "=", "model_factory", ".", "freq_n", "[", "training_stage", "]", "\n", "channels_n", "=", "model_factory", ".", "channels_n", "[", "training_stage", "]", "\n", "\n", "# find appropriate pre-processed data files", "\n", "file_pattern", "=", "f'*_sr{model_factory.sample_rate}_Nx{freq_n}x{channels_n}.tfrecord'", "\n", "input_file_path", "=", "gspath", ".", "join", "(", "data_dir", ",", "file_pattern", ")", "\n", "input_files", "=", "gspath", ".", "findall", "(", "input_file_path", ")", "[", "0", ":", "]", "\n", "if", "len", "(", "input_files", ")", "==", "0", ":", "\n", "      ", "raise", "ValueError", "(", "f'Did not find any preprocessed file {file_pattern} in directory {data_dir}'", ")", "\n", "", "print", "(", "\"Found {0} data files in {1}: \"", ".", "format", "(", "len", "(", "input_files", ")", ",", "data_dir", ")", ")", "\n", "for", "input_filepath", "in", "input_files", ":", "\n", "      ", "print", "(", "\"  {}\"", ".", "format", "(", "gspath", ".", "split", "(", "input_filepath", ")", "[", "1", "]", ")", ")", "\n", "\n", "", "return", "input_files", "\n", "", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.__init__": [[35, 62], ["mp3net.MP3netFactory.generator_filters_n", "tensorflow.constant", "range", "tensorflow.constant", "range", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_filters_n"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# initialization of audio & spectrum transformations", "\n", "# ProGAN training phases", "\n", "    ", "self", ".", "stages", "=", "6", "\n", "\n", "self", ".", "stage_total_songs", "=", "[", "1024", "*", "x", "for", "x", "in", "[", "0", "]", "*", "(", "self", ".", "stages", "-", "1", ")", "+", "[", "200000", "]", "]", "\n", "self", ".", "fade_in_progression", "=", "[", "\n", "lambda", "song_counter", ",", "stage", "=", "stage", ":", "tf", ".", "constant", "(", "1.", ",", "shape", "=", "(", ")", ")", "\n", "for", "stage", "in", "range", "(", "self", ".", "stages", ")", "]", "\n", "self", ".", "drown_progression", "=", "[", "\n", "lambda", "song_counter", ":", "tf", ".", "constant", "(", "3.", ",", "shape", "=", "(", ")", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "stages", ")", "]", "\n", "\n", "# CNN parameters", "\n", "self", ".", "base_block_length", "=", "4", "\n", "self", ".", "dim_ch", "=", "2", "*", "8", "\n", "self", ".", "max_dim_ch", "=", "4", "*", "128", "\n", "self", ".", "blocks_per_sec", "=", "172", "\n", "\n", "self", ".", "blocks_n", "=", "[", "4", "**", "(", "stage", "+", "1", ")", "*", "self", ".", "base_block_length", "for", "stage", "in", "range", "(", "self", ".", "stages", ")", "]", "\n", "self", ".", "freq_n", "=", "[", "2", "*", "2", "**", "(", "stage", "+", "1", ")", "for", "stage", "in", "range", "(", "self", ".", "stages", ")", "]", "# \\Sum_i^N 2^i = 2^N+1 - 1", "\n", "self", ".", "channels_n", "=", "[", "2", "for", "_", "in", "range", "(", "self", ".", "stages", ")", "]", "# 1:mono 2:stereo", "\n", "\n", "self", ".", "drown", "=", "[", "0.0", "for", "_", "in", "range", "(", "self", ".", "stages", ")", "]", "# sets amount of noise added to deeper samples", "\n", "\n", "self", ".", "sample_rate", "=", "self", ".", "freq_n", "[", "-", "1", "]", "*", "self", ".", "blocks_per_sec", "\n", "self", ".", "latent_dim", ",", "_", ",", "_", "=", "self", ".", "generator_filters_n", "(", "block_i", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.map_layer_names_for_model_growth": [[63, 77], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "map_layer_names_for_model_growth", "(", "new_model_layer_name", ")", ":", "\n", "    ", "equivalent_old_model_layer_name", "=", "new_model_layer_name", "\n", "\n", "if", "equivalent_old_model_layer_name", "==", "'generator_output_conv2d_old'", ":", "\n", "      ", "equivalent_old_model_layer_name", "=", "'generator_output_conv2d_new'", "\n", "", "elif", "equivalent_old_model_layer_name", "==", "'generator_output_conv2d_new'", ":", "\n", "      ", "equivalent_old_model_layer_name", "=", "''", "\n", "", "if", "equivalent_old_model_layer_name", "==", "'discriminator_output_conv2d_old'", ":", "\n", "      ", "equivalent_old_model_layer_name", "=", "'discriminator_output_conv2d_new'", "\n", "", "elif", "equivalent_old_model_layer_name", "==", "'discriminator_output_conv2d_new'", ":", "\n", "      ", "equivalent_old_model_layer_name", "=", "''", "\n", "\n", "", "return", "equivalent_old_model_layer_name", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_block": [[78, 130], ["mp3net.MP3netFactory.generator_filters_n", "int", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Concatenate", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.LeakyReLU", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_filters_n"], ["", "def", "generator_block", "(", "self", ",", "x", ",", "generator_block_i", ")", ":", "\n", "    ", "in_filters_n", ",", "mid_filters_n", ",", "out_filters_n", "=", "self", ".", "generator_filters_n", "(", "generator_block_i", ")", "\n", "\n", "# philosophy: drop channels, when we are upsampling!", "\n", "block_kernel_length", "=", "3", "\n", "freq_kernel_length", "=", "3", "\n", "\n", "# Make new high octave: (1, 2) up-scaling + Conv2D + Conv2D", "\n", "freq_n", "=", "x", ".", "shape", "[", "2", "]", "\n", "octaves_n", "=", "int", "(", "np", ".", "log", "(", "freq_n", "+", "1", ")", "/", "np", ".", "log", "(", "2.", ")", ")", "\n", "lower", "=", "x", "\n", "higher", "=", "x", "[", ":", ",", ":", ",", "2", "**", "(", "octaves_n", "-", "1", ")", ":", ",", ":", "]", "\n", "\n", "# Conv2DTranspose = up-sampling(2, 2) + Conv2D(1, 1)", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.0.2x2H'", ".", "format", "(", "generator_block_i", ")", ")", "(", "higher", ")", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "higher", ")", "\n", "\n", "# Conv2DTranspose = Conv2D(1, 1)", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.1.1x1H'", ".", "format", "(", "generator_block_i", ")", ")", "(", "higher", ")", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "higher", ")", "\n", "\n", "# Conv2DTranspose = up-sampling(2, 1) + Conv2D(1, 1)", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.0.2x1L'", ".", "format", "(", "generator_block_i", ")", ")", "(", "lower", ")", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "lower", ")", "\n", "\n", "# Conv2DTranspose = Conv2D(1, 1)", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.1.1x1L'", ".", "format", "(", "generator_block_i", ")", ")", "(", "lower", ")", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "lower", ")", "\n", "\n", "# LeakyReLU assumes value distribution is centered around the discontinuity at 0", "\n", "# here we rebalance lower & higher relative to each other before gluing back together (NO BatchNorm here!!)", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'generator_block_{generator_block_i}.2.1x1H'", ")", "(", "higher", ")", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'generator_block_{generator_block_i}.2.1x1L'", ")", "(", "lower", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Concatenate", "(", "axis", "=", "2", ")", "(", "[", "lower", ",", "higher", "]", ")", "\n", "\n", "# Conv2DTranspose = up-sampling(2, 1) + Conv2D(1, 1)", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.3.2x1'", ".", "format", "(", "generator_block_i", ")", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "# Conv2DTranspose = Conv2D(1, 1)", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'generator_block_{}.4.1x1'", ".", "format", "(", "generator_block_i", ")", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_block": [[131, 187], ["mp3net.MP3netFactory.discriminator_filters_n", "int", "tensorflow.pad", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.constant", "numpy.log", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_filters_n"], ["", "def", "discriminator_block", "(", "self", ",", "x", ",", "discriminator_block_i", ",", "shaving", "=", "False", ")", ":", "\n", "# Note: no BatchNormalization since we use GP on the discriminator", "\n", "    ", "in_filters_n", ",", "mid_filters_n", ",", "out_filters_n", "=", "self", ".", "discriminator_filters_n", "(", "discriminator_block_i", ")", "\n", "\n", "# 1. Full spectrum: Conv2D + Conv2D + Down-sample 2x(2, 1)", "\n", "block_kernel_length", "=", "3", "# *2", "\n", "freq_kernel_length", "=", "3", "# *4", "\n", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "in_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.4.1x1'", ")", "(", "x", ")", "\n", "if", "shaving", ":", "x", "=", "x", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.3.2x1'", ")", "(", "x", ")", "\n", "if", "shaving", ":", "x", "=", "x", "[", ":", ",", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "# inversion of the concat layer in the generator", "\n", "freq_n", "=", "x", ".", "shape", "[", "2", "]", "\n", "octaves_n", "=", "int", "(", "np", ".", "log", "(", "freq_n", "+", "1", ")", "/", "np", ".", "log", "(", "2.", ")", ")", "\n", "lower", "=", "x", "[", ":", ",", ":", ",", ":", "2", "**", "(", "octaves_n", "-", "1", ")", ",", ":", "]", "\n", "higher", "=", "x", "[", ":", ",", ":", ",", "2", "**", "(", "octaves_n", "-", "1", ")", ":", ",", ":", "]", "\n", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.2.1x1H'", ")", "(", "higher", ")", "\n", "if", "shaving", ":", "higher", "=", "higher", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "higher", ")", "\n", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.1.2x2H'", ")", "(", "higher", ")", "\n", "if", "shaving", ":", "higher", "=", "higher", "[", ":", ",", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "higher", ")", "\n", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "mid_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.2.1x1L'", ")", "(", "lower", ")", "\n", "if", "shaving", ":", "lower", "=", "lower", "[", ":", ",", "1", ":", ",", ":", ",", ":", "]", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "lower", ")", "\n", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "block_kernel_length", ",", "freq_kernel_length", ")", ",", "\n", "strides", "=", "(", "2", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.1.2x1L'", ")", "(", "lower", ")", "\n", "if", "shaving", ":", "lower", "=", "lower", "[", ":", ",", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "lower", ")", "\n", "\n", "# rescale and shift before summing", "\n", "higher", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.0.1x1H'", ")", "(", "higher", ")", "\n", "lower", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "out_filters_n", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "f'discriminator_block_{discriminator_block_i}.0.1x1L'", ")", "(", "lower", ")", "\n", "if", "shaving", ":", "\n", "      ", "lower", "=", "lower", "[", ":", ",", "1", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "higher", "=", "higher", "[", ":", ",", "1", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "", "higher", "=", "tf", ".", "pad", "(", "higher", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "2", "**", "(", "octaves_n", "-", "2", ")", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", ")", "# pad lower octaves", "\n", "x", "=", "lower", "+", "higher", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_filters_n": [[188, 197], ["min", "mp3net.MP3netFactory.generator_filters_n.ceiling"], "methods", ["None"], ["", "def", "generator_filters_n", "(", "self", ",", "block_i", ")", ":", "\n", "    ", "channels_in", "=", "4", "*", "4", "**", "(", "self", ".", "stages", "-", "1", "-", "block_i", ")", "*", "self", ".", "dim_ch", "\n", "channels_mid", "=", "2", "*", "4", "**", "(", "self", ".", "stages", "-", "1", "-", "block_i", ")", "*", "self", ".", "dim_ch", "\n", "channels_out", "=", "1", "*", "4", "**", "(", "self", ".", "stages", "-", "1", "-", "block_i", ")", "*", "self", ".", "dim_ch", "\n", "\n", "def", "ceiling", "(", "x", ")", ":", "\n", "      ", "return", "min", "(", "x", ",", "self", ".", "max_dim_ch", ")", "\n", "\n", "", "return", "ceiling", "(", "channels_in", ")", ",", "ceiling", "(", "channels_mid", ")", ",", "ceiling", "(", "channels_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_filters_n": [[198, 201], ["mp3net.MP3netFactory.generator_filters_n"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_filters_n"], ["", "def", "discriminator_filters_n", "(", "self", ",", "block_i", ")", ":", "\n", "    ", "channels_in", ",", "channels_mid", ",", "channels_out", "=", "self", ".", "generator_filters_n", "(", "block_i", ")", "\n", "return", "channels_out", ",", "channels_mid", ",", "channels_in", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.split_to_batch": [[202, 212], ["tensorflow.pad", "tensorflow.stack", "tensorflow.transpose", "tensorflow.reshape", "tensorflow.constant", "range", "sum", "sum"], "methods", ["None"], ["", "def", "split_to_batch", "(", "self", ",", "x", ",", "split", ",", "padding", ")", ":", "\n", "# pad the input", "\n", "    ", "x_padded", "=", "tf", ".", "pad", "(", "x", ",", "tf", ".", "constant", "(", "[", "[", "0", ",", "0", "]", ",", "padding", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", ")", "\n", "# sliding window over width dimension", "\n", "split_width", "=", "x", ".", "shape", "[", "1", "]", "//", "split", "\n", "x_batched", "=", "tf", ".", "stack", "(", "[", "x_padded", "[", ":", ",", "n", "*", "split_width", ":", "(", "n", "+", "1", ")", "*", "split_width", "+", "sum", "(", "padding", ")", ",", ":", ",", ":", "]", "for", "n", "in", "range", "(", "split", ")", "]", ")", "\n", "# mix width with batch dimension", "\n", "x_batched", "=", "tf", ".", "transpose", "(", "x_batched", ",", "perm", "=", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", "\n", "x_split", "=", "tf", ".", "reshape", "(", "x_batched", ",", "shape", "=", "(", "-", "1", ",", "split_width", "+", "sum", "(", "padding", ")", ",", "x_padded", ".", "shape", "[", "2", "]", ",", "x_padded", ".", "shape", "[", "3", "]", ")", ")", "\n", "return", "x_split", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.join_from_batch": [[213, 219], ["tensorflow.reshape"], "methods", ["None"], ["", "def", "join_from_batch", "(", "self", ",", "x", ",", "shave", ",", "join_width", ")", ":", "\n", "# shave off extra edges", "\n", "    ", "x_shaved", "=", "x", "[", ":", ",", "shave", "[", "0", "]", ":", "x", ".", "shape", "[", "1", "]", "-", "shave", "[", "1", "]", ",", ":", ",", ":", "]", "\n", "# move batch back to spatial", "\n", "x_joined", "=", "tf", ".", "reshape", "(", "x_shaved", ",", "shape", "=", "(", "-", "1", ",", "join_width", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", ")", "\n", "return", "x_joined", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.make_generator_model": [[220, 273], ["tensorflow.keras.Input", "mp3net.MP3netFactory.generator_filters_n", "range", "mp3net.MP3netFactory.split_to_batch", "mp3net.MP3netFactory.generator_block", "mp3net.MP3netFactory.generator_block", "mp3net.MP3netFactory.join_from_batch", "tensorflow.cast", "tensorflow.tanh", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Reshape", "tensorflow.keras.layers.LeakyReLU", "mp3net.MP3netFactory.generator_block", "tensorflow.keras.layers.Conv2D", "probes.extend", "tensorflow.keras.Model", "tensorflow.keras.Model", "tensorflow.distribute.get_strategy", "probes.append"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_filters_n", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.split_to_batch", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_block", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_block", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.join_from_batch", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.generator_block"], ["", "def", "make_generator_model", "(", "self", ",", "model_stage", ",", "global_batch_size", ",", "with_probe", "=", "False", ")", ":", "\n", "    ", "\"\"\"generator output is -1 < ... < 1 (tanh activation!)\n    [batch_size,\n       [blocks_n, freqs_n, in_channels]\n    ]\n    :param model_stage:  progressive stage of model training\n    :param with_probe:   not a Tensor, but a python variable to force re-tracing (so we get a faster and slower Graph)\n    :return:             the keras generator model\n    \"\"\"", "\n", "per_worker_batch_size", "=", "global_batch_size", "//", "tf", ".", "distribute", ".", "get_strategy", "(", ")", ".", "num_replicas_in_sync", "\n", "\n", "inputs", "=", "tf", ".", "keras", ".", "Input", "(", "batch_input_shape", "=", "(", "per_worker_batch_size", ",", "self", ".", "latent_dim", ")", ",", "name", "=", "'generator_latent_input'", ")", "\n", "probes", "=", "[", "]", "\n", "\n", "_", ",", "_", ",", "out_filters_n", "=", "self", ".", "generator_filters_n", "(", "block_i", "=", "0", ")", "\n", "\n", "# FC (= Conv2DTranspose(kernel=Xx3, 'VALID')", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "base_block_length", "*", "2", "*", "self", ".", "latent_dim", ",", "name", "=", "f'generator_conv2dt.{self.base_block_length}x1'", ")", "(", "inputs", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Reshape", "(", "(", "self", ".", "base_block_length", ",", "2", ",", "self", ".", "latent_dim", ")", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "block_i_range", "=", "range", "(", "model_stage", "+", "1", ")", "\n", "for", "generator_block_i", "in", "block_i_range", "[", ":", "-", "2", "]", ":", "\n", "      ", "x", "=", "self", ".", "generator_block", "(", "x", ",", "generator_block_i", ")", "\n", "if", "with_probe", ":", "\n", "        ", "probes", ".", "append", "(", "x", ")", "\n", "\n", "", "", "x", "=", "self", ".", "split_to_batch", "(", "x", ",", "split", "=", "128", ",", "padding", "=", "[", "4", ",", "2", "]", ")", "\n", "\n", "generator_block_i", "=", "model_stage", "-", "1", "\n", "x", "=", "self", ".", "generator_block", "(", "x", ",", "generator_block_i", ")", "\n", "generator_block_i", "=", "model_stage", "\n", "x", "=", "self", ".", "generator_block", "(", "x", ",", "generator_block_i", ")", "\n", "\n", "# note: bias is one single constant up-lifting the full output; initially it needs to pass through the pa-filter!", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "self", ".", "channels_n", "[", "model_stage", "]", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "\n", "name", "=", "'generator_output_conv2d_new'", ",", "use_bias", "=", "True", ")", "(", "x", ")", "\n", "# no Leaky ReLU or BatchNorm, as this is the actual output! (similar to ProGAN)", "\n", "x", "=", "self", ".", "join_from_batch", "(", "x", ",", "shave", "=", "[", "4", "*", "16", ",", "2", "*", "16", "]", ",", "join_width", "=", "self", ".", "blocks_n", "[", "model_stage", "]", ")", "\n", "\n", "# not present in ProGAN", "\n", "# we need it, since psychoacoustic filter expects input in -1..1 range", "\n", "# earlier we used clipping, but derivatives of clip result in zero gradients hence no learning(?)", "\n", "x", "=", "tf", ".", "cast", "(", "x", ",", "dtype", "=", "tf", ".", "float32", ")", "# does this fix the strangely quantized output of the generator...?", "\n", "x", "=", "tf", ".", "tanh", "(", "x", ")", "\n", "\n", "if", "with_probe", ":", "\n", "      ", "probes", ".", "extend", "(", "[", "x", "]", ")", "\n", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "probes", ",", "name", "=", "'generator'", ")", "\n", "", "else", ":", "\n", "      ", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "x", ",", "name", "=", "'generator'", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.make_discriminator_model": [[274, 332], ["tensorflow.TensorShape", "tensorflow.keras.Input", "mp3net.MP3netFactory.split_to_batch", "mp3net.MP3netFactory.discriminator_filters_n", "mp3net.MP3netFactory.discriminator_block", "mp3net.MP3netFactory.discriminator_block", "mp3net.MP3netFactory.join_from_batch", "mp3net.MP3netFactory.discriminator_filters_n", "tensorflow.keras.Model", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.LeakyReLU", "list", "mp3net.MP3netFactory.discriminator_block", "layers.BatchStddevLayer", "tensorflow.keras.layers.Flatten", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LeakyReLU", "tensorflow.keras.layers.Dense", "tensorflow.distribute.get_strategy", "reversed", "range"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.split_to_batch", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_filters_n", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_block", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_block", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.join_from_batch", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_filters_n", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.discriminator_block"], ["", "def", "make_discriminator_model", "(", "self", ",", "model_stage", ",", "global_batch_size", ",", "mode", ")", ":", "\n", "    ", "\"\"\"\n    Output of the discriminator is a logit (-inf..inf)\n    No batch normalization when using gradient penalty!!\n\n    :param model_stage:  phase of model training\n    :return:             critic output, [1] (= scalar)\n    \"\"\"", "\n", "per_worker_batch_size", "=", "global_batch_size", "//", "tf", ".", "distribute", ".", "get_strategy", "(", ")", ".", "num_replicas_in_sync", "\n", "batch_input_shape", "=", "tf", ".", "TensorShape", "(", "[", "per_worker_batch_size", ",", "self", ".", "blocks_n", "[", "model_stage", "]", ",", "\n", "self", ".", "freq_n", "[", "model_stage", "]", ",", "self", ".", "channels_n", "[", "model_stage", "]", "]", ")", "\n", "inputs", "=", "tf", ".", "keras", ".", "Input", "(", "batch_input_shape", "=", "batch_input_shape", ",", "name", "=", "'discriminator_input'", ")", "\n", "\n", "# let keras autocast-magic convert inputs to bfloat16 when in mixed_precision mode", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "'linear'", ")", "(", "inputs", ")", "\n", "\n", "x", "=", "self", ".", "split_to_batch", "(", "x", ",", "split", "=", "128", ",", "padding", "=", "[", "35", ",", "50", "]", ")", "\n", "\n", "# first discriminator block:", "\n", "# split input into channels", "\n", "discriminator_block_i", "=", "model_stage", "\n", "in_filter_n", ",", "_", ",", "out_filter_n", "=", "self", ".", "discriminator_filters_n", "(", "discriminator_block_i", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Conv2D", "(", "filters", "=", "in_filter_n", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", "name", "=", "'discriminator_output_conv2d_new'", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "discriminator_block", "(", "x", ",", "discriminator_block_i", ",", "shaving", "=", "True", ")", "\n", "\n", "discriminator_block_i", "=", "model_stage", "-", "1", "\n", "x", "=", "self", ".", "discriminator_block", "(", "x", ",", "discriminator_block_i", ",", "shaving", "=", "True", ")", "\n", "\n", "x", "=", "self", ".", "join_from_batch", "(", "x", ",", "shave", "=", "[", "0", ",", "0", "]", ",", "join_width", "=", "self", ".", "blocks_n", "[", "model_stage", "]", "//", "(", "4", "*", "4", ")", ")", "\n", "\n", "for", "discriminator_block_i", "in", "list", "(", "reversed", "(", "range", "(", "model_stage", "+", "1", ")", ")", ")", "[", "2", ":", "]", ":", "\n", "      ", "x", "=", "self", ".", "discriminator_block", "(", "x", ",", "discriminator_block_i", ")", "\n", "\n", "# add one feature checking the std dev of pixels", "\n", "", "x", "=", "layers", ".", "BatchStddevLayer", "(", "batch_group_size", "=", "1", ",", "device_group_size", "=", "8", ")", "(", "x", ")", "\n", "\n", "# Dense [batches_n, 4, 4-1, 8*dim] -> [batches_n, 8*dim]", "\n", "# One can also see this as a final convolution layer", "\n", "_", ",", "_", ",", "out_filters_n", "=", "self", ".", "discriminator_filters_n", "(", "block_i", "=", "0", ")", "\n", "\n", "# Conv2D(kernel=3x3, 'VALID')", "\n", "# [batches_n, self.base_block_length, 3, channels_n] --> [batches_n, 1, 1, channels_n]", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Flatten", "(", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "units", "=", "out_filters_n", ",", "name", "=", "f'discriminator_conv2d.{self.base_block_length}x1'", ")", "(", "x", ")", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "x", ")", "\n", "\n", "# Connect all channels to single logit", "\n", "# [batches_n, 1, 1, channels_n] --> [batches_n, 1]", "\n", "# make sure output is float32 for numerical stability in gradients(?)", "\n", "#   (see https://www.tensorflow.org/guide/mixed_precision#building_the_model)", "\n", "x", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "units", "=", "1", ",", "name", "=", "'discriminator_fc'", ",", "dtype", "=", "tf", ".", "float32", ")", "(", "x", ")", "\n", "\n", "model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "x", ",", "name", "=", "'discriminator'", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.build_model": [[333, 354], ["tensorflow.distribute.has_strategy", "mp3net.MP3netFactory.make_generator_model", "mp3net.MP3netFactory.make_discriminator_model", "mp3net.MP3net", "mode.lower"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.make_generator_model", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3netFactory.make_discriminator_model"], ["", "def", "build_model", "(", "self", ",", "stage", ",", "global_batch_size", ",", "mode", ")", ":", "\n", "    ", "with_probe", "=", "mode", ".", "lower", "(", ")", "==", "'infer'", "\n", "# not yet initialized, since tf.distribute.Strategy context not yet defined", "\n", "assert", "tf", ".", "distribute", ".", "has_strategy", "(", ")", ",", "\"TranceModel needs to have a strategy context active\"", "\n", "\n", "stage_total_songs", "=", "self", ".", "stage_total_songs", "[", "stage", "]", "\n", "fade_in_progression", "=", "self", ".", "fade_in_progression", "[", "stage", "]", "\n", "drown_progression", "=", "self", ".", "drown_progression", "[", "stage", "]", "\n", "\n", "blocks_n", "=", "self", ".", "blocks_n", "[", "stage", "]", "\n", "freq_n", "=", "self", ".", "freq_n", "[", "stage", "]", "\n", "channels_n", "=", "self", ".", "channels_n", "[", "stage", "]", "\n", "\n", "# generator = self.build_generator(stage)", "\n", "generator", "=", "self", ".", "make_generator_model", "(", "stage", ",", "global_batch_size", ",", "with_probe", "=", "with_probe", ")", "\n", "discriminator", "=", "self", ".", "make_discriminator_model", "(", "stage", ",", "global_batch_size", ",", "mode", ")", "\n", "\n", "return", "MP3net", "(", "stage", ",", "stage_total_songs", ",", "fade_in_progression", ",", "drown_progression", ",", "\n", "blocks_n", ",", "freq_n", ",", "channels_n", ",", "self", ".", "sample_rate", ",", "self", ".", "latent_dim", ",", "\n", "generator", ",", "discriminator", ",", "\n", "global_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.__init__": [[357, 386], ["model.audiorepresentation.AudioRepresentation", "tensorflow.constant", "tensorflow.Variable", "tensorflow.keras.mixed_precision.experimental.global_policy"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "stage", ",", "stage_total_songs", ",", "fade_in_progression", ",", "drown_progression", ",", "\n", "blocks_n", ",", "freq_n", ",", "channels_n", ",", "sample_rate", ",", "latent_dim", ",", "\n", "generator", ":", "tf", ".", "keras", ".", "Model", ",", "discriminator", ":", "tf", ".", "keras", ".", "Model", ",", "\n", "global_batch_size", ")", ":", "\n", "    ", "self", ".", "stage", "=", "stage", "\n", "self", ".", "stage_total_songs", "=", "stage_total_songs", "\n", "\n", "self", ".", "blocks_n", "=", "blocks_n", "\n", "self", ".", "freq_n", "=", "freq_n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "channels_n", "=", "channels_n", "\n", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "\n", "self", ".", "audio_representation", "=", "AudioRepresentation", "(", "self", ".", "sample_rate", ",", "self", ".", "freq_n", ",", "\n", "compute_dtype", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "global_policy", "(", ")", ".", "compute_dtype", ")", "\n", "\n", "self", ".", "global_batch_size", "=", "tf", ".", "constant", "(", "global_batch_size", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# build the models", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "\n", "# progression functions", "\n", "self", ".", "fade_in_progression", "=", "fade_in_progression", "\n", "self", ".", "drown_progression", "=", "drown_progression", "\n", "\n", "# a tf.Variable so we can save it in checkpoint", "\n", "self", ".", "song_counter", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.fade_in": [[387, 389], ["mp3net.MP3net.fade_in_progression"], "methods", ["None"], ["", "def", "fade_in", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "fade_in_progression", "(", "self", ".", "song_counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.drown": [[390, 392], ["mp3net.MP3net.drown_progression"], "methods", ["None"], ["", "def", "drown", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "drown_progression", "(", "self", ".", "song_counter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.summary": [[393, 396], ["utils.tf_utils.summary", "utils.tf_utils.summary"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.summary", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.summary"], ["", "def", "summary", "(", "self", ",", "line_length", "=", "None", ")", ":", "\n", "    ", "utils", ".", "tf_utils", ".", "summary", "(", "self", ".", "generator", ",", "line_length", ")", "\n", "utils", ".", "tf_utils", ".", "summary", "(", "self", ".", "discriminator", ",", "line_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.g_loss_verbose": [[397, 412], ["mp3net.MP3net.generator", "tensorflow.cast", "mp3net.MP3net.audio_representation.psychoacoustic_masking_ampl", "mp3net.MP3net.audio_representation.add_noise", "mp3net.MP3net._global_batch_mean", "mp3net.MP3net.discriminator", "tensorflow.keras.mixed_precision.experimental.global_policy"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._global_batch_mean"], ["", "@", "tf", ".", "function", "\n", "def", "g_loss_verbose", "(", "self", ",", "z_vector", ",", "training", ":", "bool", ")", ":", "\n", "# create fakes", "\n", "    ", "fakes_tf32", "=", "self", ".", "generator", "(", "z_vector", ",", "training", "=", "training", ")", "\n", "fakes", "=", "tf", ".", "cast", "(", "fakes_tf32", ",", "dtype", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "global_policy", "(", ")", ".", "compute_dtype", ")", "\n", "fakes_masking_threshold", "=", "self", ".", "audio_representation", ".", "psychoacoustic_masking_ampl", "(", "fakes", ")", "\n", "fakes_noised", "=", "self", ".", "audio_representation", ".", "add_noise", "(", "fakes", ",", "fakes_masking_threshold", ")", "\n", "\n", "# compute discriminator scores", "\n", "score_fake_ave", "=", "self", ".", "_global_batch_mean", "(", "self", ".", "discriminator", "(", "fakes_noised", ",", "training", "=", "training", ")", ")", "\n", "\n", "# minimizing g_loss will try to push discr_score_fake to +inf! (with fake = -inf, real = +inf)", "\n", "g_loss_ave", "=", "-", "score_fake_ave", "\n", "\n", "return", "g_loss_ave", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.g_loss": [[413, 417], ["mp3net.MP3net.g_loss_verbose"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.g_loss_verbose"], ["", "@", "tf", ".", "function", "\n", "def", "g_loss", "(", "self", ",", "z_vector", ",", "training", ":", "bool", ")", ":", "\n", "    ", "g_loss", "=", "self", ".", "g_loss_verbose", "(", "z_vector", ",", "training", ")", "\n", "return", "g_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.d_loss_verbose": [[418, 453], ["mp3net.MP3net.generator", "tensorflow.cast", "mp3net.MP3net.audio_representation.psychoacoustic_masking_ampl", "mp3net.MP3net.audio_representation.add_noise", "mp3net.MP3net.discriminator", "mp3net.MP3net.discriminator", "mp3net.MP3net._global_batch_mean", "mp3net.MP3net._global_batch_mean", "mp3net.MP3net._global_batch_mean", "mp3net.MP3net._gradient_penalty", "tensorflow.square", "tensorflow.keras.mixed_precision.experimental.global_policy", "mp3net.MP3net.drown"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.psychoacoustic_masking_ampl", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.audiorepresentation.AudioRepresentation.add_noise", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._global_batch_mean", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._global_batch_mean", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._global_batch_mean", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._gradient_penalty", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.drown"], ["", "@", "tf", ".", "function", "\n", "def", "d_loss_verbose", "(", "self", ",", "z_vector", ",", "reals_noised", ",", "training", ":", "bool", ")", ":", "\n", "# create fakes", "\n", "    ", "fakes_tf32", "=", "self", ".", "generator", "(", "z_vector", ",", "training", "=", "training", ")", "\n", "fakes", "=", "tf", ".", "cast", "(", "fakes_tf32", ",", "dtype", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "global_policy", "(", ")", ".", "compute_dtype", ")", "\n", "fakes_masking_threshold", "=", "self", ".", "audio_representation", ".", "psychoacoustic_masking_ampl", "(", "fakes", ")", "\n", "fakes_noised", "=", "self", ".", "audio_representation", ".", "add_noise", "(", "fakes", ",", "fakes_masking_threshold", ")", "\n", "\n", "# compute discriminator scores", "\n", "discr_score_fake", "=", "self", ".", "discriminator", "(", "fakes_noised", ",", "training", "=", "training", ")", "\n", "discr_score_real", "=", "self", ".", "discriminator", "(", "reals_noised", ",", "training", "=", "training", ")", "\n", "\n", "# Wasserstein-1 = Earth Mover distance (EMD) between 2 distribution", "\n", "#   (see https://en.wikipedia.org/wiki/Wasserstein_metric)", "\n", "# Wasserstein-1 is not computed directly, rather in its dual Kantorovich-Rubinstein formulation,", "\n", "# which requires the function f (discriminator) to be Lipschitz-1 (so, we need a gradient penalty)", "\n", "#   (see section 3 of https://arxiv.org/pdf/1701.07875.pdf)", "\n", "wasserstein_distance", "=", "self", ".", "_global_batch_mean", "(", "discr_score_fake", "-", "discr_score_real", ")", "\n", "\n", "# We could brute-force compute Wasserstein-1 = EMD directly on large batches with EMD algo", "\n", "# and drop the Lipschitz-1 constraint (so, no gradient penalty)", "\n", "# BUT, requiring the discriminator to be Lipschitz-1, makes our loss function", "\n", "# continuous and differentiable which improves the minimization", "\n", "#   (see theorem 1 of https://arxiv.org/pdf/1701.07875.pdf)", "\n", "grad_penalty_ave", "=", "self", ".", "_global_batch_mean", "(", "\n", "self", ".", "_gradient_penalty", "(", "reals_noised", ",", "fakes_noised", ")", ")", "\n", "\n", "# tf.square term locks in place the real discriminator scores so they don't run away and overpower the grad_penalty", "\n", "#   (see appendix A.1 of https://arxiv.org/pdf/1710.10196.pdf)", "\n", "drift_ave", "=", "self", ".", "_global_batch_mean", "(", "tf", ".", "square", "(", "discr_score_real", ")", ")", "\n", "\n", "# high GP coefficient prevents model collapse, but reduces model performance (see BigGAN paper)", "\n", "d_loss_ave", "=", "wasserstein_distance", "+", "self", ".", "drown", "(", ")", "*", "grad_penalty_ave", "+", "0.1", "*", "drift_ave", "\n", "\n", "return", "d_loss_ave", ",", "(", "wasserstein_distance", ",", "grad_penalty_ave", ",", "drift_ave", ")", ",", "(", "discr_score_fake", ",", "discr_score_real", ")", ",", "(", "fakes_tf32", ",", "fakes_noised", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.d_loss": [[454, 458], ["mp3net.MP3net.d_loss_verbose"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net.d_loss_verbose"], ["", "@", "tf", ".", "function", "\n", "def", "d_loss", "(", "self", ",", "z_vector", ",", "real_noised", ",", "training", ":", "bool", ")", ":", "\n", "    ", "d_loss", ",", "_", ",", "_", ",", "_", "=", "self", ".", "d_loss_verbose", "(", "z_vector", ",", "real_noised", ",", "training", ")", "\n", "return", "d_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._gradient_penalty": [[459, 495], ["tensorflow.random.uniform", "tape.gradient", "tensorflow.sqrt", "tensorflow.shape", "tensorflow.GradientTape", "tape.watch", "mp3net.MP3net.discriminator", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reshape", "tensorflow.shape"], "methods", ["None"], ["", "@", "tf", ".", "function", "\n", "def", "_gradient_penalty", "(", "self", ",", "reals", ",", "fakes", ")", ":", "\n", "    ", "\"\"\"\n\n    :param reals:               a real input\n    :param fakes:               a faked input (from generator)\n    :return:                    penalty factor                        [batches_n, 1]\n    \"\"\"", "\n", "# instead of clipping the weights, this alternative condition also imposes the Lipschitz constraint", "\n", "# (see: https://medium.com/@jonathan_hui/gan-wasserstein-gan-wgan-gp-6a1a2aa1b490 and", "\n", "# https://github.com/KUASWoodyLIN/TF2-WGAN/blob/master/utils/losses.py)", "\n", "# prediction should go from real (+inf) to fake (-inf)", "\n", "# pick an interpolation (alpha) and compute gradient there", "\n", "\n", "# different alpha for each element in batch", "\n", "batches_n", "=", "tf", ".", "shape", "(", "reals", ")", "[", "0", "]", "\n", "shape", "=", "[", "batches_n", "]", "+", "[", "1", "]", "*", "(", "reals", ".", "shape", ".", "ndims", "-", "1", ")", "\n", "alpha", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "0.", ",", "maxval", "=", "1.", ",", "dtype", "=", "reals", ".", "dtype", ")", "\n", "\n", "interpolated", "=", "alpha", "*", "reals", "+", "(", "1.", "-", "alpha", ")", "*", "fakes", "\n", "\n", "with", "tf", ".", "GradientTape", "(", ")", "as", "tape", ":", "\n", "      ", "tape", ".", "watch", "(", "interpolated", ")", "\n", "discr_score_interpolated", "=", "self", ".", "discriminator", "(", "interpolated", ",", "training", "=", "True", ")", "\n", "\n", "# with mixed_bfloat16, these gradients will be bfloat16", "\n", "", "gradients_new", "=", "tape", ".", "gradient", "(", "discr_score_interpolated", ",", "interpolated", ")", "\n", "\n", "# norm.shape = [batches_n, 1]", "\n", "norm", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "reshape", "(", "gradients_new", ",", "shape", "=", "[", "tf", ".", "shape", "(", "gradients_new", ")", "[", "0", "]", ",", "-", "1", "]", ")", "**", "2", ",", "\n", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "+", "_EPS", ")", "\n", "\n", "# gradient penalty loss function (forces it to 1)", "\n", "# [batches_n, 1]", "\n", "# cast to float32 since entire loss function is float32", "\n", "return", "(", "tf", ".", "cast", "(", "norm", ",", "dtype", "=", "tf", ".", "float32", ")", "-", "1.", ")", "**", "2.", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.mp3net.MP3net._global_batch_mean": [[496, 510], ["tensorflow.reduce_sum", "tensorflow.cast"], "methods", ["None"], ["", "def", "_global_batch_mean", "(", "self", ",", "batch_from_replica", ")", ":", "\n", "    ", "\"\"\"\n    Variables on replicas need to be divided by the global_batch_size (not the per_replica_batch_size)\n    since apply_gradients() adds gradients of each replica (without dividing by the number of replica!)\n\n    see: https://www.tensorflow.org/guide/distributed_training#examples_and_tutorials\n      When apply_gradients is called within a distribution strategy scope, its behavior is modified.\n      Specifically, before applying gradients on each parallel instance during synchronous training,\n      it performs a sum-over-all-replicas of the gradients\n\n    :param batch_from_replica:   batch of values from one replica to be averaged over all batches\n    :return:                     average\n    \"\"\"", "\n", "return", "tf", ".", "reduce_sum", "(", "batch_from_replica", ")", "/", "tf", ".", "cast", "(", "self", ".", "global_batch_size", ",", "dtype", "=", "batch_from_replica", ".", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.dataloader.slice_into_fixed_length": [[8, 36], ["tensorflow.map_fn", "ValueError", "tensorflow.shape", "tensorflow.range"], "function", ["None"], ["@", "tf", ".", "function", "\n", "def", "slice_into_fixed_length", "(", "audio", ",", "slice_len", ",", "slice_hop", ",", "slice_first_only", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Slice up audio into fixed-length fragments\n\n  :param audio:                (un-batched) tensor encoding audio data [blocks_n, freqs_n, channels_n, 2]\n  :param slice_len:            block length of output slices\n  :param slice_hop:            number of blocks in-between slices\n                               Note: don't set this too low, as it will explode the dataset\n  :param slice_first_only:     if True, then only first slice is returned. Defaults to False\n  :return:                     sequence of tensors of shape [slice_len, freqs_n, channels_n, 2]\n  \"\"\"", "\n", "# note: batches_n dimension is not present!", "\n", "if", "slice_hop", "<", "1", ":", "\n", "    ", "raise", "ValueError", "(", "'Overlap ratio too high'", ")", "\n", "\n", "", "blocks_n", "=", "tf", ".", "shape", "(", "audio", ")", "[", "0", "]", "\n", "\n", "# Extract sliceuences [blocks_n, freqs_n, channels_n, data/noise]", "\n", "audio_slices", "=", "tf", ".", "map_fn", "(", "fn", "=", "lambda", "start", ":", "audio", "[", "start", ":", "start", "+", "slice_len", ",", ":", ",", ":", ",", ":", "]", ",", "\n", "elems", "=", "tf", ".", "range", "(", "0", ",", "blocks_n", "-", "slice_len", "+", "1", ",", "slice_hop", ")", ",", "\n", "fn_output_signature", "=", "audio", ".", "dtype", ")", "\n", "\n", "# Only use first slice if requested", "\n", "if", "slice_first_only", ":", "\n", "    ", "audio_slices", "=", "audio_slices", "[", "0", ":", "1", ",", ":", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "", "return", "audio_slices", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.dataloader.load_dataset": [[38, 122], ["tensorflow.data.Dataset.from_tensor_slices", "dataset.shuffle.shard", "dataset.shuffle.interleave", "dataset.shuffle.map", "dataset.shuffle.filter", "dataset.shuffle.interleave", "distributed_context.get_per_replica_batch_size", "print", "print", "print", "dataset.shuffle.batch", "dataset.shuffle.prefetch", "tensorflow.io.parse_tensor", "tensorflow.cast", "audio.set_shape", "dataloader.slice_into_fixed_length", "tensorflow.data.Dataset.from_tensor_slices", "dataset.shuffle.repeat", "dataset.shuffle.shuffle", "tensorflow.data.TFRecordDataset", "tensorflow.shape", "tensorflow.keras.mixed_precision.experimental.global_policy"], "function", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.model.dataloader.slice_into_fixed_length"], ["", "def", "load_dataset", "(", "\n", "distributed_context", ",", "\n", "input_filenames", ",", "\n", "global_batch_size", ",", "\n", "slice_len", ",", "\n", "slice_hop", ",", "\n", "freq_n", ",", "channels_n", ",", "\n", "repeat", "=", "False", ",", "\n", "shuffle", "=", "False", ",", "\n", "shuffle_buffer_size", "=", "None", ",", "\n", "tpu", "=", "False", ")", ":", "\n", "  ", "\"\"\"Decodes audio file paths into mini-batches of samples.\n\n  Args:\n    distributed_context: input_context class containing information on how we can pipe data into the distributed cluster\n    input_filenames: filename and path of preprocessed audio file path\n    global_batch_size: Number of items in the batch.\n    repeat: If true (for training), continuously iterate through the dataset.\n    shuffle: If true (for training), buffer and shuffle the sliceuences.\n    shuffle_buffer_size: Number of examples to queue up before grabbing a batch.\n    tpu: Flag to indicate whether we run on a TPU (default = False)\n\n  Returns:\n    A dataset with tensor of the form [batches_n, blocks_n, freqs_n, channels_n=1]\n  \"\"\"", "\n", "# Create dataset of filepaths (still on CPU)", "\n", "# dataset = tf.data.TFRecordDataset(input_filenames, compression_type=\"GZIP\",", "\n", "#                                   num_parallel_reads=tf.data.experimental.AUTOTUNE)", "\n", "# note: if file is TOO small (e.g. needs to load 2x to fill one batch) then CPU might become the bottleneck (gzip...)", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "input_filenames", ")", "\n", "\n", "# - Be sure to shard before you use any randomizing operator (such as shuffle).", "\n", "# - Generally it is best if the shard operator is used early in the dataset", "\n", "#   pipeline. For example, when reading from a set of TFRecord files, shard", "\n", "#   before converting the dataset to input samples. This avoids reading every", "\n", "#   file on every worker. The following is an example of an efficient", "\n", "#   sharding strategy within a complete pipeline:", "\n", "dataset", "=", "dataset", ".", "shard", "(", "distributed_context", ".", "num_input_pipelines", ",", "distributed_context", ".", "input_pipeline_id", ")", "\n", "\n", "# open files (they contain string-ized tensors)", "\n", "dataset", "=", "dataset", ".", "interleave", "(", "lambda", "filename", ":", "tf", ".", "data", ".", "TFRecordDataset", "(", "filename", ",", "compression_type", "=", "\"GZIP\"", ")", ",", "\n", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ",", "\n", "deterministic", "=", "False", ")", "\n", "\n", "def", "read_and_cast", "(", "x", ")", ":", "\n", "# convert string-ized tensors to float32 tensors", "\n", "    ", "x", "=", "tf", ".", "io", ".", "parse_tensor", "(", "x", ",", "tf", ".", "float32", ")", "\n", "# convert to keras compute_dtype", "\n", "x", "=", "tf", ".", "cast", "(", "x", ",", "dtype", "=", "tf", ".", "keras", ".", "mixed_precision", ".", "experimental", ".", "global_policy", "(", ")", ".", "compute_dtype", ")", "\n", "return", "x", "\n", "", "dataset", "=", "dataset", ".", "map", "(", "read_and_cast", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "def", "filter_short_samples", "(", "audio", ")", ":", "\n", "# only keep samples which are long enough", "\n", "    ", "return", "tf", ".", "shape", "(", "audio", ")", "[", "0", "]", ">=", "slice_len", "\n", "", "dataset", "=", "dataset", ".", "filter", "(", "filter_short_samples", ")", "\n", "\n", "# slice on the fly (otherwise too much data to save to GCS and e-gress...)", "\n", "def", "_slice_file_wrapper", "(", "audio", ")", ":", "\n", "# set shape [blocks_n, freqs_n, channels_n=1, data/masking]", "\n", "    ", "audio", ".", "set_shape", "(", "[", "None", ",", "freq_n", ",", "channels_n", ",", "2", "]", ")", "\n", "\n", "audio_slices", "=", "slice_into_fixed_length", "(", "audio", ",", "slice_len", "=", "slice_len", ",", "slice_hop", "=", "slice_hop", ")", "\n", "return", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "audio_slices", ")", "\n", "", "dataset", "=", "dataset", ".", "interleave", "(", "_slice_file_wrapper", ",", "num_parallel_calls", "=", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "# I prefer repeat & shuffle to be done on the individual tensors,", "\n", "# not on the inputfiles (since then order in file is always the same)", "\n", "if", "repeat", ":", "dataset", "=", "dataset", ".", "repeat", "(", ")", "\n", "\n", "if", "shuffle", ":", "dataset", "=", "dataset", ".", "shuffle", "(", "buffer_size", "=", "shuffle_buffer_size", ")", "\n", "\n", "# Make batches (each worker will chew off a per_worker_batch_size)", "\n", "per_worker_batch_size", "=", "distributed_context", ".", "get_per_replica_batch_size", "(", "global_batch_size", ")", "\n", "print", "(", "\"Loading dataset:\"", ")", "\n", "print", "(", "\"  batch_size = {}\"", ".", "format", "(", "global_batch_size", ")", ")", "\n", "print", "(", "\"  per_worker_batch_size = {}\"", ".", "format", "(", "per_worker_batch_size", ")", ")", "\n", "\n", "dataset", "=", "dataset", ".", "batch", "(", "per_worker_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "\n", "# this starts fetching on host (cpu) while device (gpu/tpu) is still training previous batch", "\n", "dataset", ".", "prefetch", "(", "tf", ".", "data", ".", "experimental", ".", "AUTOTUNE", ")", "\n", "\n", "return", "dataset", "", "", ""]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.__init__": [[13, 28], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.__init__"], ["def", "__init__", "(", "self", ",", "batch_group_size", ",", "device_group_size", ",", "num_new_features", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n\n    :param batch_group_size:    Number of replicas to average over. Has to be a divisor of the\n    :param device_group_size:   Number of replicas to average over.\n                                Has to be either 1 (no average over devices), or the total number of replicas.\n                                Values in-between do not give the right value!\n    :param num_new_features:    Number of new feature to create with this layer\n    \"\"\"", "\n", "super", "(", "BatchStddevLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# should NOT be converted to tf.constant (tf.reshape expects fixed python constant)", "\n", "self", ".", "batch_group_size", "=", "batch_group_size", "\n", "self", ".", "device_group_size", "=", "device_group_size", "\n", "self", ".", "num_new_features", "=", "num_new_features", "\n", "self", ".", "s", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.build": [[29, 33], ["None"], "methods", ["None"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "# [NHWC]  Input shape.", "\n", "    ", "self", ".", "s", "=", "input_shape", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.call": [[34, 59], ["tensorflow.reshape", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.sqrt", "tensorflow.reduce_mean", "tensorflow.squeeze", "tensorflow.cast", "tensorflow.tile", "tensorflow.concat", "utils.reduce_mean_over_replica_group", "utils.reduce_mean_over_replica_group"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.tf_ops.reduce_mean_over_replica_group", "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.utils.tf_ops.reduce_mean_over_replica_group"], ["", "@", "tf", ".", "function", "\n", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "    ", "y", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "batch_group_size", ",", "\n", "self", ".", "s", "[", "1", "]", ",", "self", ".", "s", "[", "2", "]", ",", "\n", "self", ".", "s", "[", "3", "]", "//", "self", ".", "num_new_features", ",", "self", ".", "num_new_features", "]", ")", "\n", "y", "=", "tf", ".", "cast", "(", "y", ",", "tf", ".", "float32", ")", "# D x [MG H W cn]  Cast to FP32", "\n", "\n", "y_ave", "=", "tf", ".", "reduce_mean", "(", "y", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "# 1 x [M1 H W cn]  Mean over group G(=group_size) and devices D", "\n", "if", "self", ".", "device_group_size", ">", "1", ":", "\n", "      ", "y_ave", "=", "tf_ops", ".", "reduce_mean_over_replica_group", "(", "y_ave", ",", "self", ".", "device_group_size", ")", "\n", "\n", "", "y", "=", "tf", ".", "square", "(", "y", "-", "y_ave", ")", "# D x [MG H W cn]  Subtract the mean over group G(=group_size)", "\n", "\n", "y", "=", "tf", ".", "reduce_mean", "(", "y", ",", "axis", "=", "1", ")", "# . x [M  H W cn]  Calc variance over group G(=group_size) and devices D", "\n", "if", "self", ".", "device_group_size", ">", "1", ":", "\n", "      ", "y", "=", "tf_ops", ".", "reduce_mean_over_replica_group", "(", "y", ",", "self", ".", "device_group_size", ")", "\n", "\n", "", "y", "=", "tf", ".", "sqrt", "(", "y", "+", "1e-8", ")", "# . x [M  H W cn]  Calc stddev over group G(=group_size)", "\n", "y", "=", "tf", ".", "reduce_mean", "(", "y", ",", "axis", "=", "[", "1", ",", "2", ",", "3", "]", ",", "keepdims", "=", "True", ")", "# . x [M  1 1 1n]  Take average of these stddev over fmaps (c) and pixels (HW) --> (M x n values)", "\n", "y", "=", "tf", ".", "squeeze", "(", "y", ",", "axis", "=", "[", "3", "]", ")", "# . x [M  1 1  n]  Remove c-dimension", "\n", "\n", "y", "=", "tf", ".", "cast", "(", "y", ",", "inputs", ".", "dtype", ")", "# . x [M  1 1  n]  Cast back to original data type", "\n", "y", "=", "tf", ".", "tile", "(", "y", ",", "[", "self", ".", "batch_group_size", ",", "\n", "self", ".", "s", "[", "1", "]", ",", "self", ".", "s", "[", "2", "]", ",", "1", "]", ")", "# . x [N  H W  n]  Replicate over group and pixels (copy-paste same value to all features & pixels)", "\n", "return", "tf", ".", "concat", "(", "[", "inputs", ",", "y", "]", ",", "axis", "=", "3", ")", "# . x [N  H W  (C+n)]  Append as new fmap.", "\n", "\n"]], "home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.get_config": [[60, 68], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.korneelvdbroek_mp3net.layers.batch_stddev_layer.BatchStddevLayer.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "    ", "config", "=", "super", "(", "BatchStddevLayer", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\n", "'batch_group_size'", ":", "self", ".", "batch_group_size", ",", "\n", "'device_group_size'", ":", "self", ".", "device_group_size", ",", "\n", "'num_new_features'", ":", "self", ".", "num_new_features", "\n", "}", ")", "\n", "return", "config", "\n", "", "", ""]]}