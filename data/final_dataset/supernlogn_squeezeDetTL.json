{"home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.None.make_user_compatible.get_replaced_contents": [[38, 53], ["open", "REPLACEMENT_MAP.keys", "new_lines.append", "s.replace.replace"], "function", ["None"], ["def", "get_replaced_contents", "(", "file_path", ")", ":", "\n", "  ", "\"\"\"\n    Args:\n      Path to the file to have its contents replaced.\n    Return:\n      The new file's contents after replacement as a list of lines.\n  \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "new_lines", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "      ", "s", "=", "line", "\n", "for", "r_m", "in", "REPLACEMENT_MAP", ".", "keys", "(", ")", ":", "\n", "        ", "s", "=", "s", ".", "replace", "(", "r_m", ",", "REPLACEMENT_MAP", "[", "r_m", "]", ")", "\n", "", "new_lines", ".", "append", "(", "s", ")", "\n", "", "return", "new_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.None.make_user_compatible.write_lines": [[54, 57], ["open", "f.writelines"], "function", ["None"], ["", "", "def", "write_lines", "(", "file_path", ",", "r_c", ")", ":", "\n", "  ", "with", "open", "(", "_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "writelines", "(", "r_c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start": [[16, 55], ["supervisor.load_config.super_config", "numpy.array", "str", "config.config_cooker.direct_cook_config", "config.config_cooker.cook_config", "os.path.join", "os.path.join", "supervisor.evaluator.evaluate_once", "hypervisor.hyperparam_tuner.hopt_training", "supervisor.trainer.train", "config.config_cooker.cook_config.keys"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.load_config.super_config", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.direct_cook_config", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.cook_config", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate_once", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.hopt_training", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.trainer.train"], ["def", "start", "(", "args", ")", ":", "# pylint: disable=unused-argument", "\n", "  ", "\"\"\"\n    Descr:\n      initiates the training process, to the right path with the right configuration\n      file.\n    Args:\n      args: a dictionary containing\n        [\"TRAIN_DIR\"] = Where checkpoints and tensorboard files will be saved during training\n        [\"ext_config_file_path\"] = A string of the external configuration json file path\n        [\"mc_direct\"] = whether to read the model configuration file directly\n  \"\"\"", "\n", "sc", "=", "super_config", "(", ")", "\n", "if", "(", "\"mc_direct\"", "in", "args", "and", "args", "[", "\"mc_direct\"", "]", ")", ":", "\n", "    ", "mc", "=", "direct_cook_config", "(", "args", ",", "do_set_anchors", "=", "True", ")", "\n", "", "else", ":", "\n", "    ", "mc", "=", "cook_config", "(", "args", "[", "\"ext_config_file_path\"", "]", ")", "\n", "", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "# copy non existent key-value pairs from sc to mc", "\n", "for", "c", "in", "sc", ":", "\n", "    ", "if", "(", "not", "c", "in", "mc", ".", "keys", "(", ")", ")", ":", "\n", "      ", "mc", "[", "c", "]", "=", "sc", "[", "c", "]", "\n", "\n", "# make a train dir target", "\n", "", "", "if", "not", "\"TRAIN_DIR\"", "in", "mc", ":", "\n", "    ", "mc", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"train\"", ")", "\n", "\n", "# make an eval dir target", "\n", "", "if", "not", "\"EVAL_DIR\"", "in", "mc", ":", "\n", "    ", "mc", "[", "\"EVAL_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"evals\"", ")", "\n", "\n", "", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "mc", "[", "\"GPU\"", "]", ")", "\n", "if", "(", "mc", "[", "\"IS_TRAINING\"", "]", ")", ":", "\n", "    ", "if", "(", "\"HOPT\"", "in", "mc", ")", ":", "\n", "      ", "hyperparam_tuner", ".", "hopt_training", "(", "mc", ")", "\n", "", "else", ":", "\n", "      ", "train", "(", "mc", ")", "\n", "", "", "else", ":", "\n", "    ", "evaluate_once", "(", "mc", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.main": [[56, 69], ["os.path.exists", "auto_ITL.start"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "\"\"\"\n    check arguments provided by the user and launch\n    the framework.\n  \"\"\"", "\n", "assert", "FLAGS", ".", "config_file", "!=", "''", ",", "'No config file was specified'", "\n", "assert", "os", ".", "path", ".", "exists", "(", "FLAGS", ".", "config_file", ")", ",", "'Config file path does not exist'", "\n", "\n", "start", "(", "args", "=", "{", "\"ext_config_file_path\"", ":", "FLAGS", ".", "config_file", "}", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.caffemodel2pkl.dump_caffemodel_weights": [[20, 30], ["caffe.Net", "len", "range", "joblib.dump"], "function", ["None"], ["def", "dump_caffemodel_weights", "(", ")", ":", "\n", "  ", "net", "=", "caffe", ".", "Net", "(", "args", ".", "prototxt_path", ",", "args", ".", "caffemodel_path", ",", "caffe", ".", "TEST", ")", "\n", "weights", "=", "{", "}", "\n", "n_layers", "=", "len", "(", "net", ".", "layers", ")", "\n", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "    ", "layer_name", "=", "net", ".", "_layer_names", "[", "i", "]", "\n", "layer", "=", "net", ".", "layers", "[", "i", "]", "\n", "layer_blobs", "=", "[", "o", ".", "data", "for", "o", "in", "layer", ".", "blobs", "]", "\n", "weights", "[", "layer_name", "]", "=", "layer_blobs", "\n", "", "joblib", ".", "dump", "(", "weights", ",", "args", ".", "caffe_weights_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.timer.Timer.__init__": [[3, 9], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "total_time", "=", "0.0", "\n", "self", ".", "calls", "=", "0", "\n", "self", ".", "start_time", "=", "0.0", "\n", "self", ".", "duration", "=", "0.0", "\n", "self", ".", "average_time", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.timer.Timer.tic": [[10, 12], ["time.time"], "methods", ["None"], ["", "def", "tic", "(", "self", ")", ":", "\n", "    ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.timer.Timer.toc": [[13, 22], ["time.time"], "methods", ["None"], ["", "def", "toc", "(", "self", ",", "average", "=", "True", ")", ":", "\n", "    ", "self", ".", "duration", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "total_time", "+=", "self", ".", "duration", "\n", "self", ".", "calls", "+=", "1", "\n", "self", ".", "average_time", "=", "self", ".", "total_time", "/", "self", ".", "calls", "\n", "if", "average", ":", "\n", "      ", "return", "self", ".", "average_time", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "duration", "", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.batch_iou": [[12, 65], ["tensorflow.truediv", "numpy.finfo", "tensorflow.name_scope", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.minimum", "tensorflow.maximum", "tensorflow.multiply", "tensorflow.variable_scope", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.cast", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.constant", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.constant", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["def", "batch_iou", "(", "boxes1", ",", "boxes2", ",", "N", ",", "M", ",", "EPSILON", "=", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", ")", ":", "\n", "  ", "\"\"\" Computes the iou between two arrays\n      of boxes.\n      Args:\n        boxes1: a python dictionary containing\n                {\n                  \"xmin\" : Tensor of shape [N]\n                  \"xmax\" : Tensor of shape [N]\n                  \"ymin\" : Tensor of shape [N]\n                  \"ymax\" : Tensor of shape [N]\n                }\n        boxes2: a python dictionary containing\n                {\n                  \"xmin\" : Tensor of shape [M]\n                  \"xmax\" : Tensor of shape [M]\n                  \"ymin\" : Tensor of shape [M]\n                  \"ymax\" : Tensor of shape [M]\n                }\n        N, M : 0-D Tensors of M,N sizes\n      Returns:\n        Intersection over union with shape [M,N]\n  \"\"\"", "\n", "# TODO: look util.mass_iou to avoid transpose and reshape", "\n", "with", "tf", ".", "name_scope", "(", "'intersection'", ")", ":", "\n", "    ", "xmin1", "=", "boxes1", "[", "\"xmin\"", "]", "\n", "xmin2", "=", "boxes2", "[", "\"xmin\"", "]", "\n", "xmin", "=", "tf", ".", "maximum", "(", "xmin1", ",", "tf", ".", "expand_dims", "(", "xmin2", ",", "1", ")", ",", "name", "=", "'xmin'", ")", "\n", "\n", "xmax1", "=", "boxes1", "[", "\"xmax\"", "]", "+", "1.0", "\n", "xmax2", "=", "boxes2", "[", "\"xmax\"", "]", "+", "1.0", "\n", "xmax", "=", "tf", ".", "minimum", "(", "xmax1", ",", "tf", ".", "expand_dims", "(", "xmax2", ",", "1", ")", ",", "name", "=", "'xmax'", ")", "\n", "w", "=", "tf", ".", "maximum", "(", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "xmax", ".", "dtype", ")", ",", "xmax", "-", "xmin", ",", "name", "=", "'inter_w'", ")", "\n", "\n", "ymin1", "=", "boxes1", "[", "\"ymin\"", "]", "\n", "ymin2", "=", "boxes2", "[", "\"ymin\"", "]", "\n", "ymin", "=", "tf", ".", "maximum", "(", "ymin1", ",", "tf", ".", "expand_dims", "(", "ymin2", ",", "1", ")", ",", "name", "=", "'ymin'", ")", "\n", "\n", "ymax1", "=", "boxes1", "[", "\"ymax\"", "]", "+", "1.0", "\n", "ymax2", "=", "boxes2", "[", "\"ymax\"", "]", "+", "1.0", "\n", "ymax", "=", "tf", ".", "minimum", "(", "ymax1", ",", "tf", ".", "expand_dims", "(", "ymax2", ",", "1", ")", ",", "name", "=", "'ymax'", ")", "\n", "h", "=", "tf", ".", "maximum", "(", "tf", ".", "constant", "(", "0", ",", "dtype", "=", "ymax", ".", "dtype", ")", ",", "ymax", "-", "ymin", ",", "name", "=", "'inter_h'", ")", "\n", "\n", "intersection", "=", "tf", ".", "multiply", "(", "w", ",", "h", ",", "name", "=", "'intersection'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'union'", ")", ":", "\n", "    ", "w1", "=", "tf", ".", "subtract", "(", "xmax1", ",", "xmin1", ",", "name", "=", "'w1'", ")", "\n", "h1", "=", "tf", ".", "subtract", "(", "ymax1", ",", "ymin1", ",", "name", "=", "'h1'", ")", "\n", "w2", "=", "tf", ".", "subtract", "(", "xmax2", ",", "xmin2", ",", "name", "=", "'w2'", ")", "\n", "h2", "=", "tf", ".", "subtract", "(", "ymax2", ",", "ymin2", ",", "name", "=", "'h2'", ")", "\n", "\n", "union", "=", "tf", ".", "cast", "(", "tf", ".", "expand_dims", "(", "w1", "*", "h1", ",", "0", ")", "+", "tf", ".", "expand_dims", "(", "w2", "*", "h2", ",", "1", ")", "-", "intersection", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "return", "tf", ".", "truediv", "(", "tf", ".", "cast", "(", "intersection", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "union", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.compute_distances": [[66, 93], ["tensorflow.variable_scope", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "compute_distances", "(", "box_centers1", ",", "box_centers2", ",", "N", ",", "M", ")", ":", "\n", "  ", "\"\"\"\n    Args:\n      box_centers1 : dict of {\n        \"x\" : tensor array of center's x of shape [N]\n        \"y\" : tensor array of centers' y of shape [N]\n        \"w\" : tensor array of centers' w of shape [N]\n        \"h\" : tensor array of centers' h of shape [N]\n      }\n      box_centers2 : dict of {\n        \"x\" : tensor array of center's x of shape [M]\n        \"y\" : tensor array of centers' y of shape [M]\n        \"w\" : tensor array of centers' w of shape [M]\n        \"h\" : tensor array of centers' h of shape [M]\n      }\n    Returns:\n      a Tensor with shape [M,N] where all the squared distances \n      between bbox_centers1 and box_centers2 are computed.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"box_distances\"", ")", ":", "\n", "    ", "dx2", "=", "tf", ".", "square", "(", "tf", ".", "expand_dims", "(", "box_centers2", "[", "\"x\"", "]", ",", "1", ")", "-", "box_centers1", "[", "\"x\"", "]", ")", "\n", "dy2", "=", "tf", ".", "square", "(", "tf", ".", "expand_dims", "(", "box_centers2", "[", "\"y\"", "]", ",", "1", ")", "-", "box_centers1", "[", "\"y\"", "]", ")", "\n", "dw2", "=", "tf", ".", "square", "(", "tf", ".", "expand_dims", "(", "box_centers2", "[", "\"w\"", "]", ",", "1", ")", "-", "box_centers1", "[", "\"w\"", "]", ")", "\n", "dh2", "=", "tf", ".", "square", "(", "tf", ".", "expand_dims", "(", "box_centers2", "[", "\"h\"", "]", ",", "1", ")", "-", "box_centers1", "[", "\"h\"", "]", ")", "\n", "sq_dist", "=", "dx2", "+", "dy2", "+", "dw2", "+", "dh2", "\n", "\n", "", "return", "sq_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.batch_bbox_transform": [[94, 109], ["numpy.reshape"], "function", ["None"], ["", "def", "batch_bbox_transform", "(", "bbox", ")", ":", "\n", "  ", "\"\"\"convert a batch of bboxes of form [cx, cy, w, h] to [xmin, ymin, xmax, ymax]. Works\n     for numpy array or list of tensors.\n  \"\"\"", "\n", "reshaped_box", "=", "np", ".", "reshape", "(", "bbox", ",", "newshape", "=", "(", "-", "1", ",", "4", ")", ")", "\n", "\n", "xmin", "=", "reshaped_box", "[", ":", ",", "0", "]", "-", "reshaped_box", "[", ":", ",", "2", "]", "/", "2", "\n", "ymin", "=", "reshaped_box", "[", ":", ",", "1", "]", "-", "reshaped_box", "[", ":", ",", "3", "]", "/", "2", "\n", "xmax", "=", "reshaped_box", "[", ":", ",", "0", "]", "+", "reshaped_box", "[", ":", ",", "2", "]", "/", "2", "\n", "ymax", "=", "reshaped_box", "[", ":", ",", "1", "]", "+", "reshaped_box", "[", ":", ",", "3", "]", "/", "2", "\n", "return", "{", "\n", "\"xmin\"", ":", "xmin", ",", "\n", "\"ymin\"", ":", "ymin", ",", "\n", "\"xmax\"", ":", "xmax", ",", "\n", "\"ymax\"", ":", "ymax", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util._tf_dense_to_sparse_tensor": [[110, 118], ["tensorflow.SparseTensor", "tensorflow.gather_nd", "tensorflow.shape"], "function", ["None"], ["", "def", "_tf_dense_to_sparse_tensor", "(", "idx", ",", "tens", ")", ":", "\n", "  ", "\"\"\"\n    Returns:\n      a sparse tensor by taking the elements \n      of tens described in inidices.\n  \"\"\"", "\n", "return", "tf", ".", "SparseTensor", "(", "idx", ",", "tf", ".", "gather_nd", "(", "tens", ",", "idx", ")", ",", "tf", ".", "shape", "(", "tens", ",", "out_type", "=", "tf", ".", "int64", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.utils_test.test_batch_iou_vs_massive_iou": [[10, 60], ["numpy.stack", "numpy.stack", "tf_util.batch_iou", "tf.Session.run", "numpy.array().astype", "numpy.array().astype", "range", "numpy.array", "print", "print", "print", "print", "print", "numpy.random.random", "numpy.random.random", "tensorflow.constant", "numpy.random.random", "numpy.random.random", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session", "len", "util.batch_iou", "np.array.append", "numpy.shape", "numpy.shape", "numpy.abs", "numpy.max", "numpy.max", "boxes1.keys", "boxes1.keys", "numpy.array", "numpy.array", "numpy.abs", "numpy.abs", "numpy.random.random", "numpy.random.random", "numpy.random.random", "numpy.random.random", "util.bbox_transform_inv", "util.bbox_transform_inv", "numpy.argsort", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv"], ["def", "test_batch_iou_vs_massive_iou", "(", "sess", "=", "None", ")", ":", "\n", "  ", "WIDTH", "=", "1248.0", "\n", "HEIGHT", "=", "384.0", "\n", "N", "=", "3000", "\n", "M", "=", "200", "\n", "xmin1", "=", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", "*", "WIDTH", "\n", "ymin1", "=", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", "*", "HEIGHT", "\n", "boxes1", "=", "{", "\n", "\"xmin\"", ":", "xmin1", ",", "\n", "\"xmax\"", ":", "xmin1", "+", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", "*", "WIDTH", ",", "\n", "\"ymin\"", ":", "ymin1", ",", "\n", "\"ymax\"", ":", "ymin1", "+", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", "*", "HEIGHT", ",", "\n", "}", "\n", "boxes1_array", "=", "np", ".", "stack", "(", "[", "boxes1", "[", "\"ymin\"", "]", ",", "boxes1", "[", "\"xmin\"", "]", ",", "boxes1", "[", "\"ymax\"", "]", ",", "boxes1", "[", "\"xmax\"", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "boxes1_tens", "=", "{", "tens_name", ":", "tf", ".", "constant", "(", "boxes1", "[", "tens_name", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "tens_name", "in", "boxes1", ".", "keys", "(", ")", "}", "\n", "xmin2", "=", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", "*", "WIDTH", "\n", "ymin2", "=", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", "*", "HEIGHT", "\n", "boxes2", "=", "{", "\n", "\"xmin\"", ":", "xmin2", ",", "\n", "\"xmax\"", ":", "xmin2", "+", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", "*", "WIDTH", ",", "\n", "\"ymin\"", ":", "ymin2", ",", "\n", "\"ymax\"", ":", "ymin2", "+", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", "*", "HEIGHT", ",", "\n", "}", "\n", "boxes2_array", "=", "np", ".", "stack", "(", "[", "boxes2", "[", "\"ymin\"", "]", ",", "boxes2", "[", "\"xmin\"", "]", ",", "boxes2", "[", "\"ymax\"", "]", ",", "boxes2", "[", "\"xmax\"", "]", "]", ",", "axis", "=", "-", "1", ")", "\n", "boxes2_tens", "=", "{", "tens_name", ":", "tf", ".", "constant", "(", "boxes2", "[", "tens_name", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "tens_name", "in", "boxes1", ".", "keys", "(", ")", "}", "\n", "tens", "=", "tf_util", ".", "batch_iou", "(", "boxes1_tens", ",", "boxes2_tens", ",", "tf", ".", "constant", "(", "N", ")", ",", "tf", ".", "constant", "(", "M", ")", ")", "\n", "\n", "if", "not", "sess", ":", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "# computed", "\n", "", "c_batch_iou", "=", "sess", ".", "run", "(", "tens", ")", "\n", "# ground truth", "\n", "boxes1_centers", "=", "np", ".", "array", "(", "[", "util", ".", "bbox_transform_inv", "(", "box1", ")", "for", "box1", "in", "boxes1_array", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "boxes2_centers", "=", "np", ".", "array", "(", "[", "util", ".", "bbox_transform_inv", "(", "box2", ")", "for", "box2", "in", "boxes2_array", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# g_batch_iou = util.mass_iou(boxes2_array, boxes1_array)", "\n", "g_batch_iou", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "xmin2", ")", ")", ":", "\n", "    ", "overlaps", "=", "util", ".", "batch_iou", "(", "boxes1_centers", ",", "boxes2_centers", "[", "i", "]", ")", "\n", "# for j in range(len(xmin1)):", "\n", "#   overlaps.append(util.iou(boxes1_centers[j], boxes2_centers[i]))", "\n", "g_batch_iou", ".", "append", "(", "overlaps", ")", "\n", "", "g_batch_iou", "=", "np", ".", "array", "(", "g_batch_iou", ")", "\n", "print", "(", "np", ".", "shape", "(", "c_batch_iou", ")", ")", "\n", "print", "(", "np", ".", "shape", "(", "g_batch_iou", ")", ")", "\n", "# print(c_batch_iou)", "\n", "print", "(", "np", ".", "abs", "(", "c_batch_iou", "-", "g_batch_iou", ")", ")", "\n", "print", "(", "np", ".", "max", "(", "np", ".", "abs", "(", "np", ".", "argsort", "(", "c_batch_iou", ",", "axis", "=", "1", ")", "-", "np", ".", "argsort", "(", "g_batch_iou", ",", "axis", "=", "1", ")", ")", ")", ")", "\n", "print", "(", "np", ".", "max", "(", "np", ".", "abs", "(", "c_batch_iou", "-", "g_batch_iou", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.utils_test.test_compute_distances": [[61, 90], ["tf.Session.run", "numpy.subtract.outer", "numpy.subtract.outer", "print", "numpy.random.random", "numpy.random.random", "tensorflow.constant", "tensorflow.constant", "numpy.random.random", "numpy.random.random", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session", "tf_util.compute_distances", "numpy.max", "tensorflow.constant", "tensorflow.constant", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.compute_distances"], ["", "def", "test_compute_distances", "(", "sess", "=", "None", ")", ":", "\n", "  ", "N", "=", "10", "\n", "M", "=", "20", "\n", "box_centers1", "=", "{", "\n", "\"x\"", ":", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", ",", "\n", "\"y\"", ":", "np", ".", "random", ".", "random", "(", "[", "N", "]", ")", "\n", "}", "\n", "box_centers1_tens", "=", "{", "\n", "\"x\"", ":", "tf", ".", "constant", "(", "box_centers1", "[", "\"x\"", "]", ")", ",", "\n", "\"y\"", ":", "tf", ".", "constant", "(", "box_centers1", "[", "\"y\"", "]", ")", "\n", "}", "\n", "box_centers2", "=", "{", "\n", "\"x\"", ":", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", ",", "\n", "\"y\"", ":", "np", ".", "random", ".", "random", "(", "[", "M", "]", ")", "\n", "}", "\n", "box_centers2_tens", "=", "{", "\n", "\"x\"", ":", "tf", ".", "constant", "(", "box_centers2", "[", "\"x\"", "]", ")", ",", "\n", "\"y\"", ":", "tf", ".", "constant", "(", "box_centers2", "[", "\"y\"", "]", ")", "\n", "}", "\n", "if", "not", "sess", ":", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "# computed", "\n", "", "c_dists2", "=", "sess", ".", "run", "(", "tf_util", ".", "compute_distances", "(", "box_centers2_tens", ",", "box_centers1_tens", ",", "tf", ".", "constant", "(", "M", ")", ",", "tf", ".", "constant", "(", "N", ")", ")", ")", "# [N,M]", "\n", "# ground truth", "\n", "dX", "=", "np", ".", "subtract", ".", "outer", "(", "box_centers1", "[", "\"x\"", "]", ",", "box_centers2", "[", "\"x\"", "]", ")", "# [N, M]", "\n", "dY", "=", "np", ".", "subtract", ".", "outer", "(", "box_centers1", "[", "\"y\"", "]", ",", "box_centers2", "[", "\"y\"", "]", ")", "# [N, M]", "\n", "g_dists2", "=", "dX", "*", "dX", "+", "dY", "*", "dY", "\n", "\n", "print", "(", "np", ".", "max", "(", "np", ".", "abs", "(", "c_dists2", "-", "g_dists2", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.iou": [[10, 38], ["min", "max", "min", "max"], "function", ["None"], ["def", "iou", "(", "box1", ",", "box2", ",", "iouType", "=", "'segm'", ")", ":", "\n", "  ", "\"\"\"Compute the Intersection-Over-Union of two given boxes.\n     or the Intersection-Over box2.\n  Args:\n    box1: array of 4 elements [cx, cy, width, height].\n    box2: same as above\n    iouType: The kind of intersection it will compute. \n             'keypoints' is for intersection over box2 area.\n  Returns:\n    iou: a float number in range [0, 1]. iou of the two boxes.\n  \"\"\"", "\n", "lr", "=", "min", "(", "box1", "[", "0", "]", "+", "0.5", "*", "box1", "[", "2", "]", ",", "box2", "[", "0", "]", "+", "0.5", "*", "box2", "[", "2", "]", ")", "-", "max", "(", "box1", "[", "0", "]", "-", "0.5", "*", "box1", "[", "2", "]", ",", "box2", "[", "0", "]", "-", "0.5", "*", "box2", "[", "2", "]", ")", "\n", "if", "lr", ">", "0", ":", "\n", "    ", "tb", "=", "min", "(", "box1", "[", "1", "]", "+", "0.5", "*", "box1", "[", "3", "]", ",", "box2", "[", "1", "]", "+", "0.5", "*", "box2", "[", "3", "]", ")", "-", "max", "(", "box1", "[", "1", "]", "-", "0.5", "*", "box1", "[", "3", "]", ",", "box2", "[", "1", "]", "-", "0.5", "*", "box2", "[", "3", "]", ")", "\n", "if", "tb", ">", "0", ":", "\n", "      ", "intersection", "=", "tb", "*", "lr", "\n", "", "else", ":", "\n", "      ", "intersection", "=", "0", "\n", "", "", "if", "(", "iouType", "==", "'keypoints'", ")", ":", "\n", "    ", "box2_area", "=", "box2", "[", "2", "]", "*", "box2", "[", "3", "]", "\n", "return", "intersection", "/", "box2_area", "\n", "", "else", ":", "\n", "    ", "union", "=", "box1", "[", "2", "]", "*", "box1", "[", "3", "]", "+", "box2", "[", "2", "]", "*", "box2", "[", "3", "]", "-", "intersection", "\n", "return", "intersection", "/", "union", "\n", "\n", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou": [[39, 66], ["numpy.maximum", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.minimum", "numpy.maximum"], "function", ["None"], ["", "def", "batch_iou", "(", "boxes", ",", "box", ",", "iouType", "=", "'segm'", ")", ":", "\n", "  ", "\"\"\"Compute the Intersection-Over-Union of a batch of boxes with another\n  box.\n\n  Args:\n    box1: 2D array of [cx, cy, width, height].\n    box2: a single array of [cx, cy, width, height]\n    iouType: the type of Intersection it will compute.\n             'keypoints' is for intersection over boxes area.\n  Returns:\n    ious: array of a float number in range [0, 1].\n  \"\"\"", "\n", "lr", "=", "np", ".", "maximum", "(", "\n", "np", ".", "minimum", "(", "boxes", "[", ":", ",", "0", "]", "+", "0.5", "*", "boxes", "[", ":", ",", "2", "]", ",", "box", "[", "0", "]", "+", "0.5", "*", "box", "[", "2", "]", ")", "-", "np", ".", "maximum", "(", "boxes", "[", ":", ",", "0", "]", "-", "0.5", "*", "boxes", "[", ":", ",", "2", "]", ",", "box", "[", "0", "]", "-", "0.5", "*", "box", "[", "2", "]", ")", ",", "\n", "0", ")", "\n", "tb", "=", "np", ".", "maximum", "(", "\n", "np", ".", "minimum", "(", "boxes", "[", ":", ",", "1", "]", "+", "0.5", "*", "boxes", "[", ":", ",", "3", "]", ",", "box", "[", "1", "]", "+", "0.5", "*", "box", "[", "3", "]", ")", "-", "np", ".", "maximum", "(", "boxes", "[", ":", ",", "1", "]", "-", "0.5", "*", "boxes", "[", ":", ",", "3", "]", ",", "box", "[", "1", "]", "-", "0.5", "*", "box", "[", "3", "]", ")", ",", "\n", "0", ")", "\n", "inter", "=", "lr", "*", "tb", "\n", "if", "(", "iouType", "==", "'keypoints'", ")", ":", "\n", "    ", "boxes_areas", "=", "boxes", "[", ":", ",", "2", "]", "*", "boxes", "[", ":", ",", "3", "]", "\n", "return", "inter", "/", "boxes_areas", "\n", "", "else", ":", "\n", "    ", "union", "=", "boxes", "[", ":", ",", "2", "]", "*", "boxes", "[", ":", ",", "3", "]", "+", "box", "[", "2", "]", "*", "box", "[", "3", "]", "-", "inter", "\n", "return", "inter", "/", "union", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.mass_iou": [[67, 107], ["six.moves.xrange", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.array", "np.array.append", "np.array.append", "np.array.append", "np.array.append", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.size", "numpy.size", "numpy.shape", "numpy.minimum", "numpy.minimum", "numpy.maximum", "numpy.maximum", "numpy.size", "numpy.size", "numpy.size", "numpy.size", "numpy.finfo"], "function", ["None"], ["", "", "def", "mass_iou", "(", "boxes1", ",", "boxes2", ")", ":", "\n", "  ", "\"\"\"\n  Args:\n    boxes1: 2D array (N,4) of [y_min, x_min, y_max, x_max]\n    boxes1: 2D array (M,4) of [y_min, x_min, y_max, x_max]\n  \"\"\"", "\n", "xmin1", "=", "boxes1", "[", ":", ",", "1", "]", "\n", "ymin1", "=", "boxes1", "[", ":", ",", "0", "]", "\n", "xmax1", "=", "boxes1", "[", ":", ",", "3", "]", "\n", "ymax1", "=", "boxes1", "[", ":", ",", "2", "]", "\n", "\n", "xmin2", "=", "boxes2", "[", ":", ",", "1", "]", "\n", "ymin2", "=", "boxes2", "[", ":", ",", "0", "]", "\n", "xmax2", "=", "boxes2", "[", ":", ",", "3", "]", "\n", "ymax2", "=", "boxes2", "[", ":", ",", "2", "]", "\n", "\n", "if", "(", "np", ".", "size", "(", "xmin1", ")", "==", "0", "or", "np", ".", "size", "(", "xmin2", ")", "==", "0", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "[", "]", ")", "# avoid computations", "\n", "", "xmax", ",", "ymax", ",", "xmin", ",", "ymin", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "xrange", "(", "np", ".", "shape", "(", "boxes1", ")", "[", "0", "]", ")", ":", "\n", "    ", "xmax", ".", "append", "(", "np", ".", "minimum", "(", "xmax1", "[", "i", "]", ",", "xmax2", ")", ")", "\n", "ymax", ".", "append", "(", "np", ".", "minimum", "(", "ymax1", "[", "i", "]", ",", "ymax2", ")", ")", "\n", "xmin", ".", "append", "(", "np", ".", "maximum", "(", "xmin1", "[", "i", "]", ",", "xmin2", ")", ")", "\n", "ymin", ".", "append", "(", "np", ".", "maximum", "(", "ymin1", "[", "i", "]", ",", "ymin2", ")", ")", "\n", "", "xmax", "=", "np", ".", "array", "(", "xmax", ")", "\n", "ymax", "=", "np", ".", "array", "(", "ymax", ")", "\n", "xmin", "=", "np", ".", "array", "(", "xmin", ")", "\n", "ymin", "=", "np", ".", "array", "(", "ymin", ")", "\n", "w", "=", "xmax", "-", "xmin", "\n", "h", "=", "ymax", "-", "ymin", "\n", "intersection", "=", "w", "*", "h", "\n", "\n", "w1", "=", "np", ".", "tile", "(", "np", ".", "expand_dims", "(", "xmax1", "-", "xmin1", ",", "1", ")", ",", "[", "1", ",", "np", ".", "size", "(", "xmin2", ")", "]", ")", "\n", "h1", "=", "np", ".", "tile", "(", "np", ".", "expand_dims", "(", "ymax1", "-", "ymin1", ",", "1", ")", ",", "[", "1", ",", "np", ".", "size", "(", "xmin2", ")", "]", ")", "\n", "w2", "=", "np", ".", "tile", "(", "np", ".", "expand_dims", "(", "xmax2", "-", "xmin2", ",", "0", ")", ",", "[", "np", ".", "size", "(", "xmin1", ")", ",", "1", "]", ")", "\n", "h2", "=", "np", ".", "tile", "(", "np", ".", "expand_dims", "(", "ymax2", "-", "ymin2", ",", "0", ")", ",", "[", "np", ".", "size", "(", "xmin1", ")", ",", "1", "]", ")", "\n", "\n", "union", "=", "w1", "*", "h2", "+", "w2", "*", "h2", "-", "intersection", "\n", "\n", "return", "intersection", "/", "(", "union", "+", "np", ".", "finfo", "(", "np", ".", "float", ")", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.nms": [[108, 129], ["range", "probs.argsort", "len", "util.batch_iou", "enumerate", "len"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou"], ["", "def", "nms", "(", "boxes", ",", "probs", ",", "threshold", ",", "iouType", "=", "'segm'", ")", ":", "\n", "  ", "\"\"\"Non-Maximum supression.\n  Args:\n    boxes: array of [cx, cy, w, h] (center format)\n    probs: array of probabilities\n    threshold: two boxes are considered overlapping if their IOU is larger than\n        this threshold\n    form: 'center' or 'diagonal'\n  Returns:\n    keep: array of True or False.\n  \"\"\"", "\n", "\n", "order", "=", "probs", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "keep", "=", "[", "True", "]", "*", "len", "(", "order", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "order", ")", "-", "1", ")", ":", "\n", "    ", "ovps", "=", "batch_iou", "(", "boxes", "[", "order", "[", "i", "+", "1", ":", "]", "]", ",", "boxes", "[", "order", "[", "i", "]", "]", ",", "iouType", ")", "\n", "for", "j", ",", "ov", "in", "enumerate", "(", "ovps", ")", ":", "\n", "      ", "if", "ov", ">", "threshold", ":", "\n", "        ", "keep", "[", "order", "[", "j", "+", "i", "+", "1", "]", "]", "=", "False", "\n", "", "", "", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.recursive_nms": [[131, 190], ["boxes[].argsort", "util.recursive_nms._recur"], "function", ["None"], ["", "def", "recursive_nms", "(", "boxes", ",", "probs", ",", "threshold", ",", "form", "=", "'center'", ")", ":", "\n", "  ", "\"\"\"Recursive Non-Maximum supression.\n  Args:\n    boxes: array of [cx, cy, w, h] (center format) or [xmin, ymin, xmax, ymax]\n    probs: array of probabilities\n    threshold: two boxes are considered overlapping if their IOU is largher than\n        this threshold\n    form: 'center' or 'diagonal'\n  Returns:\n    keep: array of True or False.\n  \"\"\"", "\n", "\n", "assert", "form", "==", "'center'", "or", "form", "==", "'diagonal'", ",", "'bounding box format not accepted: {}.'", ".", "format", "(", "form", ")", "\n", "\n", "if", "form", "==", "'center'", ":", "\n", "# convert to diagonal format", "\n", "    ", "boxes", "=", "np", ".", "array", "(", "[", "bbox_transform", "(", "b", ")", "for", "b", "in", "boxes", "]", ")", "\n", "\n", "", "areas", "=", "(", "boxes", "[", ":", ",", "2", "]", "-", "boxes", "[", ":", ",", "0", "]", ")", "*", "(", "boxes", "[", ":", ",", "3", "]", "-", "boxes", "[", ":", ",", "1", "]", ")", "\n", "hidx", "=", "boxes", "[", ":", ",", "0", "]", ".", "argsort", "(", ")", "\n", "keep", "=", "[", "True", "]", "*", "len", "(", "hidx", ")", "\n", "\n", "def", "_nms", "(", "hidx", ")", ":", "\n", "    ", "order", "=", "probs", "[", "hidx", "]", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "for", "idx", "in", "xrange", "(", "len", "(", "order", ")", ")", ":", "\n", "      ", "if", "not", "keep", "[", "hidx", "[", "order", "[", "idx", "]", "]", "]", ":", "\n", "        ", "continue", "\n", "", "xx2", "=", "boxes", "[", "hidx", "[", "order", "[", "idx", "]", "]", ",", "2", "]", "\n", "for", "jdx", "in", "xrange", "(", "idx", "+", "1", ",", "len", "(", "order", ")", ")", ":", "\n", "        ", "if", "not", "keep", "[", "hidx", "[", "order", "[", "jdx", "]", "]", "]", ":", "\n", "          ", "continue", "\n", "", "xx1", "=", "boxes", "[", "hidx", "[", "order", "[", "jdx", "]", "]", ",", "0", "]", "\n", "if", "xx2", "<", "xx1", ":", "\n", "          ", "break", "\n", "", "w", "=", "xx2", "-", "xx1", "\n", "yy1", "=", "max", "(", "boxes", "[", "hidx", "[", "order", "[", "idx", "]", "]", ",", "1", "]", ",", "boxes", "[", "hidx", "[", "order", "[", "jdx", "]", "]", ",", "1", "]", ")", "\n", "yy2", "=", "min", "(", "boxes", "[", "hidx", "[", "order", "[", "idx", "]", "]", ",", "3", "]", ",", "boxes", "[", "hidx", "[", "order", "[", "jdx", "]", "]", ",", "3", "]", ")", "\n", "if", "yy2", "<=", "yy1", ":", "\n", "          ", "continue", "\n", "", "h", "=", "yy2", "-", "yy1", "\n", "inter", "=", "w", "*", "h", "\n", "iou", "=", "inter", "/", "(", "areas", "[", "hidx", "[", "order", "[", "idx", "]", "]", "]", "+", "areas", "[", "hidx", "[", "order", "[", "jdx", "]", "]", "]", "-", "inter", ")", "\n", "if", "iou", ">", "threshold", ":", "\n", "          ", "keep", "[", "hidx", "[", "order", "[", "jdx", "]", "]", "]", "=", "False", "\n", "\n", "", "", "", "", "def", "_recur", "(", "hidx", ")", ":", "\n", "    ", "if", "len", "(", "hidx", ")", "<=", "20", ":", "\n", "      ", "_nms", "(", "hidx", ")", "\n", "", "else", ":", "\n", "      ", "mid", "=", "len", "(", "hidx", ")", "/", "2", "\n", "_recur", "(", "hidx", "[", ":", "mid", "]", ")", "\n", "_recur", "(", "hidx", "[", "mid", ":", "]", ")", "\n", "_nms", "(", "[", "idx", "for", "idx", "in", "hidx", "if", "keep", "[", "idx", "]", "]", ")", "\n", "\n", "", "", "_recur", "(", "hidx", ")", "\n", "\n", "return", "keep", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense": [[191, 211], ["zip", "len", "len", "numpy.ones", "tuple"], "function", ["None"], ["", "def", "sparse_to_dense", "(", "sp_indices", ",", "output_shape", ",", "values", ",", "default_value", "=", "0", ")", ":", "\n", "  ", "\"\"\"Build a dense matrix from sparse representations.\n\n  Args:\n    sp_indices: A [0-2]-D array that contains the index to place values.\n    shape: shape of the dense matrix.\n    values: A {0,1}-D array where values corresponds to the index in each row of\n    sp_indices.\n    default_value: values to set for indices not specified in sp_indices.\n  Return:\n    A dense numpy N-D array with shape output_shape.\n  \"\"\"", "\n", "\n", "assert", "len", "(", "sp_indices", ")", "==", "len", "(", "values", ")", ",", "'Length of sp_indices is not equal to length of values'", "\n", "\n", "array", "=", "np", ".", "ones", "(", "output_shape", ")", "*", "default_value", "\n", "for", "idx", ",", "value", "in", "zip", "(", "sp_indices", ",", "values", ")", ":", "\n", "    ", "array", "[", "tuple", "(", "idx", ")", "]", "=", "value", "\n", "", "return", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bgr_to_rgb": [[212, 218], ["out.append"], "function", ["None"], ["", "def", "bgr_to_rgb", "(", "ims", ")", ":", "\n", "  ", "\"\"\"Convert a list of images from BGR format to RGB format.\"\"\"", "\n", "out", "=", "[", "]", "\n", "for", "im", "in", "ims", ":", "\n", "    ", "out", ".", "append", "(", "im", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform": [[219, 232], ["tensorflow.variable_scope"], "function", ["None"], ["", "def", "bbox_transform", "(", "bbox", ")", ":", "\n", "  ", "\"\"\"convert a bbox of form [cx, cy, w, h] to [xmin, ymin, xmax, ymax]. Works\n  for numpy array or list of tensors.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'bbox_transform'", ")", "as", "scope", ":", "\n", "    ", "cx", ",", "cy", ",", "w", ",", "h", "=", "bbox", "\n", "out_box", "=", "[", "[", "]", "]", "*", "4", "\n", "out_box", "[", "0", "]", "=", "cx", "-", "w", "/", "2", "\n", "out_box", "[", "1", "]", "=", "cy", "-", "h", "/", "2", "\n", "out_box", "[", "2", "]", "=", "cx", "+", "w", "/", "2", "\n", "out_box", "[", "3", "]", "=", "cy", "+", "h", "/", "2", "\n", "\n", "", "return", "out_box", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv": [[233, 249], ["tensorflow.variable_scope"], "function", ["None"], ["", "def", "bbox_transform_inv", "(", "bbox", ")", ":", "\n", "  ", "\"\"\"convert a bbox of form [xmin, ymin, xmax, ymax] to [cx, cy, w, h]. Works\n  for numpy array or list of tensors.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'bbox_transform_inv'", ")", "as", "scope", ":", "\n", "    ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "bbox", "\n", "out_box", "=", "[", "[", "]", "]", "*", "4", "\n", "\n", "width", "=", "xmax", "-", "xmin", "+", "1.0", "\n", "height", "=", "ymax", "-", "ymin", "+", "1.0", "\n", "out_box", "[", "0", "]", "=", "xmin", "+", "0.5", "*", "width", "\n", "out_box", "[", "1", "]", "=", "ymin", "+", "0.5", "*", "height", "\n", "out_box", "[", "2", "]", "=", "width", "\n", "out_box", "[", "3", "]", "=", "height", "\n", "\n", "", "return", "out_box", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.safe_exp": [[250, 265], ["numpy.exp", "tensorflow.variable_scope", "tensorflow.to_float", "tensorflow.exp", "tensorflow.where", "tensorflow.zeros_like"], "function", ["None"], ["", "def", "safe_exp", "(", "w", ",", "thresh", ")", ":", "\n", "  ", "\"\"\"Safe exponential function for tensors.\"\"\"", "\n", "\n", "slope", "=", "np", ".", "exp", "(", "thresh", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'safe_exponential'", ")", ":", "\n", "    ", "lin_bool", "=", "w", ">", "thresh", "\n", "lin_region", "=", "tf", ".", "to_float", "(", "lin_bool", ")", "\n", "\n", "lin_out", "=", "slope", "*", "(", "w", "-", "thresh", "+", "1.", ")", "\n", "exp_out", "=", "tf", ".", "exp", "(", "tf", ".", "where", "(", "lin_bool", ",", "tf", ".", "zeros_like", "(", "w", ")", ",", "w", ")", ")", "\n", "\n", "out", "=", "lin_region", "*", "lin_out", "+", "(", "1.", "-", "lin_region", ")", "*", "exp_out", "\n", "# TODO: all above 3 lines can be calculated with the line below", "\n", "# out = np.where(lin_bool, lin_out, np.exp(w))", "\n", "", "return", "out", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.get_matcher_algorithm": [[7, 36], ["matchers.keys", "print"], "function", ["None"], ["def", "get_matcher_algorithm", "(", "matcher_name", ")", ":", "\n", "  ", "\"\"\"\n  Args:\n    mather_name: name of the matcher algorithm\n  Returns:\n    A function object implementing the algorithm. This function object accepts arguments:\n    record: The record is a dictionary of tensors after the data input stage\n    anchor_box_tens: Tensor of anchor boxes represented in the form [xmin,ymin,xmax,ymax]\n    dataset_box_tens: Tensor of ground truth boxes, read from the dataset, in the form [xmin,ymin,xmax,ymax]\n    anchor_box_centers: Tensor of anchor boxes represented in the form [x,y,w,h]\n    dataset_box_centers: Tensor of ground truth boxes, read from the dataset, in the form [x,y,w,h]\n    idx: The indices of the returning sparse tensor.\n    N: number of boxes in anchor_box_tens (equal to number of boxes in anchor_box_centers).\n    M: number of boxes in dataset_box_tens (equal to number of boxes in dataset_box_centers).\n    pre_N: numpy number of N (not a tensorflow tensor).\n    batch_size: The batch size.\n    The function returns a sparse tensor with values the indices of \n    the matching anchors of the ground truth boxes inside the anchor_box_tens tensor.\n  \"\"\"", "\n", "matchers", "=", "{", "\n", "\"GREEDY_PARALLELIZABLE_MATCH\"", ":", "greedy_parallelizable_match", ",", "\n", "\"GREEDY_BIPARTITE_MATCH\"", ":", "greedy_bipartite_match", "\n", "}", "\n", "if", "matcher_name", "in", "matchers", ".", "keys", "(", ")", ":", "\n", "    ", "return", "matchers", "[", "matcher_name", "]", "\n", "", "else", ":", "\n", "    ", "print", "(", "\"No valid matcher selected, selecting default matcher: GREEDY_PARALLELIZABLE_MATCH\"", ")", "\n", "\n", "", "return", "matchers", "[", "\"GREEDY_PARALLELIZABLE_MATCH\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.greedy_parallelizable_match": [[37, 75], ["utils.tf_util.batch_iou", "tensorflow.reduce_max", "tensorflow.contrib.framework.argsort", "utils.tf_util.compute_distances", "tensorflow.contrib.framework.argsort", "tensorflow.where", "tensorflow.dynamic_partition", "tensorflow.concat", "tensorflow.SparseTensor", "tensorflow.cast", "tensorflow.reshape", "matchers.find_best_aidx_per_image", "tensorflow.tile", "tensorflow.shape", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.compute_distances", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.find_best_aidx_per_image"], ["", "def", "greedy_parallelizable_match", "(", "record", ",", "anchor_box_tens", ",", "dataset_box_tens", ",", "anchor_box_centers", ",", "dataset_box_centers", ",", "idx", ",", "N", ",", "M", ",", "pre_N", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"\n  This function uses the algorithm described in the coresponding paper.\n  It tries to solve the bipartite match by taking each dataset box first and then picks the closest anchor and assigns it as\n  responsible for this dataset box. It also takes care that the same anchor is not responsible for more than one dataset box.\n  Args:\n    Described in get_matcher_algorithm\n  Returns:\n    Described in get_matcher_algorithm\n  \"\"\"", "\n", "flat_overlaps", "=", "batch_iou", "(", "anchor_box_tens", ",", "\n", "dataset_box_tens", ",", "\n", "N", "=", "N", ",", "M", "=", "M", ")", "# [SIZE_XMIN, N] = [M, N]", "\n", "\n", "# sort for biggest overlaps ", "\n", "max_overlaps", "=", "tf", ".", "reduce_max", "(", "flat_overlaps", ",", "axis", "=", "1", ")", "#[SIZE_XMIN]", "\n", "overlaps_sorted_idx", "=", "tf", ".", "contrib", ".", "framework", ".", "argsort", "(", "flat_overlaps", ",", "axis", "=", "1", ",", "direction", "=", "'DESCENDING'", ")", "# [SIZE_XMIN, N]", "\n", "\n", "# get distances of between whole boxes, d([x1,y1,w1,h1], [x2,y2,w2,h2])", "\n", "flat_dists", "=", "compute_distances", "(", "anchor_box_centers", ",", "\n", "dataset_box_centers", ",", "\n", "N", "=", "N", ",", "M", "=", "M", ")", "# [SIZE_XMIN, N] = [M, N]", "\n", "\n", "# sort for minimum dists", "\n", "dists_sorted_idx", "=", "tf", ".", "contrib", ".", "framework", ".", "argsort", "(", "flat_dists", ",", "axis", "=", "1", ",", "direction", "=", "'ASCENDING'", ")", "# [SIZE_XMIN, N]", "\n", "\n", "aidx_array", "=", "tf", ".", "where", "(", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "max_overlaps", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "pre_N", "]", ")", ",", "tf", ".", "shape", "(", "overlaps_sorted_idx", ")", ")", "<=", "0", ",", "\n", "dists_sorted_idx", ",", "\n", "overlaps_sorted_idx", ")", "# [SIZE_XMIN, N]", "\n", "\n", "unstacked_aidx_array", "=", "tf", ".", "dynamic_partition", "(", "aidx_array", ",", "tf", ".", "cast", "(", "idx", "[", ":", ",", "0", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "batch_size", ",", "name", "=", "\"dynamic_partition\"", ")", "\n", "\n", "aidx_values", "=", "tf", ".", "concat", "(", "[", "find_best_aidx_per_image", "(", "el", ")", "for", "el", "in", "unstacked_aidx_array", "]", ",", "axis", "=", "0", ")", "\n", "\n", "aidx", "=", "tf", ".", "SparseTensor", "(", "idx", ",", "aidx_values", ",", "record", "[", "\"image/object/bbox/xmin\"", "]", ".", "dense_shape", ")", "\n", "\n", "return", "aidx", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.greedy_bipartite_match": [[76, 110], ["utils.tf_util.batch_iou", "tensorflow.reduce_max", "utils.tf_util.compute_distances", "tensorflow.where", "tensorflow.dynamic_partition", "tensorflow.concat", "tensorflow.SparseTensor", "tensorflow.cast", "tensorflow.reshape", "tensorflow.tile", "tensorflow.shape", "tensorflow.contrib.image.python.ops.image_ops.bipartite_match", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.compute_distances"], ["", "def", "greedy_bipartite_match", "(", "record", ",", "anchor_box_tens", ",", "dataset_box_tens", ",", "anchor_box_centers", ",", "dataset_box_centers", ",", "idx", ",", "N", ",", "M", ",", "pre_N", ",", "batch_size", ")", ":", "\n", "  ", "\"\"\"\n  This algorithm described as greed bipartite match.\n  It iterates through all the dataset boxes.\n  At each iteration, it picks the closest distance between an achor box and a dataset box.\n  It also takes care that the same anchor is not responsible for more than one dataset box.\n  Args:\n    Described in get_matcher_algorithm\n  Returns:\n    Described in get_matcher_algorithm\n  \"\"\"", "\n", "flat_overlaps", "=", "batch_iou", "(", "anchor_box_tens", ",", "\n", "dataset_box_tens", ",", "\n", "N", "=", "N", ",", "M", "=", "M", ")", "# [SIZE_XMIN, N] = [M, N]", "\n", "\n", "max_overlaps", "=", "tf", ".", "reduce_max", "(", "flat_overlaps", ",", "axis", "=", "1", ")", "#[SIZE_XMIN]", "\n", "\n", "# get distances of between whole boxes, d([x1,y1,w1,h1], [x2,y2,w2,h2])", "\n", "flat_dists", "=", "compute_distances", "(", "anchor_box_centers", ",", "\n", "dataset_box_centers", ",", "\n", "N", "=", "N", ",", "M", "=", "M", ")", "# [SIZE_XMIN, N] = [M, N]", "\n", "# get a combined distance matrix", "\n", "dst_mtxs", "=", "tf", ".", "where", "(", "tf", ".", "reshape", "(", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "max_overlaps", ",", "axis", "=", "1", ")", ",", "[", "1", ",", "pre_N", "]", ")", ",", "tf", ".", "shape", "(", "flat_overlaps", ")", ")", "<=", "0", ",", "\n", "flat_dists", ",", "\n", "1.0", "-", "flat_overlaps", ")", "\n", "\n", "unstacked_dst_mtxs", "=", "tf", ".", "dynamic_partition", "(", "dst_mtxs", ",", "tf", ".", "cast", "(", "idx", "[", ":", ",", "0", "]", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "batch_size", ",", "name", "=", "\"dynamic_partition\"", ")", "\n", "\n", "aidx_values", "=", "tf", ".", "concat", "(", "[", "image_ops", ".", "bipartite_match", "(", "el", ",", "num_valid_rows", "=", "-", "1.0", ")", "[", "0", "]", "for", "el", "in", "unstacked_dst_mtxs", "]", ",", "axis", "=", "0", ")", "\n", "\n", "aidx", "=", "tf", ".", "SparseTensor", "(", "idx", ",", "aidx_values", ",", "record", "[", "\"image/object/bbox/xmin\"", "]", ".", "dense_shape", ")", "\n", "\n", "return", "aidx", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.find_best_aidx_per_image": [[112, 141], ["tensorflow.name_scope", "tensorflow.zeros", "tensorflow.constant", "tensorflow.reshape", "tensorflow.concat", "tensorflow.ones_like", "tensorflow.while_loop", "tensorflow.shape", "tensorflow.where", "tensorflow.shape", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.equal", "tensorflow.sparse_to_dense", "tensorflow.gather", "tensorflow.shape", "tensorflow.reduce_min", "tensorflow.where", "tensorflow.logical_and", "tensorflow.not_equal", "tensorflow.not_equal"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense"], ["", "def", "find_best_aidx_per_image", "(", "aidx_slice", ")", ":", "\n", "  ", "\"\"\"\n    This function is the used for a greedy parallelizable matching of anchor boxes to dataset boxes.\n    It accepts an aidx_slice argument which is a 2D tensor (matrix) for every image, with every row containing \n    the indices of anchors sorted using the distance of the dataset box regarding this row with the \n    anchor boxes as a key.\n    Args:\n      aidx_slice: a matrix with anchor indices, each row corresponds to a dataset box.\n    Returns:\n      A greedy match for each dataset box as a 1D Tensor.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"aidx_elimination\"", ")", ":", "\n", "    ", "els_used", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "aidx_slice", ")", "[", ":", "1", "]", "-", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "# keep all used elements so far", "\n", "i", "=", "tf", ".", "constant", "(", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "els_used", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "[", "tf", ".", "expand_dims", "(", "aidx_slice", "[", "0", ",", "0", "]", ",", "0", ")", ",", "els_used", "]", ",", "axis", "=", "0", ")", ",", "tf", ".", "shape", "(", "aidx_slice", ")", "[", ":", "1", "]", ")", "\n", "\n", "neg_ones", "=", "-", "tf", ".", "ones_like", "(", "aidx_slice", ")", "#  mark with -1 elements of N that have already been used", "\n", "N", "=", "aidx_slice", "\n", "c", "=", "lambda", "i", ",", "N", ",", "els_used", ":", "i", "<", "tf", ".", "shape", "(", "N", ")", "[", "0", "]", "\n", "b", "=", "lambda", "i", ",", "N", ",", "els_used", ":", "[", "i", "+", "1", ",", "tf", ".", "where", "(", "tf", ".", "equal", "(", "N", ",", "els_used", "[", "i", "-", "1", "]", ")", ",", "neg_ones", ",", "N", ")", ",", "\n", "els_used", "+", "\n", "tf", ".", "sparse_to_dense", "(", "i", ",", "tf", ".", "shape", "(", "N", ")", "[", ":", "1", "]", ",", "\n", "tf", ".", "gather", "(", "N", "[", "i", ",", ":", "]", ",", "\n", "tf", ".", "reduce_min", "(", "\n", "tf", ".", "where", "(", "\n", "tf", ".", "logical_and", "(", "\n", "tf", ".", "not_equal", "(", "N", "[", "i", ",", ":", "]", ",", "-", "1", ")", ",", "\n", "tf", ".", "not_equal", "(", "N", "[", "i", ",", ":", "]", ",", "els_used", "[", "i", "-", "1", "]", ")", ")", ")", ")", ")", ")", "]", "\n", "return", "tf", ".", "while_loop", "(", "c", ",", "b", ",", "[", "i", ",", "N", ",", "els_used", "]", ")", "[", "2", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_keys_to_features": [[16, 29], ["tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature"], "function", ["None"], ["def", "get_keys_to_features", "(", ")", ":", "\n", "  ", "keys_to_features", "=", "{", "\n", "\"image/height\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"image/width\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", ",", "\n", "\"image/filename\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"image/encoded\"", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "\"image/object/bbox/xmin\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", ",", "\n", "\"image/object/bbox/xmax\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", ",", "\n", "\"image/object/bbox/ymin\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", ",", "\n", "\"image/object/bbox/ymax\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "float32", ")", ",", "\n", "\"image/object/class/label\"", ":", "tf", ".", "VarLenFeature", "(", "tf", ".", "int64", ")", "\n", "}", "\n", "return", "keys_to_features", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data": [[30, 144], ["tensorflow.name_scope", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.constant", "tensorflow.reshape", "tensorflow.name_scope", "range", "tensorflow.constant", "tensorflow.constant", "imdb.tf_data_augmentation", "tensorflow.stack", "tensorflow.name_scope", "tensorflow.cast", "utils.tf_util._tf_dense_to_sparse_tensor", "tensorflow.cast", "utils.tf_util._tf_dense_to_sparse_tensor", "tensorflow.cast", "utils.tf_util._tf_dense_to_sparse_tensor", "tensorflow.cast", "utils.tf_util._tf_dense_to_sparse_tensor", "tensorflow.name_scope", "numpy.array", "utils.tf_util.batch_bbox_transform", "numpy.prod", "tensorflow.constant", "tensorflow.size", "tensorflow.cast", "tensorflow.cast", "standarized_imgs.append", "numpy.shape", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.cast", "tensorflow.cast", "matchers.get_matcher_algorithm", "tensorflow.name_scope", "tensorflow.reverse", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.SparseTensor", "tensorflow.SparseTensor", "tensorflow.SparseTensor", "tensorflow.SparseTensor", "image_decoder", "tensorflow.constant", "tensorflow.constant", "tensorflow.log", "tensorflow.log", "tensorflow.constant", "tensorflow.cast", "tensorflow.gather", "tensorflow.cast", "tensorflow.gather", "tensorflow.cast", "tensorflow.gather", "tensorflow.cast", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.tf_data_augmentation", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util._tf_dense_to_sparse_tensor", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util._tf_dense_to_sparse_tensor", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util._tf_dense_to_sparse_tensor", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util._tf_dense_to_sparse_tensor", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.tf_util.batch_bbox_transform", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.matchers.get_matcher_algorithm"], ["", "def", "load_data", "(", "record", ",", "mc", ",", "training", "=", "True", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_png", ")", ":", "\n", "  ", "\"\"\"\n    In this function all preprocessing of the dataset data prior to the feature extractor is performed. Here both data augmentation\n    and \n    Args:\n      record: dictionary with input tensors see `get_keys_to_features` to see the keys of this dictionary\n      mc: model configuration dictionary\n      training: if the resulting data will be used for training or not\n      image_decoder: Image decoder function which returns a tensorflow tensor of the image batch of type tf.float32.     \n    Returns:\n      A dictionary with all the prerpocessed data for training after anchor ground truth match and data augmentation.\n      These data are appropriate for use with a network model.\n      All dimensions are normalized with the mc.IMAGE_WIDTH and mc.IMAGE_HEIGHT\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"main_input_process\"", ")", ":", "\n", "    ", "encoded_imgs", "=", "record", "[", "\"image/encoded\"", "]", "\n", "# all below have shape [BATCH_SIZE, ?]", "\n", "xmin", "=", "tf", ".", "sparse_tensor_to_dense", "(", "record", "[", "\"image/object/bbox/xmin\"", "]", ",", "default_value", "=", "0.5", ")", "\n", "xmax", "=", "tf", ".", "sparse_tensor_to_dense", "(", "record", "[", "\"image/object/bbox/xmax\"", "]", ",", "default_value", "=", "0.5", ")", "\n", "ymin", "=", "tf", ".", "sparse_tensor_to_dense", "(", "record", "[", "\"image/object/bbox/ymin\"", "]", ",", "default_value", "=", "0.5", ")", "\n", "ymax", "=", "tf", ".", "sparse_tensor_to_dense", "(", "record", "[", "\"image/object/bbox/ymax\"", "]", ",", "default_value", "=", "0.5", ")", "\n", "\n", "standarized_imgs", "=", "[", "]", "\n", "# NHWC", "\n", "new_size", "=", "tf", ".", "constant", "(", "[", "mc", ".", "IMAGE_HEIGHT", ",", "mc", ".", "IMAGE_WIDTH", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"decode_resize_imgs\"", ")", ":", "\n", "      ", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", ":", "\n", "        ", "decoded_img", "=", "tf", ".", "cast", "(", "tf", ".", "reverse", "(", "image_decoder", "(", "encoded_imgs", "[", "i", "]", ",", "channels", "=", "3", ")", ",", "axis", "=", "[", "-", "1", "]", ")", ",", "tf", ".", "float32", ")", "# RGB -> BGR -> casting", "\n", "standarized_imgs", ".", "append", "(", "\n", "tf", ".", "image", ".", "resize_images", "(", "decoded_img", "-", "tf", ".", "constant", "(", "mc", ".", "BGR_MEANS", ",", "tf", ".", "float32", ")", ",", "size", "=", "new_size", ")", ")", "\n", "# resize annotation", "\n", "", "new_size_width", "=", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ",", "name", "=", "\"image_width\"", ")", "\n", "new_size_height", "=", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ",", "name", "=", "\"image_height\"", ")", "\n", "\n", "", "if", "(", "mc", ".", "DATA_AUGMENTATION", "and", "training", ")", ":", "\n", "      ", "standarized_imgs", ",", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "tf_data_augmentation", "(", "standarized_imgs", ",", "xmin", ",", "xmax", ",", "\n", "ymin", ",", "ymax", ",", "mc", ")", "\n", "", "new_imgs", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "stack", "(", "standarized_imgs", ",", "axis", "=", "0", ")", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "IMAGE_HEIGHT", ",", "mc", ".", "IMAGE_WIDTH", ",", "3", "]", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"annotation_resizing\"", ")", ":", "\n", "      ", "idx", "=", "record", "[", "\"image/object/bbox/xmin\"", "]", ".", "indices", "\n", "\n", "xmin2", "=", "tf", ".", "cast", "(", "xmin", "*", "new_size_width", ",", "tf", ".", "float32", ")", "# [M]", "\n", "new_xmin", "=", "_tf_dense_to_sparse_tensor", "(", "idx", ",", "xmin2", ")", "\n", "\n", "xmax2", "=", "tf", ".", "cast", "(", "xmax", "*", "new_size_width", ",", "tf", ".", "float32", ")", "\n", "new_xmax", "=", "_tf_dense_to_sparse_tensor", "(", "idx", ",", "xmax2", ")", "\n", "\n", "ymin2", "=", "tf", ".", "cast", "(", "ymin", "*", "new_size_height", ",", "tf", ".", "float32", ")", "\n", "new_ymin", "=", "_tf_dense_to_sparse_tensor", "(", "idx", ",", "ymin2", ")", "\n", "\n", "ymax2", "=", "tf", ".", "cast", "(", "ymax", "*", "new_size_height", ",", "tf", ".", "float32", ")", "\n", "new_ymax", "=", "_tf_dense_to_sparse_tensor", "(", "idx", ",", "ymax2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"anchor_box_search\"", ")", ":", "\n", "      ", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "s", "=", "batch_bbox_transform", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "pre_N", "=", "np", ".", "prod", "(", "np", ".", "shape", "(", "s", "[", "\"xmin\"", "]", ")", ")", "\n", "N", "=", "tf", ".", "constant", "(", "pre_N", ")", "\n", "M", "=", "tf", ".", "size", "(", "new_xmin", ".", "values", ")", "\n", "anchor_box_tens", "=", "{", "\n", "\"xmin\"", ":", "tf", ".", "constant", "(", "s", "[", "\"xmin\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "# [N]", "\n", "\"ymin\"", ":", "tf", ".", "constant", "(", "s", "[", "\"ymin\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"xmax\"", ":", "tf", ".", "constant", "(", "s", "[", "\"xmax\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"ymax\"", ":", "tf", ".", "constant", "(", "s", "[", "\"ymax\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "}", "\n", "\n", "# compute overlaps of bounding boxes and anchor boxes", "\n", "dataset_box_tens", "=", "{", "\n", "\"xmin\"", ":", "tf", ".", "cast", "(", "new_xmin", ".", "values", ",", "tf", ".", "float32", ")", ",", "# [M]", "\n", "\"ymin\"", ":", "tf", ".", "cast", "(", "new_ymin", ".", "values", ",", "tf", ".", "float32", ")", ",", "\n", "\"xmax\"", ":", "tf", ".", "cast", "(", "new_xmax", ".", "values", ",", "tf", ".", "float32", ")", ",", "\n", "\"ymax\"", ":", "tf", ".", "cast", "(", "new_ymax", ".", "values", ",", "tf", ".", "float32", ")", "}", "\n", "\n", "anchor_box_centers", "=", "{", "\"x\"", ":", "tf", ".", "constant", "(", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"y\"", ":", "tf", ".", "constant", "(", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"w\"", ":", "tf", ".", "constant", "(", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "2", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"h\"", ":", "tf", ".", "constant", "(", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "3", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "}", "# 4 tensors of shape [N]", "\n", "dataset_box_centers", "=", "{", "\"x\"", ":", "tf", ".", "cast", "(", "dataset_box_tens", "[", "\"xmax\"", "]", "+", "dataset_box_tens", "[", "\"xmin\"", "]", ",", "tf", ".", "float32", ")", "*", "tf", ".", "constant", "(", "0.5", ")", ",", "\n", "\"y\"", ":", "tf", ".", "cast", "(", "dataset_box_tens", "[", "\"ymax\"", "]", "+", "dataset_box_tens", "[", "\"ymin\"", "]", ",", "tf", ".", "float32", ")", "*", "tf", ".", "constant", "(", "0.5", ")", ",", "\n", "\"w\"", ":", "tf", ".", "cast", "(", "dataset_box_tens", "[", "\"xmax\"", "]", "-", "dataset_box_tens", "[", "\"xmin\"", "]", "+", "tf", ".", "constant", "(", "1.0", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "\"h\"", ":", "tf", ".", "cast", "(", "dataset_box_tens", "[", "\"ymax\"", "]", "-", "dataset_box_tens", "[", "\"ymin\"", "]", "+", "tf", ".", "constant", "(", "1.0", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "}", "# 4 tensors of shape [M]", "\n", "\n", "aidx", "=", "get_matcher_algorithm", "(", "mc", ".", "MATCHER_ALGORITHM", ")", "(", "record", ",", "anchor_box_tens", ",", "dataset_box_tens", ",", "\n", "anchor_box_centers", ",", "dataset_box_centers", ",", "idx", ",", "\n", "N", ",", "M", ",", "pre_N", ",", "mc", ".", "BATCH_SIZE", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"deltas\"", ")", ":", "\n", "        ", "deltas", "=", "{", "\n", "\"dx\"", ":", "tf", ".", "SparseTensor", "(", "idx", ",", "\n", "tf", ".", "cast", "(", "dataset_box_centers", "[", "\"x\"", "]", "-", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"x\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"w\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ",", "dense_shape", "=", "new_xmin", ".", "dense_shape", ")", ",", "\n", "\"dy\"", ":", "tf", ".", "SparseTensor", "(", "idx", ",", "\n", "tf", ".", "cast", "(", "dataset_box_centers", "[", "\"y\"", "]", "-", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"y\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"h\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ",", "dense_shape", "=", "new_xmin", ".", "dense_shape", ")", ",", "\n", "\"dw\"", ":", "tf", ".", "SparseTensor", "(", "idx", ",", "tf", ".", "log", "(", "tf", ".", "cast", "(", "dataset_box_centers", "[", "\"w\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"w\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ")", ",", "dense_shape", "=", "new_xmin", ".", "dense_shape", ")", ",", "\n", "\"dh\"", ":", "tf", ".", "SparseTensor", "(", "idx", ",", "tf", ".", "log", "(", "tf", ".", "cast", "(", "dataset_box_centers", "[", "\"h\"", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "/", "tf", ".", "gather", "(", "anchor_box_centers", "[", "\"h\"", "]", ",", "indices", "=", "aidx", ".", "values", ")", ")", ",", "dense_shape", "=", "new_xmin", ".", "dense_shape", ")", "}", "\n", "\n", "# return a batch of pre-processed input", "\n", "", "", "return", "{", "\n", "\"image/object/bbox/xmin\"", ":", "new_xmin", ",", "\n", "\"image/object/bbox/xmax\"", ":", "new_xmax", ",", "\n", "\"image/object/bbox/ymin\"", ":", "new_ymin", ",", "\n", "\"image/object/bbox/ymax\"", ":", "new_ymax", ",", "\n", "\"image/object/bbox/aidx\"", ":", "tf", ".", "cast", "(", "aidx", ",", "tf", ".", "int64", ")", ",", "\n", "\"image/object/bbox/deltas\"", ":", "deltas", ",", "\n", "\"image/object/class/label\"", ":", "record", "[", "\"image/object/class/label\"", "]", ",", "\n", "\"image/decoded\"", ":", "new_imgs", ",", "\n", "\"image/height\"", ":", "record", "[", "\"image/height\"", "]", ",", "\n", "\"image/width\"", ":", "record", "[", "\"image/width\"", "]", ",", "\n", "\"image/filename\"", ":", "record", "[", "\"image/filename\"", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.tf_data_augmentation": [[145, 232], ["tensorflow.name_scope", "tensorflow.zeros", "tensorflow.name_scope", "tensorflow.maximum", "tensorflow.reduce_max", "tensorflow.minimum", "tensorflow.maximum", "tensorflow.reduce_max", "tensorflow.minimum", "tensorflow.random_uniform", "tensorflow.random_uniform", "tensorflow.stack", "tensorflow.stack", "tensorflow.cast", "tensorflow.cast", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.tile", "tensorflow.tile", "tensorflow.name_scope", "tensorflow.equal", "tensorflow.unstack", "tensorflow.unstack", "range", "tensorflow.stack", "tensorflow.stack", "tensorflow.minimum", "tensorflow.minimum", "tensorflow.image.pad_to_bounding_box", "tensorflow.random_uniform", "unstacked_flipped_imgs.append", "tensorflow.cond", "tensorflow.cond", "tensorflow.reduce_min", "float", "float", "float", "tensorflow.reduce_min", "float", "float", "float", "tensorflow.cast", "tensorflow.cast", "tensorflow.zeros", "tensorflow.cast", "tensorflow.cast", "tensorflow.fill", "tensorflow.maximum", "tensorflow.maximum", "tensorflow.slice", "range", "tensorflow.cond", "float", "float", "tensorflow.shape", "tensorflow.image.flip_left_right", "tensorflow.abs", "tensorflow.abs"], "function", ["None"], ["", "", "def", "tf_data_augmentation", "(", "imgs", ",", "xmin0", ",", "xmax0", ",", "ymin0", ",", "ymax0", ",", "mc", ")", ":", "\n", "  ", "\"\"\"\n    This function moves images randomly and in order to keep the same size adds to 0 to the holes.\n    To avoid losing a bounding box, there are provided as xmin0, xmax0, ymin0, ymax0.\n    Images can also be flipped horizontally.\n    With these transformations bounding boxes also change.\n    Args:\n      imgs: 4D Tensor of images [BATCH_SIZE, W, H, C]\n      xmin0: Tensor of xmins of bounding boxes [BATCH_SIZE, ?]\n      xmax0: Tensor of xmaxs of bounding boxes [BATCH_SIZE, ?]\n      ymin0: Tensor of ymins of bounding boxes [BATCH_SIZE, ?]\n      ymax0: Tensor of ymaxs of bounding boxes [BATCH_SIZE, ?]\n      mc: model configuration\n    Returns:\n      unstacked_flipped_imgs: images transformed as a list of length BATCH_SIZE\n      new_xmin: new Tensor of xmins of bounding boxes after transormations\n      new_xmax: new Tensor of xmaxs of bounding boxes after transormations\n      ymin: new Tensor of ymins of bounding boxes after transormations\n      ymax: new Tensor of ymaxs of bounding boxes after transormations\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"data_augmentation\"", ")", ":", "\n", "    ", "_zeros", "=", "tf", ".", "zeros", "(", "[", "mc", ".", "BATCH_SIZE", "]", ")", "\n", "# distort-move image randomly", "\n", "with", "tf", ".", "name_scope", "(", "\"image_distortion\"", ")", ":", "\n", "      ", "min_drift_x", "=", "tf", ".", "maximum", "(", "-", "tf", ".", "reduce_min", "(", "xmin0", ",", "axis", "=", "1", ")", ",", "-", "float", "(", "mc", ".", "DRIFT_X", ")", "/", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", ")", "# for each image", "\n", "max_x_per_img", "=", "tf", ".", "reduce_max", "(", "xmax0", ",", "axis", "=", "1", ")", "\n", "max_drift_x", "=", "tf", ".", "minimum", "(", "1.0", "-", "max_x_per_img", ",", "float", "(", "mc", ".", "DRIFT_X", ")", "/", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", ")", "# for each image", "\n", "min_drift_y", "=", "tf", ".", "maximum", "(", "-", "tf", ".", "reduce_min", "(", "ymin0", ",", "axis", "=", "1", ")", ",", "-", "float", "(", "mc", ".", "DRIFT_Y", ")", "/", "float", "(", "mc", ".", "IMAGE_HEIGHT", ")", ")", "# for each image", "\n", "max_y_per_img", "=", "tf", ".", "reduce_max", "(", "ymax0", ",", "axis", "=", "1", ")", "\n", "max_drift_y", "=", "tf", ".", "minimum", "(", "1.0", "-", "max_y_per_img", ",", "float", "(", "mc", ".", "DRIFT_Y", ")", "/", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", ")", "# for each image", "\n", "\n", "randoms_dx", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "mc", ".", "BATCH_SIZE", "]", ")", "\n", "randoms_dy", "=", "tf", ".", "random_uniform", "(", "shape", "=", "[", "mc", ".", "BATCH_SIZE", "]", ")", "\n", "\n", "unexpanded_dx", "=", "randoms_dx", "*", "(", "max_drift_x", "-", "min_drift_x", ")", "+", "min_drift_x", "\n", "unexpanded_dy", "=", "randoms_dy", "*", "(", "max_drift_y", "-", "min_drift_y", ")", "+", "min_drift_y", "\n", "\n", "start_x", "=", "-", "tf", ".", "minimum", "(", "unexpanded_dx", ",", "_zeros", ")", "\n", "start_y", "=", "-", "tf", ".", "minimum", "(", "unexpanded_dy", ",", "_zeros", ")", "\n", "\n", "begins", "=", "tf", ".", "stack", "(", "[", "tf", ".", "cast", "(", "start_y", "*", "mc", ".", "IMAGE_HEIGHT", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "cast", "(", "start_x", "*", "mc", ".", "IMAGE_WIDTH", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "zeros", "(", "[", "mc", ".", "BATCH_SIZE", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "sizes", "=", "tf", ".", "stack", "(", "[", "tf", ".", "cast", "(", "(", "1.0", "-", "tf", ".", "abs", "(", "unexpanded_dy", ")", ")", "*", "mc", ".", "IMAGE_HEIGHT", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "cast", "(", "(", "1.0", "-", "tf", ".", "abs", "(", "unexpanded_dx", ")", ")", "*", "mc", ".", "IMAGE_WIDTH", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "fill", "(", "[", "mc", ".", "BATCH_SIZE", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "pad_left", "=", "tf", ".", "cast", "(", "mc", ".", "IMAGE_WIDTH", "*", "tf", ".", "maximum", "(", "unexpanded_dx", ",", "_zeros", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "pad_top", "=", "tf", ".", "cast", "(", "mc", ".", "IMAGE_HEIGHT", "*", "tf", ".", "maximum", "(", "unexpanded_dy", ",", "_zeros", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "untiled_dx", "=", "tf", ".", "expand_dims", "(", "unexpanded_dx", ",", "axis", "=", "1", ")", "\n", "untiled_dy", "=", "tf", ".", "expand_dims", "(", "unexpanded_dy", ",", "axis", "=", "1", ")", "\n", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "[", "1", "]", ",", "tf", ".", "shape", "(", "xmin0", ")", "[", "1", ":", "]", "]", ",", "axis", "=", "0", ")", "\n", "dx", "=", "tf", ".", "tile", "(", "untiled_dx", ",", "multiples", "=", "tile_shape", ")", "\n", "dy", "=", "tf", ".", "tile", "(", "untiled_dy", ",", "multiples", "=", "tile_shape", ")", "\n", "\n", "xmin", "=", "xmin0", "+", "dx", "\n", "xmax", "=", "xmax0", "+", "dx", "\n", "ymin", "=", "ymin0", "+", "dy", "\n", "ymax", "=", "ymax0", "+", "dy", "\n", "\n", "distorted_imgs", "=", "[", "tf", ".", "image", ".", "pad_to_bounding_box", "(", "\n", "tf", ".", "slice", "(", "imgs", "[", "i", "]", ",", "begins", "[", "i", "]", ",", "sizes", "[", "i", "]", ")", ",", "\n", "pad_top", "[", "i", "]", ",", "pad_left", "[", "i", "]", ",", "mc", ".", "IMAGE_HEIGHT", ",", "mc", ".", "IMAGE_WIDTH", ")", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", "]", "\n", "\n", "# flip image leftright with 50% probability", "\n", "", "with", "tf", ".", "name_scope", "(", "\"flipping\"", ")", ":", "\n", "      ", "_conds", "=", "tf", ".", "equal", "(", "\n", "tf", ".", "random_uniform", "(", "\n", "[", "mc", ".", "BATCH_SIZE", "]", ",", "minval", "=", "0", ",", "maxval", "=", "2", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "1", ")", "\n", "unstacked_flipped_imgs", "=", "[", "]", "\n", "unstacked_xmin", "=", "tf", ".", "unstack", "(", "xmin", ",", "axis", "=", "0", ",", "num", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "unstacked_xmax", "=", "tf", ".", "unstack", "(", "xmax", ",", "axis", "=", "0", ",", "num", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", ":", "\n", "        ", "unstacked_flipped_imgs", ".", "append", "(", "\n", "tf", ".", "cond", "(", "_conds", "[", "i", "]", ",", "lambda", ":", "tf", ".", "image", ".", "flip_left_right", "(", "distorted_imgs", "[", "i", "]", ")", ",", "lambda", ":", "distorted_imgs", "[", "i", "]", ")", ")", "\n", "u_xmin", "=", "unstacked_xmin", "[", "i", "]", "\n", "u_xmax", "=", "unstacked_xmax", "[", "i", "]", "\n", "unstacked_xmin", "[", "i", "]", "=", "(", "tf", ".", "cond", "(", "_conds", "[", "i", "]", ",", "lambda", ":", "1.0", "-", "u_xmax", ",", "lambda", ":", "u_xmin", ")", ")", "\n", "unstacked_xmax", "[", "i", "]", "=", "(", "tf", ".", "cond", "(", "_conds", "[", "i", "]", ",", "lambda", ":", "1.0", "-", "u_xmin", ",", "lambda", ":", "u_xmax", ")", ")", "\n", "\n", "# flipped_imgs = tf.stack(unstacked_flipped_imgs, axis=0)", "\n", "", "new_xmin", "=", "tf", ".", "stack", "(", "unstacked_xmin", ",", "axis", "=", "0", ")", "\n", "new_xmax", "=", "tf", ".", "stack", "(", "unstacked_xmax", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "return", "unstacked_flipped_imgs", ",", "new_xmin", ",", "new_xmax", ",", "ymin", ",", "ymax", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_num_images": [[233, 259], ["tensorflow.Graph", "tf.Graph.as_default", "tensorflow.Session", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator().get_next", "os.path.join", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "tf.Session.run", "mc.DATASET_NAME.lower"], "function", ["None"], ["", "def", "get_num_images", "(", "mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"train\"", ")", ":", "\n", "  ", "\"\"\"\n  This function returns the number of images inside the dataset tfrecord in the path provided my mc\n  Args:\n    mc: model configuration dictionary\n    keys_to_features: keys to features of tfrecord dataset\n    dataset_set: The set of the dataset. It can be one of: \"train\",\"val\",\"test\"\n  Returns:\n    number of images inside the dataset record\n  \"\"\"", "\n", "pr_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "pr_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "pr_sess", "=", "tf", ".", "Session", "(", "graph", "=", "pr_graph", ")", "\n", "pr_dataset", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_\"", "+", "dataset_set", "+", "\".record\"", ")", ",", "\n", "1", ",", "keys_to_features", ",", "num_epochs", "=", "1", ",", "\n", "reader_num_threads", "=", "1", ",", "parser_num_threads", "=", "4", ",", "shuffle", "=", "False", ")", "\n", "pr_it", "=", "pr_dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "num_images", "=", "0", "\n", "try", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "pr_sess", ".", "run", "(", "pr_it", ")", "\n", "num_images", "+=", "1", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "pass", "\n", "", "", "return", "num_images", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.reduce_dataset_by_class": [[260, 342], ["tensorflow.python_io.TFRecordWriter", "tensorflow.Graph", "os.path.join", "os.path.join", "tf.Graph.as_default", "tensorflow.Session", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator().get_next", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tf.python_io.TFRecordWriter.close", "os.path.join", "open", "f.write", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "range", "tf.Session.run", "tensorflow.train.Example", "numpy.any", "os.path.join", "str", "len", "tf.python_io.TFRecordWriter.write", "tensorflow.train.Features", "tf.train.Example.SerializeToString", "mc.DATASET_NAME.lower", "mc.DATASET_NAME.lower", "mc.DATASET_NAME.lower", "creation.int64_feature", "creation.int64_feature", "creation.bytes_feature", "creation.bytes_feature", "creation.float_list_feature", "creation.float_list_feature", "creation.float_list_feature", "creation.float_list_feature", "creation.int64_list_feature", "temp_image_filename.encode"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode"], ["", "def", "reduce_dataset_by_class", "(", "mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"train\"", ")", ":", "\n", "  ", "\"\"\"\n    It creates a reduced dataset of the initial dataset tfrecord which is inside mc[\"DATA_PATH\"].\n    The reduced dataset is stored in mc.PREPROCESSED_DATA_DIR if PREPROCESSED_DATA_DIR is defined,\n    else it is stored in mc.BASE_DIR. The reduction procedure is done by extracting only the\n    classes defined in the mc.CLASSES table. It is important to define the mc.INDICES, so that\n    there will be a 1-1 correpsondence between the classes in the reduced dataset and the classes\n    in the initial dataset. This is needed because it is easier for the evaluation of the trained\n    model.\n    Args:\n      keys_to_features: keys to features of the initial tfrecord dataset\n      dataset_set: The set of the dataset. It can be one of: \"train\",\"val\",\"test\"\n    Returns:\n      The number of images inside the reduced dataset\n  \"\"\"", "\n", "if", "(", "\"PREPROCESSED_DATA_DIR\"", "in", "mc", ")", ":", "\n", "    ", "_writter_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"PREPROCESSED_DATA_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_\"", "+", "dataset_set", "+", "\".record\"", ")", "\n", "", "else", ":", "\n", "    ", "_writter_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_\"", "+", "dataset_set", "+", "\".record\"", ")", "\n", "", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "_writter_path", ")", "\n", "pr_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "pr_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "pr_sess", "=", "tf", ".", "Session", "(", "graph", "=", "pr_graph", ")", "\n", "pr_dataset", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_\"", "+", "dataset_set", "+", "\".record\"", ")", ",", "\n", "1", ",", "keys_to_features", ",", "num_epochs", "=", "1", ",", "\n", "reader_num_threads", "=", "1", ",", "parser_num_threads", "=", "4", ",", "shuffle", "=", "False", ")", "\n", "pr_it", "=", "pr_dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "# specify tensors to be executed to create the new dataset", "\n", "width", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/width\"", "]", ",", "[", "]", ")", "\n", "height", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/height\"", "]", ",", "[", "]", ")", "\n", "encoded_image", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/encoded\"", "]", ",", "[", "]", ")", "\n", "image_filename", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/filename\"", "]", ",", "[", "]", ")", "\n", "xmin", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/xmin\"", "]", ".", "values", ",", "[", "-", "1", "]", ")", "\n", "xmax", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/xmax\"", "]", ".", "values", ",", "[", "-", "1", "]", ")", "\n", "ymin", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/ymin\"", "]", ".", "values", ",", "[", "-", "1", "]", ")", "\n", "ymax", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/ymax\"", "]", ".", "values", ",", "[", "-", "1", "]", ")", "\n", "label", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/class/label\"", "]", ".", "values", ",", "[", "-", "1", "]", ")", "\n", "\n", "# build a reverse mapping for labels ", "\n", "reverse_map", "=", "{", "mc", ".", "LABEL_INDICES", "[", "r_m_idx", "]", ":", "r_m_idx", "for", "r_m_idx", "in", "range", "(", "len", "(", "mc", ".", "LABEL_INDICES", ")", ")", "}", "\n", "# run sessions to fill the data in the dataset with a tf_example per image", "\n", "num_images", "=", "0", "\n", "try", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "temp_height", ",", "temp_width", ",", "temp_xmin", ",", "temp_xmax", ",", "temp_ymin", ",", "temp_ymax", ",", "temp_label", ",", "temp_encoded_image", ",", "temp_image_filename", "=", "pr_sess", ".", "run", "(", "[", "\n", "height", ",", "width", ",", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", ",", "\n", "# text,", "\n", "label", ",", "\n", "encoded_image", ",", "image_filename", "]", ")", "\n", "label_indices", "=", "[", "c_label", "in", "mc", ".", "LABEL_INDICES", "for", "c_label", "in", "temp_label", "]", "\n", "labels", "=", "[", "reverse_map", "[", "c_label", "]", "for", "c_label", "in", "temp_label", "if", "c_label", "in", "mc", ".", "LABEL_INDICES", "]", "\n", "\n", "tf_example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/height'", ":", "dataset_util", ".", "int64_feature", "(", "temp_height", ")", ",", "\n", "'image/width'", ":", "dataset_util", ".", "int64_feature", "(", "temp_width", ")", ",", "\n", "'image/filename'", ":", "dataset_util", ".", "bytes_feature", "(", "temp_image_filename", ".", "encode", "(", "'utf8'", ")", ")", ",", "\n", "'image/encoded'", ":", "dataset_util", ".", "bytes_feature", "(", "temp_encoded_image", ")", ",", "\n", "'image/object/bbox/xmin'", ":", "dataset_util", ".", "float_list_feature", "(", "temp_xmin", "[", "label_indices", "]", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "dataset_util", ".", "float_list_feature", "(", "temp_xmax", "[", "label_indices", "]", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "dataset_util", ".", "float_list_feature", "(", "temp_ymin", "[", "label_indices", "]", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "dataset_util", ".", "float_list_feature", "(", "temp_ymax", "[", "label_indices", "]", ")", ",", "\n", "'image/object/class/label'", ":", "dataset_util", ".", "int64_list_feature", "(", "labels", ")", ",", "\n", "}", ")", ")", "\n", "# if corresponding labels found write to dataset file", "\n", "if", "(", "np", ".", "any", "(", "label_indices", ")", ")", ":", "\n", "          ", "writer", ".", "write", "(", "tf_example", ".", "SerializeToString", "(", ")", ")", "\n", "num_images", "+=", "1", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "pass", "\n", "", "writer", ".", "close", "(", ")", "\n", "# write num images to a file", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", ".", "BASE_DIR", ",", "\"num_images_\"", "+", "dataset_set", "+", "\".txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "str", "(", "num_images", ")", ")", "\n", "# print(RGB_SUM, num_pixels, (RGB_SUM / float(num_pixels)))", "\n", "", "", "return", "num_images", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_initial_anchor_shapes": [[343, 363], ["imdb.get_k_mean_boxes", "numpy.array"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_k_mean_boxes"], ["", "def", "get_initial_anchor_shapes", "(", "mc", ",", "reduced_dataset_path", ",", "keys_to_features", ")", ":", "\n", "  ", "\"\"\"\n    Creates the grid of anchors where each anchor contains a default width and height.\n    The number of anchors at each grid point are mc.ANCHOR_PER_GRID. The final anchor \n    3D grid is returned as a numpy array.\n    Args:\n      mc: model configuration\n      reduced_dataset_path: The path of the folder where the final dataset resides, after passing all reduction steps (if necessary).\n      keys_to_features: keys to features of tfrecord dataset\n    Returns:\n      The default anchor shapes as numpy array which are going to be used from the final layer of\n      the detection algorithm.\n  \"\"\"", "\n", "if", "mc", ".", "INIT_ANCHOR_SHAPES", "[", "\"METHOD\"", "]", "==", "\"KNN\"", ":", "\n", "    ", "k", "=", "mc", ".", "ANCHOR_PER_GRID", "\n", "initial_anchor_shapes", "=", "get_k_mean_boxes", "(", "k", ",", "\n", "reduced_dataset_path", ",", "mc", ".", "IMAGE_WIDTH", ",", "mc", ".", "IMAGE_HEIGHT", ",", "keys_to_features", ")", "\n", "", "elif", "mc", ".", "INIT_ANCHOR_SHAPES", "[", "\"METHOD\"", "]", "==", "\"CONST\"", ":", "\n", "    ", "initial_anchor_shapes", "=", "np", ".", "array", "(", "mc", ".", "INIT_ANCHOR_SHAPES", "[", "\"VALUE\"", "]", ")", "\n", "", "return", "initial_anchor_shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_k_mean_boxes": [[364, 409], ["tensorflow.Graph", "numpy.mean", "sklearn.cluster.KMeans().fit", "numpy.stack", "tf.Graph.as_default", "tensorflow.Session", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator().get_next", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "numpy.asarray", "os.path.join", "sklearn.cluster.KMeans", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tf.Session.run", "X.extend", "numpy.array"], "function", ["None"], ["", "def", "get_k_mean_boxes", "(", "k", ",", "dataset_path", ",", "image_width", ",", "image_height", ",", "keys_to_features", ")", ":", "\n", "  ", "\"\"\"\n  Use all boxes inputs of the dataset as input to k-means\n  Args:\n    k: stands for k in k-means\n    dataset_path: where the dataset is\n    mc : model configuration\n    keys_to_features: keys to features of tfrecord dataset\n  Returns:\n    The k 2-D centers\n  \"\"\"", "\n", "X", "=", "[", "]", "\n", "pr_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "pr_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "pr_sess", "=", "tf", ".", "Session", "(", "graph", "=", "pr_graph", ")", "\n", "pr_dataset", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "\n", "os", ".", "path", ".", "join", "(", "dataset_path", ")", ",", "\n", "1", ",", "keys_to_features", ",", "num_epochs", "=", "1", ",", "\n", "reader_num_threads", "=", "1", ",", "parser_num_threads", "=", "1", ",", "shuffle", "=", "False", ")", "\n", "pr_it", "=", "pr_dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "xmin", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/xmin\"", "]", ".", "values", "*", "tf", ".", "cast", "(", "pr_it", "[", "\"image/width\"", "]", ",", "tf", ".", "float32", ")", ",", "[", "-", "1", "]", ")", "\n", "xmax", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/xmax\"", "]", ".", "values", "*", "tf", ".", "cast", "(", "pr_it", "[", "\"image/width\"", "]", ",", "tf", ".", "float32", ")", ",", "[", "-", "1", "]", ")", "\n", "width", "=", "xmax", "-", "xmin", "\n", "# cx = (xmin + xmax)/2.0", "\n", "ymin", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/ymin\"", "]", ".", "values", "*", "tf", ".", "cast", "(", "pr_it", "[", "\"image/height\"", "]", ",", "tf", ".", "float32", ")", ",", "[", "-", "1", "]", ")", "\n", "ymax", "=", "tf", ".", "reshape", "(", "pr_it", "[", "\"image/object/bbox/ymax\"", "]", ".", "values", "*", "tf", ".", "cast", "(", "pr_it", "[", "\"image/height\"", "]", ",", "tf", ".", "float32", ")", ",", "[", "-", "1", "]", ")", "\n", "# cy = (ymin + ymax)/2.0", "\n", "height", "=", "ymax", "-", "ymin", "\n", "try", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "temp_width", ",", "temp_height", "=", "pr_sess", ".", "run", "(", "[", "\n", "width", ",", "height", "]", ")", "\n", "X", ".", "extend", "(", "np", ".", "array", "(", "[", "temp_width", ",", "temp_height", "]", ")", ".", "T", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "pass", "\n", "", "", "means", "=", "np", ".", "mean", "(", "X", ",", "axis", "=", "0", ")", "\n", "kmeans", "=", "KMeans", "(", "n_clusters", "=", "k", ",", "random_state", "=", "0", ")", ".", "fit", "(", "np", ".", "asarray", "(", "(", "X", "-", "means", ")", ")", ")", "\n", "\n", "_centers", "=", "kmeans", ".", "cluster_centers_", "\n", "centers_x", "=", "(", "_centers", "[", ":", ",", "0", "]", "+", "means", "[", "0", "]", ")", "/", "image_width", "\n", "centers_y", "=", "(", "_centers", "[", ":", ",", "1", "]", "+", "means", "[", "1", "]", ")", "/", "image_height", "\n", "centers", "=", "np", ".", "stack", "(", "(", "centers_x", ",", "centers_y", ")", ",", "axis", "=", "1", ")", "\n", "\n", "return", "centers", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_anchor_box_from_dataset": [[410, 421], ["imdb.get_initial_anchor_shapes", "numpy.array", "len", "config.config_cooker.set_anchors"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_initial_anchor_shapes", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.set_anchors"], ["", "def", "get_anchor_box_from_dataset", "(", "mc", ",", "reduced_dataset_path", ",", "keys_to_features", ")", ":", "\n", "  ", "\"\"\"\n    The anchors are defined by the dataset\n  \"\"\"", "\n", "# get initial anchor shapes based on config", "\n", "mc", ".", "INITIAL_ANCHOR_SHAPES", "=", "get_initial_anchor_shapes", "(", "mc", ",", "reduced_dataset_path", ",", "keys_to_features", ")", "\n", "\n", "anchor_box", "=", "np", ".", "array", "(", "config_cooker", ".", "set_anchors", "(", "mc", ")", ")", "\n", "anchors", "=", "len", "(", "anchor_box", ")", "\n", "\n", "return", "anchor_box", ",", "anchors", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.kitti": [[15, 53], ["os.path.join", "tensorflow.name_scope", "imdb.get_keys_to_features", "os.path.join", "os.path.join", "imdb.get_anchor_box_from_dataset", "os.path.dirname", "train_graph.as_default", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "imdb.load_data", "eval_graph.as_default", "easydict.EasyDict", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "imdb.load_data", "dataset_train.make_one_shot_iterator.get_next", "mc.copy", "dataset_eval.make_one_shot_iterator.get_next"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_keys_to_features", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_anchor_box_from_dataset", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data"], ["def", "kitti", "(", "mc", ",", "train_graph", ",", "eval_graph", ")", ":", "\n", "  ", "with", "tf", ".", "name_scope", "(", "\"KITTI_input\"", ")", ":", "\n", "    ", "keys_to_features", "=", "imdb", ".", "get_keys_to_features", "(", ")", "\n", "\n", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"kitti_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"kitti_val.record\"", ")", "\n", "\n", "# get anchor boxes before creating the input graph", "\n", "mc", ".", "ANCHOR_BOX", ",", "mc", ".", "ANCHORS", "=", "imdb", ".", "get_anchor_box_from_dataset", "(", "mc", ",", "dataset_train_path", ",", "keys_to_features", ")", "\n", "\n", "# prepare training dataset", "\n", "if", "train_graph", ":", "\n", "      ", "with", "train_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "dataset_train", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_train_path", ",", "\n", "mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "None", ",", "\n", "reader_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "parser_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "shuffle_buffer_size", "=", "1200", "if", "mc", ".", "IS_TRAINING", "else", "512", ",", "sloppy_ordering", "=", "True", ")", "\n", "it_train", "=", "dataset_train", ".", "make_one_shot_iterator", "(", ")", "\n", "train_list", "=", "imdb", ".", "load_data", "(", "it_train", ".", "get_next", "(", ")", ",", "mc", ",", "training", "=", "True", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_png", ")", "\n", "", "", "else", ":", "\n", "      ", "train_list", "=", "None", "\n", "\n", "# prepare evaluation dataset", "\n", "", "if", "eval_graph", ":", "\n", "      ", "with", "eval_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "eval_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "dataset_eval", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_eval_path", ",", "\n", "eval_mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "None", ",", "\n", "reader_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "parser_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "shuffle", "=", "False", ",", "drop_final_batch", "=", "True", ")", "\n", "it_eval", "=", "dataset_eval", ".", "make_one_shot_iterator", "(", ")", "\n", "eval_list", "=", "imdb", ".", "load_data", "(", "it_eval", ".", "get_next", "(", ")", ",", "eval_mc", ",", "training", "=", "False", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_png", ")", "\n", "", "", "else", ":", "\n", "      ", "eval_list", "=", "None", "\n", "\n", "", "", "mc", ".", "EVAL_TOOL_PATH", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"kitti-eval/cpp/evaluate_object\"", ")", "\n", "\n", "return", "train_list", ",", "eval_list", ",", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.evaluate_detections": [[54, 121], ["os.path.join", "enumerate", "os.path.join", "print", "subprocess.call", "os.path.join", "kitti.analyze_detections", "os.path.isdir", "os.makedirs", "os.path.join", "open", "str", "os.path.join", "os.path.exists", "names.append", "names.append", "names.append", "os.path.basename().split", "open", "enumerate", "f.write", "len", "os.path.dirname", "aps.append", "aps.append", "aps.append", "aps.extend", "xrange", "os.path.dirname", "open", "f.readlines", "len", "float", "float", "float", "os.path.basename", "len", "f.write", "[].strip", "[].strip", "[].strip", "cls.lower", "os.path.join", "lines[].split", "lines[].split", "lines[].split"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.analyze_detections"], ["", "def", "evaluate_detections", "(", "mc", ",", "eval_dir", ",", "global_step", ",", "all_boxes", ",", "filenames", ")", ":", "\n", "  ", "\"\"\"Evaluate detection results.\n  Args:\n    eval_dir: directory to write evaluation logs\n    global_step: step of the checkpoint\n    all_boxes: all_boxes[cls][image] = N x 5 arrays of \n      [xmin, ymin, xmax, ymax, score]\n  Returns:\n    aps: array of average precisions.\n    analysis: Detection Analysis dir\n  \"\"\"", "\n", "det_file_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "eval_dir", ",", "'detection_files_{:s}'", ".", "format", "(", "global_step", ")", ",", "'data'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "det_file_dir", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "det_file_dir", ")", "\n", "\n", "", "unextended_filenames", "=", "[", "os", ".", "path", ".", "basename", "(", "fname", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "fname", "in", "filenames", "]", "\n", "\n", "for", "im_idx", ",", "index", "in", "enumerate", "(", "unextended_filenames", ")", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "det_file_dir", ",", "index", "+", "'.txt'", ")", "\n", "with", "open", "(", "filename", ",", "'wt'", ")", "as", "f", ":", "\n", "      ", "for", "cls_idx", ",", "cls", "in", "enumerate", "(", "mc", ".", "CLASS_NAMES", ")", ":", "\n", "        ", "dets", "=", "all_boxes", "[", "cls_idx", "]", "[", "im_idx", "]", "\n", "for", "k", "in", "xrange", "(", "len", "(", "dets", ")", ")", ":", "\n", "          ", "f", ".", "write", "(", "\n", "'{:s} -1 -1 0.0 {:.2f} {:.2f} {:.2f} {:.2f} 0.0 0.0 0.0 0.0 0.0 '", "\n", "'0.0 0.0 {:.3f}\\n'", ".", "format", "(", "\n", "cls", ".", "lower", "(", ")", ",", "dets", "[", "k", "]", "[", "0", "]", ",", "dets", "[", "k", "]", "[", "1", "]", ",", "dets", "[", "k", "]", "[", "2", "]", ",", "dets", "[", "k", "]", "[", "3", "]", ",", "\n", "dets", "[", "k", "]", "[", "4", "]", ")", "\n", ")", "\n", "\n", "", "", "", "", "eval_list_file_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "'eval.txt'", ")", "\n", "with", "open", "(", "eval_list_file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "for", "fname", "in", "unextended_filenames", ":", "\n", "      ", "f", ".", "write", "(", "fname", "+", "\"\\n\"", ")", "\n", "\n", "", "", "cmd", "=", "mc", ".", "EVAL_TOOL_PATH", "+", "' '", "+", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "'training'", ")", "+", "' '", "+", "eval_list_file_path", "+", "' '", "+", "os", ".", "path", ".", "dirname", "(", "det_file_dir", ")", "+", "' '", "+", "str", "(", "len", "(", "unextended_filenames", ")", ")", "\n", "\n", "print", "(", "'Running: {}'", ".", "format", "(", "cmd", ")", ")", "\n", "status", "=", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "\n", "aps", "=", "[", "]", "\n", "names", "=", "[", "]", "\n", "for", "cls", "in", "mc", ".", "CLASS_NAMES", ":", "\n", "    ", "det_file_name", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "det_file_dir", ")", ",", "'stats_{:s}_ap.txt'", ".", "format", "(", "cls", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "det_file_name", ")", ":", "\n", "      ", "with", "open", "(", "det_file_name", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "assert", "len", "(", "lines", ")", "==", "3", ",", "'Line number of {} should be 3'", ".", "format", "(", "det_file_name", ")", "\n", "\n", "aps", ".", "append", "(", "float", "(", "lines", "[", "0", "]", ".", "split", "(", "'='", ")", "[", "1", "]", ".", "strip", "(", ")", ")", ")", "\n", "aps", ".", "append", "(", "float", "(", "lines", "[", "1", "]", ".", "split", "(", "'='", ")", "[", "1", "]", ".", "strip", "(", ")", ")", ")", "\n", "aps", ".", "append", "(", "float", "(", "lines", "[", "2", "]", ".", "split", "(", "'='", ")", "[", "1", "]", ".", "strip", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "aps", ".", "extend", "(", "[", "0.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "names", ".", "append", "(", "cls", "+", "'_easy'", ")", "\n", "names", ".", "append", "(", "cls", "+", "'_medium'", ")", "\n", "names", ".", "append", "(", "cls", "+", "'_hard'", ")", "\n", "", "det_error_file", "=", "os", ".", "path", ".", "join", "(", "det_file_dir", ",", "\"det_error_file.txt\"", ")", "\n", "analysis", "=", "analyze_detections", "(", "mc", ",", "det_file_dir", ",", "det_error_file", ",", "unextended_filenames", ")", "\n", "return", "aps", ",", "analysis", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.analyze_detections": [[122, 238], ["dict", "kitti._load_kitti_annotation", "f.close", "print", "print", "print", "print", "print", "print", "print", "print", "print", "f.write", "zip", "os.path.join", "f.close", "bboxes.sort", "open", "xrange", "open", "f.readlines", "line.strip().split", "float", "float", "float", "float", "float", "utils.bbox_transform_inv", "bboxes.append", "numpy.array", "len", "enumerate", "enumerate", "sum", "len", "len", "utils.batch_iou", "numpy.max", "numpy.argmax", "line.strip", "obj[].lower().strip", "len", "kitti.analyze_detections._save_detection"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti._load_kitti_annotation", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.batch_iou"], ["", "def", "analyze_detections", "(", "mc", ",", "detection_file_dir", ",", "det_error_file", ",", "filenames", ")", ":", "\n", "  ", "def", "_save_detection", "(", "f", ",", "idx", ",", "error_type", ",", "det", ",", "score", ")", ":", "\n", "    ", "f", ".", "write", "(", "\n", "'{:s} {:s} {:.1f} {:.1f} {:.1f} {:.1f} {:s} {:.3f}\\n'", ".", "format", "(", "\n", "idx", ",", "error_type", ",", "\n", "det", "[", "0", "]", "-", "det", "[", "2", "]", "/", "2.", ",", "det", "[", "1", "]", "-", "det", "[", "3", "]", "/", "2.", ",", "\n", "det", "[", "0", "]", "+", "det", "[", "2", "]", "/", "2.", ",", "det", "[", "1", "]", "+", "det", "[", "3", "]", "/", "2.", ",", "\n", "mc", ".", "CLASS_NAMES", "[", "int", "(", "det", "[", "4", "]", ")", "]", ",", "\n", "score", "\n", ")", "\n", ")", "\n", "", "class_to_idx", "=", "dict", "(", "zip", "(", "mc", ".", "CLASS_NAMES", ",", "xrange", "(", "mc", ".", "CLASSES", ")", ")", ")", "\n", "# load detections", "\n", "_det_rois", "=", "{", "}", "\n", "for", "idx", "in", "filenames", ":", "\n", "    ", "det_file_name", "=", "os", ".", "path", ".", "join", "(", "detection_file_dir", ",", "idx", "+", "'.txt'", ")", "\n", "with", "open", "(", "det_file_name", ")", "as", "f", ":", "\n", "      ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "bboxes", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "      ", "obj", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "cls", "=", "class_to_idx", "[", "obj", "[", "0", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "xmin", "=", "float", "(", "obj", "[", "4", "]", ")", "\n", "ymin", "=", "float", "(", "obj", "[", "5", "]", ")", "\n", "xmax", "=", "float", "(", "obj", "[", "6", "]", ")", "\n", "ymax", "=", "float", "(", "obj", "[", "7", "]", ")", "\n", "score", "=", "float", "(", "obj", "[", "-", "1", "]", ")", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "util", ".", "bbox_transform_inv", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "bboxes", ".", "append", "(", "[", "x", ",", "y", ",", "w", ",", "h", ",", "cls", ",", "score", "]", ")", "\n", "", "bboxes", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "_det_rois", "[", "idx", "]", "=", "bboxes", "\n", "\n", "# do error analysis", "\n", "", "num_objs", "=", "0.", "\n", "num_dets", "=", "0.", "\n", "num_correct", "=", "0.", "\n", "num_loc_error", "=", "0.", "\n", "num_cls_error", "=", "0.", "\n", "num_bg_error", "=", "0.", "\n", "num_repeated_error", "=", "0.", "\n", "num_detected_obj", "=", "0.", "\n", "_rois", "=", "_load_kitti_annotation", "(", "mc", ",", "filenames", ",", "class_to_idx", ")", "\n", "with", "open", "(", "det_error_file", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "idx", "in", "filenames", ":", "\n", "      ", "gt_bboxes", "=", "np", ".", "array", "(", "_rois", "[", "idx", "]", ")", "\n", "num_objs", "+=", "len", "(", "gt_bboxes", ")", "\n", "detected", "=", "[", "False", "]", "*", "len", "(", "gt_bboxes", ")", "\n", "\n", "det_bboxes", "=", "_det_rois", "[", "idx", "]", "\n", "if", "len", "(", "gt_bboxes", ")", "<", "1", ":", "\n", "        ", "continue", "\n", "\n", "", "for", "i", ",", "det", "in", "enumerate", "(", "det_bboxes", ")", ":", "\n", "        ", "if", "i", "<", "len", "(", "gt_bboxes", ")", ":", "\n", "          ", "num_dets", "+=", "1", "\n", "", "ious", "=", "util", ".", "batch_iou", "(", "gt_bboxes", "[", ":", ",", ":", "4", "]", ",", "det", "[", ":", "4", "]", ")", "\n", "max_iou", "=", "np", ".", "max", "(", "ious", ")", "\n", "gt_idx", "=", "np", ".", "argmax", "(", "ious", ")", "\n", "if", "max_iou", ">", "0.1", ":", "\n", "          ", "if", "gt_bboxes", "[", "gt_idx", ",", "4", "]", "==", "det", "[", "4", "]", ":", "\n", "            ", "if", "max_iou", ">=", "0.5", ":", "\n", "              ", "if", "i", "<", "len", "(", "gt_bboxes", ")", ":", "\n", "                ", "if", "not", "detected", "[", "gt_idx", "]", ":", "\n", "                  ", "num_correct", "+=", "1", "\n", "detected", "[", "gt_idx", "]", "=", "True", "\n", "", "else", ":", "\n", "                  ", "num_repeated_error", "+=", "1", "\n", "", "", "", "else", ":", "\n", "              ", "if", "i", "<", "len", "(", "gt_bboxes", ")", ":", "\n", "                ", "num_loc_error", "+=", "1", "\n", "_save_detection", "(", "f", ",", "idx", ",", "'loc'", ",", "det", ",", "det", "[", "5", "]", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "i", "<", "len", "(", "gt_bboxes", ")", ":", "\n", "              ", "print", "(", "gt_bboxes", "[", "gt_idx", ",", "4", "]", ",", "det", "[", "4", "]", ")", "\n", "num_cls_error", "+=", "1", "\n", "_save_detection", "(", "f", ",", "idx", ",", "'cls'", ",", "det", ",", "det", "[", "5", "]", ")", "\n", "", "", "", "else", ":", "\n", "          ", "if", "i", "<", "len", "(", "gt_bboxes", ")", ":", "\n", "            ", "num_bg_error", "+=", "1", "\n", "_save_detection", "(", "f", ",", "idx", ",", "'bg'", ",", "det", ",", "det", "[", "5", "]", ")", "\n", "\n", "", "", "", "for", "i", ",", "gt", "in", "enumerate", "(", "gt_bboxes", ")", ":", "\n", "        ", "if", "not", "detected", "[", "i", "]", ":", "\n", "          ", "_save_detection", "(", "f", ",", "idx", ",", "'missed'", ",", "gt", ",", "-", "1.0", ")", "\n", "", "", "num_detected_obj", "+=", "sum", "(", "detected", ")", "\n", "", "", "f", ".", "close", "(", ")", "\n", "\n", "print", "(", "'Detection Analysis:'", ")", "\n", "print", "(", "'    Number of detections: {}'", ".", "format", "(", "num_dets", ")", ")", "\n", "print", "(", "'    Number of objects: {}'", ".", "format", "(", "num_objs", ")", ")", "\n", "print", "(", "'    Percentage of correct detections: {}'", ".", "format", "(", "\n", "num_correct", "/", "num_dets", ")", ")", "\n", "print", "(", "'    Percentage of localization error: {}'", ".", "format", "(", "\n", "num_loc_error", "/", "num_dets", ")", ")", "\n", "print", "(", "'    Percentage of classification error: {}'", ".", "format", "(", "\n", "num_cls_error", "/", "num_dets", ")", ")", "\n", "print", "(", "'    Percentage of background error: {}'", ".", "format", "(", "\n", "num_bg_error", "/", "num_dets", ")", ")", "\n", "print", "(", "'    Percentage of repeated detections: {}'", ".", "format", "(", "\n", "num_repeated_error", "/", "num_dets", ")", ")", "\n", "print", "(", "'    Recall: {}'", ".", "format", "(", "\n", "num_detected_obj", "/", "num_objs", ")", ")", "\n", "\n", "out", "=", "{", "}", "\n", "out", "[", "'num of detections'", "]", "=", "num_dets", "\n", "out", "[", "'num of objects'", "]", "=", "num_objs", "\n", "out", "[", "'% correct detections'", "]", "=", "num_correct", "/", "num_dets", "\n", "out", "[", "'% localization error'", "]", "=", "num_loc_error", "/", "num_dets", "\n", "out", "[", "'% classification error'", "]", "=", "num_cls_error", "/", "num_dets", "\n", "out", "[", "'% background error'", "]", "=", "num_bg_error", "/", "num_dets", "\n", "out", "[", "'% repeated error'", "]", "=", "num_repeated_error", "/", "num_dets", "\n", "out", "[", "'% recall'", "]", "=", "num_detected_obj", "/", "num_objs", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti._load_kitti_annotation": [[239, 285], ["os.path.join", "float", "float", "os.path.join", "f.close", "open", "f.readlines", "line.strip().split", "float", "float", "float", "float", "utils.bbox_transform_inv", "bboxes.append", "float", "float", "line.strip", "kitti._load_kitti_annotation._get_obj_level"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv"], ["", "def", "_load_kitti_annotation", "(", "mc", ",", "filenames", ",", "class_to_idx", ")", ":", "\n", "  ", "def", "_get_obj_level", "(", "obj", ")", ":", "\n", "    ", "height", "=", "float", "(", "obj", "[", "7", "]", ")", "-", "float", "(", "obj", "[", "5", "]", ")", "+", "1", "\n", "truncation", "=", "float", "(", "obj", "[", "1", "]", ")", "\n", "occlusion", "=", "float", "(", "obj", "[", "2", "]", ")", "\n", "if", "height", ">=", "40", "and", "truncation", "<=", "0.15", "and", "occlusion", "<=", "0", ":", "\n", "        ", "return", "1", "\n", "", "elif", "height", ">=", "25", "and", "truncation", "<=", "0.3", "and", "occlusion", "<=", "1", ":", "\n", "        ", "return", "2", "\n", "", "elif", "height", ">=", "25", "and", "truncation", "<=", "0.5", "and", "occlusion", "<=", "2", ":", "\n", "        ", "return", "3", "\n", "", "else", ":", "\n", "        ", "return", "4", "\n", "", "", "label_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "'training'", ",", "'label_2'", ")", "\n", "idx2annotation", "=", "{", "}", "\n", "for", "index", "in", "filenames", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "label_path", ",", "index", "+", "'.txt'", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "      ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "bboxes", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "      ", "obj", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "try", ":", "\n", "        ", "cls", "=", "class_to_idx", "[", "obj", "[", "0", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "]", "\n", "", "except", ":", "\n", "        ", "continue", "\n", "\n", "", "if", "mc", ".", "EXCLUDE_HARD_EXAMPLES", "and", "_get_obj_level", "(", "obj", ")", ">", "3", ":", "\n", "        ", "continue", "\n", "", "xmin", "=", "float", "(", "obj", "[", "4", "]", ")", "\n", "ymin", "=", "float", "(", "obj", "[", "5", "]", ")", "\n", "xmax", "=", "float", "(", "obj", "[", "6", "]", ")", "\n", "ymax", "=", "float", "(", "obj", "[", "7", "]", ")", "\n", "assert", "xmin", ">=", "0.0", "and", "xmin", "<=", "xmax", ",", "'Invalid bounding box x-coord xmin {} or xmax {} at {}.txt'", ".", "format", "(", "xmin", ",", "xmax", ",", "index", ")", "\n", "assert", "ymin", ">=", "0.0", "and", "ymin", "<=", "ymax", ",", "'Invalid bounding box y-coord ymin {} or ymax {} at {}.txt'", ".", "format", "(", "ymin", ",", "ymax", ",", "index", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "util", ".", "bbox_transform_inv", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ")", "\n", "bboxes", ".", "append", "(", "[", "x", ",", "y", ",", "w", ",", "h", ",", "cls", "]", ")", "\n", "\n", "", "idx2annotation", "[", "index", "]", "=", "bboxes", "\n", "\n", "", "return", "idx2annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.main": [[288, 312], ["kitti.kitti", "easydict.EasyDict", "numpy.array", "config.config_cooker.cook_config", "numpy.array", "mc_copy.ANCHOR_BOX.tolist", "json.dump", "tensorflow.Graph", "tensorflow.Session", "sess.run", "print", "json.load", "open", "open"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.kitti.kitti", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.cook_config"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "load_precomputed", "=", "False", "\n", "if", "load_precomputed", ":", "\n", "    ", "mc", "=", "edict", "(", "json", ".", "load", "(", "open", "(", "\"precomputed_mc.json\"", ",", "\"r\"", ")", ")", ")", "\n", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "mc", ".", "NUM_EPOCHS", "=", "1", "\n", "mc", ".", "SUMMARY_STEP", "=", "1000", "\n", "mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "", "else", ":", "\n", "    ", "mc", "=", "config_cooker", ".", "cook_config", "(", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/kitti_tests/kitti_squeezeDet_config.json\"", ")", "\n", "mc", ".", "NUM_EPOCHS", "=", "1", "\n", "mc", ".", "SUMMARY_STEP", "=", "1000", "\n", "mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "mc_copy", "=", "mc", "\n", "mc_copy", ".", "ANCHOR_BOX", "=", "mc_copy", ".", "ANCHOR_BOX", ".", "tolist", "(", ")", "\n", "json", ".", "dump", "(", "mc_copy", ",", "open", "(", "\"precomputed_mc.json\"", ",", "\"w\"", ")", ")", "\n", "", "t_g", ",", "e_g", "=", "tf", ".", "Graph", "(", ")", ",", "None", "\n", "mc", "[", "\"TRAIN_DIR\"", "]", "=", "\"/media/terabyte/projects/Thesis/trainings/kitti_TRAIN_DIR1\"", "\n", "train_input", ",", "eval_input", ",", "mc", "=", "kitti", "(", "mc", ",", "t_g", ",", "e_g", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "t_g", ")", "as", "sess", ":", "\n", "    ", "X", "=", "sess", ".", "run", "(", "train_input", "[", "'image/object/class/label'", "]", ")", "\n", "print", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.ms_coco.coco": [[17, 73], ["tensorflow.name_scope", "imdb.get_keys_to_features", "os.path.join", "os.path.join", "imdb.get_anchor_box_from_dataset", "imdb.reduce_dataset_by_class", "os.path.join", "os.path.join", "easydict.EasyDict", "imdb.reduce_dataset_by_class", "os.path.join", "os.path.join", "print", "train_graph.as_default", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "imdb.load_data", "eval_graph.as_default", "easydict.EasyDict", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "imdb.load_data", "mc.copy", "dataset_train.make_one_shot_iterator.get_next", "mc.copy", "dataset_eval.make_one_shot_iterator.get_next", "mc.DATASET_NAME.lower", "mc.DATASET_NAME.lower", "mc.DATASET_NAME.lower", "mc.DATASET_NAME.lower"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_keys_to_features", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_anchor_box_from_dataset", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.reduce_dataset_by_class", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.reduce_dataset_by_class", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data"], ["def", "coco", "(", "mc", ",", "train_graph", ",", "eval_graph", ")", ":", "\n", "  ", "with", "tf", ".", "name_scope", "(", "\"COCO_input\"", ")", ":", "\n", "    ", "keys_to_features", "=", "imdb", ".", "get_keys_to_features", "(", ")", "\n", "\n", "# return tf.parse_example(batch_records, keys_to_features)", "\n", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"coco_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"coco_val.record\"", ")", "\n", "\n", "# create a new dataset with preprocessed/filtered records", "\n", "if", "(", "mc", ".", "REDUCE_DATASET", "and", "not", "mc", ".", "ALREADY_PREPROCESSED", ")", ":", "\n", "      ", "imdb", ".", "reduce_dataset_by_class", "(", "mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"train\"", ")", "\n", "if", "(", "eval_graph", ")", ":", "\n", "        ", "eval_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "# eval_mc.BATCH_SIZE = 1", "\n", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "mc", ".", "EVAL_ITERS", "=", "imdb", ".", "reduce_dataset_by_class", "(", "eval_mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"val\"", ")", "\n", "eval_mc", ".", "EVAL_ITERS", "=", "mc", ".", "EVAL_ITERS", "\n", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_val.record\"", ")", "\n", "print", "(", "\"EVAL ITERS :%d\"", "%", "(", "mc", ".", "EVAL_ITERS", ")", ")", "\n", "\n", "", "", "if", "(", "mc", ".", "REDUCE_DATASET", "and", "mc", ".", "PREPROCESSED_DATA_DIR", ")", ":", "\n", "      ", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"PREPROCESSED_DATA_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"PREPROCESSED_DATA_DIR\"", "]", ",", "\"preprocessed_\"", "+", "mc", ".", "DATASET_NAME", ".", "lower", "(", ")", "+", "\"_val.record\"", ")", "\n", "\n", "# get anchor boxes before creating the input graph", "\n", "", "mc", ".", "ANCHOR_BOX", ",", "mc", ".", "ANCHORS", "=", "imdb", ".", "get_anchor_box_from_dataset", "(", "mc", ",", "dataset_train_path", ",", "keys_to_features", ")", "\n", "\n", "# prepare training dataset", "\n", "if", "train_graph", ":", "\n", "      ", "with", "train_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "dataset_train", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_train_path", ",", "\n", "mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "mc", ".", "TRAIN_EPOCHS", ",", "\n", "reader_num_threads", "=", "8", ",", "parser_num_threads", "=", "8", ",", "shuffle_buffer_size", "=", "13000", "if", "mc", ".", "IS_TRAINING", "else", "512", ",", "sloppy_ordering", "=", "True", ")", "\n", "it_train", "=", "dataset_train", ".", "make_one_shot_iterator", "(", ")", "\n", "train_list", "=", "imdb", ".", "load_data", "(", "it_train", ".", "get_next", "(", ")", ",", "mc", ",", "training", "=", "True", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_jpeg", ")", "\n", "", "", "else", ":", "\n", "      ", "train_list", "=", "None", "\n", "\n", "# prepare evaluation dataset", "\n", "", "if", "eval_graph", ":", "\n", "      ", "with", "eval_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "eval_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "# eval_mc.BATCH_SIZE = 1", "\n", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "dataset_eval", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_eval_path", ",", "\n", "eval_mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "None", ",", "\n", "reader_num_threads", "=", "8", ",", "parser_num_threads", "=", "8", ",", "shuffle", "=", "False", ",", "drop_final_batch", "=", "True", ")", "\n", "it_eval", "=", "dataset_eval", ".", "make_one_shot_iterator", "(", ")", "\n", "eval_list", "=", "imdb", ".", "load_data", "(", "it_eval", ".", "get_next", "(", ")", ",", "eval_mc", ",", "training", "=", "False", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_png", ")", "\n", "", "", "else", ":", "\n", "      ", "eval_list", "=", "None", "\n", "\n", "", "", "return", "train_list", ",", "eval_list", ",", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.ms_coco.evaluate_detections": [[74, 105], ["pycocotools.coco.COCO", "range", "os.path.join", "pycocotools.coco.COCO.loadRes", "pycocotools.cocoeval.COCOeval", "sorted", "pycocotools.cocoeval.COCOeval.evaluate", "pycocotools.cocoeval.COCOeval.accumulate", "pycocotools.cocoeval.COCOeval.summarize", "os.path.join", "enumerate", "open", "json.dump", "pycocotools.coco.COCO.getImgIds", "result.append"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadRes", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.accumulate", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.summarize", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getImgIds"], ["", "def", "evaluate_detections", "(", "mc", ",", "eval_dir", ",", "global_step", ",", "all_boxes", ",", "filenames", ")", ":", "\n", "  ", "\"\"\"Evaluate detection results.\n  Args:\n    eval_dir: directory to write evaluation logs\n    global_step: step of the checkpoint\n    all_boxes: all_boxes[cls][image_idx] = N x 5 arrays of \n      [xmin, ymin, xmax, ymax, score]\n    img_names_raw: raw name of all images\n  Returns:\n    mAP: medium average precision.\n    names: None, no names returned\n  \"\"\"", "\n", "annType", "=", "\"bbox\"", "\n", "cocoGt", "=", "COCO", "(", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"annotations\"", ",", "\"%s_%s.json\"", "%", "(", "\"instances\"", ",", "\"val2017\"", ")", ")", ")", "\n", "result", "=", "[", "]", "\n", "for", "cls", "in", "range", "(", "mc", ".", "CLASSES", ")", ":", "\n", "    ", "for", "image_idx", ",", "bbox", "in", "enumerate", "(", "all_boxes", "[", "cls", "]", ")", ":", "\n", "      ", "result", ".", "append", "(", "{", "\"image_id\"", ":", "image_idx", ",", "\"category_id\"", ":", "(", "cls", "+", "1", ")", ",", "\"bbox\"", ":", "bbox", "[", ":", "4", "]", ",", "\"score\"", ":", "bbox", "[", "4", "]", "}", ")", "\n", "", "", "temporaryResultsFile", "=", "os", ".", "path", ".", "join", "(", "eval_dir", ",", "\"result_annotations.json\"", ")", "\n", "with", "open", "(", "temporaryResultsFile", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "json", ".", "dump", "(", "result", ",", "f", ")", "\n", "", "cocoDt", "=", "cocoGt", ".", "loadRes", "(", "temporaryResultsFile", ")", "\n", "cocoEval", "=", "COCOeval", "(", "cocoGt", ",", "cocoDt", ",", "annType", ")", "\n", "imgIds", "=", "sorted", "(", "cocoGt", ".", "getImgIds", "(", ")", ")", "\n", "cocoEval", ".", "params", ".", "imgIds", "=", "imgIds", "\n", "cocoEval", ".", "evaluate", "(", ")", "\n", "cocoEval", ".", "accumulate", "(", ")", "\n", "cocoEval", ".", "summarize", "(", ")", "\n", "# get mean precision", "\n", "mAP", "=", "[", "cocoEval", ".", "stats", "[", "2", "]", "]", "\n", "return", "mAP", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.ms_coco.main": [[106, 129], ["ms_coco.coco", "easydict.EasyDict", "numpy.array", "config.config_cooker.cook_config", "numpy.array", "mc_copy.ANCHOR_BOX.tolist", "json.dump", "tensorflow.Graph", "tensorflow.Graph", "tensorflow.Session", "sess.run", "print", "json.load", "open", "open"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.ms_coco.coco", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.cook_config"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "load_precomputed", "=", "False", "\n", "if", "load_precomputed", ":", "\n", "    ", "mc", "=", "edict", "(", "json", ".", "load", "(", "open", "(", "\"precomputed_mc.json\"", ",", "\"r\"", ")", ")", ")", "\n", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "mc", ".", "NUM_EPOCHS", "=", "100", "\n", "mc", ".", "SUMMARY_STEP", "=", "1000", "\n", "mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "", "else", ":", "\n", "    ", "mc", "=", "config_cooker", ".", "cook_config", "(", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/coco_tests/coco_squeezeDet_config.json\"", ")", "\n", "mc", ".", "NUM_EPOCHS", "=", "100", "\n", "mc", ".", "SUMMARY_STEP", "=", "1000", "\n", "mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "mc", ".", "ANCHOR_BOX", "=", "np", ".", "array", "(", "mc", ".", "ANCHOR_BOX", ")", "\n", "mc_copy", "=", "mc", "\n", "mc_copy", ".", "ANCHOR_BOX", "=", "mc_copy", ".", "ANCHOR_BOX", ".", "tolist", "(", ")", "\n", "json", ".", "dump", "(", "mc_copy", ",", "open", "(", "\"precomputed_mc.json\"", ",", "\"w\"", ")", ")", "\n", "", "t_g", ",", "e_g", "=", "tf", ".", "Graph", "(", ")", ",", "tf", ".", "Graph", "(", ")", "\n", "mc", "[", "\"TRAIN_DIR\"", "]", "=", "\"/media/terabyte/projects/Thesis/trainings/coco_TRAIN_DIR1\"", "\n", "train_input", ",", "eval_input", ",", "mc", "=", "coco", "(", "mc", ",", "t_g", ",", "e_g", ")", "\n", "with", "tf", ".", "Session", "(", "graph", "=", "t_g", ")", "as", "sess", ":", "\n", "    ", "X", "=", "sess", ".", "run", "(", "train_input", ")", "\n", "print", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.__init__.get_dataset": [[12, 21], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.__init__.get_evaluation_func": [[22, 31], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.pascal_voc.pascal_voc": [[20, 79], ["tensorflow.name_scope", "imdb.get_keys_to_features", "os.path.join", "os.path.join", "imdb.get_anchor_box_from_dataset", "imdb.reduce_dataset_by_class", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "imdb.get_num_images", "train_graph.as_default", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "imdb.load_data", "eval_graph.as_default", "tensorflow.contrib.data.make_batched_features_dataset", "tf.contrib.data.make_batched_features_dataset.make_one_shot_iterator", "easydict.EasyDict", "imdb.load_data", "easydict.EasyDict", "imdb.reduce_dataset_by_class", "print", "dataset_train.make_one_shot_iterator.get_next", "mc.copy", "dataset_eval.make_one_shot_iterator.get_next", "mc.copy"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_keys_to_features", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_anchor_box_from_dataset", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.reduce_dataset_by_class", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.get_num_images", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.load_data", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.imdb.reduce_dataset_by_class"], ["def", "pascal_voc", "(", "mc", ",", "train_graph", ",", "eval_graph", ")", ":", "\n", "  ", "with", "tf", ".", "name_scope", "(", "\"PASCAL_VOC_input\"", ")", "as", "scope", ":", "\n", "    ", "keys_to_features", "=", "imdb", ".", "get_keys_to_features", "(", ")", "\n", "# set initial record paths to read data from", "\n", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"pascal_voc_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "DATA_PATH", ",", "\"pascal_voc_val.record\"", ")", "\n", "\n", "mc", ".", "ANCHOR_BOX", ",", "mc", ".", "ANCHORS", "=", "imdb", ".", "get_anchor_box_from_dataset", "(", "mc", ",", "dataset_train_path", ",", "keys_to_features", ")", "\n", "\n", "# create a new dataset with preprocessed/filtered records", "\n", "if", "(", "mc", ".", "REDUCE_DATASET", ")", ":", "\n", "      ", "if", "(", "not", "mc", ".", "ALREADY_PREPROCESSED", ")", ":", "\n", "        ", "imdb", ".", "reduce_dataset_by_class", "(", "mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"train\"", ")", "\n", "if", "(", "eval_graph", ")", ":", "\n", "          ", "eval_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "# eval_mc.BATCH_SIZE = 1", "\n", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "mc", ".", "EVAL_ITERS", "=", "imdb", ".", "reduce_dataset_by_class", "(", "eval_mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"val\"", ")", "\n", "eval_mc", ".", "EVAL_ITERS", "=", "mc", ".", "EVAL_ITERS", "\n", "print", "(", "\"EVAL ITERS :%d\"", "%", "(", "mc", ".", "EVAL_ITERS", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "pass", "\n", "# with open(os.path.join(mc.TRAIN_DIR, \"BGR_MEANS.txt\"), \"r\") as f:", "\n", "#   mc.BGR_MEANS = np.fromstring(f.readline().split(\"[[[\")[1].split(\"]]]\")[0], sep =\" \")", "\n", "", "if", "(", "mc", ".", "PREPROCESSED_DATA_DIR", ")", ":", "\n", "        ", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "PREPROCESSED_DATA_DIR", ",", "\"preprocessed_pascal_voc_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "PREPROCESSED_DATA_DIR", ",", "\"preprocessed_pascal_voc_val.record\"", ")", "\n", "", "else", ":", "\n", "        ", "dataset_train_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "TRAIN_DIR", ",", "\"preprocessed_pascal_voc_train.record\"", ")", "\n", "dataset_eval_path", "=", "os", ".", "path", ".", "join", "(", "mc", ".", "TRAIN_DIR", ",", "\"preprocessed_pascal_voc_val.record\"", ")", "\n", "", "", "elif", "eval_graph", ":", "\n", "        ", "mc", ".", "EVAL_ITERS", "=", "imdb", ".", "get_num_images", "(", "mc", ",", "keys_to_features", ",", "dataset_set", "=", "\"val\"", ")", "\n", "# prepare training dataset", "\n", "", "if", "train_graph", ":", "\n", "      ", "with", "train_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "dataset_train", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_train_path", ",", "\n", "mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "None", ",", "\n", "reader_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "parser_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "shuffle_buffer_size", "=", "12000", ",", "shuffle", "=", "True", ",", "\n", "sloppy_ordering", "=", "True", ")", "\n", "it_train", "=", "dataset_train", ".", "make_one_shot_iterator", "(", ")", "\n", "train_list", "=", "imdb", ".", "load_data", "(", "it_train", ".", "get_next", "(", ")", ",", "mc", ",", "training", "=", "True", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_jpeg", ")", "\n", "", "", "else", ":", "\n", "      ", "train_list", "=", "None", "\n", "# prepare evaluation dataset", "\n", "", "if", "(", "eval_graph", ")", ":", "\n", "      ", "with", "eval_graph", ".", "as_default", "(", ")", ":", "\n", "        ", "dataset_eval", "=", "tf", ".", "contrib", ".", "data", ".", "make_batched_features_dataset", "(", "dataset_eval_path", ",", "\n", "mc", ".", "BATCH_SIZE", ",", "keys_to_features", ",", "num_epochs", "=", "None", ",", "\n", "reader_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "parser_num_threads", "=", "mc", ".", "NUM_THREADS", "/", "2", ",", "shuffle", "=", "False", ")", "\n", "it_eval", "=", "dataset_eval", ".", "make_one_shot_iterator", "(", ")", "\n", "eval_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "eval_list", "=", "imdb", ".", "load_data", "(", "it_eval", ".", "get_next", "(", ")", ",", "eval_mc", ",", "training", "=", "False", ",", "image_decoder", "=", "tf", ".", "image", ".", "decode_jpeg", ")", "\n", "", "", "else", ":", "\n", "      ", "eval_list", "=", "None", "\n", "\n", "", "return", "train_list", ",", "eval_list", ",", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.pascal_voc.evaluate_detections": [[81, 143], ["os.path.join", "enumerate", "os.path.join", "os.path.join", "os.path.exists", "enumerate", "os.path.isdir", "os.mkdir", "os.path.join.format", "shutil.rmtree", "os.path.join.format", "voc_eval.voc_eval", "name.split", "open", "six.moves.xrange", "len", "six.moves.xrange", "len", "f.write"], "function", ["None"], ["", "", "def", "evaluate_detections", "(", "mc", ",", "eval_dir", ",", "global_step", ",", "all_boxes", ",", "img_names_raw", ")", ":", "\n", "  ", "\"\"\"Evaluate detection results.\n  Args:\n    eval_dir: directory to write evaluation logs\n    global_step: step of the checkpoint\n    all_boxes: all_boxes[cls][image_idx] = N x 5 arrays of \n      [xmin, ymin, xmax, ymax, score]\n    img_names_raw: raw name of all images\n  Returns:\n    aps: array of average precisions.\n    names: class names corresponding to each ap\n  \"\"\"", "\n", "img_names", "=", "[", "name", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "name", "in", "img_names_raw", "]", "\n", "\n", "# det_file_dir = os.path.join(", "\n", "#     eval_dir, 'detection_files_{:s}'.format(global_step))", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "eval_dir", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "eval_dir", ")", "\n", "", "det_file_path_template", "=", "os", ".", "path", ".", "join", "(", "eval_dir", ",", "'{:s}.txt'", ")", "\n", "\n", "for", "cls_idx", ",", "cls", "in", "enumerate", "(", "mc", ".", "CLASS_NAMES", ")", ":", "\n", "    ", "det_file_name", "=", "det_file_path_template", ".", "format", "(", "cls", ")", "\n", "with", "open", "(", "det_file_name", ",", "'wt'", ")", "as", "f", ":", "\n", "      ", "for", "im_idx", "in", "xrange", "(", "len", "(", "img_names", ")", ")", ":", "\n", "        ", "dets", "=", "all_boxes", "[", "cls_idx", "]", "[", "im_idx", "]", "\n", "# VOC expects 1-based indices", "\n", "for", "k", "in", "xrange", "(", "len", "(", "dets", ")", ")", ":", "\n", "          ", "f", ".", "write", "(", "'{:s} {:.3f} {:.1f} {:.1f} {:.1f} {:.1f}\\n'", ".", "\n", "format", "(", "img_names", "[", "im_idx", "]", ",", "dets", "[", "k", "]", "[", "-", "1", "]", ",", "\n", "dets", "[", "k", "]", "[", "0", "]", "+", "1", ",", "dets", "[", "k", "]", "[", "1", "]", "+", "1", ",", "\n", "dets", "[", "k", "]", "[", "2", "]", "+", "1", ",", "dets", "[", "k", "]", "[", "3", "]", "+", "1", ")", "\n", ")", "\n", "\n", "# Evaluate detection results", "\n", "", "", "", "", "annopath", "=", "os", ".", "path", ".", "join", "(", "\n", "mc", ".", "DATA_PATH", ",", "\n", "'VOC2012'", ",", "\n", "'Annotations'", ",", "\n", "'{:s}.xml'", "\n", ")", "\n", "# imagesetfile = os.path.join(", "\n", "#     mc.DATA_PATH,", "\n", "#     'VOC2012',", "\n", "#     'ImageSets',", "\n", "#     'Main',", "\n", "#     'val' + '.txt'", "\n", "# )", "\n", "cachedir", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "'annotations_cache'", ")", "\n", "# remove cache folder before calculating all the aps", "\n", "if", "(", "os", ".", "path", ".", "exists", "(", "cachedir", ")", ")", ":", "\n", "    ", "rmtree", "(", "cachedir", ")", "\n", "", "aps", "=", "[", "]", "\n", "for", "i", ",", "cls", "in", "enumerate", "(", "mc", ".", "CLASS_NAMES", ")", ":", "\n", "    ", "filename", "=", "det_file_path_template", ".", "format", "(", "cls", ")", "\n", "_", ",", "_", ",", "ap", "=", "voc_eval", "(", "\n", "filename", ",", "annopath", ",", "img_names", ",", "cls", ",", "cachedir", ",", "ovthresh", "=", "0.5", ",", "\n", "use_07_metric", "=", "False", ")", "\n", "aps", "+=", "[", "ap", "]", "\n", "# print ('{:s}: AP = {:.4f}'.format(cls, ap))", "\n", "\n", "# print ('Mean AP = {:.4f}'.format(np.mean(aps)))", "\n", "", "return", "aps", ",", "None", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.__init__": [[72, 90], ["dict", "dict", "dict", "dict", "collections.defaultdict", "collections.defaultdict", "print", "time.time", "json.load", "print", "coco.COCO.createIndex", "open", "type", "type", "time.time"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.createIndex"], ["    ", "def", "__init__", "(", "self", ",", "annotation_file", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor of Microsoft COCO helper class for reading and visualizing annotations.\n        :param annotation_file (str): location of annotation file\n        :param image_folder (str): location to the folder that hosts images.\n        :return:\n        \"\"\"", "\n", "# load dataset", "\n", "self", ".", "dataset", ",", "self", ".", "anns", ",", "self", ".", "cats", ",", "self", ".", "imgs", "=", "dict", "(", ")", ",", "dict", "(", ")", ",", "dict", "(", ")", ",", "dict", "(", ")", "\n", "self", ".", "imgToAnns", ",", "self", ".", "catToImgs", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "if", "not", "annotation_file", "==", "None", ":", "\n", "            ", "print", "(", "'loading annotations into memory...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "dataset", "=", "json", ".", "load", "(", "open", "(", "annotation_file", ",", "'r'", ")", ")", "\n", "assert", "type", "(", "dataset", ")", "==", "dict", ",", "'annotation file format {} not supported'", ".", "format", "(", "type", "(", "dataset", ")", ")", "\n", "print", "(", "'Done (t={:0.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "createIndex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.createIndex": [[91, 121], ["print", "print", "collections.defaultdict", "collections.defaultdict", "imgToAnns[].append", "catToImgs[].append"], "methods", ["None"], ["", "", "def", "createIndex", "(", "self", ")", ":", "\n", "# create index", "\n", "        ", "print", "(", "'creating index...'", ")", "\n", "anns", ",", "cats", ",", "imgs", "=", "{", "}", ",", "{", "}", ",", "{", "}", "\n", "imgToAnns", ",", "catToImgs", "=", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "\n", "if", "'annotations'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "imgToAnns", "[", "ann", "[", "'image_id'", "]", "]", ".", "append", "(", "ann", ")", "\n", "anns", "[", "ann", "[", "'id'", "]", "]", "=", "ann", "\n", "\n", "", "", "if", "'images'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", ":", "\n", "                ", "imgs", "[", "img", "[", "'id'", "]", "]", "=", "img", "\n", "\n", "", "", "if", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "cat", "in", "self", ".", "dataset", "[", "'categories'", "]", ":", "\n", "                ", "cats", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "\n", "", "", "if", "'annotations'", "in", "self", ".", "dataset", "and", "'categories'", "in", "self", ".", "dataset", ":", "\n", "            ", "for", "ann", "in", "self", ".", "dataset", "[", "'annotations'", "]", ":", "\n", "                ", "catToImgs", "[", "ann", "[", "'category_id'", "]", "]", ".", "append", "(", "ann", "[", "'image_id'", "]", ")", "\n", "\n", "", "", "print", "(", "'index created!'", ")", "\n", "\n", "# create class members", "\n", "self", ".", "anns", "=", "anns", "\n", "self", ".", "imgToAnns", "=", "imgToAnns", "\n", "self", ".", "catToImgs", "=", "catToImgs", "\n", "self", ".", "imgs", "=", "imgs", "\n", "self", ".", "cats", "=", "cats", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.info": [[122, 129], ["coco.COCO.dataset[].items", "print"], "methods", ["None"], ["", "def", "info", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Print information about the annotation file.\n        :return:\n        \"\"\"", "\n", "for", "key", ",", "value", "in", "self", ".", "dataset", "[", "'info'", "]", ".", "items", "(", ")", ":", "\n", "            ", "print", "(", "'{}: {}'", ".", "format", "(", "key", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getAnnIds": [[130, 157], ["coco._isArrayLike", "coco._isArrayLike", "len", "len", "len", "list", "len", "itertools.chain.from_iterable", "len", "len"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "", "def", "getAnnIds", "(", "self", ",", "imgIds", "=", "[", "]", ",", "catIds", "=", "[", "]", ",", "areaRng", "=", "[", "]", ",", "iscrowd", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Get ann ids that satisfy given filter conditions. default skips that filter\n        :param imgIds  (int array)     : get anns for given imgs\n               catIds  (int array)     : get anns for given cats\n               areaRng (float array)   : get anns for given area range (e.g. [0 inf])\n               iscrowd (boolean)       : get anns for given crowd label (False or True)\n        :return: ids (int array)       : integer array of ann ids\n        \"\"\"", "\n", "imgIds", "=", "imgIds", "if", "_isArrayLike", "(", "imgIds", ")", "else", "[", "imgIds", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "imgIds", ")", "==", "len", "(", "catIds", ")", "==", "len", "(", "areaRng", ")", "==", "0", ":", "\n", "            ", "anns", "=", "self", ".", "dataset", "[", "'annotations'", "]", "\n", "", "else", ":", "\n", "            ", "if", "not", "len", "(", "imgIds", ")", "==", "0", ":", "\n", "                ", "lists", "=", "[", "self", ".", "imgToAnns", "[", "imgId", "]", "for", "imgId", "in", "imgIds", "if", "imgId", "in", "self", ".", "imgToAnns", "]", "\n", "anns", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "lists", ")", ")", "\n", "", "else", ":", "\n", "                ", "anns", "=", "self", ".", "dataset", "[", "'annotations'", "]", "\n", "", "anns", "=", "anns", "if", "len", "(", "catIds", ")", "==", "0", "else", "[", "ann", "for", "ann", "in", "anns", "if", "ann", "[", "'category_id'", "]", "in", "catIds", "]", "\n", "anns", "=", "anns", "if", "len", "(", "areaRng", ")", "==", "0", "else", "[", "ann", "for", "ann", "in", "anns", "if", "ann", "[", "'area'", "]", ">", "areaRng", "[", "0", "]", "and", "ann", "[", "'area'", "]", "<", "areaRng", "[", "1", "]", "]", "\n", "", "if", "not", "iscrowd", "==", "None", ":", "\n", "            ", "ids", "=", "[", "ann", "[", "'id'", "]", "for", "ann", "in", "anns", "if", "ann", "[", "'iscrowd'", "]", "==", "iscrowd", "]", "\n", "", "else", ":", "\n", "            ", "ids", "=", "[", "ann", "[", "'id'", "]", "for", "ann", "in", "anns", "]", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getCatIds": [[158, 179], ["coco._isArrayLike", "coco._isArrayLike", "coco._isArrayLike", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "def", "getCatIds", "(", "self", ",", "catNms", "=", "[", "]", ",", "supNms", "=", "[", "]", ",", "catIds", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        filtering parameters. default skips that filter.\n        :param catNms (str array)  : get cats for given cat names\n        :param supNms (str array)  : get cats for given supercategory names\n        :param catIds (int array)  : get cats for given cat ids\n        :return: ids (int array)   : integer array of cat ids\n        \"\"\"", "\n", "catNms", "=", "catNms", "if", "_isArrayLike", "(", "catNms", ")", "else", "[", "catNms", "]", "\n", "supNms", "=", "supNms", "if", "_isArrayLike", "(", "supNms", ")", "else", "[", "supNms", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "catNms", ")", "==", "len", "(", "supNms", ")", "==", "len", "(", "catIds", ")", "==", "0", ":", "\n", "            ", "cats", "=", "self", ".", "dataset", "[", "'categories'", "]", "\n", "", "else", ":", "\n", "            ", "cats", "=", "self", ".", "dataset", "[", "'categories'", "]", "\n", "cats", "=", "cats", "if", "len", "(", "catNms", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'name'", "]", "in", "catNms", "]", "\n", "cats", "=", "cats", "if", "len", "(", "supNms", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'supercategory'", "]", "in", "supNms", "]", "\n", "cats", "=", "cats", "if", "len", "(", "catIds", ")", "==", "0", "else", "[", "cat", "for", "cat", "in", "cats", "if", "cat", "[", "'id'", "]", "in", "catIds", "]", "\n", "", "ids", "=", "[", "cat", "[", "'id'", "]", "for", "cat", "in", "cats", "]", "\n", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getImgIds": [[180, 200], ["list", "coco._isArrayLike", "coco._isArrayLike", "len", "len", "coco.COCO.imgs.keys", "set", "enumerate", "set", "set", "len"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "def", "getImgIds", "(", "self", ",", "imgIds", "=", "[", "]", ",", "catIds", "=", "[", "]", ")", ":", "\n", "        ", "'''\n        Get img ids that satisfy given filter conditions.\n        :param imgIds (int array) : get imgs for given ids\n        :param catIds (int array) : get imgs with all given cats\n        :return: ids (int array)  : integer array of img ids\n        '''", "\n", "imgIds", "=", "imgIds", "if", "_isArrayLike", "(", "imgIds", ")", "else", "[", "imgIds", "]", "\n", "catIds", "=", "catIds", "if", "_isArrayLike", "(", "catIds", ")", "else", "[", "catIds", "]", "\n", "\n", "if", "len", "(", "imgIds", ")", "==", "len", "(", "catIds", ")", "==", "0", ":", "\n", "            ", "ids", "=", "self", ".", "imgs", ".", "keys", "(", ")", "\n", "", "else", ":", "\n", "            ", "ids", "=", "set", "(", "imgIds", ")", "\n", "for", "i", ",", "catId", "in", "enumerate", "(", "catIds", ")", ":", "\n", "                ", "if", "i", "==", "0", "and", "len", "(", "ids", ")", "==", "0", ":", "\n", "                    ", "ids", "=", "set", "(", "self", ".", "catToImgs", "[", "catId", "]", ")", "\n", "", "else", ":", "\n", "                    ", "ids", "&=", "set", "(", "self", ".", "catToImgs", "[", "catId", "]", ")", "\n", "", "", "", "return", "list", "(", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns": [[201, 211], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "def", "loadAnns", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load anns with the specified ids.\n        :param ids (int array)       : integer ids specifying anns\n        :return: anns (object array) : loaded ann objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "anns", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "anns", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadCats": [[212, 222], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "", "def", "loadCats", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load cats with the specified ids.\n        :param ids (int array)       : integer ids specifying cats\n        :return: cats (object array) : loaded cat objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "cats", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "cats", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadImgs": [[223, 233], ["coco._isArrayLike", "type"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike"], ["", "", "def", "loadImgs", "(", "self", ",", "ids", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        Load anns with the specified ids.\n        :param ids (int array)       : integer ids specifying img\n        :return: imgs (object array) : loaded img objects\n        \"\"\"", "\n", "if", "_isArrayLike", "(", "ids", ")", ":", "\n", "            ", "return", "[", "self", ".", "imgs", "[", "id", "]", "for", "id", "in", "ids", "]", "\n", "", "elif", "type", "(", "ids", ")", "==", "int", ":", "\n", "            ", "return", "[", "self", ".", "imgs", "[", "ids", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.showAnns": [[234, 297], ["len", "matplotlib.gca", "matplotlib.gca.set_autoscale_on", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "matplotlib.collections.PatchCollection", "matplotlib.gca.add_collection", "Exception", "numpy.array", "matplotlib.plot", "matplotlib.plot", "print", "type", "mask.decode", "numpy.ones", "range", "matplotlib.gca.imshow", "type", "numpy.array", "numpy.all", "numpy.array().reshape", "polygons.append", "color.append", "type", "mask.frPyObjects", "numpy.dstack", "matplotlib.plot", "matplotlib.patches.Polygon", "numpy.array", "numpy.random.random().tolist", "numpy.random.random", "numpy.array", "int", "coco.COCO.loadCats", "numpy.random.random", "len"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.decode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadCats"], ["", "", "def", "showAnns", "(", "self", ",", "anns", ")", ":", "\n", "        ", "\"\"\"\n        Display the specified annotations.\n        :param anns (array of object): annotations to display\n        :return: None\n        \"\"\"", "\n", "if", "len", "(", "anns", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "if", "'segmentation'", "in", "anns", "[", "0", "]", "or", "'keypoints'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "datasetType", "=", "'instances'", "\n", "", "elif", "'caption'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "datasetType", "=", "'captions'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'datasetType not supported'", ")", "\n", "", "if", "datasetType", "==", "'instances'", ":", "\n", "            ", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "set_autoscale_on", "(", "False", ")", "\n", "polygons", "=", "[", "]", "\n", "color", "=", "[", "]", "\n", "for", "ann", "in", "anns", ":", "\n", "                ", "c", "=", "(", "np", ".", "random", ".", "random", "(", "(", "1", ",", "3", ")", ")", "*", "0.6", "+", "0.4", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "if", "'segmentation'", "in", "ann", ":", "\n", "                    ", "if", "type", "(", "ann", "[", "'segmentation'", "]", ")", "==", "list", ":", "\n", "# polygon", "\n", "                        ", "for", "seg", "in", "ann", "[", "'segmentation'", "]", ":", "\n", "                            ", "poly", "=", "np", ".", "array", "(", "seg", ")", ".", "reshape", "(", "(", "int", "(", "len", "(", "seg", ")", "/", "2", ")", ",", "2", ")", ")", "\n", "polygons", ".", "append", "(", "Polygon", "(", "poly", ")", ")", "\n", "color", ".", "append", "(", "c", ")", "\n", "", "", "else", ":", "\n", "# mask", "\n", "                        ", "t", "=", "self", ".", "imgs", "[", "ann", "[", "'image_id'", "]", "]", "\n", "if", "type", "(", "ann", "[", "'segmentation'", "]", "[", "'counts'", "]", ")", "==", "list", ":", "\n", "                            ", "rle", "=", "maskUtils", ".", "frPyObjects", "(", "[", "ann", "[", "'segmentation'", "]", "]", ",", "t", "[", "'height'", "]", ",", "t", "[", "'width'", "]", ")", "\n", "", "else", ":", "\n", "                            ", "rle", "=", "[", "ann", "[", "'segmentation'", "]", "]", "\n", "", "m", "=", "maskUtils", ".", "decode", "(", "rle", ")", "\n", "img", "=", "np", ".", "ones", "(", "(", "m", ".", "shape", "[", "0", "]", ",", "m", ".", "shape", "[", "1", "]", ",", "3", ")", ")", "\n", "if", "ann", "[", "'iscrowd'", "]", "==", "1", ":", "\n", "                            ", "color_mask", "=", "np", ".", "array", "(", "[", "2.0", ",", "166.0", ",", "101.0", "]", ")", "/", "255", "\n", "", "if", "ann", "[", "'iscrowd'", "]", "==", "0", ":", "\n", "                            ", "color_mask", "=", "np", ".", "random", ".", "random", "(", "(", "1", ",", "3", ")", ")", ".", "tolist", "(", ")", "[", "0", "]", "\n", "", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                            ", "img", "[", ":", ",", ":", ",", "i", "]", "=", "color_mask", "[", "i", "]", "\n", "", "ax", ".", "imshow", "(", "np", ".", "dstack", "(", "(", "img", ",", "m", "*", "0.5", ")", ")", ")", "\n", "", "", "if", "'keypoints'", "in", "ann", "and", "type", "(", "ann", "[", "'keypoints'", "]", ")", "==", "list", ":", "\n", "# turn skeleton into zero-based index", "\n", "                    ", "sks", "=", "np", ".", "array", "(", "self", ".", "loadCats", "(", "ann", "[", "'category_id'", "]", ")", "[", "0", "]", "[", "'skeleton'", "]", ")", "-", "1", "\n", "kp", "=", "np", ".", "array", "(", "ann", "[", "'keypoints'", "]", ")", "\n", "x", "=", "kp", "[", "0", ":", ":", "3", "]", "\n", "y", "=", "kp", "[", "1", ":", ":", "3", "]", "\n", "v", "=", "kp", "[", "2", ":", ":", "3", "]", "\n", "for", "sk", "in", "sks", ":", "\n", "                        ", "if", "np", ".", "all", "(", "v", "[", "sk", "]", ">", "0", ")", ":", "\n", "                            ", "plt", ".", "plot", "(", "x", "[", "sk", "]", ",", "y", "[", "sk", "]", ",", "linewidth", "=", "3", ",", "color", "=", "c", ")", "\n", "", "", "plt", ".", "plot", "(", "x", "[", "v", ">", "0", "]", ",", "y", "[", "v", ">", "0", "]", ",", "'o'", ",", "markersize", "=", "8", ",", "markerfacecolor", "=", "c", ",", "markeredgecolor", "=", "'k'", ",", "markeredgewidth", "=", "2", ")", "\n", "plt", ".", "plot", "(", "x", "[", "v", ">", "1", "]", ",", "y", "[", "v", ">", "1", "]", ",", "'o'", ",", "markersize", "=", "8", ",", "markerfacecolor", "=", "c", ",", "markeredgecolor", "=", "c", ",", "markeredgewidth", "=", "2", ")", "\n", "", "", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolor", "=", "color", ",", "linewidths", "=", "0", ",", "alpha", "=", "0.4", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "p", "=", "PatchCollection", "(", "polygons", ",", "facecolor", "=", "'none'", ",", "edgecolors", "=", "color", ",", "linewidths", "=", "2", ")", "\n", "ax", ".", "add_collection", "(", "p", ")", "\n", "", "elif", "datasetType", "==", "'captions'", ":", "\n", "            ", "for", "ann", "in", "anns", ":", "\n", "                ", "print", "(", "ann", "[", "'caption'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadRes": [[298, 358], ["coco.COCO", "print", "time.time", "print", "coco.COCO.createIndex", "json.load", "type", "set", "enumerate", "type", "type", "open", "type", "coco.COCO.loadNumpyAnnotations", "set", "set", "set", "set", "copy.deepcopy", "enumerate", "coco.COCO.getImgIds", "copy.deepcopy", "enumerate", "time.time", "mask.area", "copy.deepcopy", "enumerate", "mask.toBbox", "numpy.min", "numpy.max", "numpy.min", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.createIndex", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadNumpyAnnotations", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getImgIds", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.area", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.toBbox"], ["", "", "", "def", "loadRes", "(", "self", ",", "resFile", ")", ":", "\n", "        ", "\"\"\"\n        Load result file and return a result api object.\n        :param   resFile (str)     : file name of result file\n        :return: res (obj)         : result api object\n        \"\"\"", "\n", "res", "=", "COCO", "(", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "self", ".", "dataset", "[", "'images'", "]", "]", "\n", "\n", "print", "(", "'Loading and preparing results...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "if", "type", "(", "resFile", ")", "==", "str", "or", "type", "(", "resFile", ")", "==", "unicode", ":", "\n", "            ", "anns", "=", "json", ".", "load", "(", "open", "(", "resFile", ")", ")", "\n", "", "elif", "type", "(", "resFile", ")", "==", "np", ".", "ndarray", ":", "\n", "            ", "anns", "=", "self", ".", "loadNumpyAnnotations", "(", "resFile", ")", "\n", "", "else", ":", "\n", "            ", "anns", "=", "resFile", "\n", "", "assert", "type", "(", "anns", ")", "==", "list", ",", "'results in not an array of objects'", "\n", "annsImgIds", "=", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", "\n", "assert", "set", "(", "annsImgIds", ")", "==", "(", "set", "(", "annsImgIds", ")", "&", "set", "(", "self", ".", "getImgIds", "(", ")", ")", ")", ",", "'Results do not correspond to current coco set'", "\n", "if", "'caption'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "imgIds", "=", "set", "(", "[", "img", "[", "'id'", "]", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "]", ")", "&", "set", "(", "[", "ann", "[", "'image_id'", "]", "for", "ann", "in", "anns", "]", ")", "\n", "res", ".", "dataset", "[", "'images'", "]", "=", "[", "img", "for", "img", "in", "res", ".", "dataset", "[", "'images'", "]", "if", "img", "[", "'id'", "]", "in", "imgIds", "]", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "", "", "elif", "'bbox'", "in", "anns", "[", "0", "]", "and", "not", "anns", "[", "0", "]", "[", "'bbox'", "]", "==", "[", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "bb", "=", "ann", "[", "'bbox'", "]", "\n", "x1", ",", "x2", ",", "y1", ",", "y2", "=", "[", "bb", "[", "0", "]", ",", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", ",", "bb", "[", "1", "]", ",", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "]", "\n", "if", "not", "'segmentation'", "in", "ann", ":", "\n", "                    ", "ann", "[", "'segmentation'", "]", "=", "[", "[", "x1", ",", "y1", ",", "x1", ",", "y2", ",", "x2", ",", "y2", ",", "x2", ",", "y1", "]", "]", "\n", "", "ann", "[", "'area'", "]", "=", "bb", "[", "2", "]", "*", "bb", "[", "3", "]", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'segmentation'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "# now only support compressed RLE format as segmentation results", "\n", "                ", "ann", "[", "'area'", "]", "=", "maskUtils", ".", "area", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "if", "not", "'bbox'", "in", "ann", ":", "\n", "                    ", "ann", "[", "'bbox'", "]", "=", "maskUtils", ".", "toBbox", "(", "ann", "[", "'segmentation'", "]", ")", "\n", "", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'iscrowd'", "]", "=", "0", "\n", "", "", "elif", "'keypoints'", "in", "anns", "[", "0", "]", ":", "\n", "            ", "res", ".", "dataset", "[", "'categories'", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "dataset", "[", "'categories'", "]", ")", "\n", "for", "id", ",", "ann", "in", "enumerate", "(", "anns", ")", ":", "\n", "                ", "s", "=", "ann", "[", "'keypoints'", "]", "\n", "x", "=", "s", "[", "0", ":", ":", "3", "]", "\n", "y", "=", "s", "[", "1", ":", ":", "3", "]", "\n", "x0", ",", "x1", ",", "y0", ",", "y1", "=", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "min", "(", "y", ")", ",", "np", ".", "max", "(", "y", ")", "\n", "ann", "[", "'area'", "]", "=", "(", "x1", "-", "x0", ")", "*", "(", "y1", "-", "y0", ")", "\n", "ann", "[", "'id'", "]", "=", "id", "+", "1", "\n", "ann", "[", "'bbox'", "]", "=", "[", "x0", ",", "y0", ",", "x1", "-", "x0", ",", "y1", "-", "y0", "]", "\n", "", "", "print", "(", "'DONE (t={:0.2f}s)'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n", "res", ".", "dataset", "[", "'annotations'", "]", "=", "anns", "\n", "res", ".", "createIndex", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.download": [[359, 382], ["len", "enumerate", "print", "len", "coco.COCO.imgs.values", "coco.COCO.loadImgs", "os.path.exists", "os.makedirs", "time.time", "os.path.join", "print", "os.path.exists", "urlretrieve", "time.time"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadImgs"], ["", "def", "download", "(", "self", ",", "tarDir", "=", "None", ",", "imgIds", "=", "[", "]", ")", ":", "\n", "        ", "'''\n        Download COCO images from mscoco.org server.\n        :param tarDir (str): COCO results directory name\n               imgIds (list): images to be downloaded\n        :return:\n        '''", "\n", "if", "tarDir", "is", "None", ":", "\n", "            ", "print", "(", "'Please specify target directory'", ")", "\n", "return", "-", "1", "\n", "", "if", "len", "(", "imgIds", ")", "==", "0", ":", "\n", "            ", "imgs", "=", "self", ".", "imgs", ".", "values", "(", ")", "\n", "", "else", ":", "\n", "            ", "imgs", "=", "self", ".", "loadImgs", "(", "imgIds", ")", "\n", "", "N", "=", "len", "(", "imgs", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "tarDir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "tarDir", ")", "\n", "", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "            ", "tic", "=", "time", ".", "time", "(", ")", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "tarDir", ",", "img", "[", "'file_name'", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "fname", ")", ":", "\n", "                ", "urlretrieve", "(", "img", "[", "'coco_url'", "]", ",", "fname", ")", "\n", "", "print", "(", "'downloaded {}/{} images (t={:0.1f}s)'", ".", "format", "(", "i", ",", "N", ",", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadNumpyAnnotations": [[383, 405], ["print", "print", "range", "type", "print", "int", "int"], "methods", ["None"], ["", "", "def", "loadNumpyAnnotations", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Convert result data from a numpy array [Nx7] where each row contains {imageID,x1,y1,w,h,score,class}\n        :param  data (numpy.ndarray)\n        :return: annotations (python nested list)\n        \"\"\"", "\n", "print", "(", "'Converting ndarray to lists...'", ")", "\n", "assert", "(", "type", "(", "data", ")", "==", "np", ".", "ndarray", ")", "\n", "print", "(", "data", ".", "shape", ")", "\n", "assert", "(", "data", ".", "shape", "[", "1", "]", "==", "7", ")", "\n", "N", "=", "data", ".", "shape", "[", "0", "]", "\n", "ann", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "if", "i", "%", "1000000", "==", "0", ":", "\n", "                ", "print", "(", "'{}/{}'", ".", "format", "(", "i", ",", "N", ")", ")", "\n", "", "ann", "+=", "[", "{", "\n", "'image_id'", ":", "int", "(", "data", "[", "i", ",", "0", "]", ")", ",", "\n", "'bbox'", ":", "[", "data", "[", "i", ",", "1", "]", ",", "data", "[", "i", ",", "2", "]", ",", "data", "[", "i", ",", "3", "]", ",", "data", "[", "i", ",", "4", "]", "]", ",", "\n", "'score'", ":", "data", "[", "i", ",", "5", "]", ",", "\n", "'category_id'", ":", "int", "(", "data", "[", "i", ",", "6", "]", ")", ",", "\n", "}", "]", "\n", "", "return", "ann", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.annToRLE": [[406, 426], ["type", "mask.frPyObjects", "mask.merge", "type", "mask.frPyObjects"], "methods", ["None"], ["", "def", "annToRLE", "(", "self", ",", "ann", ")", ":", "\n", "        ", "\"\"\"\n        Convert annotation which can be polygons, uncompressed RLE to RLE.\n        :return: binary mask (numpy 2D array)\n        \"\"\"", "\n", "t", "=", "self", ".", "imgs", "[", "ann", "[", "'image_id'", "]", "]", "\n", "h", ",", "w", "=", "t", "[", "'height'", "]", ",", "t", "[", "'width'", "]", "\n", "segm", "=", "ann", "[", "'segmentation'", "]", "\n", "if", "type", "(", "segm", ")", "==", "list", ":", "\n", "# polygon -- a single object might consist of multiple parts", "\n", "# we merge all parts into one mask rle code", "\n", "            ", "rles", "=", "maskUtils", ".", "frPyObjects", "(", "segm", ",", "h", ",", "w", ")", "\n", "rle", "=", "maskUtils", ".", "merge", "(", "rles", ")", "\n", "", "elif", "type", "(", "segm", "[", "'counts'", "]", ")", "==", "list", ":", "\n", "# uncompressed RLE", "\n", "            ", "rle", "=", "maskUtils", ".", "frPyObjects", "(", "segm", ",", "h", ",", "w", ")", "\n", "", "else", ":", "\n", "# rle", "\n", "            ", "rle", "=", "ann", "[", "'segmentation'", "]", "\n", "", "return", "rle", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.annToMask": [[427, 435], ["coco.COCO.annToRLE", "mask.decode"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.annToRLE", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.decode"], ["", "def", "annToMask", "(", "self", ",", "ann", ")", ":", "\n", "        ", "\"\"\"\n        Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n        :return: binary mask (numpy 2D array)\n        \"\"\"", "\n", "rle", "=", "self", ".", "annToRLE", "(", "ann", ")", "\n", "m", "=", "maskUtils", ".", "decode", "(", "rle", ")", "\n", "return", "m", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco._isArrayLike": [[67, 69], ["hasattr", "hasattr"], "function", ["None"], ["", "def", "_isArrayLike", "(", "obj", ")", ":", "\n", "    ", "return", "hasattr", "(", "obj", ",", "'__iter__'", ")", "and", "hasattr", "(", "obj", ",", "'__len__'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode": [[80, 86], ["len", "_mask.encode", "len", "_mask.encode", "bimask.reshape"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode"], ["def", "encode", "(", "bimask", ")", ":", "\n", "    ", "if", "len", "(", "bimask", ".", "shape", ")", "==", "3", ":", "\n", "        ", "return", "_mask", ".", "encode", "(", "bimask", ")", "\n", "", "elif", "len", "(", "bimask", ".", "shape", ")", "==", "2", ":", "\n", "        ", "h", ",", "w", "=", "bimask", ".", "shape", "\n", "return", "_mask", ".", "encode", "(", "bimask", ".", "reshape", "(", "(", "h", ",", "w", ",", "1", ")", ",", "order", "=", "'F'", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.decode": [[87, 92], ["type", "_mask.decode", "_mask.decode"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.decode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.decode"], ["", "", "def", "decode", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "decode", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "decode", "(", "[", "rleObjs", "]", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.area": [[93, 98], ["type", "_mask.area", "_mask.area"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.area", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.area"], ["", "", "def", "area", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "area", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "area", "(", "[", "rleObjs", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.toBbox": [[99, 104], ["type", "_mask.toBbox", "_mask.toBbox"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.toBbox", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.toBbox"], ["", "", "def", "toBbox", "(", "rleObjs", ")", ":", "\n", "    ", "if", "type", "(", "rleObjs", ")", "==", "list", ":", "\n", "        ", "return", "_mask", ".", "toBbox", "(", "rleObjs", ")", "\n", "", "else", ":", "\n", "        ", "return", "_mask", ".", "toBbox", "(", "[", "rleObjs", "]", ")", "[", "0", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.__init__": [[60, 83], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "cocoeval.Params", "print", "sorted", "sorted", "cocoGt.getImgIds", "cocoGt.getCatIds"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getImgIds", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getCatIds"], ["    ", "def", "__init__", "(", "self", ",", "cocoGt", "=", "None", ",", "cocoDt", "=", "None", ",", "iouType", "=", "'segm'", ")", ":", "\n", "        ", "'''\n        Initialize CocoEval using coco APIs for gt and dt\n        :param cocoGt: coco object with ground truth annotations\n        :param cocoDt: coco object with detection results\n        :return: None\n        '''", "\n", "if", "not", "iouType", ":", "\n", "            ", "print", "(", "'iouType not specified. use default iouType segm'", ")", "\n", "", "self", ".", "cocoGt", "=", "cocoGt", "# ground truth COCO API", "\n", "self", ".", "cocoDt", "=", "cocoDt", "# detections COCO API", "\n", "self", ".", "params", "=", "{", "}", "# evaluation parameters", "\n", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category evaluation results [KxAxI] elements", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "self", ".", "params", "=", "Params", "(", "iouType", "=", "iouType", ")", "# parameters", "\n", "self", ".", "_paramsEval", "=", "{", "}", "# parameters for evaluation", "\n", "self", ".", "stats", "=", "[", "]", "# result summarization", "\n", "self", ".", "ious", "=", "{", "}", "# ious between all gts and dts", "\n", "if", "not", "cocoGt", "is", "None", ":", "\n", "            ", "self", ".", "params", ".", "imgIds", "=", "sorted", "(", "cocoGt", ".", "getImgIds", "(", ")", ")", "\n", "self", ".", "params", ".", "catIds", "=", "sorted", "(", "cocoGt", ".", "getCatIds", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval._prepare": [[85, 121], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "cocoeval.COCOeval.cocoGt.loadAnns", "cocoeval.COCOeval.cocoDt.loadAnns", "cocoeval.COCOeval.cocoGt.loadAnns", "cocoeval.COCOeval.cocoDt.loadAnns", "cocoeval.COCOeval._prepare._toMask"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns"], ["", "", "def", "_prepare", "(", "self", ")", ":", "\n", "        ", "'''\n        Prepare ._gts and ._dts for evaluation based on params\n        :return: None\n        '''", "\n", "def", "_toMask", "(", "anns", ",", "coco", ")", ":", "\n", "# modify ann['segmentation'] by reference", "\n", "            ", "for", "ann", "in", "anns", ":", "\n", "                ", "rle", "=", "coco", ".", "annToRLE", "(", "ann", ")", "\n", "ann", "[", "'segmentation'", "]", "=", "rle", "\n", "", "", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ",", "catIds", "=", "p", ".", "catIds", ")", ")", "\n", "", "else", ":", "\n", "            ", "gts", "=", "self", ".", "cocoGt", ".", "loadAnns", "(", "self", ".", "cocoGt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "dts", "=", "self", ".", "cocoDt", ".", "loadAnns", "(", "self", ".", "cocoDt", ".", "getAnnIds", "(", "imgIds", "=", "p", ".", "imgIds", ")", ")", "\n", "\n", "# convert ground truth to mask if iouType == 'segm'", "\n", "", "if", "p", ".", "iouType", "==", "'segm'", ":", "\n", "            ", "_toMask", "(", "gts", ",", "self", ".", "cocoGt", ")", "\n", "_toMask", "(", "dts", ",", "self", ".", "cocoDt", ")", "\n", "# set ignore flag", "\n", "", "for", "gt", "in", "gts", ":", "\n", "            ", "gt", "[", "'ignore'", "]", "=", "gt", "[", "'ignore'", "]", "if", "'ignore'", "in", "gt", "else", "0", "\n", "gt", "[", "'ignore'", "]", "=", "'iscrowd'", "in", "gt", "and", "gt", "[", "'iscrowd'", "]", "\n", "if", "p", ".", "iouType", "==", "'keypoints'", ":", "\n", "                ", "gt", "[", "'ignore'", "]", "=", "(", "gt", "[", "'num_keypoints'", "]", "==", "0", ")", "or", "gt", "[", "'ignore'", "]", "\n", "", "", "self", ".", "_gts", "=", "defaultdict", "(", "list", ")", "# gt for evaluation", "\n", "self", ".", "_dts", "=", "defaultdict", "(", "list", ")", "# dt for evaluation", "\n", "for", "gt", "in", "gts", ":", "\n", "            ", "self", ".", "_gts", "[", "gt", "[", "'image_id'", "]", ",", "gt", "[", "'category_id'", "]", "]", ".", "append", "(", "gt", ")", "\n", "", "for", "dt", "in", "dts", ":", "\n", "            ", "self", ".", "_dts", "[", "dt", "[", "'image_id'", "]", ",", "dt", "[", "'category_id'", "]", "]", ".", "append", "(", "dt", ")", "\n", "", "self", ".", "evalImgs", "=", "defaultdict", "(", "list", ")", "# per-image per-category evaluation results", "\n", "self", ".", "eval", "=", "{", "}", "# accumulated evaluation results", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.evaluate": [[122, 163], ["time.time", "print", "print", "list", "sorted", "cocoeval.COCOeval._prepare", "copy.deepcopy", "time.time", "print", "print", "numpy.unique", "list", "cocoeval.COCOeval.computeIoU"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval._prepare", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.computeIoU"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "'''\n        Run per image evaluation on given images and store results (a list of dict) in self.evalImgs\n        :return: None\n        '''", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Running per image evaluation...'", ")", "\n", "p", "=", "self", ".", "params", "\n", "# add backward compatibility if useSegm is specified in params", "\n", "if", "not", "p", ".", "useSegm", "is", "None", ":", "\n", "            ", "p", ".", "iouType", "=", "'segm'", "if", "p", ".", "useSegm", "==", "1", "else", "'bbox'", "\n", "print", "(", "'useSegm (deprecated) is not None. Running {} evaluation'", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "", "print", "(", "'Evaluate annotation type *{}*'", ".", "format", "(", "p", ".", "iouType", ")", ")", "\n", "p", ".", "imgIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "imgIds", ")", ")", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "p", ".", "catIds", "=", "list", "(", "np", ".", "unique", "(", "p", ".", "catIds", ")", ")", "\n", "", "p", ".", "maxDets", "=", "sorted", "(", "p", ".", "maxDets", ")", "\n", "self", ".", "params", "=", "p", "\n", "\n", "self", ".", "_prepare", "(", ")", "\n", "# loop through images, area range, max detection number", "\n", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "else", "[", "-", "1", "]", "\n", "\n", "if", "p", ".", "iouType", "==", "'segm'", "or", "p", ".", "iouType", "==", "'bbox'", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeIoU", "\n", "", "elif", "p", ".", "iouType", "==", "'keypoints'", ":", "\n", "            ", "computeIoU", "=", "self", ".", "computeOks", "\n", "", "self", ".", "ious", "=", "{", "(", "imgId", ",", "catId", ")", ":", "computeIoU", "(", "imgId", ",", "catId", ")", "for", "imgId", "in", "p", ".", "imgIds", "\n", "for", "catId", "in", "catIds", "}", "\n", "\n", "evaluateImg", "=", "self", ".", "evaluateImg", "\n", "maxDet", "=", "p", ".", "maxDets", "[", "-", "1", "]", "\n", "self", ".", "evalImgs", "=", "[", "evaluateImg", "(", "imgId", ",", "catId", ",", "areaRng", ",", "maxDet", ")", "\n", "for", "catId", "in", "catIds", "\n", "for", "areaRng", "in", "p", ".", "areaRng", "\n", "for", "imgId", "in", "p", ".", "imgIds", "\n", "]", "\n", "self", ".", "_paramsEval", "=", "copy", ".", "deepcopy", "(", "self", ".", "params", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'DONE (t={:0.2f}s).'", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.computeIoU": [[164, 192], ["numpy.argsort", "mask.iou", "len", "int", "len", "len", "Exception"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.iou"], ["", "def", "computeIoU", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dt", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dt", "=", "dt", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "\n", "", "if", "p", ".", "iouType", "==", "'segm'", ":", "\n", "            ", "g", "=", "[", "g", "[", "'segmentation'", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "'segmentation'", "]", "for", "d", "in", "dt", "]", "\n", "", "elif", "p", ".", "iouType", "==", "'bbox'", ":", "\n", "            ", "g", "=", "[", "g", "[", "'bbox'", "]", "for", "g", "in", "gt", "]", "\n", "d", "=", "[", "d", "[", "'bbox'", "]", "for", "d", "in", "dt", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'unknown iouType for iou computation'", ")", "\n", "\n", "# compute iou between each dt and gt region", "\n", "", "iscrowd", "=", "[", "int", "(", "o", "[", "'iscrowd'", "]", ")", "for", "o", "in", "gt", "]", "\n", "ious", "=", "maskUtils", ".", "iou", "(", "d", ",", "g", ",", "iscrowd", ")", "\n", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.computeOks": [[193, 235], ["numpy.argsort", "numpy.zeros", "len", "enumerate", "len", "numpy.array", "numpy.array", "numpy.count_nonzero", "enumerate", "len", "len", "len", "len", "numpy.array", "numpy.zeros", "numpy.sum", "numpy.max", "numpy.max", "numpy.max", "numpy.max", "numpy.exp", "numpy.spacing"], "methods", ["None"], ["", "def", "computeOks", "(", "self", ",", "imgId", ",", "catId", ")", ":", "\n", "        ", "p", "=", "self", ".", "params", "\n", "# dimention here should be Nxm", "\n", "gts", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dts", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "inds", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dts", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dts", "=", "[", "dts", "[", "i", "]", "for", "i", "in", "inds", "]", "\n", "if", "len", "(", "dts", ")", ">", "p", ".", "maxDets", "[", "-", "1", "]", ":", "\n", "            ", "dts", "=", "dts", "[", "0", ":", "p", ".", "maxDets", "[", "-", "1", "]", "]", "\n", "# if len(gts) == 0 and len(dts) == 0:", "\n", "", "if", "len", "(", "gts", ")", "==", "0", "or", "len", "(", "dts", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "dts", ")", ",", "len", "(", "gts", ")", ")", ")", "\n", "sigmas", "=", "np", ".", "array", "(", "[", ".26", ",", ".25", ",", ".25", ",", ".35", ",", ".35", ",", ".79", ",", ".79", ",", ".72", ",", ".72", ",", ".62", ",", ".62", ",", "1.07", ",", "1.07", ",", ".87", ",", ".87", ",", ".89", ",", ".89", "]", ")", "/", "10.0", "\n", "vars", "=", "(", "sigmas", "*", "2", ")", "**", "2", "\n", "k", "=", "len", "(", "sigmas", ")", "\n", "# compute oks between each detection and ground truth object", "\n", "for", "j", ",", "gt", "in", "enumerate", "(", "gts", ")", ":", "\n", "# create bounds for ignore regions(double the gt bbox)", "\n", "            ", "g", "=", "np", ".", "array", "(", "gt", "[", "'keypoints'", "]", ")", "\n", "xg", "=", "g", "[", "0", ":", ":", "3", "]", ";", "yg", "=", "g", "[", "1", ":", ":", "3", "]", ";", "vg", "=", "g", "[", "2", ":", ":", "3", "]", "\n", "k1", "=", "np", ".", "count_nonzero", "(", "vg", ">", "0", ")", "\n", "bb", "=", "gt", "[", "'bbox'", "]", "\n", "x0", "=", "bb", "[", "0", "]", "-", "bb", "[", "2", "]", ";", "x1", "=", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", "*", "2", "\n", "y0", "=", "bb", "[", "1", "]", "-", "bb", "[", "3", "]", ";", "y1", "=", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", "*", "2", "\n", "for", "i", ",", "dt", "in", "enumerate", "(", "dts", ")", ":", "\n", "                ", "d", "=", "np", ".", "array", "(", "dt", "[", "'keypoints'", "]", ")", "\n", "xd", "=", "d", "[", "0", ":", ":", "3", "]", ";", "yd", "=", "d", "[", "1", ":", ":", "3", "]", "\n", "if", "k1", ">", "0", ":", "\n", "# measure the per-keypoint distance if keypoints visible", "\n", "                    ", "dx", "=", "xd", "-", "xg", "\n", "dy", "=", "yd", "-", "yg", "\n", "", "else", ":", "\n", "# measure minimum distance to keypoints in (x0,y0) & (x1,y1)", "\n", "                    ", "z", "=", "np", ".", "zeros", "(", "(", "k", ")", ")", "\n", "dx", "=", "np", ".", "max", "(", "(", "z", ",", "x0", "-", "xd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "xd", "-", "x1", ")", ",", "axis", "=", "0", ")", "\n", "dy", "=", "np", ".", "max", "(", "(", "z", ",", "y0", "-", "yd", ")", ",", "axis", "=", "0", ")", "+", "np", ".", "max", "(", "(", "z", ",", "yd", "-", "y1", ")", ",", "axis", "=", "0", ")", "\n", "", "e", "=", "(", "dx", "**", "2", "+", "dy", "**", "2", ")", "/", "vars", "/", "(", "gt", "[", "'area'", "]", "+", "np", ".", "spacing", "(", "1", ")", ")", "/", "2", "\n", "if", "k1", ">", "0", ":", "\n", "                    ", "e", "=", "e", "[", "vg", ">", "0", "]", "\n", "", "ious", "[", "i", ",", "j", "]", "=", "np", ".", "sum", "(", "np", ".", "exp", "(", "-", "e", ")", ")", "/", "e", ".", "shape", "[", "0", "]", "\n", "", "", "return", "ious", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.evaluateImg": [[236, 314], ["numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.zeros", "numpy.array().reshape", "numpy.logical_or", "int", "enumerate", "numpy.logical_and", "len", "len", "len", "len", "enumerate", "numpy.array", "len", "numpy.repeat", "min", "enumerate"], "methods", ["None"], ["", "def", "evaluateImg", "(", "self", ",", "imgId", ",", "catId", ",", "aRng", ",", "maxDet", ")", ":", "\n", "        ", "'''\n        perform evaluation for single category and image\n        :return: dict (single image results)\n        '''", "\n", "p", "=", "self", ".", "params", "\n", "if", "p", ".", "useCats", ":", "\n", "            ", "gt", "=", "self", ".", "_gts", "[", "imgId", ",", "catId", "]", "\n", "dt", "=", "self", ".", "_dts", "[", "imgId", ",", "catId", "]", "\n", "", "else", ":", "\n", "            ", "gt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_gts", "[", "imgId", ",", "cId", "]", "]", "\n", "dt", "=", "[", "_", "for", "cId", "in", "p", ".", "catIds", "for", "_", "in", "self", ".", "_dts", "[", "imgId", ",", "cId", "]", "]", "\n", "", "if", "len", "(", "gt", ")", "==", "0", "and", "len", "(", "dt", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "for", "g", "in", "gt", ":", "\n", "            ", "if", "g", "[", "'ignore'", "]", "or", "(", "g", "[", "'area'", "]", "<", "aRng", "[", "0", "]", "or", "g", "[", "'area'", "]", ">", "aRng", "[", "1", "]", ")", ":", "\n", "                ", "g", "[", "'_ignore'", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "g", "[", "'_ignore'", "]", "=", "0", "\n", "\n", "# sort dt highest score first, sort gt ignore last", "\n", "", "", "gtind", "=", "np", ".", "argsort", "(", "[", "g", "[", "'_ignore'", "]", "for", "g", "in", "gt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "gt", "=", "[", "gt", "[", "i", "]", "for", "i", "in", "gtind", "]", "\n", "dtind", "=", "np", ".", "argsort", "(", "[", "-", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "kind", "=", "'mergesort'", ")", "\n", "dt", "=", "[", "dt", "[", "i", "]", "for", "i", "in", "dtind", "[", "0", ":", "maxDet", "]", "]", "\n", "iscrowd", "=", "[", "int", "(", "o", "[", "'iscrowd'", "]", ")", "for", "o", "in", "gt", "]", "\n", "# load computed ious", "\n", "ious", "=", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "[", ":", ",", "gtind", "]", "if", "len", "(", "self", ".", "ious", "[", "imgId", ",", "catId", "]", ")", ">", "0", "else", "self", ".", "ious", "[", "imgId", ",", "catId", "]", "\n", "\n", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "G", "=", "len", "(", "gt", ")", "\n", "D", "=", "len", "(", "dt", ")", "\n", "gtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "G", ")", ")", "\n", "dtm", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "gtIg", "=", "np", ".", "array", "(", "[", "g", "[", "'_ignore'", "]", "for", "g", "in", "gt", "]", ")", "\n", "dtIg", "=", "np", ".", "zeros", "(", "(", "T", ",", "D", ")", ")", "\n", "if", "not", "len", "(", "ious", ")", "==", "0", ":", "\n", "            ", "for", "tind", ",", "t", "in", "enumerate", "(", "p", ".", "iouThrs", ")", ":", "\n", "                ", "for", "dind", ",", "d", "in", "enumerate", "(", "dt", ")", ":", "\n", "# information about best match so far (m=-1 -> unmatched)", "\n", "                    ", "iou", "=", "min", "(", "[", "t", ",", "1", "-", "1e-10", "]", ")", "\n", "m", "=", "-", "1", "\n", "for", "gind", ",", "g", "in", "enumerate", "(", "gt", ")", ":", "\n", "# if this gt already matched, and not a crowd, continue", "\n", "                        ", "if", "gtm", "[", "tind", ",", "gind", "]", ">", "0", "and", "not", "iscrowd", "[", "gind", "]", ":", "\n", "                            ", "continue", "\n", "# if dt matched to reg gt, and on ignore gt, stop", "\n", "", "if", "m", ">", "-", "1", "and", "gtIg", "[", "m", "]", "==", "0", "and", "gtIg", "[", "gind", "]", "==", "1", ":", "\n", "                            ", "break", "\n", "# continue to next gt unless better match made", "\n", "", "if", "ious", "[", "dind", ",", "gind", "]", "<", "iou", ":", "\n", "                            ", "continue", "\n", "# if match successful and best so far, store appropriately", "\n", "", "iou", "=", "ious", "[", "dind", ",", "gind", "]", "\n", "m", "=", "gind", "\n", "# if match made store id of match for both dt and gt", "\n", "", "if", "m", "==", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "dtIg", "[", "tind", ",", "dind", "]", "=", "gtIg", "[", "m", "]", "\n", "dtm", "[", "tind", ",", "dind", "]", "=", "gt", "[", "m", "]", "[", "'id'", "]", "\n", "gtm", "[", "tind", ",", "m", "]", "=", "d", "[", "'id'", "]", "\n", "# set unmatched detections outside of area range to ignore", "\n", "", "", "", "a", "=", "np", ".", "array", "(", "[", "d", "[", "'area'", "]", "<", "aRng", "[", "0", "]", "or", "d", "[", "'area'", "]", ">", "aRng", "[", "1", "]", "for", "d", "in", "dt", "]", ")", ".", "reshape", "(", "(", "1", ",", "len", "(", "dt", ")", ")", ")", "\n", "dtIg", "=", "np", ".", "logical_or", "(", "dtIg", ",", "np", ".", "logical_and", "(", "dtm", "==", "0", ",", "np", ".", "repeat", "(", "a", ",", "T", ",", "0", ")", ")", ")", "\n", "# store results for given image and category", "\n", "return", "{", "\n", "'image_id'", ":", "imgId", ",", "\n", "'category_id'", ":", "catId", ",", "\n", "'aRng'", ":", "aRng", ",", "\n", "'maxDet'", ":", "maxDet", ",", "\n", "'dtIds'", ":", "[", "d", "[", "'id'", "]", "for", "d", "in", "dt", "]", ",", "\n", "'gtIds'", ":", "[", "g", "[", "'id'", "]", "for", "g", "in", "gt", "]", ",", "\n", "'dtMatches'", ":", "dtm", ",", "\n", "'gtMatches'", ":", "gtm", ",", "\n", "'dtScores'", ":", "[", "d", "[", "'score'", "]", "for", "d", "in", "dt", "]", ",", "\n", "'gtIgnore'", ":", "gtIg", ",", "\n", "'dtIgnore'", ":", "dtIg", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.accumulate": [[316, 422], ["print", "time.time", "len", "len", "len", "len", "set", "set", "set", "set", "len", "len", "enumerate", "time.time", "print", "print", "len", "numpy.ones", "numpy.ones", "numpy.ones", "map", "enumerate", "datetime.datetime.now().strftime", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "map", "numpy.concatenate", "numpy.argsort", "numpy.concatenate", "numpy.count_nonzero", "numpy.logical_and", "numpy.logical_and", "numpy.cumsum().astype", "numpy.cumsum().astype", "enumerate", "datetime.datetime.now", "len", "numpy.concatenate", "numpy.concatenate", "numpy.logical_not", "numpy.logical_not", "numpy.logical_not", "zip", "numpy.array", "numpy.array", "len", "numpy.zeros", "numpy.zeros", "pr.tolist.tolist.tolist", "q.tolist.tolist.tolist", "range", "numpy.searchsorted", "numpy.array", "numpy.array", "tuple", "numpy.cumsum", "numpy.cumsum", "enumerate", "numpy.spacing"], "methods", ["None"], ["", "def", "accumulate", "(", "self", ",", "p", "=", "None", ")", ":", "\n", "        ", "'''\n        Accumulate per image evaluation results and store the result in self.eval\n        :param p: input params for evaluation\n        :return: None\n        '''", "\n", "print", "(", "'Accumulating evaluation results...'", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "self", ".", "evalImgs", ":", "\n", "            ", "print", "(", "'Please run evaluate() first'", ")", "\n", "# allows input customized parameters", "\n", "", "if", "p", "is", "None", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "", "p", ".", "catIds", "=", "p", ".", "catIds", "if", "p", ".", "useCats", "==", "1", "else", "[", "-", "1", "]", "\n", "T", "=", "len", "(", "p", ".", "iouThrs", ")", "\n", "R", "=", "len", "(", "p", ".", "recThrs", ")", "\n", "K", "=", "len", "(", "p", ".", "catIds", ")", "if", "p", ".", "useCats", "else", "1", "\n", "A", "=", "len", "(", "p", ".", "areaRng", ")", "\n", "M", "=", "len", "(", "p", ".", "maxDets", ")", "\n", "precision", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "R", ",", "K", ",", "A", ",", "M", ")", ")", "# -1 for the precision of absent categories", "\n", "recall", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "K", ",", "A", ",", "M", ")", ")", "\n", "scores", "=", "-", "np", ".", "ones", "(", "(", "T", ",", "R", ",", "K", ",", "A", ",", "M", ")", ")", "\n", "\n", "# create dictionary for future indexing", "\n", "_pe", "=", "self", ".", "_paramsEval", "\n", "catIds", "=", "_pe", ".", "catIds", "if", "_pe", ".", "useCats", "else", "[", "-", "1", "]", "\n", "setK", "=", "set", "(", "catIds", ")", "\n", "setA", "=", "set", "(", "map", "(", "tuple", ",", "_pe", ".", "areaRng", ")", ")", "\n", "setM", "=", "set", "(", "_pe", ".", "maxDets", ")", "\n", "setI", "=", "set", "(", "_pe", ".", "imgIds", ")", "\n", "# get inds to evaluate", "\n", "k_list", "=", "[", "n", "for", "n", ",", "k", "in", "enumerate", "(", "p", ".", "catIds", ")", "if", "k", "in", "setK", "]", "\n", "m_list", "=", "[", "m", "for", "n", ",", "m", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "m", "in", "setM", "]", "\n", "a_list", "=", "[", "n", "for", "n", ",", "a", "in", "enumerate", "(", "map", "(", "lambda", "x", ":", "tuple", "(", "x", ")", ",", "p", ".", "areaRng", ")", ")", "if", "a", "in", "setA", "]", "\n", "i_list", "=", "[", "n", "for", "n", ",", "i", "in", "enumerate", "(", "p", ".", "imgIds", ")", "if", "i", "in", "setI", "]", "\n", "I0", "=", "len", "(", "_pe", ".", "imgIds", ")", "\n", "A0", "=", "len", "(", "_pe", ".", "areaRng", ")", "\n", "# retrieve E at each category, area range, and max number of detections", "\n", "for", "k", ",", "k0", "in", "enumerate", "(", "k_list", ")", ":", "\n", "            ", "Nk", "=", "k0", "*", "A0", "*", "I0", "\n", "for", "a", ",", "a0", "in", "enumerate", "(", "a_list", ")", ":", "\n", "                ", "Na", "=", "a0", "*", "I0", "\n", "for", "m", ",", "maxDet", "in", "enumerate", "(", "m_list", ")", ":", "\n", "                    ", "E", "=", "[", "self", ".", "evalImgs", "[", "Nk", "+", "Na", "+", "i", "]", "for", "i", "in", "i_list", "]", "\n", "E", "=", "[", "e", "for", "e", "in", "E", "if", "not", "e", "is", "None", "]", "\n", "if", "len", "(", "E", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "dtScores", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtScores'", "]", "[", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ")", "\n", "\n", "# different sorting method generates slightly different results.", "\n", "# mergesort is used to be consistent as Matlab implementation.", "\n", "inds", "=", "np", ".", "argsort", "(", "-", "dtScores", ",", "kind", "=", "'mergesort'", ")", "\n", "dtScoresSorted", "=", "dtScores", "[", "inds", "]", "\n", "\n", "dtm", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtMatches'", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "dtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'dtIgnore'", "]", "[", ":", ",", "0", ":", "maxDet", "]", "for", "e", "in", "E", "]", ",", "axis", "=", "1", ")", "[", ":", ",", "inds", "]", "\n", "gtIg", "=", "np", ".", "concatenate", "(", "[", "e", "[", "'gtIgnore'", "]", "for", "e", "in", "E", "]", ")", "\n", "npig", "=", "np", ".", "count_nonzero", "(", "gtIg", "==", "0", ")", "\n", "if", "npig", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "tps", "=", "np", ".", "logical_and", "(", "dtm", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "fps", "=", "np", ".", "logical_and", "(", "np", ".", "logical_not", "(", "dtm", ")", ",", "np", ".", "logical_not", "(", "dtIg", ")", ")", "\n", "\n", "tp_sum", "=", "np", ".", "cumsum", "(", "tps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "fp_sum", "=", "np", ".", "cumsum", "(", "fps", ",", "axis", "=", "1", ")", ".", "astype", "(", "dtype", "=", "np", ".", "float", ")", "\n", "for", "t", ",", "(", "tp", ",", "fp", ")", "in", "enumerate", "(", "zip", "(", "tp_sum", ",", "fp_sum", ")", ")", ":", "\n", "                        ", "tp", "=", "np", ".", "array", "(", "tp", ")", "\n", "fp", "=", "np", ".", "array", "(", "fp", ")", "\n", "nd", "=", "len", "(", "tp", ")", "\n", "rc", "=", "tp", "/", "npig", "\n", "pr", "=", "tp", "/", "(", "fp", "+", "tp", "+", "np", ".", "spacing", "(", "1", ")", ")", "\n", "q", "=", "np", ".", "zeros", "(", "(", "R", ",", ")", ")", "\n", "ss", "=", "np", ".", "zeros", "(", "(", "R", ",", ")", ")", "\n", "\n", "if", "nd", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "rc", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                            ", "recall", "[", "t", ",", "k", ",", "a", ",", "m", "]", "=", "0", "\n", "\n", "# numpy is slow without cython optimization for accessing elements", "\n", "# use python array gets significant speed improvement", "\n", "", "pr", "=", "pr", ".", "tolist", "(", ")", ";", "q", "=", "q", ".", "tolist", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "nd", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "                            ", "if", "pr", "[", "i", "]", ">", "pr", "[", "i", "-", "1", "]", ":", "\n", "                                ", "pr", "[", "i", "-", "1", "]", "=", "pr", "[", "i", "]", "\n", "\n", "", "", "inds", "=", "np", ".", "searchsorted", "(", "rc", ",", "p", ".", "recThrs", ",", "side", "=", "'left'", ")", "\n", "try", ":", "\n", "                            ", "for", "ri", ",", "pi", "in", "enumerate", "(", "inds", ")", ":", "\n", "                                ", "q", "[", "ri", "]", "=", "pr", "[", "pi", "]", "\n", "ss", "[", "ri", "]", "=", "dtScoresSorted", "[", "pi", "]", "\n", "", "", "except", ":", "\n", "                            ", "pass", "\n", "", "precision", "[", "t", ",", ":", ",", "k", ",", "a", ",", "m", "]", "=", "np", ".", "array", "(", "q", ")", "\n", "scores", "[", "t", ",", ":", ",", "k", ",", "a", ",", "m", "]", "=", "np", ".", "array", "(", "ss", ")", "\n", "", "", "", "", "self", ".", "eval", "=", "{", "\n", "'params'", ":", "p", ",", "\n", "'counts'", ":", "[", "T", ",", "R", ",", "K", ",", "A", ",", "M", "]", ",", "\n", "'date'", ":", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M:%S'", ")", ",", "\n", "'precision'", ":", "precision", ",", "\n", "'recall'", ":", "recall", ",", "\n", "'scores'", ":", "scores", ",", "\n", "}", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'DONE (t={:0.2f}s).'", ".", "format", "(", "toc", "-", "tic", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.summarize": [[423, 495], ["cocoeval.COCOeval.summarize"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.summarize"], ["", "def", "summarize", "(", "self", ")", ":", "\n", "        ", "'''\n        Compute and display summary metrics for evaluation results.\n        Note this functin can *only* be applied on the default parameter setting\n        '''", "\n", "def", "_summarize", "(", "ap", "=", "1", ",", "iouThr", "=", "None", ",", "areaRng", "=", "'all'", ",", "maxDets", "=", "100", ")", ":", "\n", "            ", "p", "=", "self", ".", "params", "\n", "iStr", "=", "' {:<18} {} @[ IoU={:<9} | area={:>6s} | maxDets={:>3d} ] = {:0.3f}'", "\n", "titleStr", "=", "'Average Precision'", "if", "ap", "==", "1", "else", "'Average Recall'", "\n", "typeStr", "=", "'(AP)'", "if", "ap", "==", "1", "else", "'(AR)'", "\n", "iouStr", "=", "'{:0.2f}:{:0.2f}'", ".", "format", "(", "p", ".", "iouThrs", "[", "0", "]", ",", "p", ".", "iouThrs", "[", "-", "1", "]", ")", "if", "iouThr", "is", "None", "else", "'{:0.2f}'", ".", "format", "(", "iouThr", ")", "\n", "\n", "aind", "=", "[", "i", "for", "i", ",", "aRng", "in", "enumerate", "(", "p", ".", "areaRngLbl", ")", "if", "aRng", "==", "areaRng", "]", "\n", "mind", "=", "[", "i", "for", "i", ",", "mDet", "in", "enumerate", "(", "p", ".", "maxDets", ")", "if", "mDet", "==", "maxDets", "]", "\n", "if", "ap", "==", "1", ":", "\n", "# dimension of precision: [TxRxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "'precision'", "]", "\n", "# IoU", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "else", ":", "\n", "# dimension of recall: [TxKxAxM]", "\n", "                ", "s", "=", "self", ".", "eval", "[", "'recall'", "]", "\n", "if", "iouThr", "is", "not", "None", ":", "\n", "                    ", "t", "=", "np", ".", "where", "(", "iouThr", "==", "p", ".", "iouThrs", ")", "[", "0", "]", "\n", "s", "=", "s", "[", "t", "]", "\n", "", "s", "=", "s", "[", ":", ",", ":", ",", "aind", ",", "mind", "]", "\n", "", "if", "len", "(", "s", "[", "s", ">", "-", "1", "]", ")", "==", "0", ":", "\n", "                ", "mean_s", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "mean_s", "=", "np", ".", "mean", "(", "s", "[", "s", ">", "-", "1", "]", ")", "\n", "", "print", "(", "iStr", ".", "format", "(", "titleStr", ",", "typeStr", ",", "iouStr", ",", "areaRng", ",", "maxDets", ",", "mean_s", ")", ")", "\n", "return", "mean_s", "\n", "", "def", "_summarizeDets", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "12", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", ".5", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "iouThr", "=", ".75", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'small'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'medium'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "1", ",", "areaRng", "=", "'large'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "0", "]", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "1", "]", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'small'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "10", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'medium'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "stats", "[", "11", "]", "=", "_summarize", "(", "0", ",", "areaRng", "=", "'large'", ",", "maxDets", "=", "self", ".", "params", ".", "maxDets", "[", "2", "]", ")", "\n", "return", "stats", "\n", "", "def", "_summarizeKps", "(", ")", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "(", "10", ",", ")", ")", "\n", "stats", "[", "0", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "1", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".5", ")", "\n", "stats", "[", "2", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".75", ")", "\n", "stats", "[", "3", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'medium'", ")", "\n", "stats", "[", "4", "]", "=", "_summarize", "(", "1", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'large'", ")", "\n", "stats", "[", "5", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ")", "\n", "stats", "[", "6", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".5", ")", "\n", "stats", "[", "7", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "iouThr", "=", ".75", ")", "\n", "stats", "[", "8", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'medium'", ")", "\n", "stats", "[", "9", "]", "=", "_summarize", "(", "0", ",", "maxDets", "=", "20", ",", "areaRng", "=", "'large'", ")", "\n", "return", "stats", "\n", "", "if", "not", "self", ".", "eval", ":", "\n", "            ", "raise", "Exception", "(", "'Please run accumulate() first'", ")", "\n", "", "iouType", "=", "self", ".", "params", ".", "iouType", "\n", "if", "iouType", "==", "'segm'", "or", "iouType", "==", "'bbox'", ":", "\n", "            ", "summarize", "=", "_summarizeDets", "\n", "", "elif", "iouType", "==", "'keypoints'", ":", "\n", "            ", "summarize", "=", "_summarizeKps", "\n", "", "self", ".", "stats", "=", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.__str__": [[496, 498], ["cocoeval.COCOeval.summarize"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.COCOeval.summarize"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "self", ".", "summarize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.Params.setDetParams": [[503, 513], ["numpy.linspace", "numpy.linspace", "numpy.round", "numpy.round"], "methods", ["None"], ["def", "setDetParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", ".5", ",", "0.95", ",", "np", ".", "round", "(", "(", "0.95", "-", ".5", ")", "/", ".05", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", ".0", ",", "1.00", ",", "np", ".", "round", "(", "(", "1.00", "-", ".0", ")", "/", ".01", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "1", ",", "10", ",", "100", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "'all'", ",", "'small'", ",", "'medium'", ",", "'large'", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.Params.setKpParams": [[514, 524], ["numpy.linspace", "numpy.linspace", "numpy.round", "numpy.round"], "methods", ["None"], ["", "def", "setKpParams", "(", "self", ")", ":", "\n", "        ", "self", ".", "imgIds", "=", "[", "]", "\n", "self", ".", "catIds", "=", "[", "]", "\n", "# np.arange causes trouble.  the data point on arange is slightly larger than the true value", "\n", "self", ".", "iouThrs", "=", "np", ".", "linspace", "(", ".5", ",", "0.95", ",", "np", ".", "round", "(", "(", "0.95", "-", ".5", ")", "/", ".05", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "recThrs", "=", "np", ".", "linspace", "(", ".0", ",", "1.00", ",", "np", ".", "round", "(", "(", "1.00", "-", ".0", ")", "/", ".01", ")", "+", "1", ",", "endpoint", "=", "True", ")", "\n", "self", ".", "maxDets", "=", "[", "20", "]", "\n", "self", ".", "areaRng", "=", "[", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", "]", "\n", "self", ".", "areaRngLbl", "=", "[", "'all'", ",", "'medium'", ",", "'large'", "]", "\n", "self", ".", "useCats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.Params.__init__": [[525, 535], ["cocoeval.Params.setDetParams", "cocoeval.Params.setKpParams", "Exception"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.Params.setDetParams", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.cocoeval.Params.setKpParams"], ["", "def", "__init__", "(", "self", ",", "iouType", "=", "'segm'", ")", ":", "\n", "        ", "if", "iouType", "==", "'segm'", "or", "iouType", "==", "'bbox'", ":", "\n", "            ", "self", ".", "setDetParams", "(", ")", "\n", "", "elif", "iouType", "==", "'keypoints'", ":", "\n", "            ", "self", ".", "setKpParams", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'iouType not supported'", ")", "\n", "", "self", ".", "iouType", "=", "iouType", "\n", "# useSegm is deprecated", "\n", "self", ".", "useSegm", "=", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.convert_kitti_to_tfrecords": [[73, 138], ["label_map_util.get_label_map_dict", "print", "os.path.join", "os.path.join", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "sorted", "int", "numpy.random.choice", "enumerate", "tf.python_io.TFRecordWriter.close", "tf.python_io.TFRecordWriter.close", "os.path.join", "os.path.join", "tensorflow.gfile.ListDirectory", "range", "int", "create_kitti_tf_record.read_annotation_file", "os.path.join", "create_kitti_tf_record.filter_annotations", "label_map_util.get_label_map_dict.keys", "len", "len", "os.path.join", "len", "create_kitti_tf_record.prepare_example", "img_name.split", "tf.python_io.TFRecordWriter.write", "tf.python_io.TFRecordWriter.write", "str().zfill", "prepare_example.SerializeToString", "prepare_example.SerializeToString", "str"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.get_label_map_dict", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.read_annotation_file", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.filter_annotations", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.prepare_example"], ["def", "convert_kitti_to_tfrecords", "(", "data_dir", ",", "output_path", ",", "classes_to_use", ",", "\n", "label_map_path", ",", "validation_set_size", ")", ":", "\n", "  ", "\"\"\"Convert the KITTI detection dataset to TFRecords.\n\n  Args:\n    data_dir: The full path to the unzipped folder containing the unzipped data\n      from data_object_image_2 and data_object_label_2.zip.\n      Folder structure is assumed to be: data_dir/training/label_2 (annotations)\n      and data_dir/data_object_image_2/training/image_2 (images).\n    output_path: The path to which TFRecord files will be written. The TFRecord\n      with the training set will be located at: <output_path>_train.tfrecord\n      And the TFRecord with the validation set will be located at:\n      <output_path>_val.tfrecord\n    classes_to_use: List of strings naming the classes for which data should be\n      converted. Use the same names as presented in the KIITI README file.\n      Adding dontcare class will remove all other bounding boxes that overlap\n      with areas marked as dontcare regions.\n    label_map_path: Path to label map proto\n    validation_set_size: How many images should be left as the validation set.\n      (Ffirst `validation_set_size` examples are selected to be in the\n      validation set).\n  \"\"\"", "\n", "_label_map_dict", "=", "label_map_util", ".", "get_label_map_dict", "(", "label_map_path", ")", "\n", "label_map_dict", "=", "{", "x", ":", "(", "_label_map_dict", "[", "x", "]", "-", "1", ")", "for", "x", "in", "_label_map_dict", ".", "keys", "(", ")", "}", "\n", "print", "(", "label_map_dict", ")", "\n", "train_count", "=", "0", "\n", "val_count", "=", "0", "\n", "\n", "annotation_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\n", "'training'", ",", "\n", "'label_2'", ")", "\n", "\n", "image_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\n", "'training'", ",", "\n", "'image_2'", ")", "\n", "\n", "train_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "'kitti_train.record'", ")", ")", "\n", "val_writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "os", ".", "path", ".", "join", "(", "output_path", ",", "'kitti_val.record'", ")", ")", "\n", "\n", "images", "=", "sorted", "(", "tf", ".", "gfile", ".", "ListDirectory", "(", "image_dir", ")", ")", "\n", "validation_set_size", "=", "int", "(", "len", "(", "images", ")", "/", "2", ")", "\n", "validation_images_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "len", "(", "images", ")", ")", ",", "size", "=", "validation_set_size", ",", "replace", "=", "False", ")", "\n", "for", "img_idx", ",", "img_name", "in", "enumerate", "(", "images", ")", ":", "\n", "    ", "img_num", "=", "int", "(", "img_name", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "is_validation_img", "=", "(", "img_idx", "in", "validation_images_idx", ")", "\n", "img_anno", "=", "read_annotation_file", "(", "os", ".", "path", ".", "join", "(", "annotation_dir", ",", "\n", "str", "(", "img_num", ")", ".", "zfill", "(", "6", ")", "+", "'.txt'", ")", ")", "\n", "\n", "image_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "img_name", ")", "\n", "\n", "# Filter all bounding boxes of this frame that are of a legal class, and", "\n", "# don't overlap with a dontcare region.", "\n", "# TODO(talremez) filter out targets that are truncated or heavily occluded.", "\n", "annotation_for_image", "=", "filter_annotations", "(", "img_anno", ",", "classes_to_use", ")", "\n", "if", "(", "len", "(", "annotation_for_image", "[", "'2d_bbox_left'", "]", ")", ">", "0", ")", ":", "\n", "      ", "example", "=", "prepare_example", "(", "image_path", ",", "annotation_for_image", ",", "label_map_dict", ")", "\n", "if", "is_validation_img", ":", "\n", "        ", "val_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "val_count", "+=", "1", "\n", "", "else", ":", "\n", "        ", "train_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "train_count", "+=", "1", "\n", "\n", "", "", "", "train_writer", ".", "close", "(", ")", "\n", "val_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.prepare_example": [[140, 208], ["io.BytesIO", "PIL.open", "numpy.asarray", "int", "int", "tensorflow.train.Example", "tensorflow.gfile.GFile", "fid.read", "float", "float", "float", "float", "tensorflow.train.Features", "dataset_util.int64_feature", "dataset_util.int64_feature", "dataset_util.bytes_feature", "dataset_util.bytes_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.int64_list_feature", "image_path.encode"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode"], ["", "def", "prepare_example", "(", "image_path", ",", "annotations", ",", "label_map_dict", ")", ":", "\n", "  ", "\"\"\"Converts a dictionary with annotations for an image to tf.Example proto.\n\n  Args:\n    image_path: The complete path to image.\n    annotations: A dictionary representing the annotation of a single object\n      that appears in the image.\n    label_map_dict: A map from string label names to integer ids.\n\n  Returns:\n    example: The converted tf.Example.\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "image_path", ",", "'rb'", ")", "as", "fid", ":", "\n", "    ", "encoded_png", "=", "fid", ".", "read", "(", ")", "\n", "", "encoded_png_io", "=", "io", ".", "BytesIO", "(", "encoded_png", ")", "\n", "image", "=", "pil", ".", "open", "(", "encoded_png_io", ")", "\n", "image", "=", "np", ".", "asarray", "(", "image", ")", "\n", "\n", "# key = hashlib.sha256(encoded_png).hexdigest()", "\n", "\n", "width", "=", "int", "(", "image", ".", "shape", "[", "1", "]", ")", "\n", "height", "=", "int", "(", "image", ".", "shape", "[", "0", "]", ")", "\n", "\n", "xmin_norm", "=", "(", "annotations", "[", "'2d_bbox_left'", "]", ")", "/", "float", "(", "width", ")", "\n", "ymin_norm", "=", "(", "annotations", "[", "'2d_bbox_top'", "]", ")", "/", "float", "(", "height", ")", "\n", "xmax_norm", "=", "(", "annotations", "[", "'2d_bbox_right'", "]", ")", "/", "float", "(", "width", ")", "\n", "ymax_norm", "=", "(", "annotations", "[", "'2d_bbox_bottom'", "]", ")", "/", "float", "(", "height", ")", "\n", "\n", "# difficult_obj = [0]*len(xmin_norm)", "\n", "\n", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/height'", ":", "dataset_util", ".", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "dataset_util", ".", "int64_feature", "(", "width", ")", ",", "\n", "'image/filename'", ":", "dataset_util", ".", "bytes_feature", "(", "image_path", ".", "encode", "(", "'utf8'", ")", ")", ",", "\n", "# 'image/source_id': dataset_util.bytes_feature(image_path.encode('utf8')),", "\n", "# 'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),", "\n", "'image/encoded'", ":", "dataset_util", ".", "bytes_feature", "(", "encoded_png", ")", ",", "\n", "# 'image/format': dataset_util.bytes_feature('png'.encode('utf8')),", "\n", "'image/object/bbox/xmin'", ":", "dataset_util", ".", "float_list_feature", "(", "xmin_norm", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "dataset_util", ".", "float_list_feature", "(", "xmax_norm", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "dataset_util", ".", "float_list_feature", "(", "ymin_norm", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "dataset_util", ".", "float_list_feature", "(", "ymax_norm", ")", ",", "\n", "# 'image/object/class/text': dataset_util.bytes_list_feature(", "\n", "#     [x.encode('utf8') for x in annotations['type']]),", "\n", "'image/object/class/label'", ":", "dataset_util", ".", "int64_list_feature", "(", "\n", "[", "label_map_dict", "[", "x", "]", "for", "x", "in", "annotations", "[", "'type'", "]", "]", ")", ",", "\n", "# 'image/object/difficult': dataset_util.int64_list_feature(difficult_obj),", "\n", "# 'image/object/truncated': dataset_util.float_list_feature(", "\n", "#     annotations['truncated']),", "\n", "# 'image/object/alpha': dataset_util.float_list_feature(", "\n", "#     annotations['alpha']),", "\n", "# 'image/object/3d_bbox/height': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_height']),", "\n", "# 'image/object/3d_bbox/width': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_width']),", "\n", "# 'image/object/3d_bbox/length': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_length']),", "\n", "# 'image/object/3d_bbox/x': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_x']),", "\n", "# 'image/object/3d_bbox/y': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_y']),", "\n", "# 'image/object/3d_bbox/z': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_z']),", "\n", "# 'image/object/3d_bbox/rot_y': dataset_util.float_list_feature(", "\n", "#     annotations['3d_bbox_rot_y']),", "\n", "}", ")", ")", "\n", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.filter_annotations": [[210, 262], ["img_all_annotations.keys", "numpy.stack", "utils.util.mass_iou", "enumerate", "img_all_annotations.keys", "enumerate", "numpy.amax", "numpy.logical_not"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.mass_iou"], ["", "def", "filter_annotations", "(", "img_all_annotations", ",", "used_classes", ")", ":", "\n", "  ", "\"\"\"Filters out annotations from the unused classes and dontcare regions.\n\n  Filters out the annotations that belong to classes we do now wish to use and\n  (optionally) also removes all boxes that overlap with dontcare regions.\n\n  Args:\n    img_all_annotations: A list of annotation dictionaries. See documentation of\n      read_annotation_file for more details about the format of the annotations.\n    used_classes: A list of strings listing the classes we want to keep, if the\n    list contains \"dontcare\", all bounding boxes with overlapping with dont\n    care regions will also be filtered out.\n\n  Returns:\n    img_filtered_annotations: A list of annotation dictionaries that have passed\n      the filtering.\n  \"\"\"", "\n", "\n", "img_filtered_annotations", "=", "{", "}", "\n", "\n", "# Filter the type of the objects.", "\n", "relevant_annotation_indices", "=", "[", "\n", "i", "for", "i", ",", "x", "in", "enumerate", "(", "img_all_annotations", "[", "'type'", "]", ")", "if", "x", "in", "used_classes", "\n", "]", "\n", "\n", "for", "key", "in", "img_all_annotations", ".", "keys", "(", ")", ":", "\n", "    ", "img_filtered_annotations", "[", "key", "]", "=", "(", "\n", "img_all_annotations", "[", "key", "]", "[", "relevant_annotation_indices", "]", ")", "\n", "\n", "", "if", "'dontcare'", "in", "used_classes", ":", "\n", "    ", "dont_care_indices", "=", "[", "i", "for", "i", ",", "\n", "x", "in", "enumerate", "(", "img_filtered_annotations", "[", "'type'", "]", ")", "\n", "if", "x", "==", "'dontcare'", "]", "\n", "\n", "# bounding box format [y_min, x_min, y_max, x_max]", "\n", "all_boxes", "=", "np", ".", "stack", "(", "[", "img_filtered_annotations", "[", "'2d_bbox_top'", "]", ",", "\n", "img_filtered_annotations", "[", "'2d_bbox_left'", "]", ",", "\n", "img_filtered_annotations", "[", "'2d_bbox_bottom'", "]", ",", "\n", "img_filtered_annotations", "[", "'2d_bbox_right'", "]", "]", ",", "\n", "axis", "=", "1", ")", "\n", "\n", "ious", "=", "iou", "(", "boxes1", "=", "all_boxes", ",", "\n", "boxes2", "=", "all_boxes", "[", "dont_care_indices", "]", ")", "\n", "\n", "# Remove all bounding boxes that overlap with a dontcare region.", "\n", "if", "ious", ".", "size", ">", "0", ":", "\n", "      ", "boxes_to_remove", "=", "np", ".", "amax", "(", "ious", ",", "axis", "=", "1", ")", ">", "0.0", "\n", "for", "key", "in", "img_all_annotations", ".", "keys", "(", ")", ":", "\n", "        ", "img_filtered_annotations", "[", "key", "]", "=", "(", "\n", "img_filtered_annotations", "[", "key", "]", "[", "np", ".", "logical_not", "(", "boxes_to_remove", ")", "]", ")", "\n", "\n", "", "", "", "return", "img_filtered_annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.read_annotation_file": [[264, 301], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "open", "f.readlines", "x.strip().split", "x[].lower", "float", "int", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "float", "x.strip"], "function", ["None"], ["", "def", "read_annotation_file", "(", "filename", ")", ":", "\n", "  ", "\"\"\"Reads a KITTI annotation file.\n\n  Converts a KITTI annotation file into a dictionary containing all the\n  relevant information.\n\n  Args:\n    filename: the path to the annotataion text file.\n\n  Returns:\n    anno: A dictionary with the converted annotation information. See annotation\n    README file for details on the different fields.\n  \"\"\"", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "    ", "content", "=", "f", ".", "readlines", "(", ")", "\n", "", "content", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "content", "]", "\n", "\n", "anno", "=", "{", "}", "\n", "anno", "[", "'type'", "]", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", ".", "lower", "(", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'truncated'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "1", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'occluded'", "]", "=", "np", ".", "array", "(", "[", "int", "(", "x", "[", "2", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'alpha'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "3", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "\n", "anno", "[", "'2d_bbox_left'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "4", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'2d_bbox_top'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "5", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'2d_bbox_right'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "6", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'2d_bbox_bottom'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "7", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "\n", "anno", "[", "'3d_bbox_height'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "8", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_width'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "9", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_length'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "10", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_x'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "11", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_y'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "12", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_z'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "13", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "anno", "[", "'3d_bbox_rot_y'", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", "[", "14", "]", ")", "for", "x", "in", "content", "]", ")", "\n", "\n", "return", "anno", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.main": [[303, 310], ["create_kitti_tf_record.convert_kitti_to_tfrecords", "FLAGS.classes_to_use.split"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_kitti_tf_record.convert_kitti_to_tfrecords"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "convert_kitti_to_tfrecords", "(", "\n", "data_dir", "=", "FLAGS", ".", "data_dir", ",", "\n", "output_path", "=", "FLAGS", ".", "output_path", ",", "\n", "classes_to_use", "=", "FLAGS", ".", "classes_to_use", ".", "split", "(", "','", ")", ",", "\n", "label_map_path", "=", "FLAGS", ".", "label_map_path", ",", "\n", "validation_set_size", "=", "FLAGS", ".", "validation_set_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_pascal_tf_record.dict_to_tf_example": [[59, 138], ["os.path.join", "os.path.join", "io.BytesIO", "PIL.Image.open", "hashlib.sha256().hexdigest", "int", "int", "tensorflow.train.Example", "tensorflow.gfile.GFile", "fid.read", "ValueError", "hashlib.sha256", "bool", "difficult_obj.append", "xmin.append", "ymin.append", "xmax.append", "ymax.append", "classes_text.append", "classes.append", "truncated.append", "poses.append", "tensorflow.train.Features", "int", "int", "obj[].encode", "int", "obj[].encode", "float", "float", "float", "float", "dataset_util.int64_feature", "dataset_util.int64_feature", "dataset_util.bytes_feature", "dataset_util.bytes_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.int64_list_feature", "data[].encode"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode"], ["def", "dict_to_tf_example", "(", "data", ",", "\n", "dataset_directory", ",", "\n", "label_map_dict", ",", "\n", "ignore_difficult_instances", "=", "False", ",", "\n", "image_subdirectory", "=", "'JPEGImages'", ")", ":", "\n", "  ", "\"\"\"Convert XML derived dict to tf.Example proto.\n\n  Notice that this function normalizes the bounding box coordinates provided\n  by the raw data.\n\n  Args:\n    data: dict holding PASCAL XML fields for a single image (obtained by\n      running dataset_util.recursive_parse_xml_to_dict)\n    dataset_directory: Path to root directory holding PASCAL dataset\n    label_map_dict: A map from string label names to integers ids.\n    ignore_difficult_instances: Whether to skip difficult instances in the\n      dataset  (default: False).\n    image_subdirectory: String specifying subdirectory within the\n      PASCAL dataset directory holding the actual image data.\n\n  Returns:\n    example: The converted tf.Example.\n\n  Raises:\n    ValueError: if the image pointed to by data['filename'] is not a valid JPEG\n  \"\"\"", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "data", "[", "'folder'", "]", ",", "image_subdirectory", ",", "data", "[", "'filename'", "]", ")", "\n", "full_path", "=", "os", ".", "path", ".", "join", "(", "dataset_directory", ",", "img_path", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "full_path", ",", "'rb'", ")", "as", "fid", ":", "\n", "    ", "encoded_jpg", "=", "fid", ".", "read", "(", ")", "\n", "", "encoded_jpg_io", "=", "io", ".", "BytesIO", "(", "encoded_jpg", ")", "\n", "image", "=", "PIL", ".", "Image", ".", "open", "(", "encoded_jpg_io", ")", "\n", "if", "image", ".", "format", "!=", "'JPEG'", ":", "\n", "    ", "raise", "ValueError", "(", "'Image format not JPEG'", ")", "\n", "", "key", "=", "hashlib", ".", "sha256", "(", "encoded_jpg", ")", ".", "hexdigest", "(", ")", "\n", "\n", "width", "=", "int", "(", "data", "[", "'size'", "]", "[", "'width'", "]", ")", "\n", "height", "=", "int", "(", "data", "[", "'size'", "]", "[", "'height'", "]", ")", "\n", "\n", "xmin", "=", "[", "]", "\n", "ymin", "=", "[", "]", "\n", "xmax", "=", "[", "]", "\n", "ymax", "=", "[", "]", "\n", "classes", "=", "[", "]", "\n", "classes_text", "=", "[", "]", "\n", "truncated", "=", "[", "]", "\n", "poses", "=", "[", "]", "\n", "difficult_obj", "=", "[", "]", "\n", "if", "'object'", "in", "data", ":", "\n", "    ", "for", "obj", "in", "data", "[", "'object'", "]", ":", "\n", "      ", "difficult", "=", "bool", "(", "int", "(", "obj", "[", "'difficult'", "]", ")", ")", "\n", "if", "ignore_difficult_instances", "and", "difficult", ":", "\n", "        ", "continue", "\n", "\n", "", "difficult_obj", ".", "append", "(", "int", "(", "difficult", ")", ")", "\n", "\n", "xmin", ".", "append", "(", "float", "(", "obj", "[", "'bndbox'", "]", "[", "'xmin'", "]", ")", "/", "width", ")", "\n", "ymin", ".", "append", "(", "float", "(", "obj", "[", "'bndbox'", "]", "[", "'ymin'", "]", ")", "/", "height", ")", "\n", "xmax", ".", "append", "(", "float", "(", "obj", "[", "'bndbox'", "]", "[", "'xmax'", "]", ")", "/", "width", ")", "\n", "ymax", ".", "append", "(", "float", "(", "obj", "[", "'bndbox'", "]", "[", "'ymax'", "]", ")", "/", "height", ")", "\n", "classes_text", ".", "append", "(", "obj", "[", "'name'", "]", ".", "encode", "(", "'utf8'", ")", ")", "\n", "classes", ".", "append", "(", "label_map_dict", "[", "obj", "[", "'name'", "]", "]", ")", "\n", "truncated", ".", "append", "(", "int", "(", "obj", "[", "'truncated'", "]", ")", ")", "\n", "poses", ".", "append", "(", "obj", "[", "'pose'", "]", ".", "encode", "(", "'utf8'", ")", ")", "\n", "\n", "", "", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/height'", ":", "dataset_util", ".", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "dataset_util", ".", "int64_feature", "(", "width", ")", ",", "\n", "'image/filename'", ":", "dataset_util", ".", "bytes_feature", "(", "\n", "data", "[", "'filename'", "]", ".", "encode", "(", "'utf8'", ")", ")", ",", "\n", "'image/encoded'", ":", "dataset_util", ".", "bytes_feature", "(", "encoded_jpg", ")", ",", "\n", "'image/object/bbox/xmin'", ":", "dataset_util", ".", "float_list_feature", "(", "xmin", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "dataset_util", ".", "float_list_feature", "(", "xmax", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "dataset_util", ".", "float_list_feature", "(", "ymin", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "dataset_util", ".", "float_list_feature", "(", "ymax", ")", ",", "\n", "# 'image/object/class/text': dataset_util.bytes_list_feature(classes_text),", "\n", "'image/object/class/label'", ":", "dataset_util", ".", "int64_list_feature", "(", "classes", ")", "\n", "}", ")", ")", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_pascal_tf_record.main": [[140, 175], ["tensorflow.python_io.TFRecordWriter", "label_map_util.get_label_map_dict", "tf.python_io.TFRecordWriter.close", "ValueError", "ValueError", "logging.info", "os.path.join", "os.path.join", "dataset_util.read_examples_list", "enumerate", "os.path.join", "lxml.etree.fromstring", "create_pascal_tf_record.dict_to_tf_example", "tf.python_io.TFRecordWriter.write", "logging.info", "tensorflow.gfile.GFile", "fid.read", "dataset_util.recursive_parse_xml_to_dict", "dict_to_tf_example.SerializeToString", "len"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.get_label_map_dict", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.info", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.read_examples_list", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_pascal_tf_record.dict_to_tf_example", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.info", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.recursive_parse_xml_to_dict"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "if", "FLAGS", ".", "set", "not", "in", "SETS", ":", "\n", "    ", "raise", "ValueError", "(", "'set must be in : {}'", ".", "format", "(", "SETS", ")", ")", "\n", "", "if", "FLAGS", ".", "year", "not", "in", "YEARS", ":", "\n", "    ", "raise", "ValueError", "(", "'year must be in : {}'", ".", "format", "(", "YEARS", ")", ")", "\n", "\n", "", "data_dir", "=", "FLAGS", ".", "data_dir", "\n", "years", "=", "[", "'VOC2007'", ",", "'VOC2012'", "]", "\n", "if", "FLAGS", ".", "year", "!=", "'merged'", ":", "\n", "    ", "years", "=", "[", "FLAGS", ".", "year", "]", "\n", "\n", "", "writer", "=", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "FLAGS", ".", "output_path", ")", "\n", "\n", "label_map_dict", "=", "label_map_util", ".", "get_label_map_dict", "(", "FLAGS", ".", "label_map_path", ")", "\n", "\n", "for", "year", "in", "years", ":", "\n", "    ", "logging", ".", "info", "(", "'Reading from PASCAL %s dataset.'", ",", "year", ")", "\n", "examples_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "year", ",", "'ImageSets'", ",", "'Main'", ",", "\n", "''", "+", "FLAGS", ".", "set", "+", "'.txt'", ")", "# aeroplane_", "\n", "annotations_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "year", ",", "FLAGS", ".", "annotations_dir", ")", "\n", "examples_list", "=", "dataset_util", ".", "read_examples_list", "(", "examples_path", ")", "\n", "for", "idx", ",", "example", "in", "enumerate", "(", "examples_list", ")", ":", "\n", "      ", "if", "idx", "%", "100", "==", "0", ":", "\n", "        ", "logging", ".", "info", "(", "'On image %d of %d'", ",", "idx", ",", "len", "(", "examples_list", ")", ")", "\n", "", "path", "=", "os", ".", "path", ".", "join", "(", "annotations_dir", ",", "example", "+", "'.xml'", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "path", ",", "'r'", ")", "as", "fid", ":", "\n", "        ", "xml_str", "=", "fid", ".", "read", "(", ")", "\n", "", "xml", "=", "etree", ".", "fromstring", "(", "xml_str", ")", "\n", "data", "=", "dataset_util", ".", "recursive_parse_xml_to_dict", "(", "xml", ")", "[", "'annotation'", "]", "\n", "\n", "tf_example", "=", "dict_to_tf_example", "(", "data", ",", "FLAGS", ".", "data_dir", ",", "label_map_dict", ",", "\n", "FLAGS", ".", "ignore_difficult_instances", ")", "\n", "writer", ".", "write", "(", "tf_example", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature": [[21, 23], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["def", "int64_feature", "(", "value", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_list_feature": [[25, 27], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["", "def", "int64_list_feature", "(", "value", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature": [[29, 31], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "bytes_feature", "(", "value", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_list_feature": [[33, 35], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "bytes_list_feature", "(", "value", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature": [[37, 39], ["tensorflow.train.Feature", "tensorflow.train.FloatList"], "function", ["None"], ["", "def", "float_list_feature", "(", "value", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Feature", "(", "float_list", "=", "tf", ".", "train", ".", "FloatList", "(", "value", "=", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.read_examples_list": [[41, 61], ["tensorflow.gfile.GFile", "fid.readlines", "line.strip().split", "line.strip"], "function", ["None"], ["", "def", "read_examples_list", "(", "path", ")", ":", "\n", "  ", "\"\"\"Read list of training or validation examples.\n\n  The file is assumed to contain a single example per line where the first\n  token in the line is an identifier that allows us to find the image and\n  annotation xml for that example.\n\n  For example, the line:\n  xyz 3\n  would allow us to find files xyz.jpg and xyz.xml (the 3 would be ignored).\n\n  Args:\n    path: absolute path to examples list file.\n\n  Returns:\n    list of example identifiers (strings).\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "path", ")", "as", "fid", ":", "\n", "    ", "lines", "=", "fid", ".", "readlines", "(", ")", "\n", "", "return", "[", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "line", "in", "lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.recursive_parse_xml_to_dict": [[63, 87], ["dataset_util.recursive_parse_xml_to_dict", "result[].append"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.recursive_parse_xml_to_dict"], ["", "def", "recursive_parse_xml_to_dict", "(", "xml", ")", ":", "\n", "  ", "\"\"\"Recursively parses XML contents to python dict.\n\n  We assume that `object` tags are the only ones that can appear\n  multiple times at the same level of a tree.\n\n  Args:\n    xml: xml tree obtained by parsing XML file contents using lxml.etree\n\n  Returns:\n    Python dictionary holding XML contents.\n  \"\"\"", "\n", "if", "not", "xml", ":", "\n", "    ", "return", "{", "xml", ".", "tag", ":", "xml", ".", "text", "}", "\n", "", "result", "=", "{", "}", "\n", "for", "child", "in", "xml", ":", "\n", "    ", "child_result", "=", "recursive_parse_xml_to_dict", "(", "child", ")", "\n", "if", "child", ".", "tag", "!=", "'object'", ":", "\n", "      ", "result", "[", "child", ".", "tag", "]", "=", "child_result", "[", "child", ".", "tag", "]", "\n", "", "else", ":", "\n", "      ", "if", "child", ".", "tag", "not", "in", "result", ":", "\n", "        ", "result", "[", "child", ".", "tag", "]", "=", "[", "]", "\n", "", "result", "[", "child", ".", "tag", "]", ".", "append", "(", "child_result", "[", "child", ".", "tag", "]", ")", "\n", "", "", "return", "{", "xml", ".", "tag", ":", "result", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.make_initializable_iterator": [[89, 104], ["dataset.make_initializable_iterator", "tensorflow.add_to_collection"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.make_initializable_iterator"], ["", "def", "make_initializable_iterator", "(", "dataset", ")", ":", "\n", "  ", "\"\"\"Creates an iterator, and initializes tables.\n\n  This is useful in cases where make_one_shot_iterator wouldn't work because\n  the graph contains a hash table that needs to be initialized.\n\n  Args:\n    dataset: A `tf.data.Dataset` object.\n\n  Returns:\n    A `tf.data.Iterator`.\n  \"\"\"", "\n", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "TABLE_INITIALIZERS", ",", "iterator", ".", "initializer", ")", "\n", "return", "iterator", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.read_dataset": [[106, 141], ["tensorflow.concat", "tensorflow.data.Dataset.from_tensor_slices", "filename_dataset.shuffle.repeat", "filename_dataset.shuffle.apply", "records_dataset.shuffle.map", "records_dataset.map.prefetch", "filename_dataset.shuffle.shuffle", "tensorflow.contrib.data.parallel_interleave", "records_dataset.shuffle.shuffle", "tensorflow.matching_files", "tensorflow.logging.warning"], "function", ["None"], ["", "def", "read_dataset", "(", "file_read_func", ",", "decode_func", ",", "input_files", ",", "config", ")", ":", "\n", "  ", "\"\"\"Reads a dataset, and handles repetition and shuffling.\n\n  Args:\n    file_read_func: Function to use in tf.data.Dataset.interleave, to read\n      every individual file into a tf.data.Dataset.\n    decode_func: Function to apply to all records.\n    input_files: A list of file paths to read.\n    config: A input_reader_builder.InputReader object.\n\n  Returns:\n    A tf.data.Dataset based on config.\n  \"\"\"", "\n", "# Shard, shuffle, and read files.", "\n", "filenames", "=", "tf", ".", "concat", "(", "[", "tf", ".", "matching_files", "(", "pattern", ")", "for", "pattern", "in", "input_files", "]", ",", "\n", "0", ")", "\n", "filename_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "filenames", ")", "\n", "if", "config", ".", "shuffle", ":", "\n", "    ", "filename_dataset", "=", "filename_dataset", ".", "shuffle", "(", "\n", "config", ".", "filenames_shuffle_buffer_size", ")", "\n", "", "elif", "config", ".", "num_readers", ">", "1", ":", "\n", "    ", "tf", ".", "logging", ".", "warning", "(", "'`shuffle` is false, but the input data stream is '", "\n", "'still slightly shuffled since `num_readers` > 1.'", ")", "\n", "\n", "", "filename_dataset", "=", "filename_dataset", ".", "repeat", "(", "config", ".", "num_epochs", "or", "None", ")", "\n", "\n", "records_dataset", "=", "filename_dataset", ".", "apply", "(", "\n", "tf", ".", "contrib", ".", "data", ".", "parallel_interleave", "(", "\n", "file_read_func", ",", "cycle_length", "=", "config", ".", "num_readers", ",", "\n", "block_length", "=", "config", ".", "read_block_length", ",", "sloppy", "=", "config", ".", "shuffle", ")", ")", "\n", "if", "config", ".", "shuffle", ":", "\n", "    ", "records_dataset", "=", "records_dataset", ".", "shuffle", "(", "config", ".", "shuffle_buffer_size", ")", "\n", "", "tensor_dataset", "=", "records_dataset", ".", "map", "(", "\n", "decode_func", ",", "num_parallel_calls", "=", "config", ".", "num_parallel_map_calls", ")", "\n", "return", "tensor_dataset", ".", "prefetch", "(", "config", ".", "prefetch_size", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util._validate_label_map": [[25, 40], ["ValueError", "ValueError"], "function", ["None"], ["def", "_validate_label_map", "(", "label_map", ")", ":", "\n", "  ", "\"\"\"Checks if a label map is valid.\n\n  Args:\n    label_map: StringIntLabelMap to validate.\n\n  Raises:\n    ValueError: if label map is invalid.\n  \"\"\"", "\n", "for", "item", "in", "label_map", ".", "item", ":", "\n", "    ", "if", "item", ".", "id", "<", "0", ":", "\n", "      ", "raise", "ValueError", "(", "'Label map ids should be >= 0.'", ")", "\n", "", "if", "(", "item", ".", "id", "==", "0", "and", "item", ".", "name", "!=", "'background'", "and", "\n", "item", ".", "display_name", "!=", "'background'", ")", ":", "\n", "      ", "raise", "ValueError", "(", "'Label map id 0 is reserved for the background label'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.create_category_index": [[42, 59], ["None"], "function", ["None"], ["", "", "", "def", "create_category_index", "(", "categories", ")", ":", "\n", "  ", "\"\"\"Creates dictionary of COCO compatible categories keyed by category id.\n\n  Args:\n    categories: a list of dicts, each of which has the following keys:\n      'id': (required) an integer id uniquely identifying this category.\n      'name': (required) string representing category name\n        e.g., 'cat', 'dog', 'pizza'.\n\n  Returns:\n    category_index: a dict containing the same entries as categories, but keyed\n      by the 'id' field of each category.\n  \"\"\"", "\n", "category_index", "=", "{", "}", "\n", "for", "cat", "in", "categories", ":", "\n", "    ", "category_index", "[", "cat", "[", "'id'", "]", "]", "=", "cat", "\n", "", "return", "category_index", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.get_max_label_map_index": [[61, 71], ["max"], "function", ["None"], ["", "def", "get_max_label_map_index", "(", "label_map", ")", ":", "\n", "  ", "\"\"\"Get maximum index in label map.\n\n  Args:\n    label_map: a StringIntLabelMapProto\n\n  Returns:\n    an integer\n  \"\"\"", "\n", "return", "max", "(", "[", "item", ".", "id", "for", "item", "in", "label_map", ".", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.convert_label_map_to_categories": [[73, 121], ["range", "categories.append", "logging.info", "item.HasField", "list_of_ids_already_added.append", "categories.append"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.info"], ["", "def", "convert_label_map_to_categories", "(", "label_map", ",", "\n", "max_num_classes", ",", "\n", "use_display_name", "=", "True", ")", ":", "\n", "  ", "\"\"\"Loads label map proto and returns categories list compatible with eval.\n\n  This function loads a label map and returns a list of dicts, each of which\n  has the following keys:\n    'id': (required) an integer id uniquely identifying this category.\n    'name': (required) string representing category name\n      e.g., 'cat', 'dog', 'pizza'.\n  We only allow class into the list if its id-label_id_offset is\n  between 0 (inclusive) and max_num_classes (exclusive).\n  If there are several items mapping to the same id in the label map,\n  we will only keep the first one in the categories list.\n\n  Args:\n    label_map: a StringIntLabelMapProto or None.  If None, a default categories\n      list is created with max_num_classes categories.\n    max_num_classes: maximum number of (consecutive) label indices to include.\n    use_display_name: (boolean) choose whether to load 'display_name' field\n      as category name.  If False or if the display_name field does not exist,\n      uses 'name' field as category names instead.\n  Returns:\n    categories: a list of dictionaries representing all possible categories.\n  \"\"\"", "\n", "categories", "=", "[", "]", "\n", "list_of_ids_already_added", "=", "[", "]", "\n", "if", "not", "label_map", ":", "\n", "    ", "label_id_offset", "=", "1", "\n", "for", "class_id", "in", "range", "(", "max_num_classes", ")", ":", "\n", "      ", "categories", ".", "append", "(", "{", "\n", "'id'", ":", "class_id", "+", "label_id_offset", ",", "\n", "'name'", ":", "'category_{}'", ".", "format", "(", "class_id", "+", "label_id_offset", ")", "\n", "}", ")", "\n", "", "return", "categories", "\n", "", "for", "item", "in", "label_map", ".", "item", ":", "\n", "    ", "if", "not", "0", "<", "item", ".", "id", "<=", "max_num_classes", ":", "\n", "      ", "logging", ".", "info", "(", "'Ignore item %d since it falls outside of requested '", "\n", "'label range.'", ",", "item", ".", "id", ")", "\n", "continue", "\n", "", "if", "use_display_name", "and", "item", ".", "HasField", "(", "'display_name'", ")", ":", "\n", "      ", "name", "=", "item", ".", "display_name", "\n", "", "else", ":", "\n", "      ", "name", "=", "item", ".", "name", "\n", "", "if", "item", ".", "id", "not", "in", "list_of_ids_already_added", ":", "\n", "      ", "list_of_ids_already_added", ".", "append", "(", "item", ".", "id", ")", "\n", "categories", ".", "append", "(", "{", "'id'", ":", "item", ".", "id", ",", "'name'", ":", "name", "}", ")", "\n", "", "", "return", "categories", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.load_labelmap": [[123, 140], ["label_map_util._validate_label_map", "tensorflow.gfile.GFile", "fid.read", "string_int_label_map_pb2.StringIntLabelMap", "google.protobuf.text_format.Merge", "string_int_label_map_pb2.StringIntLabelMap.ParseFromString"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util._validate_label_map"], ["", "def", "load_labelmap", "(", "path", ")", ":", "\n", "  ", "\"\"\"Loads label map proto.\n\n  Args:\n    path: path to StringIntLabelMap proto text file.\n  Returns:\n    a StringIntLabelMapProto\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "path", ",", "'r'", ")", "as", "fid", ":", "\n", "    ", "label_map_string", "=", "fid", ".", "read", "(", ")", "\n", "label_map", "=", "string_int_label_map_pb2", ".", "StringIntLabelMap", "(", ")", "\n", "try", ":", "\n", "      ", "text_format", ".", "Merge", "(", "label_map_string", ",", "label_map", ")", "\n", "", "except", "text_format", ".", "ParseError", ":", "\n", "      ", "label_map", ".", "ParseFromString", "(", "label_map_string", ")", "\n", "", "", "_validate_label_map", "(", "label_map", ")", "\n", "return", "label_map", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.get_label_map_dict": [[142, 160], ["label_map_util.load_labelmap"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.load_labelmap"], ["", "def", "get_label_map_dict", "(", "label_map_path", ",", "use_display_name", "=", "False", ")", ":", "\n", "  ", "\"\"\"Reads a label map and returns a dictionary of label names to id.\n\n  Args:\n    label_map_path: path to label_map.\n    use_display_name: whether to use the label map items' display names as keys.\n\n  Returns:\n    A dictionary mapping label names to id.\n  \"\"\"", "\n", "label_map", "=", "load_labelmap", "(", "label_map_path", ")", "\n", "label_map_dict", "=", "{", "}", "\n", "for", "item", "in", "label_map", ".", "item", ":", "\n", "    ", "if", "use_display_name", ":", "\n", "      ", "label_map_dict", "[", "item", ".", "display_name", "]", "=", "item", ".", "id", "\n", "", "else", ":", "\n", "      ", "label_map_dict", "[", "item", ".", "name", "]", "=", "item", ".", "id", "\n", "", "", "return", "label_map_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.create_category_index_from_labelmap": [[162, 177], ["label_map_util.load_labelmap", "max", "label_map_util.convert_label_map_to_categories", "label_map_util.create_category_index"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.load_labelmap", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.convert_label_map_to_categories", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.create_category_index"], ["", "def", "create_category_index_from_labelmap", "(", "label_map_path", ")", ":", "\n", "  ", "\"\"\"Reads a label map and returns a category index.\n\n  Args:\n    label_map_path: Path to `StringIntLabelMap` proto text file.\n\n  Returns:\n    A category index, which is a dictionary that maps integer ids to dicts\n    containing categories, e.g.\n    {1: {'id': 1, 'name': 'dog'}, 2: {'id': 2, 'name': 'cat'}, ...}\n  \"\"\"", "\n", "label_map", "=", "load_labelmap", "(", "label_map_path", ")", "\n", "max_num_classes", "=", "max", "(", "item", ".", "id", "for", "item", "in", "label_map", ".", "item", ")", "\n", "categories", "=", "convert_label_map_to_categories", "(", "label_map", ",", "max_num_classes", ")", "\n", "return", "create_category_index", "(", "categories", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.label_map_util.create_class_agnostic_category_index": [[179, 182], ["None"], "function", ["None"], ["", "def", "create_class_agnostic_category_index", "(", ")", ":", "\n", "  ", "\"\"\"Creates a category index with a single `object` class.\"\"\"", "\n", "return", "{", "1", ":", "{", "'id'", ":", "1", ",", "'name'", ":", "'object'", "}", "}", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_coco_tf_record.create_coco_detection_dataset": [[47, 97], ["pycocotools.coco.COCO", "pycocotools.coco.COCO.getImgIds", "pycocotools.coco.COCO.getCatIds", "len", "random.shuffle", "tensorflow.python_io.TFRecordWriter", "enumerate", "pycocotools.coco.COCO.getAnnIds", "pycocotools.coco.COCO.loadAnns", "os.path.join", "os.path.join", "tensorflow.gfile.FastGFile().read", "os.path.join.encode", "create_coco_tf_record.dict_to_coco_example", "tfrecord_writer.write", "print", "pycocotools.coco.COCO.loadImgs", "bboxes.append", "labels.append", "dict_to_coco_example.SerializeToString", "tensorflow.gfile.FastGFile", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getImgIds", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getCatIds", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.getAnnIds", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadAnns", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.mask.encode", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_coco_tf_record.dict_to_coco_example", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.pycocotools.coco.COCO.loadImgs"], ["def", "create_coco_detection_dataset", "(", "imgs_dir", ",", "annotations_filepath", ",", "shuffle_img", "=", "True", ")", ":", "\n", "    ", "\"\"\"Load data from dataset by pycocotools. This tools can be download from \"http://mscoco.org/dataset/#download\"\n    Args:\n        imgs_dir: directories of coco images\n        annotations_filepath: file path of coco annotations file\n        shuffle_img: wheter to shuffle images order\n    \"\"\"", "\n", "coco", "=", "COCO", "(", "annotations_filepath", ")", "\n", "img_ids", "=", "coco", ".", "getImgIds", "(", ")", "# totally 82783 images", "\n", "cat_ids", "=", "coco", ".", "getCatIds", "(", ")", "# totally 90 catagories, however, the number of categories is not continuous, \\", "\n", "# [0,12,26,29,30,45,66,68,69,71,83] are missing, this is the problem of coco dataset.", "\n", "\n", "if", "shuffle_img", ":", "\n", "        ", "shuffle", "(", "img_ids", ")", "\n", "\n", "", "nb_imgs", "=", "len", "(", "img_ids", ")", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "FLAGS", ".", "output_filepath", ")", "as", "tfrecord_writer", ":", "\n", "        ", "for", "index", ",", "img_id", "in", "enumerate", "(", "img_ids", ")", ":", "\n", "            ", "if", "index", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "\"Reading/Writing images: %d / %d \"", "%", "(", "index", ",", "nb_imgs", ")", ")", "\n", "", "img_info", "=", "{", "}", "\n", "bboxes", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "img_detail", "=", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "\n", "pic_height", "=", "img_detail", "[", "'height'", "]", "\n", "pic_width", "=", "img_detail", "[", "'width'", "]", "\n", "\n", "ann_ids", "=", "coco", ".", "getAnnIds", "(", "imgIds", "=", "img_id", ",", "catIds", "=", "cat_ids", ")", "\n", "anns", "=", "coco", ".", "loadAnns", "(", "ann_ids", ")", "\n", "for", "ann", "in", "anns", ":", "\n", "                ", "bboxes_data", "=", "ann", "[", "'bbox'", "]", "\n", "bboxes_data", "=", "[", "bboxes_data", "[", "0", "]", "/", "float", "(", "pic_width", ")", ",", "bboxes_data", "[", "1", "]", "/", "float", "(", "pic_height", ")", ",", "bboxes_data", "[", "2", "]", "/", "float", "(", "pic_width", ")", ",", "bboxes_data", "[", "3", "]", "/", "float", "(", "pic_height", ")", "]", "\n", "# the format of coco bounding boxs is [Xmin, Ymin, width, height]", "\n", "bboxes", ".", "append", "(", "bboxes_data", ")", "\n", "labels", ".", "append", "(", "ann", "[", "'category_id'", "]", ")", "\n", "\n", "", "img_path", "=", "os", ".", "path", ".", "join", "(", "imgs_dir", ",", "img_detail", "[", "'file_name'", "]", ")", "\n", "img_bytes", "=", "tf", ".", "gfile", ".", "FastGFile", "(", "img_path", ",", "'rb'", ")", ".", "read", "(", ")", "\n", "\n", "img_info", "[", "'pixel_data'", "]", "=", "img_bytes", "\n", "img_info", "[", "'height'", "]", "=", "pic_height", "\n", "img_info", "[", "'width'", "]", "=", "pic_width", "\n", "img_info", "[", "'bboxes'", "]", "=", "bboxes", "\n", "img_info", "[", "'labels'", "]", "=", "labels", "\n", "img_info", "[", "'filename'", "]", "=", "img_path", ".", "encode", "(", "'utf8'", ")", "\n", "# write img_info to tf record", "\n", "example", "=", "dict_to_coco_example", "(", "img_info", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_coco_tf_record.dict_to_coco_example": [[99, 127], ["tensorflow.train.Example", "xmin.append", "xmax.append", "ymin.append", "ymax.append", "tensorflow.train.Features", "dataset_util.int64_feature", "dataset_util.int64_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.float_list_feature", "dataset_util.int64_list_feature", "dataset_util.bytes_feature", "dataset_util.bytes_feature"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.float_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.int64_list_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.dataset_util.bytes_feature"], ["", "", "", "def", "dict_to_coco_example", "(", "img_data", ")", ":", "\n", "    ", "\"\"\"Convert python dictionary formath data of one image to tf.Example proto.\n    Args:\n        img_data: infomation of one image, inclue bounding box, labels of bounding box,\\\n            height, width, encoded pixel data.\n    Returns:\n        example: The converted tf.Example\n    \"\"\"", "\n", "bboxes", "=", "img_data", "[", "'bboxes'", "]", "\n", "xmin", ",", "xmax", ",", "ymin", ",", "ymax", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "bbox", "in", "bboxes", ":", "\n", "        ", "xmin", ".", "append", "(", "bbox", "[", "0", "]", ")", "\n", "xmax", ".", "append", "(", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ")", "\n", "ymin", ".", "append", "(", "bbox", "[", "1", "]", ")", "\n", "ymax", ".", "append", "(", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ")", "\n", "\n", "", "example", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/height'", ":", "dataset_util", ".", "int64_feature", "(", "img_data", "[", "'height'", "]", ")", ",", "\n", "'image/width'", ":", "dataset_util", ".", "int64_feature", "(", "img_data", "[", "'width'", "]", ")", ",", "\n", "'image/object/bbox/xmin'", ":", "dataset_util", ".", "float_list_feature", "(", "xmin", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "dataset_util", ".", "float_list_feature", "(", "xmax", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "dataset_util", ".", "float_list_feature", "(", "ymin", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "dataset_util", ".", "float_list_feature", "(", "ymax", ")", ",", "\n", "'image/object/class/label'", ":", "dataset_util", ".", "int64_list_feature", "(", "img_data", "[", "'labels'", "]", ")", ",", "\n", "'image/encoded'", ":", "dataset_util", ".", "bytes_feature", "(", "img_data", "[", "'pixel_data'", "]", ")", ",", "\n", "'image/filename'", ":", "dataset_util", ".", "bytes_feature", "(", "img_data", "[", "'filename'", "]", ")", "\n", "}", ")", ")", "\n", "return", "example", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_coco_tf_record.main": [[128, 141], ["create_coco_tf_record.create_coco_detection_dataset", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "ValueError"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.creation.create_coco_tf_record.create_coco_detection_dataset"], ["", "def", "main", "(", "_", ")", ":", "\n", "    ", "if", "FLAGS", ".", "set", "==", "\"train\"", ":", "\n", "        ", "imgs_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'train'", ")", "\n", "annotations_filepath", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'annotations'", ",", "'instances_train2017.json'", ")", "\n", "print", "(", "\"Convert coco train file to tf record\"", ")", "\n", "", "elif", "FLAGS", ".", "set", "==", "\"val\"", ":", "\n", "        ", "imgs_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'val'", ")", "\n", "annotations_filepath", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "data_dir", ",", "'annotations'", ",", "'instances_val2017.json'", ")", "\n", "print", "(", "\"Convert coco val file to tf record\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"you must either convert train data or val data\"", ")", "\n", "# load total coco data", "\n", "", "create_coco_detection_dataset", "(", "imgs_dir", ",", "annotations_filepath", ",", "shuffle_img", "=", "FLAGS", ".", "shuffle_imgs", ")", "\n", "# total_imgs = len(coco_data)", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.random_agent.random_search": [[5, 26], ["numpy.any", "Xi.append", "constant_configs.keys", "fx.append", "numpy.random.randint", "var_ranges.keys", "func", "numpy.min", "numpy.all", "x.keys", "numpy.argmin", "numpy.iinfo", "numpy.iinfo", "xi.values", "Xnew.values"], "function", ["None"], ["def", "random_search", "(", "func", ",", "var_ranges", ",", "constant_configs", "=", "{", "}", ",", "var_ranges_dtype", "=", "np", ".", "int16", ")", ":", "\n", "  ", "\"\"\"\n  Args:\n    func: function to find maxima\n  \"\"\"", "\n", "Xi", "=", "[", "]", "\n", "fx", "=", "[", "]", "\n", "while", "True", ":", "\n", "    ", "Xnew", "=", "{", "var_name", ":", "var_ranges", "[", "var_name", "]", "(", "np", ".", "random", ".", "randint", "(", "low", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "min", ",", "high", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "max", ",", "dtype", "=", "var_ranges_dtype", ")", ")", "\n", "for", "var_name", "in", "var_ranges", ".", "keys", "(", ")", "}", "\n", "if", "not", "np", ".", "any", "(", "[", "np", ".", "all", "(", "xi", ".", "values", "(", ")", "==", "Xnew", ".", "values", "(", ")", ")", "for", "xi", "in", "Xi", "]", ")", ":", "\n", "      ", "Xi", ".", "append", "(", "Xnew", ")", "\n", "x", "=", "Xnew", "\n", "for", "s", "in", "constant_configs", ".", "keys", "(", ")", ":", "\n", "        ", "if", "s", "not", "in", "x", ".", "keys", "(", ")", ":", "\n", "          ", "x", "[", "s", "]", "=", "constant_configs", "[", "s", "]", "\n", "", "", "fx", ".", "append", "(", "func", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "      ", "continue", "\n", "", "yield", "(", "Xi", "[", "np", ".", "argmin", "(", "fx", ")", "]", ",", "np", ".", "min", "(", "fx", ")", ")", "\n", "", "return", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.np_array": [[16, 20], ["numpy.array"], "function", ["None"], ["def", "np_array", "(", "*", "args", ")", ":", "\n", "  ", "\"\"\" np.array wrapper\n  \"\"\"", "\n", "return", "np", ".", "array", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.parse_mc_option": [[29, 54], ["type", "type", "easydict.EasyDict", "mc_option[].split", "float", "print", "str_args[].split"], "function", ["None"], ["def", "parse_mc_option", "(", "mc_option", ",", "hfuncs", ")", ":", "\n", "  ", "\"\"\" parses a string of model config hyperparameter value\n      into an array.\n      Returns:\n        1) list of values as the user requested\n        2) if the list accepts integer values only\n  \"\"\"", "\n", "if", "type", "(", "mc_option", ")", "==", "type", "(", "edict", "(", ")", ")", ":", "\n", "    ", "if", "\"HVALUE\"", "in", "mc_option", ":", "\n", "      ", "str_func", ",", "str_args", "=", "mc_option", "[", "\"HVALUE\"", "]", ".", "split", "(", "\"(\"", ")", "\n", "args", "=", "[", "float", "(", "str_arg", ")", "for", "str_arg", "in", "str_args", "[", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "if", "str_func", "in", "hfuncs", ":", "\n", "        ", "val_list", "=", "hfuncs", "[", "str_func", "]", "(", "*", "args", ")", "\n", "if", "\"IS_INTEGER\"", "in", "mc_option", ":", "\n", "          ", "return", "val_list", ",", "mc_option", "[", "\"IS_INTEGER\"", "]", "\n", "", "else", ":", "\n", "          ", "return", "val_list", ",", "False", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"ERROR NO SUCH HFUNC\"", ")", "\n", "return", "None", "\n", "", "", "else", ":", "\n", "        ", "return", "mc_option", ",", "None", "\n", "", "", "else", ":", "\n", "    ", "return", "mc_option", ",", "None", "\n", "", "return", "mc_option", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.parse_mc": [[55, 75], ["mc.keys", "easydict.EasyDict", "hyperparam_tuner.parse_mc_option", "mc.copy", "hopt_vars.append"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.parse_mc_option"], ["", "def", "parse_mc", "(", "mc", ")", ":", "\n", "  ", "\"\"\"\n    Parses all mc to find hopt vars to hyperoptimize and to edit\n    in every hyperoptimization iteration.\n    Args:\n      mc: model configuration\n    Returns:\n      mc: new model_configuration\n      hopt_vars: array of triples (mc key, array of possible values of mc[key], is_integer)\n  \"\"\"", "\n", "hopt_vars", "=", "[", "]", "\n", "for", "x", "in", "mc", ".", "keys", "(", ")", ":", "\n", "    ", "val_ar", ",", "r", "=", "parse_mc_option", "(", "mc", "[", "x", "]", ",", "hfuncs", ")", "\n", "if", "r", "!=", "None", ":", "\n", "      ", "hopt_vars", ".", "append", "(", "(", "x", ",", "val_ar", ",", "r", ")", ")", "\n", "", "else", ":", "\n", "      ", "mc", "[", "x", "]", "=", "val_ar", "\n", "", "", "new_mc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "\n", "return", "new_mc", ",", "hopt_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.create_mc_from_hopt_vars": [[76, 96], ["easydict.EasyDict", "zip", "easydict.EasyDict", "mc.copy", "int"], "function", ["None"], ["", "def", "create_mc_from_hopt_vars", "(", "mc", ",", "hopt_vars_vals", ",", "hopt_vars_keys", ",", "is_integer", ")", ":", "\n", "  ", "\"\"\"\n  Args:\n    mc: basic model configuration\n    hopt_vars_vals: Array of hyperoptimization values proposal\n    hopt_vars_keys: keys of the returning model config\n    is_integer: Array indicating if corresponding variable in hopt_vars_vals is integer\n  Returns:\n    rmc: a proper dictionary for model configuration   \n  \"\"\"", "\n", "rmc", "=", "edict", "(", "mc", ".", "copy", "(", ")", ")", "\n", "i", "=", "0", "\n", "for", "key", ",", "val", "in", "zip", "(", "hopt_vars_keys", ",", "hopt_vars_vals", ")", ":", "\n", "    ", "if", "is_integer", "[", "i", "]", ":", "\n", "      ", "rmc", "[", "key", "]", "=", "int", "(", "val", ")", "\n", "", "else", ":", "\n", "      ", "rmc", "[", "key", "]", "=", "val", "\n", "", "i", "=", "i", "+", "1", "\n", "\n", "", "return", "edict", "(", "rmc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.train_and_evaluate": [[97, 117], ["supervisor.trainer.train", "os.path.join", "open", "numpy.max", "json.load"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.trainer.train"], ["", "def", "train_and_evaluate", "(", "mc", ")", ":", "\n", "  ", "\"\"\"\n    start training and evaluate it after the last step\n    Args:\n      mc: model configuration dictionary\n    Returns:\n      The maximum mAP found in the total training process.\n  \"\"\"", "\n", "# start training", "\n", "sup_train", "(", "mc", ")", "\n", "\n", "# read evaluation map file if exists", "\n", "eval_file_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "eval_file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "# mAP_per_step = f.readlines()", "\n", "# mAPs = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in mAP_per_step if \"mAP\" in l]", "\n", "    ", "mAPs", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "max_mAP", "=", "np", ".", "max", "(", "mAPs", ")", "\n", "\n", "", "return", "max_mAP", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.create_trainer": [[118, 147], ["hyperparam_tuner.create_mc_from_hopt_vars", "os.path.join", "os.path.join", "hyperparam_tuner.train_and_evaluate", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "str", "zip", "str"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.create_mc_from_hopt_vars", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.train_and_evaluate"], ["", "def", "create_trainer", "(", "mc", ",", "hopt_vars", ",", "is_integer", ")", ":", "\n", "  ", "\"\"\"\n    Creates a trainer function to be used by the dlib hyperoptimization functions\n    Args:\n      mc: basic model configuration\n      hopt_vars: array of pairs (mc key, array of possible values of mc[key])\n      is_integer: Array indicating if corresponding variable in hopt_vars_vals is integer\n  \"\"\"", "\n", "hopt_vars_keys", "=", "[", "p", "[", "0", "]", "for", "p", "in", "hopt_vars", "]", "\n", "\n", "def", "_train", "(", "*", "args", ")", ":", "\n", "    ", "xmc", "=", "create_mc_from_hopt_vars", "(", "mc", ",", "args", ",", "hopt_vars_keys", ",", "is_integer", ")", "\n", "hyperiteration_string", "=", "'_'", ".", "join", "(", "[", "(", "str", "(", "k", ")", "+", "\"_\"", "+", "str", "(", "v", ")", ")", "for", "k", ",", "v", "in", "zip", "(", "hopt_vars_keys", ",", "args", ")", "]", ")", "\n", "new_TRAIN_DIR", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"train\"", "+", "hyperiteration_string", ")", "\n", "new_eval_dir", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"eval\"", "+", "hyperiteration_string", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "new_TRAIN_DIR", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "new_TRAIN_DIR", ")", "\n", "", "xmc", "[", "\"TRAIN_DIR\"", "]", "=", "new_TRAIN_DIR", "\n", "xmc", ".", "TRAIN_DIR", "=", "new_TRAIN_DIR", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "new_eval_dir", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "new_eval_dir", ")", "\n", "", "xmc", "[", "\"EVAL_DIR\"", "]", "=", "new_eval_dir", "\n", "xmc", ".", "EVAL_DIR", "=", "new_eval_dir", "\n", "\n", "return", "train_and_evaluate", "(", "xmc", ")", "\n", "\n", "", "return", "_train", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.hopt_training": [[148, 185], ["hyperparam_tuner.parse_mc", "os.path.join", "os.path.exists", "lipo_agent.adalipo_search", "hyperparam_tuner.create_trainer", "open", "f.write", "f.write", "zip", "open", "f.read", "initial_values.append", "os.path.join", "f.write", "ast.literal_eval", "float", "h[].split", "dlib.function_evaluation"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.parse_mc", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.lipo_agent.adalipo_search", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.hyperparam_tuner.create_trainer"], ["", "def", "hopt_training", "(", "mc", ")", ":", "\n", "  ", "\"\"\"\n    Starts the hyperoptimization training based on mc values\n    Args:\n      mc: model configuration as given by the user\n  \"\"\"", "\n", "mc", ",", "hopt_vars", "=", "parse_mc", "(", "mc", ")", "\n", "hopt_vars_keys", "=", "[", "p", "[", "0", "]", "for", "p", "in", "hopt_vars", "]", "\n", "\n", "mins", "=", "[", "p", "[", "1", "]", "[", "0", "]", "for", "p", "in", "hopt_vars", "]", "\n", "maxs", "=", "[", "p", "[", "1", "]", "[", "-", "1", "]", "for", "p", "in", "hopt_vars", "]", "\n", "is_integer", "=", "[", "p", "[", "2", "]", "for", "p", "in", "hopt_vars", "]", "\n", "\n", "# read history (if any)", "\n", "hist_path", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"hp_opt_history.txt\"", ")", "\n", "initial_values", "=", "[", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "hist_path", ")", ":", "\n", "    ", "with", "open", "(", "hist_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "      ", "hist_strings", "=", "f", ".", "read", "(", ")", "\n", "", "for", "h", "in", "hist_strings", ":", "\n", "      ", "t", "=", "[", "ast", ".", "literal_eval", "(", "x", ")", "for", "x", "in", "h", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "x", "=", "t", "[", ":", "-", "1", "]", "\n", "func_val", "=", "t", "[", "-", "1", "]", "\n", "initial_values", ".", "append", "(", "[", "function_evaluation_obj", "(", "x", ",", "func_val", ")", "]", ")", "\n", "\n", "# optimize", "\n", "", "", "opt_hp", ",", "opt_eval", "=", "adalipo_search", "(", "mc", ",", "create_trainer", "(", "mc", ",", "hopt_vars", ",", "is_integer", ")", ",", "mc", "[", "\"HOPT\"", "]", "[", "\"MAX_ITERATIONS\"", "]", ",", "\n", "mins", ",", "maxs", ",", "is_integer", ",", "initial_values", "=", "initial_values", ")", "\n", "\n", "# report best result", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"hopt_results.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "\"Best evaluation is: %f\\n\"", "%", "float", "(", "opt_eval", ")", ")", "\n", "f", ".", "write", "(", "\"optimal variables are:\\n\"", ")", "\n", "for", "k", ",", "v", "in", "zip", "(", "hopt_vars_keys", ",", "opt_hp", ")", ":", "\n", "      ", "f", ".", "write", "(", "\"%s:  %f\\n\"", "%", "(", "k", ",", "v", ")", ")", "\n", "\n", "", "", "return", "True", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f": [[9, 11], ["None"], "function", ["None"], ["def", "f", "(", "x", ")", ":", "\n", "  ", "return", "(", "x", "[", "0", "]", "-", "2", ")", "*", "(", "x", "[", "0", "]", "-", "2", ")", "*", "(", "x", "[", "1", "]", "-", "1", ")", "*", "(", "x", "[", "1", "]", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f_sep": [[12, 14], ["agent_test.f"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f"], ["", "def", "f_sep", "(", "x0", ",", "x1", ")", ":", "\n", "  ", "return", "f", "(", "[", "x0", ",", "x1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f_args": [[15, 17], ["agent_test.f"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f"], ["", "def", "f_args", "(", "*", "x", ")", ":", "\n", "  ", "return", "f", "(", "[", "x", "[", "0", "]", ",", "x", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.agent_test.f_labeled": [[18, 20], ["None"], "function", ["None"], ["", "def", "f_labeled", "(", "x", ")", ":", "\n", "  ", "return", "(", "x", "[", "\"0\"", "]", "-", "2", ")", "*", "(", "x", "[", "\"0\"", "]", "-", "2", ")", "*", "(", "x", "[", "\"1\"", "]", "-", "1", ")", "*", "(", "x", "[", "\"1\"", "]", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.lipo_agent.adalipo_search": [[5, 46], ["dlib.function_spec", "xrange", "dlib.global_function_search.get_best_function_eval", "list", "dlib.global_function_search", "dlib.global_function_search", "dlib.global_function_search.get_next_x", "func", "opt.get_next_x.set", "open", "list", "list.append", "f.write", "f.write", "len", "os.path.join", "str"], "function", ["None"], ["def", "adalipo_search", "(", "mc", ",", "func", ",", "num_iterations", ",", "mins", ",", "maxs", ",", "is_integer", ",", "initial_values", "=", "[", "]", ",", "history_file", "=", "\"hp_opt_history.txt\"", ")", ":", "\n", "  ", "\"\"\"\n  This function searches for the global maxima of func inside the\n  parameters.\n  Args:\n    mc:\n    func: Objective function to be optimized, defined as func(*args)\n    num_iterations: Number of iterations till maxima is found\n    mins[i]: minimum of hyperparameter #i to be optimized\n    mins[i]: maximum of hyperparameter #i to be optimized\n    is_integer[i]: if hyperparameter #i accepts only integer values\n    initial_values: if this optimization has been done for some iterations\n                    in the past then the results can bee added here as a list\n                    with entries of type dlib.function_evaluation.\n  Returns:\n    The best values of the hyperparameters\n    The best evaluation\n  \"\"\"", "\n", "specs", "=", "dlib", ".", "function_spec", "(", "mins", ",", "maxs", ",", "is_integer", ")", "\n", "\n", "if", "initial_values", "!=", "[", "]", ":", "\n", "    ", "opt", "=", "dlib", ".", "global_function_search", "(", "[", "specs", "]", "*", "len", "(", "initial_values", ")", ",", "initial_values", ",", "0.001", ")", "\n", "", "else", ":", "\n", "    ", "opt", "=", "dlib", ".", "global_function_search", "(", "specs", ")", "\n", "\n", "", "for", "_", "in", "xrange", "(", "num_iterations", ")", ":", "\n", "    ", "function_evaluation_request_next", "=", "opt", ".", "get_next_x", "(", ")", "\n", "x", "=", "function_evaluation_request_next", ".", "x", "\n", "f_val", "=", "func", "(", "*", "x", ")", "\n", "function_evaluation_request_next", ".", "set", "(", "f_val", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "history_file", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "      ", "y", "=", "list", "(", "x", ")", "\n", "y", ".", "append", "(", "f_val", ")", "\n", "f", ".", "write", "(", "str", "(", "y", ")", ")", "\n", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "# return best point so far", "\n", "", "", "r", "=", "opt", ".", "get_best_function_eval", "(", ")", "\n", "opt_hp", "=", "list", "(", "r", "[", "0", "]", ")", "\n", "opt_eval", "=", "r", "[", "1", "]", "\n", "return", "(", "opt_hp", ",", "opt_eval", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.gaussian": [[4, 6], ["numpy.exp", "numpy.square", "numpy.square"], "function", ["None"], ["def", "gaussian", "(", "x", ",", "mu", ",", "sigma", ")", ":", "\n", "    ", "return", "np", ".", "exp", "(", "-", "np", ".", "square", "(", "x", "-", "mu", ")", "/", "(", "2", "*", "np", ".", "square", "(", "sigma", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.translateDNA": [[8, 21], ["numpy.shape", "six.moves.xrange", "enumerate", "population_vars.append", "var_ranges.keys"], "function", ["None"], ["", "def", "translateDNA", "(", "pop", ",", "var_ranges", ")", ":", "\n", "  ", "\"\"\"\n    pop: the population as 2D array of ints\n    var_ranges: a dictionary from variables to lambdas with input int which return the value of the variable\n  \"\"\"", "\n", "_shape", "=", "np", ".", "shape", "(", "pop", ")", "\n", "population_vars", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "_shape", "[", "0", "]", ")", ":", "\n", "    ", "var_row", "=", "{", "}", "\n", "for", "j", ",", "var_name", "in", "enumerate", "(", "var_ranges", ".", "keys", "(", ")", ")", ":", "\n", "      ", "var_row", "[", "var_name", "]", "=", "var_ranges", "[", "var_name", "]", "(", "pop", "[", "i", ",", "j", "]", ")", "\n", "", "population_vars", ".", "append", "(", "var_row", ")", "\n", "", "return", "population_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.get_population_values": [[22, 36], ["six.moves.xrange", "len", "extra_configs.copy", "f_vals.append", "func"], "function", ["None"], ["", "def", "get_population_values", "(", "func", ",", "translated_population", ",", "extra_configs", ")", ":", "\n", "  ", "\"\"\"\n    Args:\n      func: function to use for values\n      translated: list of dictionaries with values\n      extra_configs: extra list of non optimizable parameters to pass to func.\n  \"\"\"", "\n", "f_vals", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "translated_population", ")", ")", ":", "\n", "    ", "f_input", "=", "extra_configs", ".", "copy", "(", ")", "\n", "for", "key", "in", "translated_population", "[", "i", "]", ":", "\n", "      ", "f_input", "[", "key", "]", "=", "translated_population", "[", "i", "]", "[", "key", "]", "\n", "", "f_vals", ".", "append", "(", "func", "(", "f_input", ")", ")", "# calculate the function", "\n", "", "return", "f_vals", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.get_fittness": [[37, 39], ["ga_agent.gaussian", "numpy.array", "numpy.min"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.gaussian"], ["", "def", "get_fittness", "(", "population_vals", ")", ":", "\n", "  ", "return", "gaussian", "(", "np", ".", "array", "(", "population_vals", ")", ",", "np", ".", "min", "(", "population_vals", ")", ",", "100.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.select": [[40, 47], ["numpy.unique", "numpy.random.choice", "numpy.arange", "fittness.sum"], "function", ["None"], ["", "def", "select", "(", "population", ",", "fittness", ",", "population_size", ")", ":", "\n", "  ", "\"\"\"\n    The idea of selection phase is to select the fittest individuals\n    and let them pass their genes to the next generation.\n  \"\"\"", "\n", "idx", "=", "np", ".", "unique", "(", "np", ".", "random", ".", "choice", "(", "a", "=", "np", ".", "arange", "(", "population_size", ")", ",", "size", "=", "population_size", ",", "replace", "=", "True", ",", "p", "=", "fittness", "/", "fittness", ".", "sum", "(", ")", ")", ")", "\n", "return", "population", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.crossover": [[48, 54], ["numpy.random.rand", "numpy.random.randint", "numpy.random.randint().astype", "numpy.random.randint"], "function", ["None"], ["", "def", "crossover", "(", "parent", ",", "population", ",", "population_size", ",", "dna_size", ",", "cross_rate", ")", ":", "\n", "  ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "cross_rate", ":", "\n", "    ", "i_", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "population_size", ",", "size", "=", "1", ")", "# select another individual from pop", "\n", "cross_points", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "dna_size", ")", ".", "astype", "(", "np", ".", "bool", ")", "# choose crossover points", "\n", "parent", "[", "cross_points", "]", "=", "population", "[", "i_", ",", "cross_points", "]", "# mating and produce one child", "\n", "", "return", "parent", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.mutate": [[55, 60], ["six.moves.xrange", "numpy.random.rand", "numpy.random.randint", "numpy.iinfo", "numpy.iinfo"], "function", ["None"], ["", "def", "mutate", "(", "child", ",", "dna_size", ",", "mutation_rate", ",", "var_ranges_dtype", ")", ":", "\n", "  ", "for", "point", "in", "xrange", "(", "dna_size", ")", ":", "\n", "    ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "mutation_rate", ":", "\n", "      ", "child", "[", "point", "]", "=", "child", "[", "point", "]", "^", "np", ".", "random", ".", "randint", "(", "low", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "min", ",", "high", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "max", ",", "dtype", "=", "var_ranges_dtype", ")", "\n", "", "", "return", "child", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.ga_search": [[72, 98], ["len", "numpy.random.randint", "constant_configs.keys", "func", "var_ranges.keys", "ga_agent.translateDNA", "ga_agent.get_population_values", "ga_agent.select", "np.array.copy", "numpy.array", "var_ranges.keys", "all_time_min_vars.keys", "numpy.min", "numpy.min", "ga_agent.get_fittness", "numpy.shape", "ga_agent.crossover", "ga_agent.mutate", "numpy.iinfo", "numpy.iinfo", "numpy.argmin"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.translateDNA", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.get_population_values", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.select", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.get_fittness", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.crossover", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.hypervisor.ga_agent.mutate"], ["", "def", "ga_search", "(", "func", ",", "var_ranges", ",", "population_size", ",", "cross_rate", ",", "mutation_rate", ",", "constant_configs", "=", "{", "}", ",", "var_ranges_dtype", "=", "np", ".", "int16", ")", ":", "\n", "  ", "dna_size", "=", "len", "(", "var_ranges", ".", "keys", "(", ")", ")", "\n", "population", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "min", ",", "high", "=", "np", ".", "iinfo", "(", "var_ranges_dtype", ")", ".", "max", ",", "size", "=", "(", "population_size", ",", "dna_size", ")", ",", "dtype", "=", "var_ranges_dtype", ")", "# initialize the gene population", "\n", "all_time_min_vars", "=", "{", "var_name", ":", "var_ranges", "[", "var_name", "]", "(", "0", ")", "for", "var_name", "in", "var_ranges", ".", "keys", "(", ")", "}", "\n", "for", "s", "in", "constant_configs", ".", "keys", "(", ")", ":", "\n", "    ", "if", "s", "not", "in", "all_time_min_vars", ".", "keys", "(", ")", ":", "\n", "      ", "all_time_min_vars", "[", "s", "]", "=", "constant_configs", "[", "s", "]", "\n", "", "", "all_time_min_val", "=", "func", "(", "all_time_min_vars", ")", "\n", "while", "True", ":", "\n", "# generate population values", "\n", "    ", "translated_population", "=", "translateDNA", "(", "population", ",", "var_ranges", ")", "\n", "F_values", "=", "get_population_values", "(", "func", ",", "translated_population", ",", "constant_configs", ")", "\n", "if", "(", "np", ".", "min", "(", "F_values", ")", "<", "all_time_min_val", ")", ":", "\n", "      ", "all_time_min_vars", "=", "translated_population", "[", "np", ".", "argmin", "(", "F_values", ")", "]", "\n", "all_time_min_val", "=", "np", ".", "min", "(", "F_values", ")", "\n", "", "yield", "(", "all_time_min_vars", ",", "all_time_min_val", ")", "\n", "# select", "\n", "population", "=", "select", "(", "population", ",", "get_fittness", "(", "F_values", ")", ",", "population_size", ")", "\n", "population_size", "=", "np", ".", "shape", "(", "population", ")", "[", "0", "]", "\n", "pop_copy", "=", "population", ".", "copy", "(", ")", "\n", "# crossover", "\n", "children", "=", "[", "crossover", "(", "parent", ",", "pop_copy", ",", "population_size", ",", "dna_size", ",", "cross_rate", ")", "for", "parent", "in", "population", "]", "\n", "# mutate", "\n", "mutants", "=", "[", "mutate", "(", "child", ",", "dna_size", ",", "mutation_rate", ",", "var_ranges_dtype", ")", "for", "child", "in", "children", "]", "\n", "population", "=", "np", ".", "array", "(", "mutants", ")", "\n", "", "return", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.load_config.super_config": [[4, 8], ["json.load", "open", "os.path.join", "os.path.dirname"], "function", ["None"], ["def", "super_config", "(", ")", ":", "\n", "  ", "super_config", "=", "load", "(", "open", "(", "join", "(", "dirname", "(", "__file__", ")", ",", "\n", "\"supervisor_config.json\"", ")", ",", "\"r\"", ")", ")", "\n", "return", "super_config", "\n", "# for x in super_config:", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.trainer.train": [[22, 133], ["tf.train.MonitoredTrainingSession.run", "six.moves.xrange", "os.path.join", "os.path.join", "os.path.exists", "os.mkdir", "tensorflow.Graph", "datasets.get_dataset", "tensorflow.train.get_checkpoint_state", "tensorflow.train.get_checkpoint_state", "train_graph.as_default", "tensorflow.ConfigProto", "tensorflow.train.get_or_create_global_step", "tensorflow.train.MonitoredTrainingSession", "tensorflow.summary.FileWriter", "supervisor.evaluator.create_evaluation_model", "tf.train.Saver.restore", "numpy.zeros", "tf.train.MonitoredTrainingSession.run", "tensorflow.Graph", "tensorflow.RunMetadata", "tensorflow.RunOptions", "nets.get_net", "tensorflow.summary.merge", "tensorflow.summary.merge", "tensorflow.all_variables", "tensorflow.train.Saver", "supervisor.evaluator.evaluate", "time.time", "open", "json.dump", "tensorflow.train.Scaffold", "tensorflow.python.client.timeline.Timeline", "timeline.Timeline.generate_chrome_trace_format", "os.path.join", "tensorflow.summary.merge_all", "tensorflow.summary.merge_all", "open", "f.write", "list", "numpy.any", "os.path.join", "numpy.arange", "tensorflow.global_variables_initializer", "str"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.__init__.get_dataset", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.create_evaluation_model", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.__init__.get_net", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate"], ["def", "train", "(", "mc", ")", ":", "\n", "  ", "\"\"\"\n    It trains the SqueezeDet model.\n    Args:\n      mc: The model configuration as an EasyDict object.\n    Returns:\n      Always True\n  \"\"\"", "\n", "\n", "if", "not", "\"TRAIN_DIR\"", "in", "mc", ":", "\n", "    ", "mc", ".", "TRAIN_DIR", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"train\"", ")", "\n", "mc", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"train\"", ")", "\n", "\n", "# if it does not exist in the filesystem, create it. ", "\n", "", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ")", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ")", "\n", "\n", "# create a training and evaluation graphs", "\n", "", "train_graph", ",", "eval_graph", "=", "tf", ".", "Graph", "(", ")", ",", "tf", ".", "Graph", "(", ")", "if", "(", "mc", ".", "EVAL_WITH_TRAIN", ")", "else", "None", "\n", "\n", "# get training and evaluation inputs", "\n", "train_list", ",", "eval_list", ",", "mc", "=", "datasets", ".", "get_dataset", "(", "mc", ".", "DATASET_NAME", ")", "(", "mc", ",", "\n", "train_graph", ",", "\n", "eval_graph", ")", "\n", "# get checkpoint", "\n", "if", "(", "\"ckpt_path\"", "in", "mc", ")", ":", "\n", "    ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "mc", "[", "\"ckpt_path\"", "]", ")", "\n", "", "else", ":", "\n", "    ", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ")", "\n", "\n", "\n", "", "with", "train_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "jit_level", "=", "tf", ".", "OptimizerOptions", ".", "ON_2", "\n", "sess_config", ".", "graph_options", ".", "optimizer_options", ".", "global_jit_level", "=", "jit_level", "\n", "if", "(", "mc", "[", "\"SAVE_XLA_TIMELINE\"", "]", ")", ":", "\n", "      ", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "run_options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "", "else", ":", "\n", "      ", "run_metadata", "=", "None", "\n", "run_options", "=", "None", "\n", "# get/set global step", "\n", "", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "model", "=", "nets", ".", "get_net", "(", "mc", ".", "NET", ")", "(", "mc", ",", "train_list", ",", "global_step", "=", "global_step", ")", "\n", "\n", "if", "mc", ".", "VISUALIZE_ON", ":", "\n", "      ", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "tf", ".", "summary", ".", "merge_all", "(", ")", ",", "model", ".", "viz_op", "]", ")", "\n", "", "else", ":", "\n", "      ", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "tf", ".", "summary", ".", "merge_all", "(", ")", "]", ")", "\n", "\n", "", "if", "(", "not", "mc", ".", "LOAD_PRETRAINED_MODEL", ")", ":", "\n", "      ", "var_list", "=", "tf", ".", "all_variables", "(", ")", "\n", "if", "(", "mc", ".", "LAYERS_TO_LOAD", ")", ":", "\n", "        ", "new_var_list", "=", "[", "var_name", "for", "var_name", "in", "var_list", "if", "np", ".", "any", "(", "[", "layer_name", "+", "\"/\"", "in", "str", "(", "var_name", ")", "for", "layer_name", "in", "mc", ".", "LAYERS_TO_LOAD", "]", ")", "]", "\n", "", "else", ":", "\n", "        ", "new_var_list", "=", "var_list", "\n", "", "train_saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "new_var_list", ")", "\n", "", "train_sess", "=", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "master", "=", "''", ",", "\n", "is_chief", "=", "True", ",", "\n", "checkpoint_dir", "=", "mc", "[", "\"TRAIN_DIR\"", "]", ",", "\n", "scaffold", "=", "tf", ".", "train", ".", "Scaffold", "(", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", "else", "None", ",", "\n", "summary_op", "=", "summary_op", ")", ",", "\n", "hooks", "=", "None", ",", "\n", "chief_only_hooks", "=", "None", ",", "\n", "save_summaries_steps", "=", "mc", "[", "\"SUMMARY_STEP\"", "]", ",", "\n", "config", "=", "sess_config", ",", "\n", "stop_grace_period_secs", "=", "120", ",", "\n", "log_step_count_steps", "=", "100", ",", "\n", "max_wait_secs", "=", "7200", ",", "\n", "save_checkpoint_steps", "=", "mc", "[", "\"checkpoint_step\"", "]", ")", "\n", "train_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ",", "train_sess", ".", "graph", ")", "\n", "", "if", "(", "mc", ".", "EVAL_WITH_TRAIN", ")", ":", "\n", "    ", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", "=", "create_evaluation_model", "(", "mc", ",", "eval_list", ",", "eval_graph", ")", "\n", "\n", "# load variables from checkpoint", "\n", "", "if", "(", "not", "mc", ".", "LOAD_PRETRAINED_MODEL", "and", "ckpt", "and", "ckpt", ".", "model_checkpoint_path", ")", ":", "\n", "    ", "train_saver", ".", "restore", "(", "train_sess", ",", "ckpt", ".", "model_checkpoint_path", ")", "\n", "\n", "# get current step", "\n", "", "g_s", "=", "train_sess", ".", "run", "(", "global_step", ",", "options", "=", "run_options", ")", "\n", "# create an array of times of each step", "\n", "if", "mc", ".", "TIMING", ":", "\n", "    ", "times", "=", "np", ".", "zeros", "(", "(", "mc", "[", "\"MAX_STEPS\"", "]", ",", ")", ")", "\n", "\n", "# run the whole thing", "\n", "", "for", "i", "in", "xrange", "(", "mc", "[", "\"MAX_STEPS\"", "]", ")", ":", "\n", "    ", "train_sess", ".", "run", "(", "model", ".", "train_op", ",", "\n", "run_metadata", "=", "run_metadata", ",", "options", "=", "run_options", ")", "\n", "if", "i", "%", "mc", "[", "\"EVAL_PER_STEPS\"", "]", "==", "0", "and", "i", ">=", "5000", "and", "mc", ".", "EVAL_WITH_TRAIN", ":", "\n", "# run evaluation", "\n", "      ", "evaluate", "(", "mc", ",", "eval_graph", ",", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", ")", "\n", "", "elif", "i", "%", "mc", "[", "\"EVAL_PER_STEPS\"", "]", "==", "5", "and", "(", "g_s", "+", "i", ">=", "1000", ")", "and", "mc", ".", "SAVE_XLA_TIMELINE", ":", "\n", "# produce timeline", "\n", "      ", "fetched_timeline", "=", "timeline", ".", "Timeline", "(", "run_metadata", ".", "step_stats", ")", "\n", "chrome_trace", "=", "fetched_timeline", ".", "generate_chrome_trace_format", "(", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", ".", "TRAIN_DIR", ",", "'timeline_02_step_%d.json'", "%", "i", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "chrome_trace", ")", "\n", "", "break", "\n", "", "if", "mc", ".", "TIMING", ":", "\n", "      ", "times", "[", "i", "]", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "if", "mc", ".", "TIMING", ":", "\n", "    ", "times", "-=", "times", "[", "0", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", ".", "TRAIN_DIR", ",", "'step_times.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "{", "\"TIMES\"", ":", "times", ",", "\"MAX_STEPS\"", ":", "list", "(", "np", ".", "arange", "(", "mc", "[", "\"MAX_STEPS\"", "]", ")", ")", "}", ",", "f", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.create_evaluation_model": [[13, 44], ["tensorflow.Session", "os.path.join", "os.path.join", "os.path.exists", "os.mkdir", "eval_graph.as_default", "tf.Session.run", "eval_model.geteval_op_list", "tensorflow.summary.FileWriter", "eval_model.geteval_op_list.append", "tensorflow.train.Saver", "tensorflow.ConfigProto", "nets.get_net", "tensorflow.global_variables_initializer", "tensorflow.summary.merge", "tensorflow.summary.merge", "tensorflow.summary.merge_all", "tensorflow.summary.merge_all"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton.geteval_op_list", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.__init__.get_net"], ["def", "create_evaluation_model", "(", "mc", ",", "eval_input", ",", "eval_graph", ")", ":", "\n", "  ", "\"\"\"\n    Create an evaluation Session and operations\n    to be computed for the evaluation of the model.\n  \"\"\"", "\n", "eval_mc", "=", "mc", "\n", "if", "not", "\"EVAL_DIR\"", "in", "mc", ":", "\n", "    ", "mc", ".", "EVAL_DIR", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"evals\"", ")", "\n", "mc", "[", "\"EVAL_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "mc", "[", "\"BASE_DIR\"", "]", ",", "\"evals\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_mc", "[", "\"EVAL_DIR\"", "]", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "eval_mc", "[", "\"EVAL_DIR\"", "]", ")", "\n", "\n", "", "eval_mc", ".", "IS_TRAINING", "=", "False", "\n", "eval_mc", ".", "DATA_AUGMENTATION", "=", "False", "\n", "\n", "eval_sess", "=", "tf", ".", "Session", "(", "graph", "=", "eval_graph", ",", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", ")", "\n", "\n", "with", "eval_graph", ".", "as_default", "(", ")", ":", "\n", "    ", "eval_model", "=", "nets", ".", "get_net", "(", "eval_mc", ".", "NET", ")", "(", "eval_mc", ",", "eval_input", ",", "global_step", "=", "True", ")", "\n", "eval_sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "eval_ops", "=", "eval_model", ".", "geteval_op_list", "(", ")", "\n", "if", "eval_model", ".", "viz_op", "!=", "None", ":", "\n", "      ", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "tf", ".", "summary", ".", "merge_all", "(", ")", ",", "eval_model", ".", "viz_op", "]", ")", "\n", "", "else", ":", "\n", "      ", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "tf", ".", "summary", ".", "merge_all", "(", ")", "]", ")", "\n", "", "eval_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "eval_mc", "[", "\"EVAL_DIR\"", "]", ",", "graph", "=", "eval_graph", ",", "flush_secs", "=", "100000000", ")", "\n", "eval_ops", ".", "append", "(", "summary_op", ")", "\n", "eval_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "", "return", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate": [[45, 117], ["tensorflow.train.get_checkpoint_state", "eval_saver.restore", "datasets.get_evaluation_func", "int", "int", "six.moves.xrange", "six.moves.xrange", "datasets.get_evaluation_func.", "os.path.exists", "print", "eval_writer.flush", "open", "[].split", "eval_sess.run", "prediction_boxes.append", "score.append", "cls_idx_per_img.append", "img_names.extend", "widths.extend", "heights.extend", "eval_writer.add_summary", "print", "zip", "os.path.join", "open", "history.append", "json.dump", "os.path.join", "six.moves.xrange", "enumerate", "open", "f.write", "analysis.keys", "f.write", "json.load", "os.path.join", "f.readline().split", "six.moves.xrange", "float", "float", "[].append", "os.path.join", "f.write", "open", "numpy.mean", "[].split", "str", "os.path.join", "f.readline", "str", "latest_checkpoint.split", "str"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.__init__.get_evaluation_func"], ["", "def", "evaluate", "(", "mc", ",", "eval_graph", ",", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", ")", ":", "\n", "  ", "\"\"\"\n    Evaluate the model obtained from the last checkpoint\n    and create the tensorboard summaries.\n  \"\"\"", "\n", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ")", "\n", "# global_vars = tf.global_variables()", "\n", "# is_not_initialized = eval_sess.run([tf.is_variable_initialized(var) for var in global_vars if(not \"iou\" in var)])", "\n", "eval_saver", ".", "restore", "(", "eval_sess", ",", "ckpt", ".", "model_checkpoint_path", ")", "\n", "evaluation_func", "=", "datasets", ".", "get_evaluation_func", "(", "mc", ".", "DATASET_NAME", ")", "\n", "# get current training global step from last checkpoint", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"TRAIN_DIR\"", "]", ",", "\"checkpoint\"", ")", ")", "as", "f", ":", "\n", "    ", "latest_checkpoint", "=", "f", ".", "readline", "(", ")", ".", "split", "(", "\"model_checkpoint_path: \\\"\"", ")", "[", "-", "1", "]", "[", ":", "-", "2", "]", "\n", "", "global_step", "=", "latest_checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".data\"", ")", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "\n", "g_s", "=", "int", "(", "global_step", ")", "\n", "# fill data from iterations to feed them to the evaluation tool", "\n", "prediction_boxes", ",", "score", ",", "cls_idx_per_img", ",", "img_names", ",", "widths", ",", "heights", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "max_iters", "=", "int", "(", "mc", ".", "EVAL_ITERS", "/", "mc", ".", "BATCH_SIZE", ")", "\n", "all_boxes", "=", "[", "[", "[", "]", "for", "_", "in", "xrange", "(", "max_iters", "*", "mc", ".", "BATCH_SIZE", ")", "]", "\n", "for", "_", "in", "xrange", "(", "mc", ".", "CLASSES", ")", "]", "\n", "for", "i", "in", "xrange", "(", "max_iters", ")", ":", "\n", "    ", "res", "=", "eval_sess", ".", "run", "(", "eval_ops", ")", "\n", "prediction_boxes", ".", "append", "(", "res", "[", "0", "]", ")", "\n", "score", ".", "append", "(", "res", "[", "1", "]", ")", "\n", "cls_idx_per_img", ".", "append", "(", "res", "[", "2", "]", ")", "\n", "img_names", ".", "extend", "(", "res", "[", "3", "]", ")", "\n", "widths", ".", "extend", "(", "res", "[", "4", "]", ")", "\n", "heights", ".", "extend", "(", "res", "[", "5", "]", ")", "\n", "eval_writer", ".", "add_summary", "(", "res", "[", "-", "1", "]", ",", "g_s", ")", "\n", "print", "(", "\"%d/%d\"", "%", "(", "i", ",", "max_iters", ")", ")", "\n", "\n", "# loop per step/batch", "\n", "", "local_iter", "=", "0", "\n", "for", "eval_iter", "in", "xrange", "(", "max_iters", ")", ":", "\n", "# loop per image inside the batch", "\n", "    ", "for", "c", ",", "b", ",", "s", "in", "zip", "(", "cls_idx_per_img", "[", "eval_iter", "]", ",", "prediction_boxes", "[", "eval_iter", "]", ",", "score", "[", "eval_iter", "]", ")", ":", "\n", "      ", "x_scale", "=", "widths", "[", "local_iter", "]", "/", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", "\n", "y_scale", "=", "heights", "[", "local_iter", "]", "/", "float", "(", "mc", ".", "IMAGE_HEIGHT", ")", "\n", "for", "i", ",", "cls_idx", "in", "enumerate", "(", "c", ")", ":", "\n", "        ", "c_i", "=", "cls_idx", "\n", "all_boxes", "[", "c_i", "]", "[", "local_iter", "]", ".", "append", "(", "[", "b", "[", "\"xmins\"", "]", "[", "i", "]", "*", "x_scale", ",", "\n", "b", "[", "\"ymins\"", "]", "[", "i", "]", "*", "y_scale", ",", "\n", "b", "[", "\"xmaxs\"", "]", "[", "i", "]", "*", "x_scale", ",", "\n", "b", "[", "\"ymaxs\"", "]", "[", "i", "]", "*", "y_scale", ",", "s", "[", "i", "]", "]", ")", "\n", "", "local_iter", "+=", "1", "\n", "# analyse", "\n", "", "", "aps", ",", "analysis", "=", "evaluation_func", "(", "mc", ",", "mc", "[", "\"EVAL_DIR\"", "]", ",", "global_step", ",", "all_boxes", ",", "img_names", ")", "\n", "# write analysis", "\n", "if", "(", "analysis", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "\"analysis_raw.txt\"", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "str", "(", "global_step", ")", "+", "\"\\n{\\n\"", ")", "\n", "for", "el", "in", "analysis", ".", "keys", "(", ")", ":", "\n", "        ", "f", ".", "write", "(", "str", "(", "el", ")", "+", "\": \"", "+", "str", "(", "analysis", "[", "el", "]", ")", "+", "\"\\n\"", ")", "\n", "", "f", ".", "write", "(", "\"}\\n\"", ")", "\n", "# write mAPs", "\n", "", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "\"mAP_history.json\"", ")", ")", ":", "\n", "    ", "history", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "\"mAP_history.json\"", ")", ")", ")", "[", "\"history\"", "]", "\n", "", "else", ":", "\n", "    ", "history", "=", "[", "]", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mc", "[", "\"EVAL_DIR\"", "]", ",", "\"mAP_history.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "history", ".", "append", "(", "{", "\"step\"", ":", "global_step", ",", "\"mAP\"", ":", "np", ".", "mean", "(", "aps", ")", "}", ")", "\n", "json", ".", "dump", "(", "{", "\"history\"", ":", "history", "}", ",", "f", ")", "\n", "# f.write(\"{\\n\\\"step\\\": \"+global_step+\",\\n\\\"mAP\\\": {:.4f}\\n\".format(np.mean(aps)))", "\n", "# for cls_idx, cls in enumerate(mc.CLASS_NAMES):", "\n", "#   f.write(\"\\\"{:s}_AP\\\" : \\\"e\\\": {:.4f}, \\\"m\\\": {:.4f}, \\\"h\\\": {:.4f}\\n\".format(cls, aps[cls_idx*3], aps[cls_idx*3+1], aps[cls_idx*3+2]))", "\n", "# f.write(\"}\\n\")", "\n", "", "print", "(", "\"evaluation done for\"", "+", "global_step", ")", "\n", "# flush eval_writer", "\n", "eval_writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate_once": [[118, 139], ["tensorflow.Graph", "evaluator.create_evaluation_model", "evaluator.evaluate", "datasets.get_dataset"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.create_evaluation_model", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.supervisor.evaluator.evaluate", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.datasets.__init__.get_dataset"], ["", "def", "evaluate_once", "(", "mc", ")", ":", "\n", "  ", "\"\"\" Create an evalution graph and evaluate it once.\n      A previous training is required to create a valid checkpoint from which\n      to load the trained weights.\n      Args:\n        mc: model configuration \n  \"\"\"", "\n", "# allocate evaluation graph and initialize as empty", "\n", "eval_graph", "=", "tf", ".", "Graph", "(", ")", "\n", "# create dataset input handlers for the evaluation", "\n", "_", ",", "eval_list", ",", "mc", "=", "datasets", ".", "get_dataset", "(", "mc", ".", "DATASET_NAME", ")", "(", "mc", ",", "\n", "None", ",", "\n", "eval_graph", ")", "\n", "# add model to evaluation graph", "\n", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", "=", "create_evaluation_model", "(", "mc", ",", "eval_list", ",", "eval_graph", ")", "\n", "\n", "# evaluate", "\n", "evaluate", "(", "mc", ",", "eval_graph", ",", "eval_sess", ",", "eval_ops", ",", "eval_saver", ",", "eval_writer", ")", "\n", "\n", "return", "True", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator._get_output_shape": [[9, 25], ["net_shape_calculator.get_squeezeDetPlus_shape", "int", "int", "int", "net_shape_calculator.get_squeezeDet_shape"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_squeezeDetPlus_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_squeezeDet_shape"], ["def", "_get_output_shape", "(", "mc", ")", ":", "\n", "  ", "\"\"\" Given the image shape from the model configuration,\n      this function produces the final feature output shape\n      @param mc model configuration dictionary\n      @Note channel num is not always right\n  \"\"\"", "\n", "\n", "# # # shapes are (H, W, C) using the standard tensorflow paradigm", "\n", "if", "(", "mc", ".", "NET", "==", "\"squeezeDet+\"", ")", ":", "\n", "    ", "ret_shape", "=", "get_squeezeDetPlus_shape", "(", "mc", ")", "\n", "", "elif", "(", "mc", ".", "NET", "==", "\"squeezeDet\"", ")", ":", "\n", "    ", "ret_shape", "=", "get_squeezeDet_shape", "(", "mc", ")", "\n", "", "else", ":", "\n", "    ", "ret_shape", "=", "None", "\n", "\n", "", "return", "(", "int", "(", "ret_shape", "[", "0", "]", ")", ",", "int", "(", "ret_shape", "[", "1", "]", ")", ",", "int", "(", "ret_shape", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape": [[27, 40], ["numpy.ceil", "numpy.ceil", "float", "numpy.ceil", "numpy.ceil", "float", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["None"], ["", "def", "get_conv2d_out_shape", "(", "in_dims", ",", "filter_sizes", ",", "strides", ",", "padding", ")", ":", "\n", "  ", "\"\"\" @param in_dims = input (height, width, channels)\n      @param filter_sizes = (kernel height, kernel width, number of filters)\n      @param strides = (filter height stride, filter width stride)\n  \"\"\"", "\n", "if", "(", "padding", "==", "'SAME'", ")", ":", "\n", "    ", "return", "(", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "0", "]", ")", "/", "float", "(", "strides", "[", "0", "]", ")", ")", ",", "\n", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "1", "]", ")", "/", "float", "(", "strides", "[", "1", "]", ")", ")", ",", "\n", "float", "(", "filter_sizes", "[", "2", "]", ")", ")", "\n", "", "elif", "(", "padding", "==", "'VALID'", ")", ":", "\n", "    ", "return", "(", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "0", "]", "-", "filter_sizes", "[", "0", "]", "+", "1", ")", "/", "float", "(", "strides", "[", "0", "]", ")", ")", ",", "\n", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "1", "]", "-", "filter_sizes", "[", "1", "]", "+", "1", ")", "/", "float", "(", "strides", "[", "1", "]", ")", ")", ",", "\n", "float", "(", "filter_sizes", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape": [[41, 50], ["numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "float", "float", "float", "float", "float", "float", "float", "float"], "function", ["None"], ["", "", "def", "get_pool_out_shape", "(", "in_dims", ",", "filter_sizes", ",", "strides", ",", "padding", ")", ":", "\n", "  ", "if", "(", "padding", "==", "'SAME'", ")", ":", "\n", "    ", "return", "(", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "0", "]", ")", "/", "float", "(", "strides", "[", "0", "]", ")", ")", ",", "\n", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "1", "]", ")", "/", "float", "(", "strides", "[", "1", "]", ")", ")", ",", "\n", "in_dims", "[", "2", "]", ")", "\n", "", "elif", "(", "padding", "==", "'VALID'", ")", ":", "\n", "    ", "return", "(", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "0", "]", "-", "filter_sizes", "[", "0", "]", "+", "1", ")", "/", "float", "(", "strides", "[", "0", "]", ")", ")", ",", "\n", "np", ".", "ceil", "(", "float", "(", "in_dims", "[", "1", "]", "-", "filter_sizes", "[", "1", "]", "+", "1", ")", "/", "float", "(", "strides", "[", "1", "]", ")", ")", ",", "\n", "in_dims", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape": [[51, 56], ["net_shape_calculator.get_conv2d_out_shape", "net_shape_calculator.get_conv2d_out_shape", "net_shape_calculator.get_conv2d_out_shape"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape"], ["", "", "def", "get_fire_out_shape", "(", "in_dims", ",", "s1x1", ",", "e1x1", ",", "e3x3", ")", ":", "\n", "  ", "sq1x1_shape", "=", "get_conv2d_out_shape", "(", "in_dims", ",", "(", "1", ",", "1", ",", "s1x1", ")", ",", "[", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "ex1x1_shape", "=", "get_conv2d_out_shape", "(", "sq1x1_shape", ",", "(", "1", ",", "1", ",", "e1x1", ")", ",", "[", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "ex3x3_shape", "=", "get_conv2d_out_shape", "(", "sq1x1_shape", ",", "(", "3", ",", "3", ",", "e3x3", ")", ",", "[", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "return", "(", "ex3x3_shape", "[", "0", "]", ",", "ex3x3_shape", "[", "1", "]", ",", "ex3x3_shape", "[", "2", "]", "+", "ex1x1_shape", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_squeezeDetPlus_shape": [[57, 108], ["net_shape_calculator.get_conv2d_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_conv2d_out_shape"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape"], ["", "def", "get_squeezeDetPlus_shape", "(", "mc", ")", ":", "\n", "  ", "input_shape", "=", "(", "mc", ".", "IMAGE_HEIGHT", ",", "\n", "mc", ".", "IMAGE_WIDTH", ",", "\n", "3", ")", "\n", "conv1_shape", "=", "get_conv2d_out_shape", "(", "input_shape", ",", "\n", "(", "7", ",", "7", ",", "96", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'VALID'", ")", "\n", "pool1_shape", "=", "get_pool_out_shape", "(", "conv1_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'VALID'", ")", "\n", "fire2_shape", "=", "get_fire_out_shape", "(", "pool1_shape", ",", "\n", "s1x1", "=", "96", ",", "e1x1", "=", "64", ",", "\n", "e3x3", "=", "64", ")", "\n", "fire3_shape", "=", "get_fire_out_shape", "(", "fire2_shape", ",", "\n", "s1x1", "=", "96", ",", "e1x1", "=", "64", ",", "\n", "e3x3", "=", "64", ")", "\n", "fire4_shape", "=", "get_fire_out_shape", "(", "fire3_shape", ",", "\n", "s1x1", "=", "192", ",", "e1x1", "=", "128", ",", "\n", "e3x3", "=", "128", ")", "\n", "pool4_shape", "=", "get_pool_out_shape", "(", "fire4_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'VALID'", ")", "\n", "fire5_shape", "=", "get_fire_out_shape", "(", "pool4_shape", ",", "\n", "s1x1", "=", "192", ",", "e1x1", "=", "128", ",", "\n", "e3x3", "=", "128", ")", "\n", "fire6_shape", "=", "get_fire_out_shape", "(", "fire5_shape", ",", "\n", "s1x1", "=", "288", ",", "e1x1", "=", "192", ",", "\n", "e3x3", "=", "192", ")", "\n", "fire7_shape", "=", "get_fire_out_shape", "(", "fire6_shape", ",", "\n", "s1x1", "=", "288", ",", "e1x1", "=", "192", ",", "\n", "e3x3", "=", "192", ")", "\n", "fire8_shape", "=", "get_fire_out_shape", "(", "fire7_shape", ",", "\n", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "pool8_shape", "=", "get_pool_out_shape", "(", "fire8_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'VALID'", ")", "\n", "fire9_shape", "=", "get_fire_out_shape", "(", "pool8_shape", ",", "\n", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "fire10_shape", "=", "get_fire_out_shape", "(", "fire9_shape", ",", "\n", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "fire11_shape", "=", "get_fire_out_shape", "(", "fire10_shape", ",", "\n", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "conv12_shape", "=", "get_conv2d_out_shape", "(", "fire11_shape", ",", "\n", "(", "3", ",", "3", ",", "num_output", ")", ",", "\n", "[", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "return", "conv12_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_squeezeDet_shape": [[110, 161], ["net_shape_calculator.get_conv2d_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_pool_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_fire_out_shape", "net_shape_calculator.get_conv2d_out_shape"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_pool_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_fire_out_shape", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator.get_conv2d_out_shape"], ["", "def", "get_squeezeDet_shape", "(", "mc", ")", ":", "\n", "  ", "input_shape", "=", "(", "mc", ".", "IMAGE_HEIGHT", ",", "\n", "mc", ".", "IMAGE_WIDTH", ",", "\n", "3", ")", "\n", "conv1_shape", "=", "get_conv2d_out_shape", "(", "input_shape", ",", "\n", "(", "3", ",", "3", ",", "64", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'SAME'", ")", "\n", "pool1_shape", "=", "get_pool_out_shape", "(", "conv1_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'SAME'", ")", "\n", "fire2_shape", "=", "get_fire_out_shape", "(", "pool1_shape", ",", "\n", "s1x1", "=", "16", ",", "e1x1", "=", "64", ",", "\n", "e3x3", "=", "64", ")", "\n", "fire3_shape", "=", "get_fire_out_shape", "(", "fire2_shape", ",", "\n", "s1x1", "=", "16", ",", "e1x1", "=", "64", ",", "\n", "e3x3", "=", "64", ")", "\n", "pool3_shape", "=", "get_pool_out_shape", "(", "fire3_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'SAME'", ")", "\n", "fire4_shape", "=", "get_fire_out_shape", "(", "pool3_shape", ",", "\n", "s1x1", "=", "32", ",", "e1x1", "=", "128", ",", "\n", "e3x3", "=", "128", ")", "\n", "fire5_shape", "=", "get_fire_out_shape", "(", "fire4_shape", ",", "\n", "s1x1", "=", "32", ",", "e1x1", "=", "128", ",", "\n", "e3x3", "=", "128", ")", "\n", "pool5_shape", "=", "get_pool_out_shape", "(", "fire5_shape", ",", "\n", "(", "3", ",", "3", ")", ",", "\n", "[", "2", ",", "2", "]", ",", "'SAME'", ")", "\n", "fire6_shape", "=", "get_fire_out_shape", "(", "pool5_shape", ",", "\n", "s1x1", "=", "48", ",", "e1x1", "=", "192", ",", "\n", "e3x3", "=", "192", ")", "\n", "fire7_shape", "=", "get_fire_out_shape", "(", "fire6_shape", ",", "\n", "s1x1", "=", "48", ",", "e1x1", "=", "192", ",", "\n", "e3x3", "=", "192", ")", "\n", "fire8_shape", "=", "get_fire_out_shape", "(", "fire7_shape", ",", "\n", "s1x1", "=", "64", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "fire9_shape", "=", "get_fire_out_shape", "(", "fire8_shape", ",", "\n", "s1x1", "=", "64", ",", "e1x1", "=", "256", ",", "\n", "e3x3", "=", "256", ")", "\n", "fire10_shape", "=", "get_fire_out_shape", "(", "fire9_shape", ",", "\n", "s1x1", "=", "96", ",", "e1x1", "=", "384", ",", "\n", "e3x3", "=", "384", ")", "\n", "fire11_shape", "=", "get_fire_out_shape", "(", "fire10_shape", ",", "\n", "s1x1", "=", "96", ",", "e1x1", "=", "384", ",", "\n", "e3x3", "=", "384", ")", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "conv12_shape", "=", "get_conv2d_out_shape", "(", "fire11_shape", ",", "\n", "(", "3", ",", "3", ",", "num_output", ")", ",", "\n", "[", "1", ",", "1", "]", ",", "'SAME'", ")", "\n", "return", "conv12_shape", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.base_model_config": [[16, 26], ["os.path.join", "os.path.dirname", "open", "easydict.EasyDict", "os.path.realpath", "json.load"], "function", ["None"], ["def", "base_model_config", "(", ")", ":", "\n", "  ", "\"\"\" This creates the basic model, which needs only few adjustements by the other configurations,\n      in order to work for other datasets and/or detection neural networks.\n  \"\"\"", "\n", "BASE_CONFIG_FILENAME", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "\"configs\"", ",", "\"base_config.json\"", ")", "\n", "\n", "with", "open", "(", "BASE_CONFIG_FILENAME", ",", "'r'", ")", "as", "fp", ":", "\n", "    ", "cfg", "=", "edict", "(", "json", ".", "load", "(", "fp", ",", "encoding", "=", "\"utf8\"", ")", ")", "\n", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.cook_config": [[27, 45], ["config_cooker.base_model_config", "open", "easydict.EasyDict", "easydict.EasyDict.keys", "json.load"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.base_model_config"], ["", "def", "cook_config", "(", "ext_config_filename", ")", ":", "\n", "  ", "\"\"\"\n    This function is usefull for merging basic config with external configs.\n    External config's constants overwrite those of basic config.\n    Args:\n        ext_config_filename: the path for the external config json file. \n  \"\"\"", "\n", "mc", "=", "base_model_config", "(", ")", "\n", "with", "open", "(", "ext_config_filename", ",", "\"r\"", ")", "as", "fp", ":", "\n", "    ", "ext_mc", "=", "edict", "(", "json", ".", "load", "(", "fp", ",", "encoding", "=", "\"utf8\"", ")", ")", "\n", "for", "s", "in", "ext_mc", ".", "keys", "(", ")", ":", "\n", "      ", "mc", "[", "s", "]", "=", "ext_mc", "[", "s", "]", "\n", "# mc.ANCHOR_BOX            = set_anchors(mc)", "\n", "# print(np.max(np.square(np.array(set_anchors_testing(mc)) - np.array(set_anchors(mc)))))", "\n", "# mc.ANCHORS               = len(mc.ANCHOR_BOX)", "\n", "# H, W, C                  = _get_output_shape(mc)", "\n", "# mc.MODEL_OUTPUT_SHAPE    = [H, W, mc.ANCHOR_PER_GRID]", "\n", "", "", "return", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.direct_cook_config": [[46, 57], ["config_cooker.base_model_config"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.base_model_config"], ["", "def", "direct_cook_config", "(", "nmc", ",", "do_set_anchors", "=", "True", ")", ":", "\n", "  ", "mc", "=", "base_model_config", "(", ")", "\n", "# override and register new members to dict  ", "\n", "for", "s", "in", "nmc", ":", "\n", "    ", "mc", "[", "s", "]", "=", "nmc", "[", "s", "]", "\n", "# if(do_set_anchors):", "\n", "#   mc.ANCHOR_BOX            = set_anchors(mc)", "\n", "#   mc.ANCHORS               = len(mc.ANCHOR_BOX)", "\n", "# H, W, C                  = _get_output_shape(mc)", "\n", "# mc.MODEL_OUTPUT_SHAPE    = [H, W, mc.ANCHOR_PER_GRID]", "\n", "", "return", "mc", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.set_anchors": [[58, 103], ["net_shape_calculator._get_output_shape", "numpy.array", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.transpose", "numpy.transpose", "numpy.concatenate", "numpy.reshape", "numpy.reshape", "numpy.array", "numpy.array", "numpy.arange", "float", "numpy.arange", "float"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.net_shape_calculator._get_output_shape"], ["", "def", "set_anchors", "(", "mc", ")", ":", "\n", "  ", "\"\"\"\n    This function returns the default anchors given the image shapes and the\n    anchors per grid point. The grid has width and height equal to the final's \n    layer output.\n    Args:\n      mc model configuration\n    returns:\n      default anchors\n  \"\"\"", "\n", "H", ",", "W", ",", "C", "=", "_get_output_shape", "(", "mc", ")", "\n", "B", "=", "mc", ".", "ANCHOR_PER_GRID", "\n", "X", "=", "np", ".", "array", "(", "mc", ".", "INITIAL_ANCHOR_SHAPES", ")", "\n", "X", "[", ":", ",", "0", "]", "*=", "mc", ".", "IMAGE_WIDTH", "\n", "X", "[", ":", ",", "1", "]", "*=", "mc", ".", "IMAGE_HEIGHT", "\n", "anchor_shapes", "=", "np", ".", "reshape", "(", "# it refers to the anchor width and height", "\n", "[", "X", "]", "*", "H", "*", "W", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "2", ")", "\n", ")", "\n", "center_x", "=", "np", ".", "reshape", "(", "\n", "np", ".", "transpose", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "array", "(", "[", "np", ".", "arange", "(", "1", ",", "W", "+", "1", ")", "*", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", "/", "(", "W", "+", "1", ")", "]", "*", "H", "*", "B", ")", ",", "\n", "(", "B", ",", "H", ",", "W", ")", "\n", ")", ",", "\n", "(", "1", ",", "2", ",", "0", ")", "\n", ")", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "1", ")", "\n", ")", "\n", "center_y", "=", "np", ".", "reshape", "(", "\n", "np", ".", "transpose", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "array", "(", "[", "np", ".", "arange", "(", "1", ",", "H", "+", "1", ")", "*", "float", "(", "mc", ".", "IMAGE_HEIGHT", ")", "/", "(", "H", "+", "1", ")", "]", "*", "W", "*", "B", ")", ",", "\n", "(", "B", ",", "W", ",", "H", ")", "\n", ")", ",", "\n", "(", "2", ",", "1", ",", "0", ")", "\n", ")", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "1", ")", "\n", ")", "\n", "anchors", "=", "np", ".", "reshape", "(", "\n", "np", ".", "concatenate", "(", "(", "center_x", ",", "center_y", ",", "anchor_shapes", ")", ",", "axis", "=", "3", ")", ",", "\n", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "return", "anchors", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.config.config_cooker.set_anchors_testing": [[104, 139], ["numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.transpose", "numpy.transpose", "numpy.concatenate", "numpy.reshape", "numpy.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.arange", "float", "numpy.arange", "float"], "function", ["None"], ["", "def", "set_anchors_testing", "(", "mc", ")", ":", "\n", "  ", "H", ",", "W", ",", "B", "=", "24", ",", "78", ",", "9", "\n", "anchor_shapes", "=", "np", ".", "reshape", "(", "\n", "[", "np", ".", "array", "(", "\n", "[", "[", "36.", ",", "37.", "]", ",", "[", "366.", ",", "174.", "]", ",", "[", "115.", ",", "59.", "]", ",", "\n", "[", "162.", ",", "87.", "]", ",", "[", "38.", ",", "90.", "]", ",", "[", "258.", ",", "173.", "]", ",", "\n", "[", "224.", ",", "108.", "]", ",", "[", "78.", ",", "170.", "]", ",", "[", "72.", ",", "43.", "]", "]", ")", "]", "*", "H", "*", "W", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "2", ")", "\n", ")", "\n", "center_x", "=", "np", ".", "reshape", "(", "\n", "np", ".", "transpose", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "array", "(", "[", "np", ".", "arange", "(", "1", ",", "W", "+", "1", ")", "*", "float", "(", "mc", ".", "IMAGE_WIDTH", ")", "/", "(", "W", "+", "1", ")", "]", "*", "H", "*", "B", ")", ",", "\n", "(", "B", ",", "H", ",", "W", ")", "\n", ")", ",", "\n", "(", "1", ",", "2", ",", "0", ")", "\n", ")", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "1", ")", "\n", ")", "\n", "center_y", "=", "np", ".", "reshape", "(", "\n", "np", ".", "transpose", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "array", "(", "[", "np", ".", "arange", "(", "1", ",", "H", "+", "1", ")", "*", "float", "(", "mc", ".", "IMAGE_HEIGHT", ")", "/", "(", "H", "+", "1", ")", "]", "*", "W", "*", "B", ")", ",", "\n", "(", "B", ",", "W", ",", "H", ")", "\n", ")", ",", "\n", "(", "2", ",", "1", ",", "0", ")", "\n", ")", ",", "\n", "(", "H", ",", "W", ",", "B", ",", "1", ")", "\n", ")", "\n", "anchors", "=", "np", ".", "reshape", "(", "\n", "np", ".", "concatenate", "(", "(", "center_x", ",", "center_y", ",", "anchor_shapes", ")", ",", "axis", "=", "3", ")", ",", "\n", "(", "-", "1", ",", "4", ")", "\n", ")", "\n", "\n", "return", "anchors", "\n", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.vgg16_convDet.VGG16ConvDet.__init__": [[17, 28], ["tensorflow.device", "nets.nn_skeleton.ModelSkeleton.__init__", "vgg16_convDet.VGG16ConvDet._add_forward_graph", "vgg16_convDet.VGG16ConvDet._add_interpretation_graph", "vgg16_convDet.VGG16ConvDet._add_loss_graph", "vgg16_convDet.VGG16ConvDet._add_train_graph", "vgg16_convDet.VGG16ConvDet._add_viz_graph"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet.__init__", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._add_forward_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_interpretation_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_loss_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_train_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_viz_graph"], ["  ", "def", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "gpu_id", "=", "0", ",", "base_net", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/job:localhost/replica:0/task:0/device:CPU:0'", ")", ":", "\n", "      ", "ModelSkeleton", ".", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "base_net", "=", "base_net", ",", "global_step", "=", "global_step", ")", "\n", "\n", "self", ".", "_add_forward_graph", "(", ")", "\n", "self", ".", "_add_interpretation_graph", "(", ")", "\n", "self", ".", "_add_loss_graph", "(", ")", "\n", "if", "mc", ".", "IS_TRAINING", ":", "\n", "        ", "self", ".", "_add_train_graph", "(", ")", "\n", "", "if", "mc", ".", "VISUALIZE_ON", ":", "\n", "        ", "self", ".", "_add_viz_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.vgg16_convDet.VGG16ConvDet._add_forward_graph": [[29, 89], ["tensorflow.nn.dropout", "vgg16_convDet.VGG16ConvDet._conv_layer", "tensorflow.gfile.Exists", "joblib.load", "tensorflow.variable_scope", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._pooling_layer", "tensorflow.variable_scope", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._pooling_layer", "tensorflow.variable_scope", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._pooling_layer", "tensorflow.variable_scope", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._pooling_layer", "tensorflow.variable_scope", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer", "vgg16_convDet.VGG16ConvDet._conv_layer"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer"], ["", "", "", "def", "_add_forward_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"Build the VGG-16 model.\"\"\"", "\n", "\n", "mc", "=", "self", ".", "mc", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "assert", "tf", ".", "gfile", ".", "Exists", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", ",", "'Cannot find pretrained model at the given path:'", "'  {}'", ".", "format", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "self", ".", "caffemodel_weight", "=", "joblib", ".", "load", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv1'", ")", "as", "scope", ":", "\n", "      ", "conv1_1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv1_1'", ",", "self", ".", "image_input", ",", "filters", "=", "64", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "freeze", "=", "True", ")", "\n", "conv1_2", "=", "self", ".", "_conv_layer", "(", "\n", "'conv1_2'", ",", "conv1_1", ",", "filters", "=", "64", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "freeze", "=", "True", ")", "\n", "pool1", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool1'", ",", "conv1_2", ",", "size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv2'", ")", "as", "scope", ":", "\n", "      ", "conv2_1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv2_1'", ",", "pool1", ",", "filters", "=", "128", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "freeze", "=", "True", ")", "\n", "conv2_2", "=", "self", ".", "_conv_layer", "(", "\n", "'conv2_2'", ",", "conv2_1", ",", "filters", "=", "128", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "freeze", "=", "True", ")", "\n", "pool2", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool2'", ",", "conv2_2", ",", "size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv3'", ")", "as", "scope", ":", "\n", "      ", "conv3_1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv3_1'", ",", "pool2", ",", "filters", "=", "256", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv3_2", "=", "self", ".", "_conv_layer", "(", "\n", "'conv3_2'", ",", "conv3_1", ",", "filters", "=", "256", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv3_3", "=", "self", ".", "_conv_layer", "(", "\n", "'conv3_3'", ",", "conv3_2", ",", "filters", "=", "256", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "pool3", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool3'", ",", "conv3_3", ",", "size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv4'", ")", "as", "scope", ":", "\n", "      ", "conv4_1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv4_1'", ",", "pool3", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv4_2", "=", "self", ".", "_conv_layer", "(", "\n", "'conv4_2'", ",", "conv4_1", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv4_3", "=", "self", ".", "_conv_layer", "(", "\n", "'conv4_3'", ",", "conv4_2", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "pool4", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool4'", ",", "conv4_3", ",", "size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv5'", ")", "as", "scope", ":", "\n", "      ", "conv5_1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv5_1'", ",", "pool4", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv5_2", "=", "self", ".", "_conv_layer", "(", "\n", "'conv5_2'", ",", "conv5_1", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "conv5_3", "=", "self", ".", "_conv_layer", "(", "\n", "'conv5_3'", ",", "conv5_2", ",", "filters", "=", "512", ",", "size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "", "dropout5", "=", "tf", ".", "nn", ".", "dropout", "(", "conv5_3", ",", "self", ".", "keep_prob", ",", "name", "=", "'drop6'", ")", "\n", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "self", ".", "preds", "=", "self", ".", "_conv_layer", "(", "\n", "'conv6'", ",", "dropout5", ",", "filters", "=", "num_output", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "xavier", "=", "False", ",", "relu", "=", "False", ",", "stddev", "=", "0.0001", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDetPlus.SqueezeDetPlus.__init__": [[7, 18], ["tensorflow.device", "nets.nn_skeleton.ModelSkeleton.__init__", "squeezeDetPlus.SqueezeDetPlus._add_forward_graph", "squeezeDetPlus.SqueezeDetPlus._add_interpretation_graph", "squeezeDetPlus.SqueezeDetPlus._add_loss_graph", "squeezeDetPlus.SqueezeDetPlus._add_viz_graph", "squeezeDetPlus.SqueezeDetPlus._add_train_graph"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet.__init__", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._add_forward_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_interpretation_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_loss_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_viz_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_train_graph"], ["  ", "def", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "gpu_id", "=", "0", ",", "base_net", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/job:localhost/replica:0/task:0/device:CPU:0'", ")", ":", "\n", "# with tf.device('/GPU:{}'.format(gpu_id)):", "\n", "      ", "ModelSkeleton", ".", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "base_net", "=", "base_net", ",", "global_step", "=", "global_step", ")", "\n", "# with tf.variable_scope(\"net_%d\"% self.model_id) as scope:", "\n", "self", ".", "_add_forward_graph", "(", ")", "\n", "self", ".", "_add_interpretation_graph", "(", ")", "\n", "self", ".", "_add_loss_graph", "(", ")", "\n", "if", "mc", ".", "IS_TRAINING", ":", "\n", "        ", "self", ".", "_add_train_graph", "(", ")", "\n", "", "self", ".", "_add_viz_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDetPlus.SqueezeDetPlus._add_forward_graph": [[19, 73], ["joblib.load", "squeezeDetPlus.SqueezeDetPlus._conv_layer", "squeezeDetPlus.SqueezeDetPlus._pooling_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._pooling_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._pooling_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "squeezeDetPlus.SqueezeDetPlus._fire_layer", "tensorflow.nn.dropout", "squeezeDetPlus.SqueezeDetPlus._conv_layer", "tensorflow.gfile.Exists"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer"], ["", "", "def", "_add_forward_graph", "(", "self", ",", "base_net", "=", "None", ")", ":", "\n", "    ", "mc", "=", "self", ".", "mc", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "assert", "tf", ".", "gfile", ".", "Exists", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", ",", "'Cannot find pretrained model at the given path:'", "'  {}'", ".", "format", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "", "self", ".", "caffemodel_weight", "=", "joblib", ".", "load", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "conv1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv1'", ",", "self", ".", "image_input", ",", "filters", "=", "96", ",", "size", "=", "7", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'conv1'", "]", ")", "\n", "self", ".", "pool1", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool1'", ",", "conv1", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "self", ".", "fire2", "=", "self", ".", "_fire_layer", "(", "\n", "'fire2'", ",", "self", ".", "pool1", ",", "s1x1", "=", "96", ",", "e1x1", "=", "64", ",", "e3x3", "=", "64", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire2'", "]", ")", "\n", "\n", "self", ".", "fire3", "=", "self", ".", "_fire_layer", "(", "\n", "'fire3'", ",", "self", ".", "fire2", ",", "s1x1", "=", "96", ",", "e1x1", "=", "64", ",", "e3x3", "=", "64", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire3'", "]", ")", "\n", "\n", "self", ".", "fire4", "=", "self", ".", "_fire_layer", "(", "\n", "'fire4'", ",", "self", ".", "fire3", ",", "s1x1", "=", "192", ",", "e1x1", "=", "128", ",", "e3x3", "=", "128", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire4'", "]", ")", "\n", "self", ".", "pool4", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool4'", ",", "self", ".", "fire4", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "\n", "self", ".", "fire5", "=", "self", ".", "_fire_layer", "(", "\n", "'fire5'", ",", "self", ".", "pool4", ",", "s1x1", "=", "192", ",", "e1x1", "=", "128", ",", "e3x3", "=", "128", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire5'", "]", ")", "\n", "self", ".", "fire6", "=", "self", ".", "_fire_layer", "(", "\n", "'fire6'", ",", "self", ".", "fire5", ",", "s1x1", "=", "288", ",", "e1x1", "=", "192", ",", "e3x3", "=", "192", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire6'", "]", ")", "\n", "self", ".", "fire7", "=", "self", ".", "_fire_layer", "(", "\n", "'fire7'", ",", "self", ".", "fire6", ",", "s1x1", "=", "288", ",", "e1x1", "=", "192", ",", "e3x3", "=", "192", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire7'", "]", ")", "\n", "\n", "self", ".", "fire8", "=", "self", ".", "_fire_layer", "(", "\n", "'fire8'", ",", "self", ".", "fire7", ",", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire8'", "]", ")", "\n", "self", ".", "pool8", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool8'", ",", "self", ".", "fire8", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "\n", "self", ".", "fire9", "=", "self", ".", "_fire_layer", "(", "\n", "'fire9'", ",", "self", ".", "pool8", ",", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire9'", "]", ")", "\n", "\n", "# Two extra fire modules that are not trained before", "\n", "self", ".", "fire10", "=", "self", ".", "_fire_layer", "(", "\n", "'fire10'", ",", "self", ".", "fire9", ",", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire10'", "]", ")", "\n", "self", ".", "fire11", "=", "self", ".", "_fire_layer", "(", "\n", "'fire11'", ",", "self", ".", "fire10", ",", "s1x1", "=", "384", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'fire11'", "]", ")", "\n", "self", ".", "dropout11", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "fire11", ",", "self", ".", "keep_prob", ",", "name", "=", "'drop11'", ")", "\n", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "self", ".", "preds", "=", "self", ".", "_conv_layer", "(", "\n", "'conv12'", ",", "self", ".", "dropout11", ",", "filters", "=", "num_output", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "xavier", "=", "False", ",", "relu", "=", "False", ",", "stddev", "=", "0.0001", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "'conv12'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDetPlus.SqueezeDetPlus._fire_layer": [[74, 100], ["squeezeDetPlus.SqueezeDetPlus._conv_layer", "squeezeDetPlus.SqueezeDetPlus._conv_layer", "squeezeDetPlus.SqueezeDetPlus._conv_layer", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer"], ["", "def", "_fire_layer", "(", "self", ",", "layer_name", ",", "inputs", ",", "s1x1", ",", "e1x1", ",", "e3x3", ",", "stddev", "=", "0.01", ",", "\n", "freeze", "=", "False", ")", ":", "\n", "    ", "\"\"\"Fire layer constructor.\n\n    Args:\n      layer_name: layer name\n      inputs: input tensor\n      s1x1: number of 1x1 filters in squeeze layer.\n      e1x1: number of 1x1 filters in expand layer.\n      e3x3: number of 3x3 filters in expand layer.\n      freeze: if true, do not train parameters in this layer.\n    Returns:\n      fire layer operation.\n    \"\"\"", "\n", "\n", "sq1x1", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/squeeze1x1'", ",", "inputs", ",", "filters", "=", "s1x1", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "ex1x1", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/expand1x1'", ",", "sq1x1", ",", "filters", "=", "e1x1", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "ex3x3", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/expand3x3'", ",", "sq1x1", ",", "filters", "=", "e3x3", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "ex1x1", ",", "ex3x3", "]", ",", "3", ",", "name", "=", "layer_name", "+", "'/concat'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet.__init__": [[15, 26], ["tensorflow.device", "nets.nn_skeleton.ModelSkeleton.__init__", "squeezeDet.SqueezeDet._add_forward_graph", "squeezeDet.SqueezeDet._add_interpretation_graph", "squeezeDet.SqueezeDet._add_loss_graph", "squeezeDet.SqueezeDet._add_train_graph", "squeezeDet.SqueezeDet._add_viz_graph"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet.__init__", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._add_forward_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_interpretation_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_loss_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_train_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_viz_graph"], ["  ", "def", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "gpu_id", "=", "0", ",", "base_net", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/job:localhost/replica:0/task:0/device:CPU:0'", ")", ":", "\n", "      ", "ModelSkeleton", ".", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "base_net", "=", "base_net", ",", "global_step", "=", "global_step", ")", "\n", "\n", "self", ".", "_add_forward_graph", "(", ")", "\n", "self", ".", "_add_interpretation_graph", "(", ")", "\n", "self", ".", "_add_loss_graph", "(", ")", "\n", "if", "mc", ".", "IS_TRAINING", ":", "\n", "        ", "self", ".", "_add_train_graph", "(", ")", "\n", "", "if", "mc", ".", "VISUALIZE_ON", ":", "\n", "        ", "self", ".", "_add_viz_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._add_forward_graph": [[27, 78], ["squeezeDet.SqueezeDet._conv_layer", "squeezeDet.SqueezeDet._pooling_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._pooling_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._pooling_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "squeezeDet.SqueezeDet._fire_layer", "tensorflow.nn.dropout", "squeezeDet.SqueezeDet._conv_layer", "tensorflow.gfile.Exists", "joblib.load"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer"], ["", "", "", "def", "_add_forward_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"NN architecture.\"\"\"", "\n", "\n", "mc", "=", "self", ".", "mc", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "assert", "tf", ".", "gfile", ".", "Exists", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", ",", "'Cannot find pretrained model at the given path:'", "'  {}'", ".", "format", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "self", ".", "caffemodel_weight", "=", "joblib", ".", "load", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "", "self", ".", "conv1", "=", "self", ".", "_conv_layer", "(", "\n", "'conv1'", ",", "self", ".", "image_input", ",", "filters", "=", "64", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'SAME'", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"conv1\"", "]", ")", "\n", "self", ".", "pool1", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool1'", ",", "self", ".", "conv1", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "self", ".", "fire2", "=", "self", ".", "_fire_layer", "(", "\n", "'fire2'", ",", "self", ".", "pool1", ",", "s1x1", "=", "16", ",", "e1x1", "=", "64", ",", "e3x3", "=", "64", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire2\"", "]", ")", "\n", "self", ".", "fire3", "=", "self", ".", "_fire_layer", "(", "\n", "'fire3'", ",", "self", ".", "fire2", ",", "s1x1", "=", "16", ",", "e1x1", "=", "64", ",", "e3x3", "=", "64", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire3\"", "]", ")", "\n", "self", ".", "pool3", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool3'", ",", "self", ".", "fire3", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "self", ".", "fire4", "=", "self", ".", "_fire_layer", "(", "\n", "'fire4'", ",", "self", ".", "pool3", ",", "s1x1", "=", "32", ",", "e1x1", "=", "128", ",", "e3x3", "=", "128", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire4\"", "]", ")", "\n", "self", ".", "fire5", "=", "self", ".", "_fire_layer", "(", "\n", "'fire5'", ",", "self", ".", "fire4", ",", "s1x1", "=", "32", ",", "e1x1", "=", "128", ",", "e3x3", "=", "128", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire5\"", "]", ")", "\n", "self", ".", "pool5", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool5'", ",", "self", ".", "fire5", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'SAME'", ")", "\n", "\n", "self", ".", "fire6", "=", "self", ".", "_fire_layer", "(", "\n", "'fire6'", ",", "self", ".", "pool5", ",", "s1x1", "=", "48", ",", "e1x1", "=", "192", ",", "e3x3", "=", "192", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire6\"", "]", ")", "\n", "self", ".", "fire7", "=", "self", ".", "_fire_layer", "(", "\n", "'fire7'", ",", "self", ".", "fire6", ",", "s1x1", "=", "48", ",", "e1x1", "=", "192", ",", "e3x3", "=", "192", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire7\"", "]", ")", "\n", "self", ".", "fire8", "=", "self", ".", "_fire_layer", "(", "\n", "'fire8'", ",", "self", ".", "fire7", ",", "s1x1", "=", "64", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire8\"", "]", ")", "\n", "self", ".", "fire9", "=", "self", ".", "_fire_layer", "(", "\n", "'fire9'", ",", "self", ".", "fire8", ",", "s1x1", "=", "64", ",", "e1x1", "=", "256", ",", "e3x3", "=", "256", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire9\"", "]", ")", "\n", "\n", "# Two extra fire modules that are not trained before", "\n", "self", ".", "fire10", "=", "self", ".", "_fire_layer", "(", "\n", "'fire10'", ",", "self", ".", "fire9", ",", "s1x1", "=", "96", ",", "e1x1", "=", "384", ",", "e3x3", "=", "384", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire10\"", "]", ")", "\n", "self", ".", "fire11", "=", "self", ".", "_fire_layer", "(", "\n", "'fire11'", ",", "self", ".", "fire10", ",", "s1x1", "=", "96", ",", "e1x1", "=", "384", ",", "e3x3", "=", "384", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"fire11\"", "]", ")", "\n", "self", ".", "dropout11", "=", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "fire11", ",", "self", ".", "keep_prob", ",", "name", "=", "'drop11'", ")", "\n", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "self", ".", "preds", "=", "self", ".", "_conv_layer", "(", "\n", "'conv12'", ",", "self", ".", "dropout11", ",", "filters", "=", "num_output", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "xavier", "=", "False", ",", "relu", "=", "False", ",", "stddev", "=", "0.0001", ",", "freeze", "=", "mc", ".", "FREEZE_LAYERS", "[", "\"conv12\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.squeezeDet.SqueezeDet._fire_layer": [[79, 105], ["squeezeDet.SqueezeDet._conv_layer", "squeezeDet.SqueezeDet._conv_layer", "squeezeDet.SqueezeDet._conv_layer", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer"], ["", "def", "_fire_layer", "(", "self", ",", "layer_name", ",", "inputs", ",", "s1x1", ",", "e1x1", ",", "e3x3", ",", "stddev", "=", "0.01", ",", "\n", "freeze", "=", "False", ")", ":", "\n", "    ", "\"\"\"Fire layer constructor.\n\n    Args:\n      layer_name: layer name\n      inputs: input tensor\n      s1x1: number of 1x1 filters in squeeze layer.\n      e1x1: number of 1x1 filters in expand layer.\n      e3x3: number of 3x3 filters in expand layer.\n      freeze: if true, do not train parameters in this layer.\n    Returns:\n      fire layer operation.\n    \"\"\"", "\n", "\n", "sq1x1", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/squeeze1x1'", ",", "inputs", ",", "filters", "=", "s1x1", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "ex1x1", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/expand1x1'", ",", "sq1x1", ",", "filters", "=", "e1x1", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "ex3x3", "=", "self", ".", "_conv_layer", "(", "\n", "layer_name", "+", "'/expand3x3'", ",", "sq1x1", ",", "filters", "=", "e3x3", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "stddev", "=", "stddev", ",", "freeze", "=", "freeze", ")", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "ex1x1", ",", "ex3x3", "]", ",", "3", ",", "name", "=", "layer_name", "+", "'/concat'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton.__init__": [[69, 110], ["tensorflow.stack", "tensorflow.scatter_nd", "tensorflow.train.get_or_create_global_step", "tensorflow.ones_like", "tensorflow.cast"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "base_net", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "self", ".", "mc", "=", "mc", "\n", "\n", "if", "global_step", "!=", "None", ":", "\n", "# self.global_step = tf.Variable(0, name='global_step', trainable=False)", "\n", "      ", "self", ".", "global_step", "=", "global_step", "\n", "", "else", ":", "\n", "      ", "self", ".", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "# a scalar tensor in range (0, 1]. Usually set to 0.5 in training phase and", "\n", "# 1.0 in evaluation phase", "\n", "", "self", ".", "keep_prob", "=", "mc", ".", "KEEP_PROB", "if", "mc", ".", "IS_TRAINING", "else", "1.0", "\n", "\n", "self", ".", "image_input", "=", "record_input", "[", "\"image/decoded\"", "]", "\n", "# A tensor where each element corresponds to a box in an image of a batch of images", "\n", "# and its value is the index of the \"responsible\" anchor box.", "\n", "self", ".", "aidx", "=", "record_input", "[", "\"image/object/bbox/aidx\"", "]", "\n", "self", ".", "paired_aidx_values", "=", "tf", ".", "stack", "(", "[", "tf", ".", "cast", "(", "self", ".", "aidx", ".", "indices", "[", ":", ",", "0", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "self", ".", "aidx", ".", "values", "]", ",", "axis", "=", "1", ")", "\n", "# A tensor where an element is 1 if the corresponding box is \"responsible\"", "\n", "# for detection an object and 0 otherwise.", "\n", "self", ".", "input_mask", "=", "tf", ".", "scatter_nd", "(", "self", ".", "paired_aidx_values", ",", "\n", "tf", ".", "ones_like", "(", "self", ".", "aidx", ".", "values", ")", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", "]", ")", "\n", "\n", "self", ".", "box_input", "=", "{", "\n", "\"image/object/bbox/xmin\"", ":", "record_input", "[", "\"image/object/bbox/xmin\"", "]", ",", "\n", "\"image/object/bbox/xmax\"", ":", "record_input", "[", "\"image/object/bbox/xmax\"", "]", ",", "\n", "\"image/object/bbox/ymin\"", ":", "record_input", "[", "\"image/object/bbox/ymin\"", "]", ",", "\n", "\"image/object/bbox/ymax\"", ":", "record_input", "[", "\"image/object/bbox/ymax\"", "]", "}", "\n", "self", ".", "labels", "=", "record_input", "[", "\"image/object/class/label\"", "]", "\n", "self", ".", "box_delta_input", "=", "record_input", "[", "\"image/object/bbox/deltas\"", "]", "\n", "\n", "if", "(", "mc", ".", "EVAL_WITH_TRAIN", ")", ":", "\n", "      ", "self", ".", "filenames", "=", "record_input", "[", "\"image/filename\"", "]", "\n", "self", ".", "widths", "=", "record_input", "[", "\"image/width\"", "]", "\n", "self", ".", "heights", "=", "record_input", "[", "\"image/height\"", "]", "\n", "\n", "# model parameters", "\n", "", "self", ".", "model_params", "=", "[", "]", "\n", "\n", "self", ".", "viz_op", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_forward_graph": [[111, 114], ["None"], "methods", ["None"], ["", "def", "_add_forward_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"NN architecture specification.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_interpretation_graph": [[115, 266], ["tensorflow.variable_scope", "tensorflow.reshape", "tensorflow.sigmoid", "tensorflow.reshape", "tensorflow.cast", "tensorflow.variable_scope", "tensorflow.name_scope", "nn_skeleton.ModelSkeleton._add_interpretation_graph._tensor_iou"], "methods", ["None"], ["", "def", "_add_interpretation_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"Interpret NN output.\"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'interpret_output'", ")", "as", "scope", ":", "\n", "      ", "preds", "=", "self", ".", "preds", "\n", "# probability", "\n", "num_class_probs", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "mc", ".", "CLASSES", "\n", "self", ".", "pred_class_probs", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "nn", ".", "softmax", "(", "\n", "tf", ".", "reshape", "(", "\n", "preds", "[", ":", ",", ":", ",", ":", ",", ":", "num_class_probs", "]", ",", "\n", "[", "-", "1", ",", "mc", ".", "CLASSES", "]", ")", ")", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", ",", "mc", ".", "CLASSES", "]", ",", "\n", "name", "=", "'pred_class_probs'", ")", "\n", "\n", "# confidence", "\n", "num_confidence_scores", "=", "mc", ".", "ANCHOR_PER_GRID", "+", "num_class_probs", "\n", "self", ".", "pred_conf", "=", "tf", ".", "sigmoid", "(", "\n", "tf", ".", "reshape", "(", "\n", "preds", "[", ":", ",", ":", ",", ":", ",", "num_class_probs", ":", "num_confidence_scores", "]", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", "]", ")", ",", "\n", "name", "=", "'pred_confidence_score'", ")", "\n", "\n", "# bbox_delta", "\n", "self", ".", "pred_box_delta", "=", "tf", ".", "reshape", "(", "\n", "preds", "[", ":", ",", ":", ",", ":", ",", "num_confidence_scores", ":", "]", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", ",", "4", "]", ",", "\n", "name", "=", "'bbox_delta'", ")", "\n", "\n", "# number of objects. Used to normalize bbox and classification loss", "\n", "# self.num_objects = tf.reduce_sum(self.input_mask, name='num_objects')", "\n", "self", ".", "num_objects", "=", "tf", ".", "cast", "(", "tf", ".", "size", "(", "self", ".", "box_input", "[", "\"image/object/bbox/xmin\"", "]", ".", "values", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'bbox'", ")", "as", "scope", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'stretching'", ")", ":", "\n", "        ", "delta_x", ",", "delta_y", ",", "delta_w", ",", "delta_h", "=", "tf", ".", "unstack", "(", "\n", "self", ".", "pred_box_delta", ",", "axis", "=", "2", ")", "\n", "\n", "anchor_x", "=", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "0", "]", "\n", "anchor_y", "=", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "1", "]", "\n", "anchor_w", "=", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "2", "]", "\n", "anchor_h", "=", "mc", ".", "ANCHOR_BOX", "[", ":", ",", "3", "]", "\n", "\n", "box_center_x", "=", "tf", ".", "identity", "(", "\n", "anchor_x", "+", "delta_x", "*", "anchor_w", ",", "name", "=", "'bbox_cx'", ")", "\n", "box_center_y", "=", "tf", ".", "identity", "(", "\n", "anchor_y", "+", "delta_y", "*", "anchor_h", ",", "name", "=", "'bbox_cy'", ")", "\n", "box_width", "=", "tf", ".", "identity", "(", "\n", "anchor_w", "*", "util", ".", "safe_exp", "(", "delta_w", ",", "mc", ".", "EXP_THRESH", ")", ",", "\n", "name", "=", "'bbox_width'", ")", "\n", "box_height", "=", "tf", ".", "identity", "(", "\n", "anchor_h", "*", "util", ".", "safe_exp", "(", "delta_h", ",", "mc", ".", "EXP_THRESH", ")", ",", "\n", "name", "=", "'bbox_height'", ")", "\n", "\n", "self", ".", "_activation_summary", "(", "delta_x", ",", "'delta_x'", ")", "\n", "self", ".", "_activation_summary", "(", "delta_y", ",", "'delta_y'", ")", "\n", "self", ".", "_activation_summary", "(", "delta_w", ",", "'delta_w'", ")", "\n", "self", ".", "_activation_summary", "(", "delta_h", ",", "'delta_h'", ")", "\n", "\n", "self", ".", "_activation_summary", "(", "box_center_x", ",", "'bbox_cx'", ")", "\n", "self", ".", "_activation_summary", "(", "box_center_y", ",", "'bbox_cy'", ")", "\n", "self", ".", "_activation_summary", "(", "box_width", ",", "'bbox_width'", ")", "\n", "self", ".", "_activation_summary", "(", "box_height", ",", "'bbox_height'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'trimming'", ")", ":", "\n", "        ", "xmins", ",", "ymins", ",", "xmaxs", ",", "ymaxs", "=", "util", ".", "bbox_transform", "(", "\n", "[", "box_center_x", ",", "box_center_y", ",", "box_width", ",", "box_height", "]", ")", "\n", "\n", "# The max x position is mc.IMAGE_WIDTH - 1 since we use zero-based", "\n", "# pixels. Same for y.", "\n", "xmins", "=", "tf", ".", "minimum", "(", "\n", "tf", ".", "maximum", "(", "0.0", ",", "xmins", ")", ",", "mc", ".", "IMAGE_WIDTH", "-", "1.0", ",", "name", "=", "'bbox_xmin'", ")", "# shape = [mc.BATCH_SIZE, mc.ANCHORS]", "\n", "self", ".", "_activation_summary", "(", "xmins", ",", "'box_xmin'", ")", "\n", "\n", "ymins", "=", "tf", ".", "minimum", "(", "\n", "tf", ".", "maximum", "(", "0.0", ",", "ymins", ")", ",", "mc", ".", "IMAGE_HEIGHT", "-", "1.0", ",", "name", "=", "'bbox_ymin'", ")", "# shape = [mc.BATCH_SIZE, mc.ANCHORS]", "\n", "self", ".", "_activation_summary", "(", "ymins", ",", "'box_ymin'", ")", "\n", "\n", "xmaxs", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "minimum", "(", "mc", ".", "IMAGE_WIDTH", "-", "1.0", ",", "xmaxs", ")", ",", "0.0", ",", "name", "=", "'bbox_xmax'", ")", "# shape = [mc.BATCH_SIZE, mc.ANCHORS]", "\n", "self", ".", "_activation_summary", "(", "xmaxs", ",", "'box_xmax'", ")", "\n", "\n", "ymaxs", "=", "tf", ".", "maximum", "(", "\n", "tf", ".", "minimum", "(", "mc", ".", "IMAGE_HEIGHT", "-", "1.0", ",", "ymaxs", ")", ",", "0.0", ",", "name", "=", "'bbox_ymax'", ")", "# shape = [mc.BATCH_SIZE, mc.ANCHORS]", "\n", "self", ".", "_activation_summary", "(", "ymaxs", ",", "'box_ymax'", ")", "\n", "\n", "self", ".", "det_boxes", "=", "{", "\"xmins\"", ":", "xmins", ",", "\n", "\"ymins\"", ":", "ymins", ",", "\n", "\"xmaxs\"", ":", "xmaxs", ",", "\n", "\"ymaxs\"", ":", "ymaxs", "}", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "'IOU'", ")", ":", "\n", "      ", "def", "_tensor_iou", "(", "box1", ",", "box2", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'intersection'", ")", ":", "\n", "          ", "xmin", "=", "tf", ".", "maximum", "(", "box1", "[", "\"xmin\"", "]", ",", "box2", "[", "\"xmin\"", "]", ",", "name", "=", "'xmin'", ")", "\n", "ymin", "=", "tf", ".", "maximum", "(", "box1", "[", "\"ymin\"", "]", ",", "box2", "[", "\"ymin\"", "]", ",", "name", "=", "'ymin'", ")", "\n", "xmax", "=", "tf", ".", "minimum", "(", "box1", "[", "\"xmax\"", "]", ",", "box2", "[", "\"xmax\"", "]", ",", "name", "=", "'xmax'", ")", "\n", "ymax", "=", "tf", ".", "minimum", "(", "box1", "[", "\"ymax\"", "]", ",", "box2", "[", "\"ymax\"", "]", ",", "name", "=", "'ymax'", ")", "\n", "\n", "w", "=", "tf", ".", "maximum", "(", "0.0", ",", "xmax", "-", "xmin", ",", "name", "=", "'inter_w'", ")", "\n", "h", "=", "tf", ".", "maximum", "(", "0.0", ",", "ymax", "-", "ymin", ",", "name", "=", "'inter_h'", ")", "\n", "intersection", "=", "tf", ".", "multiply", "(", "w", ",", "h", ",", "name", "=", "'intersection'", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'union'", ")", ":", "\n", "          ", "w1", "=", "tf", ".", "subtract", "(", "box1", "[", "\"xmax\"", "]", ",", "box1", "[", "\"xmin\"", "]", ",", "name", "=", "'w1'", ")", "\n", "h1", "=", "tf", ".", "subtract", "(", "box1", "[", "\"ymax\"", "]", ",", "box1", "[", "\"ymin\"", "]", ",", "name", "=", "'h1'", ")", "\n", "w2", "=", "tf", ".", "subtract", "(", "box2", "[", "\"xmax\"", "]", ",", "box2", "[", "\"xmin\"", "]", ",", "name", "=", "'w2'", ")", "\n", "h2", "=", "tf", ".", "subtract", "(", "box2", "[", "\"ymax\"", "]", ",", "box2", "[", "\"ymin\"", "]", ",", "name", "=", "'h2'", ")", "\n", "\n", "union", "=", "tf", ".", "cast", "(", "w1", "*", "h1", "+", "w2", "*", "h2", "-", "intersection", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "", "return", "tf", ".", "truediv", "(", "tf", ".", "cast", "(", "intersection", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "union", "+", "tf", ".", "constant", "(", "mc", ".", "EPSILON", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "", "mini_ious_values", "=", "_tensor_iou", "(", "\n", "{", "\"xmin\"", ":", "tf", ".", "cast", "(", "tf", ".", "gather_nd", "(", "xmins", ",", "self", ".", "paired_aidx_values", ")", ",", "tf", ".", "float32", ")", ",", "\n", "\"ymin\"", ":", "tf", ".", "cast", "(", "tf", ".", "gather_nd", "(", "ymins", ",", "self", ".", "paired_aidx_values", ")", ",", "tf", ".", "float32", ")", ",", "\n", "\"xmax\"", ":", "tf", ".", "cast", "(", "tf", ".", "gather_nd", "(", "xmaxs", ",", "self", ".", "paired_aidx_values", ")", ",", "tf", ".", "float32", ")", ",", "\n", "\"ymax\"", ":", "tf", ".", "cast", "(", "tf", ".", "gather_nd", "(", "ymaxs", ",", "self", ".", "paired_aidx_values", ")", ",", "tf", ".", "float32", ")", "}", ",", "# predicted boxes", "\n", "{", "\"xmin\"", ":", "tf", ".", "cast", "(", "self", ".", "box_input", "[", "\"image/object/bbox/xmin\"", "]", ".", "values", ",", "tf", ".", "float32", ")", ",", "\n", "\"ymin\"", ":", "tf", ".", "cast", "(", "self", ".", "box_input", "[", "\"image/object/bbox/ymin\"", "]", ".", "values", ",", "tf", ".", "float32", ")", ",", "\n", "\"xmax\"", ":", "tf", ".", "cast", "(", "self", ".", "box_input", "[", "\"image/object/bbox/xmax\"", "]", ".", "values", ",", "tf", ".", "float32", ")", ",", "\n", "\"ymax\"", ":", "tf", ".", "cast", "(", "self", ".", "box_input", "[", "\"image/object/bbox/ymax\"", "]", ".", "values", ",", "tf", ".", "float32", ")", "}", ")", "# input boxes", "\n", "\n", "# after computing the ious of the responsible boxes,", "\n", "# put the values to a large plane containing all anchors which are responsible and those which are not", "\n", "self", ".", "_ious", "=", "tf", ".", "scatter_nd", "(", "self", ".", "paired_aidx_values", ",", "\n", "mini_ious_values", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", "]", ")", "\n", "\n", "self", ".", "_activation_summary", "(", "self", ".", "_ious", ",", "'conf_score'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'probability'", ")", "as", "scope", ":", "\n", "      ", "self", ".", "_activation_summary", "(", "self", ".", "pred_class_probs", ",", "'class_probs'", ")", "\n", "\n", "probs", "=", "tf", ".", "multiply", "(", "\n", "self", ".", "pred_class_probs", ",", "\n", "tf", ".", "reshape", "(", "self", ".", "pred_conf", ",", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", ",", "1", "]", ")", ",", "\n", "name", "=", "'final_class_prob'", ")", "\n", "\n", "self", ".", "_activation_summary", "(", "probs", ",", "'final_class_prob'", ")", "\n", "\n", "self", ".", "det_probs", "=", "tf", ".", "reduce_max", "(", "probs", ",", "axis", "=", "2", ",", "name", "=", "'score'", ")", "\n", "self", ".", "det_class", "=", "tf", ".", "argmax", "(", "probs", ",", "axis", "=", "2", ",", "name", "=", "'class_idx'", ")", "\n", "\n", "self", ".", "_activation_summary", "(", "tf", ".", "gather_nd", "(", "self", ".", "det_class", ",", "self", ".", "paired_aidx_values", ")", ",", "'detected_classes'", ")", "\n", "\n", "# get prediction boxes", "\n", "self", ".", "prediction_boxes", ",", "self", ".", "score", ",", "self", ".", "cls_idx_per_img", ",", "self", ".", "filter_summaries", "=", "self", ".", "filter_prediction", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_loss_graph": [[267, 325], ["tensorflow.cast", "tensorflow.add_n", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.scatter_nd", "tensorflow.truediv", "tensorflow.add_to_collection", "tensorflow.variable_scope", "tensorflow.reduce_mean", "tensorflow.add_to_collection", "tensorflow.summary.scalar", "tensorflow.variable_scope", "tensorflow.unstack", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.gather_nd", "tensorflow.truediv", "tensorflow.add_to_collection", "tensorflow.get_collection", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.ones_like", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.square", "tensorflow.square", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.cast", "tensorflow.constant", "tensorflow.constant", "tensorflow.log", "tensorflow.log", "tensorflow.constant", "tensorflow.cast"], "methods", ["None"], ["", "", "def", "_add_loss_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"Define the loss operation.\"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "\n", "input_mask", "=", "tf", ".", "cast", "(", "self", ".", "input_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'class_regression'", ")", ":", "\n", "# cross-entropy: q * -log(p) + (1-q) * -log(1-p)", "\n", "# add a small value into log to prevent blowing up", "\n", "      ", "classes_sparse_indices", "=", "tf", ".", "concat", "(", "[", "self", ".", "paired_aidx_values", ",", "tf", ".", "expand_dims", "(", "tf", ".", "cast", "(", "self", ".", "labels", ".", "values", ",", "dtype", "=", "tf", ".", "int64", ")", ",", "axis", "=", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "one_hot_labels", "=", "tf", ".", "scatter_nd", "(", "classes_sparse_indices", ",", "\n", "tf", ".", "reshape", "(", "tf", ".", "ones_like", "(", "self", ".", "labels", ".", "values", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "[", "-", "1", "]", ")", ",", "\n", "[", "mc", ".", "BATCH_SIZE", ",", "mc", ".", "ANCHORS", ",", "mc", ".", "CLASSES", "]", ")", "\n", "self", ".", "class_loss", "=", "tf", ".", "truediv", "(", "\n", "tf", ".", "reduce_sum", "(", "\n", "(", "one_hot_labels", "*", "(", "-", "tf", ".", "log", "(", "self", ".", "pred_class_probs", "+", "mc", ".", "EPSILON", ")", ")", "\n", "+", "(", "1.0", "-", "one_hot_labels", ")", "*", "(", "-", "tf", ".", "log", "(", "1", "-", "self", ".", "pred_class_probs", "+", "mc", ".", "EPSILON", ")", ")", ")", "\n", "*", "tf", ".", "expand_dims", "(", "input_mask", ",", "axis", "=", "-", "1", ")", "*", "mc", ".", "LOSS_COEF_CLASS", ")", ",", "\n", "self", ".", "num_objects", ",", "\n", "name", "=", "'class_loss'", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "self", ".", "class_loss", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'confidence_score_regression'", ")", ":", "\n", "      ", "self", ".", "conf_loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "square", "(", "(", "self", ".", "_ious", "-", "self", ".", "pred_conf", ")", ")", "\n", "*", "(", "input_mask", "*", "tf", ".", "constant", "(", "mc", ".", "LOSS_COEF_CONF_POS", ",", "tf", ".", "float32", ")", "/", "self", ".", "num_objects", "\n", "+", "(", "1.0", "-", "input_mask", ")", "*", "\n", "tf", ".", "constant", "(", "mc", ".", "LOSS_COEF_CONF_NEG", ",", "tf", ".", "float32", ")", "/", "\n", "tf", ".", "cast", "(", "tf", ".", "constant", "(", "mc", ".", "ANCHORS", ")", "-", "tf", ".", "cast", "(", "self", ".", "num_objects", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "dtype", "=", "tf", ".", "float32", ")", ")", ",", "\n", "reduction_indices", "=", "[", "1", "]", ")", ",", "\n", "name", "=", "'confidence_loss'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "self", ".", "conf_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'mean iou'", ",", "tf", ".", "reduce_sum", "(", "self", ".", "_ious", ")", "/", "self", ".", "num_objects", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'bounding_box_regression'", ")", ":", "\n", "      ", "delta_x", ",", "delta_y", ",", "delta_w", ",", "delta_h", "=", "tf", ".", "unstack", "(", "\n", "self", ".", "pred_box_delta", ",", "axis", "=", "2", ")", "\n", "_delta_x", "=", "tf", ".", "gather_nd", "(", "delta_x", ",", "self", ".", "paired_aidx_values", ")", "\n", "_delta_y", "=", "tf", ".", "gather_nd", "(", "delta_y", ",", "self", ".", "paired_aidx_values", ")", "\n", "_delta_w", "=", "tf", ".", "gather_nd", "(", "delta_w", ",", "self", ".", "paired_aidx_values", ")", "\n", "_delta_h", "=", "tf", ".", "gather_nd", "(", "delta_h", ",", "self", ".", "paired_aidx_values", ")", "\n", "self", ".", "bbox_loss", "=", "tf", ".", "truediv", "(", "\n", "tf", ".", "reduce_sum", "(", "mc", ".", "LOSS_COEF_BBOX", "*", "tf", ".", "square", "(", "tf", ".", "stack", "(", "[", "\n", "self", ".", "box_delta_input", "[", "\"dx\"", "]", ".", "values", "-", "_delta_x", ",", "\n", "self", ".", "box_delta_input", "[", "\"dy\"", "]", ".", "values", "-", "_delta_y", ",", "\n", "self", ".", "box_delta_input", "[", "\"dw\"", "]", ".", "values", "-", "_delta_w", ",", "\n", "self", ".", "box_delta_input", "[", "\"dh\"", "]", ".", "values", "-", "_delta_h", "]", ")", ")", ")", ",", "\n", "self", ".", "num_objects", ",", "\n", "name", "=", "'bbox_loss'", ")", "\n", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "self", ".", "bbox_loss", ")", "\n", "\n", "# add above losses as well as weight decay losses to form the total loss", "\n", "", "self", ".", "loss", "=", "tf", ".", "add_n", "(", "tf", ".", "get_collection", "(", "'losses'", ")", ",", "name", "=", "'total_loss'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_train_graph": [[326, 361], ["tensorflow.train.exponential_decay", "tensorflow.summary.scalar", "nn_skeleton._add_loss_summaries", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.trainable_variables", "tensorflow.train.MomentumOptimizer", "tensorflow.trainable_variables", "tensorflow.variable_scope", "enumerate", "tensorflow.summary.histogram", "tensorflow.control_dependencies", "tensorflow.no_op", "tensorflow.train.AdamOptimizer", "tensorflow.summary.histogram", "tensorflow.clip_by_norm"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._add_loss_summaries"], ["", "def", "_add_train_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"Define the training operation.\"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "\n", "lr", "=", "tf", ".", "train", ".", "exponential_decay", "(", "mc", ".", "LEARNING_RATE", ",", "\n", "self", ".", "global_step", ",", "\n", "mc", ".", "DECAY_STEPS", ",", "\n", "mc", ".", "LR_DECAY_FACTOR", ",", "\n", "staircase", "=", "True", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "lr", ")", "\n", "\n", "_add_loss_summaries", "(", "self", ".", "loss", ")", "\n", "if", "(", "mc", ".", "OPTIMIZER", "[", "\"TYPE\"", "]", "==", "\"MOMENTUM\"", ")", ":", "\n", "      ", "opt", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", "=", "lr", ",", "momentum", "=", "mc", ".", "OPTIMIZER", "[", "\"MOMENTUM\"", "]", ")", "\n", "", "elif", "(", "mc", ".", "OPTIMIZER", "[", "\"TYPE\"", "]", "==", "\"ADAM\"", ")", ":", "\n", "      ", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "lr", ",", "beta1", "=", "mc", ".", "OPTIMIZER", "[", "\"BETA1\"", "]", ",", "beta2", "=", "mc", ".", "OPTIMIZER", "[", "\"BETA2\"", "]", ")", "\n", "", "grads_vars", "=", "opt", ".", "compute_gradients", "(", "self", ".", "loss", ",", "\n", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'clip_gradient'", ")", "as", "scope", ":", "\n", "      ", "for", "i", ",", "(", "grad", ",", "var", ")", "in", "enumerate", "(", "grads_vars", ")", ":", "\n", "        ", "grads_vars", "[", "i", "]", "=", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "mc", ".", "MAX_GRAD_NORM", ")", ",", "var", ")", "\n", "\n", "", "", "apply_gradient_op", "=", "opt", ".", "apply_gradients", "(", "grads_vars", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "grads_vars", ":", "\n", "      ", "if", "grad", "is", "not", "None", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "'/gradients'", ",", "grad", ")", "\n", "\n", "", "", "with", "tf", ".", "control_dependencies", "(", "[", "apply_gradient_op", "]", ")", ":", "\n", "      ", "self", ".", "train_op", "=", "tf", ".", "no_op", "(", "name", "=", "'train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_viz_graph": [[362, 434], ["tensorflow.name_scope", "tensorflow.stack", "tensorflow.image.draw_bounding_boxes", "range", "tensorflow.reduce_max", "tensorflow.concat", "tensorflow.stack", "tensorflow.image.draw_bounding_boxes", "tensorflow.summary.image", "tensorflow.summary.histogram", "tensorflow.summary.merge", "tensorflow.summary.histogram", "tensorflow.summary.merge", "tensorflow.reverse", "ymins.append", "xmins.append", "ymaxs.append", "xmaxs.append", "tensorflow.size", "_lens.append", "_sparse_indices_per_image.append", "tensorflow.stack", "tensorflow.concat", "tensorflow.constant", "tensorflow.concat", "tensorflow.constant", "tensorflow.concat", "tensorflow.constant", "tensorflow.concat", "tensorflow.constant", "tensorflow.concat", "tensorflow.concat", "tensorflow.stack", "tensorflow.sparse_to_dense", "tensorflow.sparse_to_dense", "tensorflow.sparse_to_dense", "tensorflow.sparse_to_dense", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.constant", "tensorflow.expand_dims", "tensorflow.boolean_mask", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.sparse_tensor_to_dense", "tensorflow.constant", "tensorflow.fill", "tensorflow.range", "tensorflow.equal", "range", "tensorflow.reshape", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.sparse_to_dense"], ["", "", "def", "_add_viz_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"Define the visualization operation.\"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "with", "tf", ".", "name_scope", "(", "\"viz_graph\"", ")", ":", "\n", "# draw ground truth", "\n", "      ", "bounding_boxes1", "=", "tf", ".", "stack", "(", "[", "\n", "tf", ".", "cast", "(", "tf", ".", "sparse_tensor_to_dense", "(", "\n", "self", ".", "box_input", "[", "\"image/object/bbox/ymin\"", "]", ")", ",", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "sparse_tensor_to_dense", "(", "\n", "self", ".", "box_input", "[", "\"image/object/bbox/xmin\"", "]", ")", ",", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "sparse_tensor_to_dense", "(", "\n", "self", ".", "box_input", "[", "\"image/object/bbox/ymax\"", "]", ")", ",", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "sparse_tensor_to_dense", "(", "\n", "self", ".", "box_input", "[", "\"image/object/bbox/xmax\"", "]", ")", ",", "tf", ".", "float32", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "ground_truth_drawn", "=", "tf", ".", "image", ".", "draw_bounding_boxes", "(", "\n", "tf", ".", "reverse", "(", "\n", "self", ".", "image_input", "+", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "constant", "(", "mc", ".", "BGR_MEANS", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "axis", "=", "0", ")", ",", "\n", "axis", "=", "[", "-", "1", "]", ")", ",", "\n", "bounding_boxes1", ")", "\n", "# make prediction boxes dense", "\n", "ymins", ",", "xmins", ",", "ymaxs", ",", "xmaxs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "_sparse_indices_per_image", "=", "[", "]", "\n", "_lens", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", ":", "\n", "        ", "ymins", ".", "append", "(", "self", ".", "prediction_boxes", "[", "i", "]", "[", "\"ymins\"", "]", ")", "\n", "xmins", ".", "append", "(", "self", ".", "prediction_boxes", "[", "i", "]", "[", "\"xmins\"", "]", ")", "\n", "ymaxs", ".", "append", "(", "self", ".", "prediction_boxes", "[", "i", "]", "[", "\"ymaxs\"", "]", ")", "\n", "xmaxs", ".", "append", "(", "self", ".", "prediction_boxes", "[", "i", "]", "[", "\"xmaxs\"", "]", ")", "\n", "# In order to draw bounding boxes a dense structure is required.", "\n", "# To describe the bounding boxes, each of their dimensions should be", "\n", "# in the range of [0,1]", "\n", "_len", "=", "tf", ".", "size", "(", "ymins", "[", "i", "]", ")", "\n", "_lens", ".", "append", "(", "_len", ")", "\n", "_sparse_indices_per_image", ".", "append", "(", "\n", "tf", ".", "stack", "(", "[", "tf", ".", "fill", "(", "tf", ".", "reshape", "(", "_len", ",", "[", "1", "]", ")", ",", "i", ")", ",", "\n", "tf", ".", "range", "(", "_len", ")", "]", ",", "\n", "axis", "=", "-", "1", ")", ")", "\n", "", "_max_len", "=", "tf", ".", "reduce_max", "(", "tf", ".", "stack", "(", "_lens", ")", ")", "\n", "_sparse_indices", "=", "tf", ".", "concat", "(", "_sparse_indices_per_image", ",", "axis", "=", "0", ")", "\n", "_ymins", "=", "tf", ".", "concat", "(", "ymins", ",", "axis", "=", "0", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", "\n", "_xmins", "=", "tf", ".", "concat", "(", "xmins", ",", "axis", "=", "0", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", "\n", "_ymaxs", "=", "tf", ".", "concat", "(", "ymaxs", ",", "axis", "=", "0", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", "\n", "_xmaxs", "=", "tf", ".", "concat", "(", "xmaxs", ",", "axis", "=", "0", ")", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", "\n", "bounding_boxes2", "=", "tf", ".", "stack", "(", "\n", "[", "tf", ".", "sparse_to_dense", "(", "_sparse_indices", ",", "[", "mc", ".", "BATCH_SIZE", ",", "_max_len", "]", ",", "_ymins", ")", ",", "\n", "tf", ".", "sparse_to_dense", "(", "_sparse_indices", ",", "[", "mc", ".", "BATCH_SIZE", ",", "_max_len", "]", ",", "_xmins", ")", ",", "\n", "tf", ".", "sparse_to_dense", "(", "_sparse_indices", ",", "[", "mc", ".", "BATCH_SIZE", ",", "_max_len", "]", ",", "_ymaxs", ")", ",", "\n", "tf", ".", "sparse_to_dense", "(", "_sparse_indices", ",", "[", "mc", ".", "BATCH_SIZE", ",", "_max_len", "]", ",", "_xmaxs", ")", "]", ",", "\n", "axis", "=", "2", ")", "\n", "\n", "# draw prediction boxes", "\n", "self", ".", "all_boxes_drawn", "=", "tf", ".", "image", ".", "draw_bounding_boxes", "(", "ground_truth_drawn", ",", "bounding_boxes2", ")", "\n", "\n", "self", ".", "viz_op", "=", "tf", ".", "summary", ".", "image", "(", "'sample_detection_results'", ",", "\n", "self", ".", "all_boxes_drawn", ",", "collections", "=", "'image_summary'", ",", "\n", "max_outputs", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "# add summary for the detected classes", "\n", "cls_summary", "=", "tf", ".", "summary", ".", "histogram", "(", "\"detected_cls_idx\"", ",", "tf", ".", "concat", "(", "[", "cls_idx", "for", "cls_idx", "in", "self", ".", "cls_idx_per_img", "]", ",", "axis", "=", "0", ")", ",", "collections", "=", "'image_summary'", ")", "\n", "self", ".", "viz_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "self", ".", "viz_op", ",", "cls_summary", "]", ")", "\n", "# add summary for the ground trouth classes", "\n", "cls_summary", "=", "tf", ".", "summary", ".", "histogram", "(", "\"ground_truth_cls_idx\"", ",", "\n", "tf", ".", "concat", "(", "[", "tf", ".", "boolean_mask", "(", "self", ".", "labels", ".", "values", ",", "tf", ".", "equal", "(", "self", ".", "labels", ".", "indices", "[", ":", ",", "0", "]", ",", "tf", ".", "constant", "(", "i", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", "]", ",", "axis", "=", "0", ")", ",", "collections", "=", "'image_summary'", ")", "\n", "self", ".", "viz_op", "=", "tf", ".", "summary", ".", "merge", "(", "[", "self", ".", "viz_op", ",", "cls_summary", ",", "self", ".", "filter_summaries", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer": [[435, 525], ["print", "tensorflow.variable_scope", "nn_skeleton._variable_with_weight_decay", "nn_skeleton._variable_on_device", "tensorflow.nn.conv2d", "tensorflow.nn.bias_add", "tensorflow.nn.relu.get_shape().as_list", "numpy.transpose", "print", "inputs.get_shape", "tensorflow.constant", "tensorflow.constant", "print", "inputs.get_shape", "print", "tensorflow.contrib.layers.xavier_initializer_conv2d", "tensorflow.constant_initializer", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "tensorflow.nn.leaky_relu", "tensorflow.nn.relu", "tensorflow.nn.relu.get_shape", "print", "int", "inputs.get_shape().as_list", "inputs.get_shape", "int"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_with_weight_decay", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_on_device"], ["", "", "def", "_conv_layer", "(", "\n", "self", ",", "layer_name", ",", "inputs", ",", "filters", ",", "size", ",", "stride", ",", "padding", "=", "'SAME'", ",", "\n", "freeze", "=", "False", ",", "xavier", "=", "False", ",", "relu", "=", "True", ",", "stddev", "=", "0.001", ")", ":", "\n", "    ", "\"\"\"Convolutional layer operation constructor.\n\n    Args:\n      layer_name: layer name.\n      inputs: input tensor\n      filters: number of output filters.\n      size: kernel size.\n      stride: stride\n      padding: 'SAME' or 'VALID'. See tensorflow doc for detailed description.\n      freeze: if true, then do not train the parameters in this layer.\n      xavier: whether to use xavier weight initializer or not.\n      relu: whether to use relu or not.\n      stddev: standard deviation used for random weight initializer.\n    Returns:\n      A convolutional layer operation.\n    \"\"\"", "\n", "\n", "mc", "=", "self", ".", "mc", "\n", "use_pretrained_param", "=", "False", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "cw", "=", "self", ".", "caffemodel_weight", "\n", "if", "layer_name", "in", "cw", ":", "\n", "        ", "kernel_val", "=", "np", ".", "transpose", "(", "cw", "[", "layer_name", "]", "[", "0", "]", ",", "[", "2", ",", "3", ",", "1", ",", "0", "]", ")", "\n", "bias_val", "=", "cw", "[", "layer_name", "]", "[", "1", "]", "\n", "# check the shape", "\n", "if", "(", "kernel_val", ".", "shape", "==", "\n", "(", "size", ",", "size", ",", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "filters", ")", ")", "and", "(", "bias_val", ".", "shape", "==", "(", "filters", ",", ")", ")", ":", "\n", "          ", "use_pretrained_param", "=", "True", "\n", "", "else", ":", "\n", "          ", "print", "(", "'Shape of the pretrained parameter of {} does not match, '", "\n", "'use randomly initialized parameter'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Cannot find {} in the pretrained model. Using randomly initialized '", "\n", "'parameters'", ".", "format", "(", "layer_name", ")", ")", "\n", "\n", "", "", "if", "mc", ".", "DEBUG_MODE", ":", "\n", "      ", "print", "(", "'Input tensor shape to {}: {}'", ".", "format", "(", "layer_name", ",", "inputs", ".", "get_shape", "(", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", "as", "scope", ":", "\n", "      ", "channels", "=", "inputs", ".", "get_shape", "(", ")", "[", "3", "]", "\n", "\n", "# re-order the caffe kernel with shape [out, in, h, w] -> tf kernel with", "\n", "# shape [h, w, in, out]", "\n", "if", "use_pretrained_param", ":", "\n", "        ", "if", "mc", ".", "DEBUG_MODE", ":", "\n", "          ", "print", "(", "'Using pretrained model for {}'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "kernel_init", "=", "tf", ".", "constant", "(", "kernel_val", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias_init", "=", "tf", ".", "constant", "(", "bias_val", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "xavier", ":", "\n", "        ", "kernel_init", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", ")", "\n", "bias_init", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "", "else", ":", "\n", "        ", "if", "mc", ".", "DEBUG_MODE", ":", "\n", "          ", "print", "(", "'Using randomly initialized parameters for {}'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "kernel_init", "=", "tf", ".", "truncated_normal_initializer", "(", "\n", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias_init", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "\n", "", "kernel", "=", "_variable_with_weight_decay", "(", "\n", "'kernels'", ",", "shape", "=", "[", "size", ",", "size", ",", "int", "(", "channels", ")", ",", "filters", "]", ",", "\n", "wd", "=", "mc", ".", "WEIGHT_DECAY", ",", "initializer", "=", "kernel_init", ",", "trainable", "=", "(", "not", "freeze", ")", ")", "\n", "\n", "biases", "=", "_variable_on_device", "(", "'biases'", ",", "[", "filters", "]", ",", "bias_init", ",", "\n", "trainable", "=", "(", "not", "freeze", ")", ")", "\n", "self", ".", "model_params", "+=", "[", "kernel", ",", "biases", "]", "\n", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "\n", "inputs", ",", "kernel", ",", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "padding", ",", "\n", "name", "=", "'convolution'", ")", "\n", "conv_bias", "=", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "biases", ",", "name", "=", "'bias_add'", ")", "\n", "\n", "if", "relu", ":", "\n", "        ", "if", "mc", ".", "LEAKY_RELU", ":", "\n", "          ", "out", "=", "tf", ".", "nn", ".", "leaky_relu", "(", "conv_bias", ",", "mc", ".", "LEAKY_COEF", ",", "'relu'", ")", "\n", "", "else", ":", "\n", "          ", "out", "=", "tf", ".", "nn", ".", "relu", "(", "conv_bias", ",", "'relu'", ")", "\n", "", "", "else", ":", "\n", "        ", "out", "=", "conv_bias", "\n", "\n", "", "out_shape", "=", "out", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "num_flops", "=", "(", "1", "+", "2", "*", "int", "(", "channels", ")", "*", "size", "*", "size", ")", "*", "filters", "*", "out_shape", "[", "1", "]", "*", "out_shape", "[", "2", "]", "\n", "if", "relu", ":", "\n", "        ", "num_flops", "+=", "2", "*", "filters", "*", "out_shape", "[", "1", "]", "*", "out_shape", "[", "2", "]", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer": [[526, 548], ["tensorflow.variable_scope", "tensorflow.nn.max_pool", "numpy.prod", "tensorflow.nn.max_pool.get_shape().as_list", "tensorflow.nn.max_pool.get_shape"], "methods", ["None"], ["", "", "def", "_pooling_layer", "(", "\n", "self", ",", "layer_name", ",", "inputs", ",", "size", ",", "stride", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "\"\"\"Pooling layer operation constructor.\n\n    Args:\n      layer_name: layer name.\n      inputs: input tensor\n      size: kernel size.\n      stride: stride\n      padding: 'SAME' or 'VALID'. See tensorflow doc for detailed description.\n    Returns:\n      A pooling layer operation.\n    \"\"\"", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", "as", "scope", ":", "\n", "      ", "out", "=", "tf", ".", "nn", ".", "max_pool", "(", "inputs", ",", "\n", "ksize", "=", "[", "1", ",", "size", ",", "size", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "\n", "padding", "=", "padding", ")", "\n", "activation_size", "=", "np", ".", "prod", "(", "out", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._fc_layer": [[550, 650], ["print", "tensorflow.variable_scope", "tensorflow.reshape.get_shape().as_list", "nn_skeleton._variable_with_weight_decay", "nn_skeleton._variable_on_device", "tensorflow.nn.bias_add", "tensorflow.reshape", "tensorflow.constant", "tensorflow.constant", "tensorflow.matmul", "tensorflow.nn.relu", "tensorflow.reshape.get_shape", "tensorflow.reshape.get_shape", "print", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.constant_initializer", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "numpy.reshape", "numpy.transpose", "numpy.transpose", "print", "print", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_with_weight_decay", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_on_device"], ["", "", "def", "_fc_layer", "(", "\n", "self", ",", "layer_name", ",", "inputs", ",", "hiddens", ",", "flatten", "=", "False", ",", "relu", "=", "True", ",", "\n", "xavier", "=", "False", ",", "stddev", "=", "0.001", ")", ":", "\n", "    ", "\"\"\"Fully connected layer operation constructor.\n\n    Args:\n      layer_name: layer name.\n      inputs: input tensor\n      hiddens: number of (hidden) neurons in this layer.\n      flatten: if true, reshape the input 4D tensor of shape \n          (batch, height, weight, channel) into a 2D tensor with shape \n          (batch, -1). This is used when the input to the fully connected layer\n          is output of a convolutional layer.\n      relu: whether to use relu or not.\n      xavier: whether to use xavier weight initializer or not.\n      stddev: standard deviation used for random weight initializer.\n    Returns:\n      A fully connected layer operation.\n    \"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "\n", "use_pretrained_param", "=", "False", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "cw", "=", "self", ".", "caffemodel_weight", "\n", "if", "layer_name", "in", "cw", ":", "\n", "        ", "use_pretrained_param", "=", "True", "\n", "kernel_val", "=", "cw", "[", "layer_name", "]", "[", "0", "]", "\n", "bias_val", "=", "cw", "[", "layer_name", "]", "[", "1", "]", "\n", "\n", "", "", "if", "mc", ".", "DEBUG_MODE", ":", "\n", "      ", "print", "(", "'Input tensor shape to {}: {}'", ".", "format", "(", "layer_name", ",", "inputs", ".", "get_shape", "(", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "layer_name", ")", "as", "scope", ":", "\n", "      ", "input_shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "flatten", ":", "\n", "        ", "dim", "=", "input_shape", "[", "1", "]", "*", "input_shape", "[", "2", "]", "*", "input_shape", "[", "3", "]", "\n", "inputs", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "dim", "]", ")", "\n", "if", "use_pretrained_param", ":", "\n", "          ", "try", ":", "\n", "# check the size before layout transform", "\n", "            ", "assert", "kernel_val", ".", "shape", "==", "(", "hiddens", ",", "dim", ")", ",", "'kernel shape error at {}'", ".", "format", "(", "layer_name", ")", "\n", "kernel_val", "=", "np", ".", "reshape", "(", "\n", "np", ".", "transpose", "(", "\n", "np", ".", "reshape", "(", "\n", "kernel_val", ",", "# O x (C*H*W)", "\n", "(", "hiddens", ",", "input_shape", "[", "3", "]", ",", "input_shape", "[", "1", "]", ",", "input_shape", "[", "2", "]", ")", "\n", ")", ",", "# O x C x H x W", "\n", "(", "2", ",", "3", ",", "1", ",", "0", ")", "\n", ")", ",", "# H x W x C x O", "\n", "(", "dim", ",", "-", "1", ")", "\n", ")", "# (H*W*C) x O", "\n", "# check the size after layout transform", "\n", "assert", "kernel_val", ".", "shape", "==", "(", "dim", ",", "hiddens", ")", ",", "'kernel shape error at {}'", ".", "format", "(", "layer_name", ")", "\n", "", "except", ":", "\n", "# Do not use pretrained parameter if shape doesn't match", "\n", "            ", "use_pretrained_param", "=", "False", "\n", "print", "(", "'Shape of the pretrained parameter of {} does not match, '", "\n", "'use randomly initialized parameter'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "dim", "=", "input_shape", "[", "1", "]", "\n", "if", "use_pretrained_param", ":", "\n", "          ", "try", ":", "\n", "            ", "kernel_val", "=", "np", ".", "transpose", "(", "kernel_val", ",", "(", "1", ",", "0", ")", ")", "\n", "assert", "kernel_val", ".", "shape", "==", "(", "dim", ",", "hiddens", ")", ",", "'kernel shape error at {}'", ".", "format", "(", "layer_name", ")", "\n", "", "except", ":", "\n", "            ", "use_pretrained_param", "=", "False", "\n", "print", "(", "'Shape of the pretrained parameter of {} does not match, '", "\n", "'use randomly initialized parameter'", ".", "format", "(", "layer_name", ")", ")", "\n", "\n", "", "", "", "if", "use_pretrained_param", ":", "\n", "        ", "if", "mc", ".", "DEBUG_MODE", ":", "\n", "          ", "print", "(", "'Using pretrained model for {}'", ".", "format", "(", "layer_name", ")", ")", "\n", "", "kernel_init", "=", "tf", ".", "constant", "(", "kernel_val", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias_init", "=", "tf", ".", "constant", "(", "bias_val", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "elif", "xavier", ":", "\n", "        ", "kernel_init", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "bias_init", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "", "else", ":", "\n", "        ", "kernel_init", "=", "tf", ".", "truncated_normal_initializer", "(", "\n", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias_init", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "\n", "", "weights", "=", "_variable_with_weight_decay", "(", "\n", "'weights'", ",", "shape", "=", "[", "dim", ",", "hiddens", "]", ",", "wd", "=", "mc", ".", "WEIGHT_DECAY", ",", "\n", "initializer", "=", "kernel_init", ")", "\n", "biases", "=", "_variable_on_device", "(", "'biases'", ",", "[", "hiddens", "]", ",", "bias_init", ")", "\n", "self", ".", "model_params", "+=", "[", "weights", ",", "biases", "]", "\n", "\n", "outputs", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "inputs", ",", "weights", ")", ",", "biases", ")", "\n", "if", "relu", ":", "\n", "        ", "outputs", "=", "tf", ".", "nn", ".", "relu", "(", "outputs", ",", "'relu'", ")", "\n", "\n", "", "num_flops", "=", "2", "*", "dim", "*", "hiddens", "+", "hiddens", "\n", "if", "relu", ":", "\n", "        ", "num_flops", "+=", "2", "*", "hiddens", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton.filter_prediction": [[651, 762], ["tensorflow.name_scope", "tensorflow.summary.merge", "tensorflow.name_scope", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.unstack", "tensorflow.summary.histogram", "tensorflow.name_scope", "range", "tensorflow.summary.histogram", "tensorflow.contrib.framework.argsort", "tensorflow.gather", "tensorflow.gather", "tensorflow.concat", "tensorflow.unstack", "range", "tensorflow.concat", "cls_probs_per_img_before_plot_prob.append", "tensorflow.concat", "cls_idx_per_img_before_plot_prob.append", "final_boxes_per_img.append", "final_probs_per_img.append", "final_cls_idx_per_img.append", "tensorflow.concat", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "range", "range", "tensorflow.gather", "tensorflow.equal", "ymins_per_cls.append", "xmins_per_cls.append", "ymaxs_per_cls.append", "xmaxs_per_cls.append", "unstacked_probs_per_cls.append", "selected_indices_per_cls.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "range", "range", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.gather", "tensorflow.gather", "tensorflow.fill", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.image.non_max_suppression", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "tensorflow.gather", "range", "range", "tensorflow.shape", "range", "range", "range", "range", "range", "tensorflow.stack", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["", "", "def", "filter_prediction", "(", "self", ")", ":", "\n", "    ", "\"\"\"Filter bounding box predictions with probability threshold and\n    non-maximum supression.\n    Returns:\n      final_boxes: 2D array [BATCH_SIZE] of tensors with filtered bounding boxes.\n      final_probs: 2D array [BATCH_SIZE] of tensors with filtered probabilities.\n      final_cls_idx: 2D array [BATCH_SIZE] of tensors with filtered class indices.\n      s: a summary operation\n    \"\"\"", "\n", "mc", "=", "self", ".", "mc", "\n", "with", "tf", ".", "name_scope", "(", "\"filter_prediction\"", ")", ":", "\n", "### probability threshold", "\n", "# get top N boxes which have greater propability", "\n", "      ", "with", "tf", ".", "name_scope", "(", "\"probability_threshold\"", ")", ":", "\n", "        ", "order", "=", "tf", ".", "contrib", ".", "framework", ".", "argsort", "(", "self", ".", "det_probs", ",", "axis", "=", "1", ",", "direction", "=", "'ASCENDING'", ")", "[", ":", "mc", ".", "BATCH_SIZE", ",", ":", "-", "mc", ".", "TOP_N_DETECTION", "-", "1", ":", "-", "1", "]", "\n", "\n", "# unstack the order array in order to use it for each image separatelly", "\n", "unstacked_order", "=", "tf", ".", "unstack", "(", "order", ",", "axis", "=", "0", ",", "num", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "# for probs", "\n", "unstacked_det_probs", "=", "tf", ".", "unstack", "(", "self", ".", "det_probs", ",", "axis", "=", "0", ",", "num", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "unstacked_probs", "=", "[", "tf", ".", "gather", "(", "unstacked_det_probs", "[", "i", "]", ",", "unstacked_order", "[", "i", "]", ",", "axis", "=", "0", ")", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", "]", "\n", "\n", "# for class indicators", "\n", "unstacked_cls_idx", "=", "tf", ".", "unstack", "(", "self", ".", "det_class", ",", "axis", "=", "0", ",", "num", "=", "mc", ".", "BATCH_SIZE", ")", "\n", "unstacked_ordered_cls_idx", "=", "[", "tf", ".", "gather", "(", "unstacked_cls_idx", "[", "i", "]", ",", "unstacked_order", "[", "i", "]", ",", "axis", "=", "-", "1", ")", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", "]", "\n", "s1", "=", "tf", ".", "summary", ".", "histogram", "(", "\"unstacked_ordered_cls_idx\"", ",", "tf", ".", "concat", "(", "unstacked_ordered_cls_idx", ",", "axis", "=", "0", ")", ",", "collections", "=", "\"image_summary\"", ")", "\n", "# for the boxes", "\n", "unstacked_boxes", "=", "{", "tens_name", ":", "tf", ".", "unstack", "(", "self", ".", "det_boxes", "[", "tens_name", "]", ",", "axis", "=", "0", ")", "for", "tens_name", "in", "self", ".", "det_boxes", "}", "\n", "unstacked_ordered_boxes", "=", "{", "tens_name", ":", "[", "tf", ".", "gather", "(", "unstacked_boxes", "[", "tens_name", "]", "[", "i", "]", ",", "\n", "unstacked_order", "[", "i", "]", ",", "\n", "axis", "=", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", "]", "\n", "for", "tens_name", "in", "unstacked_boxes", "}", "\n", "### NMS threshold", "\n", "", "with", "tf", ".", "name_scope", "(", "\"NMS_threshold\"", ")", ":", "\n", "# get boxes regarding each class and image", "\n", "        ", "final_boxes_per_img", "=", "[", "]", "\n", "final_probs_per_img", "=", "[", "]", "\n", "final_cls_idx_per_img", "=", "[", "]", "\n", "cls_idx_per_img_before_plot_prob", "=", "[", "]", "\n", "cls_probs_per_img_before_plot_prob", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "mc", ".", "BATCH_SIZE", ")", ":", "\n", "          ", "class_mask_per_image", "=", "[", "tf", ".", "equal", "(", "unstacked_ordered_cls_idx", "[", "i", "]", ",", "c", ")", "\n", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", "\n", "selected_indices_per_cls", "=", "[", "]", "\n", "ymins_per_cls", ",", "xmins_per_cls", ",", "ymaxs_per_cls", ",", "xmaxs_per_cls", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "unstacked_probs_per_cls", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", ":", "\n", "            ", "class_mask", "=", "class_mask_per_image", "[", "c", "]", "\n", "ymins_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "unstacked_ordered_boxes", "[", "\"ymins\"", "]", "[", "i", "]", ",", "class_mask", ")", ",", "\n", "[", "-", "1", "]", ")", ")", "\n", "xmins_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "unstacked_ordered_boxes", "[", "\"xmins\"", "]", "[", "i", "]", ",", "class_mask", ")", ",", "\n", "[", "-", "1", "]", ")", ")", "\n", "ymaxs_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "unstacked_ordered_boxes", "[", "\"ymaxs\"", "]", "[", "i", "]", ",", "class_mask", ")", ",", "\n", "[", "-", "1", "]", ")", ")", "\n", "xmaxs_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "unstacked_ordered_boxes", "[", "\"xmaxs\"", "]", "[", "i", "]", ",", "class_mask", ")", ",", "\n", "[", "-", "1", "]", ")", ")", "\n", "unstacked_probs_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "unstacked_probs", "[", "i", "]", ",", "class_mask", ")", ",", "\n", "[", "-", "1", "]", ")", ")", "\n", "selected_indices_per_cls", ".", "append", "(", "\n", "tf", ".", "reshape", "(", "tf", ".", "image", ".", "non_max_suppression", "(", "\n", "boxes", "=", "tf", ".", "stack", "(", "[", "ymins_per_cls", "[", "c", "]", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", ",", "\n", "xmins_per_cls", "[", "c", "]", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", ",", "\n", "ymaxs_per_cls", "[", "c", "]", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_HEIGHT", ",", "tf", ".", "float32", ")", ",", "\n", "xmaxs_per_cls", "[", "c", "]", "/", "tf", ".", "constant", "(", "mc", ".", "IMAGE_WIDTH", ",", "tf", ".", "float32", ")", "]", ",", "\n", "axis", "=", "1", ")", ",", "\n", "scores", "=", "unstacked_probs_per_cls", "[", "c", "]", ",", "\n", "max_output_size", "=", "mc", ".", "TOP_N_DETECTION", ",", "\n", "iou_threshold", "=", "mc", ".", "NMS_THRESH", ")", ",", "[", "-", "1", "]", ")", ")", "\n", "", "_final_boxes_per_img", "=", "{", "\n", "\"ymins\"", ":", "tf", ".", "concat", "(", "[", "tf", ".", "gather", "(", "ymins_per_cls", "[", "c", "]", ",", "\n", "selected_indices_per_cls", "[", "c", "]", ")", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", ",", "\n", "\"xmins\"", ":", "tf", ".", "concat", "(", "[", "tf", ".", "gather", "(", "xmins_per_cls", "[", "c", "]", ",", "\n", "selected_indices_per_cls", "[", "c", "]", ")", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", ",", "\n", "\"ymaxs\"", ":", "tf", ".", "concat", "(", "[", "tf", ".", "gather", "(", "ymaxs_per_cls", "[", "c", "]", ",", "\n", "selected_indices_per_cls", "[", "c", "]", ")", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", ",", "\n", "\"xmaxs\"", ":", "tf", ".", "concat", "(", "[", "tf", ".", "gather", "(", "xmaxs_per_cls", "[", "c", "]", ",", "\n", "selected_indices_per_cls", "[", "c", "]", ")", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", "}", "\n", "_final_probs_per_img", "=", "tf", ".", "concat", "(", "[", "tf", ".", "gather", "(", "unstacked_probs_per_cls", "[", "c", "]", ",", "selected_indices_per_cls", "[", "c", "]", ")", "\n", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", "\n", "cls_probs_per_img_before_plot_prob", ".", "append", "(", "[", "tf", ".", "gather", "(", "unstacked_probs_per_cls", "[", "c", "]", ",", "selected_indices_per_cls", "[", "c", "]", ")", "\n", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ")", "\n", "_final_cls_idx_per_img", "=", "tf", ".", "concat", "(", "[", "tf", ".", "fill", "(", "tf", ".", "shape", "(", "selected_indices_per_cls", "[", "c", "]", ")", ",", "c", ")", "for", "c", "in", "range", "(", "mc", ".", "CLASSES", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "cls_idx_per_img_before_plot_prob", ".", "append", "(", "_final_cls_idx_per_img", ")", "\n", "# filter again using the plotting probability", "\n", "# plot_prob_mask = tf.greater(_final_probs_per_img, mc.PLOT_PROB_THRESH)", "\n", "final_boxes_per_img", ".", "append", "(", "_final_boxes_per_img", ")", "\n", "# {", "\n", "#     \"ymins\" : tf.boolean_mask(_final_boxes_per_img[\"ymins\"], plot_prob_mask),", "\n", "#     \"xmins\" : tf.boolean_mask(_final_boxes_per_img[\"xmins\"], plot_prob_mask),", "\n", "#     \"ymaxs\" : tf.boolean_mask(_final_boxes_per_img[\"ymaxs\"], plot_prob_mask),", "\n", "#     \"xmaxs\" : tf.boolean_mask(_final_boxes_per_img[\"xmaxs\"], plot_prob_mask)})", "\n", "\n", "# final_probs_per_img.append(tf.boolean_mask(_final_probs_per_img, plot_prob_mask))", "\n", "final_probs_per_img", ".", "append", "(", "_final_probs_per_img", ")", "\n", "# final_cls_idx_per_img.append(tf.boolean_mask(_final_cls_idx_per_img, plot_prob_mask))", "\n", "final_cls_idx_per_img", ".", "append", "(", "_final_cls_idx_per_img", ")", "\n", "", "s2", "=", "tf", ".", "summary", ".", "histogram", "(", "\"cls_idx_per_img_before_plot_prob\"", ",", "tf", ".", "concat", "(", "cls_idx_per_img_before_plot_prob", ",", "axis", "=", "0", ")", ",", "collections", "=", "\"image_summary\"", ")", "\n", "s3", "=", "[", "tf", ".", "summary", ".", "histogram", "(", "\"cls_probs_bef_p_p_0\"", ",", "tf", ".", "concat", "(", "[", "sc", "[", "0", "]", "for", "sc", "in", "cls_probs_per_img_before_plot_prob", "]", ",", "axis", "=", "0", ")", ")", ",", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cls_probs_bef_p_p_1\"", ",", "tf", ".", "concat", "(", "[", "sc", "[", "1", "]", "for", "sc", "in", "cls_probs_per_img_before_plot_prob", "]", ",", "axis", "=", "0", ")", ")", ",", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"cls_probs_bef_p_p_2\"", ",", "tf", ".", "concat", "(", "[", "sc", "[", "2", "]", "for", "sc", "in", "cls_probs_per_img_before_plot_prob", "]", ",", "axis", "=", "0", ")", ")", "]", "\n", "\n", "", "", "return", "final_boxes_per_img", ",", "final_probs_per_img", ",", "final_cls_idx_per_img", ",", "tf", ".", "summary", ".", "merge", "(", "[", "s1", ",", "s2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._activation_summary": [[763, 783], ["tensorflow.variable_scope", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.nn.zero_fraction", "tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reduce_min"], "methods", ["None"], ["", "def", "_activation_summary", "(", "self", ",", "x", ",", "layer_name", ")", ":", "\n", "    ", "\"\"\"Helper to create summaries for activations.\n\n    Args:\n      x: layer output tensor\n      layer_name: name of the layer\n    Returns:\n      nothing\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'activation_summary'", ")", ":", "\n", "      ", "tf", ".", "summary", ".", "histogram", "(", "\n", "'activation_summary/'", "+", "layer_name", ",", "x", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "'activation_summary/'", "+", "layer_name", "+", "'/sparsity'", ",", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "'activation_summary/'", "+", "layer_name", "+", "'/average'", ",", "tf", ".", "reduce_mean", "(", "x", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "'activation_summary/'", "+", "layer_name", "+", "'/max'", ",", "tf", ".", "reduce_max", "(", "x", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\n", "'activation_summary/'", "+", "layer_name", "+", "'/min'", ",", "tf", ".", "reduce_min", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton.geteval_op_list": [[784, 796], ["tensorflow.transpose", "filter", "tensorflow.stack", "utils.util.bbox_transform_inv"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.utils.util.bbox_transform_inv"], ["", "", "def", "geteval_op_list", "(", "self", ")", ":", "\n", "    ", "\"\"\"get all tensorflow operations regarding this \n       model evaluation.\n    \"\"\"", "\n", "detection_boxes", "=", "tf", ".", "transpose", "(", "\n", "tf", ".", "stack", "(", "util", ".", "bbox_transform_inv", "(", "[", "self", ".", "det_boxes", "[", "\"xmins\"", "]", ",", "self", ".", "det_boxes", "[", "\"ymins\"", "]", ",", "self", ".", "det_boxes", "[", "\"xmaxs\"", "]", ",", "self", ".", "det_boxes", "[", "\"ymaxs\"", "]", "]", ")", ")", ",", "\n", "(", "1", ",", "2", ",", "0", ")", ",", "name", "=", "'bbox'", "\n", ")", "\n", "\n", "return", "filter", "(", "lambda", "x", ":", "x", "!=", "None", ",", "\n", "[", "self", ".", "prediction_boxes", ",", "self", ".", "score", ",", "self", ".", "cls_idx_per_img", ",", "\n", "self", ".", "filenames", ",", "self", ".", "widths", ",", "self", ".", "heights", ",", "self", ".", "viz_op", ",", "self", ".", "det_boxes", ",", "self", ".", "det_probs", ",", "self", ".", "det_class", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._add_loss_summaries": [[12, 25], ["tensorflow.get_collection", "tensorflow.summary.scalar"], "function", ["None"], ["def", "_add_loss_summaries", "(", "total_loss", ")", ":", "\n", "  ", "\"\"\"Add summaries for losses\n  Generates loss summaries for visualizing the performance of the network.\n  Args:\n    total_loss: Total loss from loss().\n    model_id: The id of the models inside the model pool.\n  \"\"\"", "\n", "losses", "=", "tf", ".", "get_collection", "(", "'losses'", ")", "\n", "\n", "# Attach a scalar summary to all individual losses and the total loss; do the", "\n", "# same for the averaged version of the losses.", "\n", "for", "l", "in", "losses", "+", "[", "total_loss", "]", ":", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "l", ".", "op", ".", "name", ",", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_on_device": [[26, 45], ["callable", "tensorflow.get_variable", "tensorflow.get_variable"], "function", ["None"], ["", "", "def", "_variable_on_device", "(", "name", ",", "shape", ",", "initializer", ",", "trainable", "=", "True", ")", ":", "\n", "  ", "\"\"\"Helper to create a Variable.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    initializer: initializer for Variable\n\n  Returns:\n    Variable Tensor\n  \"\"\"", "\n", "# TODO(bichen): fix the hard-coded data type below", "\n", "dtype", "=", "tf", ".", "float32", "\n", "if", "not", "callable", "(", "initializer", ")", ":", "\n", "    ", "var", "=", "tf", ".", "get_variable", "(", "name", ",", "initializer", "=", "initializer", ",", "trainable", "=", "trainable", ")", "\n", "", "else", ":", "\n", "    ", "var", "=", "tf", ".", "get_variable", "(", "\n", "name", ",", "shape", ",", "initializer", "=", "initializer", ",", "dtype", "=", "dtype", ",", "trainable", "=", "trainable", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_with_weight_decay": [[46, 66], ["nn_skeleton._variable_on_device", "tensorflow.multiply", "tensorflow.add_to_collection", "tensorflow.nn.l2_loss"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton._variable_on_device"], ["", "def", "_variable_with_weight_decay", "(", "name", ",", "shape", ",", "wd", ",", "initializer", ",", "trainable", "=", "True", ")", ":", "\n", "  ", "\"\"\"Helper to create an initialized Variable with weight decay.\n\n  Note that the Variable is initialized with a truncated normal distribution.\n  A weight decay is added only if one is specified.\n\n  Args:\n    name: name of the variable\n    shape: list of ints\n    wd: add L2Loss weight decay multiplied by this float. If None, weight\n        decay is not added for this Variable.\n\n  Returns:\n    Variable Tensor\n  \"\"\"", "\n", "var", "=", "_variable_on_device", "(", "name", ",", "shape", ",", "initializer", ",", "trainable", ")", "\n", "if", "wd", "is", "not", "None", "and", "trainable", ":", "\n", "    ", "weight_decay", "=", "tf", ".", "multiply", "(", "tf", ".", "nn", ".", "l2_loss", "(", "var", ")", ",", "wd", ",", "name", "=", "'weight_loss'", ")", "\n", "tf", ".", "add_to_collection", "(", "'losses'", ",", "weight_decay", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.__init__.get_net": [[7, 17], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet.__init__": [[16, 27], ["tensorflow.device", "nets.nn_skeleton.ModelSkeleton.__init__", "resnet50_convDet.ResNet50ConvDet._add_forward_graph", "resnet50_convDet.ResNet50ConvDet._add_interpretation_graph", "resnet50_convDet.ResNet50ConvDet._add_loss_graph", "resnet50_convDet.ResNet50ConvDet._add_train_graph", "resnet50_convDet.ResNet50ConvDet._add_viz_graph"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet.__init__", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._add_forward_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_interpretation_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_loss_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_train_graph", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._add_viz_graph"], ["  ", "def", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "gpu_id", "=", "0", ",", "base_net", "=", "None", ",", "global_step", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "device", "(", "'/job:localhost/replica:0/task:0/device:CPU:0'", ")", ":", "\n", "      ", "ModelSkeleton", ".", "__init__", "(", "self", ",", "mc", ",", "record_input", ",", "base_net", "=", "base_net", ",", "global_step", "=", "global_step", ")", "\n", "\n", "self", ".", "_add_forward_graph", "(", ")", "\n", "self", ".", "_add_interpretation_graph", "(", ")", "\n", "self", ".", "_add_loss_graph", "(", ")", "\n", "if", "mc", ".", "IS_TRAINING", ":", "\n", "        ", "self", ".", "_add_train_graph", "(", ")", "\n", "", "if", "mc", ".", "VISUALIZE_ON", ":", "\n", "        ", "self", ".", "_add_viz_graph", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._add_forward_graph": [[28, 130], ["resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._pooling_layer", "tensorflow.nn.dropout", "resnet50_convDet.ResNet50ConvDet._conv_layer", "tensorflow.gfile.Exists", "joblib.load", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu", "tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._res_branch", "tensorflow.nn.relu"], "methods", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._pooling_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.nn_skeleton.ModelSkeleton._conv_layer", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch"], ["", "", "", "def", "_add_forward_graph", "(", "self", ")", ":", "\n", "    ", "\"\"\"NN architecture.\"\"\"", "\n", "\n", "mc", "=", "self", ".", "mc", "\n", "if", "mc", ".", "LOAD_PRETRAINED_MODEL", ":", "\n", "      ", "assert", "tf", ".", "gfile", ".", "Exists", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", ",", "'Cannot find pretrained model at the given path:'", "'  {}'", ".", "format", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "self", ".", "caffemodel_weight", "=", "joblib", ".", "load", "(", "mc", ".", "PRETRAINED_MODEL_PATH", ")", "\n", "\n", "", "conv1", "=", "self", ".", "_conv_bn_layer", "(", "\n", "self", ".", "image_input", ",", "'conv1'", ",", "'bn_conv1'", ",", "'scale_conv1'", ",", "filters", "=", "64", ",", "\n", "size", "=", "7", ",", "stride", "=", "2", ",", "freeze", "=", "True", ",", "conv_with_bias", "=", "True", ")", "\n", "pool1", "=", "self", ".", "_pooling_layer", "(", "\n", "'pool1'", ",", "conv1", ",", "size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'conv2_x'", ")", "as", "scope", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'res2a'", ")", ":", "\n", "        ", "branch1", "=", "self", ".", "_conv_bn_layer", "(", "\n", "pool1", ",", "'res2a_branch1'", ",", "'bn2a_branch1'", ",", "'scale2a_branch1'", ",", "\n", "filters", "=", "256", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "freeze", "=", "True", ",", "relu", "=", "False", ")", "\n", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "pool1", ",", "layer_name", "=", "'2a'", ",", "in_filters", "=", "64", ",", "out_filters", "=", "256", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res2a", "=", "tf", ".", "nn", ".", "relu", "(", "branch1", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res2b'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res2a", ",", "layer_name", "=", "'2b'", ",", "in_filters", "=", "64", ",", "out_filters", "=", "256", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res2b", "=", "tf", ".", "nn", ".", "relu", "(", "res2a", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res2c'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res2b", ",", "layer_name", "=", "'2c'", ",", "in_filters", "=", "64", ",", "out_filters", "=", "256", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res2c", "=", "tf", ".", "nn", ".", "relu", "(", "res2b", "+", "branch2", ",", "'relu'", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'conv3_x'", ")", "as", "scope", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'res3a'", ")", ":", "\n", "        ", "branch1", "=", "self", ".", "_conv_bn_layer", "(", "\n", "res2c", ",", "'res3a_branch1'", ",", "'bn3a_branch1'", ",", "'scale3a_branch1'", ",", "\n", "filters", "=", "512", ",", "size", "=", "1", ",", "stride", "=", "2", ",", "freeze", "=", "True", ",", "relu", "=", "False", ")", "\n", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res2c", ",", "layer_name", "=", "'3a'", ",", "in_filters", "=", "128", ",", "out_filters", "=", "512", ",", "\n", "down_sample", "=", "True", ",", "freeze", "=", "True", ")", "\n", "res3a", "=", "tf", ".", "nn", ".", "relu", "(", "branch1", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res3b'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res3a", ",", "layer_name", "=", "'3b'", ",", "in_filters", "=", "128", ",", "out_filters", "=", "512", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res3b", "=", "tf", ".", "nn", ".", "relu", "(", "res3a", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res3c'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res3b", ",", "layer_name", "=", "'3c'", ",", "in_filters", "=", "128", ",", "out_filters", "=", "512", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res3c", "=", "tf", ".", "nn", ".", "relu", "(", "res3b", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res3d'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res3c", ",", "layer_name", "=", "'3d'", ",", "in_filters", "=", "128", ",", "out_filters", "=", "512", ",", "\n", "down_sample", "=", "False", ",", "freeze", "=", "True", ")", "\n", "res3d", "=", "tf", ".", "nn", ".", "relu", "(", "res3c", "+", "branch2", ",", "'relu'", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'conv4_x'", ")", "as", "scope", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'res4a'", ")", ":", "\n", "        ", "branch1", "=", "self", ".", "_conv_bn_layer", "(", "\n", "res3d", ",", "'res4a_branch1'", ",", "'bn4a_branch1'", ",", "'scale4a_branch1'", ",", "\n", "filters", "=", "1024", ",", "size", "=", "1", ",", "stride", "=", "2", ",", "relu", "=", "False", ")", "\n", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res3d", ",", "layer_name", "=", "'4a'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "True", ")", "\n", "res4a", "=", "tf", ".", "nn", ".", "relu", "(", "branch1", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res4b'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res4a", ",", "layer_name", "=", "'4b'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "False", ")", "\n", "res4b", "=", "tf", ".", "nn", ".", "relu", "(", "res4a", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res4c'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res4b", ",", "layer_name", "=", "'4c'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "False", ")", "\n", "res4c", "=", "tf", ".", "nn", ".", "relu", "(", "res4b", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res4d'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res4c", ",", "layer_name", "=", "'4d'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "False", ")", "\n", "res4d", "=", "tf", ".", "nn", ".", "relu", "(", "res4c", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res4e'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res4d", ",", "layer_name", "=", "'4e'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "False", ")", "\n", "res4e", "=", "tf", ".", "nn", ".", "relu", "(", "res4d", "+", "branch2", ",", "'relu'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'res4f'", ")", ":", "\n", "        ", "branch2", "=", "self", ".", "_res_branch", "(", "\n", "res4e", ",", "layer_name", "=", "'4f'", ",", "in_filters", "=", "256", ",", "out_filters", "=", "1024", ",", "\n", "down_sample", "=", "False", ")", "\n", "res4f", "=", "tf", ".", "nn", ".", "relu", "(", "res4e", "+", "branch2", ",", "'relu'", ")", "\n", "\n", "", "", "dropout4", "=", "tf", ".", "nn", ".", "dropout", "(", "res4f", ",", "self", ".", "keep_prob", ",", "name", "=", "'drop4'", ")", "\n", "\n", "num_output", "=", "mc", ".", "ANCHOR_PER_GRID", "*", "(", "mc", ".", "CLASSES", "+", "1", "+", "4", ")", "\n", "self", ".", "preds", "=", "self", ".", "_conv_layer", "(", "\n", "'conv5'", ",", "dropout4", ",", "filters", "=", "num_output", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "xavier", "=", "False", ",", "relu", "=", "False", ",", "stddev", "=", "0.0001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.nets.resnet50_convDet.ResNet50ConvDet._res_branch": [[131, 167], ["tensorflow.variable_scope", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer", "resnet50_convDet.ResNet50ConvDet._conv_bn_layer"], "methods", ["None"], ["", "def", "_res_branch", "(", "\n", "self", ",", "inputs", ",", "layer_name", ",", "in_filters", ",", "out_filters", ",", "down_sample", "=", "False", ",", "\n", "freeze", "=", "False", ")", ":", "\n", "    ", "\"\"\"Residual branch constructor.\n\n      Args:\n        inputs: input tensor\n        layer_name: layer name\n        in_filters: number of filters in XX_branch2a and XX_branch2b layers.\n        out_filters: number of filters in XX_branch2clayers.\n        donw_sample: if true, down sample the input feature map \n        freeze: if true, do not change parameters in this layer\n      Returns:\n        A residual branch output operation.\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "'res'", "+", "layer_name", "+", "'_branch2'", ")", ":", "\n", "      ", "stride", "=", "2", "if", "down_sample", "else", "1", "\n", "output", "=", "self", ".", "_conv_bn_layer", "(", "\n", "inputs", ",", "\n", "conv_param_name", "=", "'res'", "+", "layer_name", "+", "'_branch2a'", ",", "\n", "bn_param_name", "=", "'bn'", "+", "layer_name", "+", "'_branch2a'", ",", "\n", "scale_param_name", "=", "'scale'", "+", "layer_name", "+", "'_branch2a'", ",", "\n", "filters", "=", "in_filters", ",", "size", "=", "1", ",", "stride", "=", "stride", ",", "freeze", "=", "freeze", ")", "\n", "output", "=", "self", ".", "_conv_bn_layer", "(", "\n", "output", ",", "\n", "conv_param_name", "=", "'res'", "+", "layer_name", "+", "'_branch2b'", ",", "\n", "bn_param_name", "=", "'bn'", "+", "layer_name", "+", "'_branch2b'", ",", "\n", "scale_param_name", "=", "'scale'", "+", "layer_name", "+", "'_branch2b'", ",", "\n", "filters", "=", "in_filters", ",", "size", "=", "3", ",", "stride", "=", "1", ",", "freeze", "=", "freeze", ")", "\n", "output", "=", "self", ".", "_conv_bn_layer", "(", "\n", "output", ",", "\n", "conv_param_name", "=", "'res'", "+", "layer_name", "+", "'_branch2c'", ",", "\n", "bn_param_name", "=", "'bn'", "+", "layer_name", "+", "'_branch2c'", ",", "\n", "scale_param_name", "=", "'scale'", "+", "layer_name", "+", "'_branch2c'", ",", "\n", "filters", "=", "out_filters", ",", "size", "=", "1", ",", "stride", "=", "1", ",", "freeze", "=", "freeze", ",", "relu", "=", "False", ")", "\n", "return", "output", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.tl_mini_experiment_kitti_pascal.run_experiment.main": [[67, 173], ["run_experiment.create_needed_dirs", "numpy.array", "json.load", "list", "os.path.join", "json.dump", "numpy.array", "json.load", "list", "os.path.join", "json.dump", "range", "open", "open", "open", "open", "open", "f.write", "f.write", "open", "f.write", "f.write", "LAYERS_TO_LOAD.append", "os.path.join", "os.path.join", "json.dump", "auto_ITL.start", "os.path.join", "os.path.join", "json.dump", "auto_ITL.start", "os.path.join", "os.path.join", "json.dump", "auto_ITL.start", "os.path.join", "os.path.join", "json.dump", "auto_ITL.start", "os.path.join", "os.path.join", "open", "open", "open", "open", "open", "f.write", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.tl_mini_experiment_kitti_pascal.run_experiment.create_needed_dirs", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start", "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start"], ["def", "main", "(", "TRAIN_DIR", ",", "num_classes", "=", "3", ")", ":", "\n", "# create needed folders", "\n", "  ", "create_needed_dirs", "(", "TRAIN_DIR", ")", "\n", "\n", "# dataset A = half the pascal voc", "\n", "label_indices_A", "=", "np", ".", "array", "(", "[", "1", ",", "2", ",", "3", "]", ")", "# for full pascal: np.random.choice(range(1,21), size=num_classes, replace=False)", "\n", "class_names_A", "=", "[", "\"car\"", ",", "\"pedestrian\"", ",", "\"cyclist\"", "]", "# for full pascal: full_pascal_voc[\"CLASS_NAMES\"][label_indices_A - 1]", "\n", "config_A", "=", "json", ".", "load", "(", "open", "(", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/kitti_tests/kitti_squeezeDet_config.json\"", ")", ")", "\n", "config_A", "[", "\"CLASS_NAMES\"", "]", "=", "class_names_A", "\n", "config_A", "[", "\"CLASSES\"", "]", "=", "num_classes", "\n", "config_A", "[", "\"LABEL_INDICES\"", "]", "=", "list", "(", "label_indices_A", ")", "\n", "config_A", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"A\"", ")", "\n", "A_ext_config", "=", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/tl_mini_experiment/A_config.json\"", "\n", "json", ".", "dump", "(", "config_A", ",", "open", "(", "A_ext_config", ",", "\"w\"", ")", ")", "\n", "# dataset B = the other half pascal voc", "\n", "label_indices_B", "=", "np", ".", "array", "(", "[", "2", ",", "6", ",", "12", "]", ")", "\n", "class_names_B", "=", "[", "full_pascal_voc", "[", "\"CLASS_NAMES\"", "]", "[", "i", "-", "1", "]", "for", "i", "in", "label_indices_B", "]", "\n", "config_B", "=", "json", ".", "load", "(", "open", "(", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/tl_mini_experiment/full_pascal_voc_config.json\"", ")", ")", "\n", "config_B", "[", "\"CLASS_NAMES\"", "]", "=", "class_names_B", "\n", "config_B", "[", "\"CLASSES\"", "]", "=", "num_classes", "\n", "config_B", "[", "\"LABEL_INDICES\"", "]", "=", "list", "(", "label_indices_B", ")", "\n", "config_B", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"B\"", ")", "\n", "B_ext_config", "=", "\"/media/terabyte/projects/Thesis/transfer_learning/auto_ITL/scripts/tl_mini_experiment/B_config.json\"", "\n", "json", ".", "dump", "(", "config_B", ",", "open", "(", "B_ext_config", ",", "\"w\"", ")", ")", "\n", "### 1 st phase", "\n", "# model A", "\n", "# train model A in dataset A", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "config_A", "[", "\"TRAIN_DIR\"", "]", ",", "\"init_info.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "str", "(", "label_indices_A", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "str", "(", "class_names_A", ")", "+", "\"\\n\"", ")", "\n", "# start(A_ext_config)", "\n", "", "A_best_checkpoint", "=", "config_A", "[", "\"TRAIN_DIR\"", "]", "# os.path.join(config_A[\"TRAIN_DIR\"], max(os.listdir(config_A[\"TRAIN_DIR\"]), key=os.path.getctime)) # the best is not always the latest, but...", "\n", "config_A", "[", "\"ckpt_path\"", "]", "=", "A_best_checkpoint", "\n", "\n", "# model B", "\n", "# train model B in dataset B", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "config_B", "[", "\"TRAIN_DIR\"", "]", ",", "\"init_info.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "f", ".", "write", "(", "str", "(", "label_indices_B", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "write", "(", "str", "(", "class_names_B", ")", "+", "\"\\n\"", ")", "\n", "\n", "# start({\"ext_config_file_path\": B_ext_config})", "\n", "", "B_best_checkpoint", "=", "config_B", "[", "\"TRAIN_DIR\"", "]", "# os.path.join(config_B[\"TRAIN_DIR\"], max(os.listdir(config_B[\"TRAIN_DIR\"]), key=os.path.getctime)) # the best is not always the latest, but...", "\n", "config_B", "[", "\"ckpt_path\"", "]", "=", "B_best_checkpoint", "\n", "### 2nd phase", "\n", "# models should load from checkpoints", "\n", "config_A", "[", "\"LOAD_PRETRAINED_MODEL\"", "]", "=", "False", "\n", "config_A", "[", "\"DATASET_NAME\"", "]", "=", "\"PASCAL_VOC\"", "\n", "config_A", "[", "\"DATA_PATH\"", "]", "=", "config_B", "[", "\"DATA_PATH\"", "]", "\n", "config_A", "[", "\"INITIAL_ANCHOR_SHAPES\"", "]", "=", "config_B", "[", "\"INITIAL_ANCHOR_SHAPES\"", "]", "\n", "config_A", "[", "\"CLASS_NAMES\"", "]", "=", "class_names_B", "\n", "config_A", "[", "\"LABEL_INDICES\"", "]", "=", "config_B", "[", "\"LABEL_INDICES\"", "]", "\n", "config_A", "[", "\"REDUCE_DATASET\"", "]", "=", "True", "\n", "config_A", "[", "\"PREPROCESSED_DATA_DIR\"", "]", "=", "config_B", "[", "\"PREPROCESSED_DATA_DIR\"", "]", "\n", "config_A", "[", "\"IMAGE_WIDTH\"", "]", "=", "config_B", "[", "\"IMAGE_WIDTH\"", "]", "\n", "config_A", "[", "\"IMAGE_HEIGHT\"", "]", "=", "config_B", "[", "\"IMAGE_HEIGHT\"", "]", "\n", "config_A", "[", "\"EVAL_ITERS\"", "]", "=", "200", "\n", "config_B", "[", "\"LOAD_PRETRAINED_MODEL\"", "]", "=", "False", "\n", "LAYERS_TO_LOAD", "=", "[", "]", "\n", "# Let a model C", "\n", "for", "i", "in", "range", "(", "11", ")", ":", "\n", "    ", "freeze_layers", "[", "layers", "[", "i", "]", "]", "=", "True", "\n", "LAYERS_TO_LOAD", ".", "append", "(", "layers", "[", "i", "]", ")", "\n", "# (AnB)", "\n", "# transfer from A to C all layers < i the rest are randomly initialized", "\n", "# freeze all layers < i of C", "\n", "# now train C in dataset B", "\n", "config_A", "[", "\"FREEZE_LAYERS\"", "]", "=", "freeze_layers", "\n", "config_A", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_layer_%d\"", "%", "i", ")", "\n", "config_A", "[", "\"LAYERS_TO_LOAD\"", "]", "=", "LAYERS_TO_LOAD", "\n", "\n", "A_ext_config", "=", "os", ".", "path", ".", "join", "(", "config_A", "[", "\"TRAIN_DIR\"", "]", ",", "\"A_config.json\"", ")", "\n", "json", ".", "dump", "(", "config_A", ",", "open", "(", "A_ext_config", ",", "\"w\"", ")", ")", "\n", "start", "(", "{", "\"ext_config_file_path\"", ":", "A_ext_config", "}", ")", "\n", "# (AnB+)", "\n", "# transfer from A to C all layers < i the rest are randomly initialized", "\n", "# do not freeze any layer", "\n", "# now train C in dataset B", "\n", "config_A", "[", "\"FREEZE_LAYERS\"", "]", "=", "hot_layers", "\n", "config_A", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_plus_layer_%d\"", "%", "i", ")", "\n", "config_A", "[", "\"LAYERS_TO_LOAD\"", "]", "=", "LAYERS_TO_LOAD", "\n", "A_ext_config", "=", "os", ".", "path", ".", "join", "(", "config_A", "[", "\"TRAIN_DIR\"", "]", ",", "\"A_config.json\"", ")", "\n", "json", ".", "dump", "(", "config_A", ",", "open", "(", "A_ext_config", ",", "\"w\"", ")", ")", "\n", "start", "(", "{", "\"ext_config_file_path\"", ":", "A_ext_config", "}", ")", "\n", "# (BnB)", "\n", "# transfer from B to C all layers < i the rest are randomly initialized", "\n", "# freeze all layers < i of C", "\n", "# now train C in dataset B", "\n", "config_B", "[", "\"FREEZE_LAYERS\"", "]", "=", "freeze_layers", "\n", "config_B", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_layer_%d\"", "%", "i", ")", "\n", "config_B", "[", "\"LAYERS_TO_LOAD\"", "]", "=", "LAYERS_TO_LOAD", "\n", "B_ext_config", "=", "os", ".", "path", ".", "join", "(", "config_B", "[", "\"TRAIN_DIR\"", "]", ",", "\"B_config.json\"", ")", "\n", "json", ".", "dump", "(", "config_B", ",", "open", "(", "B_ext_config", ",", "\"w\"", ")", ")", "\n", "start", "(", "{", "\"ext_config_file_path\"", ":", "B_ext_config", "}", ")", "\n", "# (BnB+)", "\n", "# transfer from B to C all layers < i the rest are randomly initialized", "\n", "# do not freeze any layer", "\n", "# now train C in dataset B", "\n", "config_B", "[", "\"FREEZE_LAYERS\"", "]", "=", "hot_layers", "\n", "config_B", "[", "\"TRAIN_DIR\"", "]", "=", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_plus_layer_%d\"", "%", "i", ")", "\n", "config_B", "[", "\"LAYERS_TO_LOAD\"", "]", "=", "LAYERS_TO_LOAD", "\n", "B_ext_config", "=", "os", ".", "path", ".", "join", "(", "config_B", "[", "\"TRAIN_DIR\"", "]", ",", "\"B_config.json\"", ")", "\n", "json", ".", "dump", "(", "config_B", ",", "open", "(", "B_ext_config", ",", "\"w\"", ")", ")", "\n", "start", "(", "{", "\"ext_config_file_path\"", ":", "B_ext_config", "}", ")", "\n", "# update that the i-th test has finished", "\n", "with", "open", "(", "\"report_status.txt\"", ",", "\"a\"", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "str", "(", "i", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.tl_mini_experiment_kitti_pascal.run_experiment.create_needed_dirs": [[174, 190], ["range", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "", "def", "create_needed_dirs", "(", "TRAIN_DIR", ")", ":", "\n", "  ", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"A\"", ")", ")", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"A\"", ")", ")", "\n", "\n", "", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"B\"", ")", ")", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"B\"", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "12", ")", ":", "\n", "    ", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_layer_%d\"", "%", "i", ")", ")", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_layer_%d\"", "%", "i", ")", ")", "\n", "", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_plus_layer_%d\"", "%", "i", ")", ")", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"AnB_plus_layer_%d\"", "%", "i", ")", ")", "\n", "", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_layer_%d\"", "%", "i", ")", ")", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_layer_%d\"", "%", "i", ")", ")", "\n", "", "if", "(", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_plus_layer_%d\"", "%", "i", ")", ")", ")", ":", "\n", "      ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "TRAIN_DIR", ",", "\"BnB_plus_layer_%d\"", "%", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.tl_mini_experiment_kitti_pascal.present_results.read_results": [[15, 64], ["json.load", "os.path.join", "max", "print", "range", "print", "open", "open", "os.path.join", "AnB.append", "os.path.join", "AnB_plus.append", "os.path.join", "BnB.append", "os.path.join", "BnB_plus.append", "open", "json.dump", "open", "max", "open", "max", "open", "max", "open", "max", "json.load", "json.load", "json.load", "json.load", "json.load"], "function", ["None"], ["def", "read_results", "(", "BASE_DIR", ")", ":", "\n", "# read B ", "\n", "  ", "B_ext_config", "=", "json", ".", "load", "(", "open", "(", "\"B_pascal_voc_config.json\"", ")", ")", "\n", "B_TRAIN_DIR", "=", "B_ext_config", "[", "\"TRAIN_DIR\"", "]", "\n", "file_to_read", "=", "os", ".", "path", ".", "join", "(", "B_TRAIN_DIR", ",", "\"evals\"", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "file_to_read", ")", "as", "f", ":", "\n", "# lines = f.readlines()", "\n", "# maps = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in lines if \"mAP\" in l]", "\n", "    ", "maps", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "", "B_mAP", "=", "max", "(", "maps", ")", "\n", "print", "(", "B_mAP", ")", "\n", "\n", "AnB", ",", "AnB_plus", ",", "BnB", ",", "BnB_plus", "=", "[", "B_mAP", "]", ",", "[", "B_mAP", "]", ",", "[", "B_mAP", "]", ",", "[", "B_mAP", "]", "\n", "for", "i", "in", "range", "(", "11", ")", ":", "\n", "# AnB", "\n", "    ", "file_to_read", "=", "os", ".", "path", ".", "join", "(", "BASE_DIR", ",", "\"AnB_layer_%d\"", "%", "i", ",", "\"evals\"", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "file_to_read", ")", "as", "f", ":", "\n", "# lines = f.readlines()", "\n", "# maps = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in lines if \"mAP\" in l]", "\n", "      ", "maps", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "", "AnB", ".", "append", "(", "max", "(", "maps", ")", ")", "\n", "# AnB+", "\n", "file_to_read", "=", "os", ".", "path", ".", "join", "(", "BASE_DIR", ",", "\"AnB_plus_layer_%d\"", "%", "i", ",", "\"evals\"", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "file_to_read", ")", "as", "f", ":", "\n", "# lines = f.readlines()", "\n", "# maps = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in lines if \"mAP\" in l]", "\n", "      ", "maps", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "", "AnB_plus", ".", "append", "(", "max", "(", "maps", ")", ")", "\n", "# BnB", "\n", "file_to_read", "=", "os", ".", "path", ".", "join", "(", "BASE_DIR", ",", "\"BnB_layer_%d\"", "%", "i", ",", "\"evals\"", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "file_to_read", ")", "as", "f", ":", "\n", "# lines = f.readlines()", "\n", "# maps = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in lines if \"mAP\" in l]", "\n", "      ", "maps", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "", "BnB", ".", "append", "(", "max", "(", "maps", ")", ")", "\n", "# BnB+", "\n", "file_to_read", "=", "os", ".", "path", ".", "join", "(", "BASE_DIR", ",", "\"BnB_plus_layer_%d\"", "%", "i", ",", "\"evals\"", ",", "\"mAP_history.json\"", ")", "\n", "with", "open", "(", "file_to_read", ")", "as", "f", ":", "\n", "# lines = f.readlines()", "\n", "# maps = [float(l.split(\"\\\"mAP\\\": \")[-1]) for l in lines if \"mAP\" in l]", "\n", "      ", "maps", "=", "[", "h", "[", "\"mAP\"", "]", "for", "h", "in", "json", ".", "load", "(", "f", ")", "[", "\"history\"", "]", "]", "\n", "", "BnB_plus", ".", "append", "(", "max", "(", "maps", ")", ")", "\n", "\n", "", "print", "(", "AnB", ",", "AnB_plus", ",", "BnB", ",", "BnB_plus", ")", "\n", "with", "open", "(", "\"TLresults.txt\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "json", ".", "dump", "(", "{", "\"AnB\"", ":", "AnB", ",", "\n", "\"AnB+\"", ":", "AnB_plus", ",", "\n", "\"BnB\"", ":", "BnB", ",", "\n", "\"BnB+\"", ":", "BnB_plus", "}", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.tl_mini_experiment_kitti_pascal.present_results.plot_results": [[66, 123], ["numpy.arange", "matplotlib.pyplot.figure", "matplotlib.pyplot.subplot", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.plot", "plt.subplot.spines[].set_visible", "plt.subplot.spines[].set_visible", "plt.subplot.legend", "matplotlib.pyplot.xticks", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.savefig", "numpy.log10", "matplotlib.pyplot.figure", "matplotlib.pyplot.subplot", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.add_patch", "plt.subplot.plot", "plt.subplot.plot", "plt.subplot.spines[].set_visible", "plt.subplot.spines[].set_visible", "plt.subplot.legend", "matplotlib.pyplot.xticks", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "open", "json.load", "matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "numpy.ones_like", "numpy.arange", "numpy.log10", "matplotlib.patches.Polygon", "numpy.log10", "matplotlib.patches.Polygon", "numpy.log10", "matplotlib.patches.Polygon", "numpy.log10", "numpy.ones_like", "numpy.log10", "numpy.arange", "list", "list", "list", "list", "list", "list", "zip", "zip", "zip", "zip", "zip", "zip", "numpy.log10", "numpy.log10", "numpy.log10"], "function", ["None"], ["", "", "def", "plot_results", "(", ")", ":", "\n", "# plot the lines", "\n", "# in our case we did that on a separate computer", "\n", "  ", "with", "open", "(", "\"TLresults.txt\"", ")", "as", "f", ":", "\n", "    ", "TLresults", "=", "json", ".", "load", "(", "f", ")", "\n", "AnB", "=", "TLresults", "[", "\"AnB\"", "]", "\n", "AnB_plus", "=", "TLresults", "[", "\"AnB+\"", "]", "\n", "BnB", "=", "TLresults", "[", "\"BnB\"", "]", "\n", "BnB_plus", "=", "TLresults", "[", "\"BnB+\"", "]", "\n", "", "X", "=", "np", ".", "arange", "(", "0", ",", "12", ",", "1", ")", "\n", "Ymax", "=", "AnB", "[", "0", "]", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ")", "\n", "ax", ".", "plot", "(", "AnB", ",", "linewidth", "=", "2", ",", "color", "=", "\"r\"", ",", "label", "=", "r'$AnB$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "AnB", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:coral'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.3", ")", ")", "\n", "ax", ".", "plot", "(", "AnB_plus", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:orange red\"", ",", "label", "=", "r'$AnB^+$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "AnB_plus", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:salmon'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.3", ")", ")", "\n", "ax", ".", "plot", "(", "BnB", ",", "linewidth", "=", "2", ",", "color", "=", "\"b\"", ",", "label", "=", "r'$BnB$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "BnB", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:light blue'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.7", ")", ")", "\n", "ax", ".", "plot", "(", "BnB_plus", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:sky blue\"", ",", "label", "=", "r'$BnB^+$'", ")", "\n", "y", "=", "np", ".", "ones_like", "(", "AnB", ")", "*", "AnB", "[", "0", "]", "\n", "ax", ".", "plot", "(", "y", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:black\"", ")", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "0", ",", "12", ",", "1", ")", ")", "\n", "plt", ".", "xlabel", "(", "r\"Layer $n$ at which network is chopped and retrained\"", ")", "\n", "plt", ".", "ylabel", "(", "\"mAP (higher is better)\"", ")", "\n", "plt", ".", "savefig", "(", "\"grantExp.pdf\"", ")", "\n", "\n", "# the same figure in logarithmic scale", "\n", "Ymax", "=", "np", ".", "log10", "(", "AnB", "[", "0", "]", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ")", "\n", "ax", ".", "plot", "(", "np", ".", "log10", "(", "AnB", ")", ",", "linewidth", "=", "2", ",", "color", "=", "\"r\"", ",", "label", "=", "r'$AnB$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "np", ".", "log10", "(", "AnB", ")", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:coral'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.3", ")", ")", "\n", "ax", ".", "plot", "(", "np", ".", "log10", "(", "AnB_plus", ")", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:orange red\"", ",", "label", "=", "r'$AnB^+$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "np", ".", "log10", "(", "AnB_plus", ")", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:salmon'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.3", ")", ")", "\n", "ax", ".", "plot", "(", "np", ".", "log10", "(", "BnB", ")", ",", "linewidth", "=", "2", ",", "color", "=", "\"b\"", ",", "label", "=", "r'$BnB$'", ")", "\n", "verts", "=", "[", "(", "0", ",", "Ymax", ")", "]", "+", "list", "(", "zip", "(", "X", ",", "np", ".", "log10", "(", "BnB", ")", ")", ")", "+", "[", "(", "11", ",", "Ymax", ")", "]", "\n", "ax", ".", "add_patch", "(", "Polygon", "(", "verts", ",", "facecolor", "=", "'xkcd:light blue'", ",", "edgecolor", "=", "'1.0'", ",", "alpha", "=", "0.3", ")", ")", "\n", "ax", ".", "plot", "(", "np", ".", "log10", "(", "BnB_plus", ")", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:sky blue\"", ",", "label", "=", "r'$BnB^+$'", ")", "\n", "y", "=", "np", ".", "ones_like", "(", "AnB", ")", "*", "np", ".", "log10", "(", "AnB", "[", "0", "]", ")", "\n", "ax", ".", "plot", "(", "y", ",", "linestyle", "=", "'--'", ",", "linewidth", "=", "2", ",", "color", "=", "\"xkcd:black\"", ")", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "0", ",", "12", ",", "1", ")", ")", "\n", "plt", ".", "xlabel", "(", "r\"Layer $n$ at which network is chopped and retrained\"", ")", "\n", "plt", ".", "ylabel", "(", "r\"$\\log_{10}(mAP)$ (higher is better)\"", ")", "\n", "plt", ".", "savefig", "(", "\"grantExpLog.pdf\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.bipartite_tests.kitti_train.launchTensorBoard": [[10, 14], ["os.system"], "function", ["None"], ["def", "launchTensorBoard", "(", "tensorBoardPath", ")", ":", "\n", "  ", "import", "os", "\n", "os", ".", "system", "(", "'tensorboard --logdir '", "+", "tensorBoardPath", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.kitti_tests.kitti_train.launchTensorBoard": [[10, 14], ["os.system"], "function", ["None"], ["def", "launchTensorBoard", "(", "tensorBoardPath", ")", ":", "\n", "  ", "import", "os", "\n", "os", ".", "system", "(", "'tensorboard --logdir '", "+", "tensorBoardPath", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.compare_pascal_voc_trainings.cmp_pascal_voc.train_pascal": [[11, 23], ["os.path.dirname", "os.path.join", "os.path.exists", "os.makedirs", "auto_ITL.start", "os.path.abspath", "open", "shutil.rmtree", "json.load"], "function", ["home.repos.pwc.inspect_result.supernlogn_squeezeDetTL.src.auto_ITL.start"], ["def", "train_pascal", "(", "json_file", ")", ":", "\n", "  ", "args", "=", "{", "}", "\n", "dir_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", "\n", "args", "[", "\"ext_config_file_path\"", "]", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "json_file", ")", "\n", "with", "open", "(", "args", "[", "\"ext_config_file_path\"", "]", ",", "\"r\"", ")", "as", "f", ":", "\n", "    ", "dir_name", "=", "json", ".", "load", "(", "f", ")", "[", "\"BASE_DIR\"", "]", "\n", "\n", "", "if", "(", "os", ".", "path", ".", "exists", "(", "dir_name", ")", ")", ":", "\n", "    ", "shutil", ".", "rmtree", "(", "dir_name", ")", "\n", "", "os", ".", "makedirs", "(", "dir_name", ")", "\n", "start", "(", "args", ")", "\n", "return", "dir_name", "\n", "\n"]]}