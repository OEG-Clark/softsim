{"home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.train.DataTrainingArguments.__post_init__": [[240, 249], ["ValueError", "train.DataTrainingArguments.train_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\n", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.train.OurTrainingArguments._setup_devices": [[268, 316], ["logger.info", "torch.device", "transformers.file_utils.is_torch_tpu_available", "torch.cuda.set_device", "xm.xla_device", "torch.device", "torch.cuda.device_count", "torch.device", "deepspeed.init_distributed", "torch.distributed.init_process_group", "torch.cuda.is_available", "is_deepspeed_available", "ImportError"], "methods", ["None"], ["@", "cached_property", "\n", "@", "torch_required", "\n", "def", "_setup_devices", "(", "self", ")", "->", "\"torch.device\"", ":", "\n", "        ", "logger", ".", "info", "(", "\"PyTorch: setting up devices\"", ")", "\n", "if", "self", ".", "no_cuda", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "_n_gpu", "=", "0", "\n", "", "elif", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "device", "=", "xm", ".", "xla_device", "(", ")", "\n", "self", ".", "_n_gpu", "=", "0", "\n", "", "elif", "self", ".", "local_rank", "==", "-", "1", ":", "\n", "# if n_gpu is > 1 we'll use nn.DataParallel.", "\n", "# If you only want to use a specific subset of GPUs use `CUDA_VISIBLE_DEVICES=0`", "\n", "# Explicitly set CUDA to the first (index 0) CUDA device, otherwise `set_device` will", "\n", "# trigger an error that a device index is missing. Index 0 takes into account the", "\n", "# GPUs available in the environment, so `CUDA_VISIBLE_DEVICES=1,2` with `cuda:0`", "\n", "# will use the first GPU in that env, i.e. GPU#1", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "# Sometimes the line in the postinit has not been run before we end up here, so just checking we're not at", "\n", "# the default value.", "\n", "self", ".", "_n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "\n", "# Here, we'll use torch.distributed.", "\n", "# Initializes the distributed backend which will take care of synchronizing nodes/GPUs", "\n", "#", "\n", "# deepspeed performs its own DDP internally, and requires the program to be started with:", "\n", "# deepspeed  ./program.py", "\n", "# rather than:", "\n", "# python -m torch.distributed.launch --nproc_per_node=2 ./program.py", "\n", "            ", "if", "self", ".", "deepspeed", ":", "\n", "                ", "from", ".", "integrations", "import", "is_deepspeed_available", "\n", "\n", "if", "not", "is_deepspeed_available", "(", ")", ":", "\n", "                    ", "raise", "ImportError", "(", "\n", "\"--deepspeed requires deepspeed: `pip install deepspeed`.\"", ")", "\n", "", "import", "deepspeed", "\n", "\n", "deepspeed", ".", "init_distributed", "(", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "self", ".", "local_rank", ")", "\n", "self", ".", "_n_gpu", "=", "1", "\n", "\n", "", "if", "device", ".", "type", "==", "\"cuda\"", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "\n", "", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.train.main": [[318, 723], ["transformers.HfArgumentParser", "wandb.config.update", "os.path.join", "logging.basicConfig", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "BertForCL.from_pretrained.resize_token_embeddings", "scd.trainers.CLTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "wandb.init", "wandb.init", "os.path.exists", "os.listdir", "ValueError", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "data_args.train_file.split", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "logger.info", "transformers.AutoModelForMaskedLM.from_config", "len", "len", "len", "range", "AutoTokenizer.from_pretrained.", "datasets[].map", "OurDataCollatorWithPadding", "scd.trainers.CLTrainer.train", "scd.trainers.CLTrainer.save_model", "os.path.join", "scd.trainers.CLTrainer.is_world_process_zero", "logger.info", "scd.trainers.CLTrainer.evaluate", "os.path.join", "scd.trainers.CLTrainer.is_world_process_zero", "len", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "scd.models.RobertaForCL.from_pretrained", "len", "logger.error", "range", "len", "train..tokenizer.pad", "inputs.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "train..tokenizer.convert_tokens_to_ids", "torch.randint", "scd.trainers.CLTrainer.state.save_to_json", "os.path.abspath", "data_args.tags.split", "transformers.trainer_utils.is_main_process", "scd.models.BertForCL.from_pretrained", "len", "len", "range", "train..mask_tokens", "torch.tensor", "special_tokens_mask.bool.bool", "torch.bernoulli().bool", "len", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "bool", "bool", "transformers.BertForPreTraining.from_pretrained", "BertForCL.from_pretrained.lm_head.load_state_dict", "flat_features.append", "batch[].view", "train..tokenizer.get_special_tokens_mask", "torch.bernoulli", "torch.bernoulli().bool", "trainer.train.metrics.items", "logger.info", "writer.write", "trainer.evaluate.items", "logger.info", "writer.write", "bool", "BertForPreTraining.from_pretrained.cls.predictions.state_dict", "range", "range", "batch[].view", "inputs.clone.tolist", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.evaluate"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "\n", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "OurTrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "\n", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "if", "not", "(", "data_args", ".", "tags", "is", "None", ")", ":", "\n", "        ", "data_args", ".", "tags", "=", "[", "item", "for", "item", "in", "data_args", ".", "tags", ".", "split", "(", "','", ")", "]", "\n", "\n", "", "if", "not", "(", "data_args", ".", "tags", "is", "None", ")", ":", "\n", "        ", "wandb", ".", "init", "(", "project", "=", "data_args", ".", "description", ",", "tags", "=", "data_args", ".", "tags", ")", "\n", "\n", "", "else", ":", "\n", "        ", "wandb", ".", "init", "(", "project", "=", "data_args", ".", "description", ")", "\n", "\n", "", "wandb", ".", "config", ".", "update", "(", "{", "\"Command Line\"", ":", "'python '", "+", "' '", ".", "join", "(", "sys", ".", "argv", "[", "0", ":", "]", ")", "}", ")", "\n", "\n", "if", "not", "(", "wandb", ".", "run", ".", "name", "is", "None", ")", ":", "\n", "        ", "output_name", "=", "wandb", ".", "run", ".", "name", "\n", "", "else", ":", "\n", "        ", "output_name", "=", "'dummy-run'", "\n", "", "training_args", ".", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "output_name", ")", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "training_args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", "\n", "and", "training_args", ".", "do_train", "\n", "and", "not", "training_args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty.\"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "is_main_process", "(", "\n", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column. You can easily tweak this", "\n", "# behavior (see below)", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "        ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "        ", "extension", "=", "\"text\"", "\n", "", "if", "extension", "==", "\"csv\"", ":", "\n", "        ", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "\"./data/\"", ",", "\n", "delimiter", "=", "\"\\t\"", "if", "\"tsv\"", "in", "data_args", ".", "train_file", "else", "\",\"", ")", "\n", "", "else", ":", "\n", "        ", "datasets", "=", "load_dataset", "(", "\n", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "\"./data/\"", ")", "\n", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\n", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "# SCD - BEGIN: parameters", "\n", "", "config", ".", "multi_dropout", "=", "True", "\n", "config", ".", "task_lambda", "=", "model_args", ".", "task_lambda", "\n", "config", ".", "task_alpha", "=", "model_args", ".", "task_alpha", "\n", "config", ".", "task_beta", "=", "model_args", ".", "task_beta", "\n", "config", ".", "embedding_dim", "=", "model_args", ".", "embedding_dim", "\n", "config", ".", "projector", "=", "model_args", ".", "projector", "\n", "config", ".", "hidden_dropout_prob_noise", "=", "model_args", ".", "hidden_dropout_prob_noise", "\n", "config", ".", "hidden_dropout_prob", "=", "model_args", ".", "hidden_dropout_prob", "\n", "# if attention dropout is not specified (default), then take the same values as for hidden", "\n", "if", "model_args", ".", "attention_probs_dropout_prob_noise", "is", "None", ":", "\n", "        ", "config", ".", "attention_probs_dropout_prob_noise", "=", "model_args", ".", "hidden_dropout_prob_noise", "\n", "", "else", ":", "\n", "        ", "config", ".", "attention_probs_dropout_prob_noise", "=", "model_args", ".", "attention_probs_dropout_prob_noise", "\n", "\n", "\n", "\n", "\n", "# if attention dropout is not specified (default), then take the same values as for hidden", "\n", "", "if", "model_args", ".", "attention_probs_dropout_prob", "is", "None", ":", "\n", "        ", "config", ".", "attention_probs_dropout_prob", "=", "model_args", ".", "hidden_dropout_prob", "\n", "", "else", ":", "\n", "        ", "config", ".", "attention_probs_dropout_prob", "=", "model_args", ".", "attention_probs_dropout_prob", "\n", "#SCD - END: parameters", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "if", "'roberta'", "in", "model_args", ".", "model_name_or_path", ":", "\n", "            ", "model", "=", "RobertaForCL", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "model_args", "=", "model_args", "\n", ")", "\n", "", "elif", "'bert'", "in", "model_args", ".", "model_name_or_path", ":", "\n", "            ", "model", "=", "BertForCL", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "model_args", "=", "model_args", "\n", ")", "\n", "if", "model_args", ".", "do_mlm", ":", "\n", "                ", "pretrained_model", "=", "BertForPreTraining", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ")", "\n", "model", ".", "lm_head", ".", "load_state_dict", "(", "\n", "pretrained_model", ".", "cls", ".", "predictions", ".", "state_dict", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelForMaskedLM", ".", "from_config", "(", "config", ")", "\n", "\n", "", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Prepare features", "\n", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "sent2_cname", "=", "None", "\n", "if", "len", "(", "column_names", ")", "==", "2", ":", "\n", "# Pair datasets", "\n", "        ", "sent0_cname", "=", "column_names", "[", "0", "]", "\n", "sent1_cname", "=", "column_names", "[", "1", "]", "\n", "", "elif", "len", "(", "column_names", ")", "==", "3", ":", "\n", "# Pair datasets with hard negatives", "\n", "        ", "sent0_cname", "=", "column_names", "[", "0", "]", "\n", "sent1_cname", "=", "column_names", "[", "1", "]", "\n", "sent2_cname", "=", "column_names", "[", "2", "]", "\n", "", "elif", "len", "(", "column_names", ")", "==", "1", ":", "\n", "# Unsupervised datasets", "\n", "        ", "sent0_cname", "=", "column_names", "[", "0", "]", "\n", "sent1_cname", "=", "column_names", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "def", "prepare_features", "(", "examples", ")", ":", "\n", "# padding = longest (default)", "\n", "#   If no sentence in the batch exceed the max length, then use", "\n", "#   the max sentence length in the batch, otherwise use the", "\n", "#   max sentence length in the argument and truncate those that", "\n", "#   exceed the max length.", "\n", "# padding = max_length (when pad_to_max_length, for pressure test)", "\n", "#   All sentences are padded/truncated to data_args.max_seq_length.", "\n", "        ", "total", "=", "len", "(", "examples", "[", "sent0_cname", "]", ")", "\n", "\n", "# Avoid \"None\" fields", "\n", "for", "idx", "in", "range", "(", "total", ")", ":", "\n", "            ", "if", "examples", "[", "sent0_cname", "]", "[", "idx", "]", "is", "None", ":", "\n", "                ", "examples", "[", "sent0_cname", "]", "[", "idx", "]", "=", "\" \"", "\n", "", "if", "examples", "[", "sent1_cname", "]", "[", "idx", "]", "is", "None", ":", "\n", "                ", "examples", "[", "sent1_cname", "]", "[", "idx", "]", "=", "\" \"", "\n", "\n", "", "", "sentences", "=", "examples", "[", "sent0_cname", "]", "+", "examples", "[", "sent1_cname", "]", "\n", "\n", "# If hard negative exists", "\n", "if", "sent2_cname", "is", "not", "None", ":", "\n", "# SCD - BEGIN", "\n", "            ", "logger", ".", "error", "(", "\"Hard negatives not supposerted\"", ")", "\n", "assert", "False", ",", "\"SCD does not support hard negatives\"", "\n", "# SCD - END", "\n", "for", "idx", "in", "range", "(", "total", ")", ":", "\n", "                ", "if", "examples", "[", "sent2_cname", "]", "[", "idx", "]", "is", "None", ":", "\n", "                    ", "examples", "[", "sent2_cname", "]", "[", "idx", "]", "=", "\" \"", "\n", "", "", "sentences", "+=", "examples", "[", "sent2_cname", "]", "\n", "\n", "", "sent_features", "=", "tokenizer", "(", "\n", "sentences", ",", "\n", "max_length", "=", "data_args", ".", "max_seq_length", ",", "\n", "truncation", "=", "True", ",", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", ",", "\n", ")", "\n", "\n", "features", "=", "{", "}", "\n", "if", "sent2_cname", "is", "not", "None", ":", "\n", "            ", "for", "key", "in", "sent_features", ":", "\n", "                ", "features", "[", "key", "]", "=", "[", "[", "sent_features", "[", "key", "]", "[", "i", "]", ",", "sent_features", "[", "key", "]", "\n", "[", "i", "+", "total", "]", ",", "sent_features", "[", "key", "]", "[", "i", "+", "total", "*", "2", "]", "]", "for", "i", "in", "range", "(", "total", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "for", "key", "in", "sent_features", ":", "\n", "                ", "features", "[", "key", "]", "=", "[", "[", "sent_features", "[", "key", "]", "[", "i", "]", ",", "sent_features", "[", "key", "]", "\n", "[", "i", "+", "total", "]", "]", "for", "i", "in", "range", "(", "total", ")", "]", "\n", "\n", "", "", "return", "features", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "datasets", "[", "\"train\"", "]", ".", "map", "(", "\n", "prepare_features", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "", "@", "dataclass", "\n", "class", "OurDataCollatorWithPadding", ":", "\n", "\n", "        ", "tokenizer", ":", "PreTrainedTokenizerBase", "\n", "padding", ":", "Union", "[", "bool", ",", "str", ",", "PaddingStrategy", "]", "=", "True", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", "\n", "pad_to_multiple_of", ":", "Optional", "[", "int", "]", "=", "None", "\n", "mlm", ":", "bool", "=", "True", "\n", "mlm_probability", ":", "float", "=", "data_args", ".", "mlm_probability", "\n", "\n", "def", "__call__", "(", "self", ",", "features", ":", "List", "[", "Dict", "[", "str", ",", "Union", "[", "List", "[", "int", "]", ",", "List", "[", "List", "[", "int", "]", "]", ",", "torch", ".", "Tensor", "]", "]", "]", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "            ", "special_keys", "=", "[", "'input_ids'", ",", "'attention_mask'", ",", "\n", "'token_type_ids'", ",", "'mlm_input_ids'", ",", "'mlm_labels'", "]", "\n", "bs", "=", "len", "(", "features", ")", "\n", "if", "bs", ">", "0", ":", "\n", "                ", "num_sent", "=", "len", "(", "features", "[", "0", "]", "[", "'input_ids'", "]", ")", "\n", "", "else", ":", "\n", "                ", "return", "\n", "", "flat_features", "=", "[", "]", "\n", "for", "feature", "in", "features", ":", "\n", "                ", "for", "i", "in", "range", "(", "num_sent", ")", ":", "\n", "                    ", "flat_features", ".", "append", "(", "\n", "{", "k", ":", "feature", "[", "k", "]", "[", "i", "]", "if", "k", "in", "special_keys", "else", "feature", "[", "k", "]", "for", "k", "in", "feature", "}", ")", "\n", "\n", "", "", "batch", "=", "self", ".", "tokenizer", ".", "pad", "(", "\n", "flat_features", ",", "\n", "padding", "=", "self", ".", "padding", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "pad_to_multiple_of", "=", "self", ".", "pad_to_multiple_of", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", ")", "\n", "if", "model_args", ".", "do_mlm", ":", "\n", "                ", "batch", "[", "\"mlm_input_ids\"", "]", ",", "batch", "[", "\"mlm_labels\"", "]", "=", "self", ".", "mask_tokens", "(", "\n", "batch", "[", "\"input_ids\"", "]", ")", "\n", "\n", "", "batch", "=", "{", "k", ":", "batch", "[", "k", "]", ".", "view", "(", "\n", "bs", ",", "num_sent", ",", "-", "1", ")", "if", "k", "in", "special_keys", "else", "batch", "[", "k", "]", ".", "view", "(", "bs", ",", "num_sent", ",", "-", "1", ")", "[", ":", ",", "0", "]", "for", "k", "in", "batch", "}", "\n", "\n", "if", "\"label\"", "in", "batch", ":", "\n", "                ", "batch", "[", "\"labels\"", "]", "=", "batch", "[", "\"label\"", "]", "\n", "del", "batch", "[", "\"label\"", "]", "\n", "", "if", "\"label_ids\"", "in", "batch", ":", "\n", "                ", "batch", "[", "\"labels\"", "]", "=", "batch", "[", "\"label_ids\"", "]", "\n", "del", "batch", "[", "\"label_ids\"", "]", "\n", "\n", "", "return", "batch", "\n", "\n", "", "def", "mask_tokens", "(", "\n", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "special_tokens_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "            ", "\"\"\"\n            Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\n            \"\"\"", "\n", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for MLM training (with probability `self.mlm_probability`)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "self", ".", "mlm_probability", ")", "\n", "if", "special_tokens_mask", "is", "None", ":", "\n", "                ", "special_tokens_mask", "=", "[", "\n", "self", ".", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "special_tokens_mask", "=", "torch", ".", "tensor", "(", "\n", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "", "else", ":", "\n", "                ", "special_tokens_mask", "=", "special_tokens_mask", ".", "bool", "(", ")", "\n", "\n", "", "probability_matrix", ".", "masked_fill_", "(", "special_tokens_mask", ",", "value", "=", "0.0", ")", "\n", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "# We only compute loss on masked tokens", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "\n", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", "inputs", "[", "indices_replaced", "]", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "\n", "self", ".", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "\n", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "&", "~", "indices_replaced", "\n", "random_words", "=", "torch", ".", "randint", "(", "\n", "len", "(", "self", ".", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ",", "labels", "\n", "\n", "", "", "data_collator", "=", "default_data_collator", "if", "data_args", ".", "pad_to_max_length", "else", "OurDataCollatorWithPadding", "(", "\n", "tokenizer", ")", "\n", "\n", "trainer", "=", "CLTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "trainer", ".", "model_args", "=", "model_args", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "model_path", "=", "(", "\n", "model_args", ".", "model_name_or_path", "\n", "if", "(", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ")", "\n", "else", "None", "\n", ")", "\n", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "results", "=", "trainer", ".", "evaluate", "(", "eval_senteval_transfer", "=", "False", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "training_args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.train._mp_fn": [[725, 728], ["train.main"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.scd_to_huggingface.main": [[17, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "torch.load", "torch.load.items", "torch.save", "json.load", "range", "json.dump", "os.path.join", "os.path.join", "open", "len", "[].replace", "open", "torch.device", "key.replace.replace", "key.replace.replace", "os.path.join", "os.path.join"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--path\"", ",", "type", "=", "str", ",", "help", "=", "\"Path of SCD checkpoint folder\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "print", "(", "\"SCD checkpoint -> Huggingface checkpoint for {}\"", ".", "format", "(", "args", ".", "path", ")", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "path", ",", "\"pytorch_model.bin\"", ")", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "new_state_dict", "=", "{", "}", "\n", "for", "key", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "# Replace \"mlp\" to \"pooler\"", "\n", "# if \"mlp\" in key:", "\n", "#    key = key.replace(\"mlp\", \"pooler\")", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# Delete \"bert\" or \"roberta\" prefix", "\n", "        ", "if", "\"bert.\"", "in", "key", ":", "\n", "            ", "key", "=", "key", ".", "replace", "(", "\"bert.\"", ",", "\"\"", ")", "\n", "", "if", "\"roberta.\"", "in", "key", ":", "\n", "            ", "key", "=", "key", ".", "replace", "(", "\"roberta.\"", ",", "\"\"", ")", "\n", "\n", "", "new_state_dict", "[", "key", "]", "=", "param", "\n", "\n", "", "torch", ".", "save", "(", "new_state_dict", ",", "os", ".", "path", ".", "join", "(", "args", ".", "path", ",", "\"pytorch_model.bin\"", ")", ")", "\n", "\n", "# Change architectures in config.json", "\n", "config", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "path", ",", "\"config.json\"", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "config", "[", "\"architectures\"", "]", ")", ")", ":", "\n", "        ", "config", "[", "\"architectures\"", "]", "[", "i", "]", "=", "config", "[", "\"architectures\"", "]", "[", "i", "]", ".", "replace", "(", "\"ForCL\"", ",", "\"Model\"", ")", "\n", "", "json", ".", "dump", "(", "config", ",", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "path", ",", "\"config.json\"", ")", ",", "\"w\"", ")", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.print_table": [[33, 38], ["prettytable.PrettyTable", "prettytable.PrettyTable.add_row", "print"], "function", ["None"], ["def", "print_table", "(", "task_names", ",", "scores", ")", ":", "\n", "    ", "tb", "=", "PrettyTable", "(", ")", "\n", "tb", ".", "field_names", "=", "task_names", "\n", "tb", ".", "add_row", "(", "scores", ")", "\n", "print", "(", "tb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.main": [[40, 229], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "transformers.AutoModel.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "torch.device", "model.to.to", "senteval.engine.SE", "senteval.engine.SE.eval", "print", "evaluation.print_table", "task_names.append", "scores.append", "evaluation.print_table", "torch.cuda.is_available", "isinstance", "AutoTokenizer.from_pretrained.batch_encode_plus", "AutoTokenizer.from_pretrained.batch_encode_plus", "batch[].to", "torch.no_grad", "model.to.", "pooler_output.cpu", "task_names.append", "task_names.append", "print", "task_names.append", "scores.append", "evaluation.print_table", "task_names.append", "scores.append", "evaluation.print_table", "len", "len", "last_hidden[].cpu", "scores.append", "scores.append", "scores.append", "scores.append", "task_names.append", "task_names.append", "word.decode", "sum", "len", "scores.append", "scores.append", "scores.append", "pooled_result.cpu", "scores.append", "scores.append", "sum", "len", "sum", "len", "batch[].sum().unsqueeze", "pooled_result.cpu", "float", "batch[].sum().unsqueeze", "batch[].sum().unsqueeze", "float", "float", "batch[].sum", "batch[].sum", "batch[].unsqueeze", "batch[].sum", "batch[].unsqueeze", "batch[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.print_table", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.print_table", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.print_table", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.None.evaluation.print_table"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Transformers' model name or path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pooler\"", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'cls'", ",", "'cls_before_pooler'", ",", "\n", "'avg'", ",", "'avg_top2'", ",", "'avg_first_last'", "]", ",", "\n", "default", "=", "'cls_before_pooler'", ",", "\n", "help", "=", "\"Which pooler to use\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'dev'", ",", "'test'", ",", "'fasttest'", "]", ",", "\n", "default", "=", "'test'", ",", "\n", "help", "=", "\"What evaluation mode to use (dev: fast mode, dev results; test: full mode, test results); fasttest: fast mode, test results\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_set\"", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'sts'", ",", "'transfer'", ",", "'full'", ",", "'na'", ",", "'subset'", "]", ",", "\n", "default", "=", "'sts'", ",", "\n", "help", "=", "\"What set of tasks to evaluate on. If not 'na', this will override '--tasks'\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tasks\"", ",", "type", "=", "str", ",", "nargs", "=", "'+'", ",", "\n", "default", "=", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "'STS16'", ",", "\n", "'MR'", ",", "'CR'", ",", "'MPQA'", ",", "'SUBJ'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", ",", "\n", "'SICKRelatedness'", ",", "'STSBenchmark'", "]", ",", "\n", "help", "=", "\"Tasks to evaluate on. If '--task_set' is specified, this will be overridden\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Load transformers' model checkpoint", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "# Set up the tasks", "\n", "if", "args", ".", "task_set", "==", "'sts'", ":", "\n", "        ", "args", ".", "tasks", "=", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "\n", "'STS16'", ",", "'STSBenchmark'", ",", "'SICKRelatedness'", "]", "\n", "", "elif", "args", ".", "task_set", "==", "'transfer'", ":", "\n", "        ", "args", ".", "tasks", "=", "[", "'MR'", ",", "'CR'", ",", "'MPQA'", ",", "'SUBJ'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", "\n", "", "elif", "args", ".", "task_set", "==", "'full'", ":", "\n", "        ", "args", ".", "tasks", "=", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "\n", "'STS16'", ",", "'STSBenchmark'", ",", "'SICKRelatedness'", "]", "\n", "args", ".", "tasks", "+=", "[", "'MR'", ",", "'CR'", ",", "'MPQA'", ",", "'SUBJ'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", "\n", "", "elif", "args", ".", "task_set", "==", "'subset'", ":", "\n", "        ", "args", ".", "tasks", "=", "[", "'STS12'", ",", "'STS13'", "]", "\n", "args", ".", "tasks", "+=", "[", "'MR'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", "\n", "\n", "# Set params for SentEval", "\n", "", "if", "args", ".", "mode", "==", "'dev'", "or", "args", ".", "mode", "==", "'fasttest'", ":", "\n", "# Fast mode", "\n", "        ", "params", "=", "{", "'task_path'", ":", "PATH_TO_DATA", ",", "'usepytorch'", ":", "True", ",", "'kfold'", ":", "5", "}", "\n", "params", "[", "'classifier'", "]", "=", "{", "'nhid'", ":", "0", ",", "'optim'", ":", "'rmsprop'", ",", "'batch_size'", ":", "128", ",", "\n", "'tenacity'", ":", "3", ",", "'epoch_size'", ":", "2", "}", "\n", "", "elif", "args", ".", "mode", "==", "'test'", ":", "\n", "# Full mode", "\n", "        ", "params", "=", "{", "'task_path'", ":", "PATH_TO_DATA", ",", "'usepytorch'", ":", "True", ",", "'kfold'", ":", "10", "}", "\n", "params", "[", "'classifier'", "]", "=", "{", "'nhid'", ":", "0", ",", "'optim'", ":", "'adam'", ",", "'batch_size'", ":", "64", ",", "\n", "'tenacity'", ":", "5", ",", "'epoch_size'", ":", "4", "}", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# SentEval prepare and batcher", "\n", "", "def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "        ", "return", "\n", "\n", "", "def", "batcher", "(", "params", ",", "batch", ",", "max_length", "=", "None", ")", ":", "\n", "# Handle rare token encoding issues in the dataset", "\n", "        ", "if", "len", "(", "batch", ")", ">=", "1", "and", "len", "(", "batch", "[", "0", "]", ")", ">=", "1", "and", "isinstance", "(", "batch", "[", "0", "]", "[", "0", "]", ",", "bytes", ")", ":", "\n", "            ", "batch", "=", "[", "[", "word", ".", "decode", "(", "'utf-8'", ")", "for", "word", "in", "s", "]", "for", "s", "in", "batch", "]", "\n", "\n", "", "sentences", "=", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "]", "\n", "\n", "# Tokenization", "\n", "if", "max_length", "is", "not", "None", ":", "\n", "            ", "batch", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "sentences", ",", "\n", "return_tensors", "=", "'pt'", ",", "\n", "padding", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", "truncation", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "            ", "batch", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "sentences", ",", "\n", "return_tensors", "=", "'pt'", ",", "\n", "padding", "=", "True", ",", "\n", ")", "\n", "\n", "# Move to the correct device", "\n", "", "for", "k", "in", "batch", ":", "\n", "            ", "batch", "[", "k", "]", "=", "batch", "[", "k", "]", ".", "to", "(", "device", ")", "\n", "\n", "# Get raw embeddings", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "**", "batch", ",", "output_hidden_states", "=", "True", ",", "\n", "return_dict", "=", "True", ")", "\n", "last_hidden", "=", "outputs", ".", "last_hidden_state", "\n", "pooler_output", "=", "outputs", ".", "pooler_output", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", "\n", "\n", "# Apply different poolers", "\n", "", "if", "args", ".", "pooler", "==", "'cls'", ":", "\n", "# There is a linear+activation layer after CLS representation", "\n", "            ", "return", "pooler_output", ".", "cpu", "(", ")", "\n", "", "elif", "args", ".", "pooler", "==", "'cls_before_pooler'", ":", "\n", "            ", "return", "last_hidden", "[", ":", ",", "0", "]", ".", "cpu", "(", ")", "\n", "", "elif", "args", ".", "pooler", "==", "\"avg\"", ":", "\n", "            ", "return", "(", "(", "last_hidden", "*", "batch", "[", "'attention_mask'", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "batch", "[", "'attention_mask'", "]", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "cpu", "(", ")", "\n", "", "elif", "args", ".", "pooler", "==", "\"avg_first_last\"", ":", "\n", "            ", "first_hidden", "=", "hidden_states", "[", "0", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "first_hidden", "+", "last_hidden", ")", "/", "2.0", "*", "batch", "[", "'attention_mask'", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "\n", "1", ")", "/", "batch", "[", "'attention_mask'", "]", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "pooled_result", ".", "cpu", "(", ")", "\n", "", "elif", "args", ".", "pooler", "==", "\"avg_top2\"", ":", "\n", "            ", "second_last_hidden", "=", "hidden_states", "[", "-", "2", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "last_hidden", "+", "second_last_hidden", ")", "/", "2.0", "*", "\n", "batch", "[", "'attention_mask'", "]", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "batch", "[", "'attention_mask'", "]", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "pooled_result", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "results", "=", "{", "}", "\n", "\n", "for", "task", "in", "args", ".", "tasks", ":", "\n", "        ", "se", "=", "senteval", ".", "engine", ".", "SE", "(", "params", ",", "batcher", ",", "prepare", ")", "\n", "result", "=", "se", ".", "eval", "(", "task", ")", "\n", "results", "[", "task", "]", "=", "result", "\n", "\n", "# Print evaluation results", "\n", "", "if", "args", ".", "mode", "==", "'dev'", ":", "\n", "        ", "print", "(", "\"------ %s ------\"", "%", "(", "args", ".", "mode", ")", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "task", "in", "[", "'STSBenchmark'", ",", "'SICKRelatedness'", "]", ":", "\n", "            ", "task_names", ".", "append", "(", "task", ")", "\n", "if", "task", "in", "results", ":", "\n", "                ", "scores", ".", "append", "(", "\"%.2f\"", "%", "\n", "(", "results", "[", "task", "]", "[", "'dev'", "]", "[", "'spearman'", "]", "[", "0", "]", "*", "100", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "\"0.00\"", ")", "\n", "", "", "print_table", "(", "task_names", ",", "scores", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "task", "in", "[", "'MR'", ",", "'CR'", ",", "'SUBJ'", ",", "'MPQA'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", ":", "\n", "            ", "task_names", ".", "append", "(", "task", ")", "\n", "if", "task", "in", "results", ":", "\n", "                ", "scores", ".", "append", "(", "\"%.2f\"", "%", "(", "results", "[", "task", "]", "[", "'devacc'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "\"0.00\"", ")", "\n", "", "", "task_names", ".", "append", "(", "\"Avg.\"", ")", "\n", "scores", ".", "append", "(", "\"%.2f\"", "%", "(", "sum", "(", "[", "float", "(", "score", ")", "\n", "for", "score", "in", "scores", "]", ")", "/", "len", "(", "scores", ")", ")", ")", "\n", "print_table", "(", "task_names", ",", "scores", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "'test'", "or", "args", ".", "mode", "==", "'fasttest'", ":", "\n", "        ", "print", "(", "\"------ %s ------\"", "%", "(", "args", ".", "mode", ")", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "task", "in", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "'STS16'", ",", "'STSBenchmark'", ",", "'SICKRelatedness'", "]", ":", "\n", "            ", "task_names", ".", "append", "(", "task", ")", "\n", "if", "task", "in", "results", ":", "\n", "                ", "if", "task", "in", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "'STS16'", "]", ":", "\n", "                    ", "scores", ".", "append", "(", "\n", "\"%.2f\"", "%", "(", "results", "[", "task", "]", "[", "'all'", "]", "[", "'spearman'", "]", "[", "'all'", "]", "*", "100", ")", ")", "\n", "", "else", ":", "\n", "                    ", "scores", ".", "append", "(", "\n", "\"%.2f\"", "%", "(", "results", "[", "task", "]", "[", "'test'", "]", "[", "'spearman'", "]", ".", "correlation", "*", "100", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "\"0.00\"", ")", "\n", "", "", "task_names", ".", "append", "(", "\"Avg.\"", ")", "\n", "scores", ".", "append", "(", "\"%.2f\"", "%", "(", "sum", "(", "[", "float", "(", "score", ")", "\n", "for", "score", "in", "scores", "]", ")", "/", "len", "(", "scores", ")", ")", ")", "\n", "print_table", "(", "task_names", ",", "scores", ")", "\n", "\n", "task_names", "=", "[", "]", "\n", "scores", "=", "[", "]", "\n", "for", "task", "in", "[", "'MR'", ",", "'CR'", ",", "'SUBJ'", ",", "'MPQA'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", ":", "\n", "            ", "task_names", ".", "append", "(", "task", ")", "\n", "if", "task", "in", "results", ":", "\n", "                ", "scores", ".", "append", "(", "\"%.2f\"", "%", "(", "results", "[", "task", "]", "[", "'acc'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "scores", ".", "append", "(", "\"0.00\"", ")", "\n", "", "", "task_names", ".", "append", "(", "\"Avg.\"", ")", "\n", "scores", ".", "append", "(", "\"%.2f\"", "%", "(", "sum", "(", "[", "float", "(", "score", ")", "\n", "for", "score", "in", "scores", "]", ")", "/", "len", "(", "scores", ")", ")", ")", "\n", "print_table", "(", "task_names", ",", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.MLPLayer.__init__": [[31, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.MLPLayer.forward": [[36, 41], ["models.MLPLayer.dense", "models.MLPLayer.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.Similarity.__init__": [[48, 52], ["torch.Module.__init__", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity", "torch.CosineSimilarity"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "temp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temp", "=", "temp", "\n", "self", ".", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.Similarity.forward": [[53, 55], ["models.Similarity.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "return", "self", ".", "cos", "(", "x", ",", "y", ")", "/", "self", ".", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.Pooler.__init__": [[67, 72], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "pooler_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pooler_type", "=", "pooler_type", "\n", "assert", "self", ".", "pooler_type", "in", "[", "\"cls\"", ",", "\"cls_before_pooler\"", ",", "\"avg\"", ",", "\"avg_top2\"", ",", "\n", "\"avg_first_last\"", "]", ",", "\"unrecognized pooling type %s\"", "%", "self", ".", "pooler_type", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.Pooler.forward": [[73, 96], ["attention_mask.sum().unsqueeze", "attention_mask.sum().unsqueeze", "attention_mask.sum", "attention_mask.sum().unsqueeze", "attention_mask.unsqueeze", "attention_mask.sum", "attention_mask.unsqueeze", "attention_mask.sum", "attention_mask.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "attention_mask", ",", "outputs", ")", ":", "\n", "        ", "last_hidden", "=", "outputs", ".", "last_hidden_state", "\n", "pooler_output", "=", "outputs", ".", "pooler_output", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", "\n", "\n", "if", "self", ".", "pooler_type", "in", "[", "'cls_before_pooler'", ",", "'cls'", "]", ":", "\n", "            ", "return", "last_hidden", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg\"", ":", "\n", "            ", "return", "(", "(", "last_hidden", "*", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg_first_last\"", ":", "\n", "            ", "first_hidden", "=", "hidden_states", "[", "0", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "first_hidden", "+", "last_hidden", ")", "/", "2.0", "*", "\n", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "pooled_result", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg_top2\"", ":", "\n", "            ", "second_last_hidden", "=", "hidden_states", "[", "-", "2", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "last_hidden", "+", "second_last_hidden", ")", "/", "2.0", "*", "\n", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "pooled_result", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.BatchNormWrapper.__init__": [[99, 103], ["torch.Module.__init__", "models.BatchNormWrapper.m.eval"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["    ", "def", "__init__", "(", "self", ",", "m", ")", ":", "\n", "        ", "super", "(", "BatchNormWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "m", ".", "eval", "(", ")", "# Set the batch norm to eval mode", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.BatchNormWrapper.forward": [[104, 108], ["models.BatchNormWrapper.m", "models.BatchNormWrapper.to", "models.BatchNormWrapper.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "input_type", "=", "x", ".", "dtype", "\n", "x", "=", "self", ".", "m", "(", "x", ".", "float", "(", ")", ")", "\n", "return", "x", ".", "to", "(", "input_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.BertForCL.__init__": [[371, 380], ["transformers.models.bert.modeling_bert.BertPreTrainedModel.__init__", "transformers.models.bert.modeling_bert.BertModel", "models.cl_init", "transformers.models.bert.modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_init"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "model_args", ",", "**", "model_kargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_args", "=", "model_kargs", "[", "\"model_args\"", "]", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "\n", "if", "self", ".", "model_args", ".", "do_mlm", ":", "\n", "            ", "self", ".", "lm_head", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n", "", "cl_init", "(", "self", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.BertForCL.forward": [[381, 423], ["models.sentemb_forward", "models.cl_forward"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.sentemb_forward", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_forward"], ["", "def", "forward", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "sent_emb", "=", "False", ",", "\n", "mlm_input_ids", "=", "None", ",", "\n", "mlm_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "sent_emb", ":", "\n", "            ", "return", "sentemb_forward", "(", "self", ",", "self", ".", "bert", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "labels", "=", "labels", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "cl_forward", "(", "self", ",", "self", ".", "bert", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "labels", "=", "labels", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "mlm_input_ids", "=", "mlm_input_ids", ",", "\n", "mlm_labels", "=", "mlm_labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.RobertaForCL.__init__": [[429, 438], ["transformers.models.roberta.modeling_roberta.RobertaPreTrainedModel.__init__", "transformers.models.roberta.modeling_roberta.RobertaModel", "models.cl_init", "transformers.models.roberta.modeling_roberta.RobertaLMHead"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_init"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "model_args", ",", "**", "model_kargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_args", "=", "model_kargs", "[", "\"model_args\"", "]", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "\n", "if", "self", ".", "model_args", ".", "do_mlm", ":", "\n", "            ", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "", "cl_init", "(", "self", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.RobertaForCL.forward": [[439, 481], ["models.sentemb_forward", "models.cl_forward"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.sentemb_forward", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_forward"], ["", "def", "forward", "(", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "sent_emb", "=", "False", ",", "\n", "mlm_input_ids", "=", "None", ",", "\n", "mlm_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "sent_emb", ":", "\n", "            ", "return", "sentemb_forward", "(", "self", ",", "self", ".", "roberta", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "labels", "=", "labels", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "cl_forward", "(", "self", ",", "self", ".", "roberta", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "labels", "=", "labels", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", "mlm_input_ids", "=", "mlm_input_ids", ",", "\n", "mlm_labels", "=", "mlm_labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_init": [[110, 136], ["models.Pooler", "models.MLPLayer", "models.Similarity", "range", "layers.append", "torch.Sequential", "torch.BatchNorm1d", "cls.init_weights", "list", "layers.append", "layers.append", "torch.Linear", "map", "len", "layers.append", "layers.append", "torch.BatchNorm1d", "torch.ReLU", "cls.config.projector.split", "torch.Linear", "torch.Linear"], "function", ["None"], ["", "", "def", "cl_init", "(", "cls", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    Contrastive learning class init function.\n    \"\"\"", "\n", "cls", ".", "pooler_type", "=", "cls", ".", "model_args", ".", "pooler_type", "\n", "cls", ".", "pooler", "=", "Pooler", "(", "cls", ".", "model_args", ".", "pooler_type", ")", "\n", "cls", ".", "mlp", "=", "MLPLayer", "(", "config", ")", "\n", "cls", ".", "sim", "=", "Similarity", "(", "temp", "=", "cls", ".", "model_args", ".", "temp", ")", "\n", "\n", "# SCD - BEGIN: projector", "\n", "sizes", "=", "[", "cls", ".", "config", ".", "embedding_dim", "]", "+", "list", "(", "map", "(", "int", ",", "cls", ".", "config", ".", "projector", ".", "split", "(", "'-'", ")", ")", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sizes", ")", "-", "2", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "bias", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "bias", "=", "False", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "i", "+", "1", "]", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "-", "2", "]", ",", "sizes", "[", "-", "1", "]", ",", "bias", "=", "False", ")", ")", "\n", "cls", ".", "projector", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "cls", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "-", "1", "]", ",", "affine", "=", "False", ")", "\n", "# SCD - END: projector", "\n", "\n", "cls", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.normalize": [[138, 140], ["vec.div", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "def", "normalize", "(", "vec", ")", ":", "\n", "    ", "return", "vec", ".", "div", "(", "torch", ".", "norm", "(", "vec", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.off_diagonal": [[142, 147], ["[].flatten", "[].view", "x.flatten"], "function", ["None"], ["", "def", "off_diagonal", "(", "x", ")", ":", "\n", "# return a flattened view of the off-diagonal elements of a square matrix", "\n", "    ", "n", ",", "m", "=", "x", ".", "shape", "\n", "assert", "n", "==", "m", "\n", "return", "x", ".", "flatten", "(", ")", "[", ":", "-", "1", "]", ".", "view", "(", "n", "-", "1", ",", "n", "+", "1", ")", "[", ":", ",", "1", ":", "]", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.cl_forward": [[149, 319], ["input_ids.view.size", "input_ids.view.size", "input_ids.view.view", "attention_mask.view.view", "encoder", "cls.pooler", "cls.mlp.view", "c.div_", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "torch.diagonal().add_().pow_().sum", "off_diagonal().pow_().sum", "torch.diag().mean", "torch.diag().mean", "torch.diag().mean", "torch.diag().mean", "transformers.modeling_outputs.SequenceClassifierOutput", "token_type_ids.view.view", "mlm_input_ids.view.view", "encoder", "cls.mlp", "torch.is_initialized", "torch.all_gather", "torch.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cls.bn", "len", "torch.CrossEntropyLoss", "mlm_labels.view.view", "cls.lm_head", "nn.CrossEntropyLoss.", "input_ids.view.size", "attention_mask.view.size", "cls.mlp.size", "torch.all_gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "cls.bn", "cls.projector", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "torch.diagonal().add_().pow_", "off_diagonal().pow_", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "mlm_labels.view.size", "cls.lm_head.view", "mlm_labels.view.view", "token_type_ids.view.size", "mlm_input_ids.view.size", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "range", "torch.cat.contiguous", "torch.cat.contiguous", "torch.get_rank", "torch.get_rank", "cls.projector", "cls.sim", "range", "torch.cat.contiguous", "torch.get_rank", "torch.get_world_size", "torch.get_world_size", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "torch.diagonal().add_", "models.off_diagonal", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.get_world_size", "torch.diagonal", "torch.diagonal", "torch.diagonal", "torch.diagonal"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.off_diagonal"], ["", "def", "cl_forward", "(", "cls", ",", "\n", "encoder", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "mlm_input_ids", "=", "None", ",", "\n", "mlm_labels", "=", "None", ",", "\n", ")", ":", "\n", "    ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "cls", ".", "config", ".", "use_return_dict", "\n", "ori_input_ids", "=", "input_ids", "\n", "batch_size", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "# Number of sentences in one instance", "\n", "# 2: pair instance; 3: pair instance with a hard negative", "\n", "num_sent", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "mlm_outputs", "=", "None", "\n", "# Flatten input for encoding", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "\n", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent, len)", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "\n", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent len)", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "        ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "\n", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent, len)", "\n", "\n", "# Get raw embeddings", "\n", "", "outputs", "=", "encoder", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "True", "if", "cls", ".", "model_args", ".", "pooler_type", "in", "[", "\n", "'avg_top2'", ",", "'avg_first_last'", "]", "else", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "\n", "# MLM auxiliary objective", "\n", "if", "mlm_input_ids", "is", "not", "None", ":", "\n", "        ", "mlm_input_ids", "=", "mlm_input_ids", ".", "view", "(", "(", "-", "1", ",", "mlm_input_ids", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "mlm_outputs", "=", "encoder", "(", "\n", "mlm_input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "True", "if", "cls", ".", "model_args", ".", "pooler_type", "in", "[", "\n", "'avg_top2'", ",", "'avg_first_last'", "]", "else", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "\n", "# Pooling", "\n", "", "pooler_output", "=", "cls", ".", "pooler", "(", "attention_mask", ",", "outputs", ")", "\n", "pooler_output", "=", "pooler_output", ".", "view", "(", "\n", "(", "batch_size", ",", "num_sent", ",", "pooler_output", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs, num_sent, hidden)", "\n", "\n", "# If using \"cls\", we add an extra MLP layer", "\n", "# (same as BERT's original implementation) over the representation.", "\n", "if", "cls", ".", "pooler_type", "==", "\"cls\"", ":", "\n", "        ", "pooler_output", "=", "cls", ".", "mlp", "(", "pooler_output", ")", "\n", "\n", "# Separate representation", "\n", "", "z1", ",", "z2", "=", "pooler_output", "[", ":", ",", "0", "]", ",", "pooler_output", "[", ":", ",", "1", "]", "\n", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "\n", "# Hard negative", "\n", "# if num_sent == 3:", "\n", "#    z3 = pooler_output[:, 2]", "\n", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# Gather all embeddings if using distributed training", "\n", "if", "dist", ".", "is_initialized", "(", ")", "and", "cls", ".", "training", ":", "\n", "# Gather hard negative", "\n", "        ", "if", "num_sent", ">=", "3", ":", "\n", "            ", "z3_list", "=", "[", "torch", ".", "zeros_like", "(", "z3", ")", "\n", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z3_list", ",", "tensor", "=", "z3", ".", "contiguous", "(", ")", ")", "\n", "z3_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z3", "\n", "z3", "=", "torch", ".", "cat", "(", "z3_list", ",", "0", ")", "\n", "\n", "# Dummy vectors for allgather", "\n", "", "z1_list", "=", "[", "torch", ".", "zeros_like", "(", "z1", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "z2_list", "=", "[", "torch", ".", "zeros_like", "(", "z2", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "# Allgather", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z1_list", ",", "tensor", "=", "z1", ".", "contiguous", "(", ")", ")", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z2_list", ",", "tensor", "=", "z2", ".", "contiguous", "(", ")", ")", "\n", "\n", "# Since allgather results do not have gradients, we replace the", "\n", "# current process's corresponding embeddings with original tensors", "\n", "z1_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z1", "\n", "z2_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z2", "\n", "# Get full batch embeddings: (bs x N, hidden)", "\n", "z1", "=", "torch", ".", "cat", "(", "z1_list", ",", "0", ")", "\n", "z2", "=", "torch", ".", "cat", "(", "z2_list", ",", "0", ")", "\n", "\n", "", "lambd", "=", "cls", ".", "config", ".", "task_lambda", "\n", "\n", "# empirical cross-correlation matrix", "\n", "c", "=", "cls", ".", "bn", "(", "cls", ".", "projector", "(", "\n", "(", "pooler_output", "[", ":", ",", "0", "]", ")", ")", ")", ".", "T", "@", "cls", ".", "bn", "(", "cls", ".", "projector", "(", "(", "pooler_output", "[", ":", ",", "1", "]", ")", ")", ")", "\n", "\n", "# sum the cross-correlation matrix between all gpus", "\n", "c", ".", "div_", "(", "len", "(", "z1", ")", ")", "\n", "\n", "on_diag", "=", "torch", ".", "diagonal", "(", "c", ")", ".", "add_", "(", "-", "1", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "off_diag", "=", "off_diagonal", "(", "c", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "\n", "decorrelation", "=", "on_diag", "+", "lambd", "*", "off_diag", "\n", "\n", "self_contrast", "=", "torch", ".", "diag", "(", "\n", "cls", ".", "sim", "(", "z1", ".", "unsqueeze", "(", "1", ")", ",", "z2", ".", "unsqueeze", "(", "0", ")", ")", ")", ".", "mean", "(", ")", "\n", "\n", "loss", "=", "cls", ".", "config", ".", "task_alpha", "*", "self_contrast", "+", "cls", ".", "config", ".", "task_beta", "*", "decorrelation", "\n", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "\n", "# # Hard negative", "\n", "# if num_sent >= 3:", "\n", "#     z1_z3_cos = cls.sim(z1.unsqueeze(", "\n", "#         1), (z3+eps*dec_grad3).unsqueeze(0))", "\n", "#     z1_z3_cos[range(len(z1_z3_cos)), range(len(z1_z3_cos))] = 0", "\n", "#     cos_sim = torch.cat([cos_sim, z1_z3_cos], 1)", "\n", "\n", "# labels = torch.arange(cos_sim.size(0)).long().to(cls.device)", "\n", "# loss_fct = nn.CrossEntropyLoss()", "\n", "\n", "# # Calculate loss with hard negatives", "\n", "# if num_sent == 3:", "\n", "#     # Note that weights are actually logits of weights", "\n", "#     z3_weight = cls.model_args.hard_negative_weight", "\n", "#     weights = torch.tensor(", "\n", "#         [[0.0] * (cos_sim.size(-1) - z1_z3_cos.size(-1)) + [0.0] * i + [z3_weight] + [", "\n", "#             0.0] * (z1_z3_cos.size(-1) - i - 1) for i in range(z1_z3_cos.size(-1))]", "\n", "#     ).to(cls.device)", "\n", "#     cos_sim = cos_sim + weights", "\n", "\n", "# loss = loss_fct(cos_sim, labels)", "\n", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# Calculate loss for MLM", "\n", "if", "mlm_outputs", "is", "not", "None", "and", "mlm_labels", "is", "not", "None", ":", "\n", "        ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "mlm_labels", "=", "mlm_labels", ".", "view", "(", "-", "1", ",", "mlm_labels", ".", "size", "(", "-", "1", ")", ")", "\n", "prediction_scores", "=", "cls", ".", "lm_head", "(", "mlm_outputs", ".", "last_hidden_state", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "\n", "prediction_scores", ".", "view", "(", "-", "1", ",", "cls", ".", "config", ".", "vocab_size", ")", ",", "mlm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", "=", "loss", "+", "cls", ".", "model_args", ".", "mlm_weight", "*", "masked_lm_loss", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "        ", "output", "=", "(", "loss", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "loss", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.models.sentemb_forward": [[322, 365], ["encoder", "cls.pooler", "transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions"], "function", ["None"], ["", "def", "sentemb_forward", "(", "\n", "cls", ",", "\n", "encoder", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "\n", "    ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "cls", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "encoder", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "True", "if", "cls", ".", "pooler_type", "in", "[", "\n", "'avg_top2'", ",", "'avg_first_last'", "]", "else", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "\n", "pooler_output", "=", "cls", ".", "pooler", "(", "attention_mask", ",", "outputs", ")", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "# if cls.pooler_type == \"cls\" and not cls.model_args.mlp_only_train:", "\n", "#     pooler_output = cls.mlp(pooler_output)", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "if", "not", "return_dict", ":", "\n", "        ", "return", "(", "outputs", "[", "0", "]", ",", "pooler_output", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPoolingAndCrossAttentions", "(", "\n", "pooler_output", "=", "pooler_output", ",", "\n", "last_hidden_state", "=", "outputs", ".", "last_hidden_state", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.__init__": [[26, 54], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained", "torch.cuda.is_available"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_name_or_path", ":", "str", ",", "\n", "device", ":", "str", "=", "None", ",", "\n", "num_cells", ":", "int", "=", "100", ",", "\n", "num_cells_in_search", ":", "int", "=", "10", ")", ":", "\n", "\n", "        ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name_or_path", ")", "\n", "self", ".", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name_or_path", ")", "\n", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "index", "=", "None", "\n", "self", ".", "is_faiss_index", "=", "False", "\n", "self", ".", "num_cells", "=", "num_cells", "\n", "self", ".", "num_cells_in_search", "=", "num_cells_in_search", "\n", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "# if pooler is not None:", "\n", "#     self.pooler = pooler", "\n", "# elif \"unsup\" in model_name_or_path:", "\n", "#     logger.info(\"Use `cls_before_pooler` for unsupervised models. If you want to use other pooling policy, specify `pooler` argument.\")", "\n", "#     self.pooler = \"cls_before_pooler\"", "\n", "# else:", "\n", "#     self.pooler = \"cls\"", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# SCD BEGIN", "\n", "self", ".", "pooler", "=", "\"cls_before_pooler\"", "\n", "# SCD END", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.encode": [[56, 109], ["tool.SCD.model.to", "isinstance", "torch.cat", "torch.no_grad", "tqdm.tqdm.tqdm", "torch.cat.numpy", "range", "tool.SCD.tokenizer", "tool.SCD.model", "embedding_list.append", "isinstance", "len", "v.to", "torch.cat.cpu", "tool.SCD.items", "torch.cat.norm", "len"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "sentence", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "device", ":", "str", "=", "None", ",", "\n", "return_numpy", ":", "bool", "=", "False", ",", "\n", "normalize_to_unit", ":", "bool", "=", "True", ",", "\n", "keepdim", ":", "bool", "=", "False", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "max_length", ":", "int", "=", "128", ")", "->", "Union", "[", "ndarray", ",", "Tensor", "]", ":", "\n", "\n", "        ", "target_device", "=", "self", ".", "device", "if", "device", "is", "None", "else", "device", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "target_device", ")", "\n", "\n", "single_sentence", "=", "False", "\n", "if", "isinstance", "(", "sentence", ",", "str", ")", ":", "\n", "            ", "sentence", "=", "[", "sentence", "]", "\n", "single_sentence", "=", "True", "\n", "\n", "", "embedding_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "total_batch", "=", "len", "(", "sentence", ")", "//", "batch_size", "+", "(", "1", "if", "len", "(", "sentence", ")", "%", "batch_size", ">", "0", "else", "0", ")", "\n", "for", "batch_id", "in", "tqdm", "(", "range", "(", "total_batch", ")", ")", ":", "\n", "                ", "inputs", "=", "self", ".", "tokenizer", "(", "\n", "sentence", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", ",", "\n", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", "return_tensors", "=", "\"pt\"", "\n", ")", "\n", "inputs", "=", "{", "k", ":", "v", ".", "to", "(", "target_device", ")", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "}", "\n", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ",", "return_dict", "=", "True", ")", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "# if self.pooler == \"cls\":", "\n", "#     embeddings = outputs.pooler_output", "\n", "# elif self.pooler == \"cls_before_pooler\":", "\n", "#     embeddings = outputs.last_hidden_state[:, 0]", "\n", "# else:", "\n", "#     raise NotImplementedError", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# SCD BEGIN", "\n", "embeddings", "=", "outputs", ".", "last_hidden_state", "[", ":", ",", "0", "]", "\n", "# SCD END", "\n", "\n", "if", "normalize_to_unit", ":", "\n", "                    ", "embeddings", "=", "embeddings", "/", "embeddings", ".", "norm", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "embedding_list", ".", "append", "(", "embeddings", ".", "cpu", "(", ")", ")", "\n", "", "", "embeddings", "=", "torch", ".", "cat", "(", "embedding_list", ",", "0", ")", "\n", "\n", "if", "single_sentence", "and", "not", "keepdim", ":", "\n", "            ", "embeddings", "=", "embeddings", "[", "0", "]", "\n", "\n", "", "if", "return_numpy", "and", "not", "isinstance", "(", "embeddings", ",", "ndarray", ")", ":", "\n", "            ", "return", "embeddings", ".", "numpy", "(", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.similarity": [[110, 137], ["tool.SCD.encode", "sklearn.metrics.pairwise.cosine_similarity", "isinstance", "tool.SCD.encode", "query_vecs.reshape.reshape.reshape", "key_vecs.reshape.reshape.reshape", "len", "len", "float"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode"], ["", "def", "similarity", "(", "self", ",", "queries", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "keys", ":", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "ndarray", "]", ",", "\n", "device", ":", "str", "=", "None", ")", "->", "Union", "[", "float", ",", "ndarray", "]", ":", "\n", "\n", "        ", "query_vecs", "=", "self", ".", "encode", "(", "queries", ",", "device", "=", "device", ",", "return_numpy", "=", "True", ")", "# suppose N queries", "\n", "\n", "if", "not", "isinstance", "(", "keys", ",", "ndarray", ")", ":", "\n", "            ", "key_vecs", "=", "self", ".", "encode", "(", "keys", ",", "device", "=", "device", ",", "return_numpy", "=", "True", ")", "# suppose M keys", "\n", "", "else", ":", "\n", "            ", "key_vecs", "=", "keys", "\n", "\n", "# check whether N == 1 or M == 1", "\n", "", "single_query", ",", "single_key", "=", "len", "(", "query_vecs", ".", "shape", ")", "==", "1", ",", "len", "(", "key_vecs", ".", "shape", ")", "==", "1", "\n", "if", "single_query", ":", "\n", "            ", "query_vecs", "=", "query_vecs", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "if", "single_key", ":", "\n", "            ", "key_vecs", "=", "key_vecs", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "# returns an N*M similarity array", "\n", "", "similarities", "=", "cosine_similarity", "(", "query_vecs", ",", "key_vecs", ")", "\n", "\n", "if", "single_query", ":", "\n", "            ", "similarities", "=", "similarities", "[", "0", "]", "\n", "if", "single_key", ":", "\n", "                ", "similarities", "=", "float", "(", "similarities", "[", "0", "]", ")", "\n", "\n", "", "", "return", "similarities", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.build_index": [[138, 196], ["isinstance", "logger.info", "tool.SCD.encode", "logger.info", "logger.info", "faiss.IndexFlatIP", "faiss.index_cpu_to_gpu.add", "min", "hasattr", "open", "logging.info", "tqdm.tqdm.tqdm", "faiss.IndexIVFFlat", "hasattr", "logger.info", "faiss.index_cpu_to_gpu.train", "tool.SCD.astype", "len", "logger.warning", "sentences.append", "min", "logger.info", "faiss.StandardGpuResources", "faiss.StandardGpuResources.setTempMemory", "faiss.index_cpu_to_gpu", "logger.info", "tool.SCD.astype", "line.rstrip", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train"], ["", "def", "build_index", "(", "self", ",", "sentences_or_file_path", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "use_faiss", ":", "bool", "=", "None", ",", "\n", "faiss_fast", ":", "bool", "=", "False", ",", "\n", "device", ":", "str", "=", "None", ",", "\n", "batch_size", ":", "int", "=", "64", ")", ":", "\n", "\n", "        ", "if", "use_faiss", "is", "None", "or", "use_faiss", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "faiss", "\n", "assert", "hasattr", "(", "faiss", ",", "\"IndexFlatIP\"", ")", "\n", "use_faiss", "=", "True", "\n", "", "except", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Fail to import faiss. If you want to use faiss, install faiss through PyPI. Now the program continues with brute force search.\"", ")", "\n", "use_faiss", "=", "False", "\n", "\n", "# if the input sentence is a string, we assume it's the path of file that stores various sentences", "\n", "", "", "if", "isinstance", "(", "sentences_or_file_path", ",", "str", ")", ":", "\n", "            ", "sentences", "=", "[", "]", "\n", "with", "open", "(", "sentences_or_file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "logging", ".", "info", "(", "\"Loading sentences from %s ...\"", "%", "(", "sentences_or_file_path", ")", ")", "\n", "for", "line", "in", "tqdm", "(", "f", ")", ":", "\n", "                    ", "sentences", ".", "append", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "sentences_or_file_path", "=", "sentences", "\n", "\n", "", "logger", ".", "info", "(", "\"Encoding embeddings for sentences...\"", ")", "\n", "embeddings", "=", "self", ".", "encode", "(", "sentences_or_file_path", ",", "device", "=", "device", ",", "batch_size", "=", "batch_size", ",", "normalize_to_unit", "=", "True", ",", "return_numpy", "=", "True", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building index...\"", ")", "\n", "self", ".", "index", "=", "{", "\"sentences\"", ":", "sentences_or_file_path", "}", "\n", "\n", "if", "use_faiss", ":", "\n", "            ", "quantizer", "=", "faiss", ".", "IndexFlatIP", "(", "embeddings", ".", "shape", "[", "1", "]", ")", "\n", "if", "faiss_fast", ":", "\n", "                ", "index", "=", "faiss", ".", "IndexIVFFlat", "(", "quantizer", ",", "embeddings", ".", "shape", "[", "1", "]", ",", "min", "(", "self", ".", "num_cells", ",", "len", "(", "sentences_or_file_path", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "index", "=", "quantizer", "\n", "\n", "", "if", "(", "self", ".", "device", "==", "\"cuda\"", "and", "device", "!=", "\"cpu\"", ")", "or", "device", "==", "\"cuda\"", ":", "\n", "                ", "if", "hasattr", "(", "faiss", ",", "\"StandardGpuResources\"", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Use GPU-version faiss\"", ")", "\n", "res", "=", "faiss", ".", "StandardGpuResources", "(", ")", "\n", "res", ".", "setTempMemory", "(", "20", "*", "1024", "*", "1024", "*", "1024", ")", "\n", "index", "=", "faiss", ".", "index_cpu_to_gpu", "(", "res", ",", "0", ",", "index", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Use CPU-version faiss\"", ")", "\n", "", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"Use CPU-version faiss\"", ")", "\n", "\n", "", "if", "faiss_fast", ":", "\n", "                ", "index", ".", "train", "(", "embeddings", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "", "index", ".", "add", "(", "embeddings", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "index", ".", "nprobe", "=", "min", "(", "self", ".", "num_cells_in_search", ",", "len", "(", "sentences_or_file_path", ")", ")", "\n", "self", ".", "is_faiss_index", "=", "True", "\n", "", "else", ":", "\n", "            ", "index", "=", "embeddings", "\n", "self", ".", "is_faiss_index", "=", "False", "\n", "", "self", ".", "index", "[", "\"index\"", "]", "=", "index", "\n", "logger", ".", "info", "(", "\"Finished\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.search": [[197, 235], ["isinstance", "tool.SCD.similarity().tolist", "enumerate", "tool.SCD.encode", "tool.SCD.index[].search", "isinstance", "sorted", "tool.SCD.astype", "range", "tool.SCD.search.pack_single_result"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.search"], ["", "def", "search", "(", "self", ",", "queries", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "device", ":", "str", "=", "None", ",", "\n", "threshold", ":", "float", "=", "0.6", ",", "\n", "top_k", ":", "int", "=", "5", ")", "->", "Union", "[", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", ",", "List", "[", "List", "[", "Tuple", "[", "str", ",", "float", "]", "]", "]", "]", ":", "\n", "\n", "        ", "if", "not", "self", ".", "is_faiss_index", ":", "\n", "            ", "if", "isinstance", "(", "queries", ",", "list", ")", ":", "\n", "                ", "combined_results", "=", "[", "]", "\n", "for", "query", "in", "queries", ":", "\n", "                    ", "results", "=", "self", ".", "search", "(", "query", ",", "device", ")", "\n", "combined_results", ".", "append", "(", "results", ")", "\n", "", "return", "combined_results", "\n", "\n", "", "similarities", "=", "self", ".", "similarity", "(", "queries", ",", "self", ".", "index", "[", "\"index\"", "]", ")", ".", "tolist", "(", ")", "\n", "id_and_score", "=", "[", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "similarities", ")", ":", "\n", "                ", "if", "s", ">=", "threshold", ":", "\n", "                    ", "id_and_score", ".", "append", "(", "(", "i", ",", "s", ")", ")", "\n", "", "", "id_and_score", "=", "sorted", "(", "id_and_score", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "[", ":", "top_k", "]", "\n", "results", "=", "[", "(", "self", ".", "index", "[", "\"sentences\"", "]", "[", "idx", "]", ",", "score", ")", "for", "idx", ",", "score", "in", "id_and_score", "]", "\n", "return", "results", "\n", "", "else", ":", "\n", "            ", "query_vecs", "=", "self", ".", "encode", "(", "queries", ",", "device", "=", "device", ",", "normalize_to_unit", "=", "True", ",", "keepdim", "=", "True", ",", "return_numpy", "=", "True", ")", "\n", "\n", "distance", ",", "idx", "=", "self", ".", "index", "[", "\"index\"", "]", ".", "search", "(", "query_vecs", ".", "astype", "(", "np", ".", "float32", ")", ",", "top_k", ")", "\n", "\n", "def", "pack_single_result", "(", "dist", ",", "idx", ")", ":", "\n", "                ", "results", "=", "[", "(", "self", ".", "index", "[", "\"sentences\"", "]", "[", "i", "]", ",", "s", ")", "for", "i", ",", "s", "in", "zip", "(", "idx", ",", "dist", ")", "if", "s", ">=", "threshold", "]", "\n", "return", "results", "\n", "\n", "", "if", "isinstance", "(", "queries", ",", "list", ")", ":", "\n", "                ", "combined_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "queries", ")", ")", ":", "\n", "                    ", "results", "=", "pack_single_result", "(", "distance", "[", "i", "]", ",", "idx", "[", "i", "]", ")", "\n", "combined_results", ".", "append", "(", "results", ")", "\n", "", "return", "combined_results", "\n", "", "else", ":", "\n", "                ", "return", "pack_single_result", "(", "distance", "[", "0", "]", ",", "idx", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.__init__": [[108, 113], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "max_avg_sts", "=", "0", "\n", "self", ".", "max_sickr_spearman", "=", "0", "\n", "self", ".", "max_stsb_spearman", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.evaluate": [[114, 174], ["senteval.engine.SE", "trainers.CLTrainer.model.eval", "senteval.engine.SE.eval", "numpy.max", "numpy.max", "numpy.max", "trainers.CLTrainer.log", "trainers.CLTrainer.tokenizer.batch_encode_plus", "pooler_output.cpu", "batch[].to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "trainers.CLTrainer.model"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "evaluate", "(", "\n", "self", ",", "\n", "eval_dataset", ":", "Optional", "[", "Dataset", "]", "=", "None", ",", "\n", "ignore_keys", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "metric_key_prefix", ":", "str", "=", "\"eval\"", ",", "\n", "eval_senteval_transfer", ":", "bool", "=", "False", ",", "\n", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "\n", "# SentEval prepare and batcher", "\n", "        ", "def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "            ", "return", "\n", "\n", "", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "            ", "sentences", "=", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "]", "\n", "batch", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "\n", "sentences", ",", "\n", "return_tensors", "=", "'pt'", ",", "\n", "padding", "=", "True", ",", "\n", ")", "\n", "for", "k", "in", "batch", ":", "\n", "                ", "batch", "[", "k", "]", "=", "batch", "[", "k", "]", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "self", ".", "model", "(", "**", "batch", ",", "output_hidden_states", "=", "True", ",", "return_dict", "=", "True", ",", "sent_emb", "=", "True", ")", "\n", "pooler_output", "=", "outputs", ".", "pooler_output", "\n", "", "return", "pooler_output", ".", "cpu", "(", ")", "\n", "\n", "# Set params for SentEval (fastmode)", "\n", "", "params", "=", "{", "'task_path'", ":", "PATH_TO_DATA", ",", "'usepytorch'", ":", "True", ",", "'kfold'", ":", "5", "}", "\n", "params", "[", "'classifier'", "]", "=", "{", "'nhid'", ":", "0", ",", "'optim'", ":", "'rmsprop'", ",", "'batch_size'", ":", "128", ",", "\n", "'tenacity'", ":", "3", ",", "'epoch_size'", ":", "2", "}", "\n", "\n", "se", "=", "senteval", ".", "engine", ".", "SE", "(", "params", ",", "batcher", ",", "prepare", ")", "\n", "tasks", "=", "[", "'STSBenchmark'", ",", "'SICKRelatedness'", "]", "\n", "if", "eval_senteval_transfer", "or", "self", ".", "args", ".", "eval_transfer", ":", "\n", "            ", "tasks", "=", "[", "'STSBenchmark'", ",", "'SICKRelatedness'", ",", "'MR'", ",", "'CR'", ",", "'SUBJ'", ",", "'MPQA'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "results", "=", "se", ".", "eval", "(", "tasks", ")", "\n", "\n", "stsb_spearman", "=", "results", "[", "'STSBenchmark'", "]", "[", "'dev'", "]", "[", "'spearman'", "]", "[", "0", "]", "\n", "sickr_spearman", "=", "results", "[", "'SICKRelatedness'", "]", "[", "'dev'", "]", "[", "'spearman'", "]", "[", "0", "]", "\n", "\n", "self", ".", "max_avg_sts", "=", "np", ".", "max", "(", "\n", "[", "self", ".", "max_avg_sts", ",", "(", "stsb_spearman", "+", "sickr_spearman", ")", "/", "2", "]", ")", "\n", "self", ".", "max_stsb_spearman", "=", "np", ".", "max", "(", "\n", "[", "self", ".", "max_stsb_spearman", ",", "stsb_spearman", "]", ")", "\n", "self", ".", "max_sickr_spearman", "=", "np", ".", "max", "(", "\n", "[", "self", ".", "max_sickr_spearman", ",", "sickr_spearman", "]", ")", "\n", "\n", "metrics", "=", "{", "\"eval_maxavg_sts\"", ":", "self", ".", "max_avg_sts", ",", "\"eval_maxsickr_spearman\"", ":", "self", ".", "max_sickr_spearman", ",", "\"eval_maxstsb_spearman\"", ":", "self", ".", "max_stsb_spearman", ",", "\"eval_stsb_spearman\"", ":", "stsb_spearman", ",", "\n", "\"eval_sickr_spearman\"", ":", "sickr_spearman", ",", "\"eval_avg_sts\"", ":", "(", "stsb_spearman", "+", "sickr_spearman", ")", "/", "2", "}", "\n", "if", "eval_senteval_transfer", "or", "self", ".", "args", ".", "eval_transfer", ":", "\n", "            ", "avg_transfer", "=", "0", "\n", "for", "task", "in", "[", "'MR'", ",", "'CR'", ",", "'SUBJ'", ",", "'MPQA'", ",", "'SST2'", ",", "'TREC'", ",", "'MRPC'", "]", ":", "\n", "                ", "avg_transfer", "+=", "results", "[", "task", "]", "[", "'devacc'", "]", "\n", "metrics", "[", "'eval_{}'", ".", "format", "(", "task", ")", "]", "=", "results", "[", "task", "]", "[", "'devacc'", "]", "\n", "", "avg_transfer", "/=", "7", "\n", "metrics", "[", "'eval_avg_transfer'", "]", "=", "avg_transfer", "\n", "\n", "", "self", ".", "log", "(", "metrics", ")", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer._save_checkpoint": [[175, 274], ["trainers._model_unwrap", "trainers.CLTrainer.save_model", "transformers.file_utils.is_torch_tpu_available", "trainers.CLTrainer.is_world_process_zero", "trainers.CLTrainer.is_world_process_zero", "metric_to_check.startswith", "operator", "trainers.CLTrainer.save_model", "transformers.file_utils.is_torch_tpu_available", "trainers.CLTrainer.is_world_process_zero", "os.path.join", "os.path.join", "trainers.CLTrainer.store_flos", "trainers.CLTrainer.deepspeed.save_checkpoint", "xm.rendezvous", "xm.save", "trainers.CLTrainer.state.save_to_json", "trainers.CLTrainer._rotate_checkpoints", "trainers.CLTrainer.deepspeed.save_checkpoint", "xm.rendezvous", "xm.save", "trainers.CLTrainer.state.save_to_json", "tune.get_trial_id", "trainers.CLTrainer.hp_name", "trainers.CLTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "xm.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "trainers.CLTrainer.is_world_process_zero", "torch.save", "torch.save", "torch.save", "torch.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "os.path.join", "trainers.CLTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "xm.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "trainers.CLTrainer.is_world_process_zero", "torch.save", "torch.save", "torch.save", "torch.save", "transformers.trainer_pt_utils.reissue_pt_warnings", "os.path.join", "trainers.CLTrainer.lr_scheduler.state_dict", "os.path.join", "trainers.CLTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "torch.save", "torch.save", "torch.save", "torch.save", "trainers.CLTrainer.lr_scheduler.state_dict", "os.path.join", "trainers.CLTrainer.optimizer.state_dict", "os.path.join", "warnings.catch_warnings", "torch.save", "torch.save", "torch.save", "torch.save", "trainers.CLTrainer.lr_scheduler.state_dict", "os.path.join", "trainers.CLTrainer.lr_scheduler.state_dict", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers._model_unwrap"], ["", "def", "_save_checkpoint", "(", "self", ",", "model", ",", "trial", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compared to original implementation, we change the saving policy to\n        only save the best-validation checkpoints.\n        \"\"\"", "\n", "\n", "# In all cases, including ddp/dp/deepspeed, self.model is always a reference to the model we", "\n", "# want to save.", "\n", "assert", "_model_unwrap", "(", "model", ")", "is", "self", ".", "model", ",", "\"internal model should be a reference to self.model\"", "\n", "\n", "# Determine the new best metric / best model checkpoint", "\n", "if", "metrics", "is", "not", "None", "and", "self", ".", "args", ".", "metric_for_best_model", "is", "not", "None", ":", "\n", "            ", "metric_to_check", "=", "self", ".", "args", ".", "metric_for_best_model", "\n", "if", "not", "metric_to_check", ".", "startswith", "(", "\"eval_\"", ")", ":", "\n", "                ", "metric_to_check", "=", "f\"eval_{metric_to_check}\"", "\n", "", "metric_value", "=", "metrics", "[", "metric_to_check", "]", "\n", "\n", "operator", "=", "np", ".", "greater", "if", "self", ".", "args", ".", "greater_is_better", "else", "np", ".", "less", "\n", "if", "(", "\n", "self", ".", "state", ".", "best_metric", "is", "None", "\n", "or", "self", ".", "state", ".", "best_model_checkpoint", "is", "None", "\n", "or", "operator", "(", "metric_value", ",", "self", ".", "state", ".", "best_metric", ")", "\n", ")", ":", "\n", "                ", "output_dir", "=", "self", ".", "args", ".", "output_dir", "\n", "self", ".", "state", ".", "best_metric", "=", "metric_value", "\n", "self", ".", "state", ".", "best_model_checkpoint", "=", "output_dir", "\n", "\n", "# Only save model when it is the best one", "\n", "self", ".", "save_model", "(", "output_dir", ")", "\n", "if", "self", ".", "deepspeed", ":", "\n", "                    ", "self", ".", "deepspeed", ".", "save_checkpoint", "(", "output_dir", ")", "\n", "\n", "# Save optimizer and scheduler", "\n", "#if self.sharded_dpp:", "\n", "#    self.optimizer.consolidate_state_dict()", "\n", "\n", "", "if", "is_torch_tpu_available", "(", ")", ":", "\n", "                    ", "xm", ".", "rendezvous", "(", "\"saving_optimizer_states\"", ")", "\n", "xm", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                        ", "xm", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "", "", "elif", "self", ".", "is_world_process_zero", "(", ")", "and", "not", "self", ".", "deepspeed", ":", "\n", "# deepspeed.save_checkpoint above saves model/optim/sched", "\n", "                    ", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                        ", "torch", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "\n", "# Save the Trainer state", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "                    ", "self", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "", "", "", "else", ":", "\n", "# Save model checkpoint", "\n", "            ", "checkpoint_folder", "=", "f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"", "\n", "\n", "if", "self", ".", "hp_search_backend", "is", "not", "None", "and", "trial", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "hp_search_backend", "==", "HPSearchBackend", ".", "OPTUNA", ":", "\n", "                    ", "run_id", "=", "trial", ".", "number", "\n", "", "else", ":", "\n", "                    ", "from", "ray", "import", "tune", "\n", "\n", "run_id", "=", "tune", ".", "get_trial_id", "(", ")", "\n", "", "run_name", "=", "self", ".", "hp_name", "(", "trial", ")", "if", "self", ".", "hp_name", "is", "not", "None", "else", "f\"run-{run_id}\"", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "run_name", ",", "checkpoint_folder", ")", "\n", "", "else", ":", "\n", "                ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "checkpoint_folder", ")", "\n", "\n", "self", ".", "store_flos", "(", ")", "\n", "\n", "", "self", ".", "save_model", "(", "output_dir", ")", "\n", "if", "self", ".", "deepspeed", ":", "\n", "                ", "self", ".", "deepspeed", ".", "save_checkpoint", "(", "output_dir", ")", "\n", "\n", "# Save optimizer and scheduler", "\n", "#if self.sharded_dpp:", "\n", "#    self.optimizer.consolidate_state_dict()", "\n", "\n", "", "if", "is_torch_tpu_available", "(", ")", ":", "\n", "                ", "xm", ".", "rendezvous", "(", "\"saving_optimizer_states\"", ")", "\n", "xm", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                    ", "xm", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "", "", "elif", "self", ".", "is_world_process_zero", "(", ")", "and", "not", "self", ".", "deepspeed", ":", "\n", "# deepspeed.save_checkpoint above saves model/optim/sched", "\n", "                ", "torch", ".", "save", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "with", "warnings", ".", "catch_warnings", "(", "record", "=", "True", ")", "as", "caught_warnings", ":", "\n", "                    ", "torch", ".", "save", "(", "self", ".", "lr_scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "", "reissue_pt_warnings", "(", "caught_warnings", ")", "\n", "\n", "\n", "# Save the Trainer state", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "                ", "self", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Maybe delete some older checkpoints.", "\n", "", "if", "self", ".", "is_world_process_zero", "(", ")", ":", "\n", "                ", "self", ".", "_rotate_checkpoints", "(", "use_mtime", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train": [[275, 595], ["trainers.CLTrainer._hp_search_setup", "isinstance", "trainers.CLTrainer.get_train_dataloader", "transformers.trainer_callback.TrainerState", "trainers.CLTrainer._load_optimizer_and_scheduler", "transformers.file_utils.is_torch_tpu_available", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "time.time", "trainers.CLTrainer.is_local_process_zero", "trainers.CLTrainer.is_world_process_zero", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "model.to.to.zero_grad", "trainers.CLTrainer.callback_handler.on_train_begin", "range", "logger.info", "transformers.trainer_utils.speed_metrics", "trainers.CLTrainer.log", "trainers.CLTrainer.callback_handler.on_train_end", "torch.tensor().to.item", "torch.tensor().to.item", "transformers.trainer_utils.TrainOutput", "transformers.trainer_utils.set_seed", "trainers.CLTrainer.call_model_init", "max", "init_deepspeed", "trainers.CLTrainer.create_optimizer_and_scheduler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "trainers.CLTrainer.num_examples", "os.path.isfile", "transformers.trainer_callback.TrainerState.load_from_json", "logger.info", "logger.info", "logger.info", "trainers.CLTrainer.hp_name", "hp_params", "range", "trainers.CLTrainer.callback_handler.on_epoch_begin", "enumerate", "trainers.CLTrainer.callback_handler.on_epoch_end", "trainers.CLTrainer._maybe_log_save_evaluate", "hasattr", "delattr", "logger.info", "isinstance", "trainers.CLTrainer.store_flos", "model.to.to.to", "len", "math.ceil", "math.ceil", "xm.xrt_world_size", "os.path.join", "os.path.join", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "isinstance", "isinstance", "trainers.CLTrainer.sampler.set_epoch", "len", "trainers.CLTrainer.floating_point_ops", "transformers.file_utils.is_torch_tpu_available", "trainers.CLTrainer.model.from_pretrained", "torch.load", "torch.load", "torch.load", "torch.load", "trainers.CLTrainer.model.load_state_dict", "trainers.CLTrainer.deepspeed.load_checkpoint", "int", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "torch.distributed.get_world_size", "logger.warning", "trainers.CLTrainer.callback_handler.on_step_begin", "trainers.CLTrainer.training_step", "transformers.file_utils.is_torch_tpu_available", "trainers.CLTrainer.lr_scheduler.step", "model.to.to.zero_grad", "trainers.CLTrainer.callback_handler.on_step_end", "trainers.CLTrainer._maybe_log_save_evaluate", "xm.master_print", "logger.warning", "trainers.CLTrainer.model.to", "os.path.join", "isinstance", "model.to.to.no_sync", "trainers.CLTrainer.training_step", "hasattr", "xm.optimizer_step", "met.metrics_report", "getattr", "trainers.CLTrainer.scaler.unscale_", "trainers.CLTrainer.optimizer.clip_grad_norm", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "trainers.CLTrainer.scaler.step", "trainers.CLTrainer.scaler.update", "trainers.CLTrainer.optimizer.step", "amp.master_params", "model.to.to.parameters"], "methods", ["None"], ["", "", "", "def", "train", "(", "self", ",", "model_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "trial", ":", "Union", "[", "\"optuna.Trial\"", ",", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Main training entry point.\n\n        Args:\n            model_path (:obj:`str`, `optional`):\n                Local path to the model if the model to train has been instantiated from a local path. If present,\n                training will resume from the optimizer/scheduler states loaded here.\n            trial (:obj:`optuna.Trial` or :obj:`Dict[str, Any]`, `optional`):\n                The trial run or the hyperparameter dictionary for hyperparameter search.\n        \n        The main difference between ours and Huggingface's original implementation is that we \n        also load model_args when reloading best checkpoints for evaluation.\n        \"\"\"", "\n", "# This might change the seed so needs to run first.", "\n", "self", ".", "_hp_search_setup", "(", "trial", ")", "\n", "\n", "# Model re-init", "\n", "if", "self", ".", "model_init", "is", "not", "None", ":", "\n", "# Seed must be set before instantiating the model when using model_init.", "\n", "            ", "set_seed", "(", "self", ".", "args", ".", "seed", ")", "\n", "\n", "model", "=", "self", ".", "call_model_init", "(", "trial", ")", "\n", "if", "not", "self", ".", "is_model_parallel", ":", "\n", "                ", "model", "=", "model", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "model_wrapped", "=", "model", "\n", "\n", "# Reinitializes optimizer and scheduler", "\n", "self", ".", "optimizer", ",", "self", ".", "lr_scheduler", "=", "None", ",", "None", "\n", "\n", "# Keeping track whether we can can len() on the dataset or not", "\n", "", "train_dataset_is_sized", "=", "isinstance", "(", "self", ".", "train_dataset", ",", "collections", ".", "abc", ".", "Sized", ")", "\n", "\n", "# Data loader and number of training steps", "\n", "train_dataloader", "=", "self", ".", "get_train_dataloader", "(", ")", "\n", "\n", "# Setting up training control variables:", "\n", "# number of training epochs: num_train_epochs", "\n", "# number of training steps per epoch: num_update_steps_per_epoch", "\n", "# total number of training steps to execute: max_steps", "\n", "if", "train_dataset_is_sized", ":", "\n", "            ", "num_update_steps_per_epoch", "=", "len", "(", "train_dataloader", ")", "//", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "num_update_steps_per_epoch", "=", "max", "(", "num_update_steps_per_epoch", ",", "1", ")", "\n", "if", "self", ".", "args", ".", "max_steps", ">", "0", ":", "\n", "                ", "max_steps", "=", "self", ".", "args", ".", "max_steps", "\n", "num_train_epochs", "=", "self", ".", "args", ".", "max_steps", "//", "num_update_steps_per_epoch", "+", "int", "(", "\n", "self", ".", "args", ".", "max_steps", "%", "num_update_steps_per_epoch", ">", "0", "\n", ")", "\n", "", "else", ":", "\n", "                ", "max_steps", "=", "math", ".", "ceil", "(", "self", ".", "args", ".", "num_train_epochs", "*", "num_update_steps_per_epoch", ")", "\n", "num_train_epochs", "=", "math", ".", "ceil", "(", "self", ".", "args", ".", "num_train_epochs", ")", "\n", "", "", "else", ":", "\n", "# see __init__. max_steps is set when the dataset has no __len__", "\n", "            ", "max_steps", "=", "self", ".", "args", ".", "max_steps", "\n", "num_train_epochs", "=", "1", "\n", "num_update_steps_per_epoch", "=", "max_steps", "\n", "\n", "", "if", "self", ".", "args", ".", "deepspeed", ":", "\n", "            ", "model", ",", "optimizer", ",", "lr_scheduler", "=", "init_deepspeed", "(", "self", ",", "num_training_steps", "=", "max_steps", ")", "\n", "self", ".", "model", "=", "model", ".", "module", "\n", "self", ".", "model_wrapped", "=", "model", "# will get further wrapped in DDP", "\n", "self", ".", "deepspeed", "=", "model", "# DeepSpeedEngine object", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "", "else", ":", "\n", "            ", "self", ".", "create_optimizer_and_scheduler", "(", "num_training_steps", "=", "max_steps", ")", "\n", "\n", "", "self", ".", "state", "=", "TrainerState", "(", ")", "\n", "self", ".", "state", ".", "is_hyper_param_search", "=", "trial", "is", "not", "None", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "self", ".", "_load_optimizer_and_scheduler", "(", "model_path", ")", "\n", "\n", "model", "=", "self", ".", "model_wrapped", "\n", "\n", "# Mixed precision training with apex (torch < 1.6)", "\n", "if", "self", ".", "use_apex", ":", "\n", "            ", "model", ",", "self", ".", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "self", ".", "optimizer", ",", "opt_level", "=", "self", ".", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# Multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "self", ".", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "#if self.sharded_dpp:", "\n", "#    model = ShardedDDP(model, self.optimizer)", "\n", "", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "self", ".", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "self", ".", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "(", "\n", "not", "getattr", "(", "model", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", "\n", "if", "isinstance", "(", "model", ",", "PreTrainedModel", ")", "\n", "else", "True", "\n", ")", ",", "\n", ")", "\n", "# find_unused_parameters breaks checkpointing as per", "\n", "# https://github.com/huggingface/transformers/pull/4659#issuecomment-643356021", "\n", "\n", "# for the rest of this function `model` is the outside model, whether it was wrapped or not", "\n", "", "if", "model", "is", "not", "self", ".", "model", ":", "\n", "            ", "self", ".", "model_wrapped", "=", "model", "\n", "\n", "# important: at this point:", "\n", "# self.model         is the Transformers Model", "\n", "# self.model_wrapped is DDP(Transformers Model), DDP(Deepspeed(Transformers Model)), etc.", "\n", "\n", "# Train!", "\n", "", "if", "is_torch_tpu_available", "(", ")", ":", "\n", "            ", "total_train_batch_size", "=", "self", ".", "args", ".", "train_batch_size", "*", "xm", ".", "xrt_world_size", "(", ")", "\n", "", "else", ":", "\n", "            ", "total_train_batch_size", "=", "(", "\n", "self", ".", "args", ".", "train_batch_size", "\n", "*", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "self", ".", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", "\n", "", "num_examples", "=", "(", "\n", "self", ".", "num_examples", "(", "train_dataloader", ")", "\n", "if", "train_dataset_is_sized", "\n", "else", "total_train_batch_size", "*", "self", ".", "args", ".", "max_steps", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "f\"  Num examples = {num_examples}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Num Epochs = {num_train_epochs}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Instantaneous batch size per device = {self.args.per_device_train_batch_size}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_train_batch_size}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Gradient Accumulation steps = {self.args.gradient_accumulation_steps}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Total optimization steps = {max_steps}\"", ")", "\n", "\n", "self", ".", "state", ".", "epoch", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "model_path", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"trainer_state.json\"", ")", ")", ":", "\n", "            ", "self", ".", "state", "=", "TrainerState", ".", "load_from_json", "(", "os", ".", "path", ".", "join", "(", "model_path", ",", "\"trainer_state.json\"", ")", ")", "\n", "epochs_trained", "=", "self", ".", "state", ".", "global_step", "//", "num_update_steps_per_epoch", "\n", "if", "not", "self", ".", "args", ".", "ignore_data_skip", ":", "\n", "                ", "steps_trained_in_current_epoch", "=", "self", ".", "state", ".", "global_step", "%", "(", "num_update_steps_per_epoch", ")", "\n", "steps_trained_in_current_epoch", "*=", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "", "else", ":", "\n", "                ", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "f\"  Continuing training from epoch {epochs_trained}\"", ")", "\n", "logger", ".", "info", "(", "f\"  Continuing training from global step {self.state.global_step}\"", ")", "\n", "if", "not", "self", ".", "args", ".", "ignore_data_skip", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "f\"  Will skip the first {epochs_trained} epochs then the first {steps_trained_in_current_epoch} \"", "\n", "\"batches in the first epoch.\"", "\n", ")", "\n", "\n", "# Update the references", "\n", "", "", "self", ".", "callback_handler", ".", "model", "=", "self", ".", "model", "\n", "self", ".", "callback_handler", ".", "optimizer", "=", "self", ".", "optimizer", "\n", "self", ".", "callback_handler", ".", "lr_scheduler", "=", "self", ".", "lr_scheduler", "\n", "self", ".", "callback_handler", ".", "train_dataloader", "=", "train_dataloader", "\n", "self", ".", "state", ".", "trial_name", "=", "self", ".", "hp_name", "(", "trial", ")", "if", "self", ".", "hp_name", "is", "not", "None", "else", "None", "\n", "self", ".", "state", ".", "trial_params", "=", "hp_params", "(", "trial", ")", "if", "trial", "is", "not", "None", "else", "None", "\n", "# This should be the same if the state has been saved but in case the training arguments changed, it's safer", "\n", "# to set this after the load.", "\n", "self", ".", "state", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "state", ".", "num_train_epochs", "=", "num_train_epochs", "\n", "self", ".", "state", ".", "is_local_process_zero", "=", "self", ".", "is_local_process_zero", "(", ")", "\n", "self", ".", "state", ".", "is_world_process_zero", "=", "self", ".", "is_world_process_zero", "(", ")", "\n", "\n", "# tr_loss is a tensor to avoid synchronization of TPUs through .item()", "\n", "tr_loss", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "# _total_loss_scalar is updated everytime .item() has to be called on tr_loss and stores the sum of all losses", "\n", "self", ".", "_total_loss_scalar", "=", "0.0", "\n", "self", ".", "_globalstep_last_logged", "=", "0", "\n", "self", ".", "_total_flos", "=", "self", ".", "state", ".", "total_flos", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_train_begin", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n", "# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.", "\n", "if", "not", "self", ".", "args", ".", "ignore_data_skip", ":", "\n", "            ", "for", "epoch", "in", "range", "(", "epochs_trained", ")", ":", "\n", "# We just need to begin an iteration to create the randomization of the sampler.", "\n", "                ", "for", "_", "in", "train_dataloader", ":", "\n", "                    ", "break", "\n", "", "", "", "for", "epoch", "in", "range", "(", "epochs_trained", ",", "num_train_epochs", ")", ":", "\n", "            ", "if", "isinstance", "(", "train_dataloader", ",", "DataLoader", ")", "and", "isinstance", "(", "train_dataloader", ".", "sampler", ",", "DistributedSampler", ")", ":", "\n", "                ", "train_dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "epoch_iterator", "=", "train_dataloader", "\n", "\n", "# Reset the past mems state at the beginning of each epoch if necessary.", "\n", "if", "self", ".", "args", ".", "past_index", ">=", "0", ":", "\n", "                ", "self", ".", "_past", "=", "None", "\n", "\n", "", "steps_in_epoch", "=", "len", "(", "train_dataloader", ")", "if", "train_dataset_is_sized", "else", "self", ".", "args", ".", "max_steps", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_epoch_begin", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n", "assert", "train_dataset_is_sized", ",", "\"currently we only support sized dataloader!\"", "\n", "\n", "inputs", "=", "None", "\n", "last_inputs", "=", "None", "\n", "for", "step", ",", "inputs", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "                ", "if", "self", ".", "args", ".", "number_of_steps", "and", "step", ">", "self", ".", "args", ".", "number_of_steps", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Early termination\"", ")", "\n", "break", "\n", "# Skip past any already trained steps if resuming training", "\n", "", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                    ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                    ", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_step_begin", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n", "", "if", "(", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "!=", "0", ")", "and", "self", ".", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "# Avoid unnecessary DDP synchronization since there will be no backward pass on this example.", "\n", "                    ", "with", "model", ".", "no_sync", "(", ")", ":", "\n", "                        ", "tr_loss", "+=", "self", ".", "training_step", "(", "model", ",", "inputs", ")", "\n", "", "", "else", ":", "\n", "                    ", "tr_loss", "+=", "self", ".", "training_step", "(", "model", ",", "inputs", ")", "\n", "", "self", ".", "_total_flos", "+=", "self", ".", "floating_point_ops", "(", "inputs", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "self", ".", "args", ".", "gradient_accumulation_steps", "==", "0", "or", "(", "\n", "# last step in epoch but step is always smaller than gradient_accumulation_steps", "\n", "steps_in_epoch", "<=", "self", ".", "args", ".", "gradient_accumulation_steps", "\n", "and", "(", "step", "+", "1", ")", "==", "steps_in_epoch", "\n", ")", ":", "\n", "# Gradient clipping", "\n", "                    ", "if", "self", ".", "args", ".", "max_grad_norm", "is", "not", "None", "and", "self", ".", "args", ".", "max_grad_norm", ">", "0", "and", "not", "self", ".", "deepspeed", ":", "\n", "# deepspeed does its own clipping", "\n", "\n", "                        ", "if", "self", ".", "use_amp", ":", "\n", "# AMP: gradients need unscaling", "\n", "                            ", "self", ".", "scaler", ".", "unscale_", "(", "self", ".", "optimizer", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ".", "optimizer", ",", "\"clip_grad_norm\"", ")", ":", "\n", "# Some optimizers (like the sharded optimizer) have a specific way to do gradient clipping", "\n", "                            ", "self", ".", "optimizer", ".", "clip_grad_norm", "(", "self", ".", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "# Revert to normal clipping otherwise, handling Apex or full precision", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "amp", ".", "master_params", "(", "self", ".", "optimizer", ")", "if", "self", ".", "use_apex", "else", "model", ".", "parameters", "(", ")", ",", "\n", "self", ".", "args", ".", "max_grad_norm", ",", "\n", ")", "\n", "\n", "# Optimizer step", "\n", "", "", "if", "is_torch_tpu_available", "(", ")", ":", "\n", "                        ", "xm", ".", "optimizer_step", "(", "self", ".", "optimizer", ")", "\n", "", "elif", "self", ".", "use_amp", ":", "\n", "                        ", "self", ".", "scaler", ".", "step", "(", "self", ".", "optimizer", ")", "\n", "self", ".", "scaler", ".", "update", "(", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "self", ".", "state", ".", "global_step", "+=", "1", "\n", "self", ".", "state", ".", "epoch", "=", "epoch", "+", "(", "step", "+", "1", ")", "/", "steps_in_epoch", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_step_end", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "\n", "self", ".", "_maybe_log_save_evaluate", "(", "\n", "tr_loss", ",", "model", ",", "trial", ",", "epoch", ",", "ignore_keys_for_eval", "=", "None", ")", "\n", "\n", "", "if", "self", ".", "control", ".", "should_epoch_stop", "or", "self", ".", "control", ".", "should_training_stop", ":", "\n", "                    ", "break", "\n", "\n", "", "", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_epoch_end", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "self", ".", "_maybe_log_save_evaluate", "(", "\n", "tr_loss", ",", "model", ",", "trial", ",", "epoch", ",", "ignore_keys_for_eval", "=", "None", ")", "\n", "\n", "if", "self", ".", "args", ".", "tpu_metrics_debug", "or", "self", ".", "args", ".", "debug", ":", "\n", "                ", "if", "is_torch_tpu_available", "(", ")", ":", "\n", "# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)", "\n", "                    ", "xm", ".", "master_print", "(", "met", ".", "metrics_report", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"You enabled PyTorch/XLA debug metrics but you don't have a TPU \"", "\n", "\"configured. Check your training configuration if this is unexpected.\"", "\n", ")", "\n", "", "", "if", "self", ".", "control", ".", "should_training_stop", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "self", ".", "args", ".", "past_index", "and", "hasattr", "(", "self", ",", "\"_past\"", ")", ":", "\n", "# Clean the state at the end of training", "\n", "            ", "delattr", "(", "self", ",", "\"_past\"", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"\\n\\nTraining completed. Do not forget to share your model on huggingface.co/models =)\\n\\n\"", ")", "\n", "if", "self", ".", "args", ".", "load_best_model_at_end", "and", "self", ".", "state", ".", "best_model_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Loading best model from {self.state.best_model_checkpoint} (score: {self.state.best_metric}).\"", "\n", ")", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "PreTrainedModel", ")", ":", "\n", "                ", "self", ".", "model", "=", "self", ".", "model", ".", "from_pretrained", "(", "self", ".", "state", ".", "best_model_checkpoint", ",", "model_args", "=", "self", ".", "model_args", ")", "\n", "if", "not", "self", ".", "is_model_parallel", ":", "\n", "                    ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "args", ".", "device", ")", "\n", "", "", "else", ":", "\n", "                ", "state_dict", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "state", ".", "best_model_checkpoint", ",", "WEIGHTS_NAME", ")", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "if", "self", ".", "deepspeed", ":", "\n", "                ", "self", ".", "deepspeed", ".", "load_checkpoint", "(", "\n", "self", ".", "state", ".", "best_model_checkpoint", ",", "load_optimizer_states", "=", "False", ",", "load_lr_scheduler_states", "=", "False", "\n", ")", "\n", "\n", "", "", "metrics", "=", "speed_metrics", "(", "\"train\"", ",", "start_time", ",", "self", ".", "state", ".", "max_steps", ")", "\n", "if", "self", ".", "_total_flos", "is", "not", "None", ":", "\n", "            ", "self", ".", "store_flos", "(", ")", "\n", "metrics", "[", "\"total_flos\"", "]", "=", "self", ".", "state", ".", "total_flos", "\n", "", "self", ".", "log", "(", "metrics", ")", "\n", "\n", "self", ".", "control", "=", "self", ".", "callback_handler", ".", "on_train_end", "(", "self", ".", "args", ",", "self", ".", "state", ",", "self", ".", "control", ")", "\n", "# add remaining tr_loss", "\n", "self", ".", "_total_loss_scalar", "+=", "tr_loss", ".", "item", "(", ")", "\n", "\n", "return", "TrainOutput", "(", "self", ".", "state", ".", "global_step", ",", "self", ".", "_total_loss_scalar", "/", "self", ".", "state", ".", "global_step", ",", "metrics", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers._model_unwrap": [[82, 88], ["hasattr", "trainers._model_unwrap"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers._model_unwrap"], ["", "def", "_model_unwrap", "(", "model", ":", "nn", ".", "Module", ")", "->", "nn", ".", "Module", ":", "\n", "# since there could be multiple levels of wrapping, unwrap recursively", "\n", "    ", "if", "hasattr", "(", "model", ",", "\"module\"", ")", ":", "\n", "        ", "return", "_model_unwrap", "(", "model", ".", "module", ")", "\n", "", "else", ":", "\n", "        ", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertEmbeddings.__init__": [[183, 213], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "getattr", "modeling_bert.BertEmbeddings.register_buffer", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "packaging.version.parse", "packaging.version.parse", "modeling_bert.BertEmbeddings.register_buffer", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_bert.BertEmbeddings.position_ids.size"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "config", ".", "pad_token_id", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "", "self", ".", "config", "=", "config", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "\n", "# position_ids (1, len position emb) is contiguous in memory and exported when serialized", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "config", ".", "max_position_embeddings", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">", "version", ".", "parse", "(", "\"1.6.0\"", ")", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\n", "\"token_type_ids\"", ",", "\n", "torch", ".", "zeros", "(", "self", ".", "position_ids", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", ",", "\n", "persistent", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertEmbeddings.forward": [[215, 268], ["modeling_bert.BertEmbeddings.token_type_embeddings", "modeling_bert.BertEmbeddings.LayerNorm", "input_ids.size", "hasattr", "modeling_bert.BertEmbeddings.word_embeddings", "modeling_bert.BertEmbeddings.position_embeddings", "modeling_bert.BertEmbeddings.size", "buffered_token_type_ids.expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ",", "past_key_values_length", "=", "0", "\n", ")", ":", "\n", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "self", ".", "position_ids", "[", ":", ",", "past_key_values_length", ":", "seq_length", "+", "past_key_values_length", "]", "\n", "\n", "# Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs", "\n", "# when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves", "\n", "# issue #5664", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"token_type_ids\"", ")", ":", "\n", "                ", "buffered_token_type_ids", "=", "self", ".", "token_type_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "buffered_token_type_ids_expanded", "=", "buffered_token_type_ids", ".", "expand", "(", "input_shape", "[", "0", "]", ",", "seq_length", ")", "\n", "token_type_ids", "=", "buffered_token_type_ids_expanded", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", "\n", "\n", "", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "token_type_embeddings", "\n", "if", "self", ".", "position_embedding_type", "==", "\"absolute\"", ":", "\n", "            ", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "embeddings", "+=", "position_embeddings", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "\n", "# STANDARD", "\n", "            ", "if", "not", "self", ".", "config", ".", "multi_dropout", ":", "\n", "                ", "embeddings", "=", "self", ".", "dropout", "[", "0", "]", "(", "embeddings", ")", "\n", "\n", "", "else", ":", "\n", "                ", "embeddings_clone", "=", "einops", ".", "rearrange", "(", "embeddings", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "embeddings_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "embeddings_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "embeddings", "=", "einops", ".", "rearrange", "(", "embeddings_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertSelfAttention.__init__": [[271, 305], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "getattr", "ValueError", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "hasattr", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"", "\n", "f\"heads ({config.num_attention_heads})\"", "\n", ")", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.attention_probs_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "]", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "# SCD: END - multi-dropout", "\n", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "self", ".", "max_position_embeddings", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "distance_embedding", "=", "nn", ".", "Embedding", "(", "2", "*", "config", ".", "max_position_embeddings", "-", "1", ",", "self", ".", "attention_head_size", ")", "\n", "\n", "", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertSelfAttention.transpose_for_scores": [[307, 311], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertSelfAttention.forward": [[312, 420], ["modeling_bert.BertSelfAttention.query", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert.BertSelfAttention.transpose", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "modeling_bert.BertSelfAttention.distance_embedding", "positional_embedding.to.to.to", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "hidden_states.size", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "einops.rearrange().clone", "range", "einops.rearrange", "context_layer.view.view.permute", "context_layer.view.view.size", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "len", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "einops.rearrange", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "is_cross_attention", "=", "encoder_hidden_states", "is", "not", "None", "\n", "\n", "if", "is_cross_attention", "and", "past_key_value", "is", "not", "None", ":", "\n", "# reuse k,v, cross_attentions", "\n", "            ", "key_layer", "=", "past_key_value", "[", "0", "]", "\n", "value_layer", "=", "past_key_value", "[", "1", "]", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "elif", "is_cross_attention", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "encoder_hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "encoder_hidden_states", ")", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "elif", "past_key_value", "is", "not", "None", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "hidden_states", ")", ")", "\n", "key_layer", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "0", "]", ",", "key_layer", "]", ",", "dim", "=", "2", ")", "\n", "value_layer", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "1", "]", ",", "value_layer", "]", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "hidden_states", ")", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.", "\n", "# Further calls to cross_attention layer can then reuse all cross-attention", "\n", "# key/value_states (first \"if\" case)", "\n", "# if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of", "\n", "# all previous decoder key/value_states. Further calls to uni-directional self-attention", "\n", "# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)", "\n", "# if encoder bi-directional self-attention `past_key_value` is always `None`", "\n", "            ", "past_key_value", "=", "(", "key_layer", ",", "value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "seq_length", "=", "hidden_states", ".", "size", "(", ")", "[", "1", "]", "\n", "position_ids_l", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "position_ids_r", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "distance", "=", "position_ids_l", "-", "position_ids_r", "\n", "\n", "positional_embedding", "=", "self", ".", "distance_embedding", "(", "distance", "+", "self", ".", "max_position_embeddings", "-", "1", ")", "\n", "positional_embedding", "=", "positional_embedding", ".", "to", "(", "dtype", "=", "query_layer", ".", "dtype", ")", "# fp16 compatibility", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", ":", "\n", "                ", "relative_position_scores", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores", "\n", "", "elif", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "                ", "relative_position_scores_query", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "relative_position_scores_key", "=", "torch", ".", "einsum", "(", "\"bhrd,lrd->bhlr\"", ",", "key_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores_query", "+", "relative_position_scores_key", "\n", "\n", "", "", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "not", "self", ".", "config", ".", "multi_dropout", ":", "\n", "                ", "attention_probs", "=", "self", ".", "dropout", "[", "0", "]", "(", "attention_probs", ")", "\n", "\n", "", "else", ":", "\n", "                ", "attention_probs_clone", "=", "einops", ".", "rearrange", "(", "attention_probs", ",", "\"(h i) j t k -> h i j t k\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "#dropout_rates = [0.1, 0.1, 0.5, 0.0]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "#self.dropout.p = dropout_rates[i]", "\n", "                    ", "attention_probs_clone", "[", ":", ",", "i", ",", ":", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "attention_probs_clone", "[", ":", ",", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "attention_probs", "=", "einops", ".", "rearrange", "(", "attention_probs_clone", ",", "\"h i j t k -> (h i) j t k\"", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "\n", "", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "past_key_value", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertSelfOutput.__init__": [[423, 435], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "", "self", ".", "config", "=", "config", "\n", "# SCD: END - multi-dropout", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertSelfOutput.forward": [[437, 457], ["modeling_bert.BertSelfOutput.dense", "modeling_bert.BertSelfOutput.LayerNorm", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "# STANDARD", "\n", "            ", "if", "not", "self", ".", "config", ".", "multi_dropout", ":", "\n", "                ", "hidden_states", "=", "self", ".", "dropout", "[", "0", "]", "(", "hidden_states", ")", "\n", "", "else", ":", "\n", "\n", "                ", "hidden_states_clone", "=", "einops", ".", "rearrange", "(", "hidden_states", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "hidden_states", "=", "einops", ".", "rearrange", "(", "hidden_states_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertAttention.__init__": [[460, 465], ["torch.nn.Module.__init__", "modeling_bert.BertSelfAttention", "modeling_bert.BertSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertAttention.prune_heads": [[466, 483], ["modeling_utils.find_pruneable_heads_and_indices", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_bert.BertAttention.pruned_heads.union", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertAttention.forward": [[484, 506], ["modeling_bert.BertAttention.self", "modeling_bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "past_key_value", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertIntermediate.__init__": [[509, 516], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertIntermediate.forward": [[517, 521], ["modeling_bert.BertIntermediate.dense", "modeling_bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOutput.__init__": [[524, 539], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "# SCD: END - multi-dropout", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOutput.forward": [[541, 561], ["modeling_bert.BertOutput.dense", "modeling_bert.BertOutput.LayerNorm", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "# STANDARD", "\n", "            ", "if", "not", "self", ".", "config", ".", "multi_dropout", ":", "\n", "                ", "hidden_states", "=", "self", ".", "dropout", "[", "0", "]", "(", "hidden_states", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states_clone", "=", "einops", ".", "rearrange", "(", "hidden_states", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "hidden_states", "=", "einops", ".", "rearrange", "(", "hidden_states_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLayer.__init__": [[564, 576], ["torch.nn.Module.__init__", "modeling_bert.BertAttention", "modeling_bert.BertIntermediate", "modeling_bert.BertOutput", "modeling_bert.BertAttention"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chunk_size_feed_forward", "=", "config", ".", "chunk_size_feed_forward", "\n", "self", ".", "seq_len_dim", "=", "1", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "add_cross_attention", "=", "config", ".", "add_cross_attention", "\n", "if", "self", ".", "add_cross_attention", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "f\"{self} should be used as a decoder model if cross attention is added\"", "\n", "self", ".", "crossattention", "=", "BertAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLayer.forward": [[577, 639], ["modeling_bert.BertLayer.attention", "modeling_utils.apply_chunking_to_forward", "hasattr", "modeling_bert.BertLayer.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2", "\n", "        ", "self_attn_past_key_value", "=", "past_key_value", "[", ":", "2", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "past_key_value", "=", "self_attn_past_key_value", ",", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "\n", "# if decoder, the last output is tuple of self-attn cache", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "self_attention_outputs", "[", "1", ":", "-", "1", "]", "\n", "present_key_value", "=", "self_attention_outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "", "cross_attn_present_key_value", "=", "None", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"crossattention\"", "\n", ")", ",", "f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"", "\n", "\n", "# cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple", "\n", "cross_attn_past_key_value", "=", "past_key_value", "[", "-", "2", ":", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "cross_attn_past_key_value", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "-", "1", "]", "# add cross attentions if we output attention weights", "\n", "\n", "# add cross-attn cache to positions 3,4 of present_key_value tuple", "\n", "cross_attn_present_key_value", "=", "cross_attention_outputs", "[", "-", "1", "]", "\n", "present_key_value", "=", "present_key_value", "+", "cross_attn_present_key_value", "\n", "\n", "", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", "\n", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "\n", "# if decoder, return the attn key/values as the last output", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "present_key_value", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLayer.feed_forward_chunk": [[640, 644], ["modeling_bert.BertLayer.intermediate", "modeling_bert.BertLayer.output"], "methods", ["None"], ["", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertEncoder.__init__": [[676, 680], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertEncoder.forward": [[681, 769], ["enumerate", "modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "tuple", "getattr", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer_module", "logger.warning", "modeling_bert.BertEncoder.forward.create_custom_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", ":", "\n", "\n", "        ", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_self_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "output_attentions", "and", "self", ".", "config", ".", "add_cross_attention", "else", "None", "\n", "\n", "next_decoder_cache", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_head_mask", "=", "head_mask", "[", "i", "]", "if", "head_mask", "is", "not", "None", "else", "None", "\n", "past_key_value", "=", "past_key_values", "[", "i", "]", "if", "past_key_values", "is", "not", "None", "else", "None", "\n", "\n", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", "and", "self", ".", "training", ":", "\n", "\n", "                ", "if", "use_cache", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\"", "\n", ")", "\n", "use_cache", "=", "False", "\n", "\n", "", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                        ", "return", "module", "(", "*", "inputs", ",", "past_key_value", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "layer_module", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "past_key_value", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "use_cache", ":", "\n", "                ", "next_decoder_cache", "+=", "(", "layer_outputs", "[", "-", "1", "]", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_self_attentions", "=", "all_self_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "if", "self", ".", "config", ".", "add_cross_attention", ":", "\n", "                    ", "all_cross_attentions", "=", "all_cross_attentions", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "\n", "for", "v", "in", "[", "\n", "hidden_states", ",", "\n", "next_decoder_cache", ",", "\n", "all_hidden_states", ",", "\n", "all_self_attentions", ",", "\n", "all_cross_attentions", ",", "\n", "]", "\n", "if", "v", "is", "not", "None", "\n", ")", "\n", "", "return", "BaseModelOutputWithPastAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "next_decoder_cache", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_self_attentions", ",", "\n", "cross_attentions", "=", "all_cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPooler.__init__": [[773, 777], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPooler.forward": [[778, 785], ["modeling_bert.BertPooler.dense", "modeling_bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPredictionHeadTransform.__init__": [[788, 796], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "isinstance", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPredictionHeadTransform.forward": [[797, 802], ["modeling_bert.BertPredictionHeadTransform.dense", "modeling_bert.BertPredictionHeadTransform.transform_act_fn", "modeling_bert.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMPredictionHead.__init__": [[805, 817], ["torch.nn.Module.__init__", "modeling_bert.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n", "# Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`", "\n", "self", ".", "decoder", ".", "bias", "=", "self", ".", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMPredictionHead.forward": [[818, 822], ["modeling_bert.BertLMPredictionHead.transform", "modeling_bert.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOnlyMLMHead.__init__": [[825, 828], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOnlyMLMHead.forward": [[829, 832], ["modeling_bert.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOnlyNSPHead.__init__": [[835, 838], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertOnlyNSPHead.forward": [[839, 842], ["modeling_bert.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPreTrainingHeads.__init__": [[845, 849], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPreTrainingHeads.forward": [[850, 854], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertPreTrainedModel._init_weights": [[867, 882], ["isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "isinstance", "module.weight.data[].zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Initialize the weights\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertModel.__init__": [[1004, 1014], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertEmbeddings", "modeling_bert.BertEncoder", "modeling_bert.BertModel.init_weights", "modeling_bert.BertPooler"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "add_pooling_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "if", "add_pooling_layer", "else", "None", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertModel.get_input_embeddings": [[1015, 1017], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertModel.set_input_embeddings": [[1018, 1020], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertModel._prune_heads": [[1021, 1028], ["heads_to_prune.items", "modeling_bert.BertModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaAttention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n        class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertModel.forward": [[1029, 1164], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertModel.get_extended_attention_mask", "modeling_bert.BertModel.get_head_mask", "modeling_bert.BertModel.embeddings", "modeling_bert.BertModel.encoder", "modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions", "BERT_INPUTS_DOCSTRING.format", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "hasattr", "encoder_hidden_states.size", "modeling_bert.BertModel.invert_attention_mask", "modeling_bert.BertModel.pooler", "input_ids.size", "buffered_token_type_ids.expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "inputs_embeds.size"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "BaseModelOutputWithPoolingAndCrossAttentions", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n            the model is configured as a decoder.\n        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n\n            - 1 for tokens that are **not masked**,\n            - 0 for tokens that are **masked**.\n        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n\n            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n        use_cache (:obj:`bool`, `optional`):\n            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n            decoding (see :obj:`past_key_values`).\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "            ", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "", "else", ":", "\n", "            ", "use_cache", "=", "False", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "# past_key_values_length", "\n", "past_key_values_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "if", "past_key_values", "is", "not", "None", "else", "0", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "(", "(", "batch_size", ",", "seq_length", "+", "past_key_values_length", ")", ")", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "embeddings", ",", "\"token_type_ids\"", ")", ":", "\n", "                ", "buffered_token_type_ids", "=", "self", ".", "embeddings", ".", "token_type_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "buffered_token_type_ids_expanded", "=", "buffered_token_type_ids", ".", "expand", "(", "batch_size", ",", "seq_length", ")", "\n", "token_type_ids", "=", "buffered_token_type_ids_expanded", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "\n", "# If a 2D or 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_hidden_layers", ")", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "past_key_values_length", "=", "past_key_values_length", ",", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "if", "self", ".", "pooler", "is", "not", "None", "else", "None", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPoolingAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "past_key_values", "=", "encoder_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "encoder_outputs", ".", "cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForPreTraining.__init__": [[1175, 1182], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertForPreTraining.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForPreTraining.get_output_embeddings": [[1183, 1185], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForPreTraining.set_output_embeddings": [[1186, 1188], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "cls", ".", "predictions", ".", "decoder", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForPreTraining.forward": [[1189, 1269], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.replace_return_docstrings", "modeling_bert.BertForPreTraining.bert", "modeling_bert.BertForPreTraining.cls", "modeling_bert.BertForPreTrainingOutput", "BERT_INPUTS_DOCSTRING.format", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "BertForPreTrainingOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape ``(batch_size, sequence_length)``, `optional`):\n            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n        next_sentence_label (``torch.LongTensor`` of shape ``(batch_size,)``, `optional`):\n            Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair\n            (see :obj:`input_ids` docstring) Indices should be in ``[0, 1]``:\n\n            - 0 indicates sequence B is a continuation of sequence A,\n            - 1 indicates sequence B is a random sequence.\n        kwargs (:obj:`Dict[str, any]`, optional, defaults to `{}`):\n            Used to hide legacy arguments that have been deprecated.\n\n        Returns:\n\n        Example::\n\n            >>> from transformers import BertTokenizer, BertForPreTraining\n            >>> import torch\n\n            >>> tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            >>> model = BertForPreTraining.from_pretrained('bert-base-uncased')\n\n            >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n            >>> outputs = model(**inputs)\n\n            >>> prediction_logits = outputs.prediction_logits\n            >>> seq_relationship_logits = outputs.seq_relationship_logits\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "total_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", "seq_relationship_score", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "total_loss", ",", ")", "+", "output", ")", "if", "total_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "BertForPreTrainingOutput", "(", "\n", "loss", "=", "total_loss", ",", "\n", "prediction_logits", "=", "prediction_scores", ",", "\n", "seq_relationship_logits", "=", "seq_relationship_score", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel.__init__": [[1280, 1290], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertLMHeadModel.init_weights", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "not", "config", ".", "is_decoder", ":", "\n", "            ", "logger", ".", "warning", "(", "\"If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\"", ")", "\n", "\n", "", "self", ".", "bert", "=", "BertModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel.get_output_embeddings": [[1291, 1293], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel.set_output_embeddings": [[1294, 1296], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "cls", ".", "predictions", ".", "decoder", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel.forward": [[1297, 1399], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.replace_return_docstrings", "modeling_bert.BertLMHeadModel.bert", "modeling_bert.BertLMHeadModel.cls", "modeling_outputs.CausalLMOutputWithCrossAttentions", "BERT_INPUTS_DOCSTRING.format", "prediction_scores[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores[].contiguous.view", "labels[].contiguous.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "CausalLMOutputWithCrossAttentions", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n            the model is configured as a decoder.\n        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n\n            - 1 for tokens that are **not masked**,\n            - 0 for tokens that are **masked**.\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n            ``[-100, 0, ..., config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are\n            ignored (masked), the loss is only computed for the tokens with labels n ``[0, ..., config.vocab_size]``\n        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n\n            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n        use_cache (:obj:`bool`, `optional`):\n            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n            decoding (see :obj:`past_key_values`).\n\n        Returns:\n\n        Example::\n\n            >>> from transformers import BertTokenizer, BertLMHeadModel, BertConfig\n            >>> import torch\n\n            >>> tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n            >>> config = BertConfig.from_pretrained(\"bert-base-cased\")\n            >>> config.is_decoder = True\n            >>> model = BertLMHeadModel.from_pretrained('bert-base-cased', config=config)\n\n            >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n            >>> outputs = model(**inputs)\n\n            >>> prediction_logits = outputs.logits\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "use_cache", "=", "False", "\n", "\n", "", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# we are doing next-token prediction; shift prediction scores and input ids by one", "\n", "            ", "shifted_prediction_scores", "=", "prediction_scores", "[", ":", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "labels", "=", "labels", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "lm_loss", "=", "loss_fct", "(", "shifted_prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "lm_loss", ",", ")", "+", "output", ")", "if", "lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "CausalLMOutputWithCrossAttentions", "(", "\n", "loss", "=", "lm_loss", ",", "\n", "logits", "=", "prediction_scores", ",", "\n", "past_key_values", "=", "outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "outputs", ".", "cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel.prepare_inputs_for_generation": [[1401, 1412], ["input_ids.new_ones"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "input_shape", "=", "input_ids", ".", "shape", "\n", "# if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_shape", ")", "\n", "\n", "# cut decoder_input_ids if past is used", "\n", "", "if", "past", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"attention_mask\"", ":", "attention_mask", ",", "\"past_key_values\"", ":", "past", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertLMHeadModel._reorder_cache": [[1413, 1418], ["tuple", "past_state.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "        ", "reordered_past", "=", "(", ")", "\n", "for", "layer_past", "in", "past", ":", "\n", "            ", "reordered_past", "+=", "(", "tuple", "(", "past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", "for", "past_state", "in", "layer_past", ")", ",", ")", "\n", "", "return", "reordered_past", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMaskedLM.__init__": [[1426, 1439], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertForMaskedLM.init_weights", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "config", ".", "is_decoder", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for \"", "\n", "\"bi-directional self-attention.\"", "\n", ")", "\n", "\n", "", "self", ".", "bert", "=", "BertModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMaskedLM.get_output_embeddings": [[1440, 1442], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMaskedLM.set_output_embeddings": [[1443, 1445], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "cls", ".", "predictions", ".", "decoder", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMaskedLM.forward": [[1446, 1508], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertForMaskedLM.bert", "modeling_bert.BertForMaskedLM.cls", "modeling_outputs.MaskedLMOutput", "BERT_INPUTS_DOCSTRING.format", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForMaskedLM.view", "labels.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "MaskedLMOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n        \"\"\"", "\n", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "# -100 index = padding token", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "MaskedLMOutput", "(", "\n", "loss", "=", "masked_lm_loss", ",", "\n", "logits", "=", "prediction_scores", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMaskedLM.prepare_inputs_for_generation": [[1510, 1523], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.new_zeros"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "input_shape", "=", "input_ids", ".", "shape", "\n", "effective_batch_size", "=", "input_shape", "[", "0", "]", "\n", "\n", "#  add a dummy token", "\n", "assert", "self", ".", "config", ".", "pad_token_id", "is", "not", "None", ",", "\"The PAD token should be defined for generation\"", "\n", "attention_mask", "=", "torch", ".", "cat", "(", "[", "attention_mask", ",", "attention_mask", ".", "new_zeros", "(", "(", "attention_mask", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "dummy_token", "=", "torch", ".", "full", "(", "\n", "(", "effective_batch_size", ",", "1", ")", ",", "self", ".", "config", ".", "pad_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", "\n", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "dummy_token", "]", ",", "dim", "=", "1", ")", "\n", "\n", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"attention_mask\"", ":", "attention_mask", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForNextSentencePrediction.__init__": [[1530, 1537], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyNSPHead", "modeling_bert.BertForNextSentencePrediction.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForNextSentencePrediction.forward": [[1538, 1620], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.replace_return_docstrings", "modeling_bert.BertForNextSentencePrediction.bert", "modeling_bert.BertForNextSentencePrediction.cls", "modeling_outputs.NextSentencePredictorOutput", "BERT_INPUTS_DOCSTRING.format", "warnings.warn", "kwargs.pop", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForNextSentencePrediction.view", "kwargs.pop.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "NextSentencePredictorOutput", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the next sequence prediction (classification) loss. Input should be a sequence pair\n            (see ``input_ids`` docstring). Indices should be in ``[0, 1]``:\n\n            - 0 indicates sequence B is a continuation of sequence A,\n            - 1 indicates sequence B is a random sequence.\n\n        Returns:\n\n        Example::\n\n            >>> from transformers import BertTokenizer, BertForNextSentencePrediction\n            >>> import torch\n\n            >>> tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            >>> model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n\n            >>> prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n            >>> next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n            >>> encoding = tokenizer(prompt, next_sentence, return_tensors='pt')\n\n            >>> outputs = model(**encoding, labels=torch.LongTensor([1]))\n            >>> logits = outputs.logits\n            >>> assert logits[0, 0] < logits[0, 1] # next sentence was random\n        \"\"\"", "\n", "\n", "if", "\"next_sentence_label\"", "in", "kwargs", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"The `next_sentence_label` argument is deprecated and will be removed in a future version, use `labels` instead.\"", ",", "\n", "FutureWarning", ",", "\n", ")", "\n", "labels", "=", "kwargs", ".", "pop", "(", "\"next_sentence_label\"", ")", "\n", "\n", "", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "seq_relationship_scores", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "next_sentence_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_scores", ".", "view", "(", "-", "1", ",", "2", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "seq_relationship_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "next_sentence_loss", ",", ")", "+", "output", ")", "if", "next_sentence_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "NextSentencePredictorOutput", "(", "\n", "loss", "=", "next_sentence_loss", ",", "\n", "logits", "=", "seq_relationship_scores", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForSequenceClassification.__init__": [[1631, 1644], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bert.BertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "classifier_dropout", "=", "(", "\n", "config", ".", "classifier_dropout", "if", "config", ".", "classifier_dropout", "is", "not", "None", "else", "config", ".", "hidden_dropout_prob", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "classifier_dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForSequenceClassification.forward": [[1645, 1721], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertForSequenceClassification.bert", "modeling_bert.BertForSequenceClassification.dropout", "modeling_bert.BertForSequenceClassification.classifier", "modeling_outputs.SequenceClassifierOutput", "BERT_INPUTS_DOCSTRING.format", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "modeling_bert.BertForSequenceClassification.squeeze", "labels.squeeze", "modeling_bert.BertForSequenceClassification.view", "labels.view", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss."], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "SequenceClassifierOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "problem_type", "is", "None", ":", "\n", "                ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"regression\"", "\n", "", "elif", "self", ".", "num_labels", ">", "1", "and", "(", "labels", ".", "dtype", "==", "torch", ".", "long", "or", "labels", ".", "dtype", "==", "torch", ".", "int", ")", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"single_label_classification\"", "\n", "", "else", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"multi_label_classification\"", "\n", "\n", "", "", "if", "self", ".", "config", ".", "problem_type", "==", "\"regression\"", ":", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                    ", "loss", "=", "loss_fct", "(", "logits", ".", "squeeze", "(", ")", ",", "labels", ".", "squeeze", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "", "elif", "self", ".", "config", ".", "problem_type", "==", "\"single_label_classification\"", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "config", ".", "problem_type", "==", "\"multi_label_classification\"", ":", "\n", "                ", "loss_fct", "=", "BCEWithLogitsLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMultipleChoice.__init__": [[1732, 1740], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bert.BertForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForMultipleChoice.forward": [[1741, 1812], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertForMultipleChoice.bert", "modeling_bert.BertForMultipleChoice.dropout", "modeling_bert.BertForMultipleChoice.classifier", "modeling_bert.BertForMultipleChoice.view", "modeling_outputs.MultipleChoiceModelOutput", "BERT_INPUTS_DOCSTRING.format", "input_ids.view", "attention_mask.view", "token_type_ids.view", "position_ids.view", "inputs_embeds.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "input_ids.size", "attention_mask.size", "token_type_ids.size", "position_ids.size", "inputs_embeds.size", "inputs_embeds.size"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, num_choices, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "MultipleChoiceModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n            num_choices-1]`` where :obj:`num_choices` is the size of the second dimension of the input tensors. (See\n            :obj:`input_ids` above)\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "shape", "[", "1", "]", "\n", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "if", "input_ids", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "inputs_embeds", "=", "(", "\n", "inputs_embeds", ".", "view", "(", "-", "1", ",", "inputs_embeds", ".", "size", "(", "-", "2", ")", ",", "inputs_embeds", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "inputs_embeds", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "MultipleChoiceModelOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "reshaped_logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForTokenClassification.__init__": [[1826, 1838], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bert.BertForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "classifier_dropout", "=", "(", "\n", "config", ".", "classifier_dropout", "if", "config", ".", "classifier_dropout", "is", "not", "None", "else", "config", ".", "hidden_dropout_prob", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "classifier_dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForTokenClassification.forward": [[1839, 1906], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertForTokenClassification.bert", "modeling_bert.BertForTokenClassification.dropout", "modeling_bert.BertForTokenClassification.classifier", "modeling_outputs.TokenClassifierOutput", "BERT_INPUTS_DOCSTRING.format", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "modeling_bert.BertForTokenClassification.view", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "labels.view", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "modeling_bert.BertForTokenClassification.view", "labels.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "TokenClassifierOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n            1]``.\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "\n", "active_labels", "=", "torch", ".", "where", "(", "\n", "active_loss", ",", "labels", ".", "view", "(", "-", "1", ")", ",", "torch", ".", "tensor", "(", "loss_fct", ".", "ignore_index", ")", ".", "type_as", "(", "labels", ")", "\n", ")", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "TokenClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForQuestionAnswering.__init__": [[1920, 1928], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bert.BertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.BertForQuestionAnswering.forward": [[1929, 2008], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_bert.BertForQuestionAnswering.bert", "modeling_bert.BertForQuestionAnswering.qa_outputs", "modeling_bert.BertForQuestionAnswering.split", "start_logits.squeeze().contiguous.squeeze().contiguous.squeeze().contiguous", "end_logits.squeeze().contiguous.squeeze().contiguous.squeeze().contiguous", "modeling_outputs.QuestionAnsweringModelOutput", "BERT_INPUTS_DOCSTRING.format", "start_logits.squeeze().contiguous.squeeze().contiguous.size", "start_positions.squeeze.squeeze.clamp", "end_positions.squeeze.squeeze.clamp", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "start_logits.squeeze().contiguous.squeeze().contiguous.squeeze", "end_logits.squeeze().contiguous.squeeze().contiguous.squeeze", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "BERT_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "QuestionAnsweringModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n            sequence are not taken into account for computing the loss.\n        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n            sequence are not taken into account for computing the loss.\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "total_loss", "=", "None", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", "=", "start_positions", ".", "clamp", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", "=", "end_positions", ".", "clamp", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "start_logits", ",", "end_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "total_loss", ",", ")", "+", "output", ")", "if", "total_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "QuestionAnsweringModelOutput", "(", "\n", "loss", "=", "total_loss", ",", "\n", "start_logits", "=", "start_logits", ",", "\n", "end_logits", "=", "end_logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.load_tf_weights_in_bert": [[106, 178], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "numpy.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\"Load tf checkpoints in a pytorch model.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "f\"Converting TensorFlow checkpoint from {tf_path}\"", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Loading TF weight {name} with shape {shape}\"", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "\n", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"AdamWeightDecayOptimizer\"", ",", "\"AdamWeightDecayOptimizer_1\"", ",", "\"global_step\"", "]", "\n", "for", "n", "in", "name", "\n", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Skipping {'/'.join(name)}\"", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Skipping {'/'.join(name)}\"", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "(", "\n", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", ")", ",", "f\"Pointer shape {pointer.shape} and array shape {array.shape} mismatched\"", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "f\"Initialize PyTorch weight {name}\"", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.computeScore": [[648, 661], ["word_precision.sum", "word_recall.sum", "matrix.max", "matrix.max", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril"], "function", ["None"], ["", "", "def", "computeScore", "(", "matrix", ",", "band", "=", "None", ")", ":", "\n", "    ", "if", "not", "(", "band", "is", "None", ")", ":", "# compute band around diagonal", "\n", "        ", "neg_val", "=", "(", "1.", "-", "1e-5", ")", "\n", "matrix", "=", "torch", ".", "triu", "(", "matrix", ",", "diagonal", "=", "1", ")", "-", "neg_val", "*", "torch", ".", "triu", "(", "matrix", ",", "diagonal", "=", "band", ")", "+", "(", "torch", ".", "tril", "(", "matrix", ",", "diagonal", "=", "0", ")", "-", "neg_val", "*", "torch", ".", "tril", "(", "matrix", ",", "diagonal", "=", "-", "band", ")", ")", "\n", "#matrix = torch.triu(matrix,diagonal=1)- torch.triu(matrix,diagonal=band)+(torch.tril(matrix,diagonal=0)- torch.tril(matrix,diagonal=-band))", "\n", "", "eps", "=", "0.001", "\n", "word_precision", "=", "matrix", ".", "max", "(", "dim", "=", "2", ")", "[", "0", "]", "\n", "word_recall", "=", "matrix", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "P", "=", "(", "word_precision", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "R", "=", "(", "word_recall", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "F", "=", "2", "*", "P", "*", "R", "/", "(", "P", "+", "R", "+", "eps", ")", "\n", "\n", "return", "P", ",", "R", ",", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.completePerturbations": [[663, 672], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "modeling_bert.computeScore", "torch.sum", "embedding_2[].transpose", "mask_1[].unsqueeze().float", "mask_2[].unsqueeze().float", "mask_1[].unsqueeze", "mask_2[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.bert.modeling_bert.computeScore"], ["", "def", "completePerturbations", "(", "args", ",", "embedding_1", ",", "mask_1", ",", "embedding_2", ",", "mask_2", ",", "device", ")", ":", "\n", "\n", "    ", "loss_sum", "=", "torch", ".", "tensor", "(", "0.", ",", "device", "=", "device", ")", "\n", "\n", "tmp", "=", "torch", ".", "bmm", "(", "embedding_1", "[", ":", ",", "0", ":", "1", ",", ":", "]", ",", "embedding_2", "[", ":", ",", "0", ":", "1", ",", ":", "]", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "mask", "=", "torch", ".", "bmm", "(", "mask_1", "[", ":", ",", "0", ":", "1", "]", ".", "unsqueeze", "(", "2", ")", ".", "float", "(", ")", ",", "mask_2", "[", ":", ",", "0", ":", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", ")", "\n", "_", ",", "_", ",", "F", "=", "computeScore", "(", "tmp", "*", "mask", ",", "band", "=", "args", ".", "matrix_band", ")", "\n", "loss_sum", "+=", "F", ".", "sum", "(", ")", "\n", "return", "loss_sum", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEmbeddings.__init__": [[86, 121], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "getattr", "modeling_roberta.RobertaEmbeddings.register_buffer", "torch.nn.Embedding", "torch.nn.Embedding", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "torch.arange().expand", "packaging.version.parse", "packaging.version.parse", "modeling_roberta.RobertaEmbeddings.register_buffer", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_roberta.RobertaEmbeddings.position_ids.size"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "config", ".", "pad_token_id", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "", "self", ".", "config", "=", "config", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "# position_ids (1, len position emb) is contiguous in memory and exported when serialized", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "self", ".", "register_buffer", "(", "\"position_ids\"", ",", "torch", ".", "arange", "(", "config", ".", "max_position_embeddings", ")", ".", "expand", "(", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "if", "version", ".", "parse", "(", "torch", ".", "__version__", ")", ">", "version", ".", "parse", "(", "\"1.6.0\"", ")", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\n", "\"token_type_ids\"", ",", "\n", "torch", ".", "zeros", "(", "self", ".", "position_ids", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", ",", "\n", "persistent", "=", "False", ",", "\n", ")", "\n", "\n", "# End copy", "\n", "", "self", ".", "padding_idx", "=", "config", ".", "pad_token_id", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEmbeddings.forward": [[123, 177], ["modeling_roberta.RobertaEmbeddings.token_type_embeddings", "modeling_roberta.RobertaEmbeddings.LayerNorm", "input_ids.size", "hasattr", "modeling_roberta.RobertaEmbeddings.word_embeddings", "modeling_roberta.RobertaEmbeddings.position_embeddings", "modeling_roberta.create_position_ids_from_input_ids", "modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds", "modeling_roberta.RobertaEmbeddings.size", "buffered_token_type_ids.expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.create_position_ids_from_input_ids", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ",", "past_key_values_length", "=", "0", "\n", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "# Create the position ids from the input token ids. Any padded tokens remain padded.", "\n", "                ", "position_ids", "=", "create_position_ids_from_input_ids", "(", "input_ids", ",", "self", ".", "padding_idx", ",", "past_key_values_length", ")", "\n", "", "else", ":", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_inputs_embeds", "(", "inputs_embeds", ")", "\n", "\n", "", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "# Setting the token_type_ids to the registered buffer in constructor where it is all zeros, which usually occurs", "\n", "# when its auto-generated, registered buffer helps users when tracing the model without passing token_type_ids, solves", "\n", "# issue #5664", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"token_type_ids\"", ")", ":", "\n", "                ", "buffered_token_type_ids", "=", "self", ".", "token_type_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "buffered_token_type_ids_expanded", "=", "buffered_token_type_ids", ".", "expand", "(", "input_shape", "[", "0", "]", ",", "seq_length", ")", "\n", "token_type_ids", "=", "buffered_token_type_ids_expanded", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "position_ids", ".", "device", ")", "\n", "\n", "", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "token_type_embeddings", "\n", "if", "self", ".", "position_embedding_type", "==", "\"absolute\"", ":", "\n", "            ", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "embeddings", "+=", "position_embeddings", "\n", "", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "# STANDARD", "\n", "            ", "if", "self", ".", "config", ".", "single_dropout", ":", "\n", "                ", "embeddings", "=", "self", ".", "dropout", "[", "0", "]", "(", "embeddings", ")", "\n", "\n", "", "else", ":", "\n", "                ", "embeddings_clone", "=", "einops", ".", "rearrange", "(", "embeddings", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "embeddings_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "embeddings_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "embeddings", "=", "einops", ".", "rearrange", "(", "embeddings_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds": [[178, 194], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange.unsqueeze().expand", "torch.arange.unsqueeze().expand", "inputs_embeds.size", "torch.arange.unsqueeze", "torch.arange.unsqueeze"], "methods", ["None"], ["", "def", "create_position_ids_from_inputs_embeds", "(", "self", ",", "inputs_embeds", ")", ":", "\n", "        ", "\"\"\"\n        We are provided embeddings directly. We cannot infer which are padded so just generate sequential position ids.\n\n        Args:\n            inputs_embeds: torch.Tensor\n\n        Returns: torch.Tensor\n        \"\"\"", "\n", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "sequence_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "position_ids", "=", "torch", ".", "arange", "(", "\n", "self", ".", "padding_idx", "+", "1", ",", "sequence_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "inputs_embeds", ".", "device", "\n", ")", "\n", "return", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.__init__": [[198, 231], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "getattr", "ValueError", "torch.nn.Embedding", "torch.nn.Embedding", "hasattr", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", "and", "not", "hasattr", "(", "config", ",", "\"embedding_size\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"", "\n", "f\"heads ({config.num_attention_heads})\"", "\n", ")", "\n", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.attention_probs_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "]", "\n", "\n", "", "self", ".", "config", "=", "config", "\n", "# SCD: END - multi-dropout", "\n", "\n", "self", ".", "position_embedding_type", "=", "getattr", "(", "config", ",", "\"position_embedding_type\"", ",", "\"absolute\"", ")", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "self", ".", "max_position_embeddings", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "distance_embedding", "=", "nn", ".", "Embedding", "(", "2", "*", "config", ".", "max_position_embeddings", "-", "1", ",", "self", ".", "attention_head_size", ")", "\n", "\n", "", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores": [[233, 237], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.forward": [[238, 348], ["modeling_roberta.RobertaSelfAttention.query", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_roberta.RobertaSelfAttention.transpose", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "modeling_roberta.RobertaSelfAttention.distance_embedding", "positional_embedding.to.to.to", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "hidden_states.size", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "einops.rearrange().clone", "range", "einops.rearrange", "context_layer.view.view.permute", "context_layer.view.view.size", "modeling_roberta.RobertaSelfAttention.key", "modeling_roberta.RobertaSelfAttention.value", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "modeling_roberta.RobertaSelfAttention.transpose_for_scores", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "len", "modeling_roberta.RobertaSelfAttention.key", "modeling_roberta.RobertaSelfAttention.value", "modeling_roberta.RobertaSelfAttention.key", "modeling_roberta.RobertaSelfAttention.value", "einops.rearrange", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "is_cross_attention", "=", "encoder_hidden_states", "is", "not", "None", "\n", "\n", "if", "is_cross_attention", "and", "past_key_value", "is", "not", "None", ":", "\n", "# reuse k,v, cross_attentions", "\n", "            ", "key_layer", "=", "past_key_value", "[", "0", "]", "\n", "value_layer", "=", "past_key_value", "[", "1", "]", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "elif", "is_cross_attention", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "encoder_hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "encoder_hidden_states", ")", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "elif", "past_key_value", "is", "not", "None", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "hidden_states", ")", ")", "\n", "key_layer", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "0", "]", ",", "key_layer", "]", ",", "dim", "=", "2", ")", "\n", "value_layer", "=", "torch", ".", "cat", "(", "[", "past_key_value", "[", "1", "]", ",", "value_layer", "]", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "key", "(", "hidden_states", ")", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "self", ".", "value", "(", "hidden_states", ")", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "# if cross_attention save Tuple(torch.Tensor, torch.Tensor) of all cross attention key/value_states.", "\n", "# Further calls to cross_attention layer can then reuse all cross-attention", "\n", "# key/value_states (first \"if\" case)", "\n", "# if uni-directional self-attention (decoder) save Tuple(torch.Tensor, torch.Tensor) of", "\n", "# all previous decoder key/value_states. Further calls to uni-directional self-attention", "\n", "# can concat previous decoder key/value_states to current projected key/value_states (third \"elif\" case)", "\n", "# if encoder bi-directional self-attention `past_key_value` is always `None`", "\n", "            ", "past_key_value", "=", "(", "key_layer", ",", "value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", "or", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "            ", "seq_length", "=", "hidden_states", ".", "size", "(", ")", "[", "1", "]", "\n", "position_ids_l", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "position_ids_r", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "hidden_states", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ")", "\n", "distance", "=", "position_ids_l", "-", "position_ids_r", "\n", "positional_embedding", "=", "self", ".", "distance_embedding", "(", "distance", "+", "self", ".", "max_position_embeddings", "-", "1", ")", "\n", "positional_embedding", "=", "positional_embedding", ".", "to", "(", "dtype", "=", "query_layer", ".", "dtype", ")", "# fp16 compatibility", "\n", "\n", "if", "self", ".", "position_embedding_type", "==", "\"relative_key\"", ":", "\n", "                ", "relative_position_scores", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores", "\n", "", "elif", "self", ".", "position_embedding_type", "==", "\"relative_key_query\"", ":", "\n", "                ", "relative_position_scores_query", "=", "torch", ".", "einsum", "(", "\"bhld,lrd->bhlr\"", ",", "query_layer", ",", "positional_embedding", ")", "\n", "relative_position_scores_key", "=", "torch", ".", "einsum", "(", "\"bhrd,lrd->bhlr\"", ",", "key_layer", ",", "positional_embedding", ")", "\n", "attention_scores", "=", "attention_scores", "+", "relative_position_scores_query", "+", "relative_position_scores_key", "\n", "\n", "", "", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "\n", "# STANDARD", "\n", "            ", "if", "self", ".", "config", ".", "single_dropout", ":", "\n", "                ", "attention_probs", "=", "self", ".", "dropout", "[", "0", "]", "(", "attention_probs", ")", "\n", "\n", "", "else", ":", "\n", "                ", "attention_probs_clone", "=", "einops", ".", "rearrange", "(", "attention_probs", ",", "\"(h i) j t k -> h i j t k\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "attention_probs_clone", "[", ":", ",", "i", ",", ":", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "attention_probs_clone", "[", ":", ",", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "attention_probs", "=", "einops", ".", "rearrange", "(", "attention_probs_clone", ",", "\"h i j t k -> (h i) j t k\"", ")", "\n", "\n", "# SCD: END - multi-dropout", "\n", "\n", "# Mask heads if we want to", "\n", "", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "past_key_value", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfOutput.__init__": [[353, 366], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "", "self", ".", "config", "=", "config", "\n", "# SCD: END - multi-dropout", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaSelfOutput.forward": [[367, 388], ["modeling_roberta.RobertaSelfOutput.dense", "modeling_roberta.RobertaSelfOutput.LayerNorm", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "if", "self", ".", "training", ":", "\n", "\n", "# STANDARD", "\n", "            ", "if", "self", ".", "config", ".", "single_dropout", ":", "\n", "                ", "hidden_states", "=", "self", ".", "dropout", "[", "0", "]", "(", "hidden_states", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states_clone", "=", "einops", ".", "rearrange", "(", "hidden_states", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "hidden_states", "=", "einops", ".", "rearrange", "(", "hidden_states_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaAttention.__init__": [[392, 397], ["torch.nn.Module.__init__", "modeling_roberta.RobertaSelfAttention", "modeling_roberta.RobertaSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "RobertaSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "RobertaSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaAttention.prune_heads": [[398, 415], ["modeling_utils.find_pruneable_heads_and_indices", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_roberta.RobertaAttention.pruned_heads.union", "len", "len"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "heads", ",", "index", "=", "find_pruneable_heads_and_indices", "(", "\n", "heads", ",", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ",", "self", ".", "pruned_heads", "\n", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaAttention.forward": [[416, 438], ["modeling_roberta.RobertaAttention.self", "modeling_roberta.RobertaAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "past_key_value", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaIntermediate.__init__": [[442, 449], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaIntermediate.forward": [[450, 454], ["modeling_roberta.RobertaIntermediate.dense", "modeling_roberta.RobertaIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaOutput.__init__": [[458, 472], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "# ORIGINAL CODE:", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "if", "config", ".", "multi_dropout", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", ",", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob_noise", ")", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "dropout", "=", "[", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "]", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaOutput.forward": [[475, 497], ["modeling_roberta.RobertaOutput.dense", "modeling_roberta.RobertaOutput.LayerNorm", "einops.rearrange().clone", "range", "einops.rearrange", "len", "einops.rearrange", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "\n", "# SCD: BEGIN - multi-dropout", "\n", "\n", "if", "self", ".", "training", ":", "\n", "\n", "# STANDARD", "\n", "            ", "if", "self", ".", "config", ".", "single_dropout", ":", "\n", "                ", "hidden_states", "=", "self", ".", "dropout", "[", "0", "]", "(", "hidden_states", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states_clone", "=", "einops", ".", "rearrange", "(", "hidden_states", ",", "\"(h i) j t -> h i j t\"", ",", "i", "=", "len", "(", "self", ".", "dropout", ")", ")", ".", "clone", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "dropout", ")", ")", ":", "\n", "                    ", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", "=", "self", ".", "dropout", "[", "i", "]", "(", "hidden_states_clone", "[", ":", ",", "i", ",", ":", ",", ":", "]", ")", "\n", "\n", "", "hidden_states", "=", "einops", ".", "rearrange", "(", "hidden_states_clone", ",", "\"h i j t -> (h i) j t\"", ")", "\n", "\n", "# SCD: END - multi-dropout", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaLayer.__init__": [[501, 513], ["torch.nn.Module.__init__", "modeling_roberta.RobertaAttention", "modeling_roberta.RobertaIntermediate", "modeling_roberta.RobertaOutput", "modeling_roberta.RobertaAttention"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chunk_size_feed_forward", "=", "config", ".", "chunk_size_feed_forward", "\n", "self", ".", "seq_len_dim", "=", "1", "\n", "self", ".", "attention", "=", "RobertaAttention", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "add_cross_attention", "=", "config", ".", "add_cross_attention", "\n", "if", "self", ".", "add_cross_attention", ":", "\n", "            ", "assert", "self", ".", "is_decoder", ",", "f\"{self} should be used as a decoder model if cross attention is added\"", "\n", "self", ".", "crossattention", "=", "RobertaAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "RobertaIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "RobertaOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaLayer.forward": [[515, 577], ["modeling_roberta.RobertaLayer.attention", "modeling_utils.apply_chunking_to_forward", "hasattr", "modeling_roberta.RobertaLayer.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_value", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", ")", ":", "\n", "# decoder uni-directional self-attention cached key/values tuple is at positions 1,2", "\n", "        ", "self_attn_past_key_value", "=", "past_key_value", "[", ":", "2", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "self_attention_outputs", "=", "self", ".", "attention", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "past_key_value", "=", "self_attn_past_key_value", ",", "\n", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "\n", "# if decoder, the last output is tuple of self-attn cache", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "self_attention_outputs", "[", "1", ":", "-", "1", "]", "\n", "present_key_value", "=", "self_attention_outputs", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "", "cross_attn_present_key_value", "=", "None", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "assert", "hasattr", "(", "\n", "self", ",", "\"crossattention\"", "\n", ")", ",", "f\"If `encoder_hidden_states` are passed, {self} has to be instantiated with cross-attention layers by setting `config.add_cross_attention=True`\"", "\n", "\n", "# cross_attn cached key/values tuple is at positions 3,4 of past_key_value tuple", "\n", "cross_attn_past_key_value", "=", "past_key_value", "[", "-", "2", ":", "]", "if", "past_key_value", "is", "not", "None", "else", "None", "\n", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "\n", "attention_mask", ",", "\n", "head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "cross_attn_past_key_value", ",", "\n", "output_attentions", ",", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "-", "1", "]", "# add cross attentions if we output attention weights", "\n", "\n", "# add cross-attn cache to positions 3,4 of present_key_value tuple", "\n", "cross_attn_present_key_value", "=", "cross_attention_outputs", "[", "-", "1", "]", "\n", "present_key_value", "=", "present_key_value", "+", "cross_attn_present_key_value", "\n", "\n", "", "layer_output", "=", "apply_chunking_to_forward", "(", "\n", "self", ".", "feed_forward_chunk", ",", "self", ".", "chunk_size_feed_forward", ",", "self", ".", "seq_len_dim", ",", "attention_output", "\n", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "\n", "# if decoder, return the attn key/values as the last output", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "present_key_value", ",", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaLayer.feed_forward_chunk": [[578, 582], ["modeling_roberta.RobertaLayer.intermediate", "modeling_roberta.RobertaLayer.output"], "methods", ["None"], ["", "def", "feed_forward_chunk", "(", "self", ",", "attention_output", ")", ":", "\n", "        ", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEncoder.__init__": [[586, 590], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_roberta.RobertaLayer", "range"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "RobertaLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaEncoder.forward": [[591, 682], ["enumerate", "modeling_outputs.BaseModelOutputWithPastAndCrossAttentions", "tuple", "getattr", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer_module", "logger.warning", "modeling_roberta.RobertaEncoder.forward.create_custom_forward"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_self_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "all_cross_attentions", "=", "(", ")", "if", "output_attentions", "and", "self", ".", "config", ".", "add_cross_attention", "else", "None", "\n", "\n", "next_decoder_cache", "=", "(", ")", "if", "use_cache", "else", "None", "\n", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "\n", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_head_mask", "=", "head_mask", "[", "i", "]", "if", "head_mask", "is", "not", "None", "else", "None", "\n", "past_key_value", "=", "past_key_values", "[", "i", "]", "if", "past_key_values", "is", "not", "None", "else", "None", "\n", "\n", "self", ".", "config", ".", "single_dropout", "=", "True", "\n", "if", "getattr", "(", "self", ".", "config", ",", "\"gradient_checkpointing\"", ",", "False", ")", "and", "self", ".", "training", ":", "\n", "\n", "                ", "if", "use_cache", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"`use_cache=True` is incompatible with `config.gradient_checkpointing=True`. Setting \"", "\n", "\"`use_cache=False`...\"", "\n", ")", "\n", "use_cache", "=", "False", "\n", "\n", "", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                    ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                        ", "return", "module", "(", "*", "inputs", ",", "past_key_value", ",", "True", ")", "# HACK: output_attentions instead of True", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "layer_module", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", ",", "\n", "past_key_value", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "use_cache", ":", "\n", "                ", "next_decoder_cache", "+=", "(", "layer_outputs", "[", "-", "1", "]", ",", ")", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_self_attentions", "=", "all_self_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "if", "self", ".", "config", ".", "add_cross_attention", ":", "\n", "                    ", "all_cross_attentions", "=", "all_cross_attentions", "+", "(", "layer_outputs", "[", "2", "]", ",", ")", "\n", "\n", "", "", "", "if", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "\n", "v", "\n", "for", "v", "in", "[", "\n", "hidden_states", ",", "\n", "next_decoder_cache", ",", "\n", "all_hidden_states", ",", "\n", "all_self_attentions", ",", "\n", "all_cross_attentions", ",", "\n", "]", "\n", "if", "v", "is", "not", "None", "\n", ")", "\n", "", "return", "BaseModelOutputWithPastAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "\n", "past_key_values", "=", "next_decoder_cache", ",", "\n", "hidden_states", "=", "all_hidden_states", ",", "\n", "attentions", "=", "all_self_attentions", ",", "\n", "cross_attentions", "=", "all_cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPooler.__init__": [[687, 691], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPooler.forward": [[692, 699], ["modeling_roberta.RobertaPooler.dense", "modeling_roberta.RobertaPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPreTrainedModel._init_weights": [[711, 726], ["isinstance", "module.weight.data.normal_", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "isinstance", "module.weight.data[].zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\"Initialize the weights\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "module", ".", "padding_idx", "is", "not", "None", ":", "\n", "                ", "module", ".", "weight", ".", "data", "[", "module", ".", "padding_idx", "]", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPreTrainedModel.update_keys_to_ignore": [[727, 734], ["None"], "methods", ["None"], ["", "", "def", "update_keys_to_ignore", "(", "self", ",", "config", ",", "del_keys_to_ignore", ")", ":", "\n", "        ", "\"\"\"Remove some keys from ignore list\"\"\"", "\n", "if", "not", "config", ".", "tie_word_embeddings", ":", "\n", "# must make a new list, or the class variable gets modified!", "\n", "            ", "self", ".", "_keys_to_ignore_on_save", "=", "[", "k", "for", "k", "in", "self", ".", "_keys_to_ignore_on_save", "if", "k", "not", "in", "del_keys_to_ignore", "]", "\n", "self", ".", "_keys_to_ignore_on_load_missing", "=", "[", "\n", "k", "for", "k", "in", "self", ".", "_keys_to_ignore_on_load_missing", "if", "k", "not", "in", "del_keys_to_ignore", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaModel.__init__": [[829, 839], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaEncoder", "modeling_roberta.RobertaModel.init_weights", "modeling_roberta.RobertaPooler"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "add_pooling_layer", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "RobertaEncoder", "(", "config", ")", "\n", "\n", "self", ".", "pooler", "=", "RobertaPooler", "(", "config", ")", "if", "add_pooling_layer", "else", "None", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaModel.get_input_embeddings": [[840, 842], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaModel.set_input_embeddings": [[843, 845], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaModel._prune_heads": [[846, 853], ["heads_to_prune.items", "modeling_roberta.RobertaModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaAttention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\"\n        Prunes heads of the model. heads_to_prune: dict of {layer_num: list of heads to prune in this layer} See base\n        class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaModel.forward": [[854, 990], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaModel.get_extended_attention_mask", "modeling_roberta.RobertaModel.get_head_mask", "modeling_roberta.RobertaModel.embeddings", "modeling_roberta.RobertaModel.encoder", "modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions", "ROBERTA_INPUTS_DOCSTRING.format", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "hasattr", "encoder_hidden_states.size", "modeling_roberta.RobertaModel.invert_attention_mask", "modeling_roberta.RobertaModel.pooler", "input_ids.size", "buffered_token_type_ids.expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "inputs_embeds.size"], "methods", ["None"], ["", "", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"(batch_size, sequence_length)\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "BaseModelOutputWithPoolingAndCrossAttentions", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "# Copied from transformers.models.bert.modeling_bert.BertModel.forward", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n            the model is configured as a decoder.\n        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n\n            - 1 for tokens that are **not masked**,\n            - 0 for tokens that are **masked**.\n        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n\n            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n        use_cache (:obj:`bool`, `optional`):\n            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n            decoding (see :obj:`past_key_values`).\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "            ", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "", "else", ":", "\n", "            ", "use_cache", "=", "False", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "# past_key_values_length", "\n", "past_key_values_length", "=", "past_key_values", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "2", "]", "if", "past_key_values", "is", "not", "None", "else", "0", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "(", "(", "batch_size", ",", "seq_length", "+", "past_key_values_length", ")", ")", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "embeddings", ",", "\"token_type_ids\"", ")", ":", "\n", "                ", "buffered_token_type_ids", "=", "self", ".", "embeddings", ".", "token_type_ids", "[", ":", ",", ":", "seq_length", "]", "\n", "buffered_token_type_ids_expanded", "=", "buffered_token_type_ids", ".", "expand", "(", "batch_size", ",", "seq_length", ")", "\n", "token_type_ids", "=", "buffered_token_type_ids_expanded", "\n", "", "else", ":", "\n", "                ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "", "extended_attention_mask", ":", "torch", ".", "Tensor", "=", "self", ".", "get_extended_attention_mask", "(", "attention_mask", ",", "input_shape", ",", "device", ")", "\n", "\n", "# If a 2D or 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "", "encoder_extended_attention_mask", "=", "self", ".", "invert_attention_mask", "(", "encoder_attention_mask", ")", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "head_mask", "=", "self", ".", "get_head_mask", "(", "head_mask", ",", "self", ".", "config", ".", "num_hidden_layers", ")", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "past_key_values_length", "=", "past_key_values_length", ",", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "if", "self", ".", "pooler", "is", "not", "None", "else", "None", "\n", "\n", "if", "not", "return_dict", ":", "\n", "            ", "return", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "\n", "", "return", "BaseModelOutputWithPoolingAndCrossAttentions", "(", "\n", "last_hidden_state", "=", "sequence_output", ",", "\n", "pooler_output", "=", "pooled_output", ",", "\n", "past_key_values", "=", "encoder_outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "encoder_outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "encoder_outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "encoder_outputs", ".", "cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM.__init__": [[1001, 1014], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForCausalLM.update_keys_to_ignore", "modeling_roberta.RobertaForCausalLM.init_weights", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPreTrainedModel.update_keys_to_ignore"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "not", "config", ".", "is_decoder", ":", "\n", "            ", "logger", ".", "warning", "(", "\"If you want to use `RobertaLMHeadModel` as a standalone, add `is_decoder=True.`\"", ")", "\n", "\n", "", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "# The LM head weights require special treatment only when they are tied with the word embeddings", "\n", "self", ".", "update_keys_to_ignore", "(", "config", ",", "[", "\"lm_head.decoder.weight\"", "]", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM.get_output_embeddings": [[1015, 1017], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM.set_output_embeddings": [[1018, 1020], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "lm_head", ".", "decoder", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM.forward": [[1021, 1124], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.replace_return_docstrings", "modeling_roberta.RobertaForCausalLM.roberta", "modeling_roberta.RobertaForCausalLM.lm_head", "modeling_outputs.CausalLMOutputWithCrossAttentions", "ROBERTA_INPUTS_DOCSTRING.format", "prediction_scores[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores[].contiguous.view", "labels[].contiguous.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "replace_return_docstrings", "(", "output_type", "=", "CausalLMOutputWithCrossAttentions", ",", "config_class", "=", "_CONFIG_FOR_DOC", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "past_key_values", "=", "None", ",", "\n", "use_cache", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        encoder_hidden_states  (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n            Sequence of hidden-states at the output of the last layer of the encoder. Used in the cross-attention if\n            the model is configured as a decoder.\n        encoder_attention_mask (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Mask to avoid performing attention on the padding token indices of the encoder input. This mask is used in\n            the cross-attention if the model is configured as a decoder. Mask values selected in ``[0, 1]``:\n\n            - 1 for tokens that are **not masked**,\n            - 0 for tokens that are **masked**.\n\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\n            ``[-100, 0, ..., config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are\n            ignored (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n        past_key_values (:obj:`tuple(tuple(torch.FloatTensor))` of length :obj:`config.n_layers` with each tuple having 4 tensors of shape :obj:`(batch_size, num_heads, sequence_length - 1, embed_size_per_head)`):\n            Contains precomputed key and value hidden states of the attention blocks. Can be used to speed up decoding.\n\n            If :obj:`past_key_values` are used, the user can optionally input only the last :obj:`decoder_input_ids`\n            (those that don't have their past key value states given to this model) of shape :obj:`(batch_size, 1)`\n            instead of all :obj:`decoder_input_ids` of shape :obj:`(batch_size, sequence_length)`.\n        use_cache (:obj:`bool`, `optional`):\n            If set to :obj:`True`, :obj:`past_key_values` key value states are returned and can be used to speed up\n            decoding (see :obj:`past_key_values`).\n\n        Returns:\n\n        Example::\n\n            >>> from transformers import RobertaTokenizer, RobertaForCausalLM, RobertaConfig\n            >>> import torch\n\n            >>> tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n            >>> config = RobertaConfig.from_pretrained(\"roberta-base\")\n            >>> config.is_decoder = True\n            >>> model = RobertaForCausalLM.from_pretrained('roberta-base', config=config)\n\n            >>> inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n            >>> outputs = model(**inputs)\n\n            >>> prediction_logits = outputs.logits\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "use_cache", "=", "False", "\n", "\n", "", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "past_key_values", "=", "past_key_values", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# we are doing next-token prediction; shift prediction scores and input ids by one", "\n", "            ", "shifted_prediction_scores", "=", "prediction_scores", "[", ":", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "labels", "=", "labels", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "lm_loss", "=", "loss_fct", "(", "shifted_prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "lm_loss", ",", ")", "+", "output", ")", "if", "lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "CausalLMOutputWithCrossAttentions", "(", "\n", "loss", "=", "lm_loss", ",", "\n", "logits", "=", "prediction_scores", ",", "\n", "past_key_values", "=", "outputs", ".", "past_key_values", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", "cross_attentions", "=", "outputs", ".", "cross_attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM.prepare_inputs_for_generation": [[1126, 1137], ["input_ids.new_ones"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", "=", "None", ",", "attention_mask", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "input_shape", "=", "input_ids", ".", "shape", "\n", "# if model is used as a decoder in encoder-decoder model, the decoder attention mask is created on the fly", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_shape", ")", "\n", "\n", "# cut decoder_input_ids if past is used", "\n", "", "if", "past", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "\n", "", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"attention_mask\"", ":", "attention_mask", ",", "\"past_key_values\"", ":", "past", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForCausalLM._reorder_cache": [[1138, 1143], ["tuple", "past_state.index_select"], "methods", ["None"], ["", "def", "_reorder_cache", "(", "self", ",", "past", ",", "beam_idx", ")", ":", "\n", "        ", "reordered_past", "=", "(", ")", "\n", "for", "layer_past", "in", "past", ":", "\n", "            ", "reordered_past", "+=", "(", "tuple", "(", "past_state", ".", "index_select", "(", "0", ",", "beam_idx", ")", "for", "past_state", "in", "layer_past", ")", ",", ")", "\n", "", "return", "reordered_past", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMaskedLM.__init__": [[1151, 1167], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.update_keys_to_ignore", "modeling_roberta.RobertaForMaskedLM.init_weights", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaPreTrainedModel.update_keys_to_ignore"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "if", "config", ".", "is_decoder", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"If you want to use `RobertaForMaskedLM` make sure `config.is_decoder=False` for \"", "\n", "\"bi-directional self-attention.\"", "\n", ")", "\n", "\n", "", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "# The LM head weights require special treatment only when they are tied with the word embeddings", "\n", "self", ".", "update_keys_to_ignore", "(", "config", ",", "[", "\"lm_head.decoder.weight\"", "]", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMaskedLM.get_output_embeddings": [[1168, 1170], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMaskedLM.set_output_embeddings": [[1171, 1173], ["None"], "methods", ["None"], ["", "def", "set_output_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "lm_head", ".", "decoder", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMaskedLM.forward": [[1174, 1237], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "modeling_outputs.MaskedLMOutput", "ROBERTA_INPUTS_DOCSTRING.format", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "labels.view"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "MaskedLMOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", "mask", "=", "\"<mask>\"", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n        kwargs (:obj:`Dict[str, any]`, optional, defaults to `{}`):\n            Used to hide legacy arguments that have been deprecated.\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "masked_lm_loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "masked_lm_loss", ",", ")", "+", "output", ")", "if", "masked_lm_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "MaskedLMOutput", "(", "\n", "loss", "=", "masked_lm_loss", ",", "\n", "logits", "=", "prediction_scores", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaLMHead.__init__": [[1243, 1253], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n", "# Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`", "\n", "self", ".", "decoder", ".", "bias", "=", "self", ".", "bias", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaLMHead.forward": [[1254, 1263], ["modeling_roberta.RobertaLMHead.dense", "activations.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForSequenceClassification.__init__": [[1275, 1284], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHead", "modeling_roberta.RobertaForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForSequenceClassification.forward": [[1285, 1359], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "modeling_outputs.SequenceClassifierOutput", "ROBERTA_INPUTS_DOCSTRING.format", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss.", "modeling_roberta.RobertaForSequenceClassification.squeeze", "labels.squeeze", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "torch.nn.BCEWithLogitsLoss."], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "SequenceClassifierOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "problem_type", "is", "None", ":", "\n", "                ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"regression\"", "\n", "", "elif", "self", ".", "num_labels", ">", "1", "and", "(", "labels", ".", "dtype", "==", "torch", ".", "long", "or", "labels", ".", "dtype", "==", "torch", ".", "int", ")", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"single_label_classification\"", "\n", "", "else", ":", "\n", "                    ", "self", ".", "config", ".", "problem_type", "=", "\"multi_label_classification\"", "\n", "\n", "", "", "if", "self", ".", "config", ".", "problem_type", "==", "\"regression\"", ":", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                    ", "loss", "=", "loss_fct", "(", "logits", ".", "squeeze", "(", ")", ",", "labels", ".", "squeeze", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "", "", "elif", "self", ".", "config", ".", "problem_type", "==", "\"single_label_classification\"", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "config", ".", "problem_type", "==", "\"multi_label_classification\"", ":", "\n", "                ", "loss_fct", "=", "BCEWithLogitsLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMultipleChoice.__init__": [[1372, 1380], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "modeling_roberta.RobertaForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForMultipleChoice.forward": [[1381, 1451], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaForMultipleChoice.roberta", "modeling_roberta.RobertaForMultipleChoice.dropout", "modeling_roberta.RobertaForMultipleChoice.classifier", "modeling_roberta.RobertaForMultipleChoice.view", "modeling_outputs.MultipleChoiceModelOutput", "ROBERTA_INPUTS_DOCSTRING.format", "input_ids.view", "position_ids.view", "token_type_ids.view", "attention_mask.view", "inputs_embeds.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "input_ids.size", "position_ids.size", "token_type_ids.size", "attention_mask.size", "inputs_embeds.size", "inputs_embeds.size"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, num_choices, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "MultipleChoiceModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for computing the multiple choice classification loss. Indices should be in ``[0, ...,\n            num_choices-1]`` where :obj:`num_choices` is the size of the second dimension of the input tensors. (See\n            :obj:`input_ids` above)\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "if", "input_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_inputs_embeds", "=", "(", "\n", "inputs_embeds", ".", "view", "(", "-", "1", ",", "inputs_embeds", ".", "size", "(", "-", "2", ")", ",", "inputs_embeds", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "inputs_embeds", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "flat_input_ids", ",", "\n", "position_ids", "=", "flat_position_ids", ",", "\n", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "flat_inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "MultipleChoiceModelOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "reshaped_logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForTokenClassification.__init__": [[1465, 1477], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "modeling_roberta.RobertaForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "classifier_dropout", "=", "(", "\n", "config", ".", "classifier_dropout", "if", "config", ".", "classifier_dropout", "is", "not", "None", "else", "config", ".", "hidden_dropout_prob", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "classifier_dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForTokenClassification.forward": [[1478, 1545], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaForTokenClassification.roberta", "modeling_roberta.RobertaForTokenClassification.dropout", "modeling_roberta.RobertaForTokenClassification.classifier", "modeling_outputs.TokenClassifierOutput", "ROBERTA_INPUTS_DOCSTRING.format", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "modeling_roberta.RobertaForTokenClassification.view", "torch.where", "torch.where", "torch.where", "torch.where", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "labels.view", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "torch.tensor().type_as", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "TokenClassifierOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n            Labels for computing the token classification loss. Indices should be in ``[0, ..., config.num_labels -\n            1]``.\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "loss", "=", "None", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "\n", "active_labels", "=", "torch", ".", "where", "(", "\n", "active_loss", ",", "labels", ".", "view", "(", "-", "1", ")", ",", "torch", ".", "tensor", "(", "loss_fct", ".", "ignore_index", ")", ".", "type_as", "(", "labels", ")", "\n", ")", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "loss", ",", ")", "+", "output", ")", "if", "loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "TokenClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaClassificationHead.__init__": [[1551, 1559], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "classifier_dropout", "=", "(", "\n", "config", ".", "classifier_dropout", "if", "config", ".", "classifier_dropout", "is", "not", "None", "else", "config", ".", "hidden_dropout_prob", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "classifier_dropout", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaClassificationHead.forward": [[1560, 1568], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForQuestionAnswering.__init__": [[1581, 1589], ["modeling_utils.PreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.nn.Linear", "torch.nn.Linear", "modeling_roberta.RobertaForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ",", "add_pooling_layer", "=", "False", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.RobertaForQuestionAnswering.forward": [[1590, 1669], ["file_utils.add_start_docstrings_to_model_forward", "file_utils.add_code_sample_docstrings", "modeling_roberta.RobertaForQuestionAnswering.roberta", "modeling_roberta.RobertaForQuestionAnswering.qa_outputs", "modeling_roberta.RobertaForQuestionAnswering.split", "start_logits.squeeze().contiguous.squeeze().contiguous.squeeze().contiguous", "end_logits.squeeze().contiguous.squeeze().contiguous.squeeze().contiguous", "modeling_outputs.QuestionAnsweringModelOutput", "ROBERTA_INPUTS_DOCSTRING.format", "start_logits.squeeze().contiguous.squeeze().contiguous.size", "start_positions.squeeze.squeeze.clamp", "end_positions.squeeze.squeeze.clamp", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "start_logits.squeeze().contiguous.squeeze().contiguous.squeeze", "end_logits.squeeze().contiguous.squeeze().contiguous.squeeze", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "@", "add_start_docstrings_to_model_forward", "(", "ROBERTA_INPUTS_DOCSTRING", ".", "format", "(", "\"batch_size, sequence_length\"", ")", ")", "\n", "@", "add_code_sample_docstrings", "(", "\n", "tokenizer_class", "=", "_TOKENIZER_FOR_DOC", ",", "\n", "checkpoint", "=", "_CHECKPOINT_FOR_DOC", ",", "\n", "output_type", "=", "QuestionAnsweringModelOutput", ",", "\n", "config_class", "=", "_CONFIG_FOR_DOC", ",", "\n", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        start_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for position (index) of the start of the labelled span for computing the token classification loss.\n            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n            sequence are not taken into account for computing the loss.\n        end_positions (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n            Labels for position (index) of the end of the labelled span for computing the token classification loss.\n            Positions are clamped to the length of the sequence (:obj:`sequence_length`). Position outside of the\n            sequence are not taken into account for computing the loss.\n        \"\"\"", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "return_dict", "=", "return_dict", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "total_loss", "=", "None", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", "=", "start_positions", ".", "clamp", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", "=", "end_positions", ".", "clamp", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "output", "=", "(", "start_logits", ",", "end_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "return", "(", "(", "total_loss", ",", ")", "+", "output", ")", "if", "total_loss", "is", "not", "None", "else", "output", "\n", "\n", "", "return", "QuestionAnsweringModelOutput", "(", "\n", "loss", "=", "total_loss", ",", "\n", "start_logits", "=", "start_logits", ",", "\n", "end_logits", "=", "end_logits", ",", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", ",", "\n", "attentions", "=", "outputs", ".", "attentions", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.roberta.modeling_roberta.create_position_ids_from_input_ids": [[1672, 1686], ["input_ids.ne().int", "incremental_indices.long", "input_ids.ne", "torch.cumsum().type_as", "torch.cumsum().type_as", "torch.cumsum", "torch.cumsum"], "function", ["None"], ["", "", "def", "create_position_ids_from_input_ids", "(", "input_ids", ",", "padding_idx", ",", "past_key_values_length", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Replace non-padding symbols with their position numbers. Position numbers begin at padding_idx+1. Padding symbols\n    are ignored. This is modified from fairseq's `utils.make_positions`.\n\n    Args:\n        x: torch.Tensor x:\n\n    Returns: torch.Tensor\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.", "\n", "mask", "=", "input_ids", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "incremental_indices", "=", "(", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "+", "past_key_values_length", ")", "*", "mask", "\n", "return", "incremental_indices", ".", "long", "(", ")", "+", "padding_idx", "\n", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSFilterEval.loadFile": [[40, 64], ["zip", "numpy.array", "sorted", "map", "float", "numpy.array", "numpy.array", "zip", "zip", "l.split", "io.open().read().splitlines", "s.split", "s.split", "io.open().read().splitlines", "len", "len", "io.open().read", "io.open().read", "io.open", "io.open"], "methods", ["None"], ["    ", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "self", ".", "data", "=", "{", "}", "\n", "self", ".", "samples", "=", "[", "]", "\n", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "sent1", ",", "sent2", "=", "zip", "(", "*", "[", "l", ".", "split", "(", "\"\\t\"", ")", "for", "l", "in", "\n", "io", ".", "open", "(", "fpath", "+", "'/STS.input.%s.txt'", "%", "dataset", ",", "\n", "encoding", "=", "'utf8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ")", "\n", "raw_scores", "=", "np", ".", "array", "(", "[", "x", "for", "x", "in", "\n", "io", ".", "open", "(", "fpath", "+", "'/STS.gs.%s.txt'", "%", "dataset", ",", "\n", "encoding", "=", "'utf8'", ")", "\n", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ")", "\n", "not_empty_idx", "=", "raw_scores", "!=", "''", "\n", "\n", "gs_scores", "=", "[", "float", "(", "x", ")", "for", "x", "in", "raw_scores", "[", "not_empty_idx", "]", "]", "\n", "sent1", "=", "np", ".", "array", "(", "[", "s", ".", "split", "(", ")", "for", "s", "in", "sent1", "]", ")", "[", "not_empty_idx", "]", "\n", "sent2", "=", "np", ".", "array", "(", "[", "s", ".", "split", "(", ")", "for", "s", "in", "sent2", "]", ")", "[", "not_empty_idx", "]", "\n", "# sort data by length to minimize padding in batcher", "\n", "sorted_data", "=", "sorted", "(", "zip", "(", "sent1", ",", "sent2", ",", "gs_scores", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "sent1", ",", "sent2", ",", "gs_scores", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_data", ")", ")", "\n", "\n", "self", ".", "data", "[", "dataset", "]", "=", "(", "sent1", ",", "sent2", ",", "gs_scores", ")", "\n", "self", ".", "samples", "+=", "sent1", "+", "sent2", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSFilterEval.do_prepare": [[65, 71], ["prepare", "numpy.nan_to_num", "senteval.utils.cosine", "numpy.nan_to_num", "numpy.nan_to_num"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.cosine"], ["", "", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "if", "'similarity'", "in", "params", ":", "\n", "            ", "self", ".", "similarity", "=", "params", ".", "similarity", "\n", "", "else", ":", "# Default similarity is cosine", "\n", "            ", "self", ".", "similarity", "=", "lambda", "s1", ",", "s2", ":", "np", ".", "nan_to_num", "(", "cosine", "(", "np", ".", "nan_to_num", "(", "s1", ")", ",", "np", ".", "nan_to_num", "(", "s2", ")", ")", ")", "\n", "", "return", "prepare", "(", "params", ",", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSFilterEval.run": [[73, 166], ["numpy.array", "numpy.array", "numpy.average", "numpy.average", "numpy.average", "numpy.average", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "logging.debug", "logging.debug", "logging.debug", "numpy.asarray", "numpy.asarray", "numpy.asarray", "list", "list", "list", "range", "all_sys_scores.extend", "all_gs_scores.extend", "sts_filter.align_loss", "sts_filter.uniform_loss", "logging.debug", "logging.debug", "logging.debug", "numpy.where", "len", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "len", "results.keys", "batcher", "batcher", "range", "results.keys", "results.keys", "len", "len", "len", "list", "sts_filter.STSFilterEval.similarity", "sys_scores.append", "range", "enc1[].clone", "batcher.clone", "batcher.clone", "torch.cat", "torch.cat", "torch.cat", "enc2[].clone", "batcher.clone", "batcher.clone"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.align_loss", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.uniform_loss", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.similarity"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "results", "=", "{", "}", "\n", "all_sys_scores", "=", "[", "]", "\n", "all_gs_scores", "=", "[", "]", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "sys_scores", "=", "[", "]", "\n", "input1", ",", "input2", ",", "gs_scores", "=", "self", ".", "data", "[", "dataset", "]", "\n", "gs_scores", "=", "np", ".", "asarray", "(", "gs_scores", ")", "\n", "input1", "=", "np", ".", "asarray", "(", "input1", ")", "\n", "input2", "=", "np", ".", "asarray", "(", "input2", ")", "\n", "idx", "=", "np", ".", "where", "(", "gs_scores", ">=", "4.0", ")", "[", "0", "]", "\n", "gs_scores", "=", "list", "(", "gs_scores", "[", "idx", "]", ")", "\n", "input1", "=", "list", "(", "input1", "[", "idx", "]", ")", "\n", "input2", "=", "list", "(", "input2", "[", "idx", "]", ")", "\n", "elements", "=", "0", "\n", "uniformity_dist", "=", "0", "\n", "alignment_dist", "=", "0", "\n", "\n", "refSample", "=", "None", "\n", "posSample", "=", "None", "\n", "randomSample", "=", "None", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "gs_scores", ")", ",", "params", ".", "batch_size", ")", ":", "\n", "                ", "batch1", "=", "input1", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "batch2", "=", "input2", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "\n", "# we assume get_batch already throws out the faulty ones", "\n", "if", "len", "(", "batch1", ")", "==", "len", "(", "batch2", ")", "and", "len", "(", "batch1", ")", ">", "0", ":", "\n", "                    ", "enc1", "=", "batcher", "(", "params", ",", "batch1", ")", "\n", "enc2", "=", "batcher", "(", "params", ",", "batch2", ")", "\n", "\n", "if", "True", ":", "\n", "                        ", "idx", "=", "list", "(", "range", "(", "enc1", ".", "shape", "[", "0", "]", ")", ")", "\n", "#random.shuffle(idx)", "\n", "\n", "if", "refSample", "==", "None", ":", "\n", "                            ", "randomSample", "=", "enc1", "[", "idx", ",", ":", "]", ".", "clone", "(", ")", "\n", "posSample", "=", "enc2", ".", "clone", "(", ")", "\n", "refSample", "=", "enc1", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                            ", "randomSample", "=", "torch", ".", "cat", "(", "\n", "[", "randomSample", ",", "enc2", "[", "idx", ",", ":", "]", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "posSample", "=", "torch", ".", "cat", "(", "[", "posSample", ",", "enc2", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "refSample", "=", "torch", ".", "cat", "(", "\n", "[", "refSample", ",", "enc1", ".", "clone", "(", ")", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "elements", "+=", "1", "\n", "", "for", "kk", "in", "range", "(", "enc2", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "sys_score", "=", "self", ".", "similarity", "(", "enc1", "[", "kk", "]", ",", "enc2", "[", "kk", "]", ")", "\n", "sys_scores", ".", "append", "(", "sys_score", ")", "\n", "", "", "", "all_sys_scores", ".", "extend", "(", "sys_scores", ")", "\n", "all_gs_scores", ".", "extend", "(", "gs_scores", ")", "\n", "\n", "alignment_dist", "+=", "align_loss", "(", "refSample", ",", "posSample", ")", "\n", "uniformity_dist", "+=", "uniform_loss", "(", "refSample", "-", "randomSample", ")", "\n", "\n", "#alignment_dist /= float(elements)", "\n", "#uniformity_dist /= float(elements)", "\n", "#uniformity_dist = uniformity_dist.log()", "\n", "logging", ".", "debug", "(", "\"Uniformity:  %.4f\"", "%", "uniformity_dist", ")", "\n", "logging", ".", "debug", "(", "\"Alignment:  %.4f\"", "%", "alignment_dist", ")", "\n", "results", "[", "dataset", "]", "=", "{", "'pearson'", ":", "pearsonr", "(", "sys_scores", ",", "gs_scores", ")", ",", "\n", "'spearman'", ":", "spearmanr", "(", "sys_scores", ",", "gs_scores", ")", ",", "\n", "'nsamples'", ":", "len", "(", "sys_scores", ")", "}", "\n", "logging", ".", "debug", "(", "'%s : pearson = %.4f, spearman = %.4f'", "%", "\n", "(", "dataset", ",", "results", "[", "dataset", "]", "[", "'pearson'", "]", "[", "0", "]", ",", "\n", "results", "[", "dataset", "]", "[", "'spearman'", "]", "[", "0", "]", ")", ")", "\n", "\n", "", "weights", "=", "[", "results", "[", "dset", "]", "[", "'nsamples'", "]", "for", "dset", "in", "results", ".", "keys", "(", ")", "]", "\n", "list_prs", "=", "np", ".", "array", "(", "[", "results", "[", "dset", "]", "[", "'pearson'", "]", "[", "0", "]", "for", "\n", "dset", "in", "results", ".", "keys", "(", ")", "]", ")", "\n", "list_spr", "=", "np", ".", "array", "(", "[", "results", "[", "dset", "]", "[", "'spearman'", "]", "[", "0", "]", "for", "\n", "dset", "in", "results", ".", "keys", "(", ")", "]", ")", "\n", "\n", "avg_pearson", "=", "np", ".", "average", "(", "list_prs", ")", "\n", "avg_spearman", "=", "np", ".", "average", "(", "list_spr", ")", "\n", "wavg_pearson", "=", "np", ".", "average", "(", "list_prs", ",", "weights", "=", "weights", ")", "\n", "wavg_spearman", "=", "np", ".", "average", "(", "list_spr", ",", "weights", "=", "weights", ")", "\n", "all_pearson", "=", "pearsonr", "(", "all_sys_scores", ",", "all_gs_scores", ")", "\n", "all_spearman", "=", "spearmanr", "(", "all_sys_scores", ",", "all_gs_scores", ")", "\n", "results", "[", "'all'", "]", "=", "{", "'pearson'", ":", "{", "'all'", ":", "all_pearson", "[", "0", "]", ",", "\n", "'mean'", ":", "avg_pearson", ",", "\n", "'wmean'", ":", "wavg_pearson", "}", ",", "\n", "'spearman'", ":", "{", "'all'", ":", "all_spearman", "[", "0", "]", ",", "\n", "'mean'", ":", "avg_spearman", ",", "\n", "'wmean'", ":", "wavg_spearman", "}", "}", "\n", "logging", ".", "debug", "(", "'ALL : Pearson = %.4f, \\\n            Spearman = %.4f'", "%", "(", "all_pearson", "[", "0", "]", ",", "all_spearman", "[", "0", "]", ")", ")", "\n", "logging", ".", "debug", "(", "'ALL (weighted average) : Pearson = %.4f, \\\n            Spearman = %.4f'", "%", "(", "wavg_pearson", ",", "wavg_spearman", ")", ")", "\n", "logging", ".", "debug", "(", "'ALL (average) : Pearson = %.4f, \\\n            Spearman = %.4f\\n'", "%", "(", "avg_pearson", ",", "avg_spearman", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STS12Eval.__init__": [[169, 175], ["logging.debug", "sts_filter.STS12Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS12 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'MSRpar'", ",", "'MSRvid'", ",", "'SMTeuroparl'", ",", "\n", "'surprise.OnWN'", ",", "'surprise.SMTnews'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STS13Eval.__init__": [[179, 184], ["logging.debug", "sts_filter.STS13Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS13 (-SMT) *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'FNWN'", ",", "'headlines'", ",", "'OnWN'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STS14Eval.__init__": [[187, 193], ["logging.debug", "sts_filter.STS14Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS14 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'deft-forum'", ",", "'deft-news'", ",", "'headlines'", ",", "\n", "'images'", ",", "'OnWN'", ",", "'tweet-news'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STS15Eval.__init__": [[196, 202], ["logging.debug", "sts_filter.STS15Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS15 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'answers-forums'", ",", "'answers-students'", ",", "\n", "'belief'", ",", "'headlines'", ",", "'images'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STS16Eval.__init__": [[205, 211], ["logging.debug", "sts_filter.STS16Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS16 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'answer-answer'", ",", "'headlines'", ",", "'plagiarism'", ",", "\n", "'postediting'", ",", "'question-question'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSFilterBenchmarkEval.__init__": [[214, 223], ["logging.debug", "sts_filter.STSFilterBenchmarkEval.loadFile", "sts_filter.STSFilterBenchmarkEval.loadFile", "sts_filter.STSFilterBenchmarkEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : STSBenchmark*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samples", "=", "[", "]", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-train.csv'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-dev.csv'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-test.csv'", ")", ")", "\n", "self", ".", "datasets", "=", "[", "'train'", ",", "'dev'", ",", "'test'", "]", "\n", "self", ".", "data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSFilterBenchmarkEval.loadFile": [[224, 236], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "5", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "6", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "4", "]", ")", "\n", "\n", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "self", ".", "samples", "+=", "sick_data", "[", "'X_A'", "]", "+", "sick_data", "[", "\"X_B\"", "]", "\n", "return", "(", "sick_data", "[", "'X_A'", "]", ",", "sick_data", "[", "\"X_B\"", "]", ",", "sick_data", "[", "'y'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSBenchmarkFinetune.__init__": [[238, 245], ["logging.debug", "sts_filter.STSBenchmarkFinetune.loadFile", "sts_filter.STSBenchmarkFinetune.loadFile", "sts_filter.STSBenchmarkFinetune.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : STSBenchmark*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-train.csv'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-dev.csv'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-test.csv'", ")", ")", "\n", "self", ".", "sick_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.STSBenchmarkFinetune.loadFile": [[246, 257], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "5", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "6", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "4", "]", ")", "\n", "\n", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "return", "sick_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.SICKRelatednessEval.__init__": [[260, 269], ["logging.debug", "sts_filter.SICKRelatednessEval.loadFile", "sts_filter.SICKRelatednessEval.loadFile", "sts_filter.SICKRelatednessEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : SICKRelatedness*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samples", "=", "[", "]", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_train.txt'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_trial.txt'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_test_annotated.txt'", ")", ")", "\n", "self", ".", "datasets", "=", "[", "'train'", ",", "'dev'", ",", "'test'", "]", "\n", "self", ".", "data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.SICKRelatednessEval.loadFile": [[270, 286], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "skipFirstLine", "=", "True", "\n", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "skipFirstLine", ":", "\n", "                    ", "skipFirstLine", "=", "False", "\n", "", "else", ":", "\n", "                    ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "1", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "2", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "3", "]", ")", "\n", "\n", "", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "self", ".", "samples", "+=", "sick_data", "[", "'X_A'", "]", "+", "sick_data", "[", "\"X_B\"", "]", "\n", "return", "(", "sick_data", "[", "'X_A'", "]", ",", "sick_data", "[", "\"X_B\"", "]", ",", "sick_data", "[", "'y'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.align_loss": [[32, 34], ["None"], "function", ["None"], ["def", "align_loss", "(", "x", ",", "y", ",", "alpha", "=", "2", ")", ":", "\n", "    ", "return", "(", "x", "-", "y", ")", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "pow", "(", "alpha", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts_filter.uniform_loss": [[36, 38], ["torch.pdist().pow().mul().exp().mean().log", "torch.pdist().pow().mul().exp().mean", "torch.pdist().pow().mul().exp", "torch.pdist().pow().mul", "torch.pdist().pow", "torch.pdist"], "function", ["None"], ["", "def", "uniform_loss", "(", "x", ",", "t", "=", "2", ")", ":", "\n", "    ", "return", "torch", ".", "pdist", "(", "x", ",", "p", "=", "2", ")", ".", "pow", "(", "2", ")", ".", "mul", "(", "-", "t", ")", ".", "exp", "(", ")", ".", "mean", "(", ")", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.__init__": [[30, 37], ["logging.debug", "sick.SICKEval.loadFile", "sick.SICKEval.loadFile", "sick.SICKEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : SICK-Relatedness*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_train.txt'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_trial.txt'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_test_annotated.txt'", ")", ")", "\n", "self", ".", "sick_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.do_prepare": [[38, 45], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "samples", "=", "self", ".", "sick_data", "[", "'train'", "]", "[", "'X_A'", "]", "+", "self", ".", "sick_data", "[", "'train'", "]", "[", "'X_B'", "]", "+", "self", ".", "sick_data", "[", "'dev'", "]", "[", "'X_A'", "]", "+", "self", ".", "sick_data", "[", "'dev'", "]", "[", "'X_B'", "]", "+", "self", ".", "sick_data", "[", "'test'", "]", "[", "'X_A'", "]", "+", "self", ".", "sick_data", "[", "'test'", "]", "[", "'X_B'", "]", "\n", "return", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.loadFile": [[46, 61], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "skipFirstLine", "=", "True", "\n", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "skipFirstLine", ":", "\n", "                    ", "skipFirstLine", "=", "False", "\n", "", "else", ":", "\n", "                    ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "1", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "2", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "3", "]", ")", "\n", "\n", "", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "return", "sick_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.run": [[62, 126], ["sick.SICKEval.encode_labels", "sick.SICKEval.encode_labels", "sick.SICKEval.encode_labels", "senteval.tools.relatedness.RelatednessPytorch", "senteval.tools.relatedness.RelatednessPytorch.run", "sklearn.metrics.mean_squared_error", "logging.debug", "logging.debug", "logging.info", "sorted", "numpy.array", "logging.info", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "len", "len", "zip", "range", "numpy.vstack", "len", "batcher", "[].append", "numpy.abs", "numpy.abs", "numpy.abs", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.encode_labels", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.encode_labels", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.encode_labels", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "sick_embed", "=", "{", "'train'", ":", "{", "}", ",", "'dev'", ":", "{", "}", ",", "'test'", ":", "{", "}", "}", "\n", "bsize", "=", "params", ".", "batch_size", "\n", "\n", "for", "key", "in", "self", ".", "sick_data", ":", "\n", "            ", "logging", ".", "info", "(", "'Computing embedding for {0}'", ".", "format", "(", "key", ")", ")", "\n", "# Sort to reduce padding", "\n", "sorted_corpus", "=", "sorted", "(", "zip", "(", "self", ".", "sick_data", "[", "key", "]", "[", "'X_A'", "]", ",", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_B'", "]", ",", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_A'", "]", "=", "[", "x", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_B'", "]", "=", "[", "y", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", "=", "[", "z", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "\n", "for", "txt_type", "in", "[", "'X_A'", ",", "'X_B'", "]", ":", "\n", "                ", "sick_embed", "[", "key", "]", "[", "txt_type", "]", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "bsize", ")", ":", "\n", "                    ", "batch", "=", "self", ".", "sick_data", "[", "key", "]", "[", "txt_type", "]", "[", "ii", ":", "ii", "+", "bsize", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "sick_embed", "[", "key", "]", "[", "txt_type", "]", ".", "append", "(", "embeddings", ")", "\n", "", "sick_embed", "[", "key", "]", "[", "txt_type", "]", "=", "np", ".", "vstack", "(", "sick_embed", "[", "key", "]", "[", "txt_type", "]", ")", "\n", "", "sick_embed", "[", "key", "]", "[", "'y'", "]", "=", "np", ".", "array", "(", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", ")", "\n", "logging", ".", "info", "(", "'Computed {0} embeddings'", ".", "format", "(", "key", ")", ")", "\n", "\n", "# Train", "\n", "", "trainA", "=", "sick_embed", "[", "'train'", "]", "[", "'X_A'", "]", "\n", "trainB", "=", "sick_embed", "[", "'train'", "]", "[", "'X_B'", "]", "\n", "trainF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "trainA", "-", "trainB", ")", ",", "trainA", "*", "trainB", "]", "\n", "trainY", "=", "self", ".", "encode_labels", "(", "self", ".", "sick_data", "[", "'train'", "]", "[", "'y'", "]", ")", "\n", "\n", "# Dev", "\n", "devA", "=", "sick_embed", "[", "'dev'", "]", "[", "'X_A'", "]", "\n", "devB", "=", "sick_embed", "[", "'dev'", "]", "[", "'X_B'", "]", "\n", "devF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "devA", "-", "devB", ")", ",", "devA", "*", "devB", "]", "\n", "devY", "=", "self", ".", "encode_labels", "(", "self", ".", "sick_data", "[", "'dev'", "]", "[", "'y'", "]", ")", "\n", "\n", "# Test", "\n", "testA", "=", "sick_embed", "[", "'test'", "]", "[", "'X_A'", "]", "\n", "testB", "=", "sick_embed", "[", "'test'", "]", "[", "'X_B'", "]", "\n", "testF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "testA", "-", "testB", ")", ",", "testA", "*", "testB", "]", "\n", "testY", "=", "self", ".", "encode_labels", "(", "self", ".", "sick_data", "[", "'test'", "]", "[", "'y'", "]", ")", "\n", "\n", "config", "=", "{", "'seed'", ":", "self", ".", "seed", ",", "'nclasses'", ":", "5", "}", "\n", "clf", "=", "RelatednessPytorch", "(", "train", "=", "{", "'X'", ":", "trainF", ",", "'y'", ":", "trainY", "}", ",", "\n", "valid", "=", "{", "'X'", ":", "devF", ",", "'y'", ":", "devY", "}", ",", "\n", "test", "=", "{", "'X'", ":", "testF", ",", "'y'", ":", "testY", "}", ",", "\n", "devscores", "=", "self", ".", "sick_data", "[", "'dev'", "]", "[", "'y'", "]", ",", "\n", "config", "=", "config", ")", "\n", "\n", "devspr", ",", "yhat", "=", "clf", ".", "run", "(", ")", "\n", "\n", "pr", "=", "pearsonr", "(", "yhat", ",", "self", ".", "sick_data", "[", "'test'", "]", "[", "'y'", "]", ")", "[", "0", "]", "\n", "sr", "=", "spearmanr", "(", "yhat", ",", "self", ".", "sick_data", "[", "'test'", "]", "[", "'y'", "]", ")", "[", "0", "]", "\n", "pr", "=", "0", "if", "pr", "!=", "pr", "else", "pr", "\n", "sr", "=", "0", "if", "sr", "!=", "sr", "else", "sr", "\n", "se", "=", "mean_squared_error", "(", "yhat", ",", "self", ".", "sick_data", "[", "'test'", "]", "[", "'y'", "]", ")", "\n", "logging", ".", "debug", "(", "'Dev : Spearman {0}'", ".", "format", "(", "devspr", ")", ")", "\n", "logging", ".", "debug", "(", "'Test : Pearson {0} Spearman {1} MSE {2} \\\n                       for SICK Relatedness\\n'", ".", "format", "(", "pr", ",", "sr", ",", "se", ")", ")", "\n", "\n", "return", "{", "'devspearman'", ":", "devspr", ",", "'pearson'", ":", "pr", ",", "'spearman'", ":", "sr", ",", "'mse'", ":", "se", ",", "\n", "'yhat'", ":", "yhat", ",", "'ndev'", ":", "len", "(", "devA", ")", ",", "'ntest'", ":", "len", "(", "testA", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEval.encode_labels": [[127, 139], ["numpy.zeros().astype", "enumerate", "range", "numpy.zeros", "numpy.floor", "len", "numpy.floor", "numpy.floor", "numpy.floor"], "methods", ["None"], ["", "def", "encode_labels", "(", "self", ",", "labels", ",", "nclass", "=", "5", ")", ":", "\n", "        ", "\"\"\"\n        Label encoding from Tree LSTM paper (Tai, Socher, Manning)\n        \"\"\"", "\n", "Y", "=", "np", ".", "zeros", "(", "(", "len", "(", "labels", ")", ",", "nclass", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "j", ",", "y", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "nclass", ")", ":", "\n", "                ", "if", "i", "+", "1", "==", "np", ".", "floor", "(", "y", ")", "+", "1", ":", "\n", "                    ", "Y", "[", "j", ",", "i", "]", "=", "y", "-", "np", ".", "floor", "(", "y", ")", "\n", "", "if", "i", "+", "1", "==", "np", ".", "floor", "(", "y", ")", ":", "\n", "                    ", "Y", "[", "j", ",", "i", "]", "=", "np", ".", "floor", "(", "y", ")", "-", "y", "+", "1", "\n", "", "", "", "return", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEntailmentEval.__init__": [[142, 149], ["logging.debug", "sick.SICKEntailmentEval.loadFile", "sick.SICKEntailmentEval.loadFile", "sick.SICKEntailmentEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : SICK-Entailment*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_train.txt'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_trial.txt'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_test_annotated.txt'", ")", ")", "\n", "self", ".", "sick_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEntailmentEval.loadFile": [[150, 165], ["io.open", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "label2id", "=", "{", "'CONTRADICTION'", ":", "0", ",", "'NEUTRAL'", ":", "1", ",", "'ENTAILMENT'", ":", "2", "}", "\n", "skipFirstLine", "=", "True", "\n", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "skipFirstLine", ":", "\n", "                    ", "skipFirstLine", "=", "False", "\n", "", "else", ":", "\n", "                    ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "1", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "2", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "4", "]", ")", "\n", "", "", "", "sick_data", "[", "'y'", "]", "=", "[", "label2id", "[", "s", "]", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "return", "sick_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sick.SICKEntailmentEval.run": [[166, 222], ["numpy.array", "numpy.array", "numpy.array", "senteval.tools.validation.SplitClassifier", "senteval.tools.validation.SplitClassifier.run", "logging.debug", "logging.info", "sorted", "logging.info", "len", "len", "zip", "range", "numpy.vstack", "len", "batcher", "[].append", "numpy.abs", "numpy.abs", "numpy.abs", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "sick_embed", "=", "{", "'train'", ":", "{", "}", ",", "'dev'", ":", "{", "}", ",", "'test'", ":", "{", "}", "}", "\n", "bsize", "=", "params", ".", "batch_size", "\n", "\n", "for", "key", "in", "self", ".", "sick_data", ":", "\n", "            ", "logging", ".", "info", "(", "'Computing embedding for {0}'", ".", "format", "(", "key", ")", ")", "\n", "# Sort to reduce padding", "\n", "sorted_corpus", "=", "sorted", "(", "zip", "(", "self", ".", "sick_data", "[", "key", "]", "[", "'X_A'", "]", ",", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_B'", "]", ",", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_A'", "]", "=", "[", "x", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'X_B'", "]", "=", "[", "y", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", "=", "[", "z", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "\n", "for", "txt_type", "in", "[", "'X_A'", ",", "'X_B'", "]", ":", "\n", "                ", "sick_embed", "[", "key", "]", "[", "txt_type", "]", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "self", ".", "sick_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "bsize", ")", ":", "\n", "                    ", "batch", "=", "self", ".", "sick_data", "[", "key", "]", "[", "txt_type", "]", "[", "ii", ":", "ii", "+", "bsize", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "sick_embed", "[", "key", "]", "[", "txt_type", "]", ".", "append", "(", "embeddings", ")", "\n", "", "sick_embed", "[", "key", "]", "[", "txt_type", "]", "=", "np", ".", "vstack", "(", "sick_embed", "[", "key", "]", "[", "txt_type", "]", ")", "\n", "", "logging", ".", "info", "(", "'Computed {0} embeddings'", ".", "format", "(", "key", ")", ")", "\n", "\n", "# Train", "\n", "", "trainA", "=", "sick_embed", "[", "'train'", "]", "[", "'X_A'", "]", "\n", "trainB", "=", "sick_embed", "[", "'train'", "]", "[", "'X_B'", "]", "\n", "trainF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "trainA", "-", "trainB", ")", ",", "trainA", "*", "trainB", "]", "\n", "trainY", "=", "np", ".", "array", "(", "self", ".", "sick_data", "[", "'train'", "]", "[", "'y'", "]", ")", "\n", "\n", "# Dev", "\n", "devA", "=", "sick_embed", "[", "'dev'", "]", "[", "'X_A'", "]", "\n", "devB", "=", "sick_embed", "[", "'dev'", "]", "[", "'X_B'", "]", "\n", "devF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "devA", "-", "devB", ")", ",", "devA", "*", "devB", "]", "\n", "devY", "=", "np", ".", "array", "(", "self", ".", "sick_data", "[", "'dev'", "]", "[", "'y'", "]", ")", "\n", "\n", "# Test", "\n", "testA", "=", "sick_embed", "[", "'test'", "]", "[", "'X_A'", "]", "\n", "testB", "=", "sick_embed", "[", "'test'", "]", "[", "'X_B'", "]", "\n", "testF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "testA", "-", "testB", ")", ",", "testA", "*", "testB", "]", "\n", "testY", "=", "np", ".", "array", "(", "self", ".", "sick_data", "[", "'test'", "]", "[", "'y'", "]", ")", "\n", "\n", "config", "=", "{", "'nclasses'", ":", "3", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", ",", "\n", "'nhid'", ":", "params", ".", "nhid", "}", "\n", "clf", "=", "SplitClassifier", "(", "X", "=", "{", "'train'", ":", "trainF", ",", "'valid'", ":", "devF", ",", "'test'", ":", "testF", "}", ",", "\n", "y", "=", "{", "'train'", ":", "trainY", ",", "'valid'", ":", "devY", ",", "'test'", ":", "testY", "}", ",", "\n", "config", "=", "config", ")", "\n", "\n", "devacc", ",", "testacc", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'\\nDev acc : {0} Test acc : {1} for \\\n                       SICK entailment\\n'", ".", "format", "(", "devacc", ",", "testacc", ")", ")", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "\n", "'ndev'", ":", "len", "(", "devA", ")", ",", "'ntest'", ":", "len", "(", "testA", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.__init__": [[34, 62], ["senteval.utils.dotdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "batcher", ",", "prepare", "=", "None", ")", ":", "\n", "# parameters", "\n", "        ", "params", "=", "utils", ".", "dotdict", "(", "params", ")", "\n", "params", ".", "usepytorch", "=", "True", "if", "'usepytorch'", "not", "in", "params", "else", "params", ".", "usepytorch", "\n", "params", ".", "seed", "=", "1111", "if", "'seed'", "not", "in", "params", "else", "params", ".", "seed", "\n", "\n", "params", ".", "batch_size", "=", "128", "if", "'batch_size'", "not", "in", "params", "else", "params", ".", "batch_size", "\n", "params", ".", "nhid", "=", "0", "if", "'nhid'", "not", "in", "params", "else", "params", ".", "nhid", "\n", "params", ".", "kfold", "=", "5", "if", "'kfold'", "not", "in", "params", "else", "params", ".", "kfold", "\n", "\n", "if", "'classifier'", "not", "in", "params", "or", "not", "params", "[", "'classifier'", "]", ":", "\n", "            ", "params", ".", "classifier", "=", "{", "'nhid'", ":", "0", "}", "\n", "\n", "", "assert", "'nhid'", "in", "params", ".", "classifier", ",", "'Set number of hidden units in classifier config!!'", "\n", "\n", "self", ".", "params", "=", "params", "\n", "\n", "# batcher and prepare", "\n", "self", ".", "batcher", "=", "batcher", "\n", "self", ".", "prepare", "=", "prepare", "if", "prepare", "else", "lambda", "x", ",", "y", ":", "None", "\n", "\n", "self", ".", "list_tasks", "=", "[", "'CR'", ",", "'MR'", ",", "'MPQA'", ",", "'SUBJ'", ",", "'SST2'", ",", "'SST5'", ",", "'TREC'", ",", "'MRPC'", ",", "\n", "'SICKRelatedness'", ",", "'SICKEntailment'", ",", "'STSBenchmark'", ",", "\"STSFilterBenchmark\"", ",", "\n", "'SNLI'", ",", "'ImageCaptionRetrieval'", ",", "'STS12'", ",", "'STS13'", ",", "\n", "'STS14'", ",", "'STS15'", ",", "'STS16'", ",", "\n", "'Length'", ",", "'WordContent'", ",", "'Depth'", ",", "'TopConstituents'", ",", "\n", "'BigramShift'", ",", "'Tense'", ",", "'SubjNumber'", ",", "'ObjNumber'", ",", "\n", "'OddManOut'", ",", "'CoordinationInversion'", ",", "'SICKRelatedness-finetune'", ",", "'STSBenchmark-finetune'", ",", "'STSBenchmark-fix'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval": [[63, 139], ["isinstance", "engine.SE.evaluation.do_prepare", "engine.SE.evaluation.run", "str", "senteval.binary.CREval", "engine.SE.eval", "str", "senteval.binary.MREval", "senteval.binary.MPQAEval", "senteval.binary.SUBJEval", "senteval.sst.SSTEval", "senteval.sst.SSTEval", "senteval.trec.TRECEval", "senteval.mrpc.MRPCEval", "senteval.sts.SICKRelatednessEval", "senteval.sts.STSBenchmarkEval", "senteval.sts_filter.STSFilterBenchmarkEval", "senteval.sts.STSBenchmarkEval", "senteval.sts.STSBenchmarkFinetune", "senteval.sick.SICKEval", "senteval.sick.SICKEntailmentEval", "senteval.snli.SNLIEval", "engine.SE.eval"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSEval.do_prepare", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "eval", "(", "self", ",", "name", ")", ":", "\n", "# evaluate on evaluation [name], either takes string or list of strings", "\n", "        ", "if", "(", "isinstance", "(", "name", ",", "list", ")", ")", ":", "\n", "            ", "self", ".", "results", "=", "{", "x", ":", "self", ".", "eval", "(", "x", ")", "for", "x", "in", "name", "}", "\n", "return", "self", ".", "results", "\n", "\n", "", "tpath", "=", "self", ".", "params", ".", "task_path", "\n", "assert", "name", "in", "self", ".", "list_tasks", ",", "str", "(", "name", ")", "+", "' not in '", "+", "str", "(", "self", ".", "list_tasks", ")", "\n", "\n", "# Original SentEval tasks", "\n", "if", "name", "==", "'CR'", ":", "\n", "            ", "self", ".", "evaluation", "=", "CREval", "(", "tpath", "+", "'/downstream/CR'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'MR'", ":", "\n", "            ", "self", ".", "evaluation", "=", "MREval", "(", "tpath", "+", "'/downstream/MR'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'MPQA'", ":", "\n", "            ", "self", ".", "evaluation", "=", "MPQAEval", "(", "tpath", "+", "'/downstream/MPQA'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SUBJ'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SUBJEval", "(", "tpath", "+", "'/downstream/SUBJ'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SST2'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SSTEval", "(", "tpath", "+", "'/downstream/SST/binary'", ",", "nclasses", "=", "2", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SST5'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SSTEval", "(", "tpath", "+", "'/downstream/SST/fine'", ",", "nclasses", "=", "5", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'TREC'", ":", "\n", "            ", "self", ".", "evaluation", "=", "TRECEval", "(", "tpath", "+", "'/downstream/TREC'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'MRPC'", ":", "\n", "            ", "self", ".", "evaluation", "=", "MRPCEval", "(", "tpath", "+", "'/downstream/MRPC'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SICKRelatedness'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SICKRelatednessEval", "(", "tpath", "+", "'/downstream/SICK'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'STSBenchmark'", ":", "\n", "            ", "self", ".", "evaluation", "=", "STSBenchmarkEval", "(", "tpath", "+", "'/downstream/STS/STSBenchmark'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'STSFilterBenchmark'", ":", "\n", "            ", "self", ".", "evaluation", "=", "STSFilterBenchmarkEval", "(", "tpath", "+", "'/downstream/STS/STSBenchmark'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'STSBenchmark-fix'", ":", "\n", "            ", "self", ".", "evaluation", "=", "STSBenchmarkEval", "(", "tpath", "+", "'/downstream/STS/STSBenchmark-fix'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'STSBenchmark-finetune'", ":", "\n", "            ", "self", ".", "evaluation", "=", "STSBenchmarkFinetune", "(", "tpath", "+", "'/downstream/STS/STSBenchmark'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SICKRelatedness-finetune'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SICKEval", "(", "tpath", "+", "'/downstream/SICK'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SICKEntailment'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SICKEntailmentEval", "(", "tpath", "+", "'/downstream/SICK'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SNLI'", ":", "\n", "            ", "self", ".", "evaluation", "=", "SNLIEval", "(", "tpath", "+", "'/downstream/SNLI'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "in", "[", "'STS12'", ",", "'STS13'", ",", "'STS14'", ",", "'STS15'", ",", "'STS16'", "]", ":", "\n", "            ", "fpath", "=", "name", "+", "'-en-test'", "\n", "self", ".", "evaluation", "=", "eval", "(", "name", "+", "'Eval'", ")", "(", "tpath", "+", "'/downstream/STS/'", "+", "fpath", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'ImageCaptionRetrieval'", ":", "\n", "            ", "self", ".", "evaluation", "=", "ImageCaptionRetrievalEval", "(", "tpath", "+", "'/downstream/COCO'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "\n", "# Probing Tasks", "\n", "", "elif", "name", "==", "'Length'", ":", "\n", "                ", "self", ".", "evaluation", "=", "LengthEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'WordContent'", ":", "\n", "                ", "self", ".", "evaluation", "=", "WordContentEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'Depth'", ":", "\n", "                ", "self", ".", "evaluation", "=", "DepthEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'TopConstituents'", ":", "\n", "                ", "self", ".", "evaluation", "=", "TopConstituentsEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'BigramShift'", ":", "\n", "                ", "self", ".", "evaluation", "=", "BigramShiftEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'Tense'", ":", "\n", "                ", "self", ".", "evaluation", "=", "TenseEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'SubjNumber'", ":", "\n", "                ", "self", ".", "evaluation", "=", "SubjNumberEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'ObjNumber'", ":", "\n", "                ", "self", ".", "evaluation", "=", "ObjNumberEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'OddManOut'", ":", "\n", "                ", "self", ".", "evaluation", "=", "OddManOutEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "", "elif", "name", "==", "'CoordinationInversion'", ":", "\n", "                ", "self", ".", "evaluation", "=", "CoordinationInversionEval", "(", "tpath", "+", "'/probing'", ",", "seed", "=", "self", ".", "params", ".", "seed", ")", "\n", "\n", "", "self", ".", "params", ".", "current_task", "=", "name", "\n", "self", ".", "evaluation", ".", "do_prepare", "(", "self", ".", "params", ",", "self", ".", "prepare", ")", "\n", "\n", "self", ".", "results", "=", "self", ".", "evaluation", ".", "run", "(", "self", ".", "params", ",", "self", ".", "batcher", ")", "\n", "\n", "return", "self", ".", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.trec.TRECEval.__init__": [[28, 33], ["logging.info", "trec.TRECEval.loadFile", "trec.TRECEval.loadFile", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'***** Transfer task : TREC *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'train_5500.label'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'TREC_10.label'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.trec.TRECEval.do_prepare": [[34, 37], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "samples", "=", "self", ".", "train", "[", "'X'", "]", "+", "self", ".", "test", "[", "'X'", "]", "\n", "return", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.trec.TRECEval.loadFile": [[38, 50], ["io.open", "line.strip().split", "[].split", "trec_data[].append", "trec_data[].append", "line.strip", "[].split.split"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "trec_data", "=", "{", "'X'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "tgt2idx", "=", "{", "'ABBR'", ":", "0", ",", "'DESC'", ":", "1", ",", "'ENTY'", ":", "2", ",", "\n", "'HUM'", ":", "3", ",", "'LOC'", ":", "4", ",", "'NUM'", ":", "5", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'latin-1'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "target", ",", "sample", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "':'", ",", "1", ")", "\n", "sample", "=", "sample", ".", "split", "(", "' '", ",", "1", ")", "[", "1", "]", ".", "split", "(", ")", "\n", "assert", "target", "in", "tgt2idx", ",", "target", "\n", "trec_data", "[", "'X'", "]", ".", "append", "(", "sample", ")", "\n", "trec_data", "[", "'y'", "]", ".", "append", "(", "tgt2idx", "[", "target", "]", ")", "\n", "", "", "return", "trec_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.trec.TRECEval.run": [[51, 95], ["sorted", "sorted", "range", "numpy.vstack", "logging.info", "range", "numpy.vstack", "logging.info", "senteval.tools.validation.KFoldClassifier", "senteval.tools.validation.KFoldClassifier.run", "logging.debug", "zip", "zip", "len", "batcher", "numpy.vstack.append", "len", "batcher", "numpy.vstack.append", "len", "len", "numpy.array", "numpy.array", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "train_embeddings", ",", "test_embeddings", "=", "[", "]", ",", "[", "]", "\n", "\n", "# Sort to reduce padding", "\n", "sorted_corpus_train", "=", "sorted", "(", "zip", "(", "self", ".", "train", "[", "'X'", "]", ",", "self", ".", "train", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "z", "[", "1", "]", ")", ")", "\n", "train_samples", "=", "[", "x", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus_train", "]", "\n", "train_labels", "=", "[", "y", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus_train", "]", "\n", "\n", "sorted_corpus_test", "=", "sorted", "(", "zip", "(", "self", ".", "test", "[", "'X'", "]", ",", "self", ".", "test", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "z", "[", "1", "]", ")", ")", "\n", "test_samples", "=", "[", "x", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus_test", "]", "\n", "test_labels", "=", "[", "y", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus_test", "]", "\n", "\n", "# Get train embeddings", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "train_labels", ")", ",", "params", ".", "batch_size", ")", ":", "\n", "            ", "batch", "=", "train_samples", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "train_embeddings", ".", "append", "(", "embeddings", ")", "\n", "", "train_embeddings", "=", "np", ".", "vstack", "(", "train_embeddings", ")", "\n", "logging", ".", "info", "(", "'Computed train embeddings'", ")", "\n", "\n", "# Get test embeddings", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "test_labels", ")", ",", "params", ".", "batch_size", ")", ":", "\n", "            ", "batch", "=", "test_samples", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "test_embeddings", ".", "append", "(", "embeddings", ")", "\n", "", "test_embeddings", "=", "np", ".", "vstack", "(", "test_embeddings", ")", "\n", "logging", ".", "info", "(", "'Computed test embeddings'", ")", "\n", "\n", "config_classifier", "=", "{", "'nclasses'", ":", "6", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", ",", "\n", "'kfold'", ":", "params", ".", "kfold", "}", "\n", "clf", "=", "KFoldClassifier", "(", "{", "'X'", ":", "train_embeddings", ",", "\n", "'y'", ":", "np", ".", "array", "(", "train_labels", ")", "}", ",", "\n", "{", "'X'", ":", "test_embeddings", ",", "\n", "'y'", ":", "np", ".", "array", "(", "test_labels", ")", "}", ",", "\n", "config_classifier", ")", "\n", "devacc", ",", "testacc", ",", "_", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'\\nDev acc : {0} Test acc : {1} \\\n            for TREC\\n'", ".", "format", "(", "devacc", ",", "testacc", ")", ")", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "\n", "'ndev'", ":", "len", "(", "self", ".", "train", "[", "'X'", "]", ")", ",", "'ntest'", ":", "len", "(", "self", ".", "test", "[", "'X'", "]", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sst.SSTEval.__init__": [[28, 41], ["logging.debug", "sst.SSTEval.loadFile", "sst.SSTEval.loadFile", "sst.SSTEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "nclasses", "=", "2", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "self", ".", "seed", "=", "seed", "\n", "\n", "# binary of fine-grained", "\n", "assert", "nclasses", "in", "[", "2", ",", "5", "]", "\n", "self", ".", "nclasses", "=", "nclasses", "\n", "self", ".", "task_name", "=", "'Binary'", "if", "self", ".", "nclasses", "==", "2", "else", "'Fine-Grained'", "\n", "logging", ".", "debug", "(", "'***** Transfer task : SST %s classification *****\\n\\n'", ",", "self", ".", "task_name", ")", "\n", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sentiment-train'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sentiment-dev'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sentiment-test'", ")", ")", "\n", "self", ".", "sst_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sst.SSTEval.do_prepare": [[42, 46], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "samples", "=", "self", ".", "sst_data", "[", "'train'", "]", "[", "'X'", "]", "+", "self", ".", "sst_data", "[", "'dev'", "]", "[", "'X'", "]", "+", "self", ".", "sst_data", "[", "'test'", "]", "[", "'X'", "]", "\n", "return", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sst.SSTEval.loadFile": [[47, 61], ["io.open", "max", "line.strip().split", "sst_data[].append", "sst_data[].append", "int", "sample[].split", "line.strip().split", "sst_data[].append", "sst_data[].append", "line.strip", "int", "sample[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "sst_data", "=", "{", "'X'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "self", ".", "nclasses", "==", "2", ":", "\n", "                    ", "sample", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sst_data", "[", "'y'", "]", ".", "append", "(", "int", "(", "sample", "[", "1", "]", ")", ")", "\n", "sst_data", "[", "'X'", "]", ".", "append", "(", "sample", "[", "0", "]", ".", "split", "(", ")", ")", "\n", "", "elif", "self", ".", "nclasses", "==", "5", ":", "\n", "                    ", "sample", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ",", "1", ")", "\n", "sst_data", "[", "'y'", "]", ".", "append", "(", "int", "(", "sample", "[", "0", "]", ")", ")", "\n", "sst_data", "[", "'X'", "]", ".", "append", "(", "sample", "[", "1", "]", ".", "split", "(", ")", ")", "\n", "", "", "", "assert", "max", "(", "sst_data", "[", "'y'", "]", ")", "==", "self", ".", "nclasses", "-", "1", "\n", "return", "sst_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sst.SSTEval.run": [[62, 102], ["senteval.tools.validation.SplitClassifier", "senteval.tools.validation.SplitClassifier.run", "logging.debug", "logging.info", "sorted", "map", "range", "numpy.vstack", "numpy.array", "logging.info", "len", "len", "zip", "zip", "len", "batcher", "[].append", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "sst_embed", "=", "{", "'train'", ":", "{", "}", ",", "'dev'", ":", "{", "}", ",", "'test'", ":", "{", "}", "}", "\n", "bsize", "=", "params", ".", "batch_size", "\n", "\n", "for", "key", "in", "self", ".", "sst_data", ":", "\n", "            ", "logging", ".", "info", "(", "'Computing embedding for {0}'", ".", "format", "(", "key", ")", ")", "\n", "# Sort to reduce padding", "\n", "sorted_data", "=", "sorted", "(", "zip", "(", "self", ".", "sst_data", "[", "key", "]", "[", "'X'", "]", ",", "\n", "self", ".", "sst_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "z", "[", "1", "]", ")", ")", "\n", "self", ".", "sst_data", "[", "key", "]", "[", "'X'", "]", ",", "self", ".", "sst_data", "[", "key", "]", "[", "'y'", "]", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_data", ")", ")", "\n", "\n", "sst_embed", "[", "key", "]", "[", "'X'", "]", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "self", ".", "sst_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "bsize", ")", ":", "\n", "                ", "batch", "=", "self", ".", "sst_data", "[", "key", "]", "[", "'X'", "]", "[", "ii", ":", "ii", "+", "bsize", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "sst_embed", "[", "key", "]", "[", "'X'", "]", ".", "append", "(", "embeddings", ")", "\n", "", "sst_embed", "[", "key", "]", "[", "'X'", "]", "=", "np", ".", "vstack", "(", "sst_embed", "[", "key", "]", "[", "'X'", "]", ")", "\n", "sst_embed", "[", "key", "]", "[", "'y'", "]", "=", "np", ".", "array", "(", "self", ".", "sst_data", "[", "key", "]", "[", "'y'", "]", ")", "\n", "logging", ".", "info", "(", "'Computed {0} embeddings'", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "config_classifier", "=", "{", "'nclasses'", ":", "self", ".", "nclasses", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", "}", "\n", "\n", "clf", "=", "SplitClassifier", "(", "X", "=", "{", "'train'", ":", "sst_embed", "[", "'train'", "]", "[", "'X'", "]", ",", "\n", "'valid'", ":", "sst_embed", "[", "'dev'", "]", "[", "'X'", "]", ",", "\n", "'test'", ":", "sst_embed", "[", "'test'", "]", "[", "'X'", "]", "}", ",", "\n", "y", "=", "{", "'train'", ":", "sst_embed", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "'valid'", ":", "sst_embed", "[", "'dev'", "]", "[", "'y'", "]", ",", "\n", "'test'", ":", "sst_embed", "[", "'test'", "]", "[", "'y'", "]", "}", ",", "\n", "config", "=", "config_classifier", ")", "\n", "\n", "devacc", ",", "testacc", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'\\nDev acc : {0} Test acc : {1} for \\\n            SST {2} classification\\n'", ".", "format", "(", "devacc", ",", "testacc", ",", "self", ".", "task_name", ")", ")", "\n", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "\n", "'ndev'", ":", "len", "(", "sst_embed", "[", "'dev'", "]", "[", "'X'", "]", ")", ",", "\n", "'ntest'", ":", "len", "(", "sst_embed", "[", "'test'", "]", "[", "'X'", "]", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.rank.ImageCaptionRetrievalEval.__init__": [[32, 39], ["logging.debug", "rank.ImageCaptionRetrievalEval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task: Image Caption Retrieval *****\\n\\n'", ")", "\n", "\n", "# Get captions and image features", "\n", "self", ".", "seed", "=", "seed", "\n", "train", ",", "dev", ",", "test", "=", "self", ".", "loadFile", "(", "task_path", ")", "\n", "self", ".", "coco_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.rank.ImageCaptionRetrievalEval.do_prepare": [[40, 45], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "samples", "=", "self", ".", "coco_data", "[", "'train'", "]", "[", "'sent'", "]", "+", "self", ".", "coco_data", "[", "'dev'", "]", "[", "'sent'", "]", "+", "self", ".", "coco_data", "[", "'test'", "]", "[", "'sent'", "]", "\n", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.rank.ImageCaptionRetrievalEval.loadFile": [[46, 72], ["range", "numpy.array().astype", "len", "open", "pickle.load", "open", "pickle.load", "len", "list_sent.append", "numpy.array().astype.append", "len", "len", "numpy.array", "os.path.join", "os.path.join", "sent.encode().split", "len", "sent.encode"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "coco", "=", "{", "}", "\n", "\n", "for", "split", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "list_sent", "=", "[", "]", "\n", "list_img_feat", "=", "[", "]", "\n", "if", "sys", ".", "version_info", "<", "(", "3", ",", "0", ")", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "fpath", ",", "split", "+", "'.pkl'", ")", ")", "as", "f", ":", "\n", "                    ", "cocodata", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "fpath", ",", "split", "+", "'.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "cocodata", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", "\n", "\n", "", "", "for", "imgkey", "in", "range", "(", "len", "(", "cocodata", "[", "'features'", "]", ")", ")", ":", "\n", "                ", "assert", "len", "(", "cocodata", "[", "'image_to_caption_ids'", "]", "[", "imgkey", "]", ")", ">=", "5", ",", "cocodata", "[", "'image_to_caption_ids'", "]", "[", "imgkey", "]", "\n", "for", "captkey", "in", "cocodata", "[", "'image_to_caption_ids'", "]", "[", "imgkey", "]", "[", "0", ":", "5", "]", ":", "\n", "                    ", "sent", "=", "cocodata", "[", "'captions'", "]", "[", "captkey", "]", "[", "'cleaned_caption'", "]", "\n", "sent", "+=", "' .'", "# add punctuation to end of sentence in COCO", "\n", "list_sent", ".", "append", "(", "sent", ".", "encode", "(", "'utf-8'", ")", ".", "split", "(", ")", ")", "\n", "list_img_feat", ".", "append", "(", "cocodata", "[", "'features'", "]", "[", "imgkey", "]", ")", "\n", "", "", "assert", "len", "(", "list_sent", ")", "==", "len", "(", "list_img_feat", ")", "and", "len", "(", "list_sent", ")", "%", "5", "==", "0", "\n", "list_img_feat", "=", "np", ".", "array", "(", "list_img_feat", ")", ".", "astype", "(", "'float32'", ")", "\n", "coco", "[", "split", "]", "=", "{", "'sent'", ":", "list_sent", ",", "'imgfeat'", ":", "list_img_feat", "}", "\n", "", "return", "coco", "[", "'train'", "]", ",", "coco", "[", "'valid'", "]", ",", "coco", "[", "'test'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.rank.ImageCaptionRetrievalEval.run": [[73, 114], ["senteval.tools.ranking.ImageSentenceRankingPytorch", "senteval.tools.ranking.ImageSentenceRankingPytorch.run", "logging.debug", "logging.debug", "logging.info", "numpy.array", "numpy.argsort", "len", "range", "numpy.array", "logging.info", "len", "len", "numpy.sort", "numpy.argsort", "batcher", "[].append", "numpy.vstack"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "coco_embed", "=", "{", "'train'", ":", "{", "'sentfeat'", ":", "[", "]", ",", "'imgfeat'", ":", "[", "]", "}", ",", "\n", "'dev'", ":", "{", "'sentfeat'", ":", "[", "]", ",", "'imgfeat'", ":", "[", "]", "}", ",", "\n", "'test'", ":", "{", "'sentfeat'", ":", "[", "]", ",", "'imgfeat'", ":", "[", "]", "}", "}", "\n", "\n", "for", "key", "in", "self", ".", "coco_data", ":", "\n", "            ", "logging", ".", "info", "(", "'Computing embedding for {0}'", ".", "format", "(", "key", ")", ")", "\n", "# Sort to reduce padding", "\n", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", "=", "np", ".", "array", "(", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", ")", "\n", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", ",", "idx_sort", "=", "np", ".", "sort", "(", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", ")", ",", "np", ".", "argsort", "(", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", ")", "\n", "idx_unsort", "=", "np", ".", "argsort", "(", "idx_sort", ")", "\n", "\n", "coco_embed", "[", "key", "]", "[", "'X'", "]", "=", "[", "]", "\n", "nsent", "=", "len", "(", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", ")", "\n", "for", "ii", "in", "range", "(", "0", ",", "nsent", ",", "params", ".", "batch_size", ")", ":", "\n", "                ", "batch", "=", "self", ".", "coco_data", "[", "key", "]", "[", "'sent'", "]", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "coco_embed", "[", "key", "]", "[", "'sentfeat'", "]", ".", "append", "(", "embeddings", ")", "\n", "", "coco_embed", "[", "key", "]", "[", "'sentfeat'", "]", "=", "np", ".", "vstack", "(", "coco_embed", "[", "key", "]", "[", "'sentfeat'", "]", ")", "[", "idx_unsort", "]", "\n", "coco_embed", "[", "key", "]", "[", "'imgfeat'", "]", "=", "np", ".", "array", "(", "self", ".", "coco_data", "[", "key", "]", "[", "'imgfeat'", "]", ")", "\n", "logging", ".", "info", "(", "'Computed {0} embeddings'", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "config", "=", "{", "'seed'", ":", "self", ".", "seed", ",", "'projdim'", ":", "1000", ",", "'margin'", ":", "0.2", "}", "\n", "clf", "=", "ImageSentenceRankingPytorch", "(", "train", "=", "coco_embed", "[", "'train'", "]", ",", "\n", "valid", "=", "coco_embed", "[", "'dev'", "]", ",", "\n", "test", "=", "coco_embed", "[", "'test'", "]", ",", "\n", "config", "=", "config", ")", "\n", "\n", "bestdevscore", ",", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", ",", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", "=", "clf", ".", "run", "(", ")", "\n", "\n", "logging", ".", "debug", "(", "\"\\nTest scores | Image to text: \\\n            {0}, {1}, {2}, {3}\"", ".", "format", "(", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", ")", ")", "\n", "logging", ".", "debug", "(", "\"Test scores | Text to image: \\\n            {0}, {1}, {2}, {3}\\n\"", ".", "format", "(", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", ")", ")", "\n", "\n", "return", "{", "'devacc'", ":", "bestdevscore", ",", "\n", "'acc'", ":", "[", "(", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", ")", ",", "\n", "(", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", ")", "]", ",", "\n", "'ndev'", ":", "len", "(", "coco_embed", "[", "'dev'", "]", "[", "'sentfeat'", "]", ")", ",", "\n", "'ntest'", ":", "len", "(", "coco_embed", "[", "'test'", "]", "[", "'sentfeat'", "]", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.snli.SNLIEval.__init__": [[29, 65], ["logging.debug", "snli.SNLIEval.loadFile", "snli.SNLIEval.loadFile", "io.open().read().splitlines", "snli.SNLIEval.loadFile", "snli.SNLIEval.loadFile", "io.open().read().splitlines", "snli.SNLIEval.loadFile", "snli.SNLIEval.loadFile", "io.open().read().splitlines", "sorted", "map", "sorted", "map", "sorted", "map", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "zip", "zip", "zip", "zip", "zip", "zip", "io.open().read", "io.open().read", "io.open().read", "io.open", "io.open", "io.open", "len", "len", "len", "len", "len", "len", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : SNLI Entailment*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train1", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s1.train'", ")", ")", "\n", "train2", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s2.train'", ")", ")", "\n", "\n", "trainlabels", "=", "io", ".", "open", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'labels.train'", ")", ",", "\n", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "valid1", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s1.dev'", ")", ")", "\n", "valid2", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s2.dev'", ")", ")", "\n", "validlabels", "=", "io", ".", "open", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'labels.dev'", ")", ",", "\n", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "test1", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s1.test'", ")", ")", "\n", "test2", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'s2.test'", ")", ")", "\n", "testlabels", "=", "io", ".", "open", "(", "os", ".", "path", ".", "join", "(", "taskpath", ",", "'labels.test'", ")", ",", "\n", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "# sort data (by s2 first) to reduce padding", "\n", "sorted_train", "=", "sorted", "(", "zip", "(", "train2", ",", "train1", ",", "trainlabels", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "train2", ",", "train1", ",", "trainlabels", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_train", ")", ")", "\n", "\n", "sorted_valid", "=", "sorted", "(", "zip", "(", "valid2", ",", "valid1", ",", "validlabels", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "valid2", ",", "valid1", ",", "validlabels", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_valid", ")", ")", "\n", "\n", "sorted_test", "=", "sorted", "(", "zip", "(", "test2", ",", "test1", ",", "testlabels", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "test2", ",", "test1", ",", "testlabels", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_test", ")", ")", "\n", "\n", "self", ".", "samples", "=", "train1", "+", "train2", "+", "valid1", "+", "valid2", "+", "test1", "+", "test2", "\n", "self", ".", "data", "=", "{", "'train'", ":", "(", "train1", ",", "train2", ",", "trainlabels", ")", ",", "\n", "'valid'", ":", "(", "valid1", ",", "valid2", ",", "validlabels", ")", ",", "\n", "'test'", ":", "(", "test1", ",", "test2", ",", "testlabels", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.snli.SNLIEval.do_prepare": [[67, 69], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "return", "prepare", "(", "params", ",", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.snli.SNLIEval.loadFile": [[70, 74], ["codecs.open", "line.split", "f.read().splitlines", "f.read"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "fpath", ",", "'rb'", ",", "'latin-1'", ")", "as", "f", ":", "\n", "            ", "return", "[", "line", ".", "split", "(", ")", "for", "line", "in", "\n", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.snli.SNLIEval.run": [[75, 119], ["copy.deepcopy", "senteval.tools.validation.SplitClassifier", "senteval.tools.validation.SplitClassifier.run", "logging.debug", "len", "range", "numpy.vstack", "len", "len", "batcher", "batcher", "enc_input.append", "logging.info", "len", "len", "len", "numpy.hstack", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "self", ".", "X", ",", "self", ".", "y", "=", "{", "}", ",", "{", "}", "\n", "dico_label", "=", "{", "'entailment'", ":", "0", ",", "'neutral'", ":", "1", ",", "'contradiction'", ":", "2", "}", "\n", "for", "key", "in", "self", ".", "data", ":", "\n", "            ", "if", "key", "not", "in", "self", ".", "X", ":", "\n", "                ", "self", ".", "X", "[", "key", "]", "=", "[", "]", "\n", "", "if", "key", "not", "in", "self", ".", "y", ":", "\n", "                ", "self", ".", "y", "[", "key", "]", "=", "[", "]", "\n", "\n", "", "input1", ",", "input2", ",", "mylabels", "=", "self", ".", "data", "[", "key", "]", "\n", "enc_input", "=", "[", "]", "\n", "n_labels", "=", "len", "(", "mylabels", ")", "\n", "for", "ii", "in", "range", "(", "0", ",", "n_labels", ",", "params", ".", "batch_size", ")", ":", "\n", "                ", "batch1", "=", "input1", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "batch2", "=", "input2", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "\n", "if", "len", "(", "batch1", ")", "==", "len", "(", "batch2", ")", "and", "len", "(", "batch1", ")", ">", "0", ":", "\n", "                    ", "enc1", "=", "batcher", "(", "params", ",", "batch1", ")", "\n", "enc2", "=", "batcher", "(", "params", ",", "batch2", ")", "\n", "enc_input", ".", "append", "(", "np", ".", "hstack", "(", "(", "enc1", ",", "enc2", ",", "enc1", "*", "enc2", ",", "\n", "np", ".", "abs", "(", "enc1", "-", "enc2", ")", ")", ")", ")", "\n", "", "if", "(", "ii", "*", "params", ".", "batch_size", ")", "%", "(", "20000", "*", "params", ".", "batch_size", ")", "==", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "\"PROGRESS (encoding): %.2f%%\"", "%", "\n", "(", "100", "*", "ii", "/", "n_labels", ")", ")", "\n", "", "", "self", ".", "X", "[", "key", "]", "=", "np", ".", "vstack", "(", "enc_input", ")", "\n", "self", ".", "y", "[", "key", "]", "=", "[", "dico_label", "[", "y", "]", "for", "y", "in", "mylabels", "]", "\n", "\n", "", "config", "=", "{", "'nclasses'", ":", "3", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'cudaEfficient'", ":", "True", ",", "\n", "'nhid'", ":", "params", ".", "nhid", ",", "'noreg'", ":", "True", "}", "\n", "\n", "config_classifier", "=", "copy", ".", "deepcopy", "(", "params", ".", "classifier", ")", "\n", "config_classifier", "[", "'max_epoch'", "]", "=", "15", "\n", "config_classifier", "[", "'epoch_size'", "]", "=", "1", "\n", "config", "[", "'classifier'", "]", "=", "config_classifier", "\n", "\n", "clf", "=", "SplitClassifier", "(", "self", ".", "X", ",", "self", ".", "y", ",", "config", ")", "\n", "devacc", ",", "testacc", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'Dev acc : {0} Test acc : {1} for SNLI\\n'", "\n", ".", "format", "(", "devacc", ",", "testacc", ")", ")", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "\n", "'ndev'", ":", "len", "(", "self", ".", "data", "[", "'valid'", "]", "[", "0", "]", ")", ",", "\n", "'ntest'", ":", "len", "(", "self", ".", "data", "[", "'test'", "]", "[", "0", "]", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.mrpc.MRPCEval.__init__": [[29, 37], ["logging.info", "mrpc.MRPCEval.loadFile", "mrpc.MRPCEval.loadFile", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'***** Transfer task : MRPC *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "\n", "'msr_paraphrase_train.txt'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "\n", "'msr_paraphrase_test.txt'", ")", ")", "\n", "self", ".", "mrpc_data", "=", "{", "'train'", ":", "train", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.mrpc.MRPCEval.do_prepare": [[38, 44], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "# TODO : Should we separate samples in \"train, test\"?", "\n", "        ", "samples", "=", "self", ".", "mrpc_data", "[", "'train'", "]", "[", "'X_A'", "]", "+", "self", ".", "mrpc_data", "[", "'train'", "]", "[", "'X_B'", "]", "+", "self", ".", "mrpc_data", "[", "'test'", "]", "[", "'X_A'", "]", "+", "self", ".", "mrpc_data", "[", "'test'", "]", "[", "'X_B'", "]", "\n", "return", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.mrpc.MRPCEval.loadFile": [[45, 58], ["io.open", "int", "line.strip().split", "mrpc_data[].append", "mrpc_data[].append", "mrpc_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "mrpc_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "mrpc_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "3", "]", ".", "split", "(", ")", ")", "\n", "mrpc_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "4", "]", ".", "split", "(", ")", ")", "\n", "mrpc_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "0", "]", ")", "\n", "\n", "", "", "mrpc_data", "[", "'X_A'", "]", "=", "mrpc_data", "[", "'X_A'", "]", "[", "1", ":", "]", "\n", "mrpc_data", "[", "'X_B'", "]", "=", "mrpc_data", "[", "'X_B'", "]", "[", "1", ":", "]", "\n", "mrpc_data", "[", "'y'", "]", "=", "[", "int", "(", "s", ")", "for", "s", "in", "mrpc_data", "[", "'y'", "]", "[", "1", ":", "]", "]", "\n", "return", "mrpc_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.mrpc.MRPCEval.run": [[59, 110], ["senteval.tools.validation.KFoldClassifier", "senteval.tools.validation.KFoldClassifier.run", "round", "logging.debug", "logging.info", "sorted", "numpy.array", "logging.info", "len", "len", "zip", "range", "numpy.vstack", "sklearn.metrics.f1_score", "len", "batcher", "[].append", "numpy.abs", "numpy.abs", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "mrpc_embed", "=", "{", "'train'", ":", "{", "}", ",", "'test'", ":", "{", "}", "}", "\n", "\n", "for", "key", "in", "self", ".", "mrpc_data", ":", "\n", "            ", "logging", ".", "info", "(", "'Computing embedding for {0}'", ".", "format", "(", "key", ")", ")", "\n", "# Sort to reduce padding", "\n", "text_data", "=", "{", "}", "\n", "sorted_corpus", "=", "sorted", "(", "zip", "(", "self", ".", "mrpc_data", "[", "key", "]", "[", "'X_A'", "]", ",", "\n", "self", ".", "mrpc_data", "[", "key", "]", "[", "'X_B'", "]", ",", "\n", "self", ".", "mrpc_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "\n", "text_data", "[", "'A'", "]", "=", "[", "x", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "text_data", "[", "'B'", "]", "=", "[", "y", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "text_data", "[", "'y'", "]", "=", "[", "z", "for", "(", "x", ",", "y", ",", "z", ")", "in", "sorted_corpus", "]", "\n", "\n", "for", "txt_type", "in", "[", "'A'", ",", "'B'", "]", ":", "\n", "                ", "mrpc_embed", "[", "key", "]", "[", "txt_type", "]", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "text_data", "[", "'y'", "]", ")", ",", "params", ".", "batch_size", ")", ":", "\n", "                    ", "batch", "=", "text_data", "[", "txt_type", "]", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "mrpc_embed", "[", "key", "]", "[", "txt_type", "]", ".", "append", "(", "embeddings", ")", "\n", "", "mrpc_embed", "[", "key", "]", "[", "txt_type", "]", "=", "np", ".", "vstack", "(", "mrpc_embed", "[", "key", "]", "[", "txt_type", "]", ")", "\n", "", "mrpc_embed", "[", "key", "]", "[", "'y'", "]", "=", "np", ".", "array", "(", "text_data", "[", "'y'", "]", ")", "\n", "logging", ".", "info", "(", "'Computed {0} embeddings'", ".", "format", "(", "key", ")", ")", "\n", "\n", "# Train", "\n", "", "trainA", "=", "mrpc_embed", "[", "'train'", "]", "[", "'A'", "]", "\n", "trainB", "=", "mrpc_embed", "[", "'train'", "]", "[", "'B'", "]", "\n", "trainF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "trainA", "-", "trainB", ")", ",", "trainA", "*", "trainB", "]", "\n", "trainY", "=", "mrpc_embed", "[", "'train'", "]", "[", "'y'", "]", "\n", "\n", "# Test", "\n", "testA", "=", "mrpc_embed", "[", "'test'", "]", "[", "'A'", "]", "\n", "testB", "=", "mrpc_embed", "[", "'test'", "]", "[", "'B'", "]", "\n", "testF", "=", "np", ".", "c_", "[", "np", ".", "abs", "(", "testA", "-", "testB", ")", ",", "testA", "*", "testB", "]", "\n", "testY", "=", "mrpc_embed", "[", "'test'", "]", "[", "'y'", "]", "\n", "\n", "config", "=", "{", "'nclasses'", ":", "2", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", ",", "\n", "'nhid'", ":", "params", ".", "nhid", ",", "'kfold'", ":", "params", ".", "kfold", "}", "\n", "clf", "=", "KFoldClassifier", "(", "train", "=", "{", "'X'", ":", "trainF", ",", "'y'", ":", "trainY", "}", ",", "\n", "test", "=", "{", "'X'", ":", "testF", ",", "'y'", ":", "testY", "}", ",", "config", "=", "config", ")", "\n", "\n", "devacc", ",", "testacc", ",", "yhat", "=", "clf", ".", "run", "(", ")", "\n", "testf1", "=", "round", "(", "100", "*", "f1_score", "(", "testY", ",", "yhat", ")", ",", "2", ")", "\n", "logging", ".", "debug", "(", "'Dev acc : {0} Test acc {1}; Test F1 {2} for MRPC.\\n'", "\n", ".", "format", "(", "devacc", ",", "testacc", ",", "testf1", ")", ")", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "'f1'", ":", "testf1", ",", "\n", "'ndev'", ":", "len", "(", "trainA", ")", ",", "'ntest'", ":", "len", "(", "testA", ")", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.PROBINGEval.__init__": [[29, 40], ["logging.debug", "probing.PROBINGEval.loadFile", "logging.info", "probing.PROBINGEval.task.upper", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "self", ".", "seed", "=", "seed", "\n", "self", ".", "task", "=", "task", "\n", "logging", ".", "debug", "(", "'***** (Probing) Transfer task : %s classification *****'", ",", "self", ".", "task", ".", "upper", "(", ")", ")", "\n", "self", ".", "task_data", "=", "{", "'train'", ":", "{", "'X'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", ",", "\n", "'dev'", ":", "{", "'X'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", ",", "\n", "'test'", ":", "{", "'X'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "}", "\n", "self", ".", "loadFile", "(", "task_path", ")", "\n", "logging", ".", "info", "(", "'Loaded %s train - %s dev - %s test for %s'", "%", "\n", "(", "len", "(", "self", ".", "task_data", "[", "'train'", "]", "[", "'y'", "]", ")", ",", "len", "(", "self", ".", "task_data", "[", "'dev'", "]", "[", "'y'", "]", ")", ",", "\n", "len", "(", "self", ".", "task_data", "[", "'test'", "]", "[", "'y'", "]", ")", ",", "self", ".", "task", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.PROBINGEval.do_prepare": [[41, 45], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "samples", "=", "self", ".", "task_data", "[", "'train'", "]", "[", "'X'", "]", "+", "self", ".", "task_data", "[", "'dev'", "]", "[", "'X'", "]", "+", "self", ".", "task_data", "[", "'test'", "]", "[", "'X'", "]", "\n", "return", "prepare", "(", "params", ",", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.PROBINGEval.loadFile": [[46, 61], ["sorted", "dict", "len", "io.open", "numpy.unique", "zip", "enumerate", "line.rstrip().split.rstrip().split.rstrip().split", "[].append", "[].append", "range", "line[].split", "len", "line.rstrip().split.rstrip().split.rstrip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "self", ".", "tok2split", "=", "{", "'tr'", ":", "'train'", ",", "'va'", ":", "'dev'", ",", "'te'", ":", "'test'", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "self", ".", "task_data", "[", "self", ".", "tok2split", "[", "line", "[", "0", "]", "]", "]", "[", "'X'", "]", ".", "append", "(", "line", "[", "-", "1", "]", ".", "split", "(", ")", ")", "\n", "self", ".", "task_data", "[", "self", ".", "tok2split", "[", "line", "[", "0", "]", "]", "]", "[", "'y'", "]", ".", "append", "(", "line", "[", "1", "]", ")", "\n", "\n", "", "", "labels", "=", "sorted", "(", "np", ".", "unique", "(", "self", ".", "task_data", "[", "'train'", "]", "[", "'y'", "]", ")", ")", "\n", "self", ".", "tok2label", "=", "dict", "(", "zip", "(", "labels", ",", "range", "(", "len", "(", "labels", ")", ")", ")", ")", "\n", "self", ".", "nclasses", "=", "len", "(", "self", ".", "tok2label", ")", "\n", "\n", "for", "split", "in", "self", ".", "task_data", ":", "\n", "            ", "for", "i", ",", "y", "in", "enumerate", "(", "self", ".", "task_data", "[", "split", "]", "[", "'y'", "]", ")", ":", "\n", "                ", "self", ".", "task_data", "[", "split", "]", "[", "'y'", "]", "[", "i", "]", "=", "self", ".", "tok2label", "[", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.PROBINGEval.run": [[62, 105], ["logging.info", "logging.info", "senteval.tools.validation.SplitClassifier", "senteval.tools.validation.SplitClassifier.run", "logging.debug", "sorted", "map", "range", "numpy.vstack", "numpy.array", "copy.deepcopy", "print", "len", "len", "zip", "zip", "len", "batcher", "[].append", "probing.PROBINGEval.task.upper", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "", "", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "task_embed", "=", "{", "'train'", ":", "{", "}", ",", "'dev'", ":", "{", "}", ",", "'test'", ":", "{", "}", "}", "\n", "bsize", "=", "params", ".", "batch_size", "\n", "logging", ".", "info", "(", "'Computing embeddings for train/dev/test'", ")", "\n", "for", "key", "in", "self", ".", "task_data", ":", "\n", "# Sort to reduce padding", "\n", "            ", "sorted_data", "=", "sorted", "(", "zip", "(", "self", ".", "task_data", "[", "key", "]", "[", "'X'", "]", ",", "\n", "self", ".", "task_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "z", "[", "1", "]", ")", ")", "\n", "self", ".", "task_data", "[", "key", "]", "[", "'X'", "]", ",", "self", ".", "task_data", "[", "key", "]", "[", "'y'", "]", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_data", ")", ")", "\n", "\n", "task_embed", "[", "key", "]", "[", "'X'", "]", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "self", ".", "task_data", "[", "key", "]", "[", "'y'", "]", ")", ",", "bsize", ")", ":", "\n", "                ", "batch", "=", "self", ".", "task_data", "[", "key", "]", "[", "'X'", "]", "[", "ii", ":", "ii", "+", "bsize", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "task_embed", "[", "key", "]", "[", "'X'", "]", ".", "append", "(", "embeddings", ")", "\n", "", "task_embed", "[", "key", "]", "[", "'X'", "]", "=", "np", ".", "vstack", "(", "task_embed", "[", "key", "]", "[", "'X'", "]", ")", "\n", "task_embed", "[", "key", "]", "[", "'y'", "]", "=", "np", ".", "array", "(", "self", ".", "task_data", "[", "key", "]", "[", "'y'", "]", ")", "\n", "", "logging", ".", "info", "(", "'Computed embeddings'", ")", "\n", "\n", "config_classifier", "=", "{", "'nclasses'", ":", "self", ".", "nclasses", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", "}", "\n", "\n", "if", "self", ".", "task", "==", "\"WordContent\"", "and", "params", ".", "classifier", "[", "'nhid'", "]", ">", "0", ":", "\n", "            ", "config_classifier", "=", "copy", ".", "deepcopy", "(", "config_classifier", ")", "\n", "config_classifier", "[", "'classifier'", "]", "[", "'nhid'", "]", "=", "0", "\n", "print", "(", "params", ".", "classifier", "[", "'nhid'", "]", ")", "\n", "\n", "", "clf", "=", "SplitClassifier", "(", "X", "=", "{", "'train'", ":", "task_embed", "[", "'train'", "]", "[", "'X'", "]", ",", "\n", "'valid'", ":", "task_embed", "[", "'dev'", "]", "[", "'X'", "]", ",", "\n", "'test'", ":", "task_embed", "[", "'test'", "]", "[", "'X'", "]", "}", ",", "\n", "y", "=", "{", "'train'", ":", "task_embed", "[", "'train'", "]", "[", "'y'", "]", ",", "\n", "'valid'", ":", "task_embed", "[", "'dev'", "]", "[", "'y'", "]", ",", "\n", "'test'", ":", "task_embed", "[", "'test'", "]", "[", "'y'", "]", "}", ",", "\n", "config", "=", "config_classifier", ")", "\n", "\n", "devacc", ",", "testacc", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'\\nDev acc : %.1f Test acc : %.1f for %s classification\\n'", "%", "(", "devacc", ",", "testacc", ",", "self", ".", "task", ".", "upper", "(", ")", ")", ")", "\n", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "\n", "'ndev'", ":", "len", "(", "task_embed", "[", "'dev'", "]", "[", "'X'", "]", ")", ",", "\n", "'ntest'", ":", "len", "(", "task_embed", "[", "'test'", "]", "[", "'X'", "]", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.LengthEval.__init__": [[110, 114], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sentence_length.txt'", ")", "\n", "# labels: bins", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'Length'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.WordContentEval.__init__": [[116, 120], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'word_content.txt'", ")", "\n", "# labels: 200 target words", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'WordContent'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.DepthEval.__init__": [[125, 129], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'tree_depth.txt'", ")", "\n", "# labels: bins", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'Depth'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.TopConstituentsEval.__init__": [[131, 135], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'top_constituents.txt'", ")", "\n", "# labels: 'PP_NP_VP_.' .. (20 classes)", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'TopConstituents'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.BigramShiftEval.__init__": [[137, 141], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'bigram_shift.txt'", ")", "\n", "# labels: 0 or 1", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'BigramShift'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.TenseEval.__init__": [[149, 153], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'past_present.txt'", ")", "\n", "# labels: 'PRES', 'PAST'", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'Tense'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.SubjNumberEval.__init__": [[155, 159], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'subj_number.txt'", ")", "\n", "# labels: 'NN', 'NNS'", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'SubjNumber'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.ObjNumberEval.__init__": [[161, 165], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'obj_number.txt'", ")", "\n", "# labels: 'NN', 'NNS'", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'ObjNumber'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.OddManOutEval.__init__": [[167, 171], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'odd_man_out.txt'", ")", "\n", "# labels: 'O', 'C'", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'OddManOut'", ",", "task_path", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.probing.CoordinationInversionEval.__init__": [[173, 177], ["os.path.join", "probing.PROBINGEval.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "task_path", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "'coordination_inversion.txt'", ")", "\n", "# labels: 'O', 'I'", "\n", "PROBINGEval", ".", "__init__", "(", "self", ",", "'CoordinationInversion'", ",", "task_path", ",", "seed", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.BinaryClassifierEval.__init__": [[27, 31], ["len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pos", ",", "neg", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samples", ",", "self", ".", "labels", "=", "pos", "+", "neg", ",", "[", "1", "]", "*", "len", "(", "pos", ")", "+", "[", "0", "]", "*", "len", "(", "neg", ")", "\n", "self", ".", "n_samples", "=", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.BinaryClassifierEval.do_prepare": [[32, 35], ["prepare"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare"], ["", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "# prepare is given the whole text", "\n", "        ", "return", "prepare", "(", "params", ",", "self", ".", "samples", ")", "\n", "# prepare puts everything it outputs in \"params\" : params.word2id etc", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.BinaryClassifierEval.loadFile": [[38, 41], ["io.open", "line.split", "f.read().splitlines", "f.read"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'latin-1'", ")", "as", "f", ":", "\n", "            ", "return", "[", "line", ".", "split", "(", ")", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.BinaryClassifierEval.run": [[42, 66], ["sorted", "logging.info", "range", "numpy.vstack", "logging.info", "senteval.tools.validation.InnerKFoldClassifier", "senteval.tools.validation.InnerKFoldClassifier.run", "logging.debug", "zip", "batcher", "numpy.vstack.append", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher"], ["", "", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "enc_input", "=", "[", "]", "\n", "# Sort to reduce padding", "\n", "sorted_corpus", "=", "sorted", "(", "zip", "(", "self", ".", "samples", ",", "self", ".", "labels", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "z", "[", "1", "]", ")", ")", "\n", "sorted_samples", "=", "[", "x", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus", "]", "\n", "sorted_labels", "=", "[", "y", "for", "(", "x", ",", "y", ")", "in", "sorted_corpus", "]", "\n", "logging", ".", "info", "(", "'Generating sentence embeddings'", ")", "\n", "for", "ii", "in", "range", "(", "0", ",", "self", ".", "n_samples", ",", "params", ".", "batch_size", ")", ":", "\n", "            ", "batch", "=", "sorted_samples", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "embeddings", "=", "batcher", "(", "params", ",", "batch", ")", "\n", "enc_input", ".", "append", "(", "embeddings", ")", "\n", "", "enc_input", "=", "np", ".", "vstack", "(", "enc_input", ")", "\n", "logging", ".", "info", "(", "'Generated sentence embeddings'", ")", "\n", "\n", "config", "=", "{", "'nclasses'", ":", "2", ",", "'seed'", ":", "self", ".", "seed", ",", "\n", "'usepytorch'", ":", "params", ".", "usepytorch", ",", "\n", "'classifier'", ":", "params", ".", "classifier", ",", "\n", "'nhid'", ":", "params", ".", "nhid", ",", "'kfold'", ":", "params", ".", "kfold", "}", "\n", "clf", "=", "InnerKFoldClassifier", "(", "enc_input", ",", "np", ".", "array", "(", "sorted_labels", ")", ",", "config", ")", "\n", "devacc", ",", "testacc", "=", "clf", ".", "run", "(", ")", "\n", "logging", ".", "debug", "(", "'Dev acc : {0} Test acc : {1}\\n'", ".", "format", "(", "devacc", ",", "testacc", ")", ")", "\n", "return", "{", "'devacc'", ":", "devacc", ",", "'acc'", ":", "testacc", ",", "'ndev'", ":", "self", ".", "n_samples", ",", "\n", "'ntest'", ":", "self", ".", "n_samples", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.CREval.__init__": [[69, 74], ["logging.debug", "binary.CREval.loadFile", "binary.CREval.loadFile", "binary.BinaryClassifierEval.__init__", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : CR *****\\n\\n'", ")", "\n", "pos", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'custrev.pos'", ")", ")", "\n", "neg", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'custrev.neg'", ")", ")", "\n", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "pos", ",", "neg", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.MREval.__init__": [[77, 82], ["logging.debug", "binary.MREval.loadFile", "binary.MREval.loadFile", "binary.BinaryClassifierEval.__init__", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : MR *****\\n\\n'", ")", "\n", "pos", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'rt-polarity.pos'", ")", ")", "\n", "neg", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'rt-polarity.neg'", ")", ")", "\n", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "pos", ",", "neg", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.SUBJEval.__init__": [[85, 90], ["logging.debug", "binary.SUBJEval.loadFile", "binary.SUBJEval.loadFile", "binary.BinaryClassifierEval.__init__", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : SUBJ *****\\n\\n'", ")", "\n", "obj", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'subj.objective'", ")", ")", "\n", "subj", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'subj.subjective'", ")", ")", "\n", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "obj", ",", "subj", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.binary.MPQAEval.__init__": [[93, 98], ["logging.debug", "binary.MPQAEval.loadFile", "binary.MPQAEval.loadFile", "binary.BinaryClassifierEval.__init__", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : MPQA *****\\n\\n'", ")", "\n", "pos", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'mpqa.pos'", ")", ")", "\n", "neg", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'mpqa.neg'", ")", ")", "\n", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "pos", ",", "neg", ",", "seed", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSEval.loadFile": [[32, 56], ["zip", "numpy.array", "sorted", "map", "float", "numpy.array", "numpy.array", "zip", "zip", "l.split", "io.open().read().splitlines", "s.split", "s.split", "io.open().read().splitlines", "len", "len", "io.open().read", "io.open().read", "io.open", "io.open"], "methods", ["None"], ["    ", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "self", ".", "data", "=", "{", "}", "\n", "self", ".", "samples", "=", "[", "]", "\n", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "sent1", ",", "sent2", "=", "zip", "(", "*", "[", "l", ".", "split", "(", "\"\\t\"", ")", "for", "l", "in", "\n", "io", ".", "open", "(", "fpath", "+", "'/STS.input.%s.txt'", "%", "dataset", ",", "\n", "encoding", "=", "'utf8'", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ")", "\n", "raw_scores", "=", "np", ".", "array", "(", "[", "x", "for", "x", "in", "\n", "io", ".", "open", "(", "fpath", "+", "'/STS.gs.%s.txt'", "%", "dataset", ",", "\n", "encoding", "=", "'utf8'", ")", "\n", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ")", "\n", "not_empty_idx", "=", "raw_scores", "!=", "''", "\n", "\n", "gs_scores", "=", "[", "float", "(", "x", ")", "for", "x", "in", "raw_scores", "[", "not_empty_idx", "]", "]", "\n", "sent1", "=", "np", ".", "array", "(", "[", "s", ".", "split", "(", ")", "for", "s", "in", "sent1", "]", ")", "[", "not_empty_idx", "]", "\n", "sent2", "=", "np", ".", "array", "(", "[", "s", ".", "split", "(", ")", "for", "s", "in", "sent2", "]", ")", "[", "not_empty_idx", "]", "\n", "# sort data by length to minimize padding in batcher", "\n", "sorted_data", "=", "sorted", "(", "zip", "(", "sent1", ",", "sent2", ",", "gs_scores", ")", ",", "\n", "key", "=", "lambda", "z", ":", "(", "len", "(", "z", "[", "0", "]", ")", ",", "len", "(", "z", "[", "1", "]", ")", ",", "z", "[", "2", "]", ")", ")", "\n", "sent1", ",", "sent2", ",", "gs_scores", "=", "map", "(", "list", ",", "zip", "(", "*", "sorted_data", ")", ")", "\n", "\n", "self", ".", "data", "[", "dataset", "]", "=", "(", "sent1", ",", "sent2", ",", "gs_scores", ")", "\n", "self", ".", "samples", "+=", "sent1", "+", "sent2", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSEval.do_prepare": [[57, 63], ["prepare", "numpy.nan_to_num", "senteval.utils.cosine", "numpy.nan_to_num", "numpy.nan_to_num"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.cosine"], ["", "", "def", "do_prepare", "(", "self", ",", "params", ",", "prepare", ")", ":", "\n", "        ", "if", "'similarity'", "in", "params", ":", "\n", "            ", "self", ".", "similarity", "=", "params", ".", "similarity", "\n", "", "else", ":", "# Default similarity is cosine", "\n", "            ", "self", ".", "similarity", "=", "lambda", "s1", ",", "s2", ":", "np", ".", "nan_to_num", "(", "cosine", "(", "np", ".", "nan_to_num", "(", "s1", ")", ",", "np", ".", "nan_to_num", "(", "s2", ")", ")", ")", "\n", "", "return", "prepare", "(", "params", ",", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSEval.run": [[64, 118], ["numpy.array", "numpy.array", "numpy.average", "numpy.average", "numpy.average", "numpy.average", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "logging.debug", "logging.debug", "logging.debug", "range", "all_sys_scores.extend", "all_gs_scores.extend", "logging.debug", "len", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "len", "results.keys", "batcher", "batcher", "range", "results.keys", "results.keys", "len", "len", "len", "sts.STSEval.similarity", "sys_scores.append"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.tool.SCD.similarity"], ["", "def", "run", "(", "self", ",", "params", ",", "batcher", ")", ":", "\n", "        ", "results", "=", "{", "}", "\n", "all_sys_scores", "=", "[", "]", "\n", "all_gs_scores", "=", "[", "]", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "sys_scores", "=", "[", "]", "\n", "input1", ",", "input2", ",", "gs_scores", "=", "self", ".", "data", "[", "dataset", "]", "\n", "for", "ii", "in", "range", "(", "0", ",", "len", "(", "gs_scores", ")", ",", "params", ".", "batch_size", ")", ":", "\n", "                ", "batch1", "=", "input1", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "batch2", "=", "input2", "[", "ii", ":", "ii", "+", "params", ".", "batch_size", "]", "\n", "\n", "# we assume get_batch already throws out the faulty ones", "\n", "if", "len", "(", "batch1", ")", "==", "len", "(", "batch2", ")", "and", "len", "(", "batch1", ")", ">", "0", ":", "\n", "                    ", "enc1", "=", "batcher", "(", "params", ",", "batch1", ")", "\n", "enc2", "=", "batcher", "(", "params", ",", "batch2", ")", "\n", "\n", "for", "kk", "in", "range", "(", "enc2", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "sys_score", "=", "self", ".", "similarity", "(", "enc1", "[", "kk", "]", ",", "enc2", "[", "kk", "]", ")", "\n", "sys_scores", ".", "append", "(", "sys_score", ")", "\n", "", "", "", "all_sys_scores", ".", "extend", "(", "sys_scores", ")", "\n", "all_gs_scores", ".", "extend", "(", "gs_scores", ")", "\n", "results", "[", "dataset", "]", "=", "{", "'pearson'", ":", "pearsonr", "(", "sys_scores", ",", "gs_scores", ")", ",", "\n", "'spearman'", ":", "spearmanr", "(", "sys_scores", ",", "gs_scores", ")", ",", "\n", "'nsamples'", ":", "len", "(", "sys_scores", ")", "}", "\n", "logging", ".", "debug", "(", "'%s : pearson = %.4f, spearman = %.4f'", "%", "\n", "(", "dataset", ",", "results", "[", "dataset", "]", "[", "'pearson'", "]", "[", "0", "]", ",", "\n", "results", "[", "dataset", "]", "[", "'spearman'", "]", "[", "0", "]", ")", ")", "\n", "\n", "", "weights", "=", "[", "results", "[", "dset", "]", "[", "'nsamples'", "]", "for", "dset", "in", "results", ".", "keys", "(", ")", "]", "\n", "list_prs", "=", "np", ".", "array", "(", "[", "results", "[", "dset", "]", "[", "'pearson'", "]", "[", "0", "]", "for", "\n", "dset", "in", "results", ".", "keys", "(", ")", "]", ")", "\n", "list_spr", "=", "np", ".", "array", "(", "[", "results", "[", "dset", "]", "[", "'spearman'", "]", "[", "0", "]", "for", "\n", "dset", "in", "results", ".", "keys", "(", ")", "]", ")", "\n", "\n", "avg_pearson", "=", "np", ".", "average", "(", "list_prs", ")", "\n", "avg_spearman", "=", "np", ".", "average", "(", "list_spr", ")", "\n", "wavg_pearson", "=", "np", ".", "average", "(", "list_prs", ",", "weights", "=", "weights", ")", "\n", "wavg_spearman", "=", "np", ".", "average", "(", "list_spr", ",", "weights", "=", "weights", ")", "\n", "all_pearson", "=", "pearsonr", "(", "all_sys_scores", ",", "all_gs_scores", ")", "\n", "all_spearman", "=", "spearmanr", "(", "all_sys_scores", ",", "all_gs_scores", ")", "\n", "results", "[", "'all'", "]", "=", "{", "'pearson'", ":", "{", "'all'", ":", "all_pearson", "[", "0", "]", ",", "\n", "'mean'", ":", "avg_pearson", ",", "\n", "'wmean'", ":", "wavg_pearson", "}", ",", "\n", "'spearman'", ":", "{", "'all'", ":", "all_spearman", "[", "0", "]", ",", "\n", "'mean'", ":", "avg_spearman", ",", "\n", "'wmean'", ":", "wavg_spearman", "}", "}", "\n", "logging", ".", "debug", "(", "'ALL : Pearson = %.4f, \\\n            Spearman = %.4f'", "%", "(", "all_pearson", "[", "0", "]", ",", "all_spearman", "[", "0", "]", ")", ")", "\n", "logging", ".", "debug", "(", "'ALL (weighted average) : Pearson = %.4f, \\\n            Spearman = %.4f'", "%", "(", "wavg_pearson", ",", "wavg_spearman", ")", ")", "\n", "logging", ".", "debug", "(", "'ALL (average) : Pearson = %.4f, \\\n            Spearman = %.4f\\n'", "%", "(", "avg_pearson", ",", "avg_spearman", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STS12Eval.__init__": [[121, 127], ["logging.debug", "sts.STS12Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS12 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'MSRpar'", ",", "'MSRvid'", ",", "'SMTeuroparl'", ",", "\n", "'surprise.OnWN'", ",", "'surprise.SMTnews'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STS13Eval.__init__": [[131, 136], ["logging.debug", "sts.STS13Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS13 (-SMT) *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'FNWN'", ",", "'headlines'", ",", "'OnWN'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STS14Eval.__init__": [[139, 145], ["logging.debug", "sts.STS14Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS14 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'deft-forum'", ",", "'deft-news'", ",", "'headlines'", ",", "\n", "'images'", ",", "'OnWN'", ",", "'tweet-news'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STS15Eval.__init__": [[148, 154], ["logging.debug", "sts.STS15Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS15 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'answers-forums'", ",", "'answers-students'", ",", "\n", "'belief'", ",", "'headlines'", ",", "'images'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STS16Eval.__init__": [[157, 163], ["logging.debug", "sts.STS16Eval.loadFile"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "taskpath", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'***** Transfer task : STS16 *****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "datasets", "=", "[", "'answer-answer'", ",", "'headlines'", ",", "'plagiarism'", ",", "\n", "'postediting'", ",", "'question-question'", "]", "\n", "self", ".", "loadFile", "(", "taskpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSBenchmarkEval.__init__": [[166, 175], ["logging.debug", "sts.STSBenchmarkEval.loadFile", "sts.STSBenchmarkEval.loadFile", "sts.STSBenchmarkEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : STSBenchmark*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samples", "=", "[", "]", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-train.csv'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-dev.csv'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-test.csv'", ")", ")", "\n", "self", ".", "datasets", "=", "[", "'train'", ",", "'dev'", ",", "'test'", "]", "\n", "self", ".", "data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSBenchmarkEval.loadFile": [[176, 188], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "5", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "6", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "4", "]", ")", "\n", "\n", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "self", ".", "samples", "+=", "sick_data", "[", "'X_A'", "]", "+", "sick_data", "[", "\"X_B\"", "]", "\n", "return", "(", "sick_data", "[", "'X_A'", "]", ",", "sick_data", "[", "\"X_B\"", "]", ",", "sick_data", "[", "'y'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSBenchmarkFinetune.__init__": [[190, 197], ["logging.debug", "sts.STSBenchmarkFinetune.loadFile", "sts.STSBenchmarkFinetune.loadFile", "sts.STSBenchmarkFinetune.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : STSBenchmark*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-train.csv'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-dev.csv'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'sts-test.csv'", ")", ")", "\n", "self", ".", "sick_data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.STSBenchmarkFinetune.loadFile": [[198, 209], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "5", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "6", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "4", "]", ")", "\n", "\n", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "return", "sick_data", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.__init__": [[211, 220], ["logging.debug", "sts.SICKRelatednessEval.loadFile", "sts.SICKRelatednessEval.loadFile", "sts.SICKRelatednessEval.loadFile", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile"], ["    ", "def", "__init__", "(", "self", ",", "task_path", ",", "seed", "=", "1111", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "'\\n\\n***** Transfer task : SICKRelatedness*****\\n\\n'", ")", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "samples", "=", "[", "]", "\n", "train", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_train.txt'", ")", ")", "\n", "dev", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_trial.txt'", ")", ")", "\n", "test", "=", "self", ".", "loadFile", "(", "os", ".", "path", ".", "join", "(", "task_path", ",", "'SICK_test_annotated.txt'", ")", ")", "\n", "self", ".", "datasets", "=", "[", "'train'", ",", "'dev'", ",", "'test'", "]", "\n", "self", ".", "data", "=", "{", "'train'", ":", "train", ",", "'dev'", ":", "dev", ",", "'test'", ":", "test", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.sts.SICKRelatednessEval.loadFile": [[221, 237], ["io.open", "float", "line.strip().split", "sick_data[].append", "sick_data[].append", "sick_data[].append", "text[].split", "text[].split", "line.strip"], "methods", ["None"], ["", "def", "loadFile", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "skipFirstLine", "=", "True", "\n", "sick_data", "=", "{", "'X_A'", ":", "[", "]", ",", "'X_B'", ":", "[", "]", ",", "'y'", ":", "[", "]", "}", "\n", "with", "io", ".", "open", "(", "fpath", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "if", "skipFirstLine", ":", "\n", "                    ", "skipFirstLine", "=", "False", "\n", "", "else", ":", "\n", "                    ", "text", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "sick_data", "[", "'X_A'", "]", ".", "append", "(", "text", "[", "1", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'X_B'", "]", ".", "append", "(", "text", "[", "2", "]", ".", "split", "(", ")", ")", "\n", "sick_data", "[", "'y'", "]", ".", "append", "(", "text", "[", "3", "]", ")", "\n", "\n", "", "", "", "sick_data", "[", "'y'", "]", "=", "[", "float", "(", "s", ")", "for", "s", "in", "sick_data", "[", "'y'", "]", "]", "\n", "self", ".", "samples", "+=", "sick_data", "[", "'X_A'", "]", "+", "sick_data", "[", "\"X_B\"", "]", "\n", "return", "(", "sick_data", "[", "'X_A'", "]", ",", "sick_data", "[", "\"X_B\"", "]", ",", "sick_data", "[", "'y'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.create_dictionary": [[21, 41], ["sorted", "enumerate", "words.items", "id2word.append"], "function", ["None"], ["def", "create_dictionary", "(", "sentences", ")", ":", "\n", "    ", "words", "=", "{", "}", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "for", "word", "in", "s", ":", "\n", "            ", "if", "word", "in", "words", ":", "\n", "                ", "words", "[", "word", "]", "+=", "1", "\n", "", "else", ":", "\n", "                ", "words", "[", "word", "]", "=", "1", "\n", "", "", "", "words", "[", "'<s>'", "]", "=", "1e9", "+", "4", "\n", "words", "[", "'</s>'", "]", "=", "1e9", "+", "3", "\n", "words", "[", "'<p>'", "]", "=", "1e9", "+", "2", "\n", "# words['<UNK>'] = 1e9 + 1", "\n", "sorted_words", "=", "sorted", "(", "words", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "# inverse sort", "\n", "id2word", "=", "[", "]", "\n", "word2id", "=", "{", "}", "\n", "for", "i", ",", "(", "w", ",", "_", ")", "in", "enumerate", "(", "sorted_words", ")", ":", "\n", "        ", "id2word", ".", "append", "(", "w", ")", "\n", "word2id", "[", "w", "]", "=", "i", "\n", "\n", "", "return", "id2word", ",", "word2id", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.cosine": [[43, 45], ["numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "cosine", "(", "u", ",", "v", ")", ":", "\n", "    ", "return", "np", ".", "dot", "(", "u", ",", "v", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "u", ")", "*", "np", ".", "linalg", ".", "norm", "(", "v", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.get_optimizer": [[54, 101], ["s[].split", "inspect.getargspec", "all", "Exception", "x.split", "float", "s.find", "len", "re.match", "optim_params.keys", "str", "str", "optim_params.keys", "s.find", "Exception"], "function", ["None"], ["", "def", "get_optimizer", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Parse optimizer parameters.\n    Input should be of the form:\n        - \"sgd,lr=0.01\"\n        - \"adagrad,lr=0.1,lr_decay=0.05\"\n    \"\"\"", "\n", "if", "\",\"", "in", "s", ":", "\n", "        ", "method", "=", "s", "[", ":", "s", ".", "find", "(", "','", ")", "]", "\n", "optim_params", "=", "{", "}", "\n", "for", "x", "in", "s", "[", "s", ".", "find", "(", "','", ")", "+", "1", ":", "]", ".", "split", "(", "','", ")", ":", "\n", "            ", "split", "=", "x", ".", "split", "(", "'='", ")", "\n", "assert", "len", "(", "split", ")", "==", "2", "\n", "assert", "re", ".", "match", "(", "\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)$\"", ",", "split", "[", "1", "]", ")", "is", "not", "None", "\n", "optim_params", "[", "split", "[", "0", "]", "]", "=", "float", "(", "split", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "method", "=", "s", "\n", "optim_params", "=", "{", "}", "\n", "\n", "", "if", "method", "==", "'adadelta'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adadelta", "\n", "", "elif", "method", "==", "'adagrad'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adagrad", "\n", "", "elif", "method", "==", "'adam'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adam", "\n", "", "elif", "method", "==", "'adamax'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adamax", "\n", "", "elif", "method", "==", "'asgd'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "ASGD", "\n", "", "elif", "method", "==", "'rmsprop'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "RMSprop", "\n", "", "elif", "method", "==", "'rprop'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Rprop", "\n", "", "elif", "method", "==", "'sgd'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "SGD", "\n", "assert", "'lr'", "in", "optim_params", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Unknown optimization method: \"%s\"'", "%", "method", ")", "\n", "\n", "# check that we give good parameters to the optimizer", "\n", "", "expected_args", "=", "inspect", ".", "getargspec", "(", "optim_fn", ".", "__init__", ")", "[", "0", "]", "\n", "assert", "expected_args", "[", ":", "2", "]", "==", "[", "'self'", ",", "'params'", "]", "\n", "if", "not", "all", "(", "k", "in", "expected_args", "[", "2", ":", "]", "for", "k", "in", "optim_params", ".", "keys", "(", ")", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Unexpected parameters: expected \"%s\", got \"%s\"'", "%", "(", "\n", "str", "(", "expected_args", "[", "2", ":", "]", ")", ",", "str", "(", "optim_params", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "return", "optim_fn", ",", "optim_params", "\n", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.__init__": [[29, 39], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "COCOProjNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "imgdim", "=", "config", "[", "'imgdim'", "]", "\n", "self", ".", "sentdim", "=", "config", "[", "'sentdim'", "]", "\n", "self", ".", "projdim", "=", "config", "[", "'projdim'", "]", "\n", "self", ".", "imgproj", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "imgdim", ",", "self", ".", "projdim", ")", ",", "\n", ")", "\n", "self", ".", "sentproj", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "sentdim", ",", "self", ".", "projdim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.forward": [[41, 70], ["img.view.view.unsqueeze().expand_as().contiguous", "img.view.view.view", "imgc.view.view.view", "sent.view.view.unsqueeze().expand_as().contiguous", "sent.view.view.view", "sentc.view.view.view", "ranking.COCOProjNet.imgproj", "ranking.COCOProjNet.imgproj", "ranking.COCOProjNet.sentproj", "ranking.COCOProjNet.sentproj", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "img.view.view.unsqueeze().expand_as", "sent.view.view.unsqueeze().expand_as", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "img.view.view.unsqueeze", "sent.view.view.unsqueeze", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "sent", ",", "imgc", ",", "sentc", ")", ":", "\n", "# imgc : (bsize, ncontrast, imgdim)", "\n", "# sentc : (bsize, ncontrast, sentdim)", "\n", "# img : (bsize, imgdim)", "\n", "# sent : (bsize, sentdim)", "\n", "        ", "img", "=", "img", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "imgc", ")", ".", "contiguous", "(", ")", "\n", "img", "=", "img", ".", "view", "(", "-", "1", ",", "self", ".", "imgdim", ")", "\n", "imgc", "=", "imgc", ".", "view", "(", "-", "1", ",", "self", ".", "imgdim", ")", "\n", "sent", "=", "sent", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "sentc", ")", ".", "contiguous", "(", ")", "\n", "sent", "=", "sent", ".", "view", "(", "-", "1", ",", "self", ".", "sentdim", ")", "\n", "sentc", "=", "sentc", ".", "view", "(", "-", "1", ",", "self", ".", "sentdim", ")", "\n", "\n", "imgproj", "=", "self", ".", "imgproj", "(", "img", ")", "\n", "imgproj", "=", "imgproj", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "imgproj", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "imgproj", ")", "\n", "imgcproj", "=", "self", ".", "imgproj", "(", "imgc", ")", "\n", "imgcproj", "=", "imgcproj", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "imgcproj", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "imgcproj", ")", "\n", "sentproj", "=", "self", ".", "sentproj", "(", "sent", ")", "\n", "sentproj", "=", "sentproj", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "sentproj", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "sentproj", ")", "\n", "sentcproj", "=", "self", ".", "sentproj", "(", "sentc", ")", "\n", "sentcproj", "=", "sentcproj", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "sentcproj", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "sentcproj", ")", "\n", "# (bsize*ncontrast, projdim)", "\n", "\n", "anchor1", "=", "torch", ".", "sum", "(", "(", "imgproj", "*", "sentproj", ")", ",", "1", ")", "\n", "anchor2", "=", "torch", ".", "sum", "(", "(", "sentproj", "*", "imgproj", ")", ",", "1", ")", "\n", "img_sentc", "=", "torch", ".", "sum", "(", "(", "imgproj", "*", "sentcproj", ")", ",", "1", ")", "\n", "sent_imgc", "=", "torch", ".", "sum", "(", "(", "sentproj", "*", "imgcproj", ")", ",", "1", ")", "\n", "\n", "# (bsize*ncontrast)", "\n", "return", "anchor1", ",", "anchor2", ",", "img_sentc", ",", "sent_imgc", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_sentence": [[71, 75], ["ranking.COCOProjNet.sentproj", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "proj_sentence", "(", "self", ",", "sent", ")", ":", "\n", "        ", "output", "=", "self", ".", "sentproj", "(", "sent", ")", "\n", "output", "=", "output", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "output", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "output", ")", "\n", "return", "output", "# (bsize, projdim)", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_image": [[76, 80], ["ranking.COCOProjNet.imgproj", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt().expand_as", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "proj_image", "(", "self", ",", "img", ")", ":", "\n", "        ", "output", "=", "self", ".", "imgproj", "(", "img", ")", "\n", "output", "=", "output", "/", "torch", ".", "sqrt", "(", "torch", ".", "pow", "(", "output", ",", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ")", ".", "expand_as", "(", "output", ")", "\n", "return", "output", "# (bsize, projdim)", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.PairwiseRankingLoss.__init__": [[86, 89], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["def", "__init__", "(", "self", ",", "margin", ")", ":", "\n", "        ", "super", "(", "PairwiseRankingLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.PairwiseRankingLoss.forward": [[90, 98], ["torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp().sum", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "anchor1", ",", "anchor2", ",", "img_sentc", ",", "sent_imgc", ")", ":", "\n", "\n", "        ", "cost_sent", "=", "torch", ".", "clamp", "(", "self", ".", "margin", "-", "anchor1", "+", "img_sentc", ",", "\n", "min", "=", "0.0", ")", ".", "sum", "(", ")", "\n", "cost_img", "=", "torch", ".", "clamp", "(", "self", ".", "margin", "-", "anchor2", "+", "sent_imgc", ",", "\n", "min", "=", "0.0", ")", ".", "sum", "(", ")", "\n", "loss", "=", "cost_sent", "+", "cost_img", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.__init__": [[102, 130], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "len", "len", "COCOProjNet().cuda", "PairwiseRankingLoss().cuda", "torch.Adam", "torch.Adam", "ranking.ImageSentenceRankingPytorch.model.parameters", "ranking.COCOProjNet", "ranking.PairwiseRankingLoss"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train", ",", "valid", ",", "test", ",", "config", ")", ":", "\n", "# fix seed", "\n", "        ", "self", ".", "seed", "=", "config", "[", "'seed'", "]", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "self", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "self", ".", "seed", ")", "\n", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "valid", "=", "valid", "\n", "self", ".", "test", "=", "test", "\n", "\n", "self", ".", "imgdim", "=", "len", "(", "train", "[", "'imgfeat'", "]", "[", "0", "]", ")", "\n", "self", ".", "sentdim", "=", "len", "(", "train", "[", "'sentfeat'", "]", "[", "0", "]", ")", "\n", "self", ".", "projdim", "=", "config", "[", "'projdim'", "]", "\n", "self", ".", "margin", "=", "config", "[", "'margin'", "]", "\n", "\n", "self", ".", "batch_size", "=", "128", "\n", "self", ".", "ncontrast", "=", "30", "\n", "self", ".", "maxepoch", "=", "20", "\n", "self", ".", "early_stop", "=", "True", "\n", "\n", "config_model", "=", "{", "'imgdim'", ":", "self", ".", "imgdim", ",", "'sentdim'", ":", "self", ".", "sentdim", ",", "\n", "'projdim'", ":", "self", ".", "projdim", "}", "\n", "self", ".", "model", "=", "COCOProjNet", "(", "config_model", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "loss_fn", "=", "PairwiseRankingLoss", "(", "margin", "=", "self", ".", "margin", ")", ".", "cuda", "(", ")", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.prepare_data": [[131, 141], ["torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ",", "trainTxt", ",", "trainImg", ",", "devTxt", ",", "devImg", ",", "\n", "testTxt", ",", "testImg", ")", ":", "\n", "        ", "trainTxt", "=", "torch", ".", "FloatTensor", "(", "trainTxt", ")", "\n", "trainImg", "=", "torch", ".", "FloatTensor", "(", "trainImg", ")", "\n", "devTxt", "=", "torch", ".", "FloatTensor", "(", "devTxt", ")", ".", "cuda", "(", ")", "\n", "devImg", "=", "torch", ".", "FloatTensor", "(", "devImg", ")", ".", "cuda", "(", ")", "\n", "testTxt", "=", "torch", ".", "FloatTensor", "(", "testTxt", ")", ".", "cuda", "(", ")", "\n", "testImg", "=", "torch", ".", "FloatTensor", "(", "testImg", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "trainTxt", ",", "trainImg", ",", "devTxt", ",", "devImg", ",", "testTxt", ",", "testImg", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.run": [[142, 230], ["logging.info", "ranking.ImageSentenceRankingPytorch.prepare_data", "range", "logging.info", "ranking.ImageSentenceRankingPytorch.trainepoch", "logging.info", "range", "logging.info", "logging.info", "ranking.ImageSentenceRankingPytorch.i2t", "ranking.ImageSentenceRankingPytorch.t2i", "ranking.ImageSentenceRankingPytorch.i2t", "logging.info", "ranking.ImageSentenceRankingPytorch.t2i", "logging.info", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.prepare_data", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.trainepoch", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.i2t", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.t2i", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.i2t", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.t2i"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "nepoch", "=", "0", "\n", "bestdevscore", "=", "-", "1", "\n", "early_stop_count", "=", "0", "\n", "stop_train", "=", "False", "\n", "\n", "# Preparing data", "\n", "logging", ".", "info", "(", "'prepare data'", ")", "\n", "trainTxt", ",", "trainImg", ",", "devTxt", ",", "devImg", ",", "testTxt", ",", "testImg", "=", "self", ".", "prepare_data", "(", "self", ".", "train", "[", "'sentfeat'", "]", ",", "self", ".", "train", "[", "'imgfeat'", "]", ",", "\n", "self", ".", "valid", "[", "'sentfeat'", "]", ",", "self", ".", "valid", "[", "'imgfeat'", "]", ",", "\n", "self", ".", "test", "[", "'sentfeat'", "]", ",", "self", ".", "test", "[", "'imgfeat'", "]", ")", "\n", "\n", "# Training", "\n", "while", "not", "stop_train", "and", "self", ".", "nepoch", "<=", "self", ".", "maxepoch", ":", "\n", "            ", "logging", ".", "info", "(", "'start epoch'", ")", "\n", "self", ".", "trainepoch", "(", "trainTxt", ",", "trainImg", ",", "devTxt", ",", "devImg", ",", "nepoches", "=", "1", ")", "\n", "logging", ".", "info", "(", "'Epoch {0} finished'", ".", "format", "(", "self", ".", "nepoch", ")", ")", "\n", "\n", "results", "=", "{", "'i2t'", ":", "{", "'r1'", ":", "0", ",", "'r5'", ":", "0", ",", "'r10'", ":", "0", ",", "'medr'", ":", "0", "}", ",", "\n", "'t2i'", ":", "{", "'r1'", ":", "0", ",", "'r5'", ":", "0", ",", "'r10'", ":", "0", ",", "'medr'", ":", "0", "}", ",", "\n", "'dev'", ":", "bestdevscore", "}", "\n", "score", "=", "0", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "devTxt_i", "=", "devTxt", "[", "i", "*", "5000", ":", "(", "i", "+", "1", ")", "*", "5000", "]", "\n", "devImg_i", "=", "devImg", "[", "i", "*", "5000", ":", "(", "i", "+", "1", ")", "*", "5000", "]", "\n", "# Compute dev ranks img2txt", "\n", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", "=", "self", ".", "i2t", "(", "devImg_i", ",", "\n", "devTxt_i", ")", "\n", "results", "[", "'i2t'", "]", "[", "'r1'", "]", "+=", "r1_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'r5'", "]", "+=", "r5_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'r10'", "]", "+=", "r10_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'medr'", "]", "+=", "medr_i2t", "/", "5", "\n", "logging", ".", "info", "(", "\"Image to text: {0}, {1}, {2}, {3}\"", "\n", ".", "format", "(", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", ")", ")", "\n", "# Compute dev ranks txt2img", "\n", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", "=", "self", ".", "t2i", "(", "devImg_i", ",", "\n", "devTxt_i", ")", "\n", "results", "[", "'t2i'", "]", "[", "'r1'", "]", "+=", "r1_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'r5'", "]", "+=", "r5_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'r10'", "]", "+=", "r10_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'medr'", "]", "+=", "medr_t2i", "/", "5", "\n", "logging", ".", "info", "(", "\"Text to Image: {0}, {1}, {2}, {3}\"", "\n", ".", "format", "(", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", ")", ")", "\n", "score", "+=", "(", "r1_i2t", "+", "r5_i2t", "+", "r10_i2t", "+", "\n", "r1_t2i", "+", "r5_t2i", "+", "r10_t2i", ")", "/", "5", "\n", "\n", "", "logging", ".", "info", "(", "\"Dev mean Text to Image: {0}, {1}, {2}, {3}\"", ".", "format", "(", "\n", "results", "[", "'t2i'", "]", "[", "'r1'", "]", ",", "results", "[", "'t2i'", "]", "[", "'r5'", "]", ",", "\n", "results", "[", "'t2i'", "]", "[", "'r10'", "]", ",", "results", "[", "'t2i'", "]", "[", "'medr'", "]", ")", ")", "\n", "logging", ".", "info", "(", "\"Dev mean Image to text: {0}, {1}, {2}, {3}\"", ".", "format", "(", "\n", "results", "[", "'i2t'", "]", "[", "'r1'", "]", ",", "results", "[", "'i2t'", "]", "[", "'r5'", "]", ",", "\n", "results", "[", "'i2t'", "]", "[", "'r10'", "]", ",", "results", "[", "'i2t'", "]", "[", "'medr'", "]", ")", ")", "\n", "\n", "# early stop on Pearson", "\n", "if", "score", ">", "bestdevscore", ":", "\n", "                ", "bestdevscore", "=", "score", "\n", "bestmodel", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "", "elif", "self", ".", "early_stop", ":", "\n", "                ", "if", "early_stop_count", ">=", "3", ":", "\n", "                    ", "stop_train", "=", "True", "\n", "", "early_stop_count", "+=", "1", "\n", "", "", "self", ".", "model", "=", "bestmodel", "\n", "\n", "# Compute test for the 5 splits", "\n", "results", "=", "{", "'i2t'", ":", "{", "'r1'", ":", "0", ",", "'r5'", ":", "0", ",", "'r10'", ":", "0", ",", "'medr'", ":", "0", "}", ",", "\n", "'t2i'", ":", "{", "'r1'", ":", "0", ",", "'r5'", ":", "0", ",", "'r10'", ":", "0", ",", "'medr'", ":", "0", "}", ",", "\n", "'dev'", ":", "bestdevscore", "}", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "testTxt_i", "=", "testTxt", "[", "i", "*", "5000", ":", "(", "i", "+", "1", ")", "*", "5000", "]", "\n", "testImg_i", "=", "testImg", "[", "i", "*", "5000", ":", "(", "i", "+", "1", ")", "*", "5000", "]", "\n", "# Compute test ranks img2txt", "\n", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", "=", "self", ".", "i2t", "(", "testImg_i", ",", "testTxt_i", ")", "\n", "results", "[", "'i2t'", "]", "[", "'r1'", "]", "+=", "r1_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'r5'", "]", "+=", "r5_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'r10'", "]", "+=", "r10_i2t", "/", "5", "\n", "results", "[", "'i2t'", "]", "[", "'medr'", "]", "+=", "medr_i2t", "/", "5", "\n", "# Compute test ranks txt2img", "\n", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", "=", "self", ".", "t2i", "(", "testImg_i", ",", "testTxt_i", ")", "\n", "results", "[", "'t2i'", "]", "[", "'r1'", "]", "+=", "r1_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'r5'", "]", "+=", "r5_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'r10'", "]", "+=", "r10_t2i", "/", "5", "\n", "results", "[", "'t2i'", "]", "[", "'medr'", "]", "+=", "medr_t2i", "/", "5", "\n", "\n", "", "return", "bestdevscore", ",", "results", "[", "'i2t'", "]", "[", "'r1'", "]", ",", "results", "[", "'i2t'", "]", "[", "'r5'", "]", ",", "results", "[", "'i2t'", "]", "[", "'r10'", "]", ",", "results", "[", "'i2t'", "]", "[", "'medr'", "]", ",", "results", "[", "'t2i'", "]", "[", "'r1'", "]", ",", "results", "[", "'t2i'", "]", "[", "'r5'", "]", ",", "results", "[", "'t2i'", "]", "[", "'r10'", "]", ",", "results", "[", "'t2i'", "]", "[", "'medr'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.trainepoch": [[231, 278], ["ranking.ImageSentenceRankingPytorch.model.train", "range", "list", "range", "numpy.random.permutation", "len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "numpy.random.choice", "numpy.random.choice", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.autograd.Variable().view().cuda", "torch.autograd.Variable().view().cuda", "torch.autograd.Variable().view().cuda", "torch.autograd.Variable().view().cuda", "ranking.ImageSentenceRankingPytorch.model", "ranking.ImageSentenceRankingPytorch.loss_fn", "all_costs.append", "ranking.ImageSentenceRankingPytorch.optimizer.zero_grad", "ranking.ImageSentenceRankingPytorch.backward", "ranking.ImageSentenceRankingPytorch.optimizer.step", "len", "logging.info", "ranking.ImageSentenceRankingPytorch.i2t", "logging.info", "ranking.ImageSentenceRankingPytorch.t2i", "logging.info", "ranking.ImageSentenceRankingPytorch.data.item", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.size", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "torch.autograd.Variable().view", "trainImg.index_select", "trainTxt.index_select", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "trainImg.index_select", "trainTxt.index_select"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.i2t", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.t2i"], ["", "def", "trainepoch", "(", "self", ",", "trainTxt", ",", "trainImg", ",", "devTxt", ",", "devImg", ",", "nepoches", "=", "1", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "nepoch", ",", "self", ".", "nepoch", "+", "nepoches", ")", ":", "\n", "            ", "permutation", "=", "list", "(", "np", ".", "random", ".", "permutation", "(", "len", "(", "trainTxt", ")", ")", ")", "\n", "all_costs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "trainTxt", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "# forward", "\n", "                ", "if", "i", "%", "(", "self", ".", "batch_size", "*", "500", ")", "==", "0", "and", "i", ">", "0", ":", "\n", "                    ", "logging", ".", "info", "(", "'samples : {0}'", ".", "format", "(", "i", ")", ")", "\n", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", "=", "self", ".", "i2t", "(", "devImg", ",", "\n", "devTxt", ")", "\n", "logging", ".", "info", "(", "\"Image to text: {0}, {1}, {2}, {3}\"", ".", "format", "(", "\n", "r1_i2t", ",", "r5_i2t", ",", "r10_i2t", ",", "medr_i2t", ")", ")", "\n", "# Compute test ranks txt2img", "\n", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", "=", "self", ".", "t2i", "(", "devImg", ",", "\n", "devTxt", ")", "\n", "logging", ".", "info", "(", "\"Text to Image: {0}, {1}, {2}, {3}\"", ".", "format", "(", "\n", "r1_t2i", ",", "r5_t2i", ",", "r10_t2i", ",", "medr_t2i", ")", ")", "\n", "", "idx", "=", "torch", ".", "LongTensor", "(", "permutation", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", "\n", "imgbatch", "=", "Variable", "(", "trainImg", ".", "index_select", "(", "0", ",", "idx", ")", ")", ".", "cuda", "(", ")", "\n", "sentbatch", "=", "Variable", "(", "trainTxt", ".", "index_select", "(", "0", ",", "idx", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "idximgc", "=", "np", ".", "random", ".", "choice", "(", "permutation", "[", ":", "i", "]", "+", "\n", "permutation", "[", "i", "+", "self", ".", "batch_size", ":", "]", ",", "\n", "self", ".", "ncontrast", "*", "idx", ".", "size", "(", "0", ")", ")", "\n", "idxsentc", "=", "np", ".", "random", ".", "choice", "(", "permutation", "[", ":", "i", "]", "+", "\n", "permutation", "[", "i", "+", "self", ".", "batch_size", ":", "]", ",", "\n", "self", ".", "ncontrast", "*", "idx", ".", "size", "(", "0", ")", ")", "\n", "idximgc", "=", "torch", ".", "LongTensor", "(", "idximgc", ")", "\n", "idxsentc", "=", "torch", ".", "LongTensor", "(", "idxsentc", ")", "\n", "# Get indexes for contrastive images and sentences", "\n", "imgcbatch", "=", "Variable", "(", "trainImg", ".", "index_select", "(", "0", ",", "idximgc", ")", ")", ".", "view", "(", "\n", "-", "1", ",", "self", ".", "ncontrast", ",", "self", ".", "imgdim", ")", ".", "cuda", "(", ")", "\n", "sentcbatch", "=", "Variable", "(", "trainTxt", ".", "index_select", "(", "0", ",", "idxsentc", ")", ")", ".", "view", "(", "\n", "-", "1", ",", "self", ".", "ncontrast", ",", "self", ".", "sentdim", ")", ".", "cuda", "(", ")", "\n", "\n", "anchor1", ",", "anchor2", ",", "img_sentc", ",", "sent_imgc", "=", "self", ".", "model", "(", "\n", "imgbatch", ",", "sentbatch", ",", "imgcbatch", ",", "sentcbatch", ")", "\n", "# loss", "\n", "loss", "=", "self", ".", "loss_fn", "(", "anchor1", ",", "anchor2", ",", "img_sentc", ",", "sent_imgc", ")", "\n", "all_costs", ".", "append", "(", "loss", ".", "data", ".", "item", "(", ")", ")", "\n", "# backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update parameters", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", "self", ".", "nepoch", "+=", "nepoches", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.t2i": [[279, 318], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "int", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "img_embed.index_select", "numpy.zeros", "range", "len", "img_embed.append", "sent_embed.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.mm().cpu().numpy", "torch.mm().cpu().numpy", "torch.mm().cpu().numpy", "torch.mm().cpu().numpy", "numpy.zeros", "range", "len", "len", "len", "numpy.floor", "ranking.ImageSentenceRankingPytorch.model.proj_image", "ranking.ImageSentenceRankingPytorch.model.proj_sentence", "img_embed.size", "len", "len", "len", "len", "len", "numpy.median", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.mm().cpu", "torch.mm().cpu", "torch.mm().cpu", "torch.mm().cpu", "numpy.argsort", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "img_embed.index_select.transpose"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_image", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_sentence"], ["", "def", "t2i", "(", "self", ",", "images", ",", "captions", ")", ":", "\n", "        ", "\"\"\"\n        Images: (5N, imgdim) matrix of images\n        Captions: (5N, sentdim) matrix of captions\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Project images and captions", "\n", "            ", "img_embed", ",", "sent_embed", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "img_embed", ".", "append", "(", "self", ".", "model", ".", "proj_image", "(", "\n", "Variable", "(", "images", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ")", ")", "\n", "sent_embed", ".", "append", "(", "self", ".", "model", ".", "proj_sentence", "(", "\n", "Variable", "(", "captions", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ")", ")", "\n", "", "img_embed", "=", "torch", ".", "cat", "(", "img_embed", ",", "0", ")", ".", "data", "\n", "sent_embed", "=", "torch", ".", "cat", "(", "sent_embed", ",", "0", ")", ".", "data", "\n", "\n", "npts", "=", "int", "(", "img_embed", ".", "size", "(", "0", ")", "/", "5", ")", "\n", "idxs", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "range", "(", "0", ",", "len", "(", "img_embed", ")", ",", "5", ")", ")", "\n", "ims", "=", "img_embed", ".", "index_select", "(", "0", ",", "idxs", ")", "\n", "\n", "ranks", "=", "np", ".", "zeros", "(", "5", "*", "npts", ")", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "\n", "# Get query captions", "\n", "                ", "queries", "=", "sent_embed", "[", "5", "*", "index", ":", "5", "*", "index", "+", "5", "]", "\n", "\n", "# Compute scores", "\n", "scores", "=", "torch", ".", "mm", "(", "queries", ",", "ims", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "inds", "=", "np", ".", "zeros", "(", "scores", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inds", ")", ")", ":", "\n", "                    ", "inds", "[", "i", "]", "=", "np", ".", "argsort", "(", "scores", "[", "i", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "np", ".", "where", "(", "inds", "[", "i", "]", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "# Compute metrics", "\n", "", "", "r1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "np", ".", "floor", "(", "np", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.ImageSentenceRankingPytorch.i2t": [[319, 365], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "int", "numpy.zeros", "range", "len", "img_embed.append", "sent_embed.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "scores.cpu().numpy.cpu().numpy.cpu().numpy", "index_list.append", "range", "len", "len", "len", "numpy.floor", "ranking.ImageSentenceRankingPytorch.model.proj_image", "ranking.ImageSentenceRankingPytorch.model.proj_sentence", "img_embed.size", "numpy.argsort", "len", "len", "len", "numpy.median", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "scores.cpu().numpy.cpu().numpy.cpu", "query_img.view", "sent_embed.transpose", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_image", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.ranking.COCOProjNet.proj_sentence"], ["", "", "def", "i2t", "(", "self", ",", "images", ",", "captions", ")", ":", "\n", "        ", "\"\"\"\n        Images: (5N, imgdim) matrix of images\n        Captions: (5N, sentdim) matrix of captions\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Project images and captions", "\n", "            ", "img_embed", ",", "sent_embed", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "img_embed", ".", "append", "(", "self", ".", "model", ".", "proj_image", "(", "\n", "Variable", "(", "images", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ")", ")", "\n", "sent_embed", ".", "append", "(", "self", ".", "model", ".", "proj_sentence", "(", "\n", "Variable", "(", "captions", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ")", ")", "\n", "", "img_embed", "=", "torch", ".", "cat", "(", "img_embed", ",", "0", ")", ".", "data", "\n", "sent_embed", "=", "torch", ".", "cat", "(", "sent_embed", ",", "0", ")", ".", "data", "\n", "\n", "npts", "=", "int", "(", "img_embed", ".", "size", "(", "0", ")", "/", "5", ")", "\n", "index_list", "=", "[", "]", "\n", "\n", "ranks", "=", "np", ".", "zeros", "(", "npts", ")", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "\n", "# Get query image", "\n", "                ", "query_img", "=", "img_embed", "[", "5", "*", "index", "]", "\n", "\n", "# Compute scores", "\n", "scores", "=", "torch", ".", "mm", "(", "query_img", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "sent_embed", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "inds", "=", "np", ".", "argsort", "(", "scores", ")", "[", ":", ":", "-", "1", "]", "\n", "index_list", ".", "append", "(", "inds", "[", "0", "]", ")", "\n", "\n", "# Score", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "5", "*", "index", "+", "5", ",", "1", ")", ":", "\n", "                    ", "tmp", "=", "np", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                        ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "\n", "# Compute metrics", "\n", "", "r1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "np", ".", "floor", "(", "np", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.__init__": [[30, 63], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Adam", "torch.Adam", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Softmax", "relatedness.RelatednessPytorch.model.cuda", "relatedness.RelatednessPytorch.loss_fn.cuda", "relatedness.RelatednessPytorch.model.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train", ",", "valid", ",", "test", ",", "devscores", ",", "config", ")", ":", "\n", "# fix seed", "\n", "        ", "np", ".", "random", ".", "seed", "(", "config", "[", "'seed'", "]", ")", "\n", "torch", ".", "manual_seed", "(", "config", "[", "'seed'", "]", ")", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "'torch.cuda required for Relatedness'", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "config", "[", "'seed'", "]", ")", "\n", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "valid", "=", "valid", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "devscores", "=", "devscores", "\n", "\n", "self", ".", "inputdim", "=", "train", "[", "'X'", "]", ".", "shape", "[", "1", "]", "\n", "self", ".", "nclasses", "=", "config", "[", "'nclasses'", "]", "\n", "self", ".", "seed", "=", "config", "[", "'seed'", "]", "\n", "self", ".", "l2reg", "=", "0.", "\n", "self", ".", "batch_size", "=", "64", "\n", "self", ".", "maxepoch", "=", "1000", "\n", "self", ".", "early_stop", "=", "True", "\n", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "nclasses", ")", ",", "\n", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n", "self", ".", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "cuda", "(", ")", "\n", "self", ".", "loss_fn", "=", "self", ".", "loss_fn", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "loss_fn", ".", "size_average", "=", "False", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "weight_decay", "=", "self", ".", "l2reg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.prepare_data": [[64, 74], ["torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ",", "trainX", ",", "trainy", ",", "devX", ",", "devy", ",", "testX", ",", "testy", ")", ":", "\n", "# Transform probs to log-probs for KL-divergence", "\n", "        ", "trainX", "=", "torch", ".", "from_numpy", "(", "trainX", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trainy", "=", "torch", ".", "from_numpy", "(", "trainy", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "devX", "=", "torch", ".", "from_numpy", "(", "devX", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "devy", "=", "torch", ".", "from_numpy", "(", "devy", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "testX", "=", "torch", ".", "from_numpy", "(", "testX", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "testY", "=", "torch", ".", "from_numpy", "(", "testy", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "return", "trainX", ",", "trainy", ",", "devX", ",", "devy", ",", "testX", ",", "testy", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.run": [[75, 107], ["numpy.arange", "relatedness.RelatednessPytorch.prepare_data", "numpy.dot", "relatedness.RelatednessPytorch.trainepoch", "numpy.dot", "relatedness.RelatednessPytorch.predict_proba", "relatedness.RelatednessPytorch.predict_proba", "scipy.stats.spearmanr", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.prepare_data", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.trainepoch", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.predict_proba", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.predict_proba"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "nepoch", "=", "0", "\n", "bestpr", "=", "-", "1", "\n", "early_stop_count", "=", "0", "\n", "r", "=", "np", ".", "arange", "(", "1", ",", "6", ")", "\n", "stop_train", "=", "False", "\n", "\n", "# Preparing data", "\n", "trainX", ",", "trainy", ",", "devX", ",", "devy", ",", "testX", ",", "testy", "=", "self", ".", "prepare_data", "(", "\n", "self", ".", "train", "[", "'X'", "]", ",", "self", ".", "train", "[", "'y'", "]", ",", "\n", "self", ".", "valid", "[", "'X'", "]", ",", "self", ".", "valid", "[", "'y'", "]", ",", "\n", "self", ".", "test", "[", "'X'", "]", ",", "self", ".", "test", "[", "'y'", "]", ")", "\n", "\n", "# Training", "\n", "while", "not", "stop_train", "and", "self", ".", "nepoch", "<=", "self", ".", "maxepoch", ":", "\n", "            ", "self", ".", "trainepoch", "(", "trainX", ",", "trainy", ",", "nepoches", "=", "50", ")", "\n", "yhat", "=", "np", ".", "dot", "(", "self", ".", "predict_proba", "(", "devX", ")", ",", "r", ")", "\n", "pr", "=", "spearmanr", "(", "yhat", ",", "self", ".", "devscores", ")", "[", "0", "]", "\n", "pr", "=", "0", "if", "pr", "!=", "pr", "else", "pr", "# if NaN bc std=0", "\n", "# early stop on Pearson", "\n", "if", "pr", ">", "bestpr", ":", "\n", "                ", "bestpr", "=", "pr", "\n", "bestmodel", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "", "elif", "self", ".", "early_stop", ":", "\n", "                ", "if", "early_stop_count", ">=", "3", ":", "\n", "                    ", "stop_train", "=", "True", "\n", "", "early_stop_count", "+=", "1", "\n", "", "", "self", ".", "model", "=", "bestmodel", "\n", "\n", "yhat", "=", "np", ".", "dot", "(", "self", ".", "predict_proba", "(", "testX", ")", ",", "r", ")", "\n", "\n", "return", "bestpr", ",", "yhat", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.trainepoch": [[108, 128], ["relatedness.RelatednessPytorch.model.train", "range", "numpy.random.permutation", "range", "len", "len", "torch.from_numpy().long().cuda", "torch.from_numpy().long().cuda", "torch.from_numpy().long().cuda", "torch.from_numpy().long().cuda", "relatedness.RelatednessPytorch.model", "relatedness.RelatednessPytorch.loss_fn", "all_costs.append", "relatedness.RelatednessPytorch.optimizer.zero_grad", "relatedness.RelatednessPytorch.backward", "relatedness.RelatednessPytorch.optimizer.step", "relatedness.RelatednessPytorch.item", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train"], ["", "def", "trainepoch", "(", "self", ",", "X", ",", "y", ",", "nepoches", "=", "1", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "nepoch", ",", "self", ".", "nepoch", "+", "nepoches", ")", ":", "\n", "            ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "X", ")", ")", "\n", "all_costs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "X", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "# forward", "\n", "                ", "idx", "=", "torch", ".", "from_numpy", "(", "permutation", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "Xbatch", "=", "X", "[", "idx", "]", "\n", "ybatch", "=", "y", "[", "idx", "]", "\n", "output", "=", "self", ".", "model", "(", "Xbatch", ")", "\n", "# loss", "\n", "loss", "=", "self", ".", "loss_fn", "(", "output", ",", "ybatch", ")", "\n", "all_costs", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "# backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update parameters", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", "self", ".", "nepoch", "+=", "nepoches", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.relatedness.RelatednessPytorch.predict_proba": [[129, 140], ["relatedness.RelatednessPytorch.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "len", "relatedness.RelatednessPytorch.model().data.cpu().numpy", "numpy.concatenate", "relatedness.RelatednessPytorch.model().data.cpu", "relatedness.RelatednessPytorch.model().data.cpu().numpy", "relatedness.RelatednessPytorch.model().data.cpu", "relatedness.RelatednessPytorch.model", "relatedness.RelatednessPytorch.model"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "predict_proba", "(", "self", ",", "devX", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "probas", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "devX", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "Xbatch", "=", "devX", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "if", "len", "(", "probas", ")", "==", "0", ":", "\n", "                    ", "probas", "=", "self", ".", "model", "(", "Xbatch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "probas", "=", "np", ".", "concatenate", "(", "(", "probas", ",", "self", ".", "model", "(", "Xbatch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "axis", "=", "0", ")", "\n", "", "", "", "return", "probas", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.InnerKFoldClassifier.__init__": [[48, 61], ["validation.get_classif_name"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.get_classif_name"], ["def", "__init__", "(", "self", ",", "X", ",", "y", ",", "config", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "featdim", "=", "X", ".", "shape", "[", "1", "]", "\n", "self", ".", "nclasses", "=", "config", "[", "'nclasses'", "]", "\n", "self", ".", "seed", "=", "config", "[", "'seed'", "]", "\n", "self", ".", "devresults", "=", "[", "]", "\n", "self", ".", "testresults", "=", "[", "]", "\n", "self", ".", "usepytorch", "=", "config", "[", "'usepytorch'", "]", "\n", "self", ".", "classifier_config", "=", "config", "[", "'classifier'", "]", "\n", "self", ".", "modelname", "=", "get_classif_name", "(", "self", ".", "classifier_config", ",", "self", ".", "usepytorch", ")", "\n", "\n", "self", ".", "k", "=", "5", "if", "'kfold'", "not", "in", "config", "else", "config", "[", "'kfold'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.InnerKFoldClassifier.run": [[62, 113], ["logging.info", "sklearn.model_selection.StratifiedKFold", "sklearn.model_selection.StratifiedKFold", "sklearn.model_selection.StratifiedKFold.split", "round", "round", "logging.info", "validation.InnerKFoldClassifier.devresults.append", "validation.InnerKFoldClassifier.testresults.append", "numpy.mean", "numpy.mean", "sklearn.model_selection.StratifiedKFold.split", "scores.append", "numpy.max", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "round", "range", "range", "regscores.append", "round", "numpy.argmax", "numpy.max", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.score", "sklearn.linear_model.LogisticRegression.score", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Training {0} with (inner) {1}-fold cross-validation'", "\n", ".", "format", "(", "self", ".", "modelname", ",", "self", ".", "k", ")", ")", "\n", "\n", "regs", "=", "[", "10", "**", "t", "for", "t", "in", "range", "(", "-", "5", ",", "-", "1", ")", "]", "if", "self", ".", "usepytorch", "else", "[", "2", "**", "t", "for", "t", "in", "range", "(", "-", "2", ",", "4", ",", "1", ")", "]", "\n", "skf", "=", "StratifiedKFold", "(", "n_splits", "=", "self", ".", "k", ",", "shuffle", "=", "True", ",", "random_state", "=", "1111", ")", "\n", "innerskf", "=", "StratifiedKFold", "(", "n_splits", "=", "self", ".", "k", ",", "shuffle", "=", "True", ",", "\n", "random_state", "=", "1111", ")", "\n", "count", "=", "0", "\n", "for", "train_idx", ",", "test_idx", "in", "skf", ".", "split", "(", "self", ".", "X", ",", "self", ".", "y", ")", ":", "\n", "            ", "count", "+=", "1", "\n", "X_train", ",", "X_test", "=", "self", ".", "X", "[", "train_idx", "]", ",", "self", ".", "X", "[", "test_idx", "]", "\n", "y_train", ",", "y_test", "=", "self", ".", "y", "[", "train_idx", "]", ",", "self", ".", "y", "[", "test_idx", "]", "\n", "scores", "=", "[", "]", "\n", "for", "reg", "in", "regs", ":", "\n", "                ", "regscores", "=", "[", "]", "\n", "for", "inner_train_idx", ",", "inner_test_idx", "in", "innerskf", ".", "split", "(", "X_train", ",", "y_train", ")", ":", "\n", "                    ", "X_in_train", ",", "X_in_test", "=", "X_train", "[", "inner_train_idx", "]", ",", "X_train", "[", "inner_test_idx", "]", "\n", "y_in_train", ",", "y_in_test", "=", "y_train", "[", "inner_train_idx", "]", ",", "y_train", "[", "inner_test_idx", "]", "\n", "if", "self", ".", "usepytorch", ":", "\n", "                        ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "reg", ",", "\n", "seed", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "X_in_train", ",", "y_in_train", ",", "\n", "validation_data", "=", "(", "X_in_test", ",", "y_in_test", ")", ")", "\n", "", "else", ":", "\n", "                        ", "clf", "=", "LogisticRegression", "(", "C", "=", "reg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "X_in_train", ",", "y_in_train", ")", "\n", "", "regscores", ".", "append", "(", "clf", ".", "score", "(", "X_in_test", ",", "y_in_test", ")", ")", "\n", "", "scores", ".", "append", "(", "round", "(", "100", "*", "np", ".", "mean", "(", "regscores", ")", ",", "2", ")", ")", "\n", "", "optreg", "=", "regs", "[", "np", ".", "argmax", "(", "scores", ")", "]", "\n", "logging", ".", "info", "(", "'Best param found at split {0}: l2reg = {1} \\\n                with score {2}'", ".", "format", "(", "count", ",", "optreg", ",", "np", ".", "max", "(", "scores", ")", ")", ")", "\n", "self", ".", "devresults", ".", "append", "(", "np", ".", "max", "(", "scores", ")", ")", "\n", "\n", "if", "self", ".", "usepytorch", ":", "\n", "                ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "optreg", ",", "\n", "seed", "=", "self", ".", "seed", ")", "\n", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ",", "validation_split", "=", "0.05", ")", "\n", "", "else", ":", "\n", "                ", "clf", "=", "LogisticRegression", "(", "C", "=", "optreg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "\n", "", "self", ".", "testresults", ".", "append", "(", "round", "(", "100", "*", "clf", ".", "score", "(", "X_test", ",", "y_test", ")", ",", "2", ")", ")", "\n", "\n", "", "devaccuracy", "=", "round", "(", "np", ".", "mean", "(", "self", ".", "devresults", ")", ",", "2", ")", "\n", "testaccuracy", "=", "round", "(", "np", ".", "mean", "(", "self", ".", "testresults", ")", ",", "2", ")", "\n", "return", "devaccuracy", ",", "testaccuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.KFoldClassifier.__init__": [[119, 130], ["validation.get_classif_name"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.get_classif_name"], ["def", "__init__", "(", "self", ",", "train", ",", "test", ",", "config", ")", ":", "\n", "        ", "self", ".", "train", "=", "train", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "featdim", "=", "self", ".", "train", "[", "'X'", "]", ".", "shape", "[", "1", "]", "\n", "self", ".", "nclasses", "=", "config", "[", "'nclasses'", "]", "\n", "self", ".", "seed", "=", "config", "[", "'seed'", "]", "\n", "self", ".", "usepytorch", "=", "config", "[", "'usepytorch'", "]", "\n", "self", ".", "classifier_config", "=", "config", "[", "'classifier'", "]", "\n", "self", ".", "modelname", "=", "get_classif_name", "(", "self", ".", "classifier_config", ",", "self", ".", "usepytorch", ")", "\n", "\n", "self", ".", "k", "=", "5", "if", "'kfold'", "not", "in", "config", "else", "config", "[", "'kfold'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.KFoldClassifier.run": [[131, 187], ["logging.info", "sklearn.model_selection.StratifiedKFold", "logging.info", "numpy.max", "logging.info", "logging.info", "sklearn.linear_model.LogisticRegression.predict", "sklearn.linear_model.LogisticRegression.score", "round", "sklearn.model_selection.StratifiedKFold.split", "scores.append", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression.score", "scanscores.append", "round", "numpy.argmax", "range", "range", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "range", "numpy.mean", "str", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.predict", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit"], ["", "def", "run", "(", "self", ")", ":", "\n", "# cross-validation", "\n", "        ", "logging", ".", "info", "(", "'Training {0} with {1}-fold cross-validation'", "\n", ".", "format", "(", "self", ".", "modelname", ",", "self", ".", "k", ")", ")", "\n", "regs", "=", "[", "10", "**", "t", "for", "t", "in", "range", "(", "-", "5", ",", "-", "1", ")", "]", "if", "self", ".", "usepytorch", "else", "[", "2", "**", "t", "for", "t", "in", "range", "(", "-", "1", ",", "6", ",", "1", ")", "]", "\n", "skf", "=", "StratifiedKFold", "(", "n_splits", "=", "self", ".", "k", ",", "shuffle", "=", "True", ",", "\n", "random_state", "=", "self", ".", "seed", ")", "\n", "scores", "=", "[", "]", "\n", "\n", "for", "reg", "in", "regs", ":", "\n", "            ", "scanscores", "=", "[", "]", "\n", "for", "train_idx", ",", "test_idx", "in", "skf", ".", "split", "(", "self", ".", "train", "[", "'X'", "]", ",", "\n", "self", ".", "train", "[", "'y'", "]", ")", ":", "\n", "# Split data", "\n", "                ", "X_train", ",", "y_train", "=", "self", ".", "train", "[", "'X'", "]", "[", "train_idx", "]", ",", "self", ".", "train", "[", "'y'", "]", "[", "train_idx", "]", "\n", "\n", "X_test", ",", "y_test", "=", "self", ".", "train", "[", "'X'", "]", "[", "test_idx", "]", ",", "self", ".", "train", "[", "'y'", "]", "[", "test_idx", "]", "\n", "\n", "# Train classifier", "\n", "if", "self", ".", "usepytorch", ":", "\n", "                    ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "reg", ",", "\n", "seed", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ",", "validation_data", "=", "(", "X_test", ",", "y_test", ")", ")", "\n", "", "else", ":", "\n", "                    ", "clf", "=", "LogisticRegression", "(", "C", "=", "reg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "", "score", "=", "clf", ".", "score", "(", "X_test", ",", "y_test", ")", "\n", "scanscores", ".", "append", "(", "score", ")", "\n", "# Append mean score", "\n", "", "scores", ".", "append", "(", "round", "(", "100", "*", "np", ".", "mean", "(", "scanscores", ")", ",", "2", ")", ")", "\n", "\n", "# evaluation", "\n", "", "logging", ".", "info", "(", "[", "(", "'reg:'", "+", "str", "(", "regs", "[", "idx", "]", ")", ",", "scores", "[", "idx", "]", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "scores", ")", ")", "]", ")", "\n", "optreg", "=", "regs", "[", "np", ".", "argmax", "(", "scores", ")", "]", "\n", "devaccuracy", "=", "np", ".", "max", "(", "scores", ")", "\n", "logging", ".", "info", "(", "'Cross-validation : best param found is reg = {0} \\\n            with score {1}'", ".", "format", "(", "optreg", ",", "devaccuracy", ")", ")", "\n", "\n", "logging", ".", "info", "(", "'Evaluating...'", ")", "\n", "if", "self", ".", "usepytorch", ":", "\n", "            ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "optreg", ",", "\n", "seed", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "self", ".", "train", "[", "'X'", "]", ",", "self", ".", "train", "[", "'y'", "]", ",", "validation_split", "=", "0.05", ")", "\n", "", "else", ":", "\n", "            ", "clf", "=", "LogisticRegression", "(", "C", "=", "optreg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "self", ".", "train", "[", "'X'", "]", ",", "self", ".", "train", "[", "'y'", "]", ")", "\n", "", "yhat", "=", "clf", ".", "predict", "(", "self", ".", "test", "[", "'X'", "]", ")", "\n", "\n", "testaccuracy", "=", "clf", ".", "score", "(", "self", ".", "test", "[", "'X'", "]", ",", "self", ".", "test", "[", "'y'", "]", ")", "\n", "testaccuracy", "=", "round", "(", "100", "*", "testaccuracy", ",", "2", ")", "\n", "\n", "return", "devaccuracy", ",", "testaccuracy", ",", "yhat", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.__init__": [[193, 206], ["validation.get_classif_name"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.get_classif_name"], ["def", "__init__", "(", "self", ",", "X", ",", "y", ",", "config", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "nclasses", "=", "config", "[", "'nclasses'", "]", "\n", "self", ".", "featdim", "=", "self", ".", "X", "[", "'train'", "]", ".", "shape", "[", "1", "]", "\n", "self", ".", "seed", "=", "config", "[", "'seed'", "]", "\n", "self", ".", "usepytorch", "=", "config", "[", "'usepytorch'", "]", "\n", "self", ".", "classifier_config", "=", "config", "[", "'classifier'", "]", "\n", "self", ".", "cudaEfficient", "=", "False", "if", "'cudaEfficient'", "not", "in", "config", "else", "config", "[", "'cudaEfficient'", "]", "\n", "self", ".", "modelname", "=", "get_classif_name", "(", "self", ".", "classifier_config", ",", "self", ".", "usepytorch", ")", "\n", "self", ".", "noreg", "=", "False", "if", "'noreg'", "not", "in", "config", "else", "config", "[", "'noreg'", "]", "\n", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run": [[207, 252], ["logging.info", "logging.info", "numpy.max", "logging.info", "sklearn.linear_model.LogisticRegression", "logging.info", "sklearn.linear_model.LogisticRegression.score", "round", "scores.append", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "senteval.tools.classifier.MLP", "sklearn.linear_model.LogisticRegression.fit", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "round", "numpy.argmax", "range", "range", "range", "sklearn.linear_model.LogisticRegression.score", "str", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "logging", ".", "info", "(", "'Training {0} with standard validation..'", "\n", ".", "format", "(", "self", ".", "modelname", ")", ")", "\n", "regs", "=", "[", "10", "**", "t", "for", "t", "in", "range", "(", "-", "5", ",", "-", "1", ")", "]", "if", "self", ".", "usepytorch", "else", "[", "2", "**", "t", "for", "t", "in", "range", "(", "-", "2", ",", "4", ",", "1", ")", "]", "\n", "if", "self", ".", "noreg", ":", "\n", "            ", "regs", "=", "[", "1e-9", "if", "self", ".", "usepytorch", "else", "1e9", "]", "\n", "", "scores", "=", "[", "]", "\n", "for", "reg", "in", "regs", ":", "\n", "            ", "if", "self", ".", "usepytorch", ":", "\n", "                ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "reg", ",", "\n", "seed", "=", "self", ".", "seed", ",", "cudaEfficient", "=", "self", ".", "cudaEfficient", ")", "\n", "\n", "# TODO: Find a hack for reducing nb epoches in SNLI", "\n", "clf", ".", "fit", "(", "self", ".", "X", "[", "'train'", "]", ",", "self", ".", "y", "[", "'train'", "]", ",", "\n", "validation_data", "=", "(", "self", ".", "X", "[", "'valid'", "]", ",", "self", ".", "y", "[", "'valid'", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "clf", "=", "LogisticRegression", "(", "C", "=", "reg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "self", ".", "X", "[", "'train'", "]", ",", "self", ".", "y", "[", "'train'", "]", ")", "\n", "", "scores", ".", "append", "(", "round", "(", "100", "*", "clf", ".", "score", "(", "self", ".", "X", "[", "'valid'", "]", ",", "\n", "self", ".", "y", "[", "'valid'", "]", ")", ",", "2", ")", ")", "\n", "", "logging", ".", "info", "(", "[", "(", "'reg:'", "+", "str", "(", "regs", "[", "idx", "]", ")", ",", "scores", "[", "idx", "]", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "scores", ")", ")", "]", ")", "\n", "optreg", "=", "regs", "[", "np", ".", "argmax", "(", "scores", ")", "]", "\n", "devaccuracy", "=", "np", ".", "max", "(", "scores", ")", "\n", "logging", ".", "info", "(", "'Validation : best param found is reg = {0} with score \\\n            {1}'", ".", "format", "(", "optreg", ",", "devaccuracy", ")", ")", "\n", "clf", "=", "LogisticRegression", "(", "C", "=", "optreg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "logging", ".", "info", "(", "'Evaluating...'", ")", "\n", "if", "self", ".", "usepytorch", ":", "\n", "            ", "clf", "=", "MLP", "(", "self", ".", "classifier_config", ",", "inputdim", "=", "self", ".", "featdim", ",", "\n", "nclasses", "=", "self", ".", "nclasses", ",", "l2reg", "=", "optreg", ",", "\n", "seed", "=", "self", ".", "seed", ",", "cudaEfficient", "=", "self", ".", "cudaEfficient", ")", "\n", "\n", "# TODO: Find a hack for reducing nb epoches in SNLI", "\n", "clf", ".", "fit", "(", "self", ".", "X", "[", "'train'", "]", ",", "self", ".", "y", "[", "'train'", "]", ",", "\n", "validation_data", "=", "(", "self", ".", "X", "[", "'valid'", "]", ",", "self", ".", "y", "[", "'valid'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "clf", "=", "LogisticRegression", "(", "C", "=", "optreg", ",", "random_state", "=", "self", ".", "seed", ")", "\n", "clf", ".", "fit", "(", "self", ".", "X", "[", "'train'", "]", ",", "self", ".", "y", "[", "'train'", "]", ")", "\n", "\n", "", "testaccuracy", "=", "clf", ".", "score", "(", "self", ".", "X", "[", "'test'", "]", ",", "self", ".", "y", "[", "'test'", "]", ")", "\n", "testaccuracy", "=", "round", "(", "100", "*", "testaccuracy", ",", "2", ")", "\n", "return", "devaccuracy", ",", "testaccuracy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.get_classif_name": [[33, 42], ["None"], "function", ["None"], ["def", "get_classif_name", "(", "classifier_config", ",", "usepytorch", ")", ":", "\n", "    ", "if", "not", "usepytorch", ":", "\n", "        ", "modelname", "=", "'sklearn-LogReg'", "\n", "", "else", ":", "\n", "        ", "nhid", "=", "classifier_config", "[", "'nhid'", "]", "\n", "optim", "=", "'adam'", "if", "'optim'", "not", "in", "classifier_config", "else", "classifier_config", "[", "'optim'", "]", "\n", "bs", "=", "64", "if", "'batch_size'", "not", "in", "classifier_config", "else", "classifier_config", "[", "'batch_size'", "]", "\n", "modelname", "=", "'pytorch-MLP-nhid%s-%s-bs%s'", "%", "(", "nhid", ",", "optim", ",", "bs", ")", "\n", "", "return", "modelname", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.__init__": [[30, 42], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "inputdim", ",", "nclasses", ",", "l2reg", "=", "0.", ",", "batch_size", "=", "64", ",", "seed", "=", "1111", ",", "\n", "cudaEfficient", "=", "False", ")", ":", "\n", "# fix seed", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "self", ".", "inputdim", "=", "inputdim", "\n", "self", ".", "nclasses", "=", "nclasses", "\n", "self", ".", "l2reg", "=", "l2reg", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "cudaEfficient", "=", "cudaEfficient", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.prepare_split": [[43, 64], ["torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "numpy.random.permutation", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "int", "int", "len", "len"], "methods", ["None"], ["", "def", "prepare_split", "(", "self", ",", "X", ",", "y", ",", "validation_data", "=", "None", ",", "validation_split", "=", "None", ")", ":", "\n", "# Preparing validation data", "\n", "        ", "assert", "validation_split", "or", "validation_data", "\n", "if", "validation_data", "is", "not", "None", ":", "\n", "            ", "trainX", ",", "trainy", "=", "X", ",", "y", "\n", "devX", ",", "devy", "=", "validation_data", "\n", "", "else", ":", "\n", "            ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "X", ")", ")", "\n", "trainidx", "=", "permutation", "[", "int", "(", "validation_split", "*", "len", "(", "X", ")", ")", ":", "]", "\n", "devidx", "=", "permutation", "[", "0", ":", "int", "(", "validation_split", "*", "len", "(", "X", ")", ")", "]", "\n", "trainX", ",", "trainy", "=", "X", "[", "trainidx", "]", ",", "y", "[", "trainidx", "]", "\n", "devX", ",", "devy", "=", "X", "[", "devidx", "]", ",", "y", "[", "devidx", "]", "\n", "\n", "", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "if", "self", ".", "cudaEfficient", "else", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "trainX", "=", "torch", ".", "from_numpy", "(", "trainX", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "trainy", "=", "torch", ".", "from_numpy", "(", "trainy", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "devX", "=", "torch", ".", "from_numpy", "(", "devX", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "devy", "=", "torch", ".", "from_numpy", "(", "devy", ")", ".", "to", "(", "device", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "\n", "return", "trainX", ",", "trainy", ",", "devX", ",", "devy", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.fit": [[65, 89], ["classifier.PyTorchClassifier.prepare_split", "classifier.PyTorchClassifier.trainepoch", "classifier.PyTorchClassifier.score", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.prepare_split", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.trainepoch", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", ",", "validation_data", "=", "None", ",", "validation_split", "=", "None", ",", "\n", "early_stop", "=", "True", ")", ":", "\n", "        ", "self", ".", "nepoch", "=", "0", "\n", "bestaccuracy", "=", "-", "1", "\n", "stop_train", "=", "False", "\n", "early_stop_count", "=", "0", "\n", "\n", "# Preparing validation data", "\n", "trainX", ",", "trainy", ",", "devX", ",", "devy", "=", "self", ".", "prepare_split", "(", "X", ",", "y", ",", "validation_data", ",", "\n", "validation_split", ")", "\n", "\n", "# Training", "\n", "while", "not", "stop_train", "and", "self", ".", "nepoch", "<=", "self", ".", "max_epoch", ":", "\n", "            ", "self", ".", "trainepoch", "(", "trainX", ",", "trainy", ",", "epoch_size", "=", "self", ".", "epoch_size", ")", "\n", "accuracy", "=", "self", ".", "score", "(", "devX", ",", "devy", ")", "\n", "if", "accuracy", ">", "bestaccuracy", ":", "\n", "                ", "bestaccuracy", "=", "accuracy", "\n", "bestmodel", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "", "elif", "early_stop", ":", "\n", "                ", "if", "early_stop_count", ">=", "self", ".", "tenacity", ":", "\n", "                    ", "stop_train", "=", "True", "\n", "", "early_stop_count", "+=", "1", "\n", "", "", "self", ".", "model", "=", "bestmodel", "\n", "return", "bestaccuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.trainepoch": [[90, 115], ["classifier.PyTorchClassifier.model.train", "range", "numpy.random.permutation", "range", "len", "len", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "torch.from_numpy().long().to", "classifier.PyTorchClassifier.model", "classifier.PyTorchClassifier.loss_fn", "all_costs.append", "classifier.PyTorchClassifier.optimizer.zero_grad", "classifier.PyTorchClassifier.backward", "classifier.PyTorchClassifier.optimizer.step", "Xbatch.cuda.cuda.cuda", "ybatch.cuda.cuda.cuda", "classifier.PyTorchClassifier.data.item", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.scd.trainers.CLTrainer.train"], ["", "def", "trainepoch", "(", "self", ",", "X", ",", "y", ",", "epoch_size", "=", "1", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "nepoch", ",", "self", ".", "nepoch", "+", "epoch_size", ")", ":", "\n", "            ", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "X", ")", ")", "\n", "all_costs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "X", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "# forward", "\n", "                ", "idx", "=", "torch", ".", "from_numpy", "(", "permutation", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", ")", ".", "long", "(", ")", ".", "to", "(", "X", ".", "device", ")", "\n", "\n", "Xbatch", "=", "X", "[", "idx", "]", "\n", "ybatch", "=", "y", "[", "idx", "]", "\n", "\n", "if", "self", ".", "cudaEfficient", ":", "\n", "                    ", "Xbatch", "=", "Xbatch", ".", "cuda", "(", ")", "\n", "ybatch", "=", "ybatch", ".", "cuda", "(", ")", "\n", "", "output", "=", "self", ".", "model", "(", "Xbatch", ")", "\n", "# loss", "\n", "loss", "=", "self", ".", "loss_fn", "(", "output", ",", "ybatch", ")", "\n", "all_costs", ".", "append", "(", "loss", ".", "data", ".", "item", "(", ")", ")", "\n", "# backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# Update parameters", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", "self", ".", "nepoch", "+=", "epoch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.score": [[116, 134], ["classifier.PyTorchClassifier.model.eval", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "isinstance", "len", "classifier.PyTorchClassifier.model", "pred.long().eq().sum().item", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "Xbatch.cuda.cuda.cuda", "ybatch.cuda.cuda.cuda", "classifier.PyTorchClassifier.data.max", "pred.long().eq().sum", "pred.long().eq", "ybatch.cuda.cuda.data.long", "pred.long"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "score", "(", "self", ",", "devX", ",", "devy", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "correct", "=", "0", "\n", "if", "not", "isinstance", "(", "devX", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", "or", "self", ".", "cudaEfficient", ":", "\n", "            ", "devX", "=", "torch", ".", "FloatTensor", "(", "devX", ")", ".", "cuda", "(", ")", "\n", "devy", "=", "torch", ".", "LongTensor", "(", "devy", ")", ".", "cuda", "(", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "devX", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "Xbatch", "=", "devX", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "ybatch", "=", "devy", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "if", "self", ".", "cudaEfficient", ":", "\n", "                    ", "Xbatch", "=", "Xbatch", ".", "cuda", "(", ")", "\n", "ybatch", "=", "ybatch", ".", "cuda", "(", ")", "\n", "", "output", "=", "self", ".", "model", "(", "Xbatch", ")", "\n", "pred", "=", "output", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "correct", "+=", "pred", ".", "long", "(", ")", ".", "eq", "(", "ybatch", ".", "data", ".", "long", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "accuracy", "=", "1.0", "*", "correct", "/", "len", "(", "devX", ")", "\n", "", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.predict": [[135, 148], ["classifier.PyTorchClassifier.model.eval", "numpy.array", "numpy.vstack", "isinstance", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "classifier.PyTorchClassifier.model", "numpy.append", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "[].cpu().numpy", "[].cpu", "classifier.PyTorchClassifier.data.max"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "predict", "(", "self", ",", "devX", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "not", "isinstance", "(", "devX", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "            ", "devX", "=", "torch", ".", "FloatTensor", "(", "devX", ")", ".", "cuda", "(", ")", "\n", "", "yhat", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "devX", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "Xbatch", "=", "devX", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "output", "=", "self", ".", "model", "(", "Xbatch", ")", "\n", "yhat", "=", "np", ".", "append", "(", "yhat", ",", "\n", "output", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "yhat", "=", "np", ".", "vstack", "(", "yhat", ")", "\n", "return", "yhat", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.PyTorchClassifier.predict_proba": [[149, 161], ["classifier.PyTorchClassifier.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "torch.softmax", "torch.softmax", "classifier.PyTorchClassifier.model().data.cpu().numpy", "numpy.concatenate", "classifier.PyTorchClassifier.model().data.cpu", "classifier.PyTorchClassifier.model"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.engine.SE.eval"], ["", "def", "predict_proba", "(", "self", ",", "devX", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "probas", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "devX", ")", ",", "self", ".", "batch_size", ")", ":", "\n", "                ", "Xbatch", "=", "devX", "[", "i", ":", "i", "+", "self", ".", "batch_size", "]", "\n", "vals", "=", "F", ".", "softmax", "(", "self", ".", "model", "(", "Xbatch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "not", "probas", ":", "\n", "                    ", "probas", "=", "vals", "\n", "", "else", ":", "\n", "                    ", "probas", "=", "np", ".", "concatenate", "(", "probas", ",", "vals", ",", "axis", "=", "0", ")", "\n", "", "", "", "return", "probas", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.classifier.MLP.__init__": [[168, 208], ["classifier.PyTorchClassifier.__init__", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "senteval.utils.get_optimizer", "optim_fn", "torch.nn.Sequential().cuda", "torch.nn.Sequential().cuda", "torch.nn.Sequential().cuda", "torch.nn.Sequential().cuda", "classifier.MLP.model.parameters", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.senteval.utils.get_optimizer"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "inputdim", ",", "nclasses", ",", "l2reg", "=", "0.", ",", "batch_size", "=", "64", ",", "\n", "seed", "=", "1111", ",", "cudaEfficient", "=", "False", ")", ":", "\n", "        ", "super", "(", "self", ".", "__class__", ",", "self", ")", ".", "__init__", "(", "inputdim", ",", "nclasses", ",", "l2reg", ",", "\n", "batch_size", ",", "seed", ",", "cudaEfficient", ")", "\n", "\"\"\"\n        PARAMETERS:\n        -nhid:       number of hidden units (0: Logistic Regression)\n        -optim:      optimizer (\"sgd,lr=0.1\", \"adam\", \"rmsprop\" ..)\n        -tenacity:   how many times dev acc does not increase before stopping\n        -epoch_size: each epoch corresponds to epoch_size pass on the train set\n        -max_epoch:  max number of epoches\n        -dropout:    dropout for MLP\n        \"\"\"", "\n", "\n", "self", ".", "nhid", "=", "0", "if", "\"nhid\"", "not", "in", "params", "else", "params", "[", "\"nhid\"", "]", "\n", "self", ".", "optim", "=", "\"adam\"", "if", "\"optim\"", "not", "in", "params", "else", "params", "[", "\"optim\"", "]", "\n", "self", ".", "tenacity", "=", "5", "if", "\"tenacity\"", "not", "in", "params", "else", "params", "[", "\"tenacity\"", "]", "\n", "self", ".", "epoch_size", "=", "4", "if", "\"epoch_size\"", "not", "in", "params", "else", "params", "[", "\"epoch_size\"", "]", "\n", "self", ".", "max_epoch", "=", "200", "if", "\"max_epoch\"", "not", "in", "params", "else", "params", "[", "\"max_epoch\"", "]", "\n", "self", ".", "dropout", "=", "0.", "if", "\"dropout\"", "not", "in", "params", "else", "params", "[", "\"dropout\"", "]", "\n", "self", ".", "batch_size", "=", "64", "if", "\"batch_size\"", "not", "in", "params", "else", "params", "[", "\"batch_size\"", "]", "\n", "\n", "if", "params", "[", "\"nhid\"", "]", "==", "0", ":", "\n", "            ", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "nclasses", ")", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "params", "[", "\"nhid\"", "]", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "params", "[", "\"nhid\"", "]", ",", "self", ".", "nclasses", ")", ",", "\n", ")", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "self", ".", "loss_fn", ".", "size_average", "=", "False", "\n", "\n", "optim_fn", ",", "optim_params", "=", "utils", ".", "get_optimizer", "(", "self", ".", "optim", ")", "\n", "self", ".", "optimizer", "=", "optim_fn", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "**", "optim_params", ")", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'weight_decay'", "]", "=", "self", ".", "l2reg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__": [[26, 49], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.__init__"], ["class", "MLPLayer", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Head for getting sentence representations over RoBERTa/BERT's CLS representation.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n", "\n", "", "", "class", "Similarity", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Dot product or cosine similarity\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "temp", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda": [[50, 53], ["None"], "methods", ["None"], ["self", ".", "temp", "=", "temp", "\n", "self", ".", "cos", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.forward": [[54, 92], ["sent_len_sorted.copy.copy.copy", "numpy.argsort", "sent.index_select.index_select.index_select", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "sent_output.index_select.index_select.index_select", "numpy.argsort", "models.InferSent.is_cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "models.InferSent.enc_lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "models.InferSent.is_cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.FloatTensor().unsqueeze().cuda", "torch.FloatTensor().unsqueeze().cuda", "torch.FloatTensor().unsqueeze().cuda", "torch.FloatTensor().unsqueeze().cuda", "torch.sum().squeeze", "torch.sum().squeeze", "torch.sum().squeeze", "torch.sum().squeeze", "numpy.sort", "torch.FloatTensor().unsqueeze().cuda.expand_as", "torch.FloatTensor().unsqueeze().cuda.expand_as", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "emb.squeeze.squeeze.ndimension", "emb.squeeze.squeeze.squeeze", "emb.squeeze.squeeze.ndimension", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().unsqueeze().cuda.copy", "torch.FloatTensor().unsqueeze().cuda.copy"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda"], ["        ", "return", "self", ".", "cos", "(", "x", ",", "y", ")", "/", "self", ".", "temp", "\n", "\n", "\n", "", "", "class", "Pooler", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Parameter-free poolers to get the sentence embedding\n    'cls': [CLS] representation with BERT/RoBERTa's MLP pooler.\n    'cls_before_pooler': [CLS] representation without the original MLP pooler.\n    'avg': average of the last layers' hidden states at each token.\n    'avg_top2': average of the last two layers.\n    'avg_first_last': average of the first and the last layers.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "pooler_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pooler_type", "=", "pooler_type", "\n", "assert", "self", ".", "pooler_type", "in", "[", "\"cls\"", ",", "\"cls_before_pooler\"", ",", "\"avg\"", ",", "\"avg_top2\"", ",", "\n", "\"avg_first_last\"", "]", ",", "\"unrecognized pooling type %s\"", "%", "self", ".", "pooler_type", "\n", "\n", "", "def", "forward", "(", "self", ",", "attention_mask", ",", "outputs", ")", ":", "\n", "        ", "last_hidden", "=", "outputs", ".", "last_hidden_state", "\n", "pooler_output", "=", "outputs", ".", "pooler_output", "\n", "hidden_states", "=", "outputs", ".", "hidden_states", "\n", "\n", "if", "self", ".", "pooler_type", "in", "[", "'cls_before_pooler'", ",", "'cls'", "]", ":", "\n", "            ", "return", "last_hidden", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg\"", ":", "\n", "            ", "return", "(", "(", "last_hidden", "*", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg_first_last\"", ":", "\n", "            ", "first_hidden", "=", "hidden_states", "[", "0", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "first_hidden", "+", "last_hidden", ")", "/", "2.0", "*", "\n", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "pooled_result", "\n", "", "elif", "self", ".", "pooler_type", "==", "\"avg_top2\"", ":", "\n", "            ", "second_last_hidden", "=", "hidden_states", "[", "-", "2", "]", "\n", "last_hidden", "=", "hidden_states", "[", "-", "1", "]", "\n", "pooled_result", "=", "(", "(", "last_hidden", "+", "second_last_hidden", ")", "/", "2.0", "*", "\n", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "sum", "(", "1", ")", "/", "attention_mask", ".", "sum", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.set_w2v_path": [[93, 95], ["None"], "methods", ["None"], ["return", "pooled_result", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_word_dict": [[96, 107], ["s.split", "models.InferSent.tokenize"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.tokenize"], ["\n", "\n", "", "", "", "class", "BatchNormWrapper", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "m", ")", ":", "\n", "        ", "super", "(", "BatchNormWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "m", ".", "eval", "(", ")", "# Set the batch norm to eval mode", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "input_type", "=", "x", ".", "dtype", "\n", "x", "=", "self", ".", "m", "(", "x", ".", "float", "(", ")", ")", "\n", "return", "x", ".", "to", "(", "input_type", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_w2v": [[108, 119], ["hasattr", "print", "open", "line.split", "numpy.fromstring", "len", "len"], "methods", ["None"], ["\n", "\n", "", "", "def", "cl_init", "(", "cls", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    Contrastive learning class init function.\n    \"\"\"", "\n", "cls", ".", "pooler_type", "=", "cls", ".", "model_args", ".", "pooler_type", "\n", "cls", ".", "pooler", "=", "Pooler", "(", "cls", ".", "model_args", ".", "pooler_type", ")", "\n", "cls", ".", "mlp", "=", "MLPLayer", "(", "config", ")", "\n", "cls", ".", "sim", "=", "Similarity", "(", "temp", "=", "cls", ".", "model_args", ".", "temp", ")", "\n", "\n", "# SCD - BEGIN: projector", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_w2v_k": [[120, 138], ["hasattr", "open", "line.split", "numpy.fromstring", "all", "numpy.fromstring"], "methods", ["None"], ["sizes", "=", "[", "cls", ".", "config", ".", "embedding_dim", "]", "+", "list", "(", "map", "(", "int", ",", "cls", ".", "config", ".", "projector", ".", "split", "(", "'-'", ")", ")", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "sizes", ")", "-", "2", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "bias", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "i", "]", ",", "sizes", "[", "i", "+", "1", "]", ",", "bias", "=", "False", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "i", "+", "1", "]", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sizes", "[", "-", "2", "]", ",", "sizes", "[", "-", "1", "]", ",", "bias", "=", "False", ")", ")", "\n", "cls", ".", "projector", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "cls", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "sizes", "[", "-", "1", "]", ",", "affine", "=", "False", ")", "\n", "# SCD - END: projector", "\n", "\n", "cls", ".", "init_weights", "(", ")", "\n", "\n", "\n", "", "def", "normalize", "(", "vec", ")", ":", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.build_vocab": [[139, 144], ["hasattr", "models.InferSent.get_word_dict", "models.InferSent.get_w2v", "print", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_word_dict", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_w2v"], ["    ", "return", "vec", ".", "div", "(", "torch", ".", "norm", "(", "vec", ",", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "\n", "", "def", "off_diagonal", "(", "x", ")", ":", "\n", "# return a flattened view of the off-diagonal elements of a square matrix", "\n", "    ", "n", ",", "m", "=", "x", ".", "shape", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.build_vocab_k_words": [[146, 150], ["hasattr", "models.InferSent.get_w2v_k", "print"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_w2v_k"], ["return", "x", ".", "flatten", "(", ")", "[", ":", "-", "1", "]", ".", "view", "(", "n", "-", "1", ",", "n", "+", "1", ")", "[", ":", ",", "1", ":", "]", ".", "flatten", "(", ")", "\n", "\n", "\n", "", "def", "cl_forward", "(", "cls", ",", "\n", "encoder", ",", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.update_vocab": [[151, 168], ["hasattr", "hasattr", "models.InferSent.get_word_dict", "print", "models.InferSent.get_w2v", "models.InferSent.word_vec.update", "len", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_word_dict", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_w2v"], ["input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", "mlm_input_ids", "=", "None", ",", "\n", "mlm_labels", "=", "None", ",", "\n", ")", ":", "\n", "    ", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "cls", ".", "config", ".", "use_return_dict", "\n", "ori_input_ids", "=", "input_ids", "\n", "batch_size", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "# Number of sentences in one instance", "\n", "# 2: pair instance; 3: pair instance with a hard negative", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_batch": [[169, 179], ["numpy.zeros", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "range", "len", "len", "len"], "methods", ["None"], ["num_sent", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "\n", "mlm_outputs", "=", "None", "\n", "# Flatten input for encoding", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "\n", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent, len)", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "\n", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent len)", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "        ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "\n", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs * num_sent, len)", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.tokenize": [[180, 188], ["s.replace.replace.replace", "s.replace.replace.split", "word_tokenize", "word_tokenize"], "methods", ["None"], ["\n", "# Get raw embeddings", "\n", "", "outputs", "=", "encoder", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.prepare_samples": [[189, 215], ["numpy.sum", "range", "numpy.array", "numpy.sum", "len", "print", "numpy.argsort", "numpy.array", "len", "warnings.warn", "len", "numpy.sort", "s.split", "models.InferSent.tokenize"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.tokenize"], ["output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "True", "if", "cls", ".", "model_args", ".", "pooler_type", "in", "[", "\n", "'avg_top2'", ",", "'avg_first_last'", "]", "else", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "\n", "# MLM auxiliary objective", "\n", "if", "mlm_input_ids", "is", "not", "None", ":", "\n", "        ", "mlm_input_ids", "=", "mlm_input_ids", ".", "view", "(", "(", "-", "1", ",", "mlm_input_ids", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "mlm_outputs", "=", "encoder", "(", "\n", "mlm_input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "True", "if", "cls", ".", "model_args", ".", "pooler_type", "in", "[", "\n", "'avg_top2'", ",", "'avg_first_last'", "]", "else", "False", ",", "\n", "return_dict", "=", "True", ",", "\n", ")", "\n", "\n", "# Pooling", "\n", "", "pooler_output", "=", "cls", ".", "pooler", "(", "attention_mask", ",", "outputs", ")", "\n", "pooler_output", "=", "pooler_output", ".", "view", "(", "\n", "(", "batch_size", ",", "num_sent", ",", "pooler_output", ".", "size", "(", "-", "1", ")", ")", ")", "# (bs, num_sent, hidden)", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode": [[216, 240], ["time.time", "models.InferSent.prepare_samples", "range", "numpy.vstack", "numpy.argsort", "len", "models.InferSent.get_batch", "models.InferSent.is_cuda", "numpy.vstack.append", "print", "models.InferSent.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "models.InferSent.forward().data.cpu().numpy", "models.InferSent.forward().data.cpu", "len", "models.InferSent.is_cuda", "time.time", "models.InferSent.forward"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.prepare_samples", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_batch", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.forward"], ["# If using \"cls\", we add an extra MLP layer", "\n", "# (same as BERT's original implementation) over the representation.", "\n", "if", "cls", ".", "pooler_type", "==", "\"cls\"", ":", "\n", "        ", "pooler_output", "=", "cls", ".", "mlp", "(", "pooler_output", ")", "\n", "\n", "# Separate representation", "\n", "", "z1", ",", "z2", "=", "pooler_output", "[", ":", ",", "0", "]", ",", "pooler_output", "[", ":", ",", "1", "]", "\n", "\n", "# SCD BEGIN: SimCSE legacy code", "\n", "\n", "# Hard negative", "\n", "# if num_sent == 3:", "\n", "#    z3 = pooler_output[:, 2]", "\n", "\n", "# SCD END: SimCSE legacy code", "\n", "\n", "# Gather all embeddings if using distributed training", "\n", "if", "dist", ".", "is_initialized", "(", ")", "and", "cls", ".", "training", ":", "\n", "# Gather hard negative", "\n", "        ", "if", "num_sent", ">=", "3", ":", "\n", "            ", "z3_list", "=", "[", "torch", ".", "zeros_like", "(", "z3", ")", "\n", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z3_list", ",", "tensor", "=", "z3", ".", "contiguous", "(", ")", ")", "\n", "z3_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z3", "\n", "z3", "=", "torch", ".", "cat", "(", "z3_list", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.visualize": [[241, 271], ["models.InferSent.get_batch", "models.InferSent.is_cuda", "torch.max", "torch.max", "torch.max", "torch.max", "idxs.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "range", "plt.xticks", "plt.bar", "plt.ylabel", "plt.title", "plt.show", "sent.split", "models.InferSent.tokenize", "warnings.warn", "batch.cuda.cuda.cuda", "models.InferSent.enc_lstm", "numpy.sum", "len", "idxs.data.cpu().numpy.data.cpu().numpy.data.cpu", "range", "numpy.sum", "len"], "methods", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.get_batch", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.is_cuda", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.tokenize"], ["\n", "# Dummy vectors for allgather", "\n", "", "z1_list", "=", "[", "torch", ".", "zeros_like", "(", "z1", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "z2_list", "=", "[", "torch", ".", "zeros_like", "(", "z2", ")", "for", "_", "in", "range", "(", "dist", ".", "get_world_size", "(", ")", ")", "]", "\n", "# Allgather", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z1_list", ",", "tensor", "=", "z1", ".", "contiguous", "(", ")", ")", "\n", "dist", ".", "all_gather", "(", "tensor_list", "=", "z2_list", ",", "tensor", "=", "z2", ".", "contiguous", "(", ")", ")", "\n", "\n", "# Since allgather results do not have gradients, we replace the", "\n", "# current process's corresponding embeddings with original tensors", "\n", "z1_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z1", "\n", "z2_list", "[", "dist", ".", "get_rank", "(", ")", "]", "=", "z2", "\n", "# Get full batch embeddings: (bs x N, hidden)", "\n", "z1", "=", "torch", ".", "cat", "(", "z1_list", ",", "0", ")", "\n", "z2", "=", "torch", ".", "cat", "(", "z2_list", ",", "0", ")", "\n", "\n", "", "lambd", "=", "cls", ".", "config", ".", "task_lambda", "\n", "\n", "# empirical cross-correlation matrix", "\n", "c", "=", "cls", ".", "bn", "(", "cls", ".", "projector", "(", "\n", "(", "pooler_output", "[", ":", ",", "0", "]", ")", ")", ")", ".", "T", "@", "cls", ".", "bn", "(", "cls", ".", "projector", "(", "(", "pooler_output", "[", ":", ",", "1", "]", ")", ")", ")", "\n", "\n", "# sum the cross-correlation matrix between all gpus", "\n", "c", ".", "div_", "(", "len", "(", "z1", ")", ")", "\n", "\n", "on_diag", "=", "torch", ".", "diagonal", "(", "c", ")", ".", "add_", "(", "-", "1", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "off_diag", "=", "off_diagonal", "(", "c", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", "\n", "\n", "decorrelation", "=", "on_diag", "+", "lambd", "*", "off_diag", "\n", "\n", "self_contrast", "=", "torch", ".", "diag", "(", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.gensen.prepare": [[34, 36], ["None"], "function", ["None"], ["def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.gensen.batcher": [[37, 44], ["gensen.get_representation"], "function", ["None"], ["", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "    ", "batch", "=", "[", "' '", ".", "join", "(", "sent", ")", "if", "sent", "!=", "[", "]", "else", "'.'", "for", "sent", "in", "batch", "]", "\n", "_", ",", "reps_h_t", "=", "gensen", ".", "get_representation", "(", "\n", "sentences", ",", "pool", "=", "'last'", ",", "return_numpy", "=", "True", ",", "tokenize", "=", "True", "\n", ")", "\n", "embeddings", "=", "reps_h_t", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.infersent.prepare": [[42, 44], ["params.infersent.build_vocab"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.build_vocab"], ["def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "params", ".", "infersent", ".", "build_vocab", "(", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "samples", "]", ",", "tokenize", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.infersent.batcher": [[46, 50], ["params.infersent.encode"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode"], ["", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "    ", "sentences", "=", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "]", "\n", "embeddings", "=", "params", ".", "infersent", ".", "encode", "(", "sentences", ",", "bsize", "=", "params", ".", "batch_size", ",", "tokenize", "=", "False", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.skipthought.prepare": [[37, 39], ["None"], "function", ["None"], ["def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.skipthought.batcher": [[40, 45], ["skipthoughts.encode", "str"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.models.InferSent.encode"], ["", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "    ", "batch", "=", "[", "str", "(", "' '", ".", "join", "(", "sent", ")", ",", "errors", "=", "\"ignore\"", ")", "if", "sent", "!=", "[", "]", "else", "'.'", "for", "sent", "in", "batch", "]", "\n", "embeddings", "=", "skipthoughts", ".", "encode", "(", "params", "[", "'encoder'", "]", ",", "batch", ",", "\n", "verbose", "=", "False", ",", "use_eos", "=", "True", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.create_dictionary": [[33, 57], ["sorted", "enumerate", "words.items", "id2word.append", "words.get"], "function", ["None"], ["def", "create_dictionary", "(", "sentences", ",", "threshold", "=", "0", ")", ":", "\n", "    ", "words", "=", "{", "}", "\n", "for", "s", "in", "sentences", ":", "\n", "        ", "for", "word", "in", "s", ":", "\n", "            ", "words", "[", "word", "]", "=", "words", ".", "get", "(", "word", ",", "0", ")", "+", "1", "\n", "\n", "", "", "if", "threshold", ">", "0", ":", "\n", "        ", "newwords", "=", "{", "}", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "words", "[", "word", "]", ">=", "threshold", ":", "\n", "                ", "newwords", "[", "word", "]", "=", "words", "[", "word", "]", "\n", "", "", "words", "=", "newwords", "\n", "", "words", "[", "'<s>'", "]", "=", "1e9", "+", "4", "\n", "words", "[", "'</s>'", "]", "=", "1e9", "+", "3", "\n", "words", "[", "'<p>'", "]", "=", "1e9", "+", "2", "\n", "\n", "sorted_words", "=", "sorted", "(", "words", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "# inverse sort", "\n", "id2word", "=", "[", "]", "\n", "word2id", "=", "{", "}", "\n", "for", "i", ",", "(", "w", ",", "_", ")", "in", "enumerate", "(", "sorted_words", ")", ":", "\n", "        ", "id2word", ".", "append", "(", "w", ")", "\n", "word2id", "[", "w", "]", "=", "i", "\n", "\n", "", "return", "id2word", ",", "word2id", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.get_wordvec": [[59, 72], ["logging.info", "io.open", "line.split", "len", "len", "numpy.fromstring"], "function", ["None"], ["", "def", "get_wordvec", "(", "path_to_vec", ",", "word2id", ")", ":", "\n", "    ", "word_vec", "=", "{", "}", "\n", "\n", "with", "io", ".", "open", "(", "path_to_vec", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "# if word2vec or fasttext file : skip first line \"next(f)\"", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "word", ",", "vec", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "if", "word", "in", "word2id", ":", "\n", "                ", "word_vec", "[", "word", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "'Found {0} words with word vectors, out of \\\n        {1} words'", ".", "format", "(", "len", "(", "word_vec", ")", ",", "len", "(", "word2id", ")", ")", ")", "\n", "return", "word_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.prepare": [[75, 80], ["bow.create_dictionary", "bow.get_wordvec"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.create_dictionary", "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.get_wordvec"], ["", "def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "_", ",", "params", ".", "word2id", "=", "create_dictionary", "(", "samples", ")", "\n", "params", ".", "word_vec", "=", "get_wordvec", "(", "PATH_TO_VEC", ",", "params", ".", "word2id", ")", "\n", "params", ".", "wvec_dim", "=", "300", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.bow.batcher": [[81, 98], ["numpy.vstack", "numpy.mean", "np.vstack.append", "numpy.zeros", "np.mean.append", "np.mean.append"], "function", ["None"], ["", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "    ", "batch", "=", "[", "sent", "if", "sent", "!=", "[", "]", "else", "[", "'.'", "]", "for", "sent", "in", "batch", "]", "\n", "embeddings", "=", "[", "]", "\n", "\n", "for", "sent", "in", "batch", ":", "\n", "        ", "sentvec", "=", "[", "]", "\n", "for", "word", "in", "sent", ":", "\n", "            ", "if", "word", "in", "params", ".", "word_vec", ":", "\n", "                ", "sentvec", ".", "append", "(", "params", ".", "word_vec", "[", "word", "]", ")", "\n", "", "", "if", "not", "sentvec", ":", "\n", "            ", "vec", "=", "np", ".", "zeros", "(", "params", ".", "wvec_dim", ")", "\n", "sentvec", ".", "append", "(", "vec", ")", "\n", "", "sentvec", "=", "np", ".", "mean", "(", "sentvec", ",", "0", ")", "\n", "embeddings", ".", "append", "(", "sentvec", ")", "\n", "\n", "", "embeddings", "=", "np", ".", "vstack", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.prepare": [[35, 37], ["None"], "function", ["None"], ["def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.batcher": [[38, 42], ["None"], "function", ["None"], ["", "def", "batcher", "(", "params", ",", "batch", ")", ":", "\n", "    ", "batch", "=", "[", "' '", ".", "join", "(", "sent", ")", "if", "sent", "!=", "[", "]", "else", "'.'", "for", "sent", "in", "batch", "]", "\n", "embeddings", "=", "params", "[", "'google_use'", "]", "(", "batch", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.examples.googleuse.make_embed_fn": [[43, 50], ["tensorflow.Graph().as_default", "tensorflow.placeholder", "tensorflow_hub.Module", "hub.Module.", "tensorflow.train.MonitoredSession", "tf.train.MonitoredSession.run", "tensorflow.Graph"], "function", ["home.repos.pwc.inspect_result.SAP-samples_acl2022-self-contrastive-decorrelation.tools.validation.SplitClassifier.run"], ["", "def", "make_embed_fn", "(", "module", ")", ":", "\n", "  ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "sentences", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ")", "\n", "embed", "=", "hub", ".", "Module", "(", "module", ")", "\n", "embeddings", "=", "embed", "(", "sentences", ")", "\n", "session", "=", "tf", ".", "train", ".", "MonitoredSession", "(", ")", "\n", "", "return", "lambda", "x", ":", "session", ".", "run", "(", "embeddings", ",", "{", "sentences", ":", "x", "}", ")", "\n", "\n"]]}