{"home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.None.construct_dataset.main": [[11, 33], ["pathlib.Path().mkdir", "os.walk", "open", "query_file.read().splitlines", "set", "print", "pathlib.Path", "query_file.read", "shutil.copy", "os.path.join", "print"], "function", ["None"], ["def", "main", "(", "input_args", ")", ":", "\n", "    ", "Path", "(", "input_args", ".", "destination", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "with", "open", "(", "input_args", ".", "query_list", ",", "'r'", ")", "as", "query_file", ":", "\n", "        ", "file_lines", "=", "query_file", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "query_files_set", "=", "set", "(", "file_lines", ")", "\n", "\n", "", "video_counter", "=", "0", "\n", "total_video_counter", "=", "0", "\n", "for", "root", ",", "sub_dirs", ",", "files", "in", "os", ".", "walk", "(", "input_args", ".", "source_dir", ")", ":", "\n", "        ", "for", "file", "in", "files", ":", "\n", "            ", "total_video_counter", "+=", "1", "\n", "if", "file", "in", "query_files_set", ":", "\n", "                ", "video_counter", "+=", "1", "\n", "dest_loc", "=", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "root", ",", "file", ")", ",", "input_args", ".", "destination", ")", "\n", "if", "input_args", ".", "verbose", ":", "\n", "                    ", "print", "(", "f\"copied: {dest_loc}\"", ")", "\n", "\n", "", "", "", "", "if", "input_args", ".", "verbose", ":", "\n", "        ", "print", "(", "f\"Total # of videos: {total_video_counter}, Number of videos copied: {video_counter}\"", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.flow_to_image_hsv": [[5, 19], ["cv2.cartToPolar", "numpy.zeros", "cv2.normalize", "cv2.cvtColor"], "function", ["None"], ["def", "flow_to_image_hsv", "(", "flow", ")", ":", "\n", "    ", "\"\"\"\n    Flow visualization example from OpenCV Python example\n    \"\"\"", "\n", "mag", ",", "ang", "=", "cv2", ".", "cartToPolar", "(", "flow", "[", "...", ",", "0", "]", ",", "flow", "[", "...", ",", "1", "]", ")", "\n", "\n", "hsv", "=", "np", ".", "zeros", "(", "(", "flow", ".", "shape", "[", "0", "]", ",", "flow", ".", "shape", "[", "1", "]", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "hsv", "[", "...", ",", "1", "]", "=", "255", "\n", "\n", "hsv", "[", "...", ",", "0", "]", "=", "ang", "*", "180", "/", "np", ".", "pi", "/", "2", "\n", "hsv", "[", "...", ",", "2", "]", "=", "cv2", ".", "normalize", "(", "mag", ",", "None", ",", "0", ",", "255", ",", "cv2", ".", "NORM_MINMAX", ")", "\n", "bgr", "=", "cv2", ".", "cvtColor", "(", "hsv", ",", "cv2", ".", "COLOR_HSV2BGR", ")", "\n", "\n", "return", "bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.dense_vector": [[21, 41], ["frame.copy", "range", "range", "numpy.average", "numpy.average", "cv2.arrowedLine", "int", "int"], "function", ["None"], ["", "def", "dense_vector", "(", "frame", ",", "flow", ",", "vec_patch", ")", ":", "\n", "    ", "dense_vector_frame", "=", "frame", ".", "copy", "(", ")", "\n", "row_idx", "=", "0", "\n", "\n", "arrow_color", "=", "(", "0", ",", "0", ",", "0", ")", "if", "dense_vector_frame", ".", "ndim", "==", "3", "else", "0", "\n", "for", "i", "in", "range", "(", "flow", ".", "shape", "[", "0", "]", "//", "vec_patch", "[", "0", "]", ")", ":", "\n", "        ", "col_idx", "=", "0", "\n", "for", "j", "in", "range", "(", "flow", ".", "shape", "[", "1", "]", "//", "vec_patch", "[", "1", "]", ")", ":", "\n", "            ", "patch", "=", "flow", "[", "row_idx", ":", "row_idx", "+", "vec_patch", "[", "0", "]", ",", "col_idx", ":", "col_idx", "+", "vec_patch", "[", "1", "]", ",", ":", "]", "\n", "x_avg", "=", "np", ".", "average", "(", "patch", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "y_avg", "=", "np", ".", "average", "(", "patch", "[", ":", ",", ":", ",", "1", "]", ")", "\n", "\n", "point_a", "=", "(", "(", "col_idx", "+", "(", "vec_patch", "[", "1", "]", ")", "//", "2", ")", ",", "(", "row_idx", "+", "(", "vec_patch", "[", "0", "]", ")", "//", "2", ")", ")", "\n", "point_b", "=", "(", "int", "(", "point_a", "[", "0", "]", "+", "x_avg", ")", ",", "int", "(", "point_a", "[", "1", "]", "+", "y_avg", ")", ")", "\n", "\n", "dense_vector_frame", "=", "cv2", ".", "arrowedLine", "(", "dense_vector_frame", ",", "point_a", ",", "point_b", ",", "arrow_color", ",", "1", ")", "\n", "col_idx", "+=", "vec_patch", "[", "1", "]", "\n", "", "row_idx", "+=", "vec_patch", "[", "0", "]", "\n", "\n", "", "return", "dense_vector_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.flow_2_rgb": [[43, 93], ["flow[].copy", "flow[].copy", "numpy.sqrt", "numpy.any", "numpy.sqrt", "numpy.floor().astype", "flow_util.make_color_wheel", "numpy.max", "numpy.arctan2", "numpy.abs", "numpy.floor", "np.floor().astype.astype", "numpy.logical_not", "numpy.isnan", "numpy.isnan", "numpy.abs", "numpy.finfo"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.make_color_wheel"], ["", "def", "flow_2_rgb", "(", "flow", ",", "color_wheel", "=", "None", ",", "unknown_thr", "=", "1e6", ")", ":", "\n", "    ", "\"\"\"Convert flow map to RGB image.\n\n    Copied from https://github.com/NVIDIA/flownet2-pytorch\n\n    Args:\n        flow(ndarray): optical flow\n        color_wheel(ndarray or None): color wheel used to map flow field to RGB\n            colorspace. Default color wheel will be used if not specified\n        unknown_thr(str): values above this threshold will be marked as unknown\n            and thus ignored\n\n    Returns:\n        ndarray: an RGB image that can be visualized\n    \"\"\"", "\n", "assert", "flow", ".", "ndim", "==", "3", "and", "flow", ".", "shape", "[", "-", "1", "]", "==", "2", "\n", "if", "color_wheel", "is", "None", ":", "\n", "        ", "color_wheel", "=", "make_color_wheel", "(", ")", "\n", "", "assert", "color_wheel", ".", "ndim", "==", "2", "and", "color_wheel", ".", "shape", "[", "1", "]", "==", "3", "\n", "num_bins", "=", "color_wheel", ".", "shape", "[", "0", "]", "\n", "\n", "dx", "=", "flow", "[", ":", ",", ":", ",", "0", "]", ".", "copy", "(", ")", "\n", "dy", "=", "flow", "[", ":", ",", ":", ",", "1", "]", ".", "copy", "(", ")", "\n", "\n", "ignore_inds", "=", "(", "np", ".", "isnan", "(", "dx", ")", "|", "np", ".", "isnan", "(", "dy", ")", "|", "(", "np", ".", "abs", "(", "dx", ")", ">", "unknown_thr", ")", "|", "\n", "(", "np", ".", "abs", "(", "dy", ")", ">", "unknown_thr", ")", ")", "\n", "dx", "[", "ignore_inds", "]", "=", "0", "\n", "dy", "[", "ignore_inds", "]", "=", "0", "\n", "\n", "rad", "=", "np", ".", "sqrt", "(", "dx", "**", "2", "+", "dy", "**", "2", ")", "\n", "if", "np", ".", "any", "(", "rad", ">", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", ":", "\n", "        ", "max_rad", "=", "np", ".", "max", "(", "rad", ")", "\n", "dx", "/=", "max_rad", "\n", "dy", "/=", "max_rad", "\n", "\n", "", "rad", "=", "np", ".", "sqrt", "(", "dx", "**", "2", "+", "dy", "**", "2", ")", "\n", "angle", "=", "np", ".", "arctan2", "(", "-", "dy", ",", "-", "dx", ")", "/", "np", ".", "pi", "\n", "\n", "bin_real", "=", "(", "angle", "+", "1", ")", "/", "2", "*", "(", "num_bins", "-", "1", ")", "\n", "bin_left", "=", "np", ".", "floor", "(", "bin_real", ")", ".", "astype", "(", "int", ")", "\n", "bin_right", "=", "(", "bin_left", "+", "1", ")", "%", "num_bins", "\n", "w", "=", "(", "bin_real", "-", "bin_left", ".", "astype", "(", "np", ".", "float32", ")", ")", "[", "...", ",", "None", "]", "\n", "flow_img", "=", "(", "1", "-", "w", ")", "*", "color_wheel", "[", "bin_left", ",", ":", "]", "+", "w", "*", "color_wheel", "[", "bin_right", ",", ":", "]", "\n", "small_ind", "=", "rad", "<=", "1", "\n", "flow_img", "[", "small_ind", "]", "=", "1", "-", "rad", "[", "small_ind", ",", "None", "]", "*", "(", "1", "-", "flow_img", "[", "small_ind", "]", ")", "\n", "flow_img", "[", "np", ".", "logical_not", "(", "small_ind", ")", "]", "*=", "0.75", "\n", "\n", "flow_img", "[", "ignore_inds", ",", ":", "]", "=", "0", "\n", "\n", "return", "flow_img", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.make_color_wheel": [[95, 131], ["tuple", "numpy.zeros", "enumerate", "len", "range", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange"], "function", ["None"], ["", "def", "make_color_wheel", "(", "bins", "=", "None", ")", ":", "\n", "    ", "\"\"\"Build a color wheel\n\n    Args:\n        bins(list or tuple, optional): specify number of bins for each color\n            range, corresponding to six ranges: red -> yellow, yellow -> green,\n            green -> cyan, cyan -> blue, blue -> magenta, magenta -> red.\n            [15, 6, 4, 11, 13, 6] is used for default (see Middlebury).\n\n    Returns:\n        ndarray: color wheel of shape (total_bins, 3)\n    \"\"\"", "\n", "if", "bins", "is", "None", ":", "\n", "        ", "bins", "=", "[", "15", ",", "6", ",", "4", ",", "11", ",", "13", ",", "6", "]", "\n", "", "assert", "len", "(", "bins", ")", "==", "6", "\n", "\n", "RY", ",", "YG", ",", "GC", ",", "CB", ",", "BM", ",", "MR", "=", "tuple", "(", "bins", ")", "\n", "\n", "ry", "=", "[", "1", ",", "np", ".", "arange", "(", "RY", ")", "/", "RY", ",", "0", "]", "\n", "yg", "=", "[", "1", "-", "np", ".", "arange", "(", "YG", ")", "/", "YG", ",", "1", ",", "0", "]", "\n", "gc", "=", "[", "0", ",", "1", ",", "np", ".", "arange", "(", "GC", ")", "/", "GC", "]", "\n", "cb", "=", "[", "0", ",", "1", "-", "np", ".", "arange", "(", "CB", ")", "/", "CB", ",", "1", "]", "\n", "bm", "=", "[", "np", ".", "arange", "(", "BM", ")", "/", "BM", ",", "0", ",", "1", "]", "\n", "mr", "=", "[", "1", ",", "0", ",", "1", "-", "np", ".", "arange", "(", "MR", ")", "/", "MR", "]", "\n", "\n", "num_bins", "=", "RY", "+", "YG", "+", "GC", "+", "CB", "+", "BM", "+", "MR", "\n", "\n", "color_wheel", "=", "np", ".", "zeros", "(", "(", "3", ",", "num_bins", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "col", "=", "0", "\n", "for", "i", ",", "color", "in", "enumerate", "(", "[", "ry", ",", "yg", ",", "gc", ",", "cb", ",", "bm", ",", "mr", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "3", ")", ":", "\n", "            ", "color_wheel", "[", "j", ",", "col", ":", "col", "+", "bins", "[", "i", "]", "]", "=", "color", "[", "j", "]", "\n", "", "col", "+=", "bins", "[", "i", "]", "\n", "\n", "", "return", "color_wheel", ".", "T", "\n", "", ""]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.all_videos": [[11, 29], ["os.walk", "print", "os.path.join", "os.path.join", "fix_orientation.process_video", "video_file.endswith", "print"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.process_video"], ["def", "all_videos", "(", "input_args", ")", ":", "\n", "    ", "video_counter", "=", "0", "\n", "for", "root", ",", "sub_dirs", ",", "video_files", "in", "os", ".", "walk", "(", "input_args", ".", "source_dir", ")", ":", "\n", "        ", "for", "video_file", "in", "video_files", ":", "\n", "            ", "if", "not", "video_file", ".", "endswith", "(", "\".mov\"", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "input_video_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "video_file", ")", "\n", "output_video_path", "=", "os", ".", "path", ".", "join", "(", "input_args", ".", "destination", ",", "video_file", ")", "\n", "\n", "process_video", "(", "input_video_path", ",", "output_video_path", ")", "\n", "\n", "video_counter", "+=", "1", "\n", "if", "video_counter", "%", "50", "==", "0", ":", "\n", "                ", "print", "(", "f\"{video_counter} videos processed\"", ")", "\n", "\n", "", "", "print", "(", "f\"{video_counter} total videos processed\"", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.specific_video": [[31, 37], ["os.path.basename", "os.path.join", "fix_orientation.process_video"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.process_video"], ["", "def", "specific_video", "(", "input_args", ")", ":", "\n", "    ", "video_file", "=", "os", ".", "path", ".", "basename", "(", "input_args", ".", "source_video", ")", "\n", "output_video_path", "=", "os", ".", "path", ".", "join", "(", "input_args", ".", "destination", ",", "video_file", ")", "\n", "\n", "process_video", "(", "input_args", ".", "source_video", ",", "output_video_path", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.process_video": [[39, 80], ["cv2.VideoCapture", "int", "int", "int", "fix_orientation.get_rotation", "cv2.VideoWriter", "cv2.VideoCapture.release", "cv2.VideoWriter.release", "cv2.VideoCapture.isOpened", "print", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoWriter_fourcc", "cv2.VideoCapture.read", "cv2.VideoWriter.write", "cv2.rotate", "cv2.rotate", "cv2.rotate"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.get_rotation"], ["", "def", "process_video", "(", "input_video_path", ",", "output_video_path", ")", ":", "\n", "    ", "input_video", "=", "cv2", ".", "VideoCapture", "(", "input_video_path", ")", "\n", "if", "not", "input_video", ".", "isOpened", "(", ")", ":", "\n", "        ", "print", "(", "f\"Unable to open input video {input_video_path}\"", ")", "\n", "return", "\n", "\n", "", "frame_width", "=", "int", "(", "input_video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "frame_height", "=", "int", "(", "input_video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "frame_rate", "=", "int", "(", "input_video", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", ")", "\n", "\n", "rotation", "=", "get_rotation", "(", "input_video_path", ")", "\n", "\n", "if", "rotation", "in", "(", "270", ",", "90", ")", ":", "\n", "        ", "frame_size", "=", "(", "frame_height", ",", "frame_width", ")", "\n", "", "else", ":", "\n", "        ", "frame_size", "=", "(", "frame_width", ",", "frame_height", ")", "\n", "\n", "", "output_video", "=", "cv2", ".", "VideoWriter", "(", "output_video_path", ",", "\n", "cv2", ".", "VideoWriter_fourcc", "(", "'a'", ",", "'v'", ",", "'c'", ",", "'1'", ")", ",", "\n", "frame_rate", ",", "\n", "frame_size", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "frame_exists", ",", "frame", "=", "input_video", ".", "read", "(", ")", "\n", "\n", "if", "not", "frame_exists", ":", "\n", "            ", "break", "\n", "\n", "", "if", "rotation", "==", "270", ":", "\n", "            ", "frame", "=", "cv2", ".", "rotate", "(", "frame", ",", "cv2", ".", "ROTATE_90_COUNTERCLOCKWISE", ")", "\n", "", "elif", "rotation", "==", "90", ":", "\n", "            ", "frame", "=", "cv2", ".", "rotate", "(", "frame", ",", "cv2", ".", "ROTATE_90_CLOCKWISE", ")", "\n", "", "elif", "rotation", ":", "\n", "            ", "frame", "=", "cv2", ".", "rotate", "(", "frame", ",", "cv2", ".", "ROTATE_180", ")", "\n", "\n", "", "output_video", ".", "write", "(", "frame", ")", "\n", "\n", "", "input_video", ".", "release", "(", ")", "\n", "output_video", ".", "release", "(", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.fix_orientation.get_rotation": [[82, 91], ["skvideo.io.ffprobe", "int"], "function", ["None"], ["", "def", "get_rotation", "(", "input_video_path", ")", ":", "\n", "    ", "meta_data", "=", "skvideo", ".", "io", ".", "ffprobe", "(", "input_video_path", ")", "\n", "\n", "# meta_data['video']['tag'][0]['@key'] == 'rotate'", "\n", "for", "tag", "in", "meta_data", "[", "'video'", "]", "[", "'tag'", "]", ":", "\n", "        ", "if", "tag", "[", "'@key'", "]", "==", "'rotate'", ":", "\n", "            ", "return", "int", "(", "tag", "[", "'@value'", "]", ")", "\n", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.main": [[10, 46], ["cv2.VideoCapture", "int", "cv2.VideoCapture.read", "motion_viz.pre_process", "print", "print", "cv2.VideoCapture.isOpened", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "cv2.VideoCapture.get", "tuple", "cv2.VideoCapture.read", "motion_viz.pre_process", "motion_viz.dense_flow", "utils.flow_util.flow_2_rgb", "utils.flow_util.dense_vector", "cv2.imshow", "cv2.imshow", "cv2.waitKey"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.pre_process", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.pre_process", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.dense_flow", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.flow_2_rgb", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.flow_util.dense_vector"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "video", "=", "cv2", ".", "VideoCapture", "(", "args", ".", "input_video", ")", "\n", "\n", "frame_rate", "=", "int", "(", "video", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", ")", "\n", "resize", "=", "tuple", "(", "args", ".", "resize", ")", "if", "args", ".", "resize", "else", "None", "\n", "\n", "ret", ",", "frame_1", "=", "video", ".", "read", "(", ")", "\n", "frame_1", "=", "pre_process", "(", "frame_1", ",", "resize", ")", "\n", "\n", "print", "(", "f\"Frame Size: {frame_1.shape}\"", ")", "\n", "print", "(", "f\"Frame rate: {frame_rate}\"", ")", "\n", "\n", "while", "video", ".", "isOpened", "(", ")", ":", "\n", "        ", "ret", ",", "frame_2", "=", "video", ".", "read", "(", ")", "\n", "\n", "if", "frame_2", "is", "None", ":", "\n", "            ", "break", "\n", "\n", "", "frame_2", "=", "pre_process", "(", "frame_2", ",", "resize", ")", "\n", "\n", "# compute dense flow", "\n", "flow_vectors", "=", "dense_flow", "(", "frame_1", ",", "frame_2", ")", "\n", "\n", "dense_image", "=", "fu", ".", "flow_2_rgb", "(", "flow_vectors", ")", "\n", "dense_vectors_image", "=", "fu", ".", "dense_vector", "(", "frame_1", ",", "flow_vectors", ",", "args", ".", "dense_vec_patch", ")", "\n", "\n", "cv2", ".", "imshow", "(", "\"dense\"", ",", "dense_image", ")", "\n", "cv2", ".", "imshow", "(", "\"dense_vec\"", ",", "dense_vectors_image", ")", "\n", "cv2", ".", "waitKey", "(", "0", ")", "\n", "\n", "frame_1", "=", "frame_2", "\n", "\n", "", "video", ".", "release", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.dense_flow": [[48, 61], ["cv2.cvtColor", "cv2.cvtColor", "cv2.calcOpticalFlowFarneback"], "function", ["None"], ["", "def", "dense_flow", "(", "frame_a", ",", "frame_b", ")", ":", "\n", "    ", "frame_a_gray", "=", "cv2", ".", "cvtColor", "(", "frame_a", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "frame_b_gray", "=", "cv2", ".", "cvtColor", "(", "frame_b", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "\n", "# flow = (delta y, delta x)", "\n", "# num-levels: similar to SIFT features, 'zooming' into image to account for large displacement", "\n", "# win size: pre-smoothing (see above)", "\n", "# num_iters: book/paper suggests 6 is good", "\n", "# polyN, polySigma: see book", "\n", "# flags: gaussian smoothing makes flow worse for my data set", "\n", "flow", "=", "cv2", ".", "calcOpticalFlowFarneback", "(", "frame_a_gray", ",", "frame_b_gray", ",", "None", ",", "0.5", ",", "3", ",", "9", ",", "6", ",", "7", ",", "1.5", ",", "0", ")", "\n", "\n", "return", "flow", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.utils.motion_viz.pre_process": [[63, 68], ["cv2.resize"], "function", ["None"], ["", "def", "pre_process", "(", "frame", ",", "frame_resize", ")", ":", "\n", "    ", "if", "frame_resize", ":", "\n", "        ", "frame", "=", "cv2", ".", "resize", "(", "frame", ",", "frame_resize", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "\n", "", "return", "frame", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.create_model": [[15, 75], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "tensorflow.variable_scope", "int", "dcgan_model.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "dcgan_model.create_patch_discriminator", "tensorflow.variable_scope", "dcgan_model.create_patch_discriminator", "tensorflow.abs", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tensorflow.group", "network_input.get_shape", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith", "tensorflow.log", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator"], ["def", "create_model", "(", "arguments", ",", "network_input", ")", ":", "\n", "# create generator", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "network_input", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "generator_output", "=", "create_generator", "(", "arguments", ",", "network_input", ",", "out_channels", ")", "\n", "\n", "# create discriminator", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "            ", "predict_real", "=", "create_patch_discriminator", "(", "arguments", ",", "network_input", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "predict_fake", "=", "create_patch_discriminator", "(", "arguments", ",", "generator_output", ")", "\n", "\n", "# losses", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1; shape of this method is a parabola -(log(x) + log(1 - x))", "\n", "# disc output: 1 == real, 0 == fake .... log(1) == 0", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_gan", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_l1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "network_input", "-", "generator_output", ")", ")", "\n", "gen_loss", "=", "gen_loss_gan", "*", "arguments", ".", "gan_weight", "+", "gen_loss_l1", "*", "arguments", ".", "l1_weight", "\n", "\n", "# training", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_gan", ",", "gen_loss_l1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_gan", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_l1", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "generator_output", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.create_generator": [[78, 143], ["len", "enumerate", "tensorflow.variable_scope", "dcgan_model.convolution_layer", "tensorflow.layers.max_pooling2d", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "dcgan_model.deconvolution_layer", "tensorflow.tanh", "layers.append", "tensorflow.variable_scope", "dcgan_model.leaky_relu", "dcgan_model.convolution_layer", "dcgan_model.batch_norm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "dcgan_model.deconvolution_layer", "dcgan_model.batch_norm", "layers.append", "tensorflow.layers.max_pooling2d", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.deconvolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.deconvolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm"], ["", "def", "create_generator", "(", "arguments", ",", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "# encoder", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "convolution_layer", "(", "arguments", ",", "generator_inputs", ",", "arguments", ".", "ngf", ",", "dilate", "=", "(", "4", ",", "4", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "output", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "output", ",", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "(", "arguments", ".", "ngf", "*", "2", ",", "(", "4", ",", "4", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_2: ngf => ngf * 2", "\n", "(", "arguments", ".", "ngf", "*", "4", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_3: ngf * 2 => ngf * 4", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_4: ngf * 4 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_5: ngf * 8 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_6: ngf * 8 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_7: ngf * 8 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_8: ngf * 8 => ngf * 8", "\n", "]", "\n", "\n", "for", "(", "out_channels", ",", "dilation", ",", "stride", ")", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "leaky_relu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "convolution_layer", "(", "arguments", ",", "rectified", ",", "out_channels", ",", "stride", "=", "stride", ",", "dilate", "=", "dilation", ")", "\n", "\n", "if", "dilation", "[", "0", "]", ">", "1", ":", "\n", "                ", "convolved", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "convolved", ",", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "", "output", "=", "batch_norm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder", "\n", "", "", "layer_specs", "=", "[", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: ngf * 8 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: ngf * 8 * 2 => ngf * 4 * 2", "\n", "(", "arguments", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: ngf * 4 * 2 => ngf * 2 * 2", "\n", "(", "arguments", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: ngf * 2 * 2] => ngf * 2", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "decoder_layer_cont", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "decoder_layer_cont", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "layers", "[", "-", "1", "]", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "deconvolution_layer", "(", "arguments", ",", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batch_norm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: ngf * 2 => generator_outputs_channels", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "layers", "[", "-", "1", "]", ")", "\n", "output", "=", "deconvolution_layer", "(", "arguments", ",", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.create_patch_discriminator": [[145, 173], ["range", "tensorflow.variable_scope", "dcgan_model.discriminator_convolution_layer", "dcgan_model.leaky_relu", "layers.append", "tensorflow.variable_scope", "dcgan_model.discriminator_convolution_layer", "tensorflow.sigmoid", "layers.append", "tensorflow.variable_scope", "dcgan_model.discriminator_convolution_layer", "dcgan_model.batch_norm", "dcgan_model.leaky_relu", "layers.append", "min", "len", "len"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu"], ["", "def", "create_patch_discriminator", "(", "arguments", ",", "discriminator_input", ")", ":", "\n", "    ", "\"\"\"\n    Discriminator architecture described in docs/discriminator_architecture.txt\n    \"\"\"", "\n", "\n", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "        ", "convolved", "=", "discriminator_convolution_layer", "(", "discriminator_input", ",", "arguments", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "leaky_relu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "output_channels", "=", "arguments", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discriminator_convolution_layer", "(", "layers", "[", "-", "1", "]", ",", "output_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batch_norm", "(", "convolved", ")", "\n", "rectified", "=", "leaky_relu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "        ", "convolved", "=", "discriminator_convolution_layer", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.batch_norm": [[175, 178], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "batch_norm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "\n", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.deconvolution_layer": [[180, 192], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "def", "deconvolution_layer", "(", "arguments", ",", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.convolution_layer": [[194, 204], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "", "def", "convolution_layer", "(", "arguments", ",", "batch_input", ",", "out_channels", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "dilate", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "\n", "strides", "=", "stride", ",", "padding", "=", "\"same\"", ",", "dilation_rate", "=", "dilate", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "stride", ",", "\n", "dilation_rate", "=", "dilate", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.leaky_relu": [[206, 216], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "leaky_relu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: arguments*x/2 - arguments*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dcgan_model.discriminator_convolution_layer": [[218, 224], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "discriminator_convolution_layer", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "# rank in Tensorflow represents dimensions [d, 0] => before, [d, 1] => after where d=pad_row=input rank", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "\n", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.create_model": [[17, 113], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "cgan_model.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "cgan_model.discrim_conv", "cgan_model.leaky_relu", "layers.append", "tensorflow.variable_scope", "cgan_model.discrim_conv", "tensorflow.sigmoid", "layers.append", "tensorflow.variable_scope", "cgan_model.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.discrim_conv", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.discrim_conv"], ["def", "create_model", "(", "arguments", ",", "inputs", ",", "targets", ")", ":", "\n", "    ", "def", "create_discriminator", "(", "discriminator_inputs", ",", "discriminator_targets", ")", ":", "\n", "        ", "\"\"\"\n        Discriminator architecture described in docs/discriminator_architecture.txt\n        \"\"\"", "\n", "\n", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "\n", "d_input", "=", "tf", ".", "concat", "(", "[", "discriminator_inputs", ",", "discriminator_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "d_input", ",", "arguments", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "leaky_relu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "output_channels", "=", "arguments", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "output_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batch_norm", "(", "convolved", ")", "\n", "rectified", "=", "leaky_relu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "gen_outputs", "=", "create_generator", "(", "arguments", ",", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables: reuse=True under same variable scope", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "gen_outputs", ")", "\n", "\n", "# losses", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1; shape of this method is a parabola -(log(x) + log(1 - x))", "\n", "# disc output: 1 == real, 0 == fake .... log(1) == 0", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "# G attempts minimizes the second component (plus L1 loss) while D attempts to maximize the loss", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_gan", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "\n", "gen_loss_l1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "gen_outputs", ")", ")", "\n", "\n", "# note~ while it's called l1 loss, it's actually average epe error", "\n", "# gen_loss_l1 = average_endpoint_error(targets, gen_outputs)", "\n", "\n", "gen_loss", "=", "gen_loss_gan", "*", "arguments", ".", "gan_weight", "+", "gen_loss_l1", "*", "arguments", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_gan", ",", "gen_loss_l1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_gan", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_l1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "gen_outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.create_generator": [[116, 189], ["len", "enumerate", "tensorflow.variable_scope", "cgan_model.gen_conv", "tensorflow.layers.max_pooling2d", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "cgan_model.gen_deconv", "tensorflow.tanh", "layers.append", "tensorflow.variable_scope", "cgan_model.leaky_relu", "cgan_model.gen_conv", "cgan_model.batch_norm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "cgan_model.gen_deconv", "cgan_model.batch_norm", "layers.append", "tensorflow.layers.max_pooling2d", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_conv", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_deconv", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_conv", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_deconv", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm"], ["", "def", "create_generator", "(", "arguments", ",", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "# encoder", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "arguments", ",", "generator_inputs", ",", "arguments", ".", "ngf", ",", "dilate", "=", "(", "4", ",", "4", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "output", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "output", ",", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "(", "arguments", ".", "ngf", "*", "2", ",", "(", "4", ",", "4", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_2: ngf => ngf * 2", "\n", "(", "arguments", ".", "ngf", "*", "4", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_3: ngf * 2 => ngf * 4", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", ")", ",", "# encoder_4: ngf * 4 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_5: ngf * 8 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_6: ngf * 8 => ngf * 8", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "(", "1", ",", "1", ")", ",", "(", "2", ",", "2", ")", ")", ",", "# encoder_7: ngf * 8 => ngf * 8", "\n", "# (arguments.ngf * 8, (1, 1), (2, 2)),  # encoder_8: ngf * 8 => ngf * 8", "\n", "]", "\n", "\n", "for", "(", "out_channels", ",", "dilation", ",", "stride", ")", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "leaky_relu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "gen_conv", "(", "arguments", ",", "rectified", ",", "out_channels", ",", "stride", "=", "stride", ",", "dilate", "=", "dilation", ")", "\n", "\n", "if", "dilation", "[", "0", "]", ">", "1", ":", "\n", "                ", "convolved", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "convolved", ",", "pool_size", "=", "(", "2", ",", "2", ")", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "", "output", "=", "batch_norm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder", "\n", "", "", "layer_specs", "=", "[", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: ngf * 8 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: ngf * 8 * 2 => ngf * 4 * 2", "\n", "(", "arguments", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: ngf * 4 * 2 => ngf * 2 * 2", "\n", "# (arguments.ngf, 0.0)  # decoder_2: ngf * 2 * 2] => ngf * 2", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "dec_input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "dec_input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "dec_input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "arguments", ",", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batch_norm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: ngf * 2 => generator_outputs_channels", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "dec_input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "dec_input", ")", "\n", "output", "=", "gen_deconv", "(", "arguments", ",", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.average_endpoint_error": [[191, 210], ["tf.to_float.shape.as_list", "tensorflow.name_scope", "tensorflow.to_float", "tensorflow.to_float", "tf.to_float.get_shape().assert_is_compatible_with", "tensorflow.square", "tensorflow.reduce_sum", "tensorflow.sqrt", "tensorflow.reduce_sum", "tf.to_float.get_shape", "tensorflow.subtract", "tf.to_float.get_shape"], "function", ["None"], ["", "def", "average_endpoint_error", "(", "labels", ",", "predictions", ")", ":", "\n", "    ", "\"\"\"\n    Given labels and predictions of size (N, H, W, 2), calculates average endpoint error:\n        sqrt[sum_across_channels{(X - Y)^2}]\n\n    Average endpoint error is the average euclidean distance between the two optical flow vectors\n    \"\"\"", "\n", "num_samples", "=", "predictions", ".", "shape", ".", "as_list", "(", ")", "[", "0", "]", "\n", "with", "tf", ".", "name_scope", "(", "None", ",", "\"average_endpoint_error\"", ",", "(", "predictions", ",", "labels", ")", ")", "as", "scope", ":", "\n", "        ", "predictions", "=", "tf", ".", "to_float", "(", "predictions", ")", "\n", "labels", "=", "tf", ".", "to_float", "(", "labels", ")", "\n", "predictions", ".", "get_shape", "(", ")", ".", "assert_is_compatible_with", "(", "labels", ".", "get_shape", "(", ")", ")", "\n", "\n", "squared_difference", "=", "tf", ".", "square", "(", "tf", ".", "subtract", "(", "predictions", ",", "labels", ")", ")", "\n", "# sum across channels: sum[(X - Y)^2] -> N, H, W, 1", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "squared_difference", ",", "3", ",", "keep_dims", "=", "True", ")", "\n", "loss", "=", "tf", ".", "sqrt", "(", "loss", ")", "\n", "\n", "", "return", "tf", ".", "reduce_sum", "(", "loss", ")", "/", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.batch_norm": [[212, 215], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "batch_norm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "\n", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.leaky_relu": [[217, 227], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "def", "leaky_relu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: arguments*x/2 - arguments*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_deconv": [[229, 241], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "gen_deconv", "(", "arguments", ",", "batch_input", ",", "out_channels", ",", "stride", "=", "(", "2", ",", "2", ")", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "\n", "strides", "=", "stride", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.gen_conv": [[243, 253], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "", "def", "gen_conv", "(", "arguments", ",", "batch_input", ",", "out_channels", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "dilate", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "\n", "strides", "=", "stride", ",", "padding", "=", "\"same\"", ",", "dilation_rate", "=", "dilate", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "stride", ",", "\n", "dilation_rate", "=", "dilate", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.cgan_model.discrim_conv": [[255, 261], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "# rank in Tensorflow represents dimensions [d, 0] => before, [d, 1] => after where d=pad_row=input rank", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "\n", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.__init__": [[207, 250], ["keras.backend.image_data_format", "len", "keras.activations.get", "keras.activations.get", "keras.activations.get", "keras.activations.get", "keras.layers.Recurrent.__init__", "len", "len", "len", "len", "str", "int", "keras.engine.InputSpec", "str", "range"], "methods", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.__init__"], ["def", "__init__", "(", "self", ",", "stack_sizes", ",", "R_stack_sizes", ",", "\n", "A_filt_sizes", ",", "Ahat_filt_sizes", ",", "R_filt_sizes", ",", "\n", "pixel_max", "=", "1.", ",", "error_activation", "=", "'relu'", ",", "A_activation", "=", "'relu'", ",", "\n", "LSTM_activation", "=", "'tanh'", ",", "LSTM_inner_activation", "=", "'hard_sigmoid'", ",", "\n", "output_mode", "=", "'error'", ",", "extrap_start_time", "=", "None", ",", "\n", "data_format", "=", "K", ".", "image_data_format", "(", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "stack_sizes", "=", "stack_sizes", "\n", "self", ".", "nb_layers", "=", "len", "(", "stack_sizes", ")", "\n", "assert", "len", "(", "R_stack_sizes", ")", "==", "self", ".", "nb_layers", ",", "'len(R_stack_sizes) must equal len(stack_sizes)'", "\n", "self", ".", "R_stack_sizes", "=", "R_stack_sizes", "\n", "assert", "len", "(", "A_filt_sizes", ")", "==", "(", "self", ".", "nb_layers", "-", "1", ")", ",", "'len(A_filt_sizes) must equal len(stack_sizes) - 1'", "\n", "self", ".", "A_filt_sizes", "=", "A_filt_sizes", "\n", "assert", "len", "(", "Ahat_filt_sizes", ")", "==", "self", ".", "nb_layers", ",", "'len(Ahat_filt_sizes) must equal len(stack_sizes)'", "\n", "self", ".", "Ahat_filt_sizes", "=", "Ahat_filt_sizes", "\n", "assert", "len", "(", "R_filt_sizes", ")", "==", "(", "self", ".", "nb_layers", ")", ",", "'len(R_filt_sizes) must equal len(stack_sizes)'", "\n", "self", ".", "R_filt_sizes", "=", "R_filt_sizes", "\n", "\n", "self", ".", "pixel_max", "=", "pixel_max", "\n", "self", ".", "error_activation", "=", "activations", ".", "get", "(", "error_activation", ")", "\n", "self", ".", "A_activation", "=", "activations", ".", "get", "(", "A_activation", ")", "\n", "self", ".", "LSTM_activation", "=", "activations", ".", "get", "(", "LSTM_activation", ")", "\n", "self", ".", "LSTM_inner_activation", "=", "activations", ".", "get", "(", "LSTM_inner_activation", ")", "\n", "\n", "default_output_modes", "=", "[", "'prediction'", ",", "'error'", ",", "'all'", "]", "\n", "layer_output_modes", "=", "[", "layer", "+", "str", "(", "n", ")", "for", "n", "in", "range", "(", "self", ".", "nb_layers", ")", "for", "layer", "in", "[", "'R'", ",", "'E'", ",", "'A'", ",", "'Ahat'", "]", "]", "\n", "assert", "output_mode", "in", "default_output_modes", "+", "layer_output_modes", ",", "'Invalid output_mode: '", "+", "str", "(", "output_mode", ")", "\n", "self", ".", "output_mode", "=", "output_mode", "\n", "if", "self", ".", "output_mode", "in", "layer_output_modes", ":", "\n", "            ", "self", ".", "output_layer_type", "=", "self", ".", "output_mode", "[", ":", "-", "1", "]", "\n", "self", ".", "output_layer_num", "=", "int", "(", "self", ".", "output_mode", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_layer_type", "=", "None", "\n", "self", ".", "output_layer_num", "=", "None", "\n", "", "self", ".", "extrap_start_time", "=", "extrap_start_time", "\n", "\n", "assert", "data_format", "in", "{", "'channels_last'", ",", "\n", "'channels_first'", "}", ",", "'data_format must be in {channels_last, channels_first}'", "\n", "self", ".", "data_format", "=", "data_format", "\n", "self", ".", "channel_axis", "=", "-", "3", "if", "data_format", "==", "'channels_first'", "else", "-", "1", "\n", "self", ".", "row_axis", "=", "-", "2", "if", "data_format", "==", "'channels_first'", "else", "-", "3", "\n", "self", ".", "column_axis", "=", "-", "1", "if", "data_format", "==", "'channels_first'", "else", "-", "2", "\n", "super", "(", "PredNet", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "input_spec", "=", "[", "InputSpec", "(", "ndim", "=", "5", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.compute_output_shape": [[251, 273], ["numpy.prod", "getattr"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "output_mode", "==", "'prediction'", ":", "\n", "            ", "out_shape", "=", "input_shape", "[", "2", ":", "]", "\n", "", "elif", "self", ".", "output_mode", "==", "'error'", ":", "\n", "            ", "out_shape", "=", "(", "self", ".", "nb_layers", ",", ")", "\n", "", "elif", "self", ".", "output_mode", "==", "'all'", ":", "\n", "            ", "out_shape", "=", "(", "np", ".", "prod", "(", "input_shape", "[", "2", ":", "]", ")", "+", "self", ".", "nb_layers", ",", ")", "\n", "", "else", ":", "\n", "            ", "stack_str", "=", "'R_stack_sizes'", "if", "self", ".", "output_layer_type", "==", "'R'", "else", "'stack_sizes'", "\n", "stack_mult", "=", "2", "if", "self", ".", "output_layer_type", "==", "'E'", "else", "1", "\n", "out_stack_size", "=", "stack_mult", "*", "getattr", "(", "self", ",", "stack_str", ")", "[", "self", ".", "output_layer_num", "]", "\n", "out_nb_row", "=", "input_shape", "[", "self", ".", "row_axis", "]", "/", "2", "**", "self", ".", "output_layer_num", "\n", "out_nb_col", "=", "input_shape", "[", "self", ".", "column_axis", "]", "/", "2", "**", "self", ".", "output_layer_num", "\n", "if", "self", ".", "data_format", "==", "'channels_first'", ":", "\n", "                ", "out_shape", "=", "(", "out_stack_size", ",", "out_nb_row", ",", "out_nb_col", ")", "\n", "", "else", ":", "\n", "                ", "out_shape", "=", "(", "out_nb_row", ",", "out_nb_col", ",", "out_stack_size", ")", "\n", "\n", "", "", "if", "self", ".", "return_sequences", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", "input_shape", "[", "1", "]", ")", "+", "out_shape", "\n", "", "else", ":", "\n", "            ", "return", "(", "input_shape", "[", "0", "]", ",", ")", "+", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.get_initial_state": [[274, 323], ["keras.backend.zeros_like", "range", "keras.backend.sum", "keras.backend.sum", "states_to_pass.append", "range", "keras.backend.zeros", "keras.backend.dot", "keras.backend.reshape", "T.unbroadcast", "keras.backend.variable", "keras.backend.backend"], "methods", ["None"], ["", "", "def", "get_initial_state", "(", "self", ",", "x", ")", ":", "\n", "        ", "input_shape", "=", "self", ".", "input_spec", "[", "0", "]", ".", "shape", "\n", "init_nb_row", "=", "input_shape", "[", "self", ".", "row_axis", "]", "\n", "init_nb_col", "=", "input_shape", "[", "self", ".", "column_axis", "]", "\n", "\n", "base_initial_state", "=", "K", ".", "zeros_like", "(", "x", ")", "# (samples, timesteps) + image_shape", "\n", "non_channel_axis", "=", "-", "1", "if", "self", ".", "data_format", "==", "'channels_first'", "else", "-", "2", "\n", "for", "_", "in", "range", "(", "2", ")", ":", "\n", "            ", "base_initial_state", "=", "K", ".", "sum", "(", "base_initial_state", ",", "axis", "=", "non_channel_axis", ")", "\n", "", "base_initial_state", "=", "K", ".", "sum", "(", "base_initial_state", ",", "axis", "=", "1", ")", "# (samples, nb_channels)", "\n", "\n", "initial_states", "=", "[", "]", "\n", "states_to_pass", "=", "[", "'r'", ",", "'c'", ",", "'e'", "]", "\n", "nlayers_to_pass", "=", "{", "u", ":", "self", ".", "nb_layers", "for", "u", "in", "states_to_pass", "}", "\n", "if", "self", ".", "extrap_start_time", "is", "not", "None", ":", "\n", "            ", "states_to_pass", ".", "append", "(", "'ahat'", ")", "# pass prediction in states so can use as actual for t+1 when extrapolating", "\n", "nlayers_to_pass", "[", "'ahat'", "]", "=", "1", "\n", "", "for", "u", "in", "states_to_pass", ":", "\n", "            ", "for", "l", "in", "range", "(", "nlayers_to_pass", "[", "u", "]", ")", ":", "\n", "                ", "ds_factor", "=", "2", "**", "l", "\n", "nb_row", "=", "init_nb_row", "//", "ds_factor", "\n", "nb_col", "=", "init_nb_col", "//", "ds_factor", "\n", "if", "u", "in", "[", "'r'", ",", "'c'", "]", ":", "\n", "                    ", "stack_size", "=", "self", ".", "R_stack_sizes", "[", "l", "]", "\n", "", "elif", "u", "==", "'e'", ":", "\n", "                    ", "stack_size", "=", "2", "*", "self", ".", "stack_sizes", "[", "l", "]", "\n", "", "elif", "u", "==", "'ahat'", ":", "\n", "                    ", "stack_size", "=", "self", ".", "stack_sizes", "[", "l", "]", "\n", "", "output_size", "=", "stack_size", "*", "nb_row", "*", "nb_col", "# flattened size", "\n", "\n", "reducer", "=", "K", ".", "zeros", "(", "(", "input_shape", "[", "self", ".", "channel_axis", "]", ",", "output_size", ")", ")", "# (nb_channels, output_size)", "\n", "initial_state", "=", "K", ".", "dot", "(", "base_initial_state", ",", "reducer", ")", "# (samples, output_size)", "\n", "if", "self", ".", "data_format", "==", "'channels_first'", ":", "\n", "                    ", "output_shp", "=", "(", "-", "1", ",", "stack_size", ",", "nb_row", ",", "nb_col", ")", "\n", "", "else", ":", "\n", "                    ", "output_shp", "=", "(", "-", "1", ",", "nb_row", ",", "nb_col", ",", "stack_size", ")", "\n", "", "initial_state", "=", "K", ".", "reshape", "(", "initial_state", ",", "output_shp", ")", "\n", "initial_states", "+=", "[", "initial_state", "]", "\n", "\n", "", "", "if", "K", ".", "_BACKEND", "==", "'theano'", ":", "\n", "            ", "from", "theano", "import", "tensor", "as", "T", "\n", "# There is a known issue in the Theano scan op when dealing with inputs whose shape is 1 along a dimension.", "\n", "# In our case, this is a problem when training on grayscale images, and the below line fixes it.", "\n", "initial_states", "=", "[", "T", ".", "unbroadcast", "(", "init_state", ",", "0", ",", "1", ")", "for", "init_state", "in", "initial_states", "]", "\n", "\n", "", "if", "self", ".", "extrap_start_time", "is", "not", "None", ":", "\n", "# the last state will correspond to the current timestep", "\n", "            ", "initial_states", "+=", "[", "K", ".", "variable", "(", "0", ",", "int", "if", "K", ".", "backend", "(", ")", "!=", "'tensorflow'", "else", "'int32'", ")", "]", "\n", "", "return", "initial_states", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.build": [[324, 373], ["range", "keras.layers.UpSampling2D", "keras.layers.MaxPooling2D", "sorted", "keras.engine.InputSpec", "pred_net_model.PredNet.conv_layers[].append", "pred_net_model.PredNet.conv_layers.keys", "range", "keras.backend.variable", "pred_net_model.PredNet.conv_layers[].append", "keras.layers.Conv2D", "pred_net_model.PredNet.conv_layers[].append", "len", "keras.layers.Conv2D", "keras.layers.Conv2D", "keras.backend.name_scope", "[].build", "keras.backend.backend", "str"], "methods", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "input_spec", "=", "[", "InputSpec", "(", "shape", "=", "input_shape", ")", "]", "\n", "self", ".", "conv_layers", "=", "{", "c", ":", "[", "]", "for", "c", "in", "[", "'i'", ",", "'f'", ",", "'c'", ",", "'o'", ",", "'a'", ",", "'ahat'", "]", "}", "\n", "\n", "for", "l", "in", "range", "(", "self", ".", "nb_layers", ")", ":", "\n", "            ", "for", "c", "in", "[", "'i'", ",", "'f'", ",", "'c'", ",", "'o'", "]", ":", "\n", "                ", "act", "=", "self", ".", "LSTM_activation", "if", "c", "==", "'c'", "else", "self", ".", "LSTM_inner_activation", "\n", "self", ".", "conv_layers", "[", "c", "]", ".", "append", "(", "\n", "Conv2D", "(", "self", ".", "R_stack_sizes", "[", "l", "]", ",", "self", ".", "R_filt_sizes", "[", "l", "]", ",", "padding", "=", "'same'", ",", "activation", "=", "act", ",", "\n", "data_format", "=", "self", ".", "data_format", ")", ")", "\n", "\n", "", "act", "=", "'relu'", "if", "l", "==", "0", "else", "self", ".", "A_activation", "\n", "self", ".", "conv_layers", "[", "'ahat'", "]", ".", "append", "(", "\n", "Conv2D", "(", "self", ".", "stack_sizes", "[", "l", "]", ",", "self", ".", "Ahat_filt_sizes", "[", "l", "]", ",", "padding", "=", "'same'", ",", "activation", "=", "act", ",", "\n", "data_format", "=", "self", ".", "data_format", ")", ")", "\n", "\n", "if", "l", "<", "self", ".", "nb_layers", "-", "1", ":", "\n", "                ", "self", ".", "conv_layers", "[", "'a'", "]", ".", "append", "(", "\n", "Conv2D", "(", "self", ".", "stack_sizes", "[", "l", "+", "1", "]", ",", "self", ".", "A_filt_sizes", "[", "l", "]", ",", "padding", "=", "'same'", ",", "activation", "=", "self", ".", "A_activation", ",", "\n", "data_format", "=", "self", ".", "data_format", ")", ")", "\n", "\n", "", "", "self", ".", "upsample", "=", "UpSampling2D", "(", "data_format", "=", "self", ".", "data_format", ")", "\n", "self", ".", "pool", "=", "MaxPooling2D", "(", "data_format", "=", "self", ".", "data_format", ")", "\n", "\n", "self", ".", "trainable_weights", "=", "[", "]", "\n", "nb_row", ",", "nb_col", "=", "(", "input_shape", "[", "-", "2", "]", ",", "input_shape", "[", "-", "1", "]", ")", "if", "self", ".", "data_format", "==", "'channels_first'", "else", "(", "\n", "input_shape", "[", "-", "3", "]", ",", "input_shape", "[", "-", "2", "]", ")", "\n", "for", "c", "in", "sorted", "(", "self", ".", "conv_layers", ".", "keys", "(", ")", ")", ":", "\n", "            ", "for", "l", "in", "range", "(", "len", "(", "self", ".", "conv_layers", "[", "c", "]", ")", ")", ":", "\n", "                ", "ds_factor", "=", "2", "**", "l", "\n", "if", "c", "==", "'ahat'", ":", "\n", "                    ", "nb_channels", "=", "self", ".", "R_stack_sizes", "[", "l", "]", "\n", "", "elif", "c", "==", "'a'", ":", "\n", "                    ", "nb_channels", "=", "2", "*", "self", ".", "stack_sizes", "[", "l", "]", "\n", "", "else", ":", "\n", "                    ", "nb_channels", "=", "self", ".", "stack_sizes", "[", "l", "]", "*", "2", "+", "self", ".", "R_stack_sizes", "[", "l", "]", "\n", "if", "l", "<", "self", ".", "nb_layers", "-", "1", ":", "\n", "                        ", "nb_channels", "+=", "self", ".", "R_stack_sizes", "[", "l", "+", "1", "]", "\n", "", "", "in_shape", "=", "(", "input_shape", "[", "0", "]", ",", "nb_channels", ",", "nb_row", "//", "ds_factor", ",", "nb_col", "//", "ds_factor", ")", "\n", "if", "self", ".", "data_format", "==", "'channels_last'", ":", "in_shape", "=", "(", "in_shape", "[", "0", "]", ",", "in_shape", "[", "2", "]", ",", "in_shape", "[", "3", "]", ",", "in_shape", "[", "1", "]", ")", "\n", "with", "K", ".", "name_scope", "(", "'layer_'", "+", "c", "+", "'_'", "+", "str", "(", "l", ")", ")", ":", "\n", "                    ", "self", ".", "conv_layers", "[", "c", "]", "[", "l", "]", ".", "build", "(", "in_shape", ")", "\n", "", "self", ".", "trainable_weights", "+=", "self", ".", "conv_layers", "[", "c", "]", "[", "l", "]", ".", "trainable_weights", "\n", "\n", "", "", "self", ".", "states", "=", "[", "None", "]", "*", "self", ".", "nb_layers", "*", "3", "\n", "\n", "if", "self", ".", "extrap_start_time", "is", "not", "None", ":", "\n", "            ", "self", ".", "t_extrap", "=", "K", ".", "variable", "(", "self", ".", "extrap_start_time", ",", "int", "if", "K", ".", "backend", "(", ")", "!=", "'tensorflow'", "else", "'int32'", ")", "\n", "self", ".", "states", "+=", "[", "None", "]", "*", "2", "# [previous frame prediction, timestep]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.step": [[374, 451], ["reversed", "range", "keras.backend.switch", "range", "keras.backend.concatenate", "[].call", "[].call", "[].call", "c.insert", "r.insert", "[].call", "pred_net_model.PredNet.error_activation", "pred_net_model.PredNet.error_activation", "e.append", "keras.backend.concatenate.append", "pred_net_model.PredNet.LSTM_activation", "pred_net_model.PredNet.upsample.call", "keras.backend.minimum", "keras.backend.concatenate", "[].call", "pred_net_model.PredNet.pool.call", "range", "[].call", "keras.backend.mean", "keras.backend.concatenate", "keras.backend.batch_flatten", "keras.backend.concatenate", "keras.backend.batch_flatten"], "methods", ["None"], ["", "", "def", "step", "(", "self", ",", "a", ",", "states", ")", ":", "\n", "        ", "r_tm1", "=", "states", "[", ":", "self", ".", "nb_layers", "]", "\n", "c_tm1", "=", "states", "[", "self", ".", "nb_layers", ":", "2", "*", "self", ".", "nb_layers", "]", "\n", "e_tm1", "=", "states", "[", "2", "*", "self", ".", "nb_layers", ":", "3", "*", "self", ".", "nb_layers", "]", "\n", "\n", "if", "self", ".", "extrap_start_time", "is", "not", "None", ":", "\n", "            ", "t", "=", "states", "[", "-", "1", "]", "\n", "# if past self.extrap_start_time, the previous prediction will be treated as the actual", "\n", "a", "=", "K", ".", "switch", "(", "t", ">=", "self", ".", "t_extrap", ",", "states", "[", "-", "2", "]", ",", "a", ")", "\n", "\n", "", "c", "=", "[", "]", "\n", "r", "=", "[", "]", "\n", "e", "=", "[", "]", "\n", "\n", "# Update R units starting from the top", "\n", "for", "l", "in", "reversed", "(", "range", "(", "self", ".", "nb_layers", ")", ")", ":", "\n", "            ", "inputs", "=", "[", "r_tm1", "[", "l", "]", ",", "e_tm1", "[", "l", "]", "]", "\n", "if", "l", "<", "self", ".", "nb_layers", "-", "1", ":", "\n", "                ", "inputs", ".", "append", "(", "r_up", ")", "\n", "\n", "", "inputs", "=", "K", ".", "concatenate", "(", "inputs", ",", "axis", "=", "self", ".", "channel_axis", ")", "\n", "i", "=", "self", ".", "conv_layers", "[", "'i'", "]", "[", "l", "]", ".", "call", "(", "inputs", ")", "\n", "f", "=", "self", ".", "conv_layers", "[", "'f'", "]", "[", "l", "]", ".", "call", "(", "inputs", ")", "\n", "o", "=", "self", ".", "conv_layers", "[", "'o'", "]", "[", "l", "]", ".", "call", "(", "inputs", ")", "\n", "_c", "=", "f", "*", "c_tm1", "[", "l", "]", "+", "i", "*", "self", ".", "conv_layers", "[", "'c'", "]", "[", "l", "]", ".", "call", "(", "inputs", ")", "\n", "_r", "=", "o", "*", "self", ".", "LSTM_activation", "(", "_c", ")", "\n", "c", ".", "insert", "(", "0", ",", "_c", ")", "\n", "r", ".", "insert", "(", "0", ",", "_r", ")", "\n", "\n", "if", "l", ">", "0", ":", "\n", "                ", "r_up", "=", "self", ".", "upsample", ".", "call", "(", "_r", ")", "\n", "\n", "# Update feedforward path starting from the bottom", "\n", "", "", "for", "l", "in", "range", "(", "self", ".", "nb_layers", ")", ":", "\n", "            ", "ahat", "=", "self", ".", "conv_layers", "[", "'ahat'", "]", "[", "l", "]", ".", "call", "(", "r", "[", "l", "]", ")", "\n", "if", "l", "==", "0", ":", "\n", "# note~ comment K.minimum(...) when processing optical flow", "\n", "                ", "ahat", "=", "K", ".", "minimum", "(", "ahat", ",", "self", ".", "pixel_max", ")", "\n", "frame_prediction", "=", "ahat", "\n", "\n", "# compute errors", "\n", "", "e_up", "=", "self", ".", "error_activation", "(", "ahat", "-", "a", ")", "\n", "e_down", "=", "self", ".", "error_activation", "(", "a", "-", "ahat", ")", "\n", "\n", "e", ".", "append", "(", "K", ".", "concatenate", "(", "(", "e_up", ",", "e_down", ")", ",", "axis", "=", "self", ".", "channel_axis", ")", ")", "\n", "\n", "if", "self", ".", "output_layer_num", "==", "l", ":", "\n", "                ", "if", "self", ".", "output_layer_type", "==", "'A'", ":", "\n", "                    ", "output", "=", "a", "\n", "", "elif", "self", ".", "output_layer_type", "==", "'Ahat'", ":", "\n", "                    ", "output", "=", "ahat", "\n", "", "elif", "self", ".", "output_layer_type", "==", "'R'", ":", "\n", "                    ", "output", "=", "r", "[", "l", "]", "\n", "", "elif", "self", ".", "output_layer_type", "==", "'E'", ":", "\n", "                    ", "output", "=", "e", "[", "l", "]", "\n", "\n", "", "", "if", "l", "<", "self", ".", "nb_layers", "-", "1", ":", "\n", "                ", "a", "=", "self", ".", "conv_layers", "[", "'a'", "]", "[", "l", "]", ".", "call", "(", "e", "[", "l", "]", ")", "\n", "a", "=", "self", ".", "pool", ".", "call", "(", "a", ")", "# target for next layer", "\n", "\n", "", "", "if", "self", ".", "output_layer_type", "is", "None", ":", "\n", "            ", "if", "self", ".", "output_mode", "==", "'prediction'", ":", "\n", "                ", "output", "=", "frame_prediction", "\n", "", "else", ":", "\n", "                ", "for", "l", "in", "range", "(", "self", ".", "nb_layers", ")", ":", "\n", "                    ", "layer_error", "=", "K", ".", "mean", "(", "K", ".", "batch_flatten", "(", "e", "[", "l", "]", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "all_error", "=", "layer_error", "if", "l", "==", "0", "else", "K", ".", "concatenate", "(", "(", "all_error", ",", "layer_error", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "if", "self", ".", "output_mode", "==", "'error'", ":", "\n", "                    ", "output", "=", "all_error", "\n", "", "else", ":", "\n", "                    ", "output", "=", "K", ".", "concatenate", "(", "(", "K", ".", "batch_flatten", "(", "frame_prediction", ")", ",", "all_error", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "", "", "states", "=", "r", "+", "c", "+", "e", "\n", "if", "self", ".", "extrap_start_time", "is", "not", "None", ":", "\n", "            ", "states", "+=", "[", "frame_prediction", ",", "t", "+", "1", "]", "\n", "\n", "", "return", "output", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.get_config": [[452, 468], ["super().get_config", "dict", "list", "list", "super().get_config.items", "config.items"], "methods", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "'stack_sizes'", ":", "self", ".", "stack_sizes", ",", "\n", "'R_stack_sizes'", ":", "self", ".", "R_stack_sizes", ",", "\n", "'A_filt_sizes'", ":", "self", ".", "A_filt_sizes", ",", "\n", "'Ahat_filt_sizes'", ":", "self", ".", "Ahat_filt_sizes", ",", "\n", "'R_filt_sizes'", ":", "self", ".", "R_filt_sizes", ",", "\n", "'pixel_max'", ":", "self", ".", "pixel_max", ",", "\n", "'error_activation'", ":", "self", ".", "error_activation", ".", "__name__", ",", "\n", "'A_activation'", ":", "self", ".", "A_activation", ".", "__name__", ",", "\n", "'LSTM_activation'", ":", "self", ".", "LSTM_activation", ".", "__name__", ",", "\n", "'LSTM_inner_activation'", ":", "self", ".", "LSTM_inner_activation", ".", "__name__", ",", "\n", "'data_format'", ":", "self", ".", "data_format", ",", "\n", "'extrap_start_time'", ":", "self", ".", "extrap_start_time", ",", "\n", "'output_mode'", ":", "self", ".", "output_mode", "}", "\n", "base_config", "=", "super", "(", "PredNet", ",", "self", ")", ".", "get_config", "(", ")", "\n", "return", "dict", "(", "list", "(", "base_config", ".", "items", "(", ")", ")", "+", "list", "(", "config", ".", "items", "(", ")", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.create_model": [[19, 70], ["pred_net_model.PredNet", "keras.layers.Input", "numpy.array", "numpy.expand_dims", "PredNet.", "keras.optimizers.Adam", "keras.Model", "keras.Model.compile", "keras.Model.summary", "numpy.ones", "keras.layers.TimeDistributed", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "numpy.zeros", "numpy.zeros"], "function", ["None"], ["def", "create_model", "(", "arguments", ",", "look_back", ",", "x_shape", ",", "extrap_time", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    input shape: 64x256 -> 32x128 -> 16x64 -> 8x32 -> 4x16\n\n    :param arguments: ngf\n    :param x_shape: (rows, cols, channels)\n    :param look_back: sequence length\n    :return:\n    \"\"\"", "\n", "\n", "input_channels", "=", "x_shape", "[", "-", "1", "]", "\n", "stack_sizes", "=", "(", "input_channels", ",", "arguments", ".", "ngf", ",", "arguments", ".", "ngf", "*", "2", ",", "arguments", ".", "ngf", "*", "4", ",", "arguments", ".", "ngf", "*", "4", ")", "\n", "r_stack_sizes", "=", "stack_sizes", "\n", "a_filter_sizes", "=", "(", "3", ",", "3", ",", "3", ",", "3", ")", "\n", "a_hat_filter_sizes", "=", "(", "3", ",", "3", ",", "3", ",", "3", ",", "3", ")", "\n", "r_filter_sizes", "=", "(", "3", ",", "3", ",", "3", ",", "3", ",", "3", ")", "\n", "\n", "# note~ need A_activation to be tanh for optical flow", "\n", "pred_net_layer", "=", "PredNet", "(", "stack_sizes", ",", "r_stack_sizes", ",", "a_filter_sizes", ",", "a_hat_filter_sizes", ",", "\n", "r_filter_sizes", ",", "output_mode", "=", "'error'", ",", "data_format", "=", "'channels_last'", ",", "\n", "A_activation", "=", "'relu'", ",", "return_sequences", "=", "True", ",", "extrap_time", "=", "extrap_time", ")", "\n", "\n", "inputs", "=", "layers", ".", "Input", "(", "shape", "=", "(", "look_back", ",", ")", "+", "x_shape", ")", "\n", "\n", "# equally weight all timesteps except the first", "\n", "time_loss_weights", "=", "1.", "/", "(", "look_back", "-", "1", ")", "*", "np", ".", "ones", "(", "(", "look_back", ",", "1", ")", ")", "\n", "time_loss_weights", "[", "0", "]", "=", "0", "\n", "\n", "# weighting for each layer in final loss; \"L_0\" model:  [1, 0, 0, 0], \"L_all\": [1, 0.1, 0.1, 0.1]", "\n", "layer_loss_weights", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "layer_loss_weights", "=", "np", ".", "expand_dims", "(", "layer_loss_weights", ",", "1", ")", "\n", "\n", "errors", "=", "pred_net_layer", "(", "inputs", ")", "\n", "\n", "# calculate weighted error by layer", "\n", "errors_by_time", "=", "layers", ".", "TimeDistributed", "(", "layers", ".", "Dense", "(", "1", ",", "trainable", "=", "False", ")", ",", "\n", "weights", "=", "[", "layer_loss_weights", ",", "np", ".", "zeros", "(", "1", ")", "]", ",", "\n", "trainable", "=", "False", ")", "(", "errors", ")", "\n", "\n", "errors_by_time", "=", "layers", ".", "Flatten", "(", ")", "(", "errors_by_time", ")", "# will be (batch_size, nt)", "\n", "\n", "# weight errors by time, one weighed error for each batch", "\n", "final_errors", "=", "layers", ".", "Dense", "(", "1", ",", "weights", "=", "[", "time_loss_weights", ",", "np", ".", "zeros", "(", "1", ")", "]", ",", "trainable", "=", "False", ")", "(", "errors_by_time", ")", "\n", "\n", "adam_optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "lr", "=", "arguments", ".", "lr", ",", "beta_1", "=", "arguments", ".", "beta1", ")", "\n", "model", "=", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "final_errors", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'mean_absolute_error'", ",", "optimizer", "=", "adam_optimizer", ")", "\n", "\n", "model", ".", "summary", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.load_model_cont": [[72, 119], ["keras.models.load_model", "keras.Model.layers[].get_config", "pred_net_model.PredNet", "list", "keras.layers.Input", "PredNet.", "numpy.array", "numpy.expand_dims", "keras.optimizers.Adam", "keras.Model", "keras.Model.compile", "numpy.ones", "keras.layers.TimeDistributed", "keras.layers.Flatten", "keras.layers.Dense", "keras.Model.layers[].get_weights", "tuple", "keras.layers.Dense", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.load_model", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.get_config"], ["", "def", "load_model_cont", "(", "arguments", ",", "checkpoint_path", ",", "extrap_time", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Load PredNet model to continue training\n\n    :param arguments: look back, optimizer params\n    :param checkpoint_path: path to checkpoint\n    :param output_mode: by default, error for training or: 'prediction' | 'all'\n    :param extrap_time: Model extrapolating more than one frame\n    :return:\n    \"\"\"", "\n", "model", "=", "keras", ".", "models", ".", "load_model", "(", "checkpoint_path", ",", "custom_objects", "=", "{", "'PredNet'", ":", "PredNet", "}", ")", "\n", "\n", "layer_config", "=", "model", ".", "layers", "[", "1", "]", ".", "get_config", "(", ")", "\n", "\n", "layer_config", "[", "'output_mode'", "]", "=", "'error'", "\n", "\n", "if", "extrap_time", ":", "\n", "        ", "layer_config", "[", "'extrap_start_time'", "]", "=", "extrap_time", "\n", "\n", "", "pred_net_layer", "=", "PredNet", "(", "weights", "=", "model", ".", "layers", "[", "1", "]", ".", "get_weights", "(", ")", ",", "**", "layer_config", ")", "\n", "input_shape", "=", "list", "(", "model", ".", "layers", "[", "0", "]", ".", "batch_input_shape", "[", "1", ":", "]", ")", "\n", "\n", "input_shape", "[", "0", "]", "=", "arguments", ".", "look_back", "\n", "inputs", "=", "layers", ".", "Input", "(", "shape", "=", "tuple", "(", "input_shape", ")", ")", "\n", "\n", "errors", "=", "pred_net_layer", "(", "inputs", ")", "\n", "\n", "# calculate weighted error by layer", "\n", "layer_loss_weights", "=", "np", ".", "array", "(", "[", "1.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", "]", ")", "\n", "layer_loss_weights", "=", "np", ".", "expand_dims", "(", "layer_loss_weights", ",", "1", ")", "\n", "time_loss_weights", "=", "1.", "/", "(", "arguments", ".", "look_back", "-", "1", ")", "*", "np", ".", "ones", "(", "(", "arguments", ".", "look_back", ",", "1", ")", ")", "\n", "time_loss_weights", "[", "0", "]", "=", "0", "\n", "\n", "errors_by_time", "=", "layers", ".", "TimeDistributed", "(", "layers", ".", "Dense", "(", "1", ",", "trainable", "=", "False", ")", ",", "\n", "weights", "=", "[", "layer_loss_weights", ",", "np", ".", "zeros", "(", "1", ")", "]", ",", "\n", "trainable", "=", "False", ")", "(", "errors", ")", "\n", "\n", "errors_by_time", "=", "layers", ".", "Flatten", "(", ")", "(", "errors_by_time", ")", "# will be (batch_size, nt)", "\n", "\n", "# weight errors by time, one weighed error for each batch", "\n", "final_errors", "=", "layers", ".", "Dense", "(", "1", ",", "weights", "=", "[", "time_loss_weights", ",", "np", ".", "zeros", "(", "1", ")", "]", ",", "trainable", "=", "False", ")", "(", "errors_by_time", ")", "\n", "\n", "adam_optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", "lr", "=", "arguments", ".", "lr", ",", "beta_1", "=", "arguments", ".", "beta1", ")", "\n", "model", "=", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "final_errors", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'mean_absolute_error'", ",", "optimizer", "=", "adam_optimizer", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.load_model": [[121, 152], ["keras.models.load_model", "keras.models.load_model.layers[].get_config", "pred_net_model.PredNet", "list", "keras.layers.Input", "PredNet.", "keras.Model", "keras.models.load_model.layers[].get_weights", "tuple"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.load_model", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.pred_net_model.PredNet.get_config"], ["", "def", "load_model", "(", "checkpoint_path", ",", "look_back", ",", "output_mode", "=", "'prediction'", ",", "extrap_time", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Load PredNet model for testing purposes\n\n    :param checkpoint_path:\n    :param look_back: Can be different than the original model\n    :param output_mode: by default, 'prediction', can be 'all'\n    :return:\n    \"\"\"", "\n", "model", "=", "keras", ".", "models", ".", "load_model", "(", "checkpoint_path", ",", "custom_objects", "=", "{", "'PredNet'", ":", "PredNet", "}", ")", "\n", "\n", "layer_config", "=", "model", ".", "layers", "[", "1", "]", ".", "get_config", "(", ")", "\n", "\n", "layer_config", "[", "'output_mode'", "]", "=", "output_mode", "\n", "\n", "if", "extrap_time", ":", "\n", "        ", "layer_config", "[", "'extrap_start_time'", "]", "=", "extrap_time", "\n", "", "else", ":", "\n", "        ", "layer_config", "[", "'extrap_start_time'", "]", "=", "None", "\n", "\n", "", "test_pred_net", "=", "PredNet", "(", "weights", "=", "model", ".", "layers", "[", "1", "]", ".", "get_weights", "(", ")", ",", "**", "layer_config", ")", "\n", "input_shape", "=", "list", "(", "model", ".", "layers", "[", "0", "]", ".", "batch_input_shape", "[", "1", ":", "]", ")", "\n", "\n", "input_shape", "[", "0", "]", "=", "look_back", "\n", "inputs", "=", "layers", ".", "Input", "(", "shape", "=", "tuple", "(", "input_shape", ")", ")", "\n", "\n", "predictions", "=", "test_pred_net", "(", "inputs", ")", "\n", "\n", "test_model", "=", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "predictions", ")", "\n", "\n", "return", "test_model", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_model": [[18, 131], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.variable_scope", "int", "dgan_model.create_generator", "tensorflow.variable_scope", "int", "dgan_model.create_generator", "tensorflow.variable_scope", "int", "dgan_model.create_generator", "tensorflow.variable_scope", "int", "dgan_model.create_generator", "tensorflow.variable_scope", "dgan_model.create_patch_discriminator", "tensorflow.variable_scope", "dgan_model.create_patch_discriminator", "tensorflow.variable_scope", "dgan_model.create_patch_discriminator", "tensorflow.variable_scope", "dgan_model.create_patch_discriminator", "tensorflow.abs", "tensorflow.abs", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.control_dependencies", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tf.train.ExponentialMovingAverage.average", "tensorflow.group", "tensorflow.log", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith", "tensorflow.trainable_variables", "var.name.startswith", "source_input_b.get_shape", "source_input_a.get_shape", "source_input_b.get_shape", "source_input_a.get_shape", "tensorflow.log", "tensorflow.log", "tensorflow.log", "tensorflow.log", "tensorflow.trainable_variables", "var.name.startswith", "tensorflow.trainable_variables", "var.name.startswith"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator"], ["def", "create_model", "(", "arguments", ",", "source_input_a", ",", "source_input_b", ")", ":", "\n", "# create two generators", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"generator_ab_forward\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"GeneratorAB\"", ")", ":", "\n", "            ", "out_channels", "=", "int", "(", "source_input_b", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "gen_a_b", "=", "create_generator", "(", "arguments", ",", "source_input_a", ",", "out_channels", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"generator_ba_forward\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"GeneratorBA\"", ")", ":", "\n", "            ", "out_channels", "=", "int", "(", "source_input_a", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "gen_b_a", "=", "create_generator", "(", "arguments", ",", "source_input_b", ",", "out_channels", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"generator_ab_inverse\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"GeneratorAB\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "out_channels", "=", "int", "(", "source_input_b", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "gen_b_a_b", "=", "create_generator", "(", "arguments", ",", "gen_b_a", ",", "out_channels", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"generator_ba_inverse\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"GeneratorBA\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "out_channels", "=", "int", "(", "source_input_a", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "gen_a_b_a", "=", "create_generator", "(", "arguments", ",", "gen_a_b", ",", "out_channels", ")", "\n", "\n", "# create two discriminators", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator_ab\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"DiscriminatorAB\"", ")", ":", "\n", "            ", "predict_ab_real", "=", "create_patch_discriminator", "(", "arguments", ",", "source_input_a", ",", "source_input_b", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator_ab\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"DiscriminatorAB\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "predict_ab_fake", "=", "create_patch_discriminator", "(", "arguments", ",", "source_input_a", ",", "gen_a_b", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator_ba\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"DiscriminatorBA\"", ")", ":", "\n", "            ", "predict_ba_real", "=", "create_patch_discriminator", "(", "arguments", ",", "source_input_b", ",", "source_input_a", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator_ba\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"DiscriminatorBA\"", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "predict_ba_fake", "=", "create_patch_discriminator", "(", "arguments", ",", "source_input_b", ",", "gen_b_a", ")", "\n", "\n", "# losses", "\n", "\n", "# minimizing -tf.log will try to get inputs to 1; shape of this method is a parabola -(log(x) + log(1 - x))", "\n", "# disc output: 1 == real, 0 == fake .... log(1) == 0", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_ab_loss\"", ")", ":", "\n", "        ", "discrim_ab_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_ab_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_ab_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_ba_loss\"", ")", ":", "\n", "        ", "discrim_ba_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_ba_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_ba_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_ab_loss\"", ")", ":", "\n", "        ", "gen_ab_loss_gan", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_ab_fake", "+", "EPS", ")", ")", "\n", "gen_ab_loss_l1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "source_input_a", "-", "gen_a_b_a", ")", ")", "\n", "gen_ab_loss", "=", "gen_ab_loss_gan", "*", "arguments", ".", "gan_weight", "+", "gen_ab_loss_l1", "*", "arguments", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_ba_loss\"", ")", ":", "\n", "        ", "gen_ba_loss_gan", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_ba_fake", "+", "EPS", ")", ")", "\n", "gen_ba_loss_l1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "source_input_b", "-", "gen_b_a_b", ")", ")", "\n", "gen_ba_loss", "=", "gen_ba_loss_gan", "*", "arguments", ".", "gan_weight", "+", "gen_ba_loss_l1", "*", "arguments", ".", "l1_weight", "\n", "\n", "# training", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_ab_train\"", ")", ":", "\n", "        ", "discrim_ab_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"DiscriminatorAB\"", ")", "]", "\n", "discrim_ab_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "discrim_ab_grads_and_vars", "=", "discrim_ab_optim", ".", "compute_gradients", "(", "discrim_ab_loss", ",", "var_list", "=", "discrim_ab_tvars", ")", "\n", "discrim_ab_train", "=", "discrim_ab_optim", ".", "apply_gradients", "(", "discrim_ab_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_ba_train\"", ")", ":", "\n", "        ", "discrim_ba_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"DiscriminatorBA\"", ")", "]", "\n", "discrim_ba_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "discrim_ba_grads_and_vars", "=", "discrim_ba_optim", ".", "compute_gradients", "(", "discrim_ba_loss", ",", "var_list", "=", "discrim_ba_tvars", ")", "\n", "discrim_ba_train", "=", "discrim_ba_optim", ".", "apply_gradients", "(", "discrim_ba_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_ab_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_ab_train", "]", ")", ":", "\n", "            ", "gen_ab_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"GeneratorAB\"", ")", "]", "\n", "gen_ab_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "gen_ab_grads_and_vars", "=", "gen_ab_optim", ".", "compute_gradients", "(", "gen_ab_loss", ",", "var_list", "=", "gen_ab_tvars", ")", "\n", "gen_ab_train", "=", "gen_ab_optim", ".", "apply_gradients", "(", "gen_ab_grads_and_vars", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"generator_ba_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_ba_train", "]", ")", ":", "\n", "            ", "gen_ba_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"GeneratorBA\"", ")", "]", "\n", "gen_ba_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "arguments", ".", "lr", ",", "arguments", ".", "beta1", ")", "\n", "gen_ba_grads_and_vars", "=", "gen_ba_optim", ".", "compute_gradients", "(", "gen_ba_loss", ",", "var_list", "=", "gen_ba_tvars", ")", "\n", "gen_ba_train", "=", "gen_ba_optim", ".", "apply_gradients", "(", "gen_ba_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_ab_loss", ",", "gen_ab_loss_gan", ",", "gen_ab_loss_l1", ",", "\n", "discrim_ba_loss", ",", "gen_ba_loss_gan", ",", "gen_ba_loss_l1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "predict_ab_real", "=", "predict_ab_real", ",", "\n", "predict_ab_fake", "=", "predict_ab_fake", ",", "\n", "predict_ba_real", "=", "predict_ba_real", ",", "\n", "predict_ba_fake", "=", "predict_ba_fake", ",", "\n", "discrim_ab_loss", "=", "ema", ".", "average", "(", "discrim_ab_loss", ")", ",", "\n", "discrim_ba_loss", "=", "ema", ".", "average", "(", "discrim_ba_loss", ")", ",", "\n", "discrim_ab_grads_and_vars", "=", "discrim_ab_grads_and_vars", ",", "\n", "discrim_ba_grads_and_vars", "=", "discrim_ba_grads_and_vars", ",", "\n", "gen_ab_loss_GAN", "=", "ema", ".", "average", "(", "gen_ab_loss_gan", ")", ",", "\n", "gen_ba_loss_GAN", "=", "ema", ".", "average", "(", "gen_ba_loss_gan", ")", ",", "\n", "gen_ab_loss_L1", "=", "ema", ".", "average", "(", "gen_ab_loss_l1", ")", ",", "\n", "gen_ba_loss_L1", "=", "ema", ".", "average", "(", "gen_ba_loss_l1", ")", ",", "\n", "gen_ab_grads_and_vars", "=", "gen_ab_grads_and_vars", ",", "\n", "gen_ba_grads_and_vars", "=", "gen_ba_grads_and_vars", ",", "\n", "outputs", "=", "[", "gen_a_b", ",", "gen_b_a", ",", "gen_a_b_a", ",", "gen_b_a_b", "]", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_ab_train", ",", "gen_ba_train", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_generator": [[133, 200], ["len", "enumerate", "tensorflow.variable_scope", "dgan_model.convolution_layer", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "dgan_model.deconvolution_layer", "tensorflow.tanh", "layers.append", "tensorflow.variable_scope", "dgan_model.leaky_relu", "dgan_model.convolution_layer", "dgan_model.batch_norm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "dgan_model.deconvolution_layer", "dgan_model.batch_norm", "layers.append", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.deconvolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.deconvolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm"], ["", "def", "create_generator", "(", "arguments", ",", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "# encoder", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "convolution_layer", "(", "arguments", ",", "generator_inputs", ",", "arguments", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "arguments", ".", "ngf", "*", "2", ",", "# encoder_2: ngf => ngf * 2", "\n", "arguments", ".", "ngf", "*", "4", ",", "# encoder_3: ngf * 2 => ngf * 4", "\n", "arguments", ".", "ngf", "*", "8", ",", "# encoder_4: ngf * 4 => ngf * 8", "\n", "arguments", ".", "ngf", "*", "8", ",", "# encoder_5: ngf * 8 => ngf * 8", "\n", "arguments", ".", "ngf", "*", "8", ",", "# encoder_6: ngf * 8 => ngf * 8", "\n", "arguments", ".", "ngf", "*", "8", ",", "# encoder_7: ngf * 8 => ngf * 8", "\n", "arguments", ".", "ngf", "*", "8", ",", "# encoder_8: ngf * 8 => ngf * 8", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "leaky_relu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "convolution_layer", "(", "arguments", ",", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batch_norm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder", "\n", "", "", "layer_specs", "=", "[", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: ngf * 8 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: ngf * 8 * 2 => ngf * 8 * 2", "\n", "(", "arguments", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: ngf * 8 * 2 => ngf * 4 * 2", "\n", "(", "arguments", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: ngf * 4 * 2 => ngf * 2 * 2", "\n", "(", "arguments", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: ngf * 2 * 2] => ngf * 2", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "dec_input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "dec_input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "dec_input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "deconvolution_layer", "(", "arguments", ",", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batch_norm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: ngf * 2 => generator_outputs_channels", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "dec_input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "dec_input", ")", "\n", "output", "=", "deconvolution_layer", "(", "arguments", ",", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.create_patch_discriminator": [[202, 232], ["tensorflow.concat", "range", "tensorflow.variable_scope", "dgan_model.discriminator_convolution_layer", "dgan_model.leaky_relu", "layers.append", "tensorflow.variable_scope", "dgan_model.discriminator_convolution_layer", "tensorflow.sigmoid", "layers.append", "tensorflow.variable_scope", "dgan_model.discriminator_convolution_layer", "dgan_model.batch_norm", "dgan_model.leaky_relu", "layers.append", "min", "len", "len"], "function", ["home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm", "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu"], ["", "def", "create_patch_discriminator", "(", "arguments", ",", "discriminator_inputs", ",", "discriminator_targets", ")", ":", "\n", "    ", "\"\"\"\n    Discriminator architecture described in docs/discriminator_architecture.txt\n    \"\"\"", "\n", "\n", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "\n", "d_input", "=", "tf", ".", "concat", "(", "[", "discriminator_inputs", ",", "discriminator_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "        ", "convolved", "=", "discriminator_convolution_layer", "(", "d_input", ",", "arguments", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "leaky_relu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "output_channels", "=", "arguments", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discriminator_convolution_layer", "(", "layers", "[", "-", "1", "]", ",", "output_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batch_norm", "(", "convolved", ")", "\n", "rectified", "=", "leaky_relu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "        ", "convolved", "=", "discriminator_convolution_layer", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.batch_norm": [[234, 237], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "batch_norm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "\n", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.leaky_relu": [[239, 249], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "def", "leaky_relu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: arguments*x/2 - arguments*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.deconvolution_layer": [[251, 263], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "deconvolution_layer", "(", "arguments", ",", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "\n", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.convolution_layer": [[265, 274], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "", "def", "convolution_layer", "(", "arguments", ",", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "arguments", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "\n", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "\n", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.harpreets652_highway-traffic-anomaly.models.dgan_model.discriminator_convolution_layer": [[276, 282], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "discriminator_convolution_layer", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "# rank in Tensorflow represents dimensions [d, 0] => before, [d, 1] => after where d=pad_row=input rank", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "\n", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "", "", ""]]}